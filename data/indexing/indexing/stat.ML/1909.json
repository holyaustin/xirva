[{"id": "1909.00015", "submitter": "Gon\\c{c}alo M. Correia", "authors": "Gon\\c{c}alo M. Correia, Vlad Niculae, Andr\\'e F.T. Martins", "title": "Adaptively Sparse Transformers", "comments": "Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), 2019, Hong Kong, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have become ubiquitous in NLP. Recent architectures,\nnotably the Transformer, learn powerful context-aware word representations\nthrough layered, multi-headed attention. The multiple heads learn diverse types\nof word relationships. However, with standard softmax attention, all attention\nheads are dense, assigning a non-zero weight to all context words. In this\nwork, we introduce the adaptively sparse Transformer, wherein attention heads\nhave flexible, context-dependent sparsity patterns. This sparsity is\naccomplished by replacing softmax with $\\alpha$-entmax: a differentiable\ngeneralization of softmax that allows low-scoring words to receive precisely\nzero weight. Moreover, we derive a method to automatically learn the $\\alpha$\nparameter -- which controls the shape and sparsity of $\\alpha$-entmax --\nallowing attention heads to choose between focused or spread-out behavior. Our\nadaptively sparse Transformer improves interpretability and head diversity when\ncompared to softmax Transformers on machine translation datasets. Findings of\nthe quantitative and qualitative analysis of our approach include that heads in\ndifferent layers learn different sparsity preferences and tend to be more\ndiverse in their attention distributions than softmax Transformers.\nFurthermore, at no cost in accuracy, sparsity in attention heads helps to\nuncover different head specializations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 18:06:14 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 16:55:20 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Correia", "Gon\u00e7alo M.", ""], ["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1909.00021", "submitter": "Javier Turek", "authors": "Javier S. Turek, Shailee Jain, Vy Vo, Mihai Capota, Alexander G. Huth,\n  Theodore L. Willke", "title": "Approximating Stacked and Bidirectional Recurrent Architectures with the\n  Delayed Recurrent Neural Network", "comments": "to be published in Proceedings of International Conference on Machine\n  Learning 2020 (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that topological enhancements to recurrent neural\nnetworks (RNNs) can increase their expressiveness and representational\ncapacity. Two popular enhancements are stacked RNNs, which increases the\ncapacity for learning non-linear functions, and bidirectional processing, which\nexploits acausal information in a sequence. In this work, we explore the\ndelayed-RNN, which is a single-layer RNN that has a delay between the input and\noutput. We prove that a weight-constrained version of the delayed-RNN is\nequivalent to a stacked-RNN. We also show that the delay gives rise to partial\nacausality, much like bidirectional networks. Synthetic experiments confirm\nthat the delayed-RNN can mimic bidirectional networks, solving some acausal\ntasks similarly, and outperforming them in others. Moreover, we show similar\nperformance to bidirectional networks in a real-world natural language\nprocessing task. These results suggest that delayed-RNNs can approximate\ntopologies including stacked RNNs, bidirectional RNNs, and stacked\nbidirectional RNNs - but with equivalent or faster runtimes for the\ndelayed-RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 18:18:04 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 05:45:08 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Turek", "Javier S.", ""], ["Jain", "Shailee", ""], ["Vo", "Vy", ""], ["Capota", "Mihai", ""], ["Huth", "Alexander G.", ""], ["Willke", "Theodore L.", ""]]}, {"id": "1909.00025", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag and Andrei A. Rusu and Razvan Pascanu and\n  Francesco Visin and Hujun Yin and Raia Hadsell", "title": "Meta-Learning with Warped Gradient Descent", "comments": "28 pages, 13 figures, 3 tables. Published as a conference paper at\n  ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an efficient update rule from data that promotes rapid learning of\nnew tasks from the same distribution remains an open problem in meta-learning.\nTypically, previous works have approached this issue either by attempting to\ntrain a neural network that directly produces updates or by attempting to learn\nbetter initialisations or scaling factors for a gradient-based update rule.\nBoth of these approaches pose challenges. On one hand, directly producing an\nupdate forgoes a useful inductive bias and can easily lead to non-converging\nbehaviour. On the other hand, approaches that try to control a gradient-based\nupdate rule typically resort to computing gradients through the learning\nprocess to obtain their meta-gradients, leading to methods that can not scale\nbeyond few-shot task adaptation. In this work, we propose Warped Gradient\nDescent (WarpGrad), a method that intersects these approaches to mitigate their\nlimitations. WarpGrad meta-learns an efficiently parameterised preconditioning\nmatrix that facilitates gradient descent across the task distribution.\nPreconditioning arises by interleaving non-linear layers, referred to as\nwarp-layers, between the layers of a task-learner. Warp-layers are meta-learned\nwithout backpropagating through the task training process in a manner similar\nto methods that learn to directly produce updates. WarpGrad is computationally\nefficient, easy to implement, and can scale to arbitrarily large meta-learning\nproblems. We provide a geometrical interpretation of the approach and evaluate\nits effectiveness in a variety of settings, including few-shot, standard\nsupervised, continual and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 18:27:35 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 08:57:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Rusu", "Andrei A.", ""], ["Pascanu", "Razvan", ""], ["Visin", "Francesco", ""], ["Yin", "Hujun", ""], ["Hadsell", "Raia", ""]]}, {"id": "1909.00047", "submitter": "Anis Elgabli", "authors": "Anis Elgabli, Jihong Park, Amrit S. Bedi, Mehdi Bennis, Vaneet\n  Aggarwal", "title": "GADMM: Fast and Communication Efficient Framework for Distributed\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the data is distributed across multiple servers, lowering the\ncommunication cost between the servers (or workers) while solving the\ndistributed learning problem is an important problem and is the focus of this\npaper. In particular, we propose a fast, and communication-efficient\ndecentralized framework to solve the distributed machine learning (DML)\nproblem. The proposed algorithm, Group Alternating Direction Method of\nMultipliers (GADMM) is based on the Alternating Direction Method of Multipliers\n(ADMM) framework. The key novelty in GADMM is that it solves the problem in a\ndecentralized topology where at most half of the workers are competing for the\nlimited communication resources at any given time. Moreover, each worker\nexchanges the locally trained model only with two neighboring workers, thereby\ntraining a global model with a lower amount of communication overhead in each\nexchange. We prove that GADMM converges to the optimal solution for convex loss\nfunctions, and numerically show that it converges faster and more\ncommunication-efficient than the state-of-the-art communication-efficient\nalgorithms such as the Lazily Aggregated Gradient (LAG) and dual averaging, in\nlinear and logistic regression tasks on synthetic and real datasets.\nFurthermore, we propose Dynamic GADMM (D-GADMM), a variant of GADMM, and prove\nits convergence under the time-varying network topology of the workers.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 19:39:37 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 10:18:43 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 12:06:09 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Bedi", "Amrit S.", ""], ["Bennis", "Mehdi", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1909.00052", "submitter": "Amey Agrawal", "authors": "Amey Agrawal, Rohit Karlupia", "title": "Learning Digital Circuits: A Journey Through Weight Invariant\n  Self-Pruning Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, in the paper \"Weight Agnostic Neural Networks\" Gaier & Ha utilized\narchitecture search to find networks where the topology completely encodes the\nknowledge. However, architecture search in topology space is expensive. We use\nthe existing framework of binarized networks to find performant topologies by\nconstraining the weights to be either, zero or one. We show that such\ntopologies achieve performance similar to standard networks while pruning more\nthan 99% weights. We further demonstrate that these topologies can perform\ntasks using constant weights without any explicit tuning. Finally, we discover\nthat in our setup each neuron acts like a NOR gate, virtually learning a\ndigital circuit. We demonstrate the efficacy of our approach on computer vision\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:07:39 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 18:42:12 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 22:23:59 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Agrawal", "Amey", ""], ["Karlupia", "Rohit", ""]]}, {"id": "1909.00056", "submitter": "Nicolas Papernot", "authors": "Dan Boneh and Andrew J. Grotto and Patrick McDaniel and Nicolas\n  Papernot", "title": "How Relevant is the Turing Test in the Age of Sophisbots?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular culture has contemplated societies of thinking machines for\ngenerations, envisioning futures from utopian to dystopian. These futures are,\narguably, here now-we find ourselves at the doorstep of technology that can at\nleast simulate the appearance of thinking, acting, and feeling. The real\nquestion is: now what?\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:18:18 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Boneh", "Dan", ""], ["Grotto", "Andrew J.", ""], ["McDaniel", "Patrick", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1909.00057", "submitter": "Shaunak Mishra", "authors": "Shaunak Mishra, Jelena Gligorijevic, Narayan Bhamidipati", "title": "Learning from Multi-User Activity Trails for B2B Ad Targeting", "comments": "6 pages, accepted for AdKDD 2019 workshop held in conjunction with\n  KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online purchase decisions in organizations can go through a complex journey\nwith multiple agents involved in the decision making process. Depending on the\nproduct being purchased, and the organizational structure, the process may\ninvolve employees who first conduct market research, and then influence\ndecision makers who place the online purchase order. In such cases, the online\nactivity trail of a single individual in the organization may only provide\npartial information for predicting purchases (conversions). To refine\nconversion prediction for business-to-business (B2B) products using online\nactivity trails, we introduce the notion of relevant users in an organization\nwith respect to a given B2B advertiser, and leverage the collective activity\ntrails of such relevant users to predict conversions. In particular, our notion\nof relevant users is tied to a seed list of relevant activities for a B2B\nadvertiser, and we propose a method using distributed activity representations\nto build such a seed list. Experiments using data from Yahoo Gemini demonstrate\nthat the proposed methods can improve conversion prediction AUC by 8.8%, and\nprovide an interpretable advertiser specific list of activities useful for B2B\nad targeting.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:52:33 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Mishra", "Shaunak", ""], ["Gligorijevic", "Jelena", ""], ["Bhamidipati", "Narayan", ""]]}, {"id": "1909.00066", "submitter": "Amanda Coston", "authors": "Amanda Coston, Alan Mishler, Edward H. Kennedy, Alexandra Chouldechova", "title": "Counterfactual Risk Assessments, Evaluation, and Fairness", "comments": "To appear in ACM FAT* 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic risk assessments are increasingly used to help humans make\ndecisions in high-stakes settings, such as medicine, criminal justice and\neducation. In each of these cases, the purpose of the risk assessment tool is\nto inform actions, such as medical treatments or release conditions, often with\nthe aim of reducing the likelihood of an adverse event such as hospital\nreadmission or recidivism. Problematically, most tools are trained and\nevaluated on historical data in which the outcomes observed depend on the\nhistorical decision-making policy. These tools thus reflect risk under the\nhistorical policy, rather than under the different decision options that the\ntool is intended to inform. Even when tools are constructed to predict risk\nunder a specific decision, they are often improperly evaluated as predictors of\nthe target outcome.\n  Focusing on the evaluation task, in this paper we define counterfactual\nanalogues of common predictive performance and algorithmic fairness metrics\nthat we argue are better suited for the decision-making context. We introduce a\nnew method for estimating the proposed metrics using doubly robust estimation.\nWe provide theoretical results that show that only under strong conditions can\nfairness according to the standard metric and the counterfactual metric\nsimultaneously hold. Consequently, fairness-promoting methods that target\nparity in a standard fairness metric may --- and as we show empirically, do ---\ninduce greater imbalance in the counterfactual analogue. We provide empirical\ncomparisons on both synthetic data and a real world child welfare dataset to\ndemonstrate how the proposed method improves upon standard practice.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:47:20 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 15:15:16 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 14:08:46 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Coston", "Amanda", ""], ["Mishler", "Alan", ""], ["Kennedy", "Edward H.", ""], ["Chouldechova", "Alexandra", ""]]}, {"id": "1909.00102", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Abhinav Sethy", "title": "Knowledge Enhanced Attention for Robust Natural Language Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have been very successful at achieving high accuracy on\nnatural language inference (NLI) tasks. However, as demonstrated in recent\nliterature, when tested on some simple adversarial examples, most of the models\nsuffer a significant drop in performance. This raises the concern about the\nrobustness of NLI models. In this paper, we propose to make NLI models robust\nby incorporating external knowledge to the attention mechanism using a simple\ntransformation. We apply the new attention to two popular types of NLI models:\none is Transformer encoder, and the other is a decomposable model, and show\nthat our method can significantly improve their robustness. Moreover, when\ncombined with BERT pretraining, our method achieves the human-level performance\non the adversarial SNLI data set.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 01:04:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1909.00116", "submitter": "Dong Xia", "authors": "Dong Xia and Ming Yuan", "title": "Statistical Inferences of Linear Forms for Noisy Matrix Completion", "comments": "Minor typos are corrected; real data examples are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a flexible framework for making inferences about general linear\nforms of a large matrix based on noisy observations of a subset of its entries.\nIn particular, under mild regularity conditions, we develop a universal\nprocedure to construct asymptotically normal estimators of its linear forms\nthrough double-sample debiasing and low-rank projection whenever an entry-wise\nconsistent estimator of the matrix is available. These estimators allow us to\nsubsequently construct confidence intervals for and test hypotheses about the\nlinear forms. Our proposal was motivated by a careful perturbation analysis of\nthe empirical singular spaces under the noisy matrix completion model which\nmight be of independent interest. The practical merits of our proposed\ninference procedure are demonstrated on both simulated and real-world data\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 03:30:07 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 08:49:01 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Xia", "Dong", ""], ["Yuan", "Ming", ""]]}, {"id": "1909.00122", "submitter": "Shen Yan", "authors": "Shen Yan, Biyi Fang, Faen Zhang, Yu Zheng, Xiao Zeng, Hui Xu, Mi Zhang", "title": "HM-NAS: Efficient Neural Architecture Search via Hierarchical Masking", "comments": "9 pages, 6 figures, 6 tables. Nominated for ICCV 2019 Neural\n  Architects Workshop Best Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of automatic methods, often referred to as Neural Architecture Search\n(NAS), in designing neural network architectures has recently drawn\nconsiderable attention. In this work, we present an efficient NAS approach,\nnamed HM- NAS, that generalizes existing weight sharing based NAS approaches.\nExisting weight sharing based NAS approaches still adopt hand-designed\nheuristics to generate architecture candidates. As a consequence, the space of\narchitecture candidates is constrained in a subset of all possible\narchitectures, making the architecture search results sub-optimal. HM-NAS\naddresses this limitation via two innovations. First, HM-NAS incorporates a\nmulti-level architecture encoding scheme to enable searching for more flexible\nnetwork architectures. Second, it discards the hand-designed heuristics and\nincorporates a hierarchical masking scheme that automatically learns and\ndetermines the optimal architecture. Compared to state-of-the-art weight\nsharing based approaches, HM-NAS is able to achieve better architecture search\nperformance and competitive model evaluation accuracy. Without the constraint\nimposed by the hand-designed heuristics, our searched networks contain more\nflexible and meaningful architectures that existing weight sharing based NAS\napproaches are not able to discover.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 04:02:16 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 08:33:25 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Yan", "Shen", ""], ["Fang", "Biyi", ""], ["Zhang", "Faen", ""], ["Zheng", "Yu", ""], ["Zeng", "Xiao", ""], ["Xu", "Hui", ""], ["Zhang", "Mi", ""]]}, {"id": "1909.00145", "submitter": "Jinhui Xiong", "authors": "Jinhui Xiong, Peter Richt\\'arik, Wolfgang Heidrich", "title": "Stochastic Convolutional Sparse Coding", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods for Convolutional Sparse Coding usually employ\nFourier-domain solvers in order to speed up the convolution operators. However,\nthis approach is not without shortcomings. For example, Fourier-domain\nrepresentations implicitly assume circular boundary conditions and make it hard\nto fully exploit the sparsity of the problem as well as the small spatial\nsupport of the filters. In this work, we propose a novel stochastic\nspatial-domain solver, in which a randomized subsampling strategy is introduced\nduring the learning sparse codes. Afterwards, we extend the proposed strategy\nin conjunction with online learning, scaling the CSC model up to very large\nsample sizes. In both cases, we show experimentally that the proposed\nsubsampling strategy, with a reasonable selection of the subsampling rate,\noutperforms the state-of-the-art frequency-domain solvers in terms of execution\ntime without losing the learning quality. Finally, we evaluate the\neffectiveness of the over-complete dictionary learned from large-scale\ndatasets, which demonstrates an improved sparse representation of the natural\nimages on account of more abundant learned image features.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:37:08 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Xiong", "Jinhui", ""], ["Richt\u00e1rik", "Peter", ""], ["Heidrich", "Wolfgang", ""]]}, {"id": "1909.00183", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Eloise Sorin, Joshua D. Symons, Erik Mayer, Sophia\n  N. Yaliraki, Francesca Toni, Mauricio Barahona", "title": "Extracting information from free text through unsupervised graph-based\n  clustering: an application to patient incident records", "comments": "To appear as a book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large volume of text in electronic healthcare records often remains\nunderused due to a lack of methodologies to extract interpretable content. Here\nwe present an unsupervised framework for the analysis of free text that\ncombines text-embedding with paragraph vectors and graph-theoretical multiscale\ncommunity detection. We analyse text from a corpus of patient incident reports\nfrom the National Health Service in England to find content-based clusters of\nreports in an unsupervised manner and at different levels of resolution. Our\nunsupervised method extracts groups with high intrinsic textual consistency and\ncompares well against categories hand-coded by healthcare personnel. We also\nshow how to use our content-driven clusters to improve the supervised\nprediction of the degree of harm of the incident based on the text of the\nreport. Finally, we discuss future directions to monitor reports over time, and\nto detect emerging trends outside pre-existing categories.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 10:03:11 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Sorin", "Eloise", ""], ["Symons", "Joshua D.", ""], ["Mayer", "Erik", ""], ["Yaliraki", "Sophia N.", ""], ["Toni", "Francesca", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1909.00215", "submitter": "Yi-Ting Yeh", "authors": "Yi-Ting Yeh, Yun-Nung Chen", "title": "QAInfomax: Learning Robust Question Answering System by Mutual\n  Information Maximization", "comments": "EMNLP 2019 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard accuracy metrics indicate that modern reading comprehension systems\nhave achieved strong performance in many question answering datasets. However,\nthe extent these systems truly understand language remains unknown, and\nexisting systems are not good at distinguishing distractor sentences, which\nlook related but do not actually answer the question. To address this problem,\nwe propose QAInfomax as a regularizer in reading comprehension systems by\nmaximizing mutual information among passages, a question, and its answer.\nQAInfomax helps regularize the model to not simply learn the superficial\ncorrelation for answering questions. The experiments show that our proposed\nQAInfomax achieves the state-of-the-art performance on the benchmark\nAdversarial-SQuAD dataset.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 13:50:28 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yeh", "Yi-Ting", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1909.00218", "submitter": "Eyke H\\\"ullermeier", "authors": "Vu-Linh Nguyen, S\\'ebastien Destercke, Eyke H\\\"ullermeier", "title": "Epistemic Uncertainty Sampling", "comments": "Draft version of a paper to be published in the proceedings of DS\n  2019, 22nd International Conference on Discovery Science, Split, Croatia,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various strategies for active learning have been proposed in the machine\nlearning literature. In uncertainty sampling, which is among the most popular\napproaches, the active learner sequentially queries the label of those\ninstances for which its current prediction is maximally uncertain. The\npredictions as well as the measures used to quantify the degree of uncertainty,\nsuch as entropy, are almost exclusively of a probabilistic nature. In this\npaper, we advocate a distinction between two different types of uncertainty,\nreferred to as epistemic and aleatoric, in the context of active learning.\nRoughly speaking, these notions capture the reducible and the irreducible part\nof the total uncertainty in a prediction, respectively. We conjecture that, in\nuncertainty sampling, the usefulness of an instance is better reflected by its\nepistemic than by its aleatoric uncertainty. This leads us to suggest the\nprinciple of \"epistemic uncertainty sampling\", which we instantiate by means of\na concrete approach for measuring epistemic and aleatoric uncertainty. In\nexperimental studies, epistemic uncertainty sampling does indeed show promising\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 14:04:10 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Nguyen", "Vu-Linh", ""], ["Destercke", "S\u00e9bastien", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1909.00259", "submitter": "Hiroyuki Shindo", "authors": "Hiroyuki Shindo, Yuji Matsumoto", "title": "Gated Graph Recursive Neural Networks for Molecular Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecule property prediction is a fundamental problem for computer-aided drug\ndiscovery and materials science. Quantum-chemical simulations such as density\nfunctional theory (DFT) have been widely used for calculating the molecule\nproperties, however, because of the heavy computational cost, it is difficult\nto search a huge number of potential chemical compounds. Machine learning\nmethods for molecular modeling are attractive alternatives, however, the\ndevelopment of expressive, accurate, and scalable graph neural networks for\nlearning molecular representations is still challenging. In this work, we\npropose a simple and powerful graph neural networks for molecular property\nprediction. We model a molecular as a directed complete graph in which each\natom has a spatial position, and introduce a recursive neural network with\nsimple gating function. We also feed input embeddings for every layers as skip\nconnections to accelerate the training. Experimental results show that our\nmodel achieves the state-of-the-art performance on the standard benchmark\ndataset for molecular property prediction.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 18:30:06 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 08:27:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1909.00276", "submitter": "Robert Holland", "authors": "Robert Holland, Uday Patel, Phillip Lung, Elisa Chotzoglou and\n  Bernhard Kainz", "title": "Automatic Detection of Bowel Disease with Residual Networks", "comments": "Accepted to PRIME-MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crohn's disease, one of two inflammatory bowel diseases (IBD), affects\n200,000 people in the UK alone, or roughly one in every 500. We explore the\nfeasibility of deep learning algorithms for identification of terminal ileal\nCrohn's disease in Magnetic Resonance Enterography images on a small dataset.\nWe show that they provide comparable performance to the current clinical\nstandard, the MaRIA score, while requiring only a fraction of the preparation\nand inference time. Moreover, bowels are subject to high variation between\nindividuals due to the complex and free-moving anatomy. Thus we also explore\nthe effect of difficulty of the classification at hand on performance. Finally,\nwe employ soft attention mechanisms to amplify salient local features and add\ninterpretability.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 19:51:23 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Holland", "Robert", ""], ["Patel", "Uday", ""], ["Lung", "Phillip", ""], ["Chotzoglou", "Elisa", ""], ["Kainz", "Bernhard", ""]]}, {"id": "1909.00306", "submitter": "Hallee Wong", "authors": "Hallee E. Wong, Brianna C. Heggeseth, Steven J. Miller", "title": "Categorical Co-Frequency Analysis: Clustering Diagnosis Codes to Predict\n  Hospital Readmissions", "comments": "14 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting patients' risk of 30-day hospital readmission would\nenable hospitals to efficiently allocate resource-intensive interventions. We\ndevelop a new method, Categorical Co-Frequency Analysis (CoFA), for clustering\ndiagnosis codes from the International Classification of Diseases (ICD)\naccording to the similarity in relationships between covariates and readmission\nrisk. CoFA measures the similarity between diagnoses by the frequency with\nwhich two diagnoses are split in the same direction versus split apart in\nrandom forests to predict readmission risk. Applying CoFA to de-identified data\nfrom Berkshire Medical Center, we identified three groups of diagnoses that\nvary in readmission risk. To evaluate CoFA, we compared readmission risk models\nusing ICD majors and CoFA groups to a baseline model without diagnosis\nvariables. We found substituting ICD majors for the CoFA-identified clusters\nsimplified the model without compromising the accuracy of predictions. Fitting\nseparate models for each ICD major and CoFA group did not improve predictions,\nsuggesting that readmission risk may be more homogeneous that heterogeneous\nacross diagnosis groups.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 02:36:17 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wong", "Hallee E.", ""], ["Heggeseth", "Brianna C.", ""], ["Miller", "Steven J.", ""]]}, {"id": "1909.00311", "submitter": "Prasanna Balaprakash", "authors": "Prasanna Balaprakash and Romain Egele and Misha Salim and Stefan Wild\n  and Venkatram Vishwanath and Fangfang Xia and Tom Brettin and Rick Stevens", "title": "Scalable Reinforcement-Learning-Based Neural Architecture Search for\n  Cancer Deep Learning Research", "comments": "SC '19: IEEE/ACM International Conference on High Performance\n  Computing, Networking, Storage and Analysis, November 17--22, 2019, Denver,\n  CO", "journal-ref": null, "doi": "10.1145/3295500.3356202", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is a complex disease, the understanding and treatment of which are\nbeing aided through increases in the volume of collected data and in the scale\nof deployed computing power. Consequently, there is a growing need for the\ndevelopment of data-driven and, in particular, deep learning methods for\nvarious tasks such as cancer diagnosis, detection, prognosis, and prediction.\nDespite recent successes, however, designing high-performing deep learning\nmodels for nonimage and nontext cancer data is a time-consuming,\ntrial-and-error, manual task that requires both cancer domain and deep learning\nexpertise. To that end, we develop a reinforcement-learning-based neural\narchitecture search to automate deep-learning-based predictive model\ndevelopment for a class of representative cancer data. We develop custom\nbuilding blocks that allow domain experts to incorporate the\ncancer-data-specific characteristics. We show that our approach discovers deep\nneural network architectures that have significantly fewer trainable\nparameters, shorter training time, and accuracy similar to or higher than those\nof manually designed architectures. We study and demonstrate the scalability of\nour approach on up to 1,024 Intel Knights Landing nodes of the Theta\nsupercomputer at the Argonne Leadership Computing Facility.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 02:49:59 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Balaprakash", "Prasanna", ""], ["Egele", "Romain", ""], ["Salim", "Misha", ""], ["Wild", "Stefan", ""], ["Vishwanath", "Venkatram", ""], ["Xia", "Fangfang", ""], ["Brettin", "Tom", ""], ["Stevens", "Rick", ""]]}, {"id": "1909.00333", "submitter": "Hangfeng He", "authors": "Hangfeng He, Qiang Ning, Dan Roth", "title": "QuASE: Question-Answer Driven Sentence Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question-answering (QA) data often encodes essential information in many\nfacets. This paper studies a natural question: Can we get supervision from QA\ndata for other tasks (typically, non-QA ones)? For example, {\\em can we use\nQAMR (Michael et al., 2017) to improve named entity recognition?} We suggest\nthat simply further pre-training BERT is often not the best option, and propose\nthe {\\em question-answer driven sentence encoding (QuASE)} framework. QuASE\nlearns representations from QA data, using BERT or other state-of-the-art\ncontextual language models. In particular, we observe the need to distinguish\nbetween two types of sentence encodings, depending on whether the target task\nis a single- or multi-sentence input; in both cases, the resulting encoding is\nshown to be an easy-to-use plugin for many downstream tasks. This work may\npoint out an alternative way to supervise NLP tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 06:30:57 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 15:40:12 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 21:12:24 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["He", "Hangfeng", ""], ["Ning", "Qiang", ""], ["Roth", "Dan", ""]]}, {"id": "1909.00337", "submitter": "Zijun Zhang", "authors": "Zijun Zhang, Linqi Zhou, Liangke Gou, Ying Nian Wu", "title": "Neural Architecture Search for Joint Optimization of Predictive Power\n  and Biological Knowledge", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report a neural architecture search framework, BioNAS, that is tailored\nfor biomedical researchers to easily build, evaluate, and uncover novel\nknowledge from interpretable deep learning models. The introduction of\nknowledge dissimilarity functions in BioNAS enables the joint optimization of\npredictive power and biological knowledge through searching architectures in a\nmodel space. By optimizing the consistency with existing knowledge, we\ndemonstrate that BioNAS optimal models reveal novel knowledge in both simulated\ndata and in real data of functional genomics. BioNAS provides a useful tool for\ndomain experts to inject their prior belief into automated machine learning and\ntherefore making deep learning easily accessible to practitioners. BioNAS is\navailable at https://github.com/zj-zhang/BioNAS-pub.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 07:00:21 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Zijun", ""], ["Zhou", "Linqi", ""], ["Gou", "Liangke", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1909.00349", "submitter": "Tasnim Mohiuddin", "authors": "Han Cheol Moon, Tasnim Mohiuddin, Shafiq Joty, and Xu Chi", "title": "A Unified Neural Coherence Model", "comments": "To appear at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, neural approaches to coherence modeling have achieved\nstate-of-the-art results in several evaluation tasks. However, we show that\nmost of these models often fail on harder tasks with more realistic application\nscenarios. In particular, the existing models underperform on tasks that\nrequire the model to be sensitive to local contexts such as candidate ranking\nin conversational dialogue and in machine translation. In this paper, we\npropose a unified coherence model that incorporates sentence grammar,\ninter-sentence coherence relations, and global coherence patterns into a common\nneural framework. With extensive experiments on local and global discrimination\ntasks, we demonstrate that our proposed model outperforms existing models by a\ngood margin, and establish a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 08:16:53 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Moon", "Han Cheol", ""], ["Mohiuddin", "Tasnim", ""], ["Joty", "Shafiq", ""], ["Chi", "Xu", ""]]}, {"id": "1909.00367", "submitter": "Gustav Zickert", "authors": "Gustav Zickert and Can Evren Yarman", "title": "Gaussian mixture model decomposition of multivariate signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a greedy variational method for decomposing a non-negative\nmultivariate signal as a weighted sum of Gaussians, which, borrowing the\nterminology from statistics, we refer to as a Gaussian mixture model. Notably,\nour method has the following features: (1) It accepts multivariate signals,\ni.e. sampled multivariate functions, histograms, time series, images, etc. as\ninput. (2) The method can handle general (i.e. ellipsoidal) Gaussians. (3) No\nprior assumption on the number of mixture components is needed. To the best of\nour knowledge, no previous method for Gaussian mixture model decomposition\nsimultaneously enjoys all these features. We also prove an upper bound, which\ncannot be improved by a global constant, for the distance from any mode of a\nGaussian mixture model to the set of corresponding means. For mixtures of\nspherical Gaussians with common variance $\\sigma^2$, the bound takes the simple\nform $\\sqrt{n}\\sigma$. We evaluate our method on one- and two-dimensional\nsignals. Finally, we discuss the relation between clustering and signal\ndecomposition, and compare our method to the baseline expectation maximization\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 09:44:46 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 10:45:01 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Zickert", "Gustav", ""], ["Yarman", "Can Evren", ""]]}, {"id": "1909.00384", "submitter": "Hyunjung Kwak", "authors": "Gloria Hyunjung Kwak and Pan Hui", "title": "DeepHealth: Review and challenges of artificial intelligence in health\n  informatics", "comments": "42 pages, 19 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence has provided us with an exploration of a whole new\nresearch era. As more data and better computational power become available, the\napproach is being implemented in various fields. The demand for it in health\ninformatics is also increasing, and we can expect to see the potential benefits\nof its applications in healthcare. It can help clinicians diagnose disease,\nidentify drug effects for each patient, understand the relationship between\ngenotypes and phenotypes, explore new phenotypes or treatment recommendations,\nand predict infectious disease outbreaks with high accuracy. In contrast to\ntraditional models, recent artificial intelligence approaches do not require\ndomain-specific data pre-processing, and it is expected that it will ultimately\nchange life in the future. Despite its notable advantages, there are some key\nchallenges on data (high dimensionality, heterogeneity, time dependency,\nsparsity, irregularity, lack of label, bias) and model (reliability,\ninterpretability, feasibility, security, scalability) for practical use. This\narticle presents a comprehensive review of research applying artificial\nintelligence in health informatics, focusing on the last seven years in the\nfields of medical imaging, electronic health records, genomics, sensing, and\nonline communication health, as well as challenges and promising directions for\nfuture research. We highlight ongoing popular approaches' research and identify\nseveral challenges in building models.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 11:54:38 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 05:54:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kwak", "Gloria Hyunjung", ""], ["Hui", "Pan", ""]]}, {"id": "1909.00415", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Daniel Hsu, Luis Gravano", "title": "Leveraging Just a Few Keywords for Fine-Grained Aspect Detection Through\n  Weakly Supervised Co-Training", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-generated reviews can be decomposed into fine-grained segments (e.g.,\nsentences, clauses), each evaluating a different aspect of the principal entity\n(e.g., price, quality, appearance). Automatically detecting these aspects can\nbe useful for both users and downstream opinion mining applications. Current\nsupervised approaches for learning aspect classifiers require many fine-grained\naspect labels, which are labor-intensive to obtain. And, unfortunately,\nunsupervised topic models often fail to capture the aspects of interest. In\nthis work, we consider weakly supervised approaches for training aspect\nclassifiers that only require the user to provide a small set of seed words\n(i.e., weakly positive indicators) for the aspects of interest. First, we show\nthat current weakly supervised approaches do not effectively leverage the\npredictive power of seed words for aspect detection. Next, we propose a\nstudent-teacher approach that effectively leverages seed words in a\nbag-of-words classifier (teacher); in turn, we use the teacher to train a\nsecond model (student) that is potentially more powerful (e.g., a neural\nnetwork that uses pre-trained word embeddings). Finally, we show that iterative\nco-training can be used to cope with noisy seed words, leading to both improved\nteacher and student models. Our proposed approach consistently outperforms\nprevious weakly supervised approaches (by 14.1 absolute F1 points on average)\nin six different domains of product reviews and six multilingual datasets of\nrestaurant reviews.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 15:12:23 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Hsu", "Daniel", ""], ["Gravano", "Luis", ""]]}, {"id": "1909.00430", "submitter": "Matan Ben Noach", "authors": "Matan Ben Noach and Yoav Goldberg", "title": "Transfer Learning Between Related Tasks Using Expected Label Proportions", "comments": "EMNLP 2019", "journal-ref": "2019 Conference on Empirical Methods in Natural Language\n  Processing and 9th International Joint Conference on Natural Language\n  Processing", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning systems thrive on abundance of labeled training data but such\ndata is not always available, calling for alternative methods of supervision.\nOne such method is expectation regularization (XR) (Mann and McCallum, 2007),\nwhere models are trained based on expected label proportions. We propose a\nnovel application of the XR framework for transfer learning between related\ntasks, where knowing the labels of task A provides an estimation of the label\nproportion of task B. We then use a model trained for A to label a large\ncorpus, and use this corpus with an XR loss to train a model for task B. To\nmake the XR framework applicable to large-scale deep-learning setups, we\npropose a stochastic batched approximation procedure. We demonstrate the\napproach on the task of Aspect-based Sentiment classification, where we\neffectively use a sentence-level sentiment predictor to train accurate\naspect-based predictor. The method improves upon fully supervised neural system\ntrained on aspect-level data, and is also cumulative with LM-based pretraining,\nas we demonstrate by improving a BERT-based Aspect-based Sentiment model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 17:11:35 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Noach", "Matan Ben", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1909.00440", "submitter": "Abir De", "authors": "Abir De, Adish Singla, Utkarsh Upadhyay, Manuel Gomez-Rodriguez", "title": "Can A User Anticipate What Her Followers Want?", "comments": "Fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whenever a social media user decides to share a story, she is typically\npleased to receive likes, comments, shares, or, more generally, feedback from\nher followers. As a result, she may feel compelled to use the feedback she\nreceives to (re-)estimate her followers' preferences and decides which stories\nto share next to receive more (positive) feedback. Under which conditions can\nshe succeed? In this work, we first look into this problem from a theoretical\nperspective and then provide a set of practical algorithms to identify and\ncharacterize such behavior in social media. More specifically, we address the\nabove problem from the viewpoint of sequential decision making and utility\nmaximization. For a wide variety of utility functions, we first show that, to\nsucceed, a user needs to actively trade off exploitation-- sharing stories\nwhich lead to more (positive) feedback--and exploration-- sharing stories to\nlearn about her followers' preferences. However, exploration is not necessary\nif a user utilizes the feedback her followers provide to other users in\naddition to the feedback she receives. Then, we develop a utility estimation\nframework for observation data, which relies on statistical hypothesis testing\nto determine whether a user utilizes the feedback she receives from each of her\nfollowers to decide what to post next. Experiments on synthetic data illustrate\nour theoretical findings and show that our estimation framework is able to\naccurately recover users' underlying utility functions. Experiments on several\nreal datasets gathered from Twitter and Reddit reveal that up to 82% (43%) of\nthe Twitter (Reddit) users in our datasets do use the feedback they receive to\ndecide what to post next.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 18:19:51 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 12:28:39 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["De", "Abir", ""], ["Singla", "Adish", ""], ["Upadhyay", "Utkarsh", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1909.00453", "submitter": "Sachin Kumar", "authors": "Sachin Kumar, Shuly Wintner, Noah A. Smith, Yulia Tsvetkov", "title": "Topics to Avoid: Demoting Latent Confounds in Text Classification", "comments": "2019 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive performance on many text classification tasks, deep neural\nnetworks tend to learn frequent superficial patterns that are specific to the\ntraining data and do not always generalize well. In this work, we observe this\nlimitation with respect to the task of native language identification. We find\nthat standard text classifiers which perform well on the test set end up\nlearning topical features which are confounds of the prediction task (e.g., if\nthe input text mentions Sweden, the classifier predicts that the author's\nnative language is Swedish). We propose a method that represents the latent\ntopical confounds and a model which \"unlearns\" confounding features by\npredicting both the label of the input text and the confound; but we train the\ntwo predictors adversarially in an alternating fashion to learn a text\nrepresentation that predicts the correct label but is less prone to using\ninformation about the confound. We show that this model generalizes better and\nlearns features that are indicative of the writing style rather than the\ncontent.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 19:18:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 20:18:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kumar", "Sachin", ""], ["Wintner", "Shuly", ""], ["Smith", "Noah A.", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "1909.00513", "submitter": "Shengyu Zhu", "authors": "Zhitang Chen, Shengyu Zhu, Yue Liu, Tim Tse", "title": "Causal Discovery by Kernel Intrinsic Invariance Measure", "comments": "9 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning based on causality, instead of association has been considered as a\nkey ingredient towards real machine intelligence. However, it is a challenging\ntask to infer causal relationship/structure among variables. In recent years,\nan Independent Mechanism (IM) principle was proposed, stating that the\nmechanism generating the cause and the one mapping the cause to the effect are\nindependent. As the conjecture, it is argued that in the causal direction, the\nconditional distributions instantiated at different value of the conditioning\nvariable have less variation than the anti-causal direction. Existing\nstate-of-the-arts simply compare the variance of the RKHS mean embedding norms\nof these conditional distributions. In this paper, we prove that this\nnorm-based approach sacrifices important information of the original\nconditional distributions. We propose a Kernel Intrinsic Invariance Measure\n(KIIM) to capture higher order statistics corresponding to the shapes of the\ndensity functions. We show our algorithm can be reduced to an\neigen-decomposition task on a kernel matrix measuring intrinsic\ndeviance/invariance. Causal directions can then be inferred by comparing the\nKIIM scores of two hypothetic directions. Experiments on synthetic and real\ndata are conducted to show the advantages of our methods over existing\nsolutions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:56:47 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Chen", "Zhitang", ""], ["Zhu", "Shengyu", ""], ["Liu", "Yue", ""], ["Tse", "Tim", ""]]}, {"id": "1909.00521", "submitter": "Yue Yu", "authors": "Yue Yu and Siyao Peng and Grace Hui Yang", "title": "Modeling Long-Range Context for Concurrent Dialogue Acts Recognition", "comments": "Accepted to CIKM '19", "journal-ref": null, "doi": "10.1145/3357384.3358145", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In dialogues, an utterance is a chain of consecutive sentences produced by\none speaker which ranges from a short sentence to a thousand-word post. When\nstudying dialogues at the utterance level, it is not uncommon that an utterance\nwould serve multiple functions. For instance, \"Thank you. It works great.\"\nexpresses both gratitude and positive feedback in the same utterance. Multiple\ndialogue acts (DA) for one utterance breeds complex dependencies across\ndialogue turns. Therefore, DA recognition challenges a model's predictive power\nover long utterances and complex DA context. We term this problem Concurrent\nDialogue Acts (CDA) recognition. Previous work on DA recognition either assumes\none DA per utterance or fails to realize the sequential nature of dialogues. In\nthis paper, we present an adapted Convolutional Recurrent Neural Network (CRNN)\nwhich models the interactions between utterances of long-range context. Our\nmodel significantly outperforms existing work on CDA recognition on a tech\nforum dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:12:19 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 13:28:58 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Yu", "Yue", ""], ["Peng", "Siyao", ""], ["Yang", "Grace Hui", ""]]}, {"id": "1909.00523", "submitter": "Zhao Zhang", "authors": "Zhao Zhang, Yan Zhang, Sheng Li, Guangcan Liu, Dan Zeng, Shuicheng Yan\n  and Meng Wang", "title": "Flexible Auto-weighted Local-coordinate Concept Factorization: A Robust\n  Framework for Unsupervised Clustering", "comments": "Accepted by IEEE Transactions on Knowledge and Data Engineering (IEEE\n  TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept Factorization (CF) and its variants may produce inaccurate\nrepresentation and clustering results due to the sensitivity to noise, hard\nconstraint on the reconstruction error and pre-obtained approximate\nsimilarities. To improve the representation ability, a novel unsupervised\nRobust Flexible Auto-weighted Local-coordinate Concept Factorization (RFA-LCF)\nframework is proposed for clustering high-dimensional data. Specifically,\nRFA-LCF integrates the robust flexible CF by clean data space recovery, robust\nsparse local-coordinate coding and adaptive weighting into a unified model.\nRFA-LCF improves the representations by enhancing the robustness of CF to noise\nand errors, providing a flexible constraint on the reconstruction error and\noptimizing the locality jointly. For robust learning, RFA-LCF clearly learns a\nsparse projection to recover the underlying clean data space, and then the\nflexible CF is performed in the projected feature space. RFA-LCF also uses a\nL2,1-norm based flexible residue to encode the mismatch between the recovered\ndata and its reconstruction, and uses the robust sparse local-coordinate coding\nto represent data using a few nearby basis concepts. For auto-weighting,\nRFA-LCF jointly preserves the manifold structures in the basis concept space\nand new coordinate space in an adaptive manner by minimizing the reconstruction\nerrors on clean data, anchor points and coordinates. By updating the\nlocal-coordinate preserving data, basis concepts and new coordinates\nalternately, the representation abilities can be potentially improved.\nExtensive results on public databases show that RFA-LCF delivers the\nstate-of-the-art clustering results compared with other related methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:16:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Zhao", ""], ["Zhang", "Yan", ""], ["Li", "Sheng", ""], ["Liu", "Guangcan", ""], ["Zeng", "Dan", ""], ["Yan", "Shuicheng", ""], ["Wang", "Meng", ""]]}, {"id": "1909.00525", "submitter": "Yiling Jia", "authors": "Yiling Jia, Nipun Batra, Hongning Wang, Kamin Whitehouse", "title": "Active Collaborative Sensing for Energy Breakdown", "comments": "12 pages, CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3357929", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residential homes constitute roughly one-fourth of the total energy usage\nworldwide. Providing appliance-level energy breakdown has been shown to induce\npositive behavioral changes that can reduce energy consumption by 15%. Existing\napproaches for energy breakdown either require hardware installation in every\ntarget home or demand a large set of energy sensor data available for model\ntraining. However, very few homes in the world have installed sub-meters\n(sensors measuring individual appliance energy); and the cost of retrofitting a\nhome with extensive sub-metering eats into the funds available for energy\nsaving retrofits. As a result, strategically deploying sensing hardware to\nmaximize the reconstruction accuracy of sub-metered readings in\nnon-instrumented homes while minimizing deployment costs becomes necessary and\npromising. In this work, we develop an active learning solution based on\nlow-rank tensor completion for energy breakdown. We propose to actively deploy\nenergy sensors to appliances from selected homes, with a goal to improve the\nprediction accuracy of the completed tensor with minimum sensor deployment\ncost. We empirically evaluate our approach on the largest public energy dataset\ncollected in Austin, Texas, USA, from 2013 to 2017. The results show that our\napproach gives better performance with a fixed number of sensors installed when\ncompared to the state-of-the-art, which is also proven by our theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:30:39 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Jia", "Yiling", ""], ["Batra", "Nipun", ""], ["Wang", "Hongning", ""], ["Whitehouse", "Kamin", ""]]}, {"id": "1909.00590", "submitter": "Hansika Hewamalage", "authors": "Hansika Hewamalage, Christoph Bergmeir, Kasun Bandara", "title": "Recurrent Neural Networks for Time Series Forecasting: Current Status\n  and Future Directions", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijforecast.2020.06.008", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) have become competitive forecasting methods,\nas most notably shown in the winning method of the recent M4 competition.\nHowever, established statistical models such as ETS and ARIMA gain their\npopularity not only from their high accuracy, but they are also suitable for\nnon-expert users as they are robust, efficient, and automatic. In these areas,\nRNNs have still a long way to go. We present an extensive empirical study and\nan open-source software framework of existing RNN architectures for\nforecasting, that allow us to develop guidelines and best practices for their\nuse. For example, we conclude that RNNs are capable of modelling seasonality\ndirectly if the series in the dataset possess homogeneous seasonal patterns,\notherwise we recommend a deseasonalization step. Comparisons against ETS and\nARIMA demonstrate that the implemented (semi-)automatic RNN models are no\nsilver bullets, but they are competitive alternatives in many situations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:20:30 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 12:32:55 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 01:12:24 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 05:46:58 GMT"}, {"version": "v5", "created": "Wed, 23 Dec 2020 01:56:57 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Hewamalage", "Hansika", ""], ["Bergmeir", "Christoph", ""], ["Bandara", "Kasun", ""]]}, {"id": "1909.00659", "submitter": "Prashant Gupta", "authors": "Prashant Gupta, Aashi Jindal, Jayadeva, and Debarka Sengupta", "title": "Guided Random Forest and its application to data approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new way of constructing an ensemble classifier, named the Guided\nRandom Forest (GRAF) in the sequel. GRAF extends the idea of building oblique\ndecision trees with localized partitioning to obtain a global partitioning. We\nshow that global partitioning bridges the gap between decision trees and\nboosting algorithms. We empirically demonstrate that global partitioning\nreduces the generalization error bound. Results on 115 benchmark datasets show\nthat GRAF yields comparable or better results on a majority of datasets. We\nalso present a new way of approximating the datasets in the framework of random\nforests.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 10:50:14 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Gupta", "Prashant", ""], ["Jindal", "Aashi", ""], ["Jayadeva", "", ""], ["Sengupta", "Debarka", ""]]}, {"id": "1909.00668", "submitter": "Daniel Murfet", "authors": "James Clift, Dmitry Doryn, Daniel Murfet, James Wallbridge", "title": "Logic and the $2$-Simplicial Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the $2$-simplicial Transformer, an extension of the Transformer\nwhich includes a form of higher-dimensional attention generalising the\ndot-product attention, and uses this attention to update entity representations\nwith tensor products of value vectors. We show that this architecture is a\nuseful inductive bias for logical reasoning in the context of deep\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 11:11:35 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Clift", "James", ""], ["Doryn", "Dmitry", ""], ["Murfet", "Daniel", ""], ["Wallbridge", "James", ""]]}, {"id": "1909.00693", "submitter": "Guillaume Metzler Mr", "authors": "R\\'emi Viola, R\\'emi Emonet, Amaury Habrard, Guillaume Metzler,\n  S\\'ebastien Riou and Marc Sebban", "title": "An Adjusted Nearest Neighbor Algorithm Maximizing the F-Measure from\n  Imbalanced Data", "comments": "In Proceedings of the 31 International Conference on Tools with\n  Artificial Intelligence (ICTAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the challenging problem of learning from imbalanced\ndata using a Nearest-Neighbor (NN) algorithm. In this setting, the minority\nexamples typically belong to the class of interest requiring the optimization\nof specific criteria, like the F-Measure. Based on simple geometrical ideas, we\nintroduce an algorithm that reweights the distance between a query sample and\nany positive training example. This leads to a modification of the Voronoi\nregions and thus of the decision boundaries of the NN algorithm. We provide a\ntheoretical justification about the weighting scheme needed to reduce the False\nNegative rate while controlling the number of False Positives. We perform an\nextensive experimental study on many public imbalanced datasets, but also on\nlarge scale non public data from the French Ministry of Economy and Finance on\na tax fraud detection task, showing that our method is very effective and,\ninterestingly, yields the best performance when combined with state of the art\nsampling methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:46:12 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 12:32:40 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Viola", "R\u00e9mi", ""], ["Emonet", "R\u00e9mi", ""], ["Habrard", "Amaury", ""], ["Metzler", "Guillaume", ""], ["Riou", "S\u00e9bastien", ""], ["Sebban", "Marc", ""]]}, {"id": "1909.00704", "submitter": "Giancarlo Ruffo", "authors": "Francesco Bergadano, Roberto Bertilone, Daniela Paolotti, Giancarlo\n  Ruffo", "title": "Learning Real Estate Automated Valuation Models from Heterogeneous Data\n  Sources", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real estate appraisal is a complex and important task, that can be made more\nprecise and faster with the help of automated valuation tools. Usually the\nvalue of some property is determined by taking into account both structural and\ngeographical characteristics. However, while geographical information is easily\nfound, obtaining significant structural information requires the intervention\nof a real estate expert, a professional appraiser. In this paper we propose a\nWeb data acquisition methodology, and a Machine Learning model, that can be\nused to automatically evaluate real estate properties. This method uses data\nfrom previous appraisal documents, from the advertised prices of similar\nproperties found via Web crawling, and from open data describing the\ncharacteristics of a corresponding geographical area. We describe a case study,\napplicable to the whole Italian territory, and initially trained on a data set\nof individual homes located in the city of Turin, and analyze prediction and\npractical applicability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:16:51 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bergadano", "Francesco", ""], ["Bertilone", "Roberto", ""], ["Paolotti", "Daniela", ""], ["Ruffo", "Giancarlo", ""]]}, {"id": "1909.00719", "submitter": "Andrew Y. K. Foong", "authors": "Andrew Y. K. Foong, David R. Burt, Yingzhen Li, Richard E. Turner", "title": "On the Expressiveness of Approximate Inference in Bayesian Neural\n  Networks", "comments": "NeurIPS 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Bayesian neural networks (BNNs) hold the promise of being flexible,\nwell-calibrated statistical models, inference often requires approximations\nwhose consequences are poorly understood. We study the quality of common\nvariational methods in approximating the Bayesian predictive distribution. For\nsingle-hidden layer ReLU BNNs, we prove a fundamental limitation in\nfunction-space of two of the most commonly used distributions defined in\nweight-space: mean-field Gaussian and Monte Carlo dropout. We find there are\nsimple cases where neither method can have substantially increased uncertainty\nin between well-separated regions of low uncertainty. We provide strong\nempirical evidence that exact inference does not have this pathology, hence it\nis due to the approximation and not the model. In contrast, for deep networks,\nwe prove a universality result showing that there exist approximate posteriors\nin the above classes which provide flexible uncertainty estimates. However, we\nfind empirically that pathologies of a similar form as in the single-hidden\nlayer case can persist when performing variational inference in deeper\nnetworks. Our results motivate careful consideration of the implications of\napproximate inference methods in BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:54:39 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 13:47:45 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 22:10:54 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 17:16:49 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Foong", "Andrew Y. K.", ""], ["Burt", "David R.", ""], ["Li", "Yingzhen", ""], ["Turner", "Richard E.", ""]]}, {"id": "1909.00843", "submitter": "Sikander Randhawa", "authors": "Nicholas J. A. Harvey, Christopher Liaw, Sikander Randhawa", "title": "Simple and optimal high-probability bounds for strongly-convex\n  stochastic gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stochastic gradient descent algorithms for minimizing a\nnon-smooth, strongly-convex function. Several forms of this algorithm,\nincluding suffix averaging, are known to achieve the optimal $O(1/T)$\nconvergence rate in expectation. We consider a simple, non-uniform averaging\nstrategy of Lacoste-Julien et al. (2011) and prove that it achieves the optimal\n$O(1/T)$ convergence rate with high probability. Our proof uses a recently\ndeveloped generalization of Freedman's inequality. Finally, we compare several\nof these algorithms experimentally and show that this non-uniform averaging\nstrategy outperforms many standard techniques, and with smaller variance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 19:47:47 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Harvey", "Nicholas J. A.", ""], ["Liaw", "Christopher", ""], ["Randhawa", "Sikander", ""]]}, {"id": "1909.00853", "submitter": "Branko Arsi\\'c", "authors": "Milan Ba\\v{s}i\\'c, Branko Arsi\\'c and Zoran Obradovi\\'c", "title": "Further results on structured regression for multi-scale networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Gaussian Conditional Random Fields (GCRF), as a structured regression model,\nis designed to achieve higher regression accuracy than unstructured predictors\nat the expense of execution time, taking into account the objects similarities\nand the outputs of unstructured predictors simultaneously. As most structural\nmodels, the GCRF model does not scale well with large networks. One of the\napproaches consists of performing calculations on factor graphs (if it is\npossible) rather than on the full graph, which is more computationally\nefficient. The Kronecker product of the graphs appears to be a natural choice\nfor a graph decomposition. However, this idea is not straightforwardly\napplicable for GCRF, since characterizing a Laplacian spectrum of the Kronecker\nproduct of graphs, which GCRF is based on, from spectra of its factor graphs\nhas remained an open problem. In this paper we apply new estimations for the\nLaplacian eigenvalues and eigenvectors, and achieve high prediction accuracy of\nthe proposed models, while the computational complexity of the models, compared\nto the original GCRF model, is improved from $O(n_{1}^{3}n_{2}^{3})$ to\n$O(n_{1}^{3} + n_{2}^{3})$. Furthermore, we study the GCRF model with a\nnon-Kronecker graph, where the model consists of finding the nearest Kronecker\nproduct of graph for an initial graph. Although the proposed models are more\ncomplex, they achieve high prediction accuracy too, while the execution time is\nstill much better compare to the original GCRF model. The effectiveness of the\nproposed models is characterized on three types of random networks where the\nproposed models were consistently away more accurate than the previously\npresented GCRF model for multiscale networks [Jesse Glass and Zoran Obradovic.\nStructured regression on multiscale networks. IEEE Intelligent Systems,\n32(2):23-30, 2017.].\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 20:11:11 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ba\u0161i\u0107", "Milan", ""], ["Arsi\u0107", "Branko", ""], ["Obradovi\u0107", "Zoran", ""]]}, {"id": "1909.00868", "submitter": "Bohan Li", "authors": "Bohan Li, Junxian He, Graham Neubig, Taylor Berg-Kirkpatrick, Yiming\n  Yang", "title": "A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text", "comments": "EMNLP 2019 short paper. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When trained effectively, the Variational Autoencoder (VAE) is both a\npowerful language model and an effective representation learning framework. In\npractice, however, VAEs are trained with the evidence lower bound (ELBO) as a\nsurrogate objective to the intractable marginal data likelihood. This approach\nto training yields unstable results, frequently leading to a disastrous local\noptimum known as posterior collapse. In this paper, we investigate a simple fix\nfor posterior collapse which yields surprisingly effective results. The\ncombination of two known heuristics, previously considered only in isolation,\nsubstantially improves held-out likelihood, reconstruction, and latent\nrepresentation learning when compared with previous state-of-the-art methods.\nMore interestingly, while our experiments demonstrate superiority on these\nprinciple evaluations, our method obtains a worse ELBO. We use these results to\nargue that the typical surrogate objective for VAEs may not be sufficient or\nnecessarily appropriate for balancing the goals of representation learning and\ndata distribution modeling.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:08:00 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Bohan", ""], ["He", "Junxian", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Yang", "Yiming", ""]]}, {"id": "1909.00900", "submitter": "Chengzhi Mao", "authors": "Chengzhi Mao, Ziyuan Zhong, Junfeng Yang, Carl Vondrick, Baishakhi Ray", "title": "Metric Learning for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are well-known to be fragile to adversarial attacks. We conduct\nan empirical analysis of deep representations under the state-of-the-art attack\nmethod called PGD, and find that the attack causes the internal representation\nto shift closer to the \"false\" class. Motivated by this observation, we propose\nto regularize the representation space under attack with metric learning to\nproduce more robust classifiers. By carefully sampling examples for metric\nlearning, our learned representation not only increases robustness, but also\ndetects previously unseen adversarial samples. Quantitative experiments show\nimprovement of robustness accuracy by up to 4% and detection efficiency by up\nto 6% according to Area Under Curve score over prior work. The code of our work\nis available at\nhttps://github.com/columbia/Metric_Learning_Adversarial_Robustness.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 00:39:40 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 00:43:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mao", "Chengzhi", ""], ["Zhong", "Ziyuan", ""], ["Yang", "Junfeng", ""], ["Vondrick", "Carl", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1909.00918", "submitter": "Qi Deng", "authors": "Qi Deng and Chenghao Lan", "title": "Efficiency of Coordinate Descent Methods For Structured Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel coordinate descent (CD) methods are proposed for minimizing nonconvex\nfunctions consisting of three terms: (i) a continuously differentiable term,\n(ii) a simple convex term, and (iii) a concave and continuous term. First, by\nextending randomized CD to nonsmooth nonconvex settings, we develop a\ncoordinate subgradient method that randomly updates block-coordinate variables\nby using block composite subgradient mapping. This method converges\nasymptotically to critical points with proven sublinear convergence rate for\ncertain optimality measures. Second, we develop a randomly permuted CD method\nwith two alternating steps: linearizing the concave part and cycling through\nvariables. We prove asymptotic convergence to critical points and sublinear\ncomplexity rate for objectives with both smooth and concave parts. Third, we\nextend accelerated coordinate descent (ACD) to nonsmooth and nonconvex\noptimization to develop a novel randomized proximal DC algorithm whereby we\nsolve the subproblem inexactly by ACD. Convergence is guaranteed with at most a\nfew number of ACD iterations for each DC subproblem, and convergence complexity\nis established for identification of some approximate critical points. Fourth,\nwe further develop the third method to minimize certain ill-conditioned\nnonconvex functions: weakly convex functions with high Lipschitz constant to\nnegative curvature ratios. We show that, under specific criteria, the ACD-based\nrandomized method has superior complexity compared to conventional gradient\nmethods. Finally, an empirical study on sparsity-inducing learning models\ndemonstrates that CD methods are superior to gradient-based methods for certain\nlarge-scale problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 02:11:11 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Deng", "Qi", ""], ["Lan", "Chenghao", ""]]}, {"id": "1909.00949", "submitter": "Jordan Hoffmann", "authors": "Jordan Hoffmann, Louis Maestrati, Yoshihide Sawada, Jian Tang, Jean\n  Michel Sellier, Yoshua Bengio", "title": "Data-Driven Approach to Encoding and Decoding 3-D Crystal Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative models have achieved impressive results in many domains including\nimage and text generation. In the natural sciences, generative models have led\nto rapid progress in automated drug discovery. Many of the current methods\nfocus on either 1-D or 2-D representations of typically small, drug-like\nmolecules. However, many molecules require 3-D descriptors and exceed the\nchemical complexity of commonly used dataset. We present a method to encode and\ndecode the position of atoms in 3-D molecules from a dataset of nearly 50,000\nstable crystal unit cells that vary from containing 1 to over 100 atoms. We\nconstruct a smooth and continuous 3-D density representation of each crystal\nbased on the positions of different atoms. Two different neural networks were\ntrained on a dataset of over 120,000 three-dimensional samples of single and\nrepeating crystal structures, made by rotating the single unit cells. The\nfirst, an Encoder-Decoder pair, constructs a compressed latent space\nrepresentation of each molecule and then decodes this description into an\naccurate reconstruction of the input. The second network segments the resulting\noutput into atoms and assigns each atom an atomic number. By generating\ncompressed, continuous latent spaces representations of molecules we are able\nto decode random samples, interpolate between two molecules, and alter known\nmolecules.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 04:36:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Hoffmann", "Jordan", ""], ["Maestrati", "Louis", ""], ["Sawada", "Yoshihide", ""], ["Tang", "Jian", ""], ["Sellier", "Jean Michel", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1909.00952", "submitter": "Hilmi Enes Egilmez", "authors": "Hilmi E. Egilmez, Yung-Hsuan Chao, Antonio Ortega", "title": "Graph-based Transforms for Video Coding", "comments": "To appear in IEEE Trans. on Image Processing (14 pages)", "journal-ref": null, "doi": "10.1109/TIP.2020.3026627", "report-no": null, "categories": "eess.IV cs.LG cs.MM cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many state-of-the-art compression systems, signal transformation is an\nintegral part of the encoding and decoding process, where transforms provide\ncompact representations for the signals of interest. This paper introduces a\nclass of transforms called graph-based transforms (GBTs) for video compression,\nand proposes two different techniques to design GBTs. In the first technique,\nwe formulate an optimization problem to learn graphs from data and provide\nsolutions for optimal separable and nonseparable GBT designs, called GL-GBTs.\nThe optimality of the proposed GL-GBTs is also theoretically analyzed based on\nGaussian-Markov random field (GMRF) models for intra and inter predicted block\nsignals. The second technique develops edge-adaptive GBTs (EA-GBTs) in order to\nflexibly adapt transforms to block signals with image edges (discontinuities).\nThe advantages of EA-GBTs are both theoretically and empirically demonstrated.\nOur experimental results demonstrate that the proposed transforms can\nsignificantly outperform the traditional Karhunen-Loeve transform (KLT).\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 04:53:53 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 08:44:44 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Egilmez", "Hilmi E.", ""], ["Chao", "Yung-Hsuan", ""], ["Ortega", "Antonio", ""]]}, {"id": "1909.00958", "submitter": "Yun Cheng Wang", "authors": "Fenxiao Chen, Yuncheng Wang, Bin Wang and C.-C. Jay Kuo", "title": "Graph Representation Learning: A Survey", "comments": null, "journal-ref": "APSIPA Transactions on Signal and Information Processing 9 (2020)\n  e15", "doi": "10.1017/ATSIP.2020.13", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on graph representation learning has received a lot of attention in\nrecent years since many data in real-world applications come in form of graphs.\nHigh-dimensional graph data are often in irregular form, which makes them more\ndifficult to analyze than image/video/audio data defined on regular lattices.\nVarious graph embedding techniques have been developed to convert the raw graph\ndata into a low-dimensional vector representation while preserving the\nintrinsic graph properties. In this review, we first explain the graph\nembedding task and its challenges. Next, we review a wide range of graph\nembedding techniques with insights. Then, we evaluate several state-of-the-art\nmethods against small and large datasets and compare their performance.\nFinally, potential applications and future directions are presented.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 05:21:31 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chen", "Fenxiao", ""], ["Wang", "Yuncheng", ""], ["Wang", "Bin", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1909.00982", "submitter": "Arpita Biswas", "authors": "Arpita Biswas, Siddharth Barman, Amit Deshpande, Amit Sharma", "title": "Quantifying Infra-Marginality and Its Trade-off with Group Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In critical decision-making scenarios, optimizing accuracy can lead to a\nbiased classifier, hence past work recommends enforcing group-based fairness\nmetrics in addition to maximizing accuracy. However, doing so exposes the\nclassifier to another kind of bias called infra-marginality. This refers to\nindividual-level bias where some individuals/subgroups can be worse off than\nunder simply optimizing for accuracy. For instance, a classifier implementing\nrace-based parity may significantly disadvantage women of the advantaged race.\nTo quantify this bias, we propose a general notion of $\\eta$-infra-marginality\nthat can be used to evaluate the extent of this bias. We prove theoretically\nthat, unlike other fairness metrics, infra-marginality does not have a\ntrade-off with accuracy: high accuracy directly leads to low infra-marginality.\nThis observation is confirmed through empirical analysis on multiple simulated\nand real-world datasets. Further, we find that maximizing group fairness often\nincreases infra-marginality, suggesting the consideration of both group-level\nfairness and individual-level infra-marginality. However, measuring\ninfra-marginality requires knowledge of the true distribution of\nindividual-level outcomes correctly and explicitly. We propose a practical\nmethod to measure infra-marginality, and a simple algorithm to maximize\ngroup-wise accuracy and avoid infra-marginality.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 07:24:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Biswas", "Arpita", ""], ["Barman", "Siddharth", ""], ["Deshpande", "Amit", ""], ["Sharma", "Amit", ""]]}, {"id": "1909.01039", "submitter": "Henrich Kolkhorst", "authors": "Henrich Kolkhorst and Wolfram Burgard and Michael Tangermann", "title": "Learning User Preferences for Trajectories from Brain Signals", "comments": "The International Symposium on Robotics Research (ISRR), Hanoi,\n  Vietnam, October 2019; reformatted to two-column layout", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot motions in the presence of humans should not only be feasible and safe,\nbut also conform to human preferences. This, however, requires user feedback on\nthe robot's behavior. In this work, we propose a novel approach to leverage the\nuser's brain signals as a feedback modality in order to decode the judgment of\nrobot trajectories and rank them according to the user's preferences. We show\nthat brain signals measured using electroencephalography during observation of\na robotic arm's trajectory as well as in response to preference statements are\ninformative regarding the user's preference. Furthermore, we demonstrate that\nuser feedback from brain signals can be used to reliably infer pairwise\ntrajectory preferences as well as to retrieve the preferred observed\ntrajectories of the user with a performance comparable to explicit behavioral\nfeedback.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:20:50 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 17:51:42 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Kolkhorst", "Henrich", ""], ["Burgard", "Wolfram", ""], ["Tangermann", "Michael", ""]]}, {"id": "1909.01067", "submitter": "Habibeh Naderi", "authors": "Habibeh Naderi, Behrouz Haji Soleimani, Stan Matwin", "title": "Multimodal Deep Learning for Mental Disorders Prediction from Audio\n  Speech Samples", "comments": "arXiv admin note: text overlap with arXiv:1811.09362 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key features of mental illnesses are reflected in speech. Our research\nfocuses on designing a multimodal deep learning structure that automatically\nextracts salient features from recorded speech samples for predicting various\nmental disorders including depression, bipolar, and schizophrenia. We adopt a\nvariety of pre-trained models to extract embeddings from both audio and text\nsegments. We use several state-of-the-art embedding techniques including BERT,\nFastText, and Doc2VecC for the text representation learning and WaveNet and\nVGG-ish models for audio encoding. We also leverage huge auxiliary\nemotion-labeled text and audio corpora to train emotion-specific embeddings and\nuse transfer learning in order to address the problem of insufficient annotated\nmultimodal data available. All these embeddings are then combined into a joint\nrepresentation in a multimodal fusion layer and finally a recurrent neural\nnetwork is used to predict the mental disorder. Our results show that mental\ndisorders can be predicted with acceptable accuracy through multimodal analysis\nof clinical interviews.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 11:15:19 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 23:28:40 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 22:42:25 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 18:01:37 GMT"}, {"version": "v5", "created": "Mon, 13 Apr 2020 18:56:36 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Naderi", "Habibeh", ""], ["Soleimani", "Behrouz Haji", ""], ["Matwin", "Stan", ""]]}, {"id": "1909.01093", "submitter": "Zhiqiang Ma", "authors": "Azadeh Nematzadeh, Grace Bang, Xiaomo Liu, Zhiqiang Ma", "title": "Empirical Study on Detecting Controversy in Social Media", "comments": "The work is accepted by the 2nd KDD Workshop on Anomaly Detection in\n  Finance, 2019. The authors contributed equally to this work, listed in the\n  alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies and financial investors are paying increasing attention to social\nconsciousness in developing their corporate strategies and making investment\ndecisions to support a sustainable economy for the future. Public discussion on\nincidents and events -- controversies -- of companies can provide valuable\ninsights on how well the company operates with regards to social consciousness\nand indicate the company's overall operational capability. However, there are\nchallenges in evaluating the degree of a company's social consciousness and\nenvironmental sustainability due to the lack of systematic data. We introduce a\nsystem that utilizes Twitter data to detect and monitor controversial events\nand show their impact on market volatility. In our study, controversial events\nare identified from clustered tweets that share the same 5W terms and sentiment\npolarities of these clusters. Credible news links inside the event tweets are\nused to validate the truth of the event. A case study on the Starbucks\nPhiladelphia arrests shows that this method can provide the desired\nfunctionality.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 18:36:55 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Nematzadeh", "Azadeh", ""], ["Bang", "Grace", ""], ["Liu", "Xiaomo", ""], ["Ma", "Zhiqiang", ""]]}, {"id": "1909.01108", "submitter": "Qiegen Liu", "authors": "Siyuan Wang, Junjie Lv, Yuanyuan Hu, Dong Liang, Minghui Zhang, Qiegen\n  Liu", "title": "Denoising Auto-encoding Priors in Undecimated Wavelet Domain for MR\n  Image Reconstruction", "comments": "10 pages, 11 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing is an impressive approach for fast MRI. It aims at\nreconstructing MR image using only a few under-sampled data in k-space,\nenhancing the efficiency of the data acquisition. In this study, we propose to\nlearn priors based on undecimated wavelet transform and an iterative image\nreconstruction algorithm. At the stage of prior learning, transformed feature\nimages obtained by undecimated wavelet transform are stacked as an input of\ndenoising autoencoder network (DAE). The highly redundant and multi-scale input\nenables the correlation of feature images at different channels, which allows a\nrobust network-driven prior. At the iterative reconstruction, the transformed\nDAE prior is incorporated into the classical iterative procedure by the means\nof proximal gradient algorithm. Experimental comparisons on different sampling\ntrajectories and ratios validated the great potential of the presented\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 12:09:21 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 01:56:02 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Wang", "Siyuan", ""], ["Lv", "Junjie", ""], ["Hu", "Yuanyuan", ""], ["Liang", "Dong", ""], ["Zhang", "Minghui", ""], ["Liu", "Qiegen", ""]]}, {"id": "1909.01132", "submitter": "Loc Tran H", "authors": "Loc Tran, Tho Quan, An Mai", "title": "PageRank algorithm for Directed Hypergraph", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last two decades, we easilly see that the World Wide Web's link\nstructure is modeled as the directed graph. In this paper, we will model the\nWorld Wide Web's link structure as the directed hypergraph. Moreover, we will\ndevelop the PageRank algorithm for this directed hypergraph. Due to the lack of\nthe World Wide Web directed hypergraph datasets, we will apply the PageRank\nalgorithm to the metabolic network which is the directed hypergraph itself. The\nexperiments show that our novel PageRank algorithm is successfully applied to\nthis metabolic network.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:15:25 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tran", "Loc", ""], ["Quan", "Tho", ""], ["Mai", "An", ""]]}, {"id": "1909.01135", "submitter": "Chidimma Opara", "authors": "Chidimma Opara, Bo Wei, and Yingke Chen", "title": "HTMLPhish: Enabling Phishing Web Page Detection by Applying Deep\n  Learning Techniques on HTML Analysis", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2020", "doi": "10.1109/IJCNN48605.2020.9207707", "report-no": null, "categories": "cs.CR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the development and implementation of phishing attacks require\nlittle technical skills and costs. This uprising has led to an ever-growing\nnumber of phishing attacks on the World Wide Web. Consequently, proactive\ntechniques to fight phishing attacks have become extremely necessary. In this\npaper, we propose HTMLPhish, a deep learning based data-driven end-to-end\nautomatic phishing web page classification approach. Specifically, HTMLPhish\nreceives the content of the HTML document of a web page and employs\nConvolutional Neural Networks (CNNs) to learn the semantic dependencies in the\ntextual contents of the HTML. The CNNs learn appropriate feature\nrepresentations from the HTML document embeddings without extensive manual\nfeature engineering. Furthermore, our proposed approach of the concatenation of\nthe word and character embeddings allows our model to manage new features and\nensure easy extrapolation to test data. We conduct comprehensive experiments on\na dataset of more than 50,000 HTML documents that provides a distribution of\nphishing to benign web pages obtainable in the real-world that yields over 93\npercent Accuracy and True Positive Rate. Also, HTMLPhish is a completely\nlanguage-independent and client-side strategy which can, therefore, conduct web\npage phishing detection regardless of the textual language.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 23:58:50 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 17:10:56 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 10:30:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Opara", "Chidimma", ""], ["Wei", "Bo", ""], ["Chen", "Yingke", ""]]}, {"id": "1909.01150", "submitter": "Lingxiao Wang", "authors": "Lingxiao Wang, Qi Cai, Zhuoran Yang, Zhaoran Wang", "title": "Neural Policy Gradient Methods: Global Optimality and Rates of\n  Convergence", "comments": "71 pages. The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods with actor-critic schemes demonstrate tremendous\nempirical successes, especially when the actors and critics are parameterized\nby neural networks. However, it remains less clear whether such \"neural\" policy\ngradient methods converge to globally optimal policies and whether they even\nconverge at all. We answer both the questions affirmatively in the\noverparameterized regime. In detail, we prove that neural natural policy\ngradient converges to a globally optimal policy at a sublinear rate. Also, we\nshow that neural vanilla policy gradient converges sublinearly to a stationary\npoint. Meanwhile, by relating the suboptimality of the stationary points to the\nrepresentation power of neural actor and critic classes, we prove the global\noptimality of all stationary points under mild regularity conditions.\nParticularly, we show that a key to the global optimality and convergence is\nthe \"compatibility\" between the actor and critic, which is ensured by sharing\nneural architectures and random initializations across the actor and critic. To\nthe best of our knowledge, our analysis establishes the first global optimality\nand convergence guarantees for neural policy gradient methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:38:19 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 00:25:26 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 21:42:43 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Wang", "Lingxiao", ""], ["Cai", "Qi", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1909.01174", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez (SIERRA, PSL, FAIR), Nicolas Usunier (FAIR),\n  L\\'eon Bottou (FAIR), Francis Bach (PSL, DI-ENS, SIERRA)", "title": "Demucs: Deep Extractor for Music Sources with extra unlabeled data\n  remixed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of source separation for music using deep learning with\nfour known sources: drums, bass, vocals and other accompaniments.\nState-of-the-art approaches predict soft masks over mixture spectrograms while\nmethods working on the waveform are lagging behind as measured on the standard\nMusDB benchmark. Our contribution is two fold. (i) We introduce a simple\nconvolutional and recurrent model that outperforms the state-of-the-art model\non waveforms, that is, Wave-U-Net, by 1.6 points of SDR (signal to distortion\nratio). (ii) We propose a new scheme to leverage unlabeled music. We train a\nfirst model to extract parts with at least one source silent in unlabeled\ntracks, for instance without bass. We remix this extract with a bass line taken\nfrom the supervised dataset to form a new weakly supervised training example.\nCombining our architecture and scheme, we show that waveform methods can play\nin the same ballpark as spectrogram ones.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 13:41:56 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["D\u00e9fossez", "Alexandre", "", "SIERRA, PSL, FAIR"], ["Usunier", "Nicolas", "", "FAIR"], ["Bottou", "L\u00e9on", "", "FAIR"], ["Bach", "Francis", "", "PSL, DI-ENS, SIERRA"]]}, {"id": "1909.01185", "submitter": "Yvan Lucas", "authors": "Yvan Lucas, Pierre-Edouard Portier, L\\'ea Laporte, Liyun He-Guelton,\n  Olivier Caelen, Michael Granitzer, Sylvie Calabretto", "title": "Towards automated feature engineering for credit card fraud detection\n  using multi-perspective HMMs", "comments": "published in the journal \"future generation computer systems\", in the\n  special issue: \"data exploration in the web 3.0 age\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining techniques have been used extensively in\norder to detect credit card frauds. However, most studies consider credit card\ntransactions as isolated events and not as a sequence of transactions. In this\nframework, we model a sequence of credit card transactions from three different\nperspectives, namely (i) The sequence contains or doesn't contain a fraud (ii)\nThe sequence is obtained by fixing the card-holder or the payment terminal\n(iii) It is a sequence of spent amount or of elapsed time between the current\nand previous transactions. Combinations of the three binary perspectives give\neight sets of sequences from the (training) set of transactions. Each one of\nthese sequences is modelled with a Hidden Markov Model (HMM). Each HMM\nassociates a likelihood to a transaction given its sequence of previous\ntransactions. These likelihoods are used as additional features in a Random\nForest classifier for fraud detection. Our multiple perspectives HMM-based\napproach offers automated feature engineering to model temporal correlations so\nas to improve the effectiveness of the classification task and allows for an\nincrease in the detection of fraudulent transactions when combined with the\nstate of the art expert based feature engineering strategy for credit card\nfraud detection. In extension to previous works, we show that this approach\ngoes beyond ecommerce transactions and provides a robust feature engineering\nover different datasets, hyperparameters and classifiers. Moreover, we compare\nstrategies to deal with structural missing values.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 13:53:35 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Lucas", "Yvan", ""], ["Portier", "Pierre-Edouard", ""], ["Laporte", "L\u00e9a", ""], ["He-Guelton", "Liyun", ""], ["Caelen", "Olivier", ""], ["Granitzer", "Michael", ""], ["Calabretto", "Sylvie", ""]]}, {"id": "1909.01202", "submitter": "Karanpreet Singh", "authors": "Karanpreet Singh and Rajen Bhatt", "title": "Personalizing Smartwatch Based Activity Recognition Using Transfer\n  Learning", "comments": "6 Pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartwatches are increasingly being used to recognize human daily life\nactivities. These devices may employ different kind of machine learning (ML)\nsolutions. One of such ML models is Gradient Boosting Machine (GBM) which has\nshown an excellent performance in the literature. The GBM can be trained on\navailable data set before it is deployed on any device. However, this data set\nmay not represent every kind of human behavior in real life. For example, a ML\nmodel to detect elder and young persons running activity may give different\nresults because of differences in their activity patterns. This may result in\ndecrease in the accuracy of activity recognition. Therefore, a transfer\nlearning based method is proposed in which user-specific performance can be\nimproved significantly by doing on-device calibration of GBM by just tuning its\nparameters without retraining its estimators. Results show that this method can\nsignificantly improve the user-based accuracy for activity recognition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:13:49 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Singh", "Karanpreet", ""], ["Bhatt", "Rajen", ""]]}, {"id": "1909.01205", "submitter": "Bram Wallace", "authors": "Bram Wallace, Bharath Hariharan", "title": "Few-Shot Generalization for Single-Image 3D Reconstruction via Priors", "comments": "To appear in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on single-view 3D reconstruction shows impressive results, but\nhas been restricted to a few fixed categories where extensive training data is\navailable. The problem of generalizing these models to new classes with limited\ntraining data is largely open. To address this problem, we present a new model\narchitecture that reframes single-view 3D reconstruction as learnt, category\nagnostic refinement of a provided, category-specific prior. The provided prior\nshape for a novel class can be obtained from as few as one 3D shape from this\nclass. Our model can start reconstructing objects from the novel class using\nthis prior without seeing any training image for this class and without any\nretraining. Our model outperforms category-agnostic baselines and remains\ncompetitive with more sophisticated baselines that finetune on the novel\ncategories. Additionally, our network is capable of improving the\nreconstruction given multiple views despite not being trained on task of\nmulti-view reconstruction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:18:42 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Wallace", "Bram", ""], ["Hariharan", "Bharath", ""]]}, {"id": "1909.01238", "submitter": "Adrian Wills", "authors": "Adrian Wills, Thomas Sch\\\"on", "title": "Stochastic quasi-Newton with line-search regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel quasi-Newton algorithm for use in stochastic\noptimisation. Quasi-Newton methods have had an enormous impact on deterministic\noptimisation problems because they afford rapid convergence and computationally\nattractive algorithms. In essence, this is achieved by learning the\nsecond-order (Hessian) information based on observing first-order gradients. We\nextend these ideas to the stochastic setting by employing a highly flexible\nmodel for the Hessian and infer its value based on observing noisy gradients.\nIn addition, we propose a stochastic counterpart to standard line-search\nprocedures and demonstrate the utility of this combination on maximum\nlikelihood identification for general nonlinear state space models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 15:10:42 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wills", "Adrian", ""], ["Sch\u00f6n", "Thomas", ""]]}, {"id": "1909.01251", "submitter": "Guy W Cole", "authors": "Guy W. Cole and Sinead A. Williamson", "title": "Avoiding Resentment Via Monotonic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers that achieve demographic balance by explicitly using protected\nattributes such as race or gender are often politically or culturally\ncontroversial due to their lack of individual fairness, i.e. individuals with\nsimilar qualifications will receive different outcomes. Individually and group\nfair decision criteria can produce counter-intuitive results, e.g. that the\noptimal constrained boundary may reject intuitively better candidates due to\ndemographic imbalance in similar candidates. Both approaches can be seen as\nintroducing individual resentment, where some individuals would have received a\nbetter outcome if they either belonged to a different demographic class and had\nthe same qualifications, or if they remained in the same class but had\nobjectively worse qualifications (e.g. lower test scores). We show that both\nforms of resentment can be avoided by using monotonically constrained machine\nlearning models to create individually fair, demographically balanced\nclassifiers.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 15:28:16 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Cole", "Guy W.", ""], ["Williamson", "Sinead A.", ""]]}, {"id": "1909.01264", "submitter": "Avner May", "authors": "Avner May, Jian Zhang, Tri Dao, Christopher R\\'e", "title": "On the Downstream Performance of Compressed Word Embeddings", "comments": "NeurIPS 2019 spotlight (Conference on Neural Information Processing\n  Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing word embeddings is important for deploying NLP models in\nmemory-constrained settings. However, understanding what makes compressed\nembeddings perform well on downstream tasks is challenging---existing measures\nof compression quality often fail to distinguish between embeddings that\nperform well and those that do not. We thus propose the eigenspace overlap\nscore as a new measure. We relate the eigenspace overlap score to downstream\nperformance by developing generalization bounds for the compressed embeddings\nin terms of this score, in the context of linear and logistic regression. We\nthen show that we can lower bound the eigenspace overlap score for a simple\nuniform quantization compression method, helping to explain the strong\nempirical performance of this method. Finally, we show that by using the\neigenspace overlap score as a selection criterion between embeddings drawn from\na representative set we compressed, we can efficiently identify the better\nperforming embedding with up to $2\\times$ lower selection error rates than the\nnext best measure of compression quality, and avoid the cost of training a\nmodel for each task of interest.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:00:18 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 22:21:42 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["May", "Avner", ""], ["Zhang", "Jian", ""], ["Dao", "Tri", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1909.01268", "submitter": "Samuel Asante Gyamerah", "authors": "Samuel Asante Gyamerah", "title": "Are Bitcoins price predictable? Evidence from machine learning\n  techniques using technical indicators", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST econ.EM stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The uncertainties in future Bitcoin price make it difficult to accurately\npredict the price of Bitcoin. Accurately predicting the price for Bitcoin is\ntherefore important for decision-making process of investors and market players\nin the cryptocurrency market. Using historical data from 01/01/2012 to\n16/08/2019, machine learning techniques (Generalized linear model via penalized\nmaximum likelihood, random forest, support vector regression with linear\nkernel, and stacking ensemble) were used to forecast the price of Bitcoin. The\nprediction models employed key and high dimensional technical indicators as the\npredictors. The performance of these techniques were evaluated using mean\nabsolute percentage error (MAPE), root mean square error (RMSE), mean absolute\nerror (MAE), and coefficient of determination (R-squared). The performance\nmetrics revealed that the stacking ensemble model with two base learner (random\nforest and generalized linear model via penalized maximum likelihood) and\nsupport vector regression with linear kernel as meta-learner was the optimal\nmodel for forecasting Bitcoin price. The MAPE, RMSE, MAE, and R-squared values\nfor the stacking ensemble model were 0.0191%, 15.5331 USD, 124.5508 USD, and\n0.9967 respectively. These values show a high degree of reliability in\npredicting the price of Bitcoin using the stacking ensemble model. Accurately\npredicting the future price of Bitcoin will yield significant returns for\ninvestors and market players in the cryptocurrency market.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:03:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Gyamerah", "Samuel Asante", ""]]}, {"id": "1909.01311", "submitter": "Charlotte Frenkel", "authors": "Charlotte Frenkel, Martin Lefebvre, David Bol", "title": "Learning without feedback: Fixed random learning signals allow for\n  feedforward training of deep neural networks", "comments": "This document is the paper as accepted for publication in the\n  Frontiers in Neuroscience journal, the fully-edited paper is available at\n  https://www.frontiersin.org/articles/10.3389/fnins.2021.629892", "journal-ref": null, "doi": "10.3389/fnins.2021.629892", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the backpropagation of error algorithm enables deep neural network\ntraining, it implies (i) bidirectional synaptic weight transport and (ii)\nupdate locking until the forward and backward passes are completed. Not only do\nthese constraints preclude biological plausibility, but they also hinder the\ndevelopment of low-cost adaptive smart sensors at the edge, as they severely\nconstrain memory accesses and entail buffering overhead. In this work, we show\nthat the one-hot-encoded labels provided in supervised classification problems,\ndenoted as targets, can be viewed as a proxy for the error sign. Therefore,\ntheir fixed random projections enable a layerwise feedforward training of the\nhidden layers, thus solving the weight transport and update locking problems\nwhile relaxing the computational and memory requirements. Based on these\nobservations, we propose the direct random target projection (DRTP) algorithm\nand demonstrate that it provides a tradeoff between accuracy and computational\ncost that is suitable for adaptive edge computing devices.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:04:00 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 22:09:58 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Frenkel", "Charlotte", ""], ["Lefebvre", "Martin", ""], ["Bol", "David", ""]]}, {"id": "1909.01315", "submitter": "Minjie Wang", "authors": "Minjie Wang, Da Zheng, Zihao Ye, Quan Gan, Mufei Li, Xiang Song,\n  Jinjing Zhou, Chao Ma, Lingfan Yu, Yu Gai, Tianjun Xiao, Tong He, George\n  Karypis, Jinyang Li, Zheng Zhang", "title": "Deep Graph Library: A Graph-Centric, Highly-Performant Package for Graph\n  Neural Networks", "comments": "Major update with significantly more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancing research in the emerging field of deep graph learning requires new\ntools to support tensor computation over graphs. In this paper, we present the\ndesign principles and implementation of Deep Graph Library (DGL). DGL distills\nthe computational patterns of GNNs into a few generalized sparse tensor\noperations suitable for extensive parallelization. By advocating graph as the\ncentral programming abstraction, DGL can perform optimizations transparently.\nBy cautiously adopting a framework-neutral design, DGL allows users to easily\nport and leverage the existing components across multiple deep learning\nframeworks. Our evaluation shows that DGL significantly outperforms other\npopular GNN-oriented frameworks in both speed and memory consumption over a\nvariety of benchmarks and has little overhead for small scale workloads.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:10:28 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 15:46:13 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wang", "Minjie", ""], ["Zheng", "Da", ""], ["Ye", "Zihao", ""], ["Gan", "Quan", ""], ["Li", "Mufei", ""], ["Song", "Xiang", ""], ["Zhou", "Jinjing", ""], ["Ma", "Chao", ""], ["Yu", "Lingfan", ""], ["Gai", "Yu", ""], ["Xiao", "Tianjun", ""], ["He", "Tong", ""], ["Karypis", "George", ""], ["Li", "Jinyang", ""], ["Zhang", "Zheng", ""]]}, {"id": "1909.01331", "submitter": "Suzan Ece Ada", "authors": "Suzan Ece Ada and Emre Ugur and H. Levent Akin", "title": "Generalization in Transfer Learning", "comments": "23 pages, 36 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents trained with deep reinforcement learning algorithms are capable of\nperforming highly complex tasks including locomotion in continuous\nenvironments. We investigate transferring the learning acquired in one task to\na set of previously unseen tasks. Generalization and overfitting in deep\nreinforcement learning are not commonly addressed in current transfer learning\nresearch. Conducting a comparative analysis without an intermediate\nregularization step results in underperforming benchmarks and inaccurate\nalgorithm comparisons due to rudimentary assessments. In this study, we propose\nregularization techniques in deep reinforcement learning for continuous control\nthrough the application of sample elimination, early stopping and maximum\nentropy regularized adversarial learning. First, the importance of the\ninclusion of training iteration number to the hyperparameters in deep transfer\nreinforcement learning will be discussed. Because source task performance is\nnot indicative of the generalization capacity of the algorithm, we start by\nacknowledging the training iteration number as a hyperparameter. In line with\nthis, we introduce an additional step of resorting to earlier snapshots of\npolicy parameters to prevent overfitting to the source task. Then, to generate\nrobust policies, we discard the samples that lead to overfitting via a method\nwe call strict clipping. Furthermore, we increase the generalization capacity\nin widely used transfer learning benchmarks by using maximum entropy\nregularization, different critic methods, and curriculum learning in an\nadversarial setup. Subsequently, we propose maximum entropy adversarial\nreinforcement learning to increase the domain randomization. Finally, we\nevaluate the robustness of these methods on simulated robots in target\nenvironments where the morphology of the robot, gravity, and tangential\nfriction coefficient of the environment are altered.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:57:07 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 07:48:49 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ada", "Suzan Ece", ""], ["Ugur", "Emre", ""], ["Akin", "H. Levent", ""]]}, {"id": "1909.01359", "submitter": "Fr\\'ed\\'eric Dreyer", "authors": "Stefano Carrazza and Fr\\'ed\\'eric A. Dreyer", "title": "Lund jet images from generative and cycle-consistent adversarial\n  networks", "comments": "11 pages, 15 figures, code available at\n  https://github.com/JetsGame/gLund and https://github.com/JetsGame/CycleJet,\n  updated to match published version", "journal-ref": null, "doi": "10.1140/epjc/s10052-019-7501-1", "report-no": "OUTP-19-09P, TIF-UNIMI-2019-14", "categories": "hep-ph cs.LG eess.IV hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generative model to simulate radiation patterns within a jet\nusing the Lund jet plane. We show that using an appropriate neural network\narchitecture with a stochastic generation of images, it is possible to\nconstruct a generative model which retrieves the underlying two-dimensional\ndistribution to within a few percent. We compare our model with several\nalternative state-of-the-art generative techniques. Finally, we show how a\nmapping can be created between different categories of jets, and use this\nmethod to retroactively change simulation settings or the underlying process on\nan existing sample. These results provide a framework for significantly\nreducing simulation times through fast inference of the neural network as well\nas for data augmentation of physical measurements.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:00:03 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 14:52:20 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Carrazza", "Stefano", ""], ["Dreyer", "Fr\u00e9d\u00e9ric A.", ""]]}, {"id": "1909.01377", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "Deep Equilibrium Models", "comments": "NeurIPS 2019 Spotlight Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to modeling sequential data: the deep equilibrium\nmodel (DEQ). Motivated by an observation that the hidden layers of many\nexisting deep sequence models converge towards some fixed point, we propose the\nDEQ approach that directly finds these equilibrium points via root-finding.\nSuch a method is equivalent to running an infinite depth (weight-tied)\nfeedforward network, but has the notable advantage that we can analytically\nbackpropagate through the equilibrium point using implicit differentiation.\nUsing this approach, training and prediction in these networks require only\nconstant memory, regardless of the effective \"depth\" of the network. We\ndemonstrate how DEQs can be applied to two state-of-the-art deep sequence\nmodels: self-attention transformers and trellis networks. On large-scale\nlanguage modeling tasks, such as the WikiText-103 benchmark, we show that DEQs\n1) often improve performance over these state-of-the-art models (for similar\nparameter counts); 2) have similar computational requirements to existing\nmodels; and 3) vastly reduce memory consumption (often the bottleneck for\ntraining large sequence models), demonstrating an up-to 88% memory reduction in\nour experiments. The code is available at https://github.com/locuslab/deq .\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:02:50 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 22:25:01 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1909.01401", "submitter": "Pengfei Sun", "authors": "Pengfei Sun and Gopala K. Anumanchipalli and Edward F. Chang", "title": "Brain2Char: A Deep Architecture for Decoding Text from Brain Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding language representations directly from the brain can enable new\nBrain-Computer Interfaces (BCI) for high bandwidth human-human and\nhuman-machine communication. Clinically, such technologies can restore\ncommunication in people with neurological conditions affecting their ability to\nspeak. In this study, we propose a novel deep network architecture Brain2Char,\nfor directly decoding text (specifically character sequences) from direct brain\nrecordings (called Electrocorticography, ECoG). Brain2Char framework combines\nstate-of-the-art deep learning modules --- 3D Inception layers for multiband\nspatiotemporal feature extraction from neural data and bidirectional recurrent\nlayers, dilated convolution layers followed by language model weighted beam\nsearch to decode character sequences, optimizing a connectionist temporal\nclassification (CTC) loss. Additionally, given the highly non-linear\ntransformations that underlie the conversion of cortical function to character\nsequences, we perform regularizations on the network's latent representations\nmotivated by insights into cortical encoding of speech production and\nartifactual aspects specific to ECoG data acquisition. To do this, we impose\nauxiliary losses on latent representations for articulatory movements, speech\nacoustics and session specific non-linearities. In 3 participants tested here,\nBrain2Char achieves 10.6\\%, 8.5\\% and 7.0\\% Word Error Rates (WER) respectively\non vocabulary sizes ranging from 1200 to 1900 words. Brain2Char also performs\nwell when 2 participants silently mimed sentences. These results set a new\nstate-of-the-art on decoding text from brain and demonstrate the potential of\nBrain2Char as a high-performance communication BCI.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:54:43 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sun", "Pengfei", ""], ["Anumanchipalli", "Gopala K.", ""], ["Chang", "Edward F.", ""]]}, {"id": "1909.01412", "submitter": "Youshan Zhang", "authors": "Youshan Zhang, Jiarui Xing, Miaomiao Zhang", "title": "Mixture Probabilistic Principal Geodesic Analysis", "comments": "Seventh MICCAI Workshop on Mathematical Foundations of Computational\n  Anatomy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction on Riemannian manifolds is challenging due to the\ncomplex nonlinear data structures. While probabilistic principal geodesic\nanalysis~(PPGA) has been proposed to generalize conventional principal\ncomponent analysis (PCA) onto manifolds, its effectiveness is limited to data\nwith a single modality. In this paper, we present a novel Gaussian latent\nvariable model that provides a unique way to integrate multiple PGA models into\na maximum-likelihood framework. This leads to a well-defined mixture model of\nprobabilistic principal geodesic analysis (MPPGA) on sub-populations, where\nparameters of the principal subspaces are automatically estimated by employing\nan Expectation Maximization algorithm. We further develop a mixture Bayesian\nPGA (MBPGA) model that automatically reduces data dimensionality by suppressing\nirrelevant principal geodesics. We demonstrate the advantages of our model in\nthe contexts of clustering and statistical shape analysis, using synthetic\nsphere data, real corpus callosum, and mandible data from human brain magnetic\nresonance~(MR) and CT images.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 19:22:57 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 08:23:42 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zhang", "Youshan", ""], ["Xing", "Jiarui", ""], ["Zhang", "Miaomiao", ""]]}, {"id": "1909.01436", "submitter": "Lucas Theis", "authors": "Iryna Korshunova, Hanchen Xiong, Mateusz Fedoryszak, Lucas Theis", "title": "Discriminative Topic Modeling with Logistic LDA", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many years of research into latent Dirichlet allocation (LDA),\napplying LDA to collections of non-categorical items is still challenging. Yet\nmany problems with much richer data share a similar structure and could benefit\nfrom the vast literature on LDA. We propose logistic LDA, a novel\ndiscriminative variant of latent Dirichlet allocation which is easy to apply to\narbitrary inputs. In particular, our model can easily be applied to groups of\nimages, arbitrary text embeddings, and integrates well with deep neural\nnetworks. Although it is a discriminative model, we show that logistic LDA can\nlearn from unlabeled data in an unsupervised manner by exploiting the group\nstructure present in the data. In contrast to other recent topic models\ndesigned to handle arbitrary inputs, our model does not sacrifice the\ninterpretability and principled motivation of LDA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 20:25:49 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:12:31 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Korshunova", "Iryna", ""], ["Xiong", "Hanchen", ""], ["Fedoryszak", "Mateusz", ""], ["Theis", "Lucas", ""]]}, {"id": "1909.01440", "submitter": "Rosanne Liu", "authors": "Janice Lan, Rosanne Liu, Hattie Zhou, Jason Yosinski", "title": "LCA: Loss Change Allocation for Neural Network Training", "comments": "NeurIPS 2019 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks enjoy widespread use, but many aspects of their training,\nrepresentation, and operation are poorly understood. In particular, our view\ninto the training process is limited, with a single scalar loss being the most\ncommon viewport into this high-dimensional, dynamic process. We propose a new\nwindow into training called Loss Change Allocation (LCA), in which credit for\nchanges to the network loss is conservatively partitioned to the parameters.\nThis measurement is accomplished by decomposing the components of an\napproximate path integral along the training trajectory using a Runge-Kutta\nintegrator. This rich view shows which parameters are responsible for\ndecreasing or increasing the loss during training, or which parameters \"help\"\nor \"hurt\" the network's learning, respectively. LCA may be summed over training\niterations and/or over neurons, channels, or layers for increasingly coarse\nviews. This new measurement device produces several insights into training. (1)\nWe find that barely over 50% of parameters help during any given iteration. (2)\nSome entire layers hurt overall, moving on average against the training\ngradient, a phenomenon we hypothesize may be due to phase lag in an oscillatory\ntraining process. (3) Finally, increments in learning proceed in a synchronized\nmanner across layers, often peaking on identical iterations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 20:34:05 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 05:46:16 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Lan", "Janice", ""], ["Liu", "Rosanne", ""], ["Zhou", "Hattie", ""], ["Yosinski", "Jason", ""]]}, {"id": "1909.01459", "submitter": "Miriam Hurtado Bodell", "authors": "Miriam Hurtado Bodell, Martin Arvidsson and M{\\aa}ns Magnusson", "title": "Interpretable Word Embeddings via Informative Priors", "comments": "10 pages, 2 figures, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have demonstrated strong performance on NLP tasks. However,\nlack of interpretability and the unsupervised nature of word embeddings have\nlimited their use within computational social science and digital humanities.\nWe propose the use of informative priors to create interpretable and\ndomain-informed dimensions for probabilistic word embeddings. Experimental\nresults show that sensible priors can capture latent semantic concepts better\nthan or on-par with the current state of the art, while retaining the\nsimplicity and generalizability of using priors.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:20:28 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Bodell", "Miriam Hurtado", ""], ["Arvidsson", "Martin", ""], ["Magnusson", "M\u00e5ns", ""]]}, {"id": "1909.01463", "submitter": "Qunwei Li", "authors": "Baocheng Geng, Qunwei Li, Pramod K. Varshney", "title": "Prospect Theory Based Crowdsourcing for Classification in the Presence\n  of Spammers", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": "10.1109/TSP.2020.3006754", "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the $M$-ary classification problem via crowdsourcing, where crowd\nworkers respond to simple binary questions and the answers are aggregated via\ndecision fusion. The workers have a reject option to skip answering a question\nwhen they do not have the expertise, or when the confidence of answering that\nquestion correctly is low. We further consider that there are spammers in the\ncrowd who respond to the questions with random guesses. Under the payment\nmechanism that encourages the reject option, we study the behavior of honest\nworkers and spammers, whose objectives are to maximize their monetary rewards.\nTo accurately characterize human behavioral aspects, we employ prospect theory\nto model the rationality of the crowd workers, whose perception of costs and\nprobabilities are distorted based on some value and weight functions,\nrespectively. Moreover, we estimate the number of spammers and employ a\nweighted majority voting decision rule, where we assign an optimal weight for\nevery worker to maximize the system performance. The probability of correct\nclassification and asymptotic system performance are derived. We also provide\nsimulation results to demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:25:19 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 13:29:29 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Geng", "Baocheng", ""], ["Li", "Qunwei", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1909.01464", "submitter": "Guang Cheng", "authors": "Xingye Qiao, Jiexin Duan, Guang Cheng", "title": "Rates of Convergence for Large-scale Nearest Neighbor Classification", "comments": "Camera ready version for NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor is a popular class of classification methods with many\ndesirable properties. For a large data set which cannot be loaded into the\nmemory of a single machine due to computation, communication, privacy, or\nownership limitations, we consider the divide and conquer scheme: the entire\ndata set is divided into small subsamples, on which nearest neighbor\npredictions are made, and then a final decision is reached by aggregating the\npredictions on subsamples by majority voting. We name this method the big\nNearest Neighbor (bigNN) classifier, and provide its rates of convergence under\nminimal assumptions, in terms of both the excess risk and the classification\ninstability, which are proven to be the same rates as the oracle nearest\nneighbor classifier and cannot be improved. To significantly reduce the\nprediction time that is required for achieving the optimal rate, we also\nconsider the pre-training acceleration technique applied to the bigNN method,\nwith proven convergence rate. We find that in the distributed setting, the\noptimal choice of the neighbor $k$ should scale with both the total sample size\nand the number of partitions, and there is a theoretical upper limit for the\nlatter. Numerical studies have verified the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:36:41 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 02:10:29 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Qiao", "Xingye", ""], ["Duan", "Jiexin", ""], ["Cheng", "Guang", ""]]}, {"id": "1909.01486", "submitter": "Samuel Showalter", "authors": "Samuel Showalter, Zhixin Wu", "title": "Minimizing the Societal Cost of Credit Card Fraud with Limited and\n  Imbalanced Data", "comments": "16 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has automated much of financial fraud detection, notifying\nfirms of, or even blocking, questionable transactions instantly. However, data\nimbalance starves traditionally trained models of the content necessary to\ndetect fraud. This study examines three separate factors of credit card fraud\ndetection via machine learning. First, it assesses the potential for different\nsampling methods, undersampling and Synthetic Minority Oversampling Technique\n(SMOTE), to improve algorithm performance in data-starved environments.\nAdditionally, five industry-practical machine learning algorithms are evaluated\non total fraud cost savings in addition to traditional statistical metrics.\nFinally, an ensemble of individual models is trained with a genetic algorithm\nto attempt to generate higher cost efficiency than its components. Monte Carlo\nperformance distributions discerned random undersampling outperformed SMOTE in\nlowering fraud costs, and that an ensemble was unable to outperform its\nindividual parts. Most notably,the F-1 Score, a traditional metric often used\nto measure performance with imbalanced data, was uncorrelated with derived cost\nefficiency. Assuming a realistic cost structure can be derived, cost-based\nmetrics provide an essential supplement to objective statistical evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 22:43:15 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 03:40:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Showalter", "Samuel", ""], ["Wu", "Zhixin", ""]]}, {"id": "1909.01492", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani\n  Yogatama, Sven Gowal, Krishnamurthy Dvijotham, Pushmeet Kohli", "title": "Achieving Verified Robustness to Symbol Substitutions via Interval Bound\n  Propagation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are part of many contemporary NLP systems, yet their\nempirical successes come at the price of vulnerability to adversarial attacks.\nPrevious work has used adversarial training and data augmentation to partially\nmitigate such brittleness, but these are unlikely to find worst-case\nadversaries due to the complexity of the search space arising from discrete\ntext perturbations. In this work, we approach the problem from the opposite\ndirection: to formally verify a system's robustness against a predefined class\nof adversarial attacks. We study text classification under synonym replacements\nor character flip perturbations. We propose modeling these input perturbations\nas a simplex and then using Interval Bound Propagation -- a formal model\nverification method. We modify the conventional log-likelihood training\nobjective to train models that can be efficiently verified, which would\notherwise come with exponential search complexity. The resulting models show\nonly little difference in terms of nominal accuracy, but have much improved\nverified accuracy under perturbations and come with an efficiently computable\nformal guarantee on worst case adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:03:10 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:21:49 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Huang", "Po-Sen", ""], ["Stanforth", "Robert", ""], ["Welbl", "Johannes", ""], ["Dyer", "Chris", ""], ["Yogatama", "Dani", ""], ["Gowal", "Sven", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1909.01498", "submitter": "Avinash Kori", "authors": "Parth Natekar, Avinash Kori, Ganapathy Krishnamurthi", "title": "Demystifying Brain Tumour Segmentation Networks: Interpretability and\n  Uncertainty Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The accurate automatic segmentation of gliomas and its intra-tumoral\nstructures is important not only for treatment planning but also for follow-up\nevaluations. Several methods based on 2D and 3D Deep Neural Networks (DNN) have\nbeen developed to segment brain tumors and to classify different categories of\ntumors from different MRI modalities. However, these networks are often\nblack-box models and do not provide any evidence regarding the process they\ntake to perform this task. Increasing transparency and interpretability of such\ndeep learning techniques are necessary for the complete integration of such\nmethods into medical practice. In this paper, we explore various techniques to\nexplain the functional organization of brain tumor segmentation models and to\nextract visualizations of internal concepts to understand how these networks\nachieve highly accurate tumor segmentations. We use the BraTS 2018 dataset to\ntrain three different networks with standard architectures and outline\nsimilarities and differences in the process that these networks take to segment\nbrain tumors. We show that brain tumor segmentation networks learn certain\nhuman-understandable disentangled concepts on a filter level. We also show that\nthey take a top-down or hierarchical approach to localizing the different parts\nof the tumor. We then extract visualizations of some internal feature maps and\nalso provide a measure of uncertainty with regards to the outputs of the models\nto give additional qualitative evidence about the predictions of these\nnetworks. We believe that the emergence of such human-understandable\norganization and concepts might aid in the acceptance and integration of such\nmethods in medical diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:53:11 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 06:29:21 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 03:04:49 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Natekar", "Parth", ""], ["Kori", "Avinash", ""], ["Krishnamurthi", "Ganapathy", ""]]}, {"id": "1909.01502", "submitter": "Riley Spahn", "authors": "Mathias Lecuyer, Riley Spahn, Kiran Vodrahalli, Roxana Geambasu,\n  Daniel Hsu", "title": "Privacy Accounting and Quality Control in the Sage Differentially\n  Private ML Platform", "comments": "Extended version of a paper presented at the 27th ACM Symposium on\n  Operating Systems Principles (SOSP '19)", "journal-ref": null, "doi": "10.1145/3341301.3359639", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies increasingly expose machine learning (ML) models trained over\nsensitive user data to untrusted domains, such as end-user devices and\nwide-access model stores. We present Sage, a differentially private (DP) ML\nplatform that bounds the cumulative leakage of training data through models.\nSage builds upon the rich literature on DP ML algorithms and contributes\npragmatic solutions to two of the most pressing systems challenges of global\nDP: running out of privacy budget and the privacy-utility tradeoff. To address\nthe former, we develop block composition, a new privacy loss accounting method\nthat leverages the growing database regime of ML workloads to keep training\nmodels endlessly on a sensitive data stream while enforcing a global DP\nguarantee for the stream. To address the latter, we develop privacy-adaptive\ntraining, a process that trains a model on growing amounts of data and/or with\nincreasing privacy parameters until, with high probability, the model meets\ndeveloper-configured quality criteria. They illustrate how a systems focus on\ncharacteristics of ML workloads enables pragmatic solutions that are not\napparent when one focuses on individual algorithms, as most DP ML literature\ndoes.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 00:23:21 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 18:25:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Lecuyer", "Mathias", ""], ["Spahn", "Riley", ""], ["Vodrahalli", "Kiran", ""], ["Geambasu", "Roxana", ""], ["Hsu", "Daniel", ""]]}, {"id": "1909.01504", "submitter": "Arun Verma Mr.", "authors": "Arun Verma, Manjesh K. Hanawal, Arun Rajkumar, Raman Sankaran", "title": "Censored Semi-Bandits: A Framework for Resource Allocation with Censored\n  Feedback", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study censored Semi-Bandits, a novel variant of the\nsemi-bandits problem. The learner is assumed to have a fixed amount of\nresources, which it allocates to the arms at each time step. The loss observed\nfrom an arm is random and depends on the amount of resources allocated to it.\nMore specifically, the loss equals zero if the allocation for the arm exceeds a\nconstant (but unknown)threshold that can be dependent on the arm. Our goal is\nto learn a feasible allocation that minimizes the expected loss. The problem is\nchallenging because the loss distribution and threshold value of each arm are\nunknown. We study this novel setting by establishing its `equivalence' to\nMultiple-Play Multi-Armed Bandits(MP-MAB) and Combinatorial Semi-Bandits.\nExploiting these equivalences, we derive optimal algorithms for our setting\nusing existing algorithms for MP-MABand Combinatorial Semi-Bandits. Experiments\non synthetically generated data validate performance guarantees of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 00:25:31 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 23:54:18 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 07:56:28 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Rajkumar", "Arun", ""], ["Sankaran", "Raman", ""]]}, {"id": "1909.01506", "submitter": "Yinlam Chow", "authors": "Nir Levine and Yinlam Chow and Rui Shu and Ang Li and Mohammad\n  Ghavamzadeh and Hung Bui", "title": "Prediction, Consistency, Curvature: Representation Learning for\n  Locally-Linear Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world sequential decision-making problems can be formulated as\noptimal control with high-dimensional observations and unknown dynamics. A\npromising approach is to embed the high-dimensional observations into a\nlower-dimensional latent representation space, estimate the latent dynamics\nmodel, then utilize this model for control in the latent space. An important\nopen question is how to learn a representation that is amenable to existing\ncontrol algorithms? In this paper, we focus on learning representations for\nlocally-linear control algorithms, such as iterative LQR (iLQR). By formulating\nand analyzing the representation learning problem from an optimal control\nperspective, we establish three underlying principles that the learned\nrepresentation should comprise: 1) accurate prediction in the observation\nspace, 2) consistency between latent and observation space dynamics, and 3) low\ncurvature in the latent space transitions. These principles naturally\ncorrespond to a loss function that consists of three terms: prediction,\nconsistency, and curvature (PCC). Crucially, to make PCC tractable, we derive\nan amortized variational bound for the PCC loss function. Extensive experiments\non benchmark domains demonstrate that the new variational-PCC learning\nalgorithm benefits from significantly more stable and reproducible training,\nand leads to superior control performance. Further ablation studies give\nsupport to the importance of all three PCC components for learning a good\nlatent space for control.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 00:34:27 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:35:48 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Levine", "Nir", ""], ["Chow", "Yinlam", ""], ["Shu", "Rui", ""], ["Li", "Ang", ""], ["Ghavamzadeh", "Mohammad", ""], ["Bui", "Hung", ""]]}, {"id": "1909.01515", "submitter": "Mingyang Chen", "authors": "Mingyang Chen, Wen Zhang, Wei Zhang, Qiang Chen, Huajun Chen", "title": "Meta Relational Learning for Few-Shot Link Prediction in Knowledge\n  Graphs", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is an important way to complete knowledge graphs (KGs), while\nembedding-based methods, effective for link prediction in KGs, perform poorly\non relations that only have a few associative triples. In this work, we propose\na Meta Relational Learning (MetaR) framework to do the common but challenging\nfew-shot link prediction in KGs, namely predicting new triples about a relation\nby only observing a few associative triples. We solve few-shot link prediction\nby focusing on transferring relation-specific meta information to make model\nlearn the most important knowledge and learn faster, corresponding to relation\nmeta and gradient meta respectively in MetaR. Empirically, our model achieves\nstate-of-the-art results on few-shot link prediction KG benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 01:35:47 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Chen", "Mingyang", ""], ["Zhang", "Wen", ""], ["Zhang", "Wei", ""], ["Chen", "Qiang", ""], ["Chen", "Huajun", ""]]}, {"id": "1909.01519", "submitter": "Mahammad Humayoo", "authors": "Mahammad Humayoo and Xueqi Cheng", "title": "Parameter Estimation with the Ordered $\\ell_{2}$ Regularization via an\n  Alternating Direction Method of Multipliers", "comments": null, "journal-ref": "Applied Sciences (ISSN 2076-3417; CODEN: ASPCC7)", "doi": "10.3390/app9204291", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is a popular technique in machine learning for model\nestimation and avoiding overfitting. Prior studies have found that modern\nordered regularization can be more effective in handling highly correlated,\nhigh-dimensional data than traditional regularization. The reason stems from\nthe fact that the ordered regularization can reject irrelevant variables and\nyield an accurate estimation of the parameters. How to scale up the ordered\nregularization problems when facing the large-scale training data remains an\nunanswered question. This paper explores the problem of parameter estimation\nwith the ordered $\\ell_{2}$-regularization via Alternating Direction Method of\nMultipliers (ADMM), called ADMM-O$\\ell_{2}$. The advantages of ADMM-O$\\ell_{2}$\ninclude (i) scaling up the ordered $\\ell_{2}$ to a large-scale dataset, (ii)\npredicting parameters correctly by excluding irrelevant variables\nautomatically, and (iii) having a fast convergence rate. Experiment results on\nboth synthetic data and real data indicate that ADMM-O$\\ell_{2}$ can perform\nbetter than or comparable to several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 01:58:08 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 01:15:52 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 08:33:34 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Humayoo", "Mahammad", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1909.01520", "submitter": "Tyler Hayes", "authors": "Tyler L. Hayes and Christopher Kanan", "title": "Lifelong Machine Learning with Deep Streaming Linear Discriminant\n  Analysis", "comments": "To appear in the IEEE Conference on Computer Vision and Pattern\n  Recognition Workshop (CVPR-W) on Continual Learning in Computer Vision\n  (CLVision) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When an agent acquires new information, ideally it would immediately be\ncapable of using that information to understand its environment. This is not\npossible using conventional deep neural networks, which suffer from\ncatastrophic forgetting when they are incrementally updated, with new knowledge\noverwriting established representations. A variety of approaches have been\ndeveloped that attempt to mitigate catastrophic forgetting in the incremental\nbatch learning scenario, where a model learns from a series of large\ncollections of labeled samples. However, in this setting, inference is only\npossible after a batch has been accumulated, which prohibits many applications.\nAn alternative paradigm is online learning in a single pass through the\ntraining dataset on a resource constrained budget, which is known as streaming\nlearning. Streaming learning has been much less studied in the deep learning\ncommunity. In streaming learning, an agent learns instances one-by-one and can\nbe tested at any time, rather than only after learning a large batch. Here, we\nrevisit streaming linear discriminant analysis, which has been widely used in\nthe data mining research community. By combining streaming linear discriminant\nanalysis with deep learning, we are able to outperform both incremental batch\nlearning and streaming learning algorithms on both ImageNet ILSVRC-2012 and\nCORe50, a dataset that involves learning to classify from temporally ordered\nsamples.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:13:22 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 17:17:47 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 16:28:51 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hayes", "Tyler L.", ""], ["Kanan", "Christopher", ""]]}, {"id": "1909.01525", "submitter": "Chenwei Ding", "authors": "Chenwei Ding, Mingming Gong, Kun Zhang, Dacheng Tao", "title": "Likelihood-Free Overcomplete ICA and Applications in Causal Discovery", "comments": "10 pages, 3 figures. Accepted by NeurIPS 2019 as spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery witnessed significant progress over the past decades. In\nparticular, many recent causal discovery methods make use of independent,\nnon-Gaussian noise to achieve identifiability of the causal models. Existence\nof hidden direct common causes, or confounders, generally makes causal\ndiscovery more difficult; whenever they are present, the corresponding causal\ndiscovery algorithms can be seen as extensions of overcomplete independent\ncomponent analysis (OICA). However, existing OICA algorithms usually make\nstrong parametric assumptions on the distribution of independent components,\nwhich may be violated on real data, leading to sub-optimal or even wrong\nsolutions. In addition, existing OICA algorithms rely on the Expectation\nMaximization (EM) procedure that requires computationally expensive inference\nof the posterior distribution of independent components. To tackle these\nproblems, we present a Likelihood-Free Overcomplete ICA algorithm (LFOICA) that\nestimates the mixing matrix directly by back-propagation without any explicit\nassumptions on the density function of independent components. Thanks to its\ncomputational efficiency, the proposed method makes a number of causal\ndiscovery procedures much more practically feasible. For illustrative purposes,\nwe demonstrate the computational efficiency and efficacy of our method in two\ncausal discovery tasks on both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:27:50 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 06:30:37 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Ding", "Chenwei", ""], ["Gong", "Mingming", ""], ["Zhang", "Kun", ""], ["Tao", "Dacheng", ""]]}, {"id": "1909.01539", "submitter": "Yang Li", "authors": "Yang Li and Thomas Strohmer", "title": "What Happens on the Edge, Stays on the Edge: Toward Compressive Deep\n  Learning", "comments": "14 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning at the edge offers great benefits such as increased privacy\nand security, low latency, and more autonomy. However, a major challenge is\nthat many devices, in particular edge devices, have very limited memory, weak\nprocessors, and scarce energy supply. We propose a hybrid hardware-software\nframework that has the potential to significantly reduce the computational\ncomplexity and memory requirements of on-device machine learning. In the first\nstep, inspired by compressive sensing, data is collected in compressed form\nsimultaneously with the sensing process. Thus this compression happens already\nat the hardware level during data acquisition. But unlike in compressive\nsensing, this compression is achieved via a projection operator that is\nspecifically tailored to the desired machine learning task. The second step\nconsists of a specially designed and trained deep network. As concrete example\nwe consider the task of image classification, although the proposed framework\nis more widely applicable. An additional benefit of our approach is that it can\nbe easily combined with existing on-device techniques. Numerical simulations\nillustrate the viability of our method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:29:23 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Li", "Yang", ""], ["Strohmer", "Thomas", ""]]}, {"id": "1909.01541", "submitter": "Quanyu Dai", "authors": "Quanyu Dai, Xiao Shen, Xiao-Ming Wu and Dan Wang", "title": "Network Transfer Learning via Adversarial Domain Adaptation with Graph\n  Convolution", "comments": "Submitted to IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of cross-network node classification to\novercome the insufficiency of labeled data in a single network. It aims to\nleverage the label information in a partially labeled source network to assist\nnode classification in a completely unlabeled or partially labeled target\nnetwork. Existing methods for single network learning cannot solve this problem\ndue to the domain shift across networks. Some multi-network learning methods\nheavily rely on the existence of cross-network connections, thus are\ninapplicable for this problem. To tackle this problem, we propose a novel\nnetwork transfer learning framework AdaGCN by leveraging the techniques of\nadversarial domain adaptation and graph convolution. It consists of two\ncomponents: a semi-supervised learning component and an adversarial domain\nadaptation component. The former aims to learn class discriminative node\nrepresentations with given label information of the source and target networks,\nwhile the latter contributes to mitigating the distribution divergence between\nthe source and target domains to facilitate knowledge transfer. Extensive\nempirical evaluations on real-world datasets show that AdaGCN can successfully\ntransfer class information with a low label rate on the source network and a\nsubstantial divergence between the source and target domains. Codes will be\nreleased upon acceptance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:33:10 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Dai", "Quanyu", ""], ["Shen", "Xiao", ""], ["Wu", "Xiao-Ming", ""], ["Wang", "Dan", ""]]}, {"id": "1909.01543", "submitter": "Rui Hou", "authors": "Rui Hou, Ver\\'onica P\\'erez-Rosas, Stacy Loeb, Rada Mihalcea", "title": "Towards Automatic Detection of Misinformation in Online Medical Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a significant increase in the online sharing of\nmedical information, with videos representing a large fraction of such online\nsources. Previous studies have however shown that more than half of the\nhealth-related videos on platforms such as YouTube contain misleading\ninformation and biases. Hence, it is crucial to build computational tools that\ncan help evaluate the quality of these videos so that users can obtain accurate\ninformation to help inform their decisions. In this study, we focus on the\nautomatic detection of misinformation in YouTube videos. We select prostate\ncancer videos as our entry point to tackle this problem. The contribution of\nthis paper is twofold. First, we introduce a new dataset consisting of 250\nvideos related to prostate cancer manually annotated for misinformation.\nSecond, we explore the use of linguistic, acoustic, and user engagement\nfeatures for the development of classification models to identify\nmisinformation. Using a series of ablation experiments, we show that we can\nbuild automatic models with accuracies of up to 74%, corresponding to a 76.5%\nprecision and 73.2% recall for misinformative instances.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:41:44 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Hou", "Rui", ""], ["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Loeb", "Stacy", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1909.01575", "submitter": "Jacob Rafati", "authors": "Jacob Rafati and David C. Noelle", "title": "Learning sparse representations in reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms allow artificial agents to improve\ntheir selection of actions to increase rewarding experiences in their\nenvironments. Temporal Difference (TD) Learning -- a model-free RL method -- is\na leading account of the midbrain dopamine system and the basal ganglia in\nreinforcement learning. These algorithms typically learn a mapping from the\nagent's current sensed state to a selected action (known as a policy function)\nvia learning a value function (expected future rewards). TD Learning methods\nhave been very successful on a broad range of control tasks, but learning can\nbecome intractably slow as the state space of the environment grows. This has\nmotivated methods that learn internal representations of the agent's state,\neffectively reducing the size of the state space and restructuring state\nrepresentations in order to support generalization. However, TD Learning\ncoupled with an artificial neural network, as a function approximator, has been\nshown to fail to learn some fairly simple control tasks, challenging this\nexplanation of reward-based learning. We hypothesize that such failures do not\narise in the brain because of the ubiquitous presence of lateral inhibition in\nthe cortex, producing sparse distributed internal representations that support\nthe learning of expected future reward. The sparse conjunctive representations\ncan avoid catastrophic interference while still supporting generalization. We\nprovide support for this conjecture through computational simulations,\ndemonstrating the benefits of learned sparse representations for three\nproblematic classic control tasks: Puddle-world, Mountain-car, and Acrobot.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:58:32 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Rafati", "Jacob", ""], ["Noelle", "David C.", ""]]}, {"id": "1909.01576", "submitter": "Akihiro Yabe", "authors": "Akihiro Yabe and Takanori Maehara", "title": "Empirical Hypothesis Space Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting appropriate regularization coefficients is critical to performance\nwith respect to regularized empirical risk minimization problems. Existing\ntheoretical approaches attempt to determine the coefficients in order for\nregularized empirical objectives to be upper-bounds of true objectives,\nuniformly over a hypothesis space. Such an approach is, however, known to be\nover-conservative, especially in high-dimensional settings with large\nhypothesis space. In fact, an existing generalization error bound in\nvariance-based regularization is $O(\\sqrt{d \\log n/n})$, where $d$ is the\ndimension of hypothesis space, and thus the number of samples required for\nconvergence linearly increases with respect to $d$. This paper proposes an\nalgorithm that calculates regularization coefficient, one which results in\nfaster convergence of generalization error $O(\\sqrt{\\log n/n})$ and whose\nleading term is independent of the dimension $d$. This faster convergence\nwithout dependence on the size of the hypothesis space is achieved by means of\nempirical hypothesis space reduction, which, with high probability,\nsuccessfully reduces a hypothesis space without losing the true optimum\nsolution. Calculation of uniform upper bounds over reduced spaces, then,\nenables acceleration of the convergence of generalization error.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 07:00:26 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Yabe", "Akihiro", ""], ["Maehara", "Takanori", ""]]}, {"id": "1909.01606", "submitter": "Hong Xu", "authors": "Alex Bozarth and Brendan Dwyer and Fei Hu and Daniel Jalova and\n  Karthik Muthuraman and Nick Pentreath and Simon Plovyt and Gabriela de\n  Queiroz and Saishruthi Swaminathan and Patrick Titzler and Xin Wu and Hong Xu\n  and Frederick R Reiss and Vijay Bommireddipalli", "title": "Model Asset eXchange: Path to Ubiquitous Deep Learning Deployment", "comments": "4 pages, 3 figures. Demo paper", "journal-ref": "Alex Bozarth et al. 2019. Model Asset eXchange: Path to Ubiquitous\n  Deep Learning Deployment. In The 28th ACM International Conference on\n  Information and Knowledge Management (CIKM '19)", "doi": "10.1145/3357384.3357860", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend observed in traditionally challenging fields such as computer\nvision and natural language processing has been the significant performance\ngains shown by deep learning (DL). In many different research fields, DL models\nhave been evolving rapidly and become ubiquitous. Despite researchers'\nexcitement, unfortunately, most software developers are not DL experts and\noftentimes have a difficult time following the booming DL research outputs. As\na result, it usually takes a significant amount of time for the latest superior\nDL models to prevail in industry. This issue is further exacerbated by the\ncommon use of sundry incompatible DL programming frameworks, such as\nTensorflow, PyTorch, Theano, etc. To address this issue, we propose a system,\ncalled Model Asset Exchange (MAX), that avails developers of easy access to\nstate-of-the-art DL models. Regardless of the underlying DL programming\nframeworks, it provides an open source Python library (called the MAX\nframework) that wraps DL models and unifies programming interfaces with our\nstandardized RESTful APIs. These RESTful APIs enable developers to exploit the\nwrapped DL models for inference tasks without the need to fully understand\ndifferent DL programming frameworks. Using MAX, we have wrapped and\nopen-sourced more than 30 state-of-the-art DL models from various research\nfields, including computer vision, natural language processing and signal\nprocessing, etc. In the end, we selectively demonstrate two web applications\nthat are built on top of MAX, as well as the process of adding a DL model to\nMAX.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 08:05:03 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Bozarth", "Alex", ""], ["Dwyer", "Brendan", ""], ["Hu", "Fei", ""], ["Jalova", "Daniel", ""], ["Muthuraman", "Karthik", ""], ["Pentreath", "Nick", ""], ["Plovyt", "Simon", ""], ["de Queiroz", "Gabriela", ""], ["Swaminathan", "Saishruthi", ""], ["Titzler", "Patrick", ""], ["Wu", "Xin", ""], ["Xu", "Hong", ""], ["Reiss", "Frederick R", ""], ["Bommireddipalli", "Vijay", ""]]}, {"id": "1909.01614", "submitter": "Siddharth Ramchandran", "authors": "Siddharth Ramchandran, Miika Koskinen and Harri L\\\"ahdesm\\\"aki", "title": "Latent Gaussian process with composite likelihoods and numerical\n  quadrature", "comments": null, "journal-ref": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS-2021), pp. 3718-3726. PMLR, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clinical patient records are an example of high-dimensional data that is\ntypically collected from disparate sources and comprises of multiple\nlikelihoods with noisy as well as missing values. In this work, we propose an\nunsupervised generative model that can learn a low-dimensional representation\namong the observations in a latent space, while making use of all available\ndata in a heterogeneous data setting with missing values. We improve upon the\nexisting Gaussian process latent variable model (GPLVM) by incorporating\nmultiple likelihoods and deep neural network parameterised back-constraints to\ncreate a non-linear dimensionality reduction technique for heterogeneous data.\nIn addition, we develop a variational inference method for our model that uses\nnumerical quadrature. We establish the effectiveness of our model and compare\nagainst existing GPLVM methods on a standard benchmark dataset as well as on\nclinical data of Parkinson's disease patients treated at the HUS Helsinki\nUniversity Hospital.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 08:30:22 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 11:12:01 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 18:32:04 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 14:57:11 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ramchandran", "Siddharth", ""], ["Koskinen", "Miika", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "1909.01646", "submitter": "Leonard Adolphs", "authors": "Leonard Adolphs and Thomas Hofmann", "title": "LeDeepChef: Deep Reinforcement Learning Agent for Families of Text-Based\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Reinforcement Learning (RL) approaches lead to significant achievements\nin a variety of areas in recent history, natural language tasks remained mostly\nunaffected, due to the compositional and combinatorial nature that makes them\nnotoriously hard to optimize. With the emerging field of Text-Based Games\n(TBGs), researchers try to bridge this gap. Inspired by the success of RL\nalgorithms on Atari games, the idea is to develop new methods in a restricted\ngame world and then gradually move to more complex environments. Previous work\nin the area of TBGs has mainly focused on solving individual games. We,\nhowever, consider the task of designing an agent that not just succeeds in a\nsingle game, but performs well across a whole family of games, sharing the same\ntheme. In this work, we present our deep RL agent--LeDeepChef--that shows\ngeneralization capabilities to never-before-seen games of the same family with\ndifferent environments and task descriptions. The agent participated in\nMicrosoft Research's \"First TextWorld Problems: A Language and Reinforcement\nLearning Challenge\" and outperformed all but one competitor on the final test\nset. The games from the challenge all share the same theme, namely cooking in a\nmodern house environment, but differ significantly in the arrangement of the\nrooms, the presented objects, and the specific goal (recipe to cook). To build\nan agent that achieves high scores across a whole family of games, we use an\nactor-critic framework and prune the action-space by using ideas from\nhierarchical reinforcement learning and a specialized module trained on a\nrecipe database.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:30:55 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Adolphs", "Leonard", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1909.01651", "submitter": "Leo Gautheron", "authors": "L\\'eo Gautheron (LHC), Emilie Morvant (LHC), Amaury Habrard (LHC),\n  Marc Sebban (LHC)", "title": "Metric Learning from Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key element of any machine learning algorithm is the use of a function that\nmeasures the dis/similarity between data points. Given a task, such a function\ncan be optimized with a metric learning algorithm. Although this research field\nhas received a lot of attention during the past decade, very few approaches\nhave focused on learning a metric in an imbalanced scenario where the number of\npositive examples is much smaller than the negatives. Here, we address this\nchallenging task by designing a new Mahalanobis metric learning algorithm (IML)\nwhich deals with class imbalance. The empirical study performed shows the\nefficiency of IML.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:38:58 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Gautheron", "L\u00e9o", "", "LHC"], ["Morvant", "Emilie", "", "LHC"], ["Habrard", "Amaury", "", "LHC"], ["Sebban", "Marc", "", "LHC"]]}, {"id": "1909.01688", "submitter": "Sungho Shin", "authors": "Sungho Shin, Yoonho Boo, Wonyong Sung", "title": "Knowledge distillation for optimization of quantized deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a very popular method for model size\nreduction. Recently, the technique is exploited for quantized deep neural\nnetworks (QDNNs) training as a way to restore the performance sacrificed by\nword-length reduction. KD, however, employs additional hyper-parameters, such\nas temperature, coefficient, and the size of teacher network for QDNN training.\nWe analyze the effect of these hyper-parameters for QDNN optimization with KD.\nWe find that these hyper-parameters are inter-related, and also introduce a\nsimple and effective technique that reduces \\textit{coefficient} during\ntraining. With KD employing the proposed hyper-parameters, we achieve the test\naccuracy of 92.7% and 67.0% on Resnet20 with 2-bit ternary weights for CIFAR-10\nand CIFAR-100 data sets, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:47:03 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 06:36:35 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 10:46:56 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Shin", "Sungho", ""], ["Boo", "Yoonho", ""], ["Sung", "Wonyong", ""]]}, {"id": "1909.01691", "submitter": "Alexander Fisch", "authors": "Alexander T M Fisch, Idris A Eckley, Paul Fearnhead", "title": "Subset Multivariate Collective And Point Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a growing interest in identifying anomalous\nstructure within multivariate data streams. We consider the problem of\ndetecting collective anomalies, corresponding to intervals where one or more of\nthe data streams behaves anomalously. We first develop a test for a single\ncollective anomaly that has power to simultaneously detect anomalies that are\neither rare, that is affecting few data streams, or common. We then show how to\ndetect multiple anomalies in a way that is computationally efficient but avoids\nthe approximations inherent in binary segmentation-like approaches. This\napproach, which we call MVCAPA, is shown to consistently estimate the number\nand location of the collective anomalies, a property that has not previously\nbeen shown for competing methods. MVCAPA can be made robust to point anomalies\nand can allow for the anomalies to be imperfectly aligned. We show the\npractical usefulness of allowing for imperfect alignments through a resulting\nincrease in power to detect regions of copy number variation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:58:46 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Fisch", "Alexander T M", ""], ["Eckley", "Idris A", ""], ["Fearnhead", "Paul", ""]]}, {"id": "1909.01709", "submitter": "Niklas Heim", "authors": "Niklas Heim, James E. Avery", "title": "Adaptive Anomaly Detection in Chaotic Time Series with a Spatially Aware\n  Echo State Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work builds an automated anomaly detection method for chaotic time\nseries, and more concretely for turbulent, high-dimensional, ocean simulations.\nWe solve this task by extending the Echo State Network by spatially aware input\nmaps, such as convolutions, gradients, cosine transforms, et cetera, as well as\na spatially aware loss function. The spatial ESN is used to create predictions\nwhich reduce the detection problem to thresholding of the prediction error. We\nbenchmark our detection framework on different tasks of increasing difficulty\nto show the generality of the framework before applying it to raw climate model\noutput in the region of the Japanese ocean current Kuroshio, which exhibits a\nbimodality that is not easily detected by the naked eye. The code is available\nas an open source Python package, Torsk, available at\nhttps://github.com/nmheim/torsk, where we also provide supplementary material\nand programs that reproduce the results shown in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:46:07 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Heim", "Niklas", ""], ["Avery", "James E.", ""]]}, {"id": "1909.01730", "submitter": "Carl Andersson", "authors": "Carl Andersson, Ant\\^onio H. Ribeiro, Koen Tiels, Niklas Wahlstr\\\"om\n  and Thomas B. Sch\\\"on", "title": "Deep Convolutional Networks in System Identification", "comments": "Accepted to Conference on Decision and Control, The first two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments within deep learning are relevant for nonlinear system\nidentification problems. In this paper, we establish connections between the\ndeep learning and the system identification communities. It has recently been\nshown that convolutional architectures are at least as capable as recurrent\narchitectures when it comes to sequence modeling tasks. Inspired by these\nresults we explore the explicit relationships between the recently proposed\ntemporal convolutional network (TCN) and two classic system identification\nmodel structures; Volterra series and block-oriented models. We end the paper\nwith an experimental study where we provide results on two real-world problems,\nthe well-known Silverbox dataset and a newer dataset originating from ground\nvibration experiments on an F-16 fighter aircraft.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:34:32 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:30:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Andersson", "Carl", ""], ["Ribeiro", "Ant\u00f4nio H.", ""], ["Tiels", "Koen", ""], ["Wahlstr\u00f6m", "Niklas", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1909.01735", "submitter": "Mohammad Akbari", "authors": "Mohammad Akbari and Rumi Chunara", "title": "Using Contextual Information to Improve Blood Glucose Prediction", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blood glucose value prediction is an important task in diabetes management.\nWhile it is reported that glucose concentration is sensitive to social context\nsuch as mood, physical activity, stress, diet, alongside the influence of\ndiabetes pathologies, we need more research on data and methodologies to\nincorporate and evaluate signals about such temporal context into prediction\nmodels. Person-generated data sources, such as actively contributed surveys as\nwell as passively mined data from social media offer opportunity to capture\nsuch context, however the self-reported nature and sparsity of such data mean\nthat such data are noisier and less specific than physiological measures such\nas blood glucose values themselves. Therefore, here we propose a Gaussian\nProcess model to both address these data challenges and combine blood glucose\nand latent feature representations of contextual data for a novel multi-signal\nblood glucose prediction task. We find this approach outperforms common methods\nfor multi-variate data, as well as using the blood glucose values in isolation.\nGiven a robust evaluation across two blood glucose datasets with different\nforms of contextual information, we conclude that multi-signal Gaussian\nProcesses can improve blood glucose prediction by using contextual information\nand may provide a significant shift in blood glucose prediction research and\npractice.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 11:02:52 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Akbari", "Mohammad", ""], ["Chunara", "Rumi", ""]]}, {"id": "1909.01757", "submitter": "Massimiliano Ruocco", "authors": "Andreas Kvistad, Massimiliano Ruocco, Eliezer de Souza da Silva,\n  Erlend Aune", "title": "Augmented Memory Networks for Streaming-Based Active One-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the major challenges in training deep architectures for predictive\ntasks is the scarcity and cost of labeled training data. Active Learning (AL)\nis one way of addressing this challenge. In stream-based AL, observations are\ncontinuously made available to the learner that have to decide whether to\nrequest a label or to make a prediction. The goal is to reduce the request rate\nwhile at the same time maximize prediction performance. In previous research,\nreinforcement learning has been used for learning the AL request/prediction\nstrategy. In our work, we propose to equip a reinforcement learning process\nwith memory augmented neural networks, to enhance the one-shot capabilities.\nMoreover, we introduce Class Margin Sampling (CMS) as an extension of the\nstandard margin sampling to the reinforcement learning setting. This strategy\naims to reduce training time and improve sample efficiency in the training\nprocess. We evaluate the proposed method on a classification task using\nempirical accuracy of label predictions and percentage of label requests. The\nresults indicates that the proposed method, by making use of the memory\naugmented networks and CMS in the training process, outperforms existing\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:56:50 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Kvistad", "Andreas", ""], ["Ruocco", "Massimiliano", ""], ["da Silva", "Eliezer de Souza", ""], ["Aune", "Erlend", ""]]}, {"id": "1909.01759", "submitter": "Manel Mart\\'inez-Ram\\'on", "authors": "Nestor Pereira, Miguel Angel Hombrados Herrera, Vanesssa\n  G\\'omez-Verdejo, Andrea A. Mammoli, Manel Mart\\'inez-Ram\\'on", "title": "Data Selection for Short Term load forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power load forecast with Machine Learning is a fairly mature application of\nartificial intelligence and it is indispensable in operation, control and\nplanning. Data selection techniqies have been hardly used in this application.\nHowever, the use of such techniques could be beneficial provided the assumption\nthat the data is identically distributed is clearly not true in load\nforecasting, but it is cyclostationary. In this work we present a fully\nautomatic methodology to determine what are the most adequate data to train a\npredictor which is based on a full Bayesian probabilistic model. We assess the\nperformance of the method with experiments based on real publicly available\ndata recorded from several years in the United States of America.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:51:48 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 19:48:59 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Pereira", "Nestor", ""], ["Herrera", "Miguel Angel Hombrados", ""], ["G\u00f3mez-Verdejo", "Vanesssa", ""], ["Mammoli", "Andrea A.", ""], ["Mart\u00ednez-Ram\u00f3n", "Manel", ""]]}, {"id": "1909.01779", "submitter": "Matthia Sabatelli", "authors": "Matthia Sabatelli, Gilles Louppe, Pierre Geurts, Marco A. Wiering", "title": "Approximating two value functions instead of one: towards characterizing\n  a new family of Deep Reinforcement Learning algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes one step forward towards characterizing a new family of\n\\textit{model-free} Deep Reinforcement Learning (DRL) algorithms. The aim of\nthese algorithms is to jointly learn an approximation of the state-value\nfunction ($V$), alongside an approximation of the state-action value function\n($Q$). Our analysis starts with a thorough study of the Deep Quality-Value\nLearning (DQV) algorithm, a DRL algorithm which has been shown to outperform\npopular techniques such as Deep-Q-Learning (DQN) and Double-Deep-Q-Learning\n(DDQN) \\cite{sabatelli2018deep}. Intending to investigate why DQV's learning\ndynamics allow this algorithm to perform so well, we formulate a set of\nresearch questions which help us characterize a new family of DRL algorithms.\nAmong our results, we present some specific cases in which DQV's performance\ncan get harmed and introduce a novel \\textit{off-policy} DRL algorithm, called\nDQV-Max, which can outperform DQV. We then study the behavior of the $V$ and\n$Q$ functions that are learned by DQV and DQV-Max and show that both algorithms\nmight perform so well on several DRL test-beds because they are less prone to\nsuffer from the overestimation bias of the $Q$ function.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 10:29:54 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 09:06:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Sabatelli", "Matthia", ""], ["Louppe", "Gilles", ""], ["Geurts", "Pierre", ""], ["Wiering", "Marco A.", ""]]}, {"id": "1909.01783", "submitter": "Giuseppe Vietri", "authors": "Seth Neel, Aaron Roth, Giuseppe Vietri, Zhiwei Steven Wu", "title": "Oracle Efficient Private Non-Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most effective algorithms for differentially private learning and\noptimization is objective perturbation. This technique augments a given\noptimization problem (e.g. deriving from an ERM problem) with a random linear\nterm, and then exactly solves it. However, to date, analyses of this approach\ncrucially rely on the convexity and smoothness of the objective function,\nlimiting its generality. We give two algorithms that extend this approach\nsubstantially. The first algorithm requires nothing except boundedness of the\nloss function, and operates over a discrete domain. Its privacy and accuracy\nguarantees hold even without assuming convexity. This gives an oracle-efficient\noptimization algorithm over arbitrary discrete domains that is comparable in\nits generality to the exponential mechanism. The second algorithm operates over\na continuous domain and requires only that the loss function be bounded and\nLipschitz in its continuous parameter. Its privacy analysis does not require\nconvexity. Its accuracy analysis does require convexity, but does not require\nsecond order conditions like smoothness. Even without convexity, this algorithm\ncan be generically used as an oracle-efficient optimization algorithm, with\naccuracy evaluated empirically. We complement our theoretical results with an\nempirical evaluation of the non-convex case, in which we use an integer program\nsolver as our optimization oracle. We find that for the problem of learning\nlinear classifiers, directly optimizing for 0/1 loss using our approach can\nout-perform the more standard approach of privately optimizing a\nconvex-surrogate loss function on the Adult dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:31:11 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 18:29:31 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 15:06:40 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Vietri", "Giuseppe", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1909.01789", "submitter": "Shuyan Wang", "authors": "Shuyan Wang", "title": "Unifying Causal Models with Trek Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scientific contexts, different investigators experiment with or\nobserve different variables with data from a domain in which the distinct\nvariable sets might well be related. This sort of fragmentation sometimes\noccurs in molecular biology, whether in studies of RNA expression or studies of\nprotein interaction, and it is common in the social sciences. Models are built\non the diverse data sets, but combining them can provide a more unified account\nof the causal processes in the domain. On the other hand, this problem is made\nchallenging by the fact that a variable in one data set may influence variables\nin another although neither data set contains all of the variables involved.\nSeveral authors have proposed using conditional independence properties of\nfragmentary (marginal) data collections to form unified causal explanations\nwhen it is assumed that the data have a common causal explanation but cannot be\nmerged to form a unified dataset. These methods typically return a large number\nof alternative causal models. The first part of the thesis shows that marginal\ndatasets contain extra information that can be used to reduce the number of\npossible models, in some cases yielding a unique model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 20:42:18 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Wang", "Shuyan", ""]]}, {"id": "1909.01804", "submitter": "Zhanghan Ke", "authors": "Zhanghan Ke and Daoye Wang and Qiong Yan and Jimmy Ren and Rynson W.H.\n  Lau", "title": "Dual Student: Breaking the Limits of the Teacher in Semi-supervised\n  Learning", "comments": "International Conference in Computer Vision 2019 (ICCV 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, consistency-based methods have achieved state-of-the-art results in\nsemi-supervised learning (SSL). These methods always involve two roles, an\nexplicit or implicit teacher model and a student model, and penalize\npredictions under different perturbations by a consistency constraint. However,\nthe weights of these two roles are tightly coupled since the teacher is\nessentially an exponential moving average (EMA) of the student. In this work,\nwe show that the coupled EMA teacher causes a performance bottleneck. To\naddress this problem, we introduce Dual Student, which replaces the teacher\nwith another student. We also define a novel concept, stable sample, following\nwhich a stabilization constraint is designed for our structure to be trainable.\nFurther, we discuss two variants of our method, which produce even higher\nperformance. Extensive experiments show that our method improves the\nclassification performance significantly on several main SSL benchmarks.\nSpecifically, it reduces the error rate of the 13-layer CNN from 16.84% to\n12.39% on CIFAR-10 with 1k labels and from 34.10% to 31.56% on CIFAR-100 with\n10k labels. In addition, our method also achieves a clear improvement in domain\nadaptation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:32:11 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ke", "Zhanghan", ""], ["Wang", "Daoye", ""], ["Yan", "Qiong", ""], ["Ren", "Jimmy", ""], ["Lau", "Rynson W. H.", ""]]}, {"id": "1909.01811", "submitter": "Ruomu Zou", "authors": "Ruomu Zou", "title": "A Deep, Forgetful Novelty-Seeking Movie Recommender Model", "comments": "19 pages, 14 figures, submitted as a contest entry to the S.-T. Yau\n  High School Science Award (Computer Award)", "journal-ref": null, "doi": "10.13140/RG.2.2.35255.27043", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As more and more people shift their movie watching online, competition\nbetween movie viewing websites are getting more and more intense. Therefore, it\nhas become incredibly important to accurately predict a given user's watching\nlist to maximize the chances of keeping the user on the platform. Recent\nstudies have suggested that the novelty-seeking propensity of users can impact\ntheir viewing behavior. In this paper, we aim to accurately model and describe\nthis novelty-seeking trait across many users and timestamps driven by data,\ntaking into consideration user forgetfulness. Compared to previous studies, we\npropose a more robust measure for novelty. Our model, termed Deep Forgetful\nNovelty-Seeking Model (DFNSM), leverages demographic information about users,\ngenre information about movies, and novelty-seeking traits to predict the most\nlikely next actions of a user. To evaluate the performance of our model, we\nconducted extensive experiments on a large movie rating dataset. The results\nreveal that DFNSM is very effective for movie recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:49:38 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zou", "Ruomu", ""]]}, {"id": "1909.01812", "submitter": "Shanshan Wu", "authors": "Shanshan Wu, Alexandros G. Dimakis, Sujay Sanghavi", "title": "Learning Distributions Generated by One-Layer ReLU Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the parameters of a $d$-dimensional\nrectified Gaussian distribution from i.i.d. samples. A rectified Gaussian\ndistribution is defined by passing a standard Gaussian distribution through a\none-layer ReLU neural network. We give a simple algorithm to estimate the\nparameters (i.e., the weight matrix and bias vector of the ReLU neural network)\nup to an error $\\epsilon||W||_F$ using $\\tilde{O}(1/\\epsilon^2)$ samples and\n$\\tilde{O}(d^2/\\epsilon^2)$ time (log factors are ignored for simplicity). This\nimplies that we can estimate the distribution up to $\\epsilon$ in total\nvariation distance using $\\tilde{O}(\\kappa^2d^2/\\epsilon^2)$ samples, where\n$\\kappa$ is the condition number of the covariance matrix. Our only assumption\nis that the bias vector is non-negative. Without this non-negativity\nassumption, we show that estimating the bias vector within any error requires\nthe number of samples at least exponential in the infinity norm of the bias\nvector. Our algorithm is based on the key observation that vector norms and\npairwise angles can be estimated separately. We use a recent result on learning\nfrom truncated samples. We also prove two sample complexity lower bounds:\n$\\Omega(1/\\epsilon^2)$ samples are required to estimate the parameters up to\nerror $\\epsilon$, while $\\Omega(d/\\epsilon^2)$ samples are necessary to\nestimate the distribution up to $\\epsilon$ in total variation distance. The\nfirst lower bound implies that our algorithm is optimal for parameter\nestimation. Finally, we show an interesting connection between learning a\ntwo-layer generative model and non-negative matrix factorization. Experimental\nresults are provided to support our analysis.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 14:04:46 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 16:04:46 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Wu", "Shanshan", ""], ["Dimakis", "Alexandros G.", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1909.01821", "submitter": "Thomas Dybdahl Ahle", "authors": "Thomas D. Ahle, Jakob B. T. Knudsen", "title": "Almost Optimal Tensor Sketch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a matrix $M\\in R^{m\\otimes d^c}$ with just\n$m=O(c\\,\\lambda\\,\\varepsilon^{-2}\\text{poly}\\log1/\\varepsilon\\delta)$ rows,\nwhich preserves the norm $\\|Mx\\|_2=(1\\pm\\varepsilon)\\|x\\|_2$ of all $x$ in any\ngiven $\\lambda$ dimensional subspace of $ R^d$ with probability at least\n$1-\\delta$. This matrix can be applied to tensors $x^{(1)}\\otimes\\dots\\otimes\nx^{(c)}\\in R^{d^c}$ in $O(c\\, m \\min\\{d,m\\})$ time -- hence the name \"Tensor\nSketch\". (Here $x\\otimes y = \\text{asvec}(xy^T) = [x_1y_1,\nx_1y_2,\\dots,x_1y_m,x_2y_1,\\dots,x_ny_m]\\in R^{nm}$.)\n  This improves upon earlier Tensor Sketch constructions by Pagh and Pham~[TOCT\n2013, SIGKDD 2013] and Avron et al.~[NIPS 2014] which require\n$m=\\Omega(3^c\\lambda^2\\delta^{-1})$ rows for the same guarantees. The factors\nof $\\lambda$, $\\varepsilon^{-2}$ and $\\log1/\\delta$ can all be shown to be\nnecessary making our sketch optimal up to log factors.\n  With another construction we get $\\lambda$ times more rows $m=\\tilde\nO(c\\,\\lambda^2\\,\\varepsilon^{-2}(\\log1/\\delta)^3)$, but the matrix can be\napplied to any vector $x^{(1)}\\otimes\\dots\\otimes x^{(c)}\\in R^{d^c}$ in just\n$\\tilde O(c\\, (d+m))$ time. This matches the application time of Tensor Sketch\nwhile still improving the exponential dependencies in $c$ and $\\log1/\\delta$.\n  Technically, we show two main lemmas: (1) For many Johnson Lindenstrauss (JL)\nconstructions, if $Q,Q'\\in R^{m\\times d}$ are independent JL matrices, the\nelement-wise product $Qx \\circ Q'y$ equals $M(x\\otimes y)$ for some $M\\in\nR^{m\\times d^2}$ which is itself a JL matrix. (2) If $M^{(i)}\\in R^{m\\times\nmd}$ are independent JL matrices, then $M^{(1)}(x \\otimes (M^{(2)}y \\otimes\n\\dots)) = M(x\\otimes y\\otimes \\dots)$ for some $M\\in R^{m\\times d^c}$ which is\nitself a JL matrix. Combining these two results give an efficient sketch for\ntensors of any size.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 08:56:59 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ahle", "Thomas D.", ""], ["Knudsen", "Jakob B. T.", ""]]}, {"id": "1909.01838", "submitter": "Matthew Jagielski", "authors": "Matthew Jagielski, Nicholas Carlini, David Berthelot, Alex Kurakin,\n  Nicolas Papernot", "title": "High Accuracy and High Fidelity Extraction of Neural Networks", "comments": "USENIX Security 2020, 18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a model extraction attack, an adversary steals a copy of a remotely\ndeployed machine learning model, given oracle prediction access. We taxonomize\nmodel extraction attacks around two objectives: *accuracy*, i.e., performing\nwell on the underlying learning task, and *fidelity*, i.e., matching the\npredictions of the remote victim classifier on any input.\n  To extract a high-accuracy model, we develop a learning-based attack\nexploiting the victim to supervise the training of an extracted model. Through\nanalytical and empirical arguments, we then explain the inherent limitations\nthat prevent any learning-based strategy from extracting a truly high-fidelity\nmodel---i.e., extracting a functionally-equivalent model whose predictions are\nidentical to those of the victim model on all possible inputs. Addressing these\nlimitations, we expand on prior work to develop the first practical\nfunctionally-equivalent extraction attack for direct extraction (i.e., without\ntraining) of a model's weights.\n  We perform experiments both on academic datasets and a state-of-the-art image\nclassifier trained with 1 billion proprietary images. In addition to broadening\nthe scope of model extraction research, our work demonstrates the practicality\nof model extraction attacks against production-grade systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:33:09 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:08:02 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Jagielski", "Matthew", ""], ["Carlini", "Nicholas", ""], ["Berthelot", "David", ""], ["Kurakin", "Alex", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1909.01839", "submitter": "Prashnna Gyawali", "authors": "Prashnna Kumar Gyawali, Zhiyuan Li, Cameron Knight, Sandesh Ghimire,\n  B. Milan Horacek, John Sapp and Linwei Wang", "title": "Improving Disentangled Representation Learning with the Beta Bernoulli\n  Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To improve the ability of VAE to disentangle in the latent space, existing\nworks mostly focus on enforcing independence among the learned latent factors.\nHowever, the ability of these models to disentangle often decreases as the\ncomplexity of the generative factors increases. In this paper, we investigate\nthe little-explored effect of the modeling capacity of a posterior density on\nthe disentangling ability of the VAE. We note that the independence within and\nthe complexity of the latent density are two different properties we constrain\nwhen regularizing the posterior density: while the former promotes the\ndisentangling ability of VAE, the latter -- if overly limited -- creates an\nunnecessary competition with the data reconstruction objective in VAE.\nTherefore, if we preserve the independence but allow richer modeling capacity\nin the posterior density, we will lift this competition and thereby allow\nimproved independence and data reconstruction at the same time. We investigate\nthis theoretical intuition with a VAE that utilizes a non-parametric latent\nfactor model, the Indian Buffet Process (IBP), as a latent density that is able\nto grow with the complexity of the data. Across three widely-used benchmark\ndata sets and two clinical data sets little explored for disentangled learning,\nwe qualitatively and quantitatively demonstrated the improved disentangling\nperformance of IBP-VAE over the state of the art. In the latter two clinical\ndata sets riddled with complex factors of variations, we further demonstrated\nthat unsupervised disentangling of nuisance factors via IBP-VAE -- when\ncombined with a supervised objective -- can not only improve task accuracy in\ncomparison to relevant supervised deep architectures but also facilitate\nknowledge discovery related to task decision-making. A shorter version of this\nwork will appear in the ICDM 2019 conference proceedings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:25:25 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Gyawali", "Prashnna Kumar", ""], ["Li", "Zhiyuan", ""], ["Knight", "Cameron", ""], ["Ghimire", "Sandesh", ""], ["Horacek", "B. Milan", ""], ["Sapp", "John", ""], ["Wang", "Linwei", ""]]}, {"id": "1909.01844", "submitter": "Carl Jidling", "authors": "Carl Jidling, Johannes Hendriks, Thomas B. Sch\\\"on, Adrian Wills", "title": "Deep kernel learning for integral measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep kernel learning refers to a Gaussian process that incorporates neural\nnetworks to improve the modelling of complex functions. We present a method\nthat makes this approach feasible for problems where the data consists of line\nintegral measurements of the target function. The performance is illustrated on\ncomputed tomography reconstruction examples.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 14:42:07 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Jidling", "Carl", ""], ["Hendriks", "Johannes", ""], ["Sch\u00f6n", "Thomas B.", ""], ["Wills", "Adrian", ""]]}, {"id": "1909.01866", "submitter": "Jindong Gu", "authors": "Jindong Gu, Daniela Oelke", "title": "Understanding Bias in Machine Learning", "comments": null, "journal-ref": "1st Workshop on Visualization for AI Explainability in 2018 IEEE\n  Vis", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 20:36:19 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Gu", "Jindong", ""], ["Oelke", "Daniela", ""]]}, {"id": "1909.01868", "submitter": "Ashutosh Tiwari Mr", "authors": "Ashutosh Tiwari, Avadh Bihari Narayan, Onkar Dikshit", "title": "Deep learning networks for selection of persistent scatterer pixels in\n  multi-temporal SAR interferometric processing", "comments": "10015 words, 11 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-temporal SAR interferometry (MT-InSAR), persistent scatterer (PS)\npixels are used to estimate geophysical parameters, essentially deformation.\nConventionally, PS pixels are selected on the basis of the estimated noise\npresent in the spatially uncorrelated phase component along with look-angle\nerror in a temporal interferometric stack. In this study, two deep learning\narchitectures, namely convolutional neural network for interferometric semantic\nsegmentation (CNN-ISS) and convolutional long short term memory network for\ninterferometric semantic segmentation (CLSTM-ISS), based on learning spatial\nand spatio-temporal behaviour respectively, were proposed for selection of PS\npixels. These networks were trained to relate the interferometric phase history\nto its classification into phase stable (PS) and phase unstable (non-PS)\nmeasurement pixels using ~10,000 real world interferometric images of different\nstudy sites containing man-made objects, forests, vegetation, uncropped land,\nwater bodies, and areas affected by lengthening, foreshortening, layover and\nshadowing. The networks were trained using training labels obtained from the\nStanford method for Persistent Scatterer Interferometry (StaMPS) algorithm.\nHowever, pixel selection results, when compared to a combination of R-index and\na classified image of the test dataset, reveal that CLSTM-ISS estimates\nimproved the classification of PS and non-PS pixels compared to those of StaMPS\nand CNN-ISS. The predicted results show that CLSTM-ISS reached an accuracy of\n93.50%, higher than that of CNN-ISS (89.21%). CLSTM-ISS also improved the\ndensity of reliable PS pixels compared to StaMPS and CNN-ISS and outperformed\nStaMPS and other conventional MT-InSAR methods in terms of computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:17:34 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 08:13:29 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 13:27:45 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Tiwari", "Ashutosh", ""], ["Narayan", "Avadh Bihari", ""], ["Dikshit", "Onkar", ""]]}, {"id": "1909.01869", "submitter": "Jay Budzik", "authors": "John Merrill, Geoff Ward, Sean Kamkar, Jay Budzik and Douglas Merrill", "title": "Generalized Integrated Gradients: A practical method for explaining\n  diverse ensembles", "comments": "38 pages, submitted to JMLR 9/3/2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Generalized Integrated Gradients (GIG), a formal extension of\nthe Integrated Gradients (IG) (Sundararajan et al., 2017) method for\nattributing credit to the input variables of a predictive model. GIG improves\nIG by explaining a broader variety of functions that arise from practical\napplications of ML in domains like financial services. GIG is constructed to\novercome limitations of Shapley (1953) and Aumann-Shapley (1974), and has\ndesirable properties when compared to other approaches. We prove GIG is the\nonly correct method, under a small set of reasonable axioms, for providing\nexplanations for mixed-type models or games. We describe the implementation,\nand present results of experiments on several datasets and systems of models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:17:37 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 19:57:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Merrill", "John", ""], ["Ward", "Geoff", ""], ["Kamkar", "Sean", ""], ["Budzik", "Jay", ""], ["Merrill", "Douglas", ""]]}, {"id": "1909.01887", "submitter": "Davide Barbieri", "authors": "Davide Barbieri, Carlos Cabrelli, Eugenio Hern\\'andez, Ursula Molter", "title": "Optimal translational-rotational invariant dictionaries for images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.NA math.FA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the construction of a set of square matrices whose translates and\nrotates provide a Parseval frame that is optimal for approximating a given\ndataset of images. Our approach is based on abstract harmonic analysis\ntechniques. Optimality is considered with respect to the quadratic error of\napproximation of the images in the dataset with their projection onto a linear\nsubspace that is invariant under translations and rotations. In addition, we\nprovide an elementary and fully self-contained proof of optimality, and the\nnumerical results from datasets of natural images.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:34:04 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Barbieri", "Davide", ""], ["Cabrelli", "Carlos", ""], ["Hern\u00e1ndez", "Eugenio", ""], ["Molter", "Ursula", ""]]}, {"id": "1909.01931", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Csaba Szepesv\\'ari", "title": "Efron-Stein PAC-Bayesian Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove semi-empirical concentration inequalities for random variables which\nare given as possibly nonlinear functions of independent random variables.\nThese inequalities describe concentration of random variable in terms of the\ndata/distribution-dependent Efron-Stein (ES) estimate of its variance and they\ndo not require any additional assumptions on the moments. In particular, this\nallows us to state semi-empirical Bernstein type inequalities for general\nfunctions of unbounded random variables, which gives user-friendly\nconcentration bounds for cases where related methods (e.g. bounded differences)\nmight be more challenging to apply. We extend these results to Efron-Stein\nPAC-Bayesian inequalities which hold for arbitrary probability kernels that\ndefine a random, data-dependent choice of the function of interest. Finally, we\ndemonstrate a number of applications, including PAC-Bayesian generalization\nbounds for unbounded loss functions, empirical Bernstein type generalization\nbounds, new truncation-free bounds for off-policy evaluation with Weighted\nImportance Sampling (WIS), and off-policy PAC-Bayesian learning with WIS.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 16:36:46 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 14:48:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1909.01936", "submitter": "Jarrod Olson", "authors": "Jarrod Olson and Po-Hsu Allen Chen and Marissa White and Nicole\n  Brennan and Ning Gong", "title": "State Drug Policy Effectiveness: Comparative Policy Analysis of Drug\n  Overdose Mortality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opioid overdose rates have reached an epidemic level and state-level policy\ninnovations have followed suit in an effort to prevent overdose deaths.\nState-level drug law is a set of policies that may reinforce or undermine each\nother, and analysts have a limited set of tools for handling the policy\ncollinearity using statistical methods. This paper uses a machine learning\nmethod called hierarchical clustering to empirically generate \"policy bundles\"\nby grouping states with similar sets of policies in force at a given time\ntogether for analysis in a 50-state, 10-year interrupted time series regression\nwith drug overdose deaths as the dependent variable. Policy clusters were\ngenerated from 138 binomial variables observed by state and year from the\nPrescription Drug Abuse Policy System. Clustering reduced the policies to a set\nof 10 bundles. The approach allows for ranking of the relative effect of\ndifferent bundles and is a tool to recommend those most likely to succeed. This\nstudy shows that a set of policies balancing Medication Assisted Treatment,\nNaloxone Access, Good Samaritan Laws, Medication Assisted Treatment,\nPrescription Drug Monitoring Programs and legalization of medical marijuana\nleads to a reduced number of overdose deaths, but not until its second year in\nforce.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:41:44 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 21:17:58 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 23:14:09 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Olson", "Jarrod", ""], ["Chen", "Po-Hsu Allen", ""], ["White", "Marissa", ""], ["Brennan", "Nicole", ""], ["Gong", "Ning", ""]]}, {"id": "1909.01940", "submitter": "Eduardo Pooch", "authors": "Eduardo H. P. Pooch, Pedro L. Ballester, Rodrigo C. Barros", "title": "Can we trust deep learning models diagnosis? The impact of domain shift\n  in chest radiograph classification", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning models become more widespread, their ability to handle\nunseen data and generalize for any scenario is yet to be challenged. In medical\nimaging, there is a high heterogeneity of distributions among images based on\nthe equipment that generates them and their parametrization. This heterogeneity\ntriggers a common issue in machine learning called domain shift, which\nrepresents the difference between the training data distribution and the\ndistribution of where a model is employed. A high domain shift tends to\nimplicate in a poor generalization performance from the models. In this work,\nwe evaluate the extent of domain shift on four of the largest datasets of chest\nradiographs. We show how training and testing with different datasets (e.g.,\ntraining in ChestX-ray14 and testing in CheXpert) drastically affects model\nperformance, posing a big question over the reliability of deep learning models\ntrained on public datasets. We also show that models trained on CheXpert and\nMIMIC-CXR generalize better to other datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:03:55 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:50:10 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Pooch", "Eduardo H. P.", ""], ["Ballester", "Pedro L.", ""], ["Barros", "Rodrigo C.", ""]]}, {"id": "1909.01954", "submitter": "Alessandro Lameiras Koerich", "authors": "Bernardo B. Gatto, Eulanda M. dos Santos, Alessandro L. Koerich,\n  Kazuhiro Fukui, Waldir S. S. Junior", "title": "Tensor Analysis with n-Mode Generalized Difference Subspace", "comments": "Submitted to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of multiple sensors, which produce a large amount of\nmulti-dimensional data, requires efficient representation and classification\nmethods. In this paper, we present a new method for multi-dimensional data\nclassification that relies on two premises: 1) multi-dimensional data are\nusually represented by tensors, since this brings benefits from multilinear\nalgebra and established tensor factorization methods; and 2) multilinear data\ncan be described by a subspace of a vector space. The subspace representation\nhas been employed for pattern-set recognition, and its tensor representation\ncounterpart is also available in the literature. However, traditional methods\ndo not use discriminative information of the tensors, degrading the\nclassification accuracy. In this case, generalized difference subspace (GDS)\nprovides an enhanced subspace representation by reducing data redundancy and\nrevealing discriminative structures. Since GDS does not handle tensor data, we\npropose a new projection called n-mode GDS, which efficiently handles tensor\ndata. We also introduce the n-mode Fisher score as a class separability index\nand an improved metric based on the geodesic distance for tensor data\nsimilarity. The experimental results on gesture and action recognition show\nthat the proposed method outperforms methods commonly used in the literature\nwithout relying on pre-trained models or transfer learning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:26:54 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 17:41:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Gatto", "Bernardo B.", ""], ["Santos", "Eulanda M. dos", ""], ["Koerich", "Alessandro L.", ""], ["Fukui", "Kazuhiro", ""], ["Junior", "Waldir S. S.", ""]]}, {"id": "1909.01960", "submitter": "Kristofer Schlachter", "authors": "Kristofer Schlachter, Connor DeFanti, Sebastian Herscher, Ken Perlin,\n  Jonathan Tompson", "title": "Beyond Photo Realism for Domain Adaptation from Synthetic Data", "comments": "Originally submitted for publication in November 2017", "journal-ref": null, "doi": null, "report-no": "01", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As synthetic imagery is used more frequently in training deep models, it is\nimportant to understand how different synthesis techniques impact the\nperformance of such models. In this work, we perform a thorough evaluation of\nthe effectiveness of several different synthesis techniques and their impact on\nthe complexity of classifier domain adaptation to the \"real\" underlying data\ndistribution that they seek to replicate. In addition, we propose a novel\nlearned synthesis technique to better train classifier models than\nstate-of-the-art offline graphical methods, while using significantly less\ncomputational resources. We accomplish this by learning a generative model to\nperform shading of synthetic geometry conditioned on a \"g-buffer\"\nrepresentation of the scene to render, as well as a low sample Monte Carlo\nrendered image. The major contributions are (i) a dataset that allows\ncomparison of real and synthetic versions of the same scene, (ii) an augmented\ndata representation that boosts the stability of learning and improves the\ndatasets accuracy, (iii) three different partially differentiable rendering\ntechniques where lighting, denoising and shading are learned, and (iv) we\nimprove a state of the art generative adversarial network (GAN) approach by\nusing an ensemble of trained models to generate datasets that approach the\nperformance of training on real data and surpass the performance of the full\nglobal illumination rendering.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:38:05 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Schlachter", "Kristofer", ""], ["DeFanti", "Connor", ""], ["Herscher", "Sebastian", ""], ["Perlin", "Ken", ""], ["Tompson", "Jonathan", ""]]}, {"id": "1909.01961", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "A Constructive Approach for Data-Driven Randomized Learning of\n  Feedforward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward neural networks with random hidden nodes suffer from a problem\nwith the generation of random weights and biases as these are difficult to set\noptimally to obtain a good projection space. Typically, random parameters are\ndrawn from an interval which is fixed before or adapted during the learning\nprocess. Due to the different functions of the weights and biases, selecting\nthem both from the same interval is not a good idea. Recently more\nsophisticated methods of random parameters generation have been developed, such\nas the data-driven method proposed in \\cite{Anon19}, where the sigmoids are\nplaced in randomly selected regions of the input space and then their slopes\nare adjusted to the local fluctuations of the target function. In this work, we\npropose an extended version of this method, which constructs iteratively the\nnetwork architecture. This method successively generates new hidden nodes and\naccepts them if the training error decreases significantly. The threshold of\nacceptance is adapted to the current training stage. At the beginning of the\ntraining process only those nodes which lead to the largest error reduction are\naccepted. Then, the threshold is reduced by half to accept those nodes which\nmodel the target function details more accurately. This leads to faster\nconvergence and more compact network architecture, as it includes only\n\"significant\" neurons. Several application examples are given which confirm\nthis thesis.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:38:13 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 12:08:02 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1909.01978", "submitter": "Arash Ali Amini", "authors": "Arash A. Amini, Bryon Aragam and Qing Zhou", "title": "On perfectness in Gaussian graphical models", "comments": "This note is based on a result that first appeared in\n  arXiv:1711.00991v1. The original article has now been split into two parts", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing when a graphical model is perfect to a distribution is essential in\norder to relate separation in the graph to conditional independence in the\ndistribution, and this is particularly important when performing inference from\ndata. When the model is perfect, there is a one-to-one correspondence between\nconditional independence statements in the distribution and separation\nstatements in the graph. Previous work has shown that almost all models based\non linear directed acyclic graphs as well as Gaussian chain graphs are perfect,\nthe latter of which subsumes Gaussian graphical models (i.e., the undirected\nGaussian models) as a special case. However, the complexity of chain graph\nmodels leads to a proof of this result which is indirect and mired by the\ncomplications of parameterizing this general class. In this paper, we directly\napproach the problem of perfectness for the Gaussian graphical models, and\nprovide a new proof, via a more transparent parametrization, that almost all\nsuch models are perfect. Our approach is based on, and substantially extends, a\nconstruction of Ln\\v{e}ni\\v{c}ka and Mat\\'u\\v{s} showing the existence of a\nperfect Gaussian distribution for any graph.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 19:17:23 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Amini", "Arash A.", ""], ["Aragam", "Bryon", ""], ["Zhou", "Qing", ""]]}, {"id": "1909.01994", "submitter": "Jacob Rafati", "authors": "Jacob Rafati and Roummel F. Marcia", "title": "Quasi-Newton Optimization Methods For Deep Learning Applications", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.02693", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms often require solving a highly non-linear and\nnonconvex unconstrained optimization problem. Methods for solving optimization\nproblems in large-scale machine learning, such as deep learning and deep\nreinforcement learning (RL), are generally restricted to the class of\nfirst-order algorithms, like stochastic gradient descent (SGD). While SGD\niterates are inexpensive to compute, they have slow theoretical convergence\nrates. Furthermore, they require exhaustive trial-and-error to fine-tune many\nlearning parameters. Using second-order curvature information to find search\ndirections can help with more robust convergence for non-convex optimization\nproblems. However, computing Hessian matrices for large-scale problems is not\ncomputationally practical. Alternatively, quasi-Newton methods construct an\napproximate of the Hessian matrix to build a quadratic model of the objective\nfunction. Quasi-Newton methods, like SGD, require only first-order gradient\ninformation, but they can result in superlinear convergence, which makes them\nattractive alternatives to SGD. The limited-memory\nBroyden-Fletcher-Goldfarb-Shanno (L-BFGS) approach is one of the most popular\nquasi-Newton methods that construct positive definite Hessian approximations.\nIn this chapter, we propose efficient optimization methods based on L-BFGS\nquasi-Newton methods using line search and trust-region strategies. Our methods\nbridge the disparity between first- and second-order methods by using gradient\ninformation to calculate low-rank updates to Hessian approximations. We provide\nformal convergence analysis of these methods as well as empirical results on\ndeep learning applications, such as image classification tasks and deep\nreinforcement learning on a set of ATARI 2600 video games. Our results show a\nrobust convergence with preferred generalization characteristics as well as\nfast training time.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:52:08 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Rafati", "Jacob", ""], ["Marcia", "Roummel F.", ""]]}, {"id": "1909.02005", "submitter": "Siddharth Mishra-Sharma", "authors": "Johann Brehmer, Siddharth Mishra-Sharma, Joeri Hermans, Gilles Louppe,\n  and Kyle Cranmer", "title": "Mining for Dark Matter Substructure: Inferring subhalo population\n  properties from strong lenses with machine learning", "comments": "23 pages, 6 figures, code available at\n  https://github.com/smsharma/mining-for-substructure-lens; v2, minor changes\n  to text, version accepted in ApJ", "journal-ref": "The Astrophysical Journal, Volume 886, Issue 1, article id. 49, 16\n  pp. (2019)", "doi": "10.3847/1538-4357/ab4c41", "report-no": null, "categories": "astro-ph.CO astro-ph.HE astro-ph.IM hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subtle and unique imprint of dark matter substructure on extended arcs in\nstrong lensing systems contains a wealth of information about the properties\nand distribution of dark matter on small scales and, consequently, about the\nunderlying particle physics. However, teasing out this effect poses a\nsignificant challenge since the likelihood function for realistic simulations\nof population-level parameters is intractable. We apply recently-developed\nsimulation-based inference techniques to the problem of substructure inference\nin galaxy-galaxy strong lenses. By leveraging additional information extracted\nfrom the simulator, neural networks are efficiently trained to estimate\nlikelihood ratios associated with population-level parameters characterizing\nsubstructure. Through proof-of-principle application to simulated data, we show\nthat these methods can provide an efficient and principled way to\nsimultaneously analyze an ensemble of strong lenses, and can be used to mine\nthe large sample of lensing images deliverable by near-future surveys for\nsignatures of dark matter substructure.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 18:00:00 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 20:22:14 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Brehmer", "Johann", ""], ["Mishra-Sharma", "Siddharth", ""], ["Hermans", "Joeri", ""], ["Louppe", "Gilles", ""], ["Cranmer", "Kyle", ""]]}, {"id": "1909.02060", "submitter": "Tatsunori Hashimoto", "authors": "Yonatan Oren, Shiori Sagawa, Tatsunori B. Hashimoto, Percy Liang", "title": "Distributionally Robust Language Modeling", "comments": "Camera ready version for EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are generally trained on data spanning a wide range of topics\n(e.g., news, reviews, fiction), but they might be applied to an a priori\nunknown target distribution (e.g., restaurant reviews). In this paper, we first\nshow that training on text outside the test distribution can degrade test\nperformance when using standard maximum likelihood (MLE) training. To remedy\nthis without the knowledge of the test distribution, we propose an approach\nwhich trains a model that performs well over a wide range of potential test\ndistributions. In particular, we derive a new distributionally robust\noptimization (DRO) procedure which minimizes the loss of the model over the\nworst-case mixture of topics with sufficient overlap with the training\ndistribution. Our approach, called topic conditional value at risk (topic\nCVaR), obtains a 5.5 point perplexity reduction over MLE when the language\nmodels are trained on a mixture of Yelp reviews and news and tested only on\nreviews.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:07:33 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Oren", "Yonatan", ""], ["Sagawa", "Shiori", ""], ["Hashimoto", "Tatsunori B.", ""], ["Liang", "Percy", ""]]}, {"id": "1909.02062", "submitter": "Basel Alyafi", "authors": "Basel Alyafi, Oliver Diaz, Robert Marti", "title": "DCGANs for Realistic Breast Mass Augmentation in X-ray Mammography", "comments": "4 pages, 4 figures, SPIE Medical Imaging 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of breast cancer has a major contribution to curability, and\nusing mammographic images, this can be achieved non-invasively. Supervised deep\nlearning, the dominant CADe tool currently, has played a great role in object\ndetection in computer vision, but it suffers from a limiting property: the need\nof a large amount of labelled data. This becomes stricter when it comes to\nmedical datasets which require high-cost and time-consuming annotations.\nFurthermore, medical datasets are usually imbalanced, a condition that often\nhinders classifiers performance. The aim of this paper is to learn the\ndistribution of the minority class to synthesise new samples in order to\nimprove lesion detection in mammography. Deep Convolutional Generative\nAdversarial Networks (DCGANs) can efficiently generate breast masses. They are\ntrained on increasing-size subsets of one mammographic dataset and used to\ngenerate diverse and realistic breast masses. The effect of including the\ngenerated images and/or applying horizontal and vertical flipping is tested in\nan environment where a 1:10 imbalanced dataset of masses and normal tissue\npatches is classified by a fully-convolutional network. A maximum of ~ 0:09\nimprovement of F1 score is reported by using DCGANs along with flipping\naugmentation over using the original images. We show that DCGANs can be used\nfor synthesising photo-realistic breast mass patches with considerable\ndiversity. It is demonstrated that appending synthetic images in this\nenvironment, along with flipping, outperforms the traditional augmentation\nmethod of flipping solely, offering faster improvements as a function of the\ntraining set size.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:09:49 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Alyafi", "Basel", ""], ["Diaz", "Oliver", ""], ["Marti", "Robert", ""]]}, {"id": "1909.02063", "submitter": "Bas Hofstra", "authors": "Bas Hofstra, Vivek V. Kulkarni, Sebastian Munoz-Najar Galvez, Bryan\n  He, Dan Jurafsky, Daniel A. McFarland", "title": "The Diversity-Innovation Paradox in Science", "comments": "Updated paper; tightened up terminology, added better theoretical\n  explanation, tested for a mechanism in the updated paper, added robustness\n  analyses, updated and improved metrics across the board", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Prior work finds a diversity paradox: diversity breeds innovation, and yet,\nunderrepresented groups that diversify organizations have less successful\ncareers within them. Does the diversity paradox hold for scientists as well? We\nstudy this by utilizing a near-population of ~1.2 million US doctoral\nrecipients from 1977-2015 and following their careers into publishing and\nfaculty positions. We use text analysis and machine learning to answer a series\nof questions: How do we detect scientific innovations? Are underrepresented\ngroups more likely to generate scientific innovations? And are the innovations\nof underrepresented groups adopted and rewarded? Our analyses show that\nunderrepresented groups produce higher rates of scientific novelty. However,\ntheir novel contributions are devalued and discounted: e.g., novel\ncontributions by gender and racial minorities are taken up by other scholars at\nlower rates than novel contributions by gender and racial majorities, and\nequally impactful contributions of gender and racial minorities are less likely\nto result in successful scientific careers than for majority groups. These\nresults suggest there may be unwarranted reproduction of stratification in\nacademic careers that discounts diversity's role in innovation and partly\nexplains the underrepresentation of some groups in academia.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:10:20 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 02:31:51 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hofstra", "Bas", ""], ["Kulkarni", "Vivek V.", ""], ["Galvez", "Sebastian Munoz-Najar", ""], ["He", "Bryan", ""], ["Jurafsky", "Dan", ""], ["McFarland", "Daniel A.", ""]]}, {"id": "1909.02088", "submitter": "Rohit Patra", "authors": "Arun K. Kuchibhotla and Rohit K. Patra", "title": "On Least Squares Estimation under Heteroscedastic and Heavy-Tailed\n  Errors", "comments": "49 pages, 2 figures, and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider least squares estimation in a general nonparametric regression\nmodel. The rate of convergence of the least squares estimator (LSE) for the\nunknown regression function is well studied when the errors are sub-Gaussian.\nWe find upper bounds on the rates of convergence of the LSE when the errors\nhave uniformly bounded conditional variance and have only finitely many\nmoments. We show that the interplay between the moment assumptions on the\nerror, the metric entropy of the class of functions involved, and the \"local\"\nstructure of the function class around the truth drives the rate of convergence\nof the LSE. We find sufficient conditions on the errors under which the rate of\nthe LSE matches the rate of the LSE under sub-Gaussian error. Our results are\nfinite sample and allow for heteroscedastic and heavy-tailed errors.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:21:02 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 16:58:51 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 22:02:42 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Kuchibhotla", "Arun K.", ""], ["Patra", "Rohit K.", ""]]}, {"id": "1909.02093", "submitter": "John Halloran", "authors": "John T. Halloran and David M. Rocke", "title": "Gradients of Generative Models for Improved Discriminative Analysis of\n  Tandem Mass Spectra", "comments": "13 pages. A partitioned version of this appeared in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tandem mass spectrometry (MS/MS) is a high-throughput technology used\ntoidentify the proteins in a complex biological sample, such as a drop of\nblood. A collection of spectra is generated at the output of the process, each\nspectrum of which is representative of a peptide (protein subsequence) present\nin the original complex sample. In this work, we leverage the log-likelihood\ngradients of generative models to improve the identification of such spectra.\nIn particular, we show that the gradient of a recently proposed dynamic\nBayesian network (DBN) may be naturally employed by a kernel-based\ndiscriminative classifier. The resulting Fisher kernel substantially improves\nupon recent attempts to combine generative and discriminative models for\npost-processing analysis, outperforming all other methods on the evaluated\ndatasets. We extend the improved accuracy offered by the Fisher kernel\nframework to other search algorithms by introducing Theseus, a DBN representing\na large number of widely used MS/MS scoring functions. Furthermore, with\ngradient ascent and max-product inference at hand, we use Theseus to learn\nmodel parameters without any supervision.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:29:04 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Halloran", "John T.", ""], ["Rocke", "David M.", ""]]}, {"id": "1909.02102", "submitter": "Yifei Wang", "authors": "Yifei Wang and Wuchen Li", "title": "Accelerated Information Gradient flow", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for Nesterov's accelerated gradient flows in\nprobability space. Here four examples of information metrics are considered,\nincluding Fisher-Rao metric, Wasserstein-2 metric, Kalman-Wasserstein metric\nand Stein metric. For both Fisher-Rao and Wasserstein-2 metrics, we prove\nconvergence properties of accelerated gradient flows. In implementations, we\npropose a sampling-efficient discrete-time algorithm for Wasserstein-2,\nKalman-Wasserstein and Stein accelerated gradient flows with a restart\ntechnique. We also formulate a kernel bandwidth selection method, which learns\nthe gradient of logarithm of density from Brownian-motion samples. Numerical\nexperiments, including Bayesian logistic regression and Bayesian neural\nnetwork, show the strength of the proposed methods compared with\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:43:21 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 03:30:39 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Wang", "Yifei", ""], ["Li", "Wuchen", ""]]}, {"id": "1909.02105", "submitter": "Yujia Xie", "authors": "Yujia Xie, Haoming Jiang, Feng Liu, Tuo Zhao, Hongyuan Zha", "title": "Meta Learning with Relational Information for Short Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new meta-learning method -- named HARMLESS (HAwkes\nRelational Meta LEarning method for Short Sequences) for learning heterogeneous\npoint process models from short event sequence data along with a relational\nnetwork. Specifically, we propose a hierarchical Bayesian mixture Hawkes\nprocess model, which naturally incorporates the relational information among\nsequences into point process modeling. Compared with existing methods, our\nmodel can capture the underlying mixed-community patterns of the relational\nnetwork, which simultaneously encourages knowledge sharing among sequences and\nfacilitates adaptive learning for each individual sequence. We further propose\nan efficient stochastic variational meta expectation maximization algorithm\nthat can scale to large problems. Numerical experiments on both synthetic and\nreal data show that HARMLESS outperforms existing methods in terms of\npredicting the future events.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:45:42 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Xie", "Yujia", ""], ["Jiang", "Haoming", ""], ["Liu", "Feng", ""], ["Zhao", "Tuo", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1909.02107", "submitter": "Hao-Jun Shi", "authors": "Hao-Jun Michael Shi, Dheevatsa Mudigere, Maxim Naumov, and Jiyan Yang", "title": "Compositional Embeddings Using Complementary Partitions for\n  Memory-Efficient Recommendation Systems", "comments": "11 pages, 7 figures, 1 table", "journal-ref": null, "doi": "10.1145/3394486.3403059", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning-based recommendation systems exploit hundreds to\nthousands of different categorical features, each with millions of different\ncategories ranging from clicks to posts. To respect the natural diversity\nwithin the categorical data, embeddings map each category to a unique dense\nrepresentation within an embedded space. Since each categorical feature could\ntake on as many as tens of millions of different possible categories, the\nembedding tables form the primary memory bottleneck during both training and\ninference. We propose a novel approach for reducing the embedding size in an\nend-to-end fashion by exploiting complementary partitions of the category set\nto produce a unique embedding vector for each category without explicit\ndefinition. By storing multiple smaller embedding tables based on each\ncomplementary partition and combining embeddings from each table, we define a\nunique embedding for each category at smaller memory cost. This approach may be\ninterpreted as using a specific fixed codebook to ensure uniqueness of each\ncategory's representation. Our experimental results demonstrate the\neffectiveness of our approach over the hashing trick for reducing the size of\nthe embedding tables in terms of model loss and accuracy, while retaining a\nsimilar reduction in the number of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:47:08 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 04:10:00 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Shi", "Hao-Jun Michael", ""], ["Mudigere", "Dheevatsa", ""], ["Naumov", "Maxim", ""], ["Yang", "Jiyan", ""]]}, {"id": "1909.02108", "submitter": "James Stokes", "authors": "James Stokes, Josh Izaac, Nathan Killoran, Giuseppe Carleo", "title": "Quantum Natural Gradient", "comments": "15 pages, 4 figures", "journal-ref": "Quantum 4, 269 (2020)", "doi": "10.22331/q-2020-05-25-269", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A quantum generalization of Natural Gradient Descent is presented as part of\na general-purpose optimization framework for variational quantum circuits. The\noptimization dynamics is interpreted as moving in the steepest descent\ndirection with respect to the Quantum Information Geometry, corresponding to\nthe real part of the Quantum Geometric Tensor (QGT), also known as the\nFubini-Study metric tensor. An efficient algorithm is presented for computing a\nblock-diagonal approximation to the Fubini-Study metric tensor for parametrized\nquantum circuits, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:52:32 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 16:04:25 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 16:42:28 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Stokes", "James", ""], ["Izaac", "Josh", ""], ["Killoran", "Nathan", ""], ["Carleo", "Giuseppe", ""]]}, {"id": "1909.02109", "submitter": "Yingkai Li", "authors": "Yingkai Li, Edmund Y. Lou, Liren Shan", "title": "Stochastic Linear Optimization with Adversarial Corruption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the model of stochastic bandits with adversarial corruption\n(Lykouriset al., 2018) to the stochastic linear optimization problem (Dani et\nal., 2008). Our algorithm is agnostic to the amount of corruption chosen by the\nadaptive adversary. The regret of the algorithm only increases linearly in the\namount of corruption. Our algorithm involves using L\\\"owner-John's ellipsoid\nfor exploration and dividing time horizon into epochs with exponentially\nincreasing size to limit the influence of corruption.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:55:00 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Li", "Yingkai", ""], ["Lou", "Edmund Y.", ""], ["Shan", "Liren", ""]]}, {"id": "1909.02115", "submitter": "Ali Sharifara", "authors": "Razieh Tavakoli, Mohammad Najafi and Ali Sharifara", "title": "Artificial Neural Networks and Adaptive Neuro-fuzzy Models for\n  Prediction of Remaining Useful Life", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U.S. water distribution system contains thousands of miles of pipes\nconstructed from different materials, and of various sizes, and age. These\npipes suffer from physical, environmental, structural and operational stresses,\ncausing deterioration which eventually leads to their failure. Pipe\ndeterioration results in increased break rates, reduced hydraulic capacity, and\ndetrimental impacts on water quality. Therefore, it is crucial to use accurate\nmodels to forecast deterioration rates along with estimating the remaining\nuseful life of the pipes to implement essential interference plans in order to\nprevent catastrophic failures. This paper discusses a computational model that\nforecasts the RUL of water pipes by applying Artificial Neural Networks (ANNs)\nas well as Adaptive Neural Fuzzy Inference System (ANFIS). These models are\ntrained and tested acquired field data to identify the significant parameters\nthat impact the prediction of RUL. It is concluded that, on average, with\napproximately 10\\% of wall thickness loss in existing cast iron, ductile iron,\nasbestos-cement, and steel water pipes, the reduction of the remaining useful\nlife is approximately 50%\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 01:29:52 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Tavakoli", "Razieh", ""], ["Najafi", "Mohammad", ""], ["Sharifara", "Ali", ""]]}, {"id": "1909.02116", "submitter": "Jiayuan Mao", "authors": "Jiayuan Mao and Xiuming Zhang and Yikai Li and William T. Freeman and\n  Joshua B. Tenenbaum and Jiajun Wu", "title": "Program-Guided Image Manipulators", "comments": "ICCV 2019. First two authors contributed equally. Project page:\n  http://pgim.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of building holistic representations for images at various\nlevels, from local objects, to pairwise relations, to global structures. The\ninterpretation of structures involves reasoning over repetition and symmetry of\nthe objects in the image. In this paper, we present the Program-Guided Image\nManipulator (PG-IM), inducing neuro-symbolic program-like representations to\nrepresent and manipulate images. Given an image, PG-IM detects repeated\npatterns, induces symbolic programs, and manipulates the image using a neural\nnetwork that is guided by the program. PG-IM learns from a single image,\nexploiting its internal statistics. Despite trained only on image inpainting,\nPG-IM is directly capable of extrapolation and regularity editing in a unified\nframework. Extensive experiments show that PG-IM achieves superior performance\non all the tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:10:47 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Mao", "Jiayuan", ""], ["Zhang", "Xiuming", ""], ["Li", "Yikai", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1909.02136", "submitter": "John Halloran", "authors": "John T. Halloran and David M. Rocke", "title": "Learning Concave Conditional Likelihood Models for Improved Analysis of\n  Tandem Mass Spectra", "comments": "16 pages. A partitioned version of this appeared in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most widely used technology to identify the proteins present in a complex\nbiological sample is tandem mass spectrometry, which quickly produces a large\ncollection of spectra representative of the peptides (i.e., protein\nsubsequences) present in the original sample. In this work, we greatly expand\nthe parameter learning capabilities of a dynamic Bayesian network (DBN)\npeptide-scoring algorithm, Didea, by deriving emission distributions for which\nits conditional log-likelihood scoring function remains concave. We show that\nthis class of emission distributions, called Convex Virtual Emissions (CVEs),\nnaturally generalizes the log-sum-exp function while rendering both maximum\nlikelihood estimation and conditional maximum likelihood estimation concave for\na wide range of Bayesian networks. Utilizing CVEs in Didea allows efficient\nlearning of a large number of parameters while ensuring global convergence, in\nstark contrast to Didea's previous parameter learning framework (which could\nonly learn a single parameter using a costly grid search) and other trainable\nmodels (which only ensure convergence to local optima). The newly trained\nscoring function substantially outperforms the state-of-the-art in both scoring\nfunction accuracy and downstream Fisher kernel analysis. Furthermore, we\nsignificantly improve Didea's runtime performance through successive\noptimizations to its message passing schedule and derive explicit connections\nbetween Didea's new concave score and related MS/MS scoring functions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 22:27:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Halloran", "John T.", ""], ["Rocke", "David M.", ""]]}, {"id": "1909.02157", "submitter": "Richard Jiang", "authors": "Gary Storey, Ahmed Bouridane, Richard Jiang and Chang-tsun Li", "title": "Atypical Facial Landmark Localisation with Stacked Hourglass Networks: A\n  Study on 3D Facial Modelling for Medical Diagnosis", "comments": "In press, 2019", "journal-ref": "Deep Biometrics, Springer Book, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While facial biometrics has been widely used for identification purpose, it\nhas recently been researched as medical biometrics for a range of diseases. In\nthis chapter, we investigate the facial landmark detection for atypical 3D\nfacial modelling in facial palsy cases, while potentially such modelling can\nassist the medical diagnosis using atypical facial features. In our work, a\nstudy of landmarks localisation methods such as stacked hourglass networks is\nconducted and evaluated to ascertain their accuracy when presented with unseen\natypical faces. The evaluation highlights that the state-of-the-art stacked\nhourglass architecture outperforms other traditional methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 00:08:28 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Storey", "Gary", ""], ["Bouridane", "Ahmed", ""], ["Jiang", "Richard", ""], ["Li", "Chang-tsun", ""]]}, {"id": "1909.02180", "submitter": "Bo Wang", "authors": "Jiabin Liu, Bo Wang, Zhiquan Qi, Yingjie Tian, Yong Shi", "title": "Learning from Label Proportions with Generative Adversarial Networks", "comments": "Accepted as a conference paper at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we leverage generative adversarial networks (GANs) to derive\nan effective algorithm LLP-GAN for learning from label proportions (LLP), where\nonly the bag-level proportional information in labels is available. Endowed\nwith end-to-end structure, LLP-GAN performs approximation in the light of an\nadversarial learning mechanism, without imposing restricted assumptions on\ndistribution. Accordingly, we can directly induce the final instance-level\nclassifier upon the discriminator. Under mild assumptions, we give the explicit\ngenerative representation and prove the global optimality for LLP-GAN.\nAdditionally, compared with existing methods, our work empowers LLP solver with\ncapable scalability inheriting from deep models. Several experiments on\nbenchmark datasets demonstrate vivid advantages of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 01:55:35 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 06:44:27 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 04:43:15 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 09:01:27 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Liu", "Jiabin", ""], ["Wang", "Bo", ""], ["Qi", "Zhiquan", ""], ["Tian", "Yingjie", ""], ["Shi", "Yong", ""]]}, {"id": "1909.02182", "submitter": "Anne-Sophie Krah", "authors": "Anne-Sophie Krah, Zoran Nikoli\\'c, Ralf Korn", "title": "Machine Learning in Least-Squares Monte Carlo Proxy Modeling of Life\n  Insurance Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the Solvency II regime, life insurance companies are asked to derive\ntheir solvency capital requirements from the full loss distributions over the\ncoming year. Since the industry is currently far from being endowed with\nsufficient computational capacities to fully simulate these distributions, the\ninsurers have to rely on suitable approximation techniques such as the\nleast-squares Monte Carlo (LSMC) method. The key idea of LSMC is to run only a\nfew wisely selected simulations and to process their output further to obtain a\nrisk-dependent proxy function of the loss. In this paper, we present and\nanalyze various adaptive machine learning approaches that can take over the\nproxy modeling task. The studied approaches range from ordinary and generalized\nleast-squares regression variants over GLM and GAM methods to MARS and kernel\nregression routines. We justify the combinability of their regression\ningredients in a theoretical discourse. Further, we illustrate the approaches\nin slightly disguised real-world experiments and perform comprehensive\nout-of-sample tests.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 02:02:26 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Krah", "Anne-Sophie", ""], ["Nikoli\u0107", "Zoran", ""], ["Korn", "Ralf", ""]]}, {"id": "1909.02187", "submitter": "Shiyin Lu", "authors": "Shiyin Lu, Lijun Zhang", "title": "Adaptive and Efficient Algorithms for Tracking the Best Expert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of prediction with expert advice in\ndynamic environments. We choose tracking regret as the performance metric and\ndevelop two adaptive and efficient algorithms with data-dependent tracking\nregret bounds. The first algorithm achieves a second-order tracking regret\nbound, which improves existing first-order bounds. The second algorithm enjoys\na path-length bound, which is generally not comparable to the second-order\nbound but offers advantages in slowly moving environments. Both algorithms are\ndeveloped under the online mirror descent framework and draw inspiration from\nexisting algorithms that attain data-dependent bounds of static regret. The key\nidea is to use a clipped simplex in the updating step of online mirror descent.\nFinally, we extend our algorithms and analysis to online matrix prediction and\nprovide the first data-dependent tracking regret bound for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 02:22:24 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 07:49:32 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lu", "Shiyin", ""], ["Zhang", "Lijun", ""]]}, {"id": "1909.02190", "submitter": "Jiazhen Gu", "authors": "Jiazhen Gu, Huanlin Xu, Yangfan Zhou, Xin Wang, Hui Xu, Michael Lyu", "title": "Detecting Deep Neural Network Defects with Data Flow Analysis", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are shown to be promising solutions in many\nchallenging artificial intelligence tasks. However, it is very hard to figure\nout whether the low precision of a DNN model is an inevitable result, or caused\nby defects. This paper aims at addressing this challenging problem. We find\nthat the internal data flow footprints of a DNN model can provide insights to\nlocate the root cause effectively. We develop DeepMorph (DNN Tomography) to\nanalyze the root cause, which can guide a DNN developer to improve the model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 02:56:33 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:49:21 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gu", "Jiazhen", ""], ["Xu", "Huanlin", ""], ["Zhou", "Yangfan", ""], ["Wang", "Xin", ""], ["Xu", "Hui", ""], ["Lyu", "Michael", ""]]}, {"id": "1909.02251", "submitter": "Kei Takemura", "authors": "Kei Takemura and Shinji Ito", "title": "An Arm-Wise Randomization Approach to Combinatorial Linear Semi-Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial linear semi-bandits (CLS) are widely applicable frameworks of\nsequential decision-making, in which a learner chooses a subset of arms from a\ngiven set of arms associated with feature vectors. Existing algorithms work\npoorly for the clustered case, in which the feature vectors form several large\nclusters. This shortcoming is critical in practice because it can be found in\nmany applications, including recommender systems. In this paper, we clarify why\nsuch a shortcoming occurs, and we introduce a key technique of arm-wise\nrandomization to overcome it. We propose two algorithms with this technique:\nthe perturbed C${}^2$UCB (PC${}^2$UCB) and the Thompson sampling (TS). Our\nempirical evaluation with artificial and real-world datasets demonstrates that\nthe proposed algorithms with the arm-wise randomization technique outperform\nthe existing algorithms without this technique, especially for the clustered\ncase. Our contributions also include theoretical analyses that provide high\nprobability asymptotic regret bounds for our algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:04:08 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 11:40:42 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Takemura", "Kei", ""], ["Ito", "Shinji", ""]]}, {"id": "1909.02253", "submitter": "Chris Wendler", "authors": "Chris Wendler and Dan Alistarh and Markus P\\\"uschel", "title": "Powerset Convolutional Neural Networks", "comments": "Advances in Neural Information Processing Systems 32", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel class of convolutional neural networks (CNNs) for set\nfunctions, i.e., data indexed with the powerset of a finite set. The\nconvolutions are derived as linear, shift-equivariant functions for various\nnotions of shifts on set functions. The framework is fundamentally different\nfrom graph convolutions based on the Laplacian, as it provides not one but\nseveral basic shifts, one for each element in the ground set. Prototypical\nexperiments with several set function classification tasks on synthetic\ndatasets and on datasets derived from real-world hypergraphs demonstrate the\npotential of our new powerset CNNs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:08:40 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 21:58:31 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 08:44:00 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 10:11:40 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wendler", "Chris", ""], ["Alistarh", "Dan", ""], ["P\u00fcschel", "Markus", ""]]}, {"id": "1909.02261", "submitter": "Olivier Goudet Dr", "authors": "Olivier Goudet, B\\'eatrice Duval, Jin-Kao Hao", "title": "Population-based Gradient Descent Weight Learning for Graph Coloring\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph coloring involves assigning colors to the vertices of a graph such that\ntwo vertices linked by an edge receive different colors. Graph coloring\nproblems are general models that are very useful to formulate many relevant\napplications and, however, are computationally difficult. In this work, a\ngeneral population-based weight learning framework for solving graph coloring\nproblems is presented. Unlike existing methods for graph coloring that are\nspecific to the considered problem, the presented work targets a generic\nobjective by introducing a unified method that can be applied to different\ngraph coloring problems. This work distinguishes itself by its solving approach\nthat formulates the search of a solution as a continuous weight tensor\noptimization problem and takes advantage of a gradient descent method computed\nin parallel on graphics processing units. The proposed approach is also\ncharacterized by its general global loss function that can easily be adapted to\ndifferent graph coloring problems. The usefulness of the proposed approach is\ndemonstrated by applying it to solve two typical graph coloring problems and\nperforming large computational studies on popular benchmarks. Improved\nbest-known results (new upper bounds) are reported for several large graphs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:41:11 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 17:19:12 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 08:05:02 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 14:13:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Goudet", "Olivier", ""], ["Duval", "B\u00e9atrice", ""], ["Hao", "Jin-Kao", ""]]}, {"id": "1909.02307", "submitter": "Laura Rettig", "authors": "Laura Rettig, Julien Audiffren, Philippe Cudr\\'e-Mauroux", "title": "Fusing Vector Space Models for Domain-Specific Applications", "comments": "ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of tuning word embeddings for specific use cases and\ndomains. We propose a new method that automatically combines multiple\ndomain-specific embeddings, selected from a wide range of pre-trained\ndomain-specific embeddings, to improve their combined expressive power. Our\napproach relies on two key components: 1) a ranking function, based on a new\nembedding similarity measure, that selects the most relevant embeddings to use\ngiven a domain and 2) a dimensionality reduction method that combines the\nselected embeddings to produce a more compact and efficient encoding that\npreserves the expressiveness. We empirically show that our method produces\neffective domain-specific embeddings that consistently improve the performance\nof state-of-the-art machine learning algorithms on multiple tasks, compared to\ngeneric embeddings trained on large text corpora.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:34:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Rettig", "Laura", ""], ["Audiffren", "Julien", ""], ["Cudr\u00e9-Mauroux", "Philippe", ""]]}, {"id": "1909.02330", "submitter": "Rui (Ray) Zhang", "authors": "Rui Ray Zhang, Xingwu Liu, Yuyi Wang, Liwei Wang", "title": "McDiarmid-Type Inequalities for Graph-Dependent Variables and Stability\n  Bounds", "comments": "accepted as NeurIPS 2019 spotlight paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial assumption in most statistical learning theory is that samples are\nindependently and identically distributed (i.i.d.). However, for many real\napplications, the i.i.d. assumption does not hold. We consider learning\nproblems in which examples are dependent and their dependency relation is\ncharacterized by a graph. To establish algorithm-dependent generalization\ntheory for learning with non-i.i.d. data, we first prove novel McDiarmid-type\nconcentration inequalities for Lipschitz functions of graph-dependent random\nvariables. We show that concentration relies on the forest complexity of the\ngraph, which characterizes the strength of the dependency. We demonstrate that\nfor many types of dependent data, the forest complexity is small and thus\nimplies good concentration. Based on our new inequalities we are able to build\nstability bounds for learning from graph-dependent data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 11:30:24 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:54:13 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhang", "Rui Ray", ""], ["Liu", "Xingwu", ""], ["Wang", "Yuyi", ""], ["Wang", "Liwei", ""]]}, {"id": "1909.02341", "submitter": "Gianluigi Pillonetto Dr.", "authors": "Mauro Bisiacco and Gianluigi Pillonetto", "title": "Kernel absolute summability is only sufficient for RKHS stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized approaches have been successfully applied to linear system\nidentification in recent years. Many of them model unknown impulse responses\nexploiting the so called Reproducing Kernel Hilbert spaces (RKHSs) that enjoy\nthe notable property of being in one-to-one correspondence with the class of\npositive semidefinite kernels. The necessary and sufficient condition for a\nRKHS to be stable, i.e. to contain only BIBO stable linear dynamic systems, has\nbeen known in the literature at least since 2006. However, an open question\nstill persists and concerns the equivalence of such condition with the absolute\nsummability of the kernel. This paper provides a definite answer to this matter\nby proving that such correspondence does not hold. A counterexample is\nintroduced that illustrates the existence of stable RKHSs that are induced by\nnon-absolutely summable kernels.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 11:57:52 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Bisiacco", "Mauro", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1909.02344", "submitter": "Xueying Shi", "authors": "Xueying Shi, Qi Dou, Cheng Xue, Jing Qin, Hao Chen, Pheng-Ann Heng", "title": "An Active Learning Approach for Reducing Annotation Cost in Skin Lesion\n  Analysis", "comments": "Accepted by MIML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated skin lesion analysis is very crucial in clinical practice, as skin\ncancer is among the most common human malignancy. Existing approaches with deep\nlearning have achieved remarkable performance on this challenging task,\nhowever, heavily relying on large-scale labelled datasets. In this paper, we\npresent a novel active learning framework for cost-effective skin lesion\nanalysis. The goal is to effectively select and utilize much fewer labelled\nsamples, while the network can still achieve state-of-the-art performance. Our\nsample selection criteria complementarily consider both informativeness and\nrepresentativeness, derived from decoupled aspects of measuring model certainty\nand covering sample diversity. To make wise use of the selected samples, we\nfurther design a simple yet effective strategy to aggregate intra-class images\nin pixel space, as a new form of data augmentation. We validate our proposed\nmethod on data of ISIC 2017 Skin Lesion Classification Challenge for two tasks.\nUsing only up to 50% of samples, our approach can achieve state-of-the-art\nperformances on both tasks, which are comparable or exceeding the accuracies\nwith full-data training, and outperform other well-known active learning\nmethods by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:00:01 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Shi", "Xueying", ""], ["Dou", "Qi", ""], ["Xue", "Cheng", ""], ["Qin", "Jing", ""], ["Chen", "Hao", ""], ["Heng", "Pheng-Ann", ""]]}, {"id": "1909.02362", "submitter": "Mehmet Emre Ozfatura", "authors": "Mehdi Salehi Heydar Abad and Emre Ozfatura and Deniz Gunduz and Ozgur\n  Ercetin", "title": "Hierarchical Federated Learning Across Heterogeneous Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study collaborative machine learning (ML) across wireless devices, each\nwith its own local dataset. Offloading these datasets to a cloud or an edge\nserver to implement powerful ML solutions is often not feasible due to latency,\nbandwidth and privacy constraints. Instead, we consider federated edge learning\n(FEEL), where the devices share local updates on the model parameters rather\nthan their datasets. We consider a heterogeneous cellular network (HCN), where\nsmall cell base stations (SBSs) orchestrate FL among the mobile users (MUs)\nwithin their cells, and periodically exchange model updates with the macro base\nstation (MBS) for global consensus. We employ gradient sparsification and\nperiodic averaging to increase the communication efficiency of this\nhierarchical federated learning (FL) framework. We then show using CIFAR-10\ndataset that the proposed hierarchical learning solution can significantly\nreduce the communication latency without sacrificing the model accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:42:38 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Abad", "Mehdi Salehi Heydar", ""], ["Ozfatura", "Emre", ""], ["Gunduz", "Deniz", ""], ["Ercetin", "Ozgur", ""]]}, {"id": "1909.02363", "submitter": "Shantenu Jha", "authors": "Geoffrey Fox, Shantenu Jha", "title": "Understanding ML driven HPC: Applications and Infrastructure", "comments": "Invited talk to \"Visionary Track\" at IEEE eScience 2019. arXiv admin\n  note: text overlap with arXiv:1806.04731 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recently outlined the vision of \"Learning Everywhere\" which captures the\npossibility and impact of how learning methods and traditional HPC methods can\nbe coupled together. A primary driver of such coupling is the promise that\nMachine Learning (ML) will give major performance improvements for traditional\nHPC simulations. Motivated by this potential, the ML around HPC class of\nintegration is of particular significance. In a related follow-up paper, we\nprovided an initial taxonomy for integrating learning around HPC methods. In\nthis paper, which is part of the Learning Everywhere series, we discuss \"how\"\nlearning methods and HPC simulations are being integrated to enhance effective\nperformance of computations. This paper identifies several modes ---\nsubstitution, assimilation, and control, in which learning methods integrate\nwith HPC simulations and provide representative applications in each mode. This\npaper discusses some open research questions and we hope will motivate and\nclear the ground for MLaroundHPC benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:47:48 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Fox", "Geoffrey", ""], ["Jha", "Shantenu", ""]]}, {"id": "1909.02373", "submitter": "Yanbin Liu", "authors": "Yanbin Liu, Makoto Yamada, Yao-Hung Hubert Tsai, Tam Le, Ruslan\n  Salakhutdinov, Yi Yang", "title": "LSMI-Sinkhorn: Semi-supervised Mutual Information Estimation with\n  Optimal Transport", "comments": "ECML/PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating mutual information is an important statistics and machine learning\nproblem. To estimate the mutual information from data, a common practice is\npreparing a set of paired samples $\\{(\\mathbf{x}_i,\\mathbf{y}_i)\\}_{i=1}^n\n\\stackrel{\\mathrm{i.i.d.}}{\\sim} p(\\mathbf{x},\\mathbf{y})$. However, in many\nsituations, it is difficult to obtain a large number of data pairs. To address\nthis problem, we propose the semi-supervised Squared-loss Mutual Information\n(SMI) estimation method using a small number of paired samples and the\navailable unpaired ones. We first represent SMI through the density ratio\nfunction, where the expectation is approximated by the samples from marginals\nand its assignment parameters. The objective is formulated using the optimal\ntransport problem and quadratic programming. Then, we introduce the\nLeast-Squares Mutual Information with Sinkhorn (LSMI-Sinkhorn) algorithm for\nefficient optimization. Through experiments, we first demonstrate that the\nproposed method can estimate the SMI without a large number of paired samples.\nThen, we show the effectiveness of the proposed LSMI-Sinkhorn algorithm on\nvarious types of machine learning problems such as image matching and photo\nalbum summarization. Code can be found at\nhttps://github.com/csyanbin/LSMI-Sinkhorn.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:58:20 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 07:54:10 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 06:34:41 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Liu", "Yanbin", ""], ["Yamada", "Makoto", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Le", "Tam", ""], ["Salakhutdinov", "Ruslan", ""], ["Yang", "Yi", ""]]}, {"id": "1909.02384", "submitter": "Yukuan Yang", "authors": "Yukuan Yang, Shuang Wu, Lei Deng, Tianyi Yan, Yuan Xie, Guoqi Li", "title": "Training High-Performance and Large-Scale Deep Neural Networks with Full\n  8-bit Integers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) quantization converting floating-point (FP) data in\nthe network to integers (INT) is an effective way to shrink the model size for\nmemory saving and simplify the operations for compute acceleration. Recently,\nresearches on DNN quantization develop from inference to training, laying a\nfoundation for the online training on accelerators. However, existing schemes\nleaving batch normalization (BN) untouched during training are mostly\nincomplete quantization that still adopts high precision FP in some parts of\nthe data paths. Currently, there is no solution that can use only low bit-width\nINT data during the whole training process of large-scale DNNs with acceptable\naccuracy. In this work, through decomposing all the computation steps in DNNs\nand fusing three special quantization functions to satisfy the different\nprecision requirements, we propose a unified complete quantization framework\ntermed as ``WAGEUBN'' to quantize DNNs involving all data paths including W\n(Weights), A (Activation), G (Gradient), E (Error), U (Update), and BN.\nMoreover, the Momentum optimizer is also quantized to realize a completely\nquantized framework. Experiments on ResNet18/34/50 models demonstrate that\nWAGEUBN can achieve competitive accuracy on the ImageNet dataset. For the first\ntime, the study of quantization in large-scale DNNs is advanced to the full\n8-bit INT level. In this way, all the operations in the training and inference\ncan be bit-wise operations, pushing towards faster processing speed, decreased\nmemory cost, and higher energy efficiency. Our throughout quantization\nframework has great potential for future efficient portable devices with online\nlearning ability.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:17:38 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 14:31:20 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Yang", "Yukuan", ""], ["Wu", "Shuang", ""], ["Deng", "Lei", ""], ["Yan", "Tianyi", ""], ["Xie", "Yuan", ""], ["Li", "Guoqi", ""]]}, {"id": "1909.02387", "submitter": "Murat Dundar", "authors": "Murat Dundar, Bethany L. Ehlmann, Ellen K. Leask", "title": "Machine-Learning-Driven New Geologic Discoveries at Mars Rover Landing\n  Sites: Jezero and NE Syrtis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hierarchical Bayesian classifier is trained at pixel scale with spectral\ndata from the CRISM (Compact Reconnaissance Imaging Spectrometer for Mars)\nimagery. Its utility in detecting rare phases is demonstrated with new geologic\ndiscoveries near the Mars-2020 rover landing site. Akaganeite is found in\nsediments on the Jezero crater floor and in fluvial deposits at NE Syrtis.\nJarosite and silica are found on the Jezero crater floor while\nchlorite-smectite and Al phyllosilicates are found in the Jezero crater walls.\nThese detections point to a multi-stage, multi-chemistry history of water in\nJezero crater and the surrounding region and provide new information for\nguiding the Mars-2020 rover's landed exploration. In particular, the\nakaganeite, silica, and jarosite in the floor deposits suggest either a later\nepisode of salty, Fe-rich waters that post-date Jezero delta or groundwater\nalteration of portions of the Jezero sedimentary sequence.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:22:16 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Dundar", "Murat", ""], ["Ehlmann", "Bethany L.", ""], ["Leask", "Ellen K.", ""]]}, {"id": "1909.02391", "submitter": "Hee-Sun Choi Dr.", "authors": "Hee-Sun Choi, Junmo An, Jin-Gyun Kim, Jae-Yoon Jung, Juhwan Choi,\n  Grzegorz Orzechowski, Aki Mikkola, Jin Hwan Choi", "title": "Data-driven simulation for general purpose multibody dynamics using deep\n  neural networks", "comments": "32 pages, 17 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a machine learning-based simulation framework of\ngeneral-purpose multibody dynamics is introduced. The aim of the framework is\nto generate a well-trained meta-model of multibody dynamics (MBD) systems. To\nthis end, deep neural network (DNN) is employed to the framework so as to\nconstruct data-based meta-model representing multibody systems. Constructing\nwell-defined training data set with time variable is essential to get accurate\nand reliable motion data such as displacement, velocity, acceleration, and\nforces. As a result of the introduced approach, the meta-model provides motion\nestimation of system dynamics without solving the analytical equations of\nmotion. The performance of the proposed DNN meta-modeling was evaluated to\nrepresent several MBD systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:47:35 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Choi", "Hee-Sun", ""], ["An", "Junmo", ""], ["Kim", "Jin-Gyun", ""], ["Jung", "Jae-Yoon", ""], ["Choi", "Juhwan", ""], ["Orzechowski", "Grzegorz", ""], ["Mikkola", "Aki", ""], ["Choi", "Jin Hwan", ""]]}, {"id": "1909.02393", "submitter": "Wil van der Aalst", "authors": "Anja F. Syring and Niek Tax and Wil M.P. van der Aalst", "title": "Evaluating Conformance Measures in Process Mining using Conformance\n  Propositions (Extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining sheds new light on the relationship between process models and\nreal-life processes. Process discovery can be used to learn process models from\nevent logs. Conformance checking is concerned with quantifying the quality of a\nbusiness process model in relation to event data that was logged during the\nexecution of the business process. There exist different categories of\nconformance measures. Recall, also called fitness, is concerned with\nquantifying how much of the behavior that was observed in the event log fits\nthe process model. Precision is concerned with quantifying how much behavior a\nprocess model allows for that was never observed in the event log.\nGeneralization is concerned with quantifying how well a process model\ngeneralizes to behavior that is possible in the business process but was never\nobserved in the event log. Many recall, precision, and generalization measures\nhave been developed throughout the years, but they are often defined in an\nad-hoc manner without formally defining the desired properties up front. To\naddress these problems, we formulate 21 conformance propositions and we use\nthese propositions to evaluate current and existing conformance measures. The\ngoal is to trigger a discussion by clearly formulating the challenges and\nrequirements (rather than proposing new measures). Additionally, this paper\nserves as an overview of the conformance checking measures that are available\nin the process mining area.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 19:04:18 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Syring", "Anja F.", ""], ["Tax", "Niek", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "1909.02414", "submitter": "Olivier Schwander", "authors": "Daniel Brooks, Olivier Schwander, Frederic Barbaresco, Jean-Yves\n  Schneider, Matthieu Cord", "title": "Riemannian batch normalization for SPD neural networks", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance matrices have attracted attention for machine learning\napplications due to their capacity to capture interesting structure in the\ndata. The main challenge is that one needs to take into account the particular\ngeometry of the Riemannian manifold of symmetric positive definite (SPD)\nmatrices they belong to. In the context of deep networks, several architectures\nfor these matrices have recently been proposed. In our article, we introduce a\nRiemannian batch normalization (batchnorm) algorithm, which generalizes the one\nused in Euclidean nets. This novel layer makes use of geometric operations on\nthe manifold, notably the Riemannian barycenter, parallel transport and\nnon-linear structured matrix transformations. We derive a new\nmanifold-constrained gradient descent algorithm working in the space of SPD\nmatrices, allowing to learn the batchnorm layer. We validate our proposed\napproach with experiments in three different contexts on diverse data types: a\ndrone recognition dataset from radar observations, and on emotion and action\nrecognition datasets from video and motion capture data. Experiments show that\nthe Riemannian batchnorm systematically gives better classification performance\ncompared with leading methods and a remarkable robustness to lack of data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:03:50 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 17:13:21 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Brooks", "Daniel", ""], ["Schwander", "Olivier", ""], ["Barbaresco", "Frederic", ""], ["Schneider", "Jean-Yves", ""], ["Cord", "Matthieu", ""]]}, {"id": "1909.02436", "submitter": "Alfred Laugros", "authors": "Alfred Laugros, Alice Caplier, Matthieu Ospici", "title": "Are Adversarial Robustness and Common Perturbation Robustness\n  Independent Attributes ?", "comments": "To appear in ICCV Workshop on Real-World Recognition from Low-Quality\n  Images and Videos (RLQ) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks have been shown to be sensitive to common perturbations such\nas blur, Gaussian noise, rotations, etc. They are also vulnerable to some\nartificial malicious corruptions called adversarial examples. The adversarial\nexamples study has recently become very popular and it sometimes even reduces\nthe term \"adversarial robustness\" to the term \"robustness\". Yet, we do not know\nto what extent the adversarial robustness is related to the global robustness.\nSimilarly, we do not know if a robustness to various common perturbations such\nas translations or contrast losses for instance, could help with adversarial\ncorruptions. We intend to study the links between the robustnesses of neural\nnetworks to both perturbations. With our experiments, we provide one of the\nfirst benchmark designed to estimate the robustness of neural networks to\ncommon perturbations. We show that increasing the robustness to carefully\nselected common perturbations, can make neural networks more robust to unseen\ncommon perturbations. We also prove that adversarial robustness and robustness\nto common perturbations are independent. Our results make us believe that\nneural network robustness should be addressed in a broader sense.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 14:36:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 08:14:58 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Laugros", "Alfred", ""], ["Caplier", "Alice", ""], ["Ospici", "Matthieu", ""]]}, {"id": "1909.02437", "submitter": "Sharath M Shankaranarayana Mr", "authors": "Sharath M. Shankaranarayana and Davor Runje", "title": "ALIME: Autoencoder Based Approach for Local Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and especially deep learning have garneredtremendous\npopularity in recent years due to their increased performanceover other\nmethods. The availability of large amount of data has aidedin the progress of\ndeep learning. Nevertheless, deep learning models areopaque and often seen as\nblack boxes. Thus, there is an inherent need tomake the models interpretable,\nespecially so in the medical domain. Inthis work, we propose a locally\ninterpretable method, which is inspiredby one of the recent tools that has\ngained a lot of interest, called localinterpretable model-agnostic explanations\n(LIME). LIME generates singleinstance level explanation by artificially\ngenerating a dataset aroundthe instance (by randomly sampling and using\nperturbations) and thentraining a local linear interpretable model. One of the\nmajor issues inLIME is the instability in the generated explanation, which is\ncaused dueto the randomly generated dataset. Another issue in these kind of\nlocalinterpretable models is the local fidelity. We propose novel\nmodificationsto LIME by employing an autoencoder, which serves as a better\nweightingfunction for the local model. We perform extensive comparisons\nwithdifferent datasets and show that our proposed method results in\nbothimproved stability, as well as local fidelity.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:58:11 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Shankaranarayana", "Sharath M.", ""], ["Runje", "Davor", ""]]}, {"id": "1909.02453", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Frank Hutter", "title": "Best Practices for Scientific Research on Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a well-performing architecture is often tedious for both DL\npractitioners and researchers, leading to tremendous interest in the automation\nof this task by means of neural architecture search (NAS). Although the\ncommunity has made major strides in developing better NAS methods, the quality\nof scientific empirical evaluations in the young field of NAS is still lacking\nbehind that of other areas of machine learning. To address this issue, we\ndescribe a set of possible issues and ways to avoid them, leading to the NAS\nbest practices checklist available at http://automl.org/nas_checklist.pdf.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:39:27 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 08:28:00 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 08:52:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "1909.02496", "submitter": "Ping Li", "authors": "Hang Zhang, Martin Slawski, Ping Li", "title": "The Benefits of Diversity: Permutation Recovery in Unlabeled Sensing\n  from Multiple Measurement Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In \"Unlabeled Sensing\", one observes a set of linear measurements of an\nunderlying signal with incomplete or missing information about their ordering,\nwhich can be modeled in terms of an unknown permutation. Previous work on the\ncase of a single noisy measurement vector has exposed two main challenges: 1) a\nhigh requirement concerning the \\emph{signal-to-noise ratio} ($\\snr$), i.e.,\napproximately of the order of $n^{5}$, and 2) a massive computational burden in\nlight of NP-hardness in general.\n  In this paper, we study the case of \\emph{multiple} noisy measurement vectors\n(MMVs) resulting from a \\emph{common} permutation and investigate to what\nextent the number of MMVs $m$ facilitates permutation recovery by \"borrowing\nstrength\". The above two challenges have at least partially been resolved\nwithin our work. First, we show that a large stable rank of the signal\nsignificantly reduces the required snr which can drop from a polynomial in $n$\nfor $m = 1$ to a constant for $m = \\Omega(\\log n)$, where $m$ denotes the\nnumber of MMVs and $n$ denotes the number of measurements per MV. This bound is\nshown to be sharp and is associated with a phase transition phenomenon. Second,\nwe propose a computational scheme for recovering the unknown permutation in\npractice. For the \"oracle case\" with the known signal, the maximum likelihood\n(ML) estimator reduces to a linear assignment problem whose global optimum can\nbe obtained efficiently. For the case in which both the signal and permutation\nare unknown, the problem is reformulated as a bi-convex optimization problem\nwith an auxiliary variable, which can be solved by the Alternating Direction\nMethod of Multipliers (ADMM). Numerical experiments based on the proposed\ncomputational scheme confirm the tightness of our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:55:59 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 05:49:06 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhang", "Hang", ""], ["Slawski", "Martin", ""], ["Li", "Ping", ""]]}, {"id": "1909.02506", "submitter": "Yuan Zhou", "authors": "Kefan Dong, Jian Peng, Yining Wang, Yuan Zhou", "title": "$\\sqrt{n}$-Regret for Learning in Markov Decision Processes with\n  Function Approximation and Low Bellman Rank", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of online learning of Markov decision\nprocesses (MDPs) with very large state spaces. Under the assumptions of\nrealizable function approximation and low Bellman ranks, we develop an online\nlearning algorithm that learns the optimal value function while at the same\ntime achieving very low cumulative regret during the learning process. Our\nlearning algorithm, Adaptive Value-function Elimination (AVE), is inspired by\nthe policy elimination algorithm proposed in (Jiang et al., 2017), known as\nOLIVE. One of our key technical contributions in AVE is to formulate the\nelimination steps in OLIVE as contextual bandit problems. This technique\nenables us to apply the active elimination and expert weighting methods from\n(Dudik et al., 2011), instead of the random action exploration scheme used in\nthe original OLIVE algorithm, for more efficient exploration and better control\nof the regret incurred in each policy elimination step. To the best of our\nknowledge, this is the first $\\sqrt{n}$-regret result for reinforcement\nlearning in stochastic MDPs with general value function approximation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 16:20:41 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 21:54:55 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 17:17:19 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Dong", "Kefan", ""], ["Peng", "Jian", ""], ["Wang", "Yining", ""], ["Zhou", "Yuan", ""]]}, {"id": "1909.02553", "submitter": "Nathan Kallus", "authors": "Yichun Hu, Nathan Kallus, Xiaojie Mao", "title": "Smooth Contextual Bandits: Bridging the Parametric and\n  Non-differentiable Regret Regimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a nonparametric contextual bandit problem where the expected reward\nfunctions belong to a H\\\"older class with smoothness parameter $\\beta$. We show\nhow this interpolates between two extremes that were previously studied in\nisolation: non-differentiable bandits ($\\beta\\leq1$), where rate-optimal regret\nis achieved by running separate non-contextual bandits in different context\nregions, and parametric-response bandits (satisfying $\\beta=\\infty$), where\nrate-optimal regret can be achieved with minimal or no exploration due to\ninfinite extrapolatability. We develop a novel algorithm that carefully adjusts\nto all smoothness settings and we prove its regret is rate-optimal by\nestablishing matching upper and lower bounds, recovering the existing results\nat the two extremes. In this sense, our work bridges the gap between the\nexisting literature on parametric and non-differentiable contextual bandit\nproblems and between bandit algorithms that exclusively use global or local\ninformation, shedding light on the crucial interplay of complexity and regret\nin contextual bandits.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 17:51:14 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 13:12:08 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 14:36:21 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 12:55:27 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Hu", "Yichun", ""], ["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""]]}, {"id": "1909.02562", "submitter": "Houssem Ben Braiek", "authors": "Houssem Ben Braiek and Foutse Khomh", "title": "TFCheck : A TensorFlow Library for Detecting Training Issues in Neural\n  Network Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing inclusion of Machine Learning (ML) models in safety critical\nsystems like autonomous cars have led to the development of multiple\nmodel-based ML testing techniques. One common denominator of these testing\ntechniques is their assumption that training programs are adequate and\nbug-free. These techniques only focus on assessing the performance of the\nconstructed model using manually labeled data or automatically generated data.\nHowever, their assumptions about the training program are not always true as\ntraining programs can contain inconsistencies and bugs. In this paper, we\nexamine training issues in ML programs and propose a catalog of verification\nroutines that can be used to detect the identified issues, automatically. We\nimplemented the routines in a Tensorflow-based library named TFCheck. Using\nTFCheck, practitioners can detect the aforementioned issues automatically. To\nassess the effectiveness of TFCheck, we conducted a case study with real-world,\nmutants, and synthetic training programs. Results show that TFCheck can\nsuccessfully detect training issues in ML code implementations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:21:22 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Braiek", "Houssem Ben", ""], ["Khomh", "Foutse", ""]]}, {"id": "1909.02563", "submitter": "Houssem Ben Braiek", "authors": "Houssem Ben Braiek and Foutse khomh", "title": "DeepEvolution: A Search-Based Testing Approach for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing inclusion of Deep Learning (DL) models in safety-critical\nsystems such as autonomous vehicles have led to the development of multiple\nmodel-based DL testing techniques. One common denominator of these testing\ntechniques is the automated generation of test cases, e.g., new inputs\ntransformed from the original training data with the aim to optimize some test\nadequacy criteria. So far, the effectiveness of these approaches has been\nhindered by their reliance on random fuzzing or transformations that do not\nalways produce test cases with a good diversity. To overcome these limitations,\nwe propose, DeepEvolution, a novel search-based approach for testing DL models\nthat relies on metaheuristics to ensure a maximum diversity in generated test\ncases. We assess the effectiveness of DeepEvolution in testing computer-vision\nDL models and found that it significantly increases the neuronal coverage of\ngenerated test cases. Moreover, using DeepEvolution, we could successfully find\nseveral corner-case behaviors. Finally, DeepEvolution outperformed Tensorfuzz\n(a coverage-guided fuzzing tool developed at Google Brain) in detecting latent\ndefects introduced during the quantization of the models. These results suggest\nthat search-based approaches can help build effective testing tools for DL\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:42:08 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Braiek", "Houssem Ben", ""], ["khomh", "Foutse", ""]]}, {"id": "1909.02564", "submitter": "Jarom\\'ir Janisch", "authors": "Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y and Viliam Lis\\'y", "title": "Classification with Costly Features as a Sequential Decision-Making\n  Problem", "comments": null, "journal-ref": "Machine Learning (2020): 1-29", "doi": "10.1007/s10994-020-05874-8", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on a specific classification problem, where the information\nabout a sample is not readily available, but has to be acquired for a cost, and\nthere is a per-sample budget. Inspired by real-world use-cases, we analyze\naverage and hard variations of a directly specified budget. We postulate the\nproblem in its explicit formulation and then convert it into an equivalent MDP,\nthat can be solved with deep reinforcement learning. Also, we evaluate a\nreal-world inspired setting with sparse training dataset with missing features.\nThe presented method performs robustly well in all settings across several\ndistinct datasets, outperforming other prior-art algorithms. The method is\nflexible, as showcased with all mentioned modifications and can be improved\nwith any domain independent advancement in RL.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:46:40 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Janisch", "Jarom\u00edr", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "1909.02583", "submitter": "Xian Yeow Lee", "authors": "Xian Yeow Lee, Sambit Ghadai, Kai Liang Tan, Chinmay Hegde, Soumik\n  Sarkar", "title": "Spatiotemporally Constrained Action Space Attacks on Deep Reinforcement\n  Learning Agents", "comments": "Version 2 with supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of Deep Reinforcement Learning (DRL) algorithms towards\nadversarial attacks in real world applications such as those deployed in\ncyber-physical systems (CPS) are of increasing concern. Numerous studies have\ninvestigated the mechanisms of attacks on the RL agent's state space.\nNonetheless, attacks on the RL agent's action space (AS) (corresponding to\nactuators in engineering systems) are equally perverse; such attacks are\nrelatively less studied in the ML literature. In this work, we first frame the\nproblem as an optimization problem of minimizing the cumulative reward of an RL\nagent with decoupled constraints as the budget of attack. We propose a\nwhite-box Myopic Action Space (MAS) attack algorithm that distributes the\nattacks across the action space dimensions. Next, we reformulate the\noptimization problem above with the same objective function, but with a\ntemporally coupled constraint on the attack budget to take into account the\napproximated dynamics of the agent. This leads to the white-box Look-ahead\nAction Space (LAS) attack algorithm that distributes the attacks across the\naction and temporal dimensions. Our results shows that using the same amount of\nresources, the LAS attack deteriorates the agent's performance significantly\nmore than the MAS attack. This reveals the possibility that with limited\nresource, an adversary can utilize the agent's dynamics to malevolently craft\nattacks that causes the agent to fail. Additionally, we leverage these attack\nstrategies as a possible tool to gain insights on the potential vulnerabilities\nof DRL agents.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 18:04:04 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 03:36:57 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Lee", "Xian Yeow", ""], ["Ghadai", "Sambit", ""], ["Tan", "Kai Liang", ""], ["Hegde", "Chinmay", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1909.02603", "submitter": "Kameron Harris", "authors": "Kameron Decker Harris", "title": "Additive function approximation in the brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many biological learning systems such as the mushroom body, hippocampus, and\ncerebellum are built from sparsely connected networks of neurons. For a new\nunderstanding of such networks, we study the function spaces induced by sparse\nrandom features and characterize what functions may and may not be learned. A\nnetwork with $d$ inputs per neuron is found to be equivalent to an additive\nmodel of order $d$, whereas with a degree distribution the network combines\nadditive terms of different orders. We identify three specific advantages of\nsparsity: additive function approximation is a powerful inductive bias that\nlimits the curse of dimensionality, sparse networks are stable to outlier noise\nin the inputs, and sparse random features are scalable. Thus, even simple brain\narchitectures can be powerful function approximators. Finally, we hope that\nthis work helps popularize kernel theories of networks among computational\nneuroscientists.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 19:07:33 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 21:41:07 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Harris", "Kameron Decker", ""]]}, {"id": "1909.02625", "submitter": "An Xu", "authors": "An Xu, Zhouyuan Huo, Heng Huang", "title": "Diversely Stale Parameters for Efficient Training of CNNs", "comments": "Layer-wise Staleness, Parallel Training, Convolutional Neural\n  Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation algorithm is the most popular algorithm training neural\nnetworks nowadays. However, it suffers from the forward locking, backward\nlocking and update locking problems, especially when a neural network is so\nlarge that its layers are distributed across multiple devices. Existing\nsolutions either can only handle one locking problem or lead to severe accuracy\nloss or memory inefficiency. Moreover, none of them consider the straggler\nproblem among devices. In this paper, we propose Layer-wise Staleness and a\nnovel efficient training algorithm, Diversely Stale Parameters (DSP), which can\naddress all these challenges without loss of accuracy nor memory issue. We also\nanalyze the convergence of DSP with two popular gradient-based methods and\nprove that both of them are guaranteed to converge to critical points for\nnon-convex problems. Finally, extensive experimental results on training deep\nconvolutional neural networks demonstrate that our proposed DSP algorithm can\nachieve significant training speedup with stronger robustness and better\ngeneralization than compared methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 20:41:06 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 17:31:57 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "1909.02636", "submitter": "Christoph Dinh", "authors": "Christoph Dinh, John GW Samuelsson, Alexander Hunold, Matti S\n  H\\\"am\\\"al\\\"ainen, Sheraz Khan", "title": "Contextual Minimum-Norm Estimates (CMNE): A Deep Learning Method for\n  Source Estimation in Neuronal Networks", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetoencephalography (MEG) and Electroencephalography (EEG) source\nestimates have thus far mostly been derived sample by sample, i.e., independent\nof each other in time. However, neuronal assemblies are heavily interconnected,\nconstraining the temporal evolution of neural activity in space as detected by\nMEG and EEG. The observed neural currents are thus highly context dependent.\nHere, a new method is presented which integrates predictive deep learning\nnetworks with the Minimum-Norm Estimates (MNE) approach. Specifically, we\nemploy Long Short-Term Memory (LSTM) networks, a type of recurrent neural\nnetwork, for predicting brain activity. Because we use past activity (context)\nin the estimation, we call our method Contextual MNE (CMNE). We demonstrate\nthat these contextual algorithms can be used for predicting activity based on\nprevious brain states and when used in conjunction with MNE, they lead to more\naccurate source estimation. To evaluate the performance of CMNE, it was tested\non simulated and experimental data from human auditory evoked response\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:14:20 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Dinh", "Christoph", ""], ["Samuelsson", "John GW", ""], ["Hunold", "Alexander", ""], ["H\u00e4m\u00e4l\u00e4inen", "Matti S", ""], ["Khan", "Sheraz", ""]]}, {"id": "1909.02642", "submitter": "Anne Martel", "authors": "Linde S. Hesse, Grey Kuling, Mitko Veta, Anne L. Martel", "title": "Intensity augmentation for domain transfer of whole breast segmentation\n  in MRI", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The segmentation of the breast from the chest wall is an important first step\nin the analysis of breast magnetic resonance images. 3D U-nets have been shown\nto obtain high segmentation accuracy and appear to generalize well when trained\non one scanner type and tested on another scanner, provided that a very similar\nT1-weighted MR protocol is used. There has, however, been little work\naddressing the problem of domain adaptation when image intensities or patient\norientation differ markedly between the training set and an unseen test set. To\novercome the domain shift we propose to apply extensive intensity augmentation\nin addition to geometric augmentation during training. We explored both style\ntransfer and a novel intensity remapping approach as intensity augmentation\nstrategies. For our experiments, we trained a 3D U-net on T1-weighted scans and\ntested on T2-weighted scans. By applying intensity augmentation we increased\nsegmentation performance from a DSC of 0.71 to 0.90. This performance is very\nclose to the baseline performance of training and testing on T2-weighted scans\n(0.92). Furthermore, we applied our network to an independent test set made up\nof publicly available scans acquired using a T1-weighted TWIST sequence and a\ndifferent coil configuration. On this dataset we obtained a performance of\n0.89, close to the inter-observer variability of the ground truth segmentations\n(0.92). Our results show that using intensity augmentation in addition to\ngeometric augmentation is a suitable method to overcome the intensity domain\nshift and we expect it to be useful for a wide range of segmentation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:40:02 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Hesse", "Linde S.", ""], ["Kuling", "Grey", ""], ["Veta", "Mitko", ""], ["Martel", "Anne L.", ""]]}, {"id": "1909.02659", "submitter": "Shi-Xin Zhang", "authors": "Zhou-Quan Wan and Shi-Xin Zhang", "title": "Automatic Differentiation for Complex Valued SVD", "comments": "4.2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cond-mat.stat-mech cond-mat.str-el cs.LG cs.NA quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this note, we report the back propagation formula for complex valued\nsingular value decompositions (SVD). This formula is an important ingredient\nfor a complete automatic differentiation(AD) infrastructure in terms of complex\nnumbers, and it is also the key to understand and utilize AD in tensor\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:34:15 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 13:58:40 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 11:39:46 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Wan", "Zhou-Quan", ""], ["Zhang", "Shi-Xin", ""]]}, {"id": "1909.02682", "submitter": "Sai Qian Zhang", "authors": "Sai Qian Zhang, Qi Zhang, Jieyu Lin", "title": "Efficient Communication in Multi-Agent Reinforcement Learning via\n  Variance Based Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) has recently received considerable\nattention due to its applicability to a wide range of real-world applications.\nHowever, achieving efficient communication among agents has always been an\noverarching problem in MARL. In this work, we propose Variance Based Control\n(VBC), a simple yet efficient technique to improve communication efficiency in\nMARL. By limiting the variance of the exchanged messages between agents during\nthe training phase, the noisy component in the messages can be eliminated\neffectively, while the useful part can be preserved and utilized by the agents\nfor better performance. Our evaluation using a challenging set of StarCraft II\nbenchmarks indicates that our method achieves $2-10\\times$ lower in\ncommunication overhead than state-of-the-art MARL algorithms, while allowing\nagents to better collaborate by developing sophisticated strategies.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 00:26:05 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:33:40 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Zhang", "Sai Qian", ""], ["Zhang", "Qi", ""], ["Lin", "Jieyu", ""]]}, {"id": "1909.02688", "submitter": "Tingshan Liu", "authors": "Thomas L. Athey, Benjamin D. Pedigo, Tingshan Liu, Joshua T.\n  Vogelstein", "title": "AutoGMM: Automatic and Hierarchical Gaussian Mixture Modeling in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian mixture modeling is a fundamental tool in clustering, as well as\ndiscriminant analysis and semiparametric density estimation. However,\nestimating the optimal model for any given number of components is an NP-hard\nproblem, and estimating the number of components is in some respects an even\nharder problem. In R, a popular package called mclust addresses both of these\nproblems. However, Python has lacked such a package. We therefore introduce\nAutoGMM, a Python algorithm for automatic Gaussian mixture modeling, and its\nhierarchical version, HGMM. AutoGMM builds upon scikit-learn's\nAgglomerativeClustering and GaussianMixture classes, with certain modifications\nto make the results more stable. Empirically, on several different\napplications, AutoGMM performs approximately as well as mclust, and sometimes\nbetter. This package is freely available, and further shrinks the gap between\nfunctionality of R and Python for data science.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 01:45:27 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 16:14:24 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 03:29:20 GMT"}, {"version": "v4", "created": "Sat, 12 Dec 2020 16:19:50 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Athey", "Thomas L.", ""], ["Pedigo", "Benjamin D.", ""], ["Liu", "Tingshan", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1909.02702", "submitter": "Stefano Massaroli", "authors": "Stefano Massaroli, Michael Poli, Federico Califano, Angela Faragasso,\n  Jinkyoo Park, Atsushi Yamashita, Hajime Asama", "title": "Port-Hamiltonian Approach to Neural Network Training", "comments": "To appear in the Proceedings of the 58th IEEE Conference on Decision\n  and Control (CDC 2019). The first two authors contributed equally to the work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are discrete entities: subdivided into discrete layers and\nparametrized by weights which are iteratively optimized via difference\nequations. Recent work proposes networks with layer outputs which are no longer\nquantized but are solutions of an ordinary differential equation (ODE);\nhowever, these networks are still optimized via discrete methods (e.g. gradient\ndescent). In this paper, we explore a different direction: namely, we propose a\nnovel framework for learning in which the parameters themselves are solutions\nof ODEs. By viewing the optimization process as the evolution of a\nport-Hamiltonian system, we can ensure convergence to a minimum of the\nobjective function. Numerical experiments have been performed to show the\nvalidity and effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 03:31:40 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Massaroli", "Stefano", ""], ["Poli", "Michael", ""], ["Califano", "Federico", ""], ["Faragasso", "Angela", ""], ["Park", "Jinkyoo", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""]]}, {"id": "1909.02705", "submitter": "Keyu Nie", "authors": "Keyu Nie, Zezhong Zhang, Ted Tao Yuan, Rong Song, Pauline Berry Burke", "title": "Efficient Multivariate Bandit Algorithm with Path Planning", "comments": "Multi-Armed Bandit, Monte Carlo Tree Search, Decision Tree, Path\n  Planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we solve the arms exponential exploding issue in multivariate\nMulti-Armed Bandit (Multivariate-MAB) problem when the arm dimension hierarchy\nis considered. We propose a framework called path planning (TS-PP) which\nutilizes decision graph/trees to model arm reward success rate with m-way\ndimension interaction, and adopts Thompson sampling (TS) for heuristic search\nof arm selection. Naturally, it is quite straightforward to combat the curse of\ndimensionality using a serial processes that operates sequentially by focusing\non one dimension per each process. For our best acknowledge, we are the first\nto solve Multivariate-MAB problem using graph path planning strategy and\ndeploying alike Monte-Carlo tree search ideas. Our proposed method utilizing\ntree models has advantages comparing with traditional models such as general\nlinear regression. Simulation studies validate our claim by achieving faster\nconvergence speed, better efficient optimal arm allocation and lower cumulative\nregret.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 04:16:00 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 21:00:11 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Nie", "Keyu", ""], ["Zhang", "Zezhong", ""], ["Yuan", "Ted Tao", ""], ["Song", "Rong", ""], ["Burke", "Pauline Berry", ""]]}, {"id": "1909.02707", "submitter": "Yuanhao Li", "authors": "Yuanhao Li, Badong Chen, Natsue Yoshimura, Yasuharu Koike", "title": "Restricted Minimum Error Entropy Criterion for Robust Classification", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems 2021", "doi": "10.1109/TNNLS.2021.3082571", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum error entropy (MEE) criterion has been verified as a powerful\napproach for non-Gaussian signal processing and robust machine learning.\nHowever, the implementation of MEE on robust classification is rather a vacancy\nin the literature. The original MEE only focuses on minimizing the Renyi's\nquadratic entropy of the error probability distribution function (PDF), which\ncould cause failure in noisy classification tasks. To this end, we analyze the\noptimal error distribution in the presence of outliers for those classifiers\nwith continuous errors, and introduce a simple codebook to restrict MEE so that\nit drives the error PDF towards the desired case. Half-quadratic based\noptimization and convergence analysis of the new learning criterion, called\nrestricted MEE (RMEE), are provided. Experimental results with logistic\nregression and extreme learning machine are presented to verify the desirable\nrobustness of RMEE.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 04:18:57 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 04:37:41 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 04:34:58 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 06:26:20 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Li", "Yuanhao", ""], ["Chen", "Badong", ""], ["Yoshimura", "Natsue", ""], ["Koike", "Yasuharu", ""]]}, {"id": "1909.02712", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang and Keyou You", "title": "Decentralized Stochastic Gradient Tracking for Non-convex Empirical Risk\n  Minimization", "comments": "This paper has been revised and theoretical results are improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a decentralized stochastic gradient tracking (DSGT)\nalgorithm for non-convex empirical risk minimization problems over a\npeer-to-peer network of nodes, which is in sharp contrast to the existing DSGT\nonly for convex problems. To ensure exact convergence and handle the variance\namong decentralized datasets, each node performs a stochastic gradient (SG)\ntracking step by using a mini-batch of samples, where the batch size is\ndesigned to be proportional to the size of the local dataset. We explicitly\nevaluate the convergence rate of DSGT with respect to the number of iterations\nin terms of algebraic connectivity of the network, mini-batch size, gradient\nvariance, etc. Under certain conditions, we further show that DSGT has a\nnetwork independence property in the sense that the network topology only\naffects the convergence rate up to a constant factor. Hence, the convergence\nrate of DSGT can be comparable to the centralized SGD method. Moreover, a\nlinear speedup of DSGT with respect to the number of nodes is achievable for\nsome scenarios. Numerical experiments for neural networks and logistic\nregression problems on CIFAR-10 finally illustrate the advantages of DSGT.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 05:05:45 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 05:28:08 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 08:38:02 GMT"}, {"version": "v4", "created": "Fri, 28 Aug 2020 11:46:28 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Zhang", "Jiaqi", ""], ["You", "Keyou", ""]]}, {"id": "1909.02729", "submitter": "Guneet Singh Dhillon", "authors": "Guneet S. Dhillon, Pratik Chaudhari, Avinash Ravichandran, Stefano\n  Soatto", "title": "A Baseline for Few-Shot Image Classification", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning a deep network trained with the standard cross-entropy loss is a\nstrong baseline for few-shot learning. When fine-tuned transductively, this\noutperforms the current state-of-the-art on standard datasets such as\nMini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100 with the same\nhyper-parameters. The simplicity of this approach enables us to demonstrate the\nfirst few-shot learning results on the ImageNet-21k dataset. We find that using\na large number of meta-training classes results in high few-shot accuracies\neven for a large number of few-shot classes. We do not advocate our approach as\nthe solution for few-shot learning, but simply use the results to highlight\nlimitations of current benchmarks and few-shot protocols. We perform extensive\nstudies on benchmark datasets to propose a metric that quantifies the\n\"hardness\" of a few-shot episode. This metric can be used to report the\nperformance of few-shot algorithms in a more systematic way.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 06:14:03 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 02:08:39 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 03:19:17 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2020 01:37:04 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 21:13:04 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dhillon", "Guneet S.", ""], ["Chaudhari", "Pratik", ""], ["Ravichandran", "Avinash", ""], ["Soatto", "Stefano", ""]]}, {"id": "1909.02746", "submitter": "Cheolhyeong Kim", "authors": "Cheolhyeong Kim, Haeseong Moon, Hyung Ju Hwang", "title": "NEAR: Neighborhood Edge AggregatoR for Graph Classification", "comments": "11 pages, 12 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graph-structured data with graph neural networks (GNNs) has been\nrecently emerging as an important field because of its wide applicability in\nbioinformatics, chemoinformatics, social network analysis and data mining.\nRecent GNN algorithms are based on neural message passing, which enables GNNs\nto integrate local structures and node features recursively. However, past GNN\nalgorithms based on 1-hop neighborhood neural message passing are exposed to a\nrisk of loss of information on local structures and relationships. In this\npaper, we propose Neighborhood Edge AggregatoR (NEAR), a novel framework that\naggregates relations between the nodes in the neighborhood via edges. NEAR,\nwhich can be orthogonally combined with previous GNN algorithms, gives\nintegrated information that describes which nodes in the neighborhood are\nconnected. Therefore, GNNs combined with NEAR reflect each node's local\nstructure beyond the nodes themselves. Experimental results on multiple graph\nclassification tasks show that our algorithm achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:22:50 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Kim", "Cheolhyeong", ""], ["Moon", "Haeseong", ""], ["Hwang", "Hyung Ju", ""]]}, {"id": "1909.02747", "submitter": "Takehisa Yamakita", "authors": "Takehisa Yamakita", "title": "Eelgrass beds and oyster farming at a lagoon before and after the Great\n  East Japan Earthquake 2011: potential to apply deep learning at a coastal\n  area", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a small number of case studies of automatic land cover\nclassification on the coastal area. Here, I test extraction of seagrass beds,\nsandy area, oyster farming rafts at Mangoku-ura Lagoon, Miyagi, Japan by\ncomparing manual tracing, simple image segmentation, and image transformation\nusing deep learning. The result was used to extract the changes before and\nafter the earthquake and tsunami. The output resolution was best in the image\ntransformation method, which showed more than 69% accuracy for vegetation\nclassification by an assessment using random points on independent test data.\nThe distribution of oyster farming rafts was detected by the segmentation\nmodel. Assessment of the change before and after the earthquake by the manual\ntracing and image transformation result revealed increase of sand area and\ndecrease of the vegetation. By the segmentation model only the decrease of the\noyster farming was detected. These results demonstrate the potential to extract\nthe spatial pattern of these elements after an earthquake and tsunami. Index\nTerms: Great East Japan Earthquake of 2011, Land use land cover (LULC),\nZosteracea seagrass, cultured oyster, deep learning, Mangoku Bay\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:34:58 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Yamakita", "Takehisa", ""]]}, {"id": "1909.02749", "submitter": "Kevin Shih", "authors": "Kevin J. Shih, Aysegul Dundar, Animesh Garg, Robert Pottorf, Andrew\n  Tao, Bryan Catanzaro", "title": "Video Interpolation and Prediction with Unsupervised Landmarks", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction and interpolation for long-range video data involves the complex\ntask of modeling motion trajectories for each visible object, occlusions and\ndis-occlusions, as well as appearance changes due to viewpoint and lighting.\nOptical flow based techniques generalize but are suitable only for short\ntemporal ranges. Many methods opt to project the video frames to a low\ndimensional latent space, achieving long-range predictions. However, these\nlatent representations are often non-interpretable, and therefore difficult to\nmanipulate. This work poses video prediction and interpolation as unsupervised\nlatent structure inference followed by a temporal prediction in this latent\nspace. The latent representations capture foreground semantics without explicit\nsupervision such as keypoints or poses. Further, as each landmark can be mapped\nto a coordinate indicating where a semantic part is positioned, we can reliably\ninterpolate within the coordinate domain to achieve predictable motion\ninterpolation. Given an image decoder capable of mapping these landmarks back\nto the image domain, we are able to achieve high-quality long-range video\ninterpolation and extrapolation by operating on the landmark representation\nspace.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:40:27 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Shih", "Kevin J.", ""], ["Dundar", "Aysegul", ""], ["Garg", "Animesh", ""], ["Pottorf", "Robert", ""], ["Tao", "Andrew", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1909.02750", "submitter": "Wenqing Su", "authors": "Wenqing Su, Xiao Guo, Hai Zhang", "title": "Differentially Private Precision Matrix Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of precision matrix estimation when the\ndataset contains sensitive information. In the differential privacy framework,\nwe develop a differentially private ridge estimator by perturbing the sample\ncovariance matrix. Then we develop a differentially private graphical lasso\nestimator by using the alternating direction method of multipliers (ADMM)\nalgorithm. The theoretical results and empirical results that show the utility\nof the proposed methods are also provided.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:46:12 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Su", "Wenqing", ""], ["Guo", "Xiao", ""], ["Zhang", "Hai", ""]]}, {"id": "1909.02768", "submitter": "Marius K\\\"oppel", "authors": "Marius K\\\"oppel, Alexander Segner, Martin Wagener, Lukas Pensel,\n  Andreas Karwath, Stefan Kramer", "title": "Pairwise Learning to Rank by Neural Networks Revisited: Reconstruction,\n  Theoretical Analysis and Practical Performance", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a pairwise learning to rank approach based on a neural net, called\nDirectRanker, that generalizes the RankNet architecture. We show mathematically\nthat our model is reflexive, antisymmetric, and transitive allowing for\nsimplified training and improved performance. Experimental results on the LETOR\nMSLR-WEB10K, MQ2007 and MQ2008 datasets show that our model outperforms\nnumerous state-of-the-art methods, while being inherently simpler in structure\nand using a pairwise approach only.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:42:58 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["K\u00f6ppel", "Marius", ""], ["Segner", "Alexander", ""], ["Wagener", "Martin", ""], ["Pensel", "Lukas", ""], ["Karwath", "Andreas", ""], ["Kramer", "Stefan", ""]]}, {"id": "1909.02769", "submitter": "Lior Shani", "authors": "Lior Shani and Yonathan Efroni and Shie Mannor", "title": "Adaptive Trust Region Policy Optimization: Global Convergence and Faster\n  Rates for Regularized MDPs", "comments": "Published at AAAI-2020 58 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust region policy optimization (TRPO) is a popular and empirically\nsuccessful policy search algorithm in Reinforcement Learning (RL) in which a\nsurrogate problem, that restricts consecutive policies to be 'close' to one\nanother, is iteratively solved. Nevertheless, TRPO has been considered a\nheuristic algorithm inspired by Conservative Policy Iteration (CPI). We show\nthat the adaptive scaling mechanism used in TRPO is in fact the natural \"RL\nversion\" of traditional trust-region methods from convex analysis. We first\nanalyze TRPO in the planning setting, in which we have access to the model and\nthe entire state space. Then, we consider sample-based TRPO and establish\n$\\tilde O(1/\\sqrt{N})$ convergence rate to the global optimum. Importantly, the\nadaptive scaling mechanism allows us to analyze TRPO in regularized MDPs for\nwhich we prove fast rates of $\\tilde O(1/N)$, much like results in convex\noptimization. This is the first result in RL of better rates when regularizing\nthe instantaneous cost or reward.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:43:38 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 17:07:53 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Shani", "Lior", ""], ["Efroni", "Yonathan", ""], ["Mannor", "Shie", ""]]}, {"id": "1909.02775", "submitter": "Ingmar Schuster", "authors": "Kashif Rasul, Ingmar Schuster, Roland Vollgraf, Urs Bergmann", "title": "Set Flow: A Permutation Invariant Normalizing Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model that is defined on finite sets of exchangeable,\npotentially high dimensional, data. As the architecture is an extension of\nRealNVPs, it inherits all its favorable properties, such as being invertible\nand allowing for exact log-likelihood evaluation. We show that this\narchitecture is able to learn finite non-i.i.d. set data distributions, learn\nstatistical dependencies between entities of the set and is able to train and\nsample with variable set sizes in a computationally efficient manner.\nExperiments on 3D point clouds show state-of-the art likelihoods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 09:00:24 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Rasul", "Kashif", ""], ["Schuster", "Ingmar", ""], ["Vollgraf", "Roland", ""], ["Bergmann", "Urs", ""]]}, {"id": "1909.02803", "submitter": "Johannes Schneider", "authors": "Johannes Schneider and Michail Vlachos", "title": "Personalization of Deep Learning", "comments": null, "journal-ref": "3rd International Data Science Conference 2020, Austria", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss training techniques, objectives and metrics toward personalization\nof deep learning models. In machine learning, personalization addresses the\ngoal of a trained model to target a particular individual by optimizing one or\nmore performance metrics, while conforming to certain constraints. To\npersonalize, we investigate three methods of ``curriculum learning`` and two\napproaches for data grouping, i.e., augmenting the data of an individual by\nadding similar data identified with an auto-encoder. We show that both\n``curriculuum learning'' and ``personalized'' data augmentation lead to\nimproved performance on data of an individual. Mostly, this comes at the cost\nof reduced performance on a more general, broader dataset.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:17:25 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 10:53:26 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 21:28:27 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Schneider", "Johannes", ""], ["Vlachos", "Michail", ""]]}, {"id": "1909.02811", "submitter": "Palash Goyal", "authors": "Palash Goyal, Di Huang, Sujit Rokka Chhetri, Arquimedes Canedo, Jaya\n  Shree and Evan Patterson", "title": "Graph Representation Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning on graphs has been gaining attention due to its wide\napplicability in predicting missing links, and classifying and recommending\nnodes. Most embedding methods aim to preserve certain properties of the\noriginal graph in the low dimensional space. However, real world graphs have a\ncombination of several properties which are difficult to characterize and\ncapture by a single approach. In this work, we introduce the problem of graph\nrepresentation ensemble learning and provide a first of its kind framework to\naggregate multiple graph embedding methods efficiently. We provide analysis of\nour framework and analyze -- theoretically and empirically -- the dependence\nbetween state-of-the-art embedding methods. We test our models on the node\nclassification task on four real world graphs and show that proposed ensemble\napproaches can outperform the state-of-the-art methods by up to 8% on macro-F1.\nWe further show that the approach is even more beneficial for underrepresented\nclasses providing an improvement of up to 12%.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:43:05 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 08:21:13 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Goyal", "Palash", ""], ["Huang", "Di", ""], ["Chhetri", "Sujit Rokka", ""], ["Canedo", "Arquimedes", ""], ["Shree", "Jaya", ""], ["Patterson", "Evan", ""]]}, {"id": "1909.02820", "submitter": "Minyoung Kim", "authors": "Minyoung Kim, Yuting Wang, Pritish Sahu, Vladimir Pavlovic", "title": "Bayes-Factor-VAE: Hierarchical Bayesian Deep Auto-Encoder Models for\n  Factor Disentanglement", "comments": "International Conference on Computer Vision (ICCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of novel hierarchical Bayesian deep auto-encoder models\ncapable of identifying disentangled factors of variability in data. While many\nrecent attempts at factor disentanglement have focused on sophisticated\nlearning objectives within the VAE framework, their choice of a standard normal\nas the latent factor prior is both suboptimal and detrimental to performance.\nOur key observation is that the disentangled latent variables responsible for\nmajor sources of variability, the relevant factors, can be more appropriately\nmodeled using long-tail distributions. The typical Gaussian priors are, on the\nother hand, better suited for modeling of nuisance factors. Motivated by this,\nwe extend the VAE to a hierarchical Bayesian model by introducing hyper-priors\non the variances of Gaussian latent priors, mimicking an infinite mixture,\nwhile maintaining tractable learning and inference of the traditional VAEs.\nThis analysis signifies the importance of partitioning and treating in a\ndifferent manner the latent dimensions corresponding to relevant factors and\nnuisances. Our proposed models, dubbed Bayes-Factor-VAEs, are shown to\noutperform existing methods both quantitatively and qualitatively in terms of\nlatent disentanglement across several challenging benchmark tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:20:42 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Kim", "Minyoung", ""], ["Wang", "Yuting", ""], ["Sahu", "Pritish", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1909.02827", "submitter": "Wissam Siblini", "authors": "Wissam Siblini, Jordan Fr\\'ery, Liyun He-Guelton, Fr\\'ed\\'eric Obl\\'e,\n  Yi-Qing Wang", "title": "Master your Metrics with Calibration", "comments": "Presented at IDA2020", "journal-ref": null, "doi": "10.1007/978-3-030-44584-3_36", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models deployed in real-world applications are often\nevaluated with precision-based metrics such as F1-score or AUC-PR (Area Under\nthe Curve of Precision Recall). Heavily dependent on the class prior, such\nmetrics make it difficult to interpret the variation of a model's performance\nover different subpopulations/subperiods in a dataset. In this paper, we\npropose a way to calibrate the metrics so that they can be made invariant to\nthe prior. We conduct a large number of experiments on balanced and imbalanced\ndata to assess the behavior of calibrated metrics and show that they improve\ninterpretability and provide a better control over what is really measured. We\ndescribe specific real-world use-cases where calibration is beneficial such as,\nfor instance, model monitoring in production, reporting, or fairness\nevaluation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:44:39 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 09:58:48 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Siblini", "Wissam", ""], ["Fr\u00e9ry", "Jordan", ""], ["He-Guelton", "Liyun", ""], ["Obl\u00e9", "Fr\u00e9d\u00e9ric", ""], ["Wang", "Yi-Qing", ""]]}, {"id": "1909.02850", "submitter": "Abigail Lee-Leon Ms", "authors": "Abigail Lee-Leon, Chau Yuen, Dorien Herremans", "title": "Doppler Invariant Demodulation for Shallow Water Acoustic Communications\n  Using Deep Belief Networks", "comments": null, "journal-ref": "Proceedings of 16th IEEE Asia Pacific Wireless Communications\n  Symposium (APWCS). 2019. Singapore", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shallow water environments create a challenging channel for communications.\nIn this paper, we focus on the challenges posed by the frequency-selective\nsignal distortion called the Doppler effect. We explore the design and\nperformance of machine learning (ML) based demodulation methods --- (1) Deep\nBelief Network-feed forward Neural Network (DBN-NN) and (2) Deep Belief\nNetwork-Convolutional Neural Network (DBN-CNN) in the physical layer of Shallow\nWater Acoustic Communication (SWAC). The proposed method comprises of a ML\nbased feature extraction method and classification technique. First, the\nfeature extraction converts the received signals to feature images. Next, the\nclassification model correlates the images to a corresponding binary\nrepresentative. An analysis of the ML based proposed demodulation shows that\ndespite the presence of instantaneous frequencies, the performance of the\nalgorithm shows an invariance with a small 2dB error margin in terms of bit\nerror rate (BER).\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 07:54:36 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lee-Leon", "Abigail", ""], ["Yuen", "Chau", ""], ["Herremans", "Dorien", ""]]}, {"id": "1909.02851", "submitter": "Piotr Szyma\\'nski", "authors": "Jan Mizgajski, Adrian Szymczak, Robert G{\\l}owski, Piotr Szyma\\'nski,\n  Piotr \\.Zelasko, {\\L}ukasz Augustyniak, Miko{\\l}aj Morzy, Yishay Carmiel,\n  Jeff Hodson, {\\L}ukasz W\\'ojciak, Daniel Smoczyk, Adam Wr\\'obel, Bartosz\n  Borowik, Adam Artajew, Marcin Baran, Cezary Kwiatkowski, Marzena\n  \\.Zy{\\l}a-Hoppe", "title": "Avaya Conversational Intelligence: A Real-Time System for Spoken\n  Language Understanding in Human-Human Call Center Conversations", "comments": "Accepted for Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avaya Conversational Intelligence(ACI) is an end-to-end, cloud-based solution\nfor real-time Spoken Language Understanding for call centers. It combines large\nvocabulary, real-time speech recognition, transcript refinement, and entity and\nintent recognition in order to convert live audio into a rich, actionable\nstream of structured events. These events can be further leveraged with a\nbusiness rules engine, thus serving as a foundation for real-time supervision\nand assistance applications. After the ingestion, calls are enriched with\nunsupervised keyword extraction, abstractive summarization, and\nbusiness-defined attributes, enabling offline use cases, such as business\nintelligence, topic mining, full-text search, quality assurance, and agent\ntraining. ACI comes with a pretrained, configurable library of hundreds of\nintents and a robust intent training environment that allows for efficient,\ncost-effective creation and customization of customer-specific intents.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 22:57:10 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Mizgajski", "Jan", ""], ["Szymczak", "Adrian", ""], ["G\u0142owski", "Robert", ""], ["Szyma\u0144ski", "Piotr", ""], ["\u017belasko", "Piotr", ""], ["Augustyniak", "\u0141ukasz", ""], ["Morzy", "Miko\u0142aj", ""], ["Carmiel", "Yishay", ""], ["Hodson", "Jeff", ""], ["W\u00f3jciak", "\u0141ukasz", ""], ["Smoczyk", "Daniel", ""], ["Wr\u00f3bel", "Adam", ""], ["Borowik", "Bartosz", ""], ["Artajew", "Adam", ""], ["Baran", "Marcin", ""], ["Kwiatkowski", "Cezary", ""], ["\u017by\u0142a-Hoppe", "Marzena", ""]]}, {"id": "1909.02859", "submitter": "Khaled Koutini", "authors": "Khaled Koutini, Hamid Eghbal-zadeh and Gerhard Widmer", "title": "Receptive-field-regularized CNN variants for acoustic scene\n  classification", "comments": "Accepted at Detection and Classification of Acoustic Scenes and\n  Events 2019 (DCASE Workshop 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic scene classification and related tasks have been dominated by\nConvolutional Neural Networks (CNNs). Top-performing CNNs use mainly audio\nspectograms as input and borrow their architectural design primarily from\ncomputer vision. A recent study has shown that restricting the receptive field\n(RF) of CNNs in appropriate ways is crucial for their performance, robustness\nand generalization in audio tasks. One side effect of restricting the RF of\nCNNs is that more frequency information is lost. In this paper, we perform a\nsystematic investigation of different RF configuration for various CNN\narchitectures on the DCASE 2019 Task 1.A dataset. Second, we introduce\nFrequency Aware CNNs to compensate for the lack of frequency information caused\nby the restricted RF, and experimentally determine if and in what RF ranges\nthey yield additional improvement. The result of these investigations are\nseveral well-performing submissions to different tasks in the DCASE 2019\nChallenge.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:40:38 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Koutini", "Khaled", ""], ["Eghbal-zadeh", "Hamid", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1909.02869", "submitter": "Paul Primus", "authors": "Paul Primus, Hamid Eghbal-zadeh, David Eitelsebner, Khaled Koutini,\n  Andreas Arzt and Gerhard Widmer", "title": "Exploiting Parallel Audio Recordings to Enforce Device Invariance in\n  CNN-based Acoustic Scene Classification", "comments": "Published at the Workshop on Detection and Classification of Acoustic\n  Scenes and Events, 25-26 October 2019, New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution mismatches between the data seen at training and at application\ntime remain a major challenge in all application areas of machine learning. We\nstudy this problem in the context of machine listening (Task 1b of the DCASE\n2019 Challenge). We propose a novel approach to learn domain-invariant\nclassifiers in an end-to-end fashion by enforcing equal hidden layer\nrepresentations for domain-parallel samples, i.e. time-aligned recordings from\ndifferent recording devices. No classification labels are needed for our domain\nadaptation (DA) method, which makes the data collection process cheaper.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 16:19:50 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Primus", "Paul", ""], ["Eghbal-zadeh", "Hamid", ""], ["Eitelsebner", "David", ""], ["Koutini", "Khaled", ""], ["Arzt", "Andreas", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1909.02877", "submitter": "Long Yang", "authors": "Long Yang, Yu Zhang, Qian Zheng, Pengfei Li, Gang Pan", "title": "Gradient Q$(\\sigma, \\lambda)$: A Unified Algorithm with Function\n  Approximation for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Full-sampling (e.g., Q-learning) and pure-expectation (e.g., Expected Sarsa)\nalgorithms are efficient and frequently used techniques in reinforcement\nlearning. Q$(\\sigma,\\lambda)$ is the first approach unifies them with\neligibility trace through the sampling degree $\\sigma$. However, it is limited\nto the tabular case, for large-scale learning, the Q$(\\sigma,\\lambda)$ is too\nexpensive to require a huge volume of tables to accurately storage value\nfunctions. To address above problem, we propose a GQ$(\\sigma,\\lambda)$ that\nextends tabular Q$(\\sigma,\\lambda)$ with linear function approximation. We\nprove the convergence of GQ$(\\sigma,\\lambda)$. Empirical results on some\nstandard domains show that GQ$(\\sigma,\\lambda)$ with a combination of\nfull-sampling with pure-expectation reach a better performance than\nfull-sampling and pure-expectation methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 12:54:03 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Yang", "Long", ""], ["Zhang", "Yu", ""], ["Zheng", "Qian", ""], ["Li", "Pengfei", ""], ["Pan", "Gang", ""]]}, {"id": "1909.02900", "submitter": "Yann Issartel", "authors": "Yann Issartel", "title": "On the Estimation of Network Complexity: Dimension of Graphons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network complexity has been studied for over half a century and has found a\nwide range of applications. Many methods have been developed to characterize\nand estimate the complexity of networks. However, there has been little\nresearch with statistical guarantees. In this paper, we develop a statistical\ntheory of graph complexity in a general model of random graphs, the so-called\ngraphon model.\n  Given a graphon, we endow the latent space of the nodes with the neighborhood\ndistance that measures the propensity of two nodes to be connected with similar\nnodes. Our complexity index is then based on the covering number and the\nMinkowski dimension of (a purified version of) this metric space. Although the\nlatent space is not identifiable, these indices turn out to be identifiable.\nThis notion of complexity has simple interpretations on popular examples of\nrandom graphs: it matches the number of communities in stochastic block models;\nthe dimension of the Euclidean space in random geometric graphs; the regularity\nof the link function in H\\\"older graphon models.\n  From a single observation of the graph, we construct an estimator of the\nneighborhood-distance and show universal non-asymptotic bounds for its risk,\nmatching minimax lower bounds. Based on this estimated distance, we compute the\ncorresponding covering number and Minkowski dimension and we provide optimal\nnon-asymptotic error bounds for these two plug-in estimators.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:35:39 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 00:52:27 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Issartel", "Yann", ""]]}, {"id": "1909.02902", "submitter": "Lingbo Liu", "authors": "Lingbo Liu, Jiajie Zhen, Guanbin Li, Geng Zhan, Zhaocheng He, Bowen\n  Du, Liang Lin", "title": "Dynamic Spatial-Temporal Representation Learning for Traffic Flow\n  Prediction", "comments": "Accepted by IEEE Transactions on Intelligent Transportation Systems.\n  arXiv admin note: text overlap with arXiv:1809.00101", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a crucial component in intelligent transportation systems, traffic flow\nprediction has recently attracted widespread research interest in the field of\nartificial intelligence (AI) with the increasing availability of massive\ntraffic mobility data. Its key challenge lies in how to integrate diverse\nfactors (such as temporal rules and spatial dependencies) to infer the\nevolution trend of traffic flow. To address this problem, we propose a unified\nneural network called Attentive Traffic Flow Machine (ATFM), which can\neffectively learn the spatial-temporal feature representations of traffic flow\nwith an attention mechanism. In particular, our ATFM is composed of two\nprogressive Convolutional Long Short-Term Memory (ConvLSTM\n\\cite{xingjian2015convolutional}) units connected with a convolutional layer.\nSpecifically, the first ConvLSTM unit takes normal traffic flow features as\ninput and generates a hidden state at each time-step, which is further fed into\nthe connected convolutional layer for spatial attention map inference. The\nsecond ConvLSTM unit aims at learning the dynamic spatial-temporal\nrepresentations from the attentionally weighted traffic flow features. Further,\nwe develop two deep learning frameworks based on ATFM to predict citywide\nshort-term/long-term traffic flow by adaptively incorporating the sequential\nand periodic data as well as other external influences. Extensive experiments\non two standard benchmarks well demonstrate the superiority of the proposed\nmethod for traffic flow prediction. Moreover, to verify the generalization of\nour method, we also apply the customized framework to forecast the passenger\npickup/dropoff demands in traffic prediction and show its superior performance.\nOur code and data are available at\n{\\color{blue}\\url{https://github.com/liulingbo918/ATFM}}.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:41:38 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 17:10:48 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 13:08:40 GMT"}, {"version": "v4", "created": "Sat, 13 Jun 2020 01:21:01 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Liu", "Lingbo", ""], ["Zhen", "Jiajie", ""], ["Li", "Guanbin", ""], ["Zhan", "Geng", ""], ["He", "Zhaocheng", ""], ["Du", "Bowen", ""], ["Lin", "Liang", ""]]}, {"id": "1909.02918", "submitter": "Ilia Shumailov", "authors": "Yiren Zhao, Ilia Shumailov, Han Cui, Xitong Gao, Robert Mullins, Ross\n  Anderson", "title": "Blackbox Attacks on Reinforcement Learning Agents Using Approximated\n  Temporal Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent research on reinforcement learning (RL) has suggested that trained\nagents are vulnerable to maliciously crafted adversarial samples. In this work,\nwe show how such samples can be generalised from White-box and Grey-box attacks\nto a strong Black-box case, where the attacker has no knowledge of the agents,\ntheir training parameters and their training methods. We use\nsequence-to-sequence models to predict a single action or a sequence of future\nactions that a trained agent will make. First, we show our approximation model,\nbased on time-series information from the agent, consistently predicts RL\nagents' future actions with high accuracy in a Black-box setup on a wide range\nof games and RL algorithms. Second, we find that although adversarial samples\nare transferable from the target model to our RL agents, they often outperform\nrandom Gaussian noise only marginally. This highlights a serious methodological\ndeficiency in previous work on such agents; random jamming should have been\ntaken as the baseline for evaluation. Third, we propose a novel use for\nadversarial samplesin Black-box attacks of RL agents: they can be used to\ntrigger a trained agent to misbehave after a specific time delay. This appears\nto be a genuinely new type of attack. It potentially enables an attacker to use\ndevices controlled by RL agents as time bombs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:06:21 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 19:07:45 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhao", "Yiren", ""], ["Shumailov", "Ilia", ""], ["Cui", "Han", ""], ["Gao", "Xitong", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "1909.02939", "submitter": "Harikrishna Narasimhan", "authors": "Harikrishna Narasimhan, Andrew Cotter, Maya Gupta", "title": "Optimizing Generalized Rate Metrics through Game Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general framework for solving a large class of learning problems\nwith non-linear functions of classification rates. This includes problems where\none wishes to optimize a non-decomposable performance metric such as the\nF-measure or G-mean, and constrained training problems where the classifier\nneeds to satisfy non-linear rate constraints such as predictive parity\nfairness, distribution divergences or churn ratios. We extend previous\ntwo-player game approaches for constrained optimization to a game between three\nplayers to decouple the classifier rates from the non-linear objective, and\nseek to find an equilibrium of the game. Our approach generalizes many existing\nalgorithms, and makes possible new algorithms with more flexibility and tighter\nhandling of non-linear rate constraints. We provide convergence guarantees for\nconvex functions of rates, and show how our methodology can be extended to\nhandle sums of ratios of rates. Experiments on different fairness tasks confirm\nthe efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:47:33 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Narasimhan", "Harikrishna", ""], ["Cotter", "Andrew", ""], ["Gupta", "Maya", ""]]}, {"id": "1909.02940", "submitter": "Vaneet Aggarwal", "authors": "Mridul Agarwal and Vaneet Aggarwal", "title": "Reinforcement Learning for Joint Optimization of Multiple Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.IT cs.MA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms such as DQN owe their success to\nMarkov Decision Processes, and the fact that maximizing the sum of rewards\nallows using backward induction and reduce to the Bellman optimality equation.\nHowever, many real-world problems require optimization of an objective that is\nnon-linear in cumulative rewards for which dynamic programming cannot be\napplied directly. For example, in a resource allocation problem, one of the\nobjectives is to maximize long-term fairness among the users. We notice that\nwhen the function of the sum of rewards is considered, the problem loses its\nMarkov nature. This paper addresses and formalizes the problem of optimizing a\nnon-linear function of the long term average of rewards. We propose model-based\nand model-free algorithms to learn the policy, where the model-based policy is\nshown to achieve a regret of $\\Tilde{O}\\left(KDSA\\sqrt{\\frac{A}{T}}\\right)$ for\n$K$ users. Further, using the fairness in cellular base-station scheduling, and\nqueueing system scheduling as examples, the proposed algorithm is shown to\nsignificantly outperform the conventional RL approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:48:07 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 20:42:51 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 05:10:01 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1909.02950", "submitter": "Douwe Kiela", "authors": "Douwe Kiela, Suvrat Bhooshan, Hamed Firooz, Ethan Perez, Davide\n  Testuggine", "title": "Supervised Multimodal Bitransformers for Classifying Images and Text", "comments": "Rejected from EMNLP, twice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised bidirectional transformer models such as BERT have led to\ndramatic improvements in a wide variety of textual classification tasks. The\nmodern digital world is increasingly multimodal, however, and textual\ninformation is often accompanied by other modalities such as images. We\nintroduce a supervised multimodal bitransformer model that fuses information\nfrom text and image encoders, and obtain state-of-the-art performance on\nvarious multimodal classification benchmark tasks, outperforming strong\nbaselines, including on hard test sets specifically designed to measure\nmultimodal performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:59:18 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 03:08:28 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kiela", "Douwe", ""], ["Bhooshan", "Suvrat", ""], ["Firooz", "Hamed", ""], ["Perez", "Ethan", ""], ["Testuggine", "Davide", ""]]}, {"id": "1909.02963", "submitter": "Abir De", "authors": "Abir De, Nastaran Okati, Paramita Koley, Niloy Ganguly, Manuel\n  Gomez-Rodriguez", "title": "Regression Under Human Assistance", "comments": "Extended version of AAAI 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions are increasingly taken by both humans and machine learning models.\nHowever, machine learning models are currently trained for full automation --\nthey are not aware that some of the decisions may still be taken by humans. In\nthis paper, we take a first step towards the development of machine learning\nmodels that are optimized to operate under different automation levels. More\nspecifically, we first introduce the problem of ridge regression under human\nassistance and show that it is NP-hard. Then, we derive an alternative\nrepresentation of the corresponding objective function as a difference of\nnondecreasing submodular functions. Building on this representation, we further\nshow that the objective is nondecreasing and satisfies $\\alpha$-submodularity,\na recently introduced notion of approximate submodularity. These properties\nallow a simple and efficient greedy algorithm to enjoy approximation guarantees\nat solving the problem. Experiments on synthetic and real-world data from two\nimportant applications -- medical diagnosis and content moderation-demonstrate\nthat our algorithm outsources to humans those samples in which the prediction\nerror of the ridge regression model would have been the highest if it had to\nmake a prediction, it outperforms several competitive baselines, and its\nperformance is robust with respect to several design choices and\nhyperparameters used in the experiments.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:08:52 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 11:56:14 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 12:19:33 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 10:42:37 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["De", "Abir", ""], ["Okati", "Nastaran", ""], ["Koley", "Paramita", ""], ["Ganguly", "Niloy", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1909.02971", "submitter": "Ali Bahrami Rad", "authors": "Ali Bahrami Rad, Morteza Zabihi, Zheng Zhao, Moncef Gabbouj, Aggelos\n  K. Katsaggelos, and Simo S\\\"arkk\\\"a", "title": "Automated Polysomnography Analysis for Detection of Non-Apneic and\n  Non-Hypopneic Arousals using Feature Engineering and a Bidirectional LSTM\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The aim of this study is to develop an automated classification\nalgorithm for polysomnography (PSG) recordings to detect non-apneic and\nnon-hypopneic arousals. Our particular focus is on detecting the respiratory\neffort-related arousals (RERAs) which are very subtle respiratory events that\ndo not meet the criteria for apnea or hypopnea, and are more challenging to\ndetect. Methods: The proposed algorithm is based on a bidirectional long\nshort-term memory (BiLSTM) classifier and 465 multi-domain features, extracted\nfrom multimodal clinical time series. The features consist of a set of\nphysiology-inspired features (n = 75), obtained by multiple steps of feature\nselection and expert analysis, and a set of physiology-agnostic features (n =\n390), derived from scattering transform. Results: The proposed algorithm is\nvalidated on the 2018 PhysioNet challenge dataset. The overall performance in\nterms of the area under the precision-recall curve (AUPRC) is 0.50 on the\nhidden test dataset. This result is tied for the second-best score during the\nfollow-up and official phases of the 2018 PhysioNet challenge. Conclusions: The\nresults demonstrate that it is possible to automatically detect subtle\nnon-apneic/non-hypopneic arousal events from PSG recordings. Significance:\nAutomatic detection of subtle respiratory events such as RERAs together with\nother non-apneic/non-hypopneic arousals will allow detailed annotations of\nlarge PSG databases. This contributes to a better retrospective analysis of\nsleep data, which may also improve the quality of treatment.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:29:54 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Rad", "Ali Bahrami", ""], ["Zabihi", "Morteza", ""], ["Zhao", "Zheng", ""], ["Gabbouj", "Moncef", ""], ["Katsaggelos", "Aggelos K.", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "1909.02977", "submitter": "Chi Thang Duong", "authors": "Chi Thang Duong, Hongzhi Yin, Thanh Dat Hoang, Truong Giang Le Ba,\n  Matthias Weidlich, Quoc Viet Hung Nguyen, Karl Aberer", "title": "Parallel Computation of Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph embedding aims at learning a vector-based representation of vertices\nthat incorporates the structure of the graph. This representation then enables\ninference of graph properties. Existing graph embedding techniques, however, do\nnot scale well to large graphs. We therefore propose a framework for parallel\ncomputation of a graph embedding using a cluster of compute nodes with resource\nconstraints. We show how to distribute any existing embedding technique by\nfirst splitting a graph for any given set of constrained compute nodes and then\nreconciling the embedding spaces derived for these subgraphs. We also propose a\nnew way to evaluate the quality of graph embeddings that is independent of a\nspecific inference task. Based thereon, we give a formal bound on the\ndifference between the embeddings derived by centralised and parallel\ncomputation. Experimental results illustrate that our approach for parallel\ncomputation scales well, while largely maintaining the embedding quality.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:41:44 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Duong", "Chi Thang", ""], ["Yin", "Hongzhi", ""], ["Hoang", "Thanh Dat", ""], ["Ba", "Truong Giang Le", ""], ["Weidlich", "Matthias", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Aberer", "Karl", ""]]}, {"id": "1909.02982", "submitter": "Theo Jaunet", "authors": "Theo Jaunet, Romain Vuillemot and Christian Wolf", "title": "DRLViz: Understanding Decisions and Memory in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DRLViz, a visual analytics interface to interpret the internal\nmemory of an agent (e.g. a robot) trained using deep reinforcement learning.\nThis memory is composed of large temporal vectors updated when the agent moves\nin an environment and is not trivial to understand due to the number of\ndimensions, dependencies to past vectors, spatial/temporal correlations, and\nco-correlation between dimensions. It is often referred to as a black box as\nonly inputs (images) and outputs (actions) are intelligible for humans. Using\nDRLViz, experts are assisted to interpret decisions using memory reduction\ninteractions, and to investigate the role of parts of the memory when errors\nhave been made (e.g. wrong direction). We report on DRLViz applied in the\ncontext of video games simulators (ViZDoom) for a navigation scenario with item\ngathering tasks. We also report on experts evaluation using DRLViz, and\napplicability of DRLViz to other scenarios and navigation problems beyond\nsimulation games, as well as its contribution to black box models\ninterpretability and explainability in the field of visual analytics.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:56:39 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 16:07:35 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Jaunet", "Theo", ""], ["Vuillemot", "Romain", ""], ["Wolf", "Christian", ""]]}, {"id": "1909.02998", "submitter": "Tino Werner", "authors": "Tino Werner", "title": "A review on ranking problems in statistical learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking problems, also known as preference learning problems, define a widely\nspread class of statistical learning problems with many applications, including\nfraud detection, document ranking, medicine, credit risk screening, image\nranking or media memorability. In this article, we systematically review\ndifferent types of instance ranking problems, i.e., ranking problems that\nrequire the prediction of an order of the response variables, and the\ncorresponding loss functions resp. goodness criteria. We discuss the\ndifficulties when trying to optimize those criteria. As for a detailed and\ncomprehensive overview of existing machine learning techniques to solve such\nranking problems, we systemize existing techniques and recapitulate the\ncorresponding optimization problems in a unified notation. We also discuss to\nwhich of the ranking problems the respective algorithms are tailored and\nidentify their strengths and limitations. Computational aspects and open\nresearch problems are also considered.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:24:23 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 13:30:41 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 14:11:07 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Werner", "Tino", ""]]}, {"id": "1909.03004", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Suchin Gururangan, Dallas Card, Roy Schwartz, Noah A.\n  Smith", "title": "Show Your Work: Improved Reporting of Experimental Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in natural language processing proceeds, in part, by demonstrating\nthat new models achieve superior performance (e.g., accuracy) on held-out test\ndata, compared to previous results. In this paper, we demonstrate that test-set\nperformance scores alone are insufficient for drawing accurate conclusions\nabout which model performs best. We argue for reporting additional details,\nespecially performance on validation data obtained during model development. We\npresent a novel technique for doing so: expected validation performance of the\nbest-found model as a function of computation budget (i.e., the number of\nhyperparameter search trials or the overall training time). Using our approach,\nwe find multiple recent model comparisons where authors would have reached a\ndifferent conclusion if they had used more (or less) computation. Our approach\nalso allows us to estimate the amount of computation required to obtain a given\naccuracy; applying it to several recently published results yields massive\nvariation across papers, from hours to weeks. We conclude with a set of best\npractices for reporting experimental results which allow for robust future\ncomparisons, and provide code to allow researchers to use our technique.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:40:42 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Dodge", "Jesse", ""], ["Gururangan", "Suchin", ""], ["Card", "Dallas", ""], ["Schwartz", "Roy", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.03009", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas", "title": "Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining how overparametrized neural networks simultaneously achieve low\nrisk and zero empirical risk on benchmark datasets is an open problem.\nPAC-Bayes bounds optimized using variational inference (VI) have been recently\nproposed as a promising direction in obtaining non-vacuous bounds. We show\nempirically that this approach gives negligible gains when modeling the\nposterior as a Gaussian with diagonal covariance--known as the mean-field\napproximation. We investigate common explanations, such as the failure of VI\ndue to problems in optimization or choosing a suboptimal prior. Our results\nsuggest that investigating richer posteriors is the most promising direction\nforward.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:43:49 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 16:57:07 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Pitas", "Konstantinos", ""]]}, {"id": "1909.03011", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Roy Schwartz, Hao Peng, Noah A. Smith", "title": "RNN Architecture Learning with Sparse Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models for NLP typically use large numbers of parameters to reach\nstate-of-the-art performance, which can lead to excessive memory usage and\nincreased runtime. We present a structure learning method for learning sparse,\nparameter-efficient NLP models. Our method applies group lasso to rational RNNs\n(Peng et al., 2018), a family of models that is closely connected to weighted\nfinite-state automata (WFSAs). We take advantage of rational RNNs' natural\ngrouping of the weights, so the group lasso penalty directly removes WFSA\nstates, substantially reducing the number of parameters in the model. Our\nexperiments on a number of sentiment analysis datasets, using both GloVe and\nBERT embeddings, show that our approach learns neural structures which have\nfewer parameters without sacrificing performance relative to parameter-rich\nbaselines. Our method also highlights the interpretable properties of rational\nRNNs. We show that sparsifying such models makes them easier to visualize, and\nwe present models that rely exclusively on as few as three WFSAs after pruning\nmore than 90% of the weights. We publicly release our code.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:51:21 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Dodge", "Jesse", ""], ["Schwartz", "Roy", ""], ["Peng", "Hao", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.03012", "submitter": "Amit Dhurandhar", "authors": "Vijay Arya, Rachel K. E. Bellamy, Pin-Yu Chen, Amit Dhurandhar,\n  Michael Hind, Samuel C. Hoffman, Stephanie Houde, Q. Vera Liao, Ronny Luss,\n  Aleksandra Mojsilovi\\'c, Sami Mourad, Pablo Pedemonte, Ramya Raghavendra,\n  John Richards, Prasanna Sattigeri, Karthikeyan Shanmugam, Moninder Singh,\n  Kush R. Varshney, Dennis Wei and Yunfeng Zhang", "title": "One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI\n  Explainability Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial intelligence and machine learning algorithms make further\ninroads into society, calls are increasing from multiple stakeholders for these\nalgorithms to explain their outputs. At the same time, these stakeholders,\nwhether they be affected citizens, government regulators, domain experts, or\nsystem developers, present different requirements for explanations. Toward\naddressing these needs, we introduce AI Explainability 360\n(http://aix360.mybluemix.net/), an open-source software toolkit featuring eight\ndiverse and state-of-the-art explainability methods and two evaluation metrics.\nEqually important, we provide a taxonomy to help entities requiring\nexplanations to navigate the space of explanation methods, not only those in\nthe toolkit but also in the broader literature on explainability. For data\nscientists and other users of the toolkit, we have implemented an extensible\nsoftware architecture that organizes methods according to their place in the AI\nmodeling pipeline. We also discuss enhancements to bring research innovations\ncloser to consumers of explanations, ranging from simplified, more accessible\nversions of algorithms, to tutorials and an interactive web demo to introduce\nAI explainability to different audiences and application domains. Together, our\ntoolkit and taxonomy can help identify gaps where more explainability methods\nare needed and provide a platform to incorporate them as they are developed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:53:01 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 15:08:57 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Arya", "Vijay", ""], ["Bellamy", "Rachel K. E.", ""], ["Chen", "Pin-Yu", ""], ["Dhurandhar", "Amit", ""], ["Hind", "Michael", ""], ["Hoffman", "Samuel C.", ""], ["Houde", "Stephanie", ""], ["Liao", "Q. Vera", ""], ["Luss", "Ronny", ""], ["Mojsilovi\u0107", "Aleksandra", ""], ["Mourad", "Sami", ""], ["Pedemonte", "Pablo", ""], ["Raghavendra", "Ramya", ""], ["Richards", "John", ""], ["Sattigeri", "Prasanna", ""], ["Shanmugam", "Karthikeyan", ""], ["Singh", "Moninder", ""], ["Varshney", "Kush R.", ""], ["Wei", "Dennis", ""], ["Zhang", "Yunfeng", ""]]}, {"id": "1909.03013", "submitter": "Xiaoqian Wang", "authors": "Xiaoqian Wang, Heng Huang", "title": "Approaching Machine Learning Fairness through Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is becoming a rising concern w.r.t. machine learning model\nperformance. Especially for sensitive fields such as criminal justice and loan\ndecision, eliminating the prediction discrimination towards a certain group of\npopulation (characterized by sensitive features like race and gender) is\nimportant for enhancing the trustworthiness of model. In this paper, we present\na new general framework to improve machine learning fairness. The goal of our\nmodel is to minimize the influence of sensitive feature from the perspectives\nof both the data input and the predictive model. In order to achieve this goal,\nwe reformulate the data input by removing the sensitive information and\nstrengthen model fairness by minimizing the marginal contribution of the\nsensitive feature. We propose to learn the non-sensitive input via sampling\namong features and design an adversarial network to minimize the dependence\nbetween the reformulated input and the sensitive information. Extensive\nexperiments on three benchmark datasets suggest that our model achieve better\nresults than related state-of-the-art methods with respect to both fairness\nmetrics and prediction performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:55:05 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Wang", "Xiaoqian", ""], ["Huang", "Heng", ""]]}, {"id": "1909.03037", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Saheb Pasand, Fakhri Karray, Mark Crowley", "title": "Quantized Fisher Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new subspace learning method, named Quantized Fisher\nDiscriminant Analysis (QFDA), which makes use of both machine learning and\ninformation theory. There is a lack of literature for combination of machine\nlearning and information theory and this paper tries to tackle this gap. QFDA\nfinds a subspace which discriminates the uniformly quantized images in the\nDiscrete Cosine Transform (DCT) domain at least as well as discrimination of\nnon-quantized images by Fisher Discriminant Analysis (FDA) while the images\nhave been compressed. This helps the user to throw away the original images and\nkeep the compressed images instead without noticeable loss of classification\naccuracy. We propose a cost function whose minimization can be interpreted as\nrate-distortion optimization in information theory. We also propose quantized\nFisherfaces for facial analysis in QFDA. Our experiments on AT&T face dataset\nand Fashion MNIST dataset show the effectiveness of this subspace learning\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:46:21 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Pasand", "Ali Saheb", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1909.03039", "submitter": "Jonas Kemp", "authors": "Jonas Kemp, Alvin Rajkomar, Andrew M. Dai", "title": "Improved Hierarchical Patient Classification with Language Model\n  Pretraining over Clinical Notes", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - extended\n  abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes in electronic health records contain highly heterogeneous\nwriting styles, including non-standard terminology or abbreviations. Using\nthese notes in predictive modeling has traditionally required preprocessing\n(e.g. taking frequent terms or topic modeling) that removes much of the\nrichness of the source data. We propose a pretrained hierarchical recurrent\nneural network model that parses minimally processed clinical notes in an\nintuitive fashion, and show that it improves performance for discharge\ndiagnosis classification tasks on the Medical Information Mart for Intensive\nCare III (MIMIC-III) dataset, compared to models that treat the notes as an\nunordered collection of terms or that conduct no pretraining. We also apply an\nattribution technique to examples to identify the words that the model uses to\nmake its prediction, and show the importance of the words' nearby context.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:49:56 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 20:04:00 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 02:17:14 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kemp", "Jonas", ""], ["Rajkomar", "Alvin", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1909.03044", "submitter": "Qingyu Chen", "authors": "Qingyu Chen, Jingcheng Du, Sun Kim, W. John Wilbur and Zhiyong Lu", "title": "Deep learning with sentence embeddings pre-trained on biomedical corpora\n  improves the performance of finding similar sentences in electronic medical\n  records", "comments": "15 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing sentence semantics plays a vital role in a range of text mining\napplications. Despite continuous efforts on the development of related datasets\nand models in the general domain, both datasets and models are limited in\nbiomedical and clinical domains. The BioCreative/OHNLP organizers have made the\nfirst attempt to annotate 1,068 sentence pairs from clinical notes and have\ncalled for a community effort to tackle the Semantic Textual Similarity\n(BioCreative/OHNLP STS) challenge. We developed models using traditional\nmachine learning and deep learning approaches. For the post challenge, we focus\non two models: the Random Forest and the Encoder Network. We applied sentence\nembeddings pre-trained on PubMed abstracts and MIMIC-III clinical notes and\nupdated the Random Forest and the Encoder Network accordingly. The official\nresults demonstrated our best submission was the ensemble of eight models. It\nachieved a Person correlation coefficient of 0.8328, the highest performance\namong 13 submissions from 4 teams. For the post challenge, the performance of\nboth Random Forest and the Encoder Network was improved; in particular, the\ncorrelation of the Encoder Network was improved by ~13%. During the challenge\ntask, no end-to-end deep learning models had better performance than machine\nlearning models that take manually-crafted features. In contrast, with the\nsentence embeddings pre-trained on biomedical corpora, the Encoder Network now\nachieves a correlation of ~0.84, which is higher than the original best model.\nThe ensembled model taking the improved versions of the Random Forest and\nEncoder Network as inputs further increased performance to 0.8528. Deep\nlearning models with sentence embeddings pre-trained on biomedical corpora\nachieve the highest performance on the test set.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:56:01 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Chen", "Qingyu", ""], ["Du", "Jingcheng", ""], ["Kim", "Sun", ""], ["Wilbur", "W. John", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1909.03069", "submitter": "Pedram Rooshenas", "authors": "MohamadAli Torkamani, Shiv Shankar, Amirmohammad Rooshenas, Phillip\n  Wallis", "title": "Differential Equation Units: Learning Functional Forms of Activation\n  Functions from Data", "comments": "arXiv admin note: text overlap with arXiv:1905.07685", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep neural networks use simple, fixed activation functions, such as\nsigmoids or rectified linear units, regardless of domain or network structure.\nWe introduce differential equation units (DEUs), an improvement to modern\nneural networks, which enables each neuron to learn a particular nonlinear\nactivation function from a family of solutions to an ordinary differential\nequation. Specifically, each neuron may change its functional form during\ntraining based on the behavior of the other parts of the network. We show that\nusing neurons with DEU activation functions results in a more compact network\ncapable of achieving comparable, if not superior, performance when is compared\nto much larger networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:06:15 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Torkamani", "MohamadAli", ""], ["Shankar", "Shiv", ""], ["Rooshenas", "Amirmohammad", ""], ["Wallis", "Phillip", ""]]}, {"id": "1909.03091", "submitter": "Behnaz Akbarian", "authors": "Behnaz Akbarian, Abbas Erfanian", "title": "A framework for seizure detection using effective connectivity, graph\n  theory and deep modular neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective\n  The electrical characteristics of the EEG signals can be used for seizure\ndetection. Statistical independence between different brain regions is measured\nby functional brain connectivity (FBC). Specific directional effects can't\nconsider by FBC and thus effective brain connectivity (EBC) is used to measure\ncausal intervention between one neuronal region and the rest of the neuronal\nregions. Our main purpose is to provide a reliable automatic seizure detection\napproach.\n  Methods\n  In this study, three new methods are provided. Deep modular neural network\n(DMNN) is developed based on a combination of various EBC classification\nresults in the different frequencies. Another method is named \"modular\neffective neural networks (MENN)\". This method combines the classification\nresults of the three different EBC in the specific frequency. \"Modular\nfrequency neural networks (MFNN)\" is another method that combines the\nclassification results of the specific EBC in the seven different frequencies.\n  Results\n  The mean accuracy of the MFNN are 97.14%, 98.53%, and 97.91% using directed\ntransfer function, directed coherence, and generalized partial directed\ncoherence, respectively. Using the MENN, the highest mean accuracy is 98.34%.\nFinally, DMNN has the highest mean accuracy which is equal to 99.43. To our\nbest knowledge, the proposed method is a new method that provides the high\naccuracy in comparison to other studies which used MIT-CHB database.\n  Conclusion and significance\n  The knowledge of structure-function relationships between different areas of\nthe brain is necessary for characterizing the underlying dynamics. Hence,\nfeatures based on EBC can provide a reliable automatic seizure detection\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:01:08 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Akbarian", "Behnaz", ""], ["Erfanian", "Abbas", ""]]}, {"id": "1909.03093", "submitter": "Chieh Wu T", "authors": "Chieh Wu, Jared Miller, Yale Chang, Mario Sznaier, Jennifer Dy", "title": "Solving Interpretable Kernel Dimension Reduction", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel dimensionality reduction (KDR) algorithms find a low dimensional\nrepresentation of the original data by optimizing kernel dependency measures\nthat are capable of capturing nonlinear relationships. The standard strategy is\nto first map the data into a high dimensional feature space using kernels prior\nto a projection onto a low dimensional space. While KDR methods can be easily\nsolved by keeping the most dominant eigenvectors of the kernel matrix, its\nfeatures are no longer easy to interpret. Alternatively, Interpretable KDR\n(IKDR) is different in that it projects onto a subspace \\textit{before} the\nkernel feature mapping, therefore, the projection matrix can indicate how the\noriginal features linearly combine to form the new features. Unfortunately, the\nIKDR objective requires a non-convex manifold optimization that is difficult to\nsolve and can no longer be solved by eigendecomposition. Recently, an efficient\niterative spectral (eigendecomposition) method (ISM) has been proposed for this\nobjective in the context of alternative clustering. However, ISM only provides\ntheoretical guarantees for the Gaussian kernel. This greatly constrains ISM's\nusage since any kernel method using ISM is now limited to a single kernel. This\nwork extends the theoretical guarantees of ISM to an entire family of kernels,\nthereby empowering ISM to solve any kernel method of the same objective. In\nidentifying this family, we prove that each kernel within the family has a\nsurrogate $\\Phi$ matrix and the optimal projection is formed by its most\ndominant eigenvectors. With this extension, we establish how a wide range of\nIKDR applications across different learning paradigms can be solved by ISM. To\nsupport reproducible results, the source code is made publicly available on\n\\url{https://github.com/chieh-neu/ISM_supervised_DR}.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:11:45 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 14:01:55 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 16:51:47 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wu", "Chieh", ""], ["Miller", "Jared", ""], ["Chang", "Yale", ""], ["Sznaier", "Mario", ""], ["Dy", "Jennifer", ""]]}, {"id": "1909.03115", "submitter": "Milena \\v{C}uki\\'c Dr", "authors": "Milena \\v{C}uki\\'c Radenkovi\\'c and Victoria Lopez Lopez", "title": "Machine Learning Approaches for Detecting the Depression from\n  Resting-State Electroencephalogram (EEG): A Review Study", "comments": "30 pages, 1 table. arXiv admin note: substantial text overlap with\n  arXiv1903.11454", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aimed at reviewing present literature on employing\nnonlinear analysis in combination with machine learning methods, in depression\ndetection or prediction task. We are focusing on an affordable data-driven\napproach, applicable for everyday clinical practice, and in particular, those\nbased on electroencephalographic (EEG) recordings. Among those studies\nutilizing EEG, we are discussing a group of applications used for detecting the\ndepression based on the resting state EEG (detection studies) and\ninterventional studies (using stimulus in their protocols or aiming to predict\nthe outcome of therapy). We conclude with a discussion and review of guidelines\nto improve the reliability of developed models that could serve the improvement\nof diagnostic and more accurate treatment of depression.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:11:38 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Radenkovi\u0107", "Milena \u010cuki\u0107", ""], ["Lopez", "Victoria Lopez", ""]]}, {"id": "1909.03118", "submitter": "Jianjun Yuan", "authors": "Jianjun Yuan and Andrew Lamperski", "title": "Trading-Off Static and Dynamic Regret in Online Least-Squares and Beyond", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive least-squares algorithms often use forgetting factors as a\nheuristic to adapt to non-stationary data streams. The first contribution of\nthis paper rigorously characterizes the effect of forgetting factors for a\nclass of online Newton algorithms. For exp-concave and strongly convex\nobjectives, the algorithms achieve the dynamic regret of $\\max\\{O(\\log\nT),O(\\sqrt{TV})\\}$, where $V$ is a bound on the path length of the comparison\nsequence. In particular, we show how classic recursive least-squares with a\nforgetting factor achieves this dynamic regret bound. By varying $V$, we obtain\na trade-off between static and dynamic regret. In order to obtain more\ncomputationally efficient algorithms, our second contribution is a novel\ngradient descent step size rule for strongly convex functions. Our gradient\ndescent rule recovers the order optimal dynamic regret bounds described above.\nFor smooth problems, we can also obtain static regret of $O(T^{1-\\beta})$ and\ndynamic regret of $O(T^\\beta V^*)$, where $\\beta \\in (0,1)$ and $V^*$ is the\npath length of the sequence of minimizers. By varying $\\beta$, we obtain a\ntrade-off between static and dynamic regret.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:28:00 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 08:09:22 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Yuan", "Jianjun", ""], ["Lamperski", "Andrew", ""]]}, {"id": "1909.03166", "submitter": "Vivek Gupta", "authors": "Vivek Gupta, Pegah Nokhiz, Chitradeep Dutta Roy, Suresh\n  Venkatasubramanian", "title": "Equalizing Recourse across Groups", "comments": "13 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise in machine learning-assisted decision-making has led to concerns\nabout the fairness of the decisions and techniques to mitigate problems of\ndiscrimination. If a negative decision is made about an individual (denying a\nloan, rejecting an application for housing, and so on) justice dictates that we\nbe able to ask how we might change circumstances to get a favorable decision\nthe next time. Moreover, the ability to change circumstances (a better\neducation, improved credentials) should not be limited to only those with\naccess to expensive resources. In other words, \\emph{recourse} for negative\ndecisions should be considered a desirable value that can be equalized across\n(demographically defined) groups. This paper describes how to build models that\nmake accurate predictions while still ensuring that the penalties for a\nnegative outcome do not disadvantage different groups disproportionately. We\nmeasure recourse as the distance of an individual from the decision boundary of\na classifier. We then introduce a regularized objective to minimize the\ndifference in recourse across groups. We explore linear settings and further\nextend recourse to non-linear settings as well as model-agnostic settings where\nthe exact distance from boundary cannot be calculated. Our results show that we\ncan successfully decrease the unfairness in recourse while maintaining\nclassifier performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 01:50:06 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gupta", "Vivek", ""], ["Nokhiz", "Pegah", ""], ["Roy", "Chitradeep Dutta", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1909.03172", "submitter": "Tianyi Liu", "authors": "Mo Zhou, Tianyi Liu, Yan Li, Dachao Lin, Enlu Zhou and Tuo Zhao", "title": "Towards Understanding the Importance of Noise in Training Neural\n  Networks", "comments": "International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous empirical evidence has corroborated that the noise plays a crucial\nrule in effective and efficient training of neural networks. The theory behind,\nhowever, is still largely unknown. This paper studies this fundamental problem\nthrough training a simple two-layer convolutional neural network model.\nAlthough training such a network requires solving a nonconvex optimization\nproblem with a spurious local optimum and a global optimum, we prove that\nperturbed gradient descent and perturbed mini-batch stochastic gradient\nalgorithms in conjunction with noise annealing is guaranteed to converge to a\nglobal optimum in polynomial time with arbitrary initialization. This implies\nthat the noise enables the algorithm to efficiently escape from the spurious\nlocal optimum. Numerical experiments are provided to support our theory.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 02:36:46 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Mo", ""], ["Liu", "Tianyi", ""], ["Li", "Yan", ""], ["Lin", "Dachao", ""], ["Zhou", "Enlu", ""], ["Zhao", "Tuo", ""]]}, {"id": "1909.03184", "submitter": "Kaixiong Zhou", "authors": "Kaixiong Zhou, Qingquan Song, Xiao Huang, Xia Hu", "title": "Auto-GNN: Neural Architecture Search of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) has been successfully applied to operate on the\ngraph-structured data. Given a specific scenario, rich human expertise and\ntremendous laborious trials are usually required to identify a suitable GNN\narchitecture. It is because the performance of a GNN architecture is\nsignificantly affected by the choice of graph convolution components, such as\naggregate function and hidden dimension. Neural architecture search (NAS) has\nshown its potential in discovering effective deep architectures for learning\ntasks in image and language modeling. However, existing NAS algorithms cannot\nbe directly applied to the GNN search problem. First, the search space of GNN\nis different from the ones in existing NAS work. Second, the representation\nlearning capacity of GNN architecture changes obviously with slight\narchitecture modifications. It affects the search efficiency of traditional\nsearch methods. Third, widely used techniques in NAS such as parameter sharing\nmight become unstable in GNN.\n  To bridge the gap, we propose the automated graph neural networks (AGNN)\nframework, which aims to find an optimal GNN architecture within a predefined\nsearch space. A reinforcement learning based controller is designed to greedily\nvalidate architectures via small steps. AGNN has a novel parameter sharing\nstrategy that enables homogeneous architectures to share parameters, based on a\ncarefully-designed homogeneity definition. Experiments on real-world benchmark\ndatasets demonstrate that the GNN architecture identified by AGNN achieves the\nbest performance, comparing with existing handcrafted models and tradistional\nsearch methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 04:10:41 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 01:14:33 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Zhou", "Kaixiong", ""], ["Song", "Qingquan", ""], ["Huang", "Xiao", ""], ["Hu", "Xia", ""]]}, {"id": "1909.03194", "submitter": "Wenbo Ren", "authors": "Wenbo Ren, Jia Liu, Ness B. Shroff", "title": "On Sample Complexity Upper and Lower Bounds for Exact Ranking from Noisy\n  Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of finding the exact ranking from noisy\ncomparisons. A comparison over a set of $m$ items produces a noisy outcome\nabout the most preferred item, and reveals some information about the ranking.\nBy repeatedly and adaptively choosing items to compare, we want to fully rank\nthe items with a certain confidence, and use as few comparisons as possible.\nDifferent from most previous works, in this paper, we have three main\nnovelties: (i) compared to prior works, our upper bounds (algorithms) and lower\nbounds on the sample complexity (aka number of comparisons) require the minimal\nassumptions on the instances, and are not restricted to specific models; (ii)\nwe give lower bounds and upper bounds on instances with unequal noise levels;\nand (iii) this paper aims at the exact ranking without knowledge on the\ninstances, while most of the previous works either focus on approximate\nrankings or study exact ranking but require prior knowledge. We first derive\nlower bounds for pairwise ranking (i.e., compare two items each time), and then\npropose (nearly) optimal pairwise ranking algorithms. We further make\nextensions to listwise ranking (i.e., comparing multiple items each time).\nNumerical results also show our improvements against the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 06:13:33 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 19:49:00 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 05:59:32 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ren", "Wenbo", ""], ["Liu", "Jia", ""], ["Shroff", "Ness B.", ""]]}, {"id": "1909.03198", "submitter": "Wenjie Shi", "authors": "Wenjie Shi, Shiji Song and Cheng Wu", "title": "Soft Policy Gradient Method for Maximum Entropy Deep Reinforcement\n  Learning", "comments": "to be published in Proceedings of the Twenty-Eighth International\n  Joint Conference on Artificial Intelligence (IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum entropy deep reinforcement learning (RL) methods have been\ndemonstrated on a range of challenging continuous tasks. However, existing\nmethods either suffer from severe instability when training on large off-policy\ndata or cannot scale to tasks with very high state and action dimensionality\nsuch as 3D humanoid locomotion. Besides, the optimality of desired Boltzmann\npolicy set for non-optimal soft value function is not persuasive enough. In\nthis paper, we first derive soft policy gradient based on entropy regularized\nexpected reward objective for RL with continuous actions. Then, we present an\noff-policy actor-critic, model-free maximum entropy deep RL algorithm called\ndeep soft policy gradient (DSPG) by combining soft policy gradient with soft\nBellman equation. To ensure stable learning while eliminating the need of two\nseparate critics for soft value functions, we leverage double sampling approach\nto making the soft Bellman equation tractable. The experimental results\ndemonstrate that our method outperforms in performance over off-policy prior\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 06:53:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shi", "Wenjie", ""], ["Song", "Shiji", ""], ["Wu", "Cheng", ""]]}, {"id": "1909.03200", "submitter": "Sunghoon Hong", "authors": "Wonsup Shin, Hyolim Kang, Sunghoon Hong", "title": "Mature GAIL: Imitation Learning for Low-level and High-dimensional Input\n  using Global Encoder and Cost Transformation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, GAIL framework and various variants have shown remarkable\npossibilities for solving practical MDP problems. However, detailed researches\nof low-level, and high-dimensional state input in this framework, such as image\nsequences, has not been conducted. Furthermore, the cost function learned in\nthe traditional GAIL frame-work only lies on a negative range, acting as a\nnon-penalized reward and making the agent difficult to learn the optimal\npolicy. In this paper, we propose a new algorithm based on the GAIL framework\nthat includes a global encoder and the reward penalization mechanism. The\nglobal encoder solves two issues that arise when applying GAIL framework to\nhigh-dimensional image state. Also, it is shown that the penalization mechanism\nprovides more adequate reward to the agent, resulting in stable performance\nimprovement. Our approach's potential can be backed up by the fact that it is\ngenerally applicable to variants of GAIL framework. We conducted in-depth\nexperiments by applying our methods to various variants of the GAIL framework.\nAnd, the results proved that our method significantly improves the performances\nwhen it comes to low-level and high-dimensional tasks.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 07:01:59 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shin", "Wonsup", ""], ["Kang", "Hyolim", ""], ["Hong", "Sunghoon", ""]]}, {"id": "1909.03204", "submitter": "Wenjie Shi", "authors": "Wenjie Shi, Shiji Song, Cheng Wu and C. L. Philip Chen", "title": "Multi Pseudo Q-learning Based Deterministic Policy Gradient for Tracking\n  Control of Autonomous Underwater Vehicles", "comments": "IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates trajectory tracking problem for a class of\nunderactuated autonomous underwater vehicles (AUVs) with unknown dynamics and\nconstrained inputs. Different from existing policy gradient methods which\nemploy single actor-critic but cannot realize satisfactory tracking control\naccuracy and stable learning, our proposed algorithm can achieve high-level\ntracking control accuracy of AUVs and stable learning by applying a hybrid\nactors-critics architecture, where multiple actors and critics are trained to\nlearn a deterministic policy and action-value function, respectively.\nSpecifically, for the critics, the expected absolute Bellman error based\nupdating rule is used to choose the worst critic to be updated in each time\nstep. Subsequently, to calculate the loss function with more accurate target\nvalue for the chosen critic, Pseudo Q-learning, which uses sub-greedy policy to\nreplace the greedy policy in Q-learning, is developed for continuous action\nspaces, and Multi Pseudo Q-learning (MPQ) is proposed to reduce the\noverestimation of action-value function and to stabilize the learning. As for\nthe actors, deterministic policy gradient is applied to update the weights, and\nthe final learned policy is defined as the average of all actors to avoid large\nbut bad updates. Moreover, the stability analysis of the learning is given\nqualitatively. The effectiveness and generality of the proposed MPQ-based\nDeterministic Policy Gradient (MPQ-DPG) algorithm are verified by the\napplication on AUV with two different reference trajectories. And the results\ndemonstrate high-level tracking control accuracy and stable learning of\nMPQ-DPG. Besides, the results also validate that increasing the number of the\nactors and critics will further improve the performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 07:18:41 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shi", "Wenjie", ""], ["Song", "Shiji", ""], ["Wu", "Cheng", ""], ["Chen", "C. L. Philip", ""]]}, {"id": "1909.03209", "submitter": "Ying Wei", "authors": "Ying Wei, Peilin Zhao, Huaxiu Yao, Junzhou Huang", "title": "Transferable Neural Processes for Hyperparameter Optimization", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning aims to automate the whole process of machine\nlearning, including model configuration. In this paper, we focus on automated\nhyperparameter optimization (HPO) based on sequential model-based optimization\n(SMBO). Though conventional SMBO algorithms work well when abundant HPO trials\nare available, they are far from satisfactory in practical applications where a\ntrial on a huge dataset may be so costly that an optimal hyperparameter\nconfiguration is expected to return in as few trials as possible. Observing\nthat human experts draw on their expertise in a machine learning model by\ntrying configurations that once performed well on other datasets, we are\ninspired to speed up HPO by transferring knowledge from historical HPO trials\non other datasets. We propose an end-to-end and efficient HPO algorithm named\nas Transfer Neural Processes (TNP), which achieves transfer learning by\nincorporating trials on other datasets, initializing the model with\nwell-generalized parameters, and learning an initial set of hyperparameters to\nevaluate. Experiments on extensive OpenML datasets and three computer vision\ndatasets show that the proposed model can achieve state-of-the-art performance\nin at least one order of magnitude less trials.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 08:10:08 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 04:41:24 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wei", "Ying", ""], ["Zhao", "Peilin", ""], ["Yao", "Huaxiu", ""], ["Huang", "Junzhou", ""]]}, {"id": "1909.03211", "submitter": "Deli Chen", "authors": "Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, Xu Sun", "title": "Measuring and Relieving the Over-smoothing Problem for Graph Neural\n  Networks from the Topological View", "comments": "Accepted by AAAI 2020. This complete version contains the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have achieved promising performance on a wide\nrange of graph-based tasks. Despite their success, one severe limitation of\nGNNs is the over-smoothing issue (indistinguishable representations of nodes in\ndifferent classes). In this work, we present a systematic and quantitative\nstudy on the over-smoothing issue of GNNs. First, we introduce two quantitative\nmetrics, MAD and MADGap, to measure the smoothness and over-smoothness of the\ngraph nodes representations, respectively. Then, we verify that smoothing is\nthe nature of GNNs and the critical factor leading to over-smoothness is the\nlow information-to-noise ratio of the message received by the nodes, which is\npartially determined by the graph topology. Finally, we propose two methods to\nalleviate the over-smoothing issue from the topological view: (1) MADReg which\nadds a MADGap-based regularizer to the training objective;(2) AdaGraph which\noptimizes the graph topology based on the model predictions. Extensive\nexperiments on 7 widely-used graph datasets with 10 typical GNN models show\nthat the two proposed methods are effective for relieving the over-smoothing\nissue, thus improving the performance of various GNN models.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 08:14:41 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 13:53:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chen", "Deli", ""], ["Lin", "Yankai", ""], ["Li", "Wei", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Sun", "Xu", ""]]}, {"id": "1909.03212", "submitter": "Praneet Dutta", "authors": "Praneet Dutta, Man Kit (Joe) Cheuk, Jonathan S Kim, Massimo Mascaro", "title": "AutoML for Contextual Bandits", "comments": "To be presented at the REVEAL Workshop at the ACM RecSys Conference\n  Copenhagen'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Contextual Bandits is one of the widely popular techniques used in\napplications such as personalization, recommendation systems, mobile health,\ncausal marketing etc . As a dynamic approach, it can be more efficient than\nstandard A/B testing in minimizing regret. We propose an end to end automated\nmeta-learning pipeline to approximate the optimal Q function for contextual\nbandits problems. We see that our model is able to perform much better than\nrandom exploration, being more regret efficient and able to converge with a\nlimited number of samples, while remaining very general and easy to use due to\nthe meta-learning approach. We used a linearly annealed e-greedy exploration\npolicy to define the exploration vs exploitation schedule. We tested the system\non a synthetic environment to characterize it fully and we evaluated it on some\nopen source datasets to benchmark against prior work. We see that our model\noutperforms or performs comparatively to other models while requiring no tuning\nnor feature engineering.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 08:18:03 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Dutta", "Praneet", "", "Joe"], ["Kit", "Man", "", "Joe"], ["Cheuk", "", ""], ["Kim", "Jonathan S", ""], ["Mascaro", "Massimo", ""]]}, {"id": "1909.03228", "submitter": "Yu He", "authors": "Yu He and Yangqiu Song and Jianxin Li and Cheng Ji and Jian Peng and\n  Hao Peng", "title": "HeteSpaceyWalk: A Heterogeneous Spacey Random Walk for Heterogeneous\n  Information Network Embedding", "comments": "CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous information network (HIN) embedding has gained increasing\ninterests recently. However, the current way of random-walk based HIN embedding\nmethods have paid few attention to the higher-order Markov chain nature of\nmeta-path guided random walks, especially to the stationarity issue. In this\npaper, we systematically formalize the meta-path guided random walk as a\nhigher-order Markov chain process, and present a heterogeneous personalized\nspacey random walk to efficiently and effectively attain the expected\nstationary distribution among nodes. Then we propose a generalized scalable\nframework to leverage the heterogeneous personalized spacey random walk to\nlearn embeddings for multiple types of nodes in an HIN guided by a meta-path, a\nmeta-graph, and a meta-schema respectively. We conduct extensive experiments in\nseveral heterogeneous networks and demonstrate that our methods substantially\noutperform the existing state-of-the-art network embedding algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 09:46:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["He", "Yu", ""], ["Song", "Yangqiu", ""], ["Li", "Jianxin", ""], ["Ji", "Cheng", ""], ["Peng", "Jian", ""], ["Peng", "Hao", ""]]}, {"id": "1909.03242", "submitter": "Isabelle Augenstein", "authors": "Isabelle Augenstein and Christina Lioma and Dongsheng Wang and Lucas\n  Chaves Lima and Casper Hansen and Christian Hansen and Jakob Grue Simonsen", "title": "MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact\n  Checking of Claims", "comments": "Proceedings of EMNLP 2019, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contribute the largest publicly available dataset of naturally occurring\nfactual claims for the purpose of automatic claim verification. It is collected\nfrom 26 fact checking websites in English, paired with textual sources and rich\nmetadata, and labelled for veracity by human expert journalists. We present an\nin-depth analysis of the dataset, highlighting characteristics and challenges.\nFurther, we present results for automatic veracity prediction, both with\nestablished baselines and with a novel method for joint ranking of evidence\npages and predicting veracity that outperforms all baselines. Significant\nperformance increases are achieved by encoding evidence, and by modelling\nmetadata. Our best-performing model achieves a Macro F1 of 49.2%, showing that\nthis is a challenging testbed for claim veracity prediction.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 10:57:29 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 15:51:53 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Augenstein", "Isabelle", ""], ["Lioma", "Christina", ""], ["Wang", "Dongsheng", ""], ["Lima", "Lucas Chaves", ""], ["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Simonsen", "Jakob Grue", ""]]}, {"id": "1909.03245", "submitter": "Wenjie Shi", "authors": "Wenjie Shi, Shiji Song, Hui Wu, Ya-Chu Hsu, Cheng Wu, Gao Huang", "title": "Regularized Anderson Acceleration for Off-Policy Deep Reinforcement\n  Learning", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) algorithms have been widely used\nfor a range of complex control tasks. However, slow convergence and sample\ninefficiency remain challenging problems in RL, especially when handling\ncontinuous and high-dimensional state spaces. To tackle this problem, we\npropose a general acceleration method for model-free, off-policy deep RL\nalgorithms by drawing the idea underlying regularized Anderson acceleration\n(RAA), which is an effective approach to accelerating the solving of fixed\npoint problems with perturbations. Specifically, we first explain how policy\niteration can be applied directly with Anderson acceleration. Then we extend\nRAA to the case of deep RL by introducing a regularization term to control the\nimpact of perturbation induced by function approximation errors. We further\npropose two strategies, i.e., progressive update and adaptive restart, to\nenhance the performance. The effectiveness of our method is evaluated on a\nvariety of benchmark tasks, including Atari 2600 and MuJoCo. Experimental\nresults show that our approach substantially improves both the learning speed\nand final performance of state-of-the-art deep RL algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 11:18:32 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 01:11:40 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Shi", "Wenjie", ""], ["Song", "Shiji", ""], ["Wu", "Hui", ""], ["Hsu", "Ya-Chu", ""], ["Wu", "Cheng", ""], ["Huang", "Gao", ""]]}, {"id": "1909.03253", "submitter": "Navid Alemi Koohbanani", "authors": "Mostafa Jahanifar, Navid Alemi Koohbanani, and Nasir Rajpoot", "title": "NuClick: From Clicks in the Nuclei to Nuclear Boundaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Best performing nuclear segmentation methods are based on deep learning\nalgorithms that require a large amount of annotated data. However, collecting\nannotations for nuclear segmentation is a very labor-intensive and\ntime-consuming task. Thereby, providing a tool that can facilitate and speed up\nthis procedure is very demanding. Here we propose a simple yet efficient\nframework based on convolutional neural networks, named NuClick, which can\nprecisely segment nuclei boundaries by accepting a single point position (or\nclick) inside each nucleus. Based on the clicked positions, inclusion and\nexclusion maps are generated which comprise 2D Gaussian distributions centered\non those positions. These maps serve as guiding signals for the network as they\nare concatenated to the input image. The inclusion map focuses on the desired\nnucleus while the exclusion map indicates neighboring nuclei and improve the\nresults of segmentation in scenes with nuclei clutter. The NuClick not only\nfacilitates collecting more annotation from unseen data but also leads to\nsuperior segmentation output for deep models. It is also worth mentioning that\nan instance segmentation model trained on NuClick generated labels was able to\nrank first in LYON19 challenge.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 11:52:19 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Jahanifar", "Mostafa", ""], ["Koohbanani", "Navid Alemi", ""], ["Rajpoot", "Nasir", ""]]}, {"id": "1909.03261", "submitter": "Riccardo Volpato", "authors": "Riccardo Volpato and Guangyan Song", "title": "Active learning to optimise time-expensive algorithm selection", "comments": "11 pages, 3 figures, 3 tables and 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard optimisation problems such as Boolean Satisfiability typically have long\nsolving times and can usually be solved by many algorithms, although the\nperformance can vary widely in practice. Research has shown that no single\nalgorithm outperforms all the others; thus, it is crucial to select the best\nalgorithm for a given problem. Supervised machine learning models can\naccurately predict which solver is best for a given problem, but they require\nfirst to run every solver in the portfolio for all examples available to create\nlabelled data. As this approach cannot scale, we developed an active learning\nframework that addresses this problem by constructing an optimal training set,\nso that the learner can achieve higher or equal performances with less training\ndata. Our work proves that active learning is beneficial for algorithm\nselection techniques and provides practical guidance to incorporate into\nexisting systems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 12:33:31 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Volpato", "Riccardo", ""], ["Song", "Guangyan", ""]]}, {"id": "1909.03267", "submitter": "Gerlind Plonka", "authors": "Renato Budinich, Gerlind Plonka", "title": "A Tree-based Dictionary Learning Framework", "comments": null, "journal-ref": "International Journal of Wavelets, Multiresolution and Information\n  Processing (2020) 2050041 (24 pages)", "doi": "10.1142/S0219691320500411", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new outline for adaptive dictionary learning methods for sparse\nencoding based on a hierarchical clustering of the training data. Through\nrecursive application of a clustering method, the data is organized into a\nbinary partition tree representing a multiscale structure. The dictionary atoms\nare defined adaptively based on the data clusters in the partition tree. This\napproach can be interpreted as a generalization of a discrete Haar wavelet\ntransform. Furthermore, any prior knowledge on the wanted structure of the\ndictionary elements can be simply incorporated. The computational complexity of\nour proposed algorithm depends on the employed clustering method and on the\nchosen similarity measure between data points. Thanks to the multiscale\nproperties of the partition tree, our dictionary is structured: when using\nOrthogonal Matching Pursuit to reconstruct patches from a natural image,\ndictionary atoms corresponding to nodes being closer to the root node in the\ntree have a tendency to be used with greater coefficients.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 13:48:23 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 15:55:31 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Budinich", "Renato", ""], ["Plonka", "Gerlind", ""]]}, {"id": "1909.03276", "submitter": "Weiyu Cheng", "authors": "Weiyu Cheng, Yanyan Shen, Linpeng Huang", "title": "Adaptive Factorization Network: Learning Adaptive-Order Feature\n  Interactions", "comments": "Accepted by AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various factorization-based methods have been proposed to leverage\nsecond-order, or higher-order cross features for boosting the performance of\npredictive models. They generally enumerate all the cross features under a\npredefined maximum order, and then identify useful feature interactions through\nmodel training, which suffer from two drawbacks. First, they have to make a\ntrade-off between the expressiveness of higher-order cross features and the\ncomputational cost, resulting in suboptimal predictions. Second, enumerating\nall the cross features, including irrelevant ones, may introduce noisy feature\ncombinations that degrade model performance. In this work, we propose the\nAdaptive Factorization Network (AFN), a new model that learns arbitrary-order\ncross features adaptively from data. The core of AFN is a logarithmic\ntransformation layer to convert the power of each feature in a feature\ncombination into the coefficient to be learned. The experimental results on\nfour real datasets demonstrate the superior predictive performance of AFN\nagainst the start-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 14:30:43 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 02:05:51 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cheng", "Weiyu", ""], ["Shen", "Yanyan", ""], ["Huang", "Linpeng", ""]]}, {"id": "1909.03287", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Luigi Di Sotto", "title": "A Non-Negative Factorization approach to node pooling in Graph\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper discusses a pooling mechanism to induce subsampling in graph\nstructured data and introduces it as a component of a graph convolutional\nneural network. The pooling mechanism builds on the Non-Negative Matrix\nFactorization (NMF) of a matrix representing node adjacency and node similarity\nas adaptively obtained through the vertices embedding learned by the model.\nSuch mechanism is applied to obtain an incrementally coarser graph where nodes\nare adaptively pooled into communities based on the outcomes of the\nnon-negative factorization. The empirical analysis on graph classification\nbenchmarks shows how such coarsening process yields significant improvements in\nthe predictive performance of the model with respect to its non-pooled\ncounterpart.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 15:27:49 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Bacciu", "Davide", ""], ["Di Sotto", "Luigi", ""]]}, {"id": "1909.03302", "submitter": "Tong Li", "authors": "Tong Li and Ming Yuan", "title": "On the Optimality of Gaussian Kernel Based Nonparametric Tests against\n  Smooth Alternatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric tests via kernel embedding of distributions have witnessed a\ngreat deal of practical successes in recent years. However, statistical\nproperties of these tests are largely unknown beyond consistency against a\nfixed alternative. To fill in this void, we study here the asymptotic\nproperties of goodness-of-fit, homogeneity and independence tests using\nGaussian kernels, arguably the most popular and successful among such tests.\nOur results provide theoretical justifications for this common practice by\nshowing that tests using Gaussian kernel with an appropriately chosen scaling\nparameter are minimax optimal against smooth alternatives in all three\nsettings. In addition, our analysis also pinpoints the importance of choosing a\ndiverging scaling parameter when using Gaussian kernels and suggests a\ndata-driven choice of the scaling parameter that yields tests optimal, up to an\niterated logarithmic factor, over a wide range of smooth alternatives.\nNumerical experiments are also presented to further demonstrate the practical\nmerits of the methodology.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 16:43:20 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Li", "Tong", ""], ["Yuan", "Ming", ""]]}, {"id": "1909.03306", "submitter": "Massimiliano Lupo Pasini Dr.", "authors": "Massimiliano Lupo Pasini, Junqi Yin, Ying Wai Li, Markus Eisenbach", "title": "A scalable constructive algorithm for the optimization of neural network\n  architectures", "comments": "12 pages, 15 figures, 3 table", "journal-ref": "Parallel Computing, 2021", "doi": "10.1016/j.parco.2021.102788", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new scalable method to optimize the architecture of an\nartificial neural network. The proposed algorithm, called Greedy Search for\nNeural Network Architecture, aims to determine a neural network with minimal\nnumber of layers that is at least as performant as neural networks of the same\nstructure identified by other hyperparameter search algorithms in terms of\naccuracy and computational cost. Numerical results performed on benchmark\ndatasets show that, for these datasets, our method outperforms state-of-the-art\nhyperparameter optimization algorithms in terms of attainable predictive\nperformance by the selected neural network architecture, and time-to-solution\nfor the hyperparameter optimization to complete.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 17:22:28 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 17:26:10 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 14:13:57 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Pasini", "Massimiliano Lupo", ""], ["Yin", "Junqi", ""], ["Li", "Ying Wai", ""], ["Eisenbach", "Markus", ""]]}, {"id": "1909.03316", "submitter": "Susan Meerdink", "authors": "Susan Meerdink, James Bocinsky, Alina Zare, Nicholas Kroeger, Connor\n  McCurley, Daniel Shats, Paul Gader", "title": "Multi-Target Multiple Instance Learning for Hyperspectral Target\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In remote sensing, it is often challenging to acquire or collect a large\ndataset that is accurately labeled. This difficulty is usually due to several\nissues, including but not limited to the study site's spatial area and\naccessibility, errors in the global positioning system (GPS), and mixed pixels\ncaused by an image's spatial resolution. We propose an approach, with two\nvariations, that estimates multiple target signatures from training samples\nwith imprecise labels: Multi-Target Multiple Instance Adaptive Cosine Estimator\n(Multi-Target MI-ACE) and Multi-Target Multiple Instance Spectral Match Filter\n(Multi-Target MI-SMF). The proposed methods address the problems above by\ndirectly considering the multiple-instance, imprecisely labeled dataset. They\nlearn a dictionary of target signatures that optimizes detection against a\nbackground using the Adaptive Cosine Estimator (ACE) and Spectral Match Filter\n(SMF). Experiments were conducted to test the proposed algorithms using a\nsimulated hyperspectral dataset, the MUUFL Gulfport hyperspectral dataset\ncollected over the University of Southern Mississippi-Gulfpark Campus, and the\nAVIRIS hyperspectral dataset collected over Santa Barbara County, California.\nBoth simulated and real hyperspectral target detection experiments show the\nproposed algorithms are effective at learning target signatures and performing\ntarget detection.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 18:30:54 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 16:01:44 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 20:26:23 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Meerdink", "Susan", ""], ["Bocinsky", "James", ""], ["Zare", "Alina", ""], ["Kroeger", "Nicholas", ""], ["McCurley", "Connor", ""], ["Shats", "Daniel", ""], ["Gader", "Paul", ""]]}, {"id": "1909.03332", "submitter": "Zenon Gniazdowski", "authors": "Zenon Gniazdowski and Dawid Kaliszewski", "title": "On the clustering of correlated random variables", "comments": "70 pages, 32 figures", "journal-ref": "Zeszyty Naukowe WWSI, No 18, Vol. 12, 2018, pp. 45-114", "doi": "10.26348/znwwsi.18.45", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, the possibility of clustering correlated random variables was\nexamined, both because of their mutual similarity and because of their\nsimilarity to the principal components. The k-means algorithm and spectral\nalgorithms were used for clustering. For spectral methods, the similarity\nmatrix was both the matrix of relation established on the level of correlation\nand the matrix of coefficients of determination. For four different sets of\ndata, different ways of measuring the disimilarity of variables were analyzed,\nand the impact of the diversity of initial points on the efficiency of the\nk-means algorithm was analyzed.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 20:27:40 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gniazdowski", "Zenon", ""], ["Kaliszewski", "Dawid", ""]]}, {"id": "1909.03334", "submitter": "Uyeong Jang", "authors": "Uyeong Jang, Susmit Jha, Somesh Jha", "title": "On the Need for Topology-Aware Generative Models for Manifold-Based\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning (ML) algorithms or models, especially deep neural networks\n(DNNs), have shown significant promise in several areas. However, researchers\nhave recently demonstrated that ML algorithms, especially DNNs, are vulnerable\nto adversarial examples (slightly perturbed samples that cause\nmisclassification). The existence of adversarial examples has hindered the\ndeployment of ML algorithms in safety-critical sectors, such as security.\nSeveral defenses for adversarial examples exist in the literature. One of the\nimportant classes of defenses are manifold-based defenses, where a sample is\n``pulled back\" into the data manifold before classifying. These defenses rely\non the assumption that data lie in a manifold of a lower dimension than the\ninput space. These defenses use a generative model to approximate the input\ndistribution. In this paper, we investigate the following question: do the\ngenerative models used in manifold-based defenses need to be topology-aware? We\nsuggest the answer is yes, and we provide theoretical and empirical evidence to\nsupport our claim.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 20:36:17 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:53:23 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 22:52:08 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 21:20:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jang", "Uyeong", ""], ["Jha", "Susmit", ""], ["Jha", "Somesh", ""]]}, {"id": "1909.03347", "submitter": "Arash Ali Amini", "authors": "Arash A. Amini and Zahra S. Razaee", "title": "Concentration of kernel matrices with application to kernel spectral\n  clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the concentration of random kernel matrices around their mean. We\nderive nonasymptotic exponential concentration inequalities for Lipschitz\nkernels assuming that the data points are independent draws from a class of\nmultivariate distributions on $\\mathbb R^d$, including the strongly log-concave\ndistributions under affine transformations. A feature of our result is that the\ndata points need not have identical distributions or zero mean, which is key in\ncertain applications such as clustering. Our bound for the Lipschitz kernels is\ndimension-free and sharp up to constants. For comparison, we also derive the\ncompanion result for the Euclidean (inner product) kernel for a class of\nsub-Gaussian distributions. A notable difference between the two cases is that,\nin contrast to the Euclidean kernel, in the Lipschitz case, the concentration\ninequality does not depend on the mean of the underlying vectors. As an\napplication of these inequalities, we derive a bound on the misclassification\nrate of a kernel spectral clustering (KSC) algorithm, under a perturbed\nnonparametric mixture model. We show an example where this bound establishes\nthe high-dimensional consistency (as $d \\to \\infty$) of the KSC, when applied\nwith a Gaussian kernel, to a noisy model of nested nonlinear manifolds.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 22:56:55 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 08:25:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Amini", "Arash A.", ""], ["Razaee", "Zahra S.", ""]]}, {"id": "1909.03359", "submitter": "Gurbinder Gill", "authors": "Gurbinder Gill (1), Roshan Dathathri (1), Saeed Maleki (2), Madan\n  Musuvathi (2), Todd Mytkowicz (2), Olli Saarikivi (2) ((1) The University of\n  Texas at Austin, (2) Microsoft Research)", "title": "Distributed Training of Embeddings using Graph Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications today, such as NLP, network analysis, and code analysis,\nrely on semantically embedding objects into low-dimensional fixed-length\nvectors. Such embeddings naturally provide a way to perform useful downstream\ntasks, such as identifying relations among objects or predicting objects for a\ngiven context, etc. Unfortunately, the training necessary for accurate\nembeddings is usually computationally intensive and requires processing large\namounts of data. Furthermore, distributing this training is challenging. Most\nembedding training uses stochastic gradient descent (SGD), an \"inherently\"\nsequential algorithm. Prior approaches to parallelizing SGD do not honor these\ndependencies and thus potentially suffer poor convergence.\n  This paper presents a distributed training framework for a class of\napplications that use Skip-gram-like models to generate embeddings. We call\nthis class Any2Vec and it includes Word2Vec, DeepWalk, and Node2Vec among\nothers. We first formulate Any2Vec training algorithm as a graph application\nand leverage the state-of-the-art distributed graph analytics framework,\nD-Galois. We adapt D-Galois to support dynamic graph generation and\nrepartitioning, and incorporate novel communication optimizations. Finally, we\nintroduce a novel way to combine gradients during distributed training to\nprevent accuracy loss. We show that our framework, called GraphAny2Vec, matches\non a cluster of 32 hosts the accuracy of the state-of-the-art shared-memory\nimplementations of Word2Vec and Vertex2Vec on 1 host, and gives a geo-mean\nspeedup of 12x and 5x respectively. Furthermore, GraphAny2Vec is on average 2x\nfaster than the state-of-the-art distributed Word2Vec implementation, DMTK, on\n32 hosts. We also show the superiority of our Gradient Combiner independent of\nGraphAny2Vec by incorporating it in DMTK, which raises its accuracy by > 30%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 01:06:03 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 00:34:44 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gill", "Gurbinder", ""], ["Dathathri", "Roshan", ""], ["Maleki", "Saeed", ""], ["Musuvathi", "Madan", ""], ["Mytkowicz", "Todd", ""], ["Saarikivi", "Olli", ""]]}, {"id": "1909.03371", "submitter": "Qian Qian", "authors": "Qian Qian and Xiaoyuan Qian", "title": "On the connections between algorithmic regularization and penalization\n  for convex losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we establish the equivalence of algorithmic regularization and\nexplicit convex penalization for generic convex losses. We introduce a\ngeometric condition for the optimization path of a convex function, and show\nthat if such a condition is satisfied, the optimization path of an iterative\nalgorithm on the unregularized optimization problem can be represented as the\nsolution path of a corresponding penalized problem.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 02:29:02 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Qian", "Qian", ""], ["Qian", "Xiaoyuan", ""]]}, {"id": "1909.03388", "submitter": "Yilun Xu", "authors": "Yilun Xu, Peng Cao, Yuqing Kong, Yizhou Wang", "title": "L_DMI: An Information-theoretic Noise-robust Loss Function", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately annotating large scale dataset is notoriously expensive both in\ntime and in money. Although acquiring low-quality-annotated dataset can be much\ncheaper, it often badly damages the performance of trained models when using\nsuch dataset without particular treatment. Various methods have been proposed\nfor learning with noisy labels. However, most methods only handle limited kinds\nof noise patterns, require auxiliary information or steps (e.g. , knowing or\nestimating the noise transition matrix), or lack theoretical justification. In\nthis paper, we propose a novel information-theoretic loss function,\n$\\mathcal{L}_{DMI}$, for training deep neural networks robust to label noise.\nThe core of $\\mathcal{L}_{DMI}$ is a generalized version of mutual information,\ntermed Determinant based Mutual Information (DMI), which is not only\ninformation-monotone but also relatively invariant. \\emph{To the best of our\nknowledge, $\\mathcal{L}_{DMI}$ is the first loss function that is provably\nrobust to instance-independent label noise, regardless of noise pattern, and it\ncan be applied to any existing classification neural networks straightforwardly\nwithout any auxiliary information}. In addition to theoretical justification,\nwe also empirically show that using $\\mathcal{L}_{DMI}$ outperforms all other\ncounterparts in the classification task on both image dataset and natural\nlanguage dataset include Fashion-MNIST, CIFAR-10, Dogs vs. Cats, MR with a\nvariety of synthesized noise patterns and noise amounts, as well as a\nreal-world dataset Clothing1M. Codes are available at\nhttps://github.com/Newbeeer/L_DMI .\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 05:09:45 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 18:16:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Xu", "Yilun", ""], ["Cao", "Peng", ""], ["Kong", "Yuqing", ""], ["Wang", "Yizhou", ""]]}, {"id": "1909.03403", "submitter": "Ziwei Liu", "authors": "Ziwei Liu, Zhongqi Miao, Xingang Pan, Xiaohang Zhan, Dahua Lin, Stella\n  X. Yu, Boqing Gong", "title": "Open Compound Domain Adaptation", "comments": "To appear in CVPR 2020 as an oral presentation. Code, datasets and\n  models are available at:\n  https://liuziwei7.github.io/projects/CompoundDomain.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical domain adaptation approach is to adapt models trained on the\nannotated data in a source domain (e.g., sunny weather) for achieving high\nperformance on the test data in a target domain (e.g., rainy weather). Whether\nthe target contains a single homogeneous domain or multiple heterogeneous\ndomains, existing works always assume that there exist clear distinctions\nbetween the domains, which is often not true in practice (e.g., changes in\nweather). We study an open compound domain adaptation (OCDA) problem, in which\nthe target is a compound of multiple homogeneous domains without domain labels,\nreflecting realistic data collection from mixed and novel situations. We\npropose a new approach based on two technical insights into OCDA: 1) a\ncurriculum domain adaptation strategy to bootstrap generalization across\ndomains in a data-driven self-organizing fashion and 2) a memory module to\nincrease the model's agility towards novel domains. Our experiments on digit\nclassification, facial expression recognition, semantic segmentation, and\nreinforcement learning demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 08:41:05 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 06:00:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Liu", "Ziwei", ""], ["Miao", "Zhongqi", ""], ["Pan", "Xingang", ""], ["Zhan", "Xiaohang", ""], ["Lin", "Dahua", ""], ["Yu", "Stella X.", ""], ["Gong", "Boqing", ""]]}, {"id": "1909.03410", "submitter": "Avik Pal", "authors": "Avik Pal and Aniket Das", "title": "TorchGAN: A Flexible Framework for GAN Training and Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TorchGAN is a PyTorch based framework for writing succinct and comprehensible\ncode for training and evaluation of Generative Adversarial Networks. The\nframework's modular design allows effortless customization of the model\narchitecture, loss functions, training paradigms, and evaluation metrics. The\nkey features of TorchGAN are its extensibility, built-in support for a large\nnumber of popular models, losses and evaluation metrics, and zero overhead\ncompared to vanilla PyTorch. By using the framework to implement several\npopular GAN models, we demonstrate its extensibility and ease of use. We also\nbenchmark the training time of our framework for said models against the\ncorresponding baseline PyTorch implementations and observe that TorchGAN's\nfeatures bear almost zero overhead.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 09:32:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pal", "Avik", ""], ["Das", "Aniket", ""]]}, {"id": "1909.03416", "submitter": "Abdulkadir Celikkanat", "authors": "Abdulkadir \\c{C}elikkanat, Fragkiskos D. Malliaros", "title": "Kernel Node Embeddings", "comments": "Accepted to the 7th IEEE Global Conference on Signal and Information\n  Processing (GlobalSIP), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations of nodes in a low dimensional space is a crucial\ntask with many interesting applications in network analysis, including link\nprediction and node classification. Two popular approaches for this problem\ninclude matrix factorization and random walk-based models. In this paper, we\naim to bring together the best of both worlds, towards learning latent node\nrepresentations. In particular, we propose a weighted matrix factorization\nmodel which encodes random walk-based information about the nodes of the graph.\nThe main benefit of this formulation is that it allows to utilize kernel\nfunctions on the computation of the embeddings. We perform an empirical\nevaluation on real-world networks, showing that the proposed model outperforms\nbaseline node embedding algorithms in two downstream machine learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 09:49:39 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 07:47:34 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["\u00c7elikkanat", "Abdulkadir", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "1909.03418", "submitter": "Asaf Shabtai", "authors": "Gil Fidel, Ron Bitton, Asaf Shabtai", "title": "When Explainability Meets Adversarial Learning: Detecting Adversarial\n  Examples using SHAP Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep neural networks (DNNs) are highly effective in solving\nmany complex real-world problems. However, these models are vulnerable to\nadversarial perturbation attacks, and despite the plethora of research in this\ndomain, to this day, adversaries still have the upper hand in the cat and mouse\ngame of adversarial example generation methods vs. detection and prevention\nmethods. In this research, we present a novel detection method that uses\nShapley Additive Explanations (SHAP) values computed for the internal layers of\na DNN classifier to discriminate between normal and adversarial inputs. We\nevaluate our method by building an extensive dataset of adversarial examples\nover the popular CIFAR-10 and MNIST datasets, and training a neural\nnetwork-based detector to distinguish between normal and adversarial inputs. We\nevaluate our detector against adversarial examples generated by diverse\nstate-of-the-art attacks and demonstrate its high detection accuracy and strong\ngeneralization ability to adversarial inputs generated with different attack\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 10:00:44 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Fidel", "Gil", ""], ["Bitton", "Ron", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1909.03428", "submitter": "Martin Atzmueller", "authors": "Spyroula Masiala and Willem Huijbers and Martin Atzmueller", "title": "Feature-Set-Engineering for Detecting Freezing of Gait in Parkinson's\n  Disease using Deep Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Freezing of gait (FoG) is a common gait disability in Parkinson's disease,\nthat usually appears in its advanced stage. Freeze episodes are associated with\nfalls, injuries, and psychological consequences, negatively affecting the\npatients' quality of life. For detecting FoG episodes automatically, a highly\naccurate detection method is necessary. This paper presents an approach for\ndetecting FoG episodes utilizing a deep recurrent neural network (RNN) on\n3D-accelerometer measurements. We investigate suitable features and feature\ncombinations extracted from the sensors' time series data. Specifically, for\ndetecting FoG episodes, we apply a deep RNN with Long Short-Term Memory cells.\nIn our experiments, we perform both user dependent and user independent\nexperiments, to detect freeze episodes. Our experimental results show that the\nfrequency domain features extracted from the trunk sensor are the most\ninformative feature group in the subject independent method, achieving an\naverage AUC score of 93%, Specificity of 90% and Sensitivity of 81%. Moreover,\nfrequency and statistical features of all the sensors are identified as the\nbest single input for the subject dependent method, achieving an average AUC\nscore of 97%, Specificity of 96% and Sensitivity of 87%. Overall, in a\ncomparison to state-of-the-art approaches from literature as baseline methods,\nour proposed approach outperforms these significantly.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 11:02:50 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Masiala", "Spyroula", ""], ["Huijbers", "Willem", ""], ["Atzmueller", "Martin", ""]]}, {"id": "1909.03433", "submitter": "Xialiang Dou", "authors": "Xialiang Dou, Mihai Anitescu", "title": "Distributionally Robust Optimization with Correlated Data from Vector\n  Autoregressive Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributionally robust formulation of a stochastic optimization\nproblem for non-i.i.d vector autoregressive data. We use the Wasserstein\ndistance to define robustness in the space of distributions and we show, using\nduality theory, that the problem is equivalent to a finite convex-concave\nsaddle point problem. The performance of the method is demonstrated on both\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 11:30:04 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Dou", "Xialiang", ""], ["Anitescu", "Mihai", ""]]}, {"id": "1909.03434", "submitter": "Che-Ping Tsai", "authors": "Che-Ping Tsai and Hung-Yi Lee", "title": "Order-free Learning Alleviating Exposure Bias in Multi-label\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) assigns multiple labels to each sample.\nPrior studies show that MLC can be transformed to a sequence prediction problem\nwith a recurrent neural network (RNN) decoder to model the label dependency.\nHowever, training a RNN decoder requires a predefined order of labels, which is\nnot directly available in the MLC specification. Besides, RNN thus trained\ntends to overfit the label combinations in the training set and have difficulty\ngenerating unseen label sequences. In this paper, we propose a new framework\nfor MLC which does not rely on a predefined label order and thus alleviates\nexposure bias. The experimental results on three multi-label classification\nbenchmark datasets show that our method outperforms competitive baselines by a\nlarge margin. We also find the proposed approach has a higher probability of\ngenerating label combinations not seen during training than the baseline\nmodels. The result shows that the proposed approach has better generalization\ncapability.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 11:53:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tsai", "Che-Ping", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1909.03441", "submitter": "Chieh Wu T", "authors": "Chieh Wu, Stratis Ioannidis, Mario Sznaier, Xiangyu Li, David Kaeli,\n  Jennifer G. Dy", "title": "Iterative Spectral Method for Alternative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset and an existing clustering as input, alternative clustering\naims to find an alternative partition. One of the state-of-the-art approaches\nis Kernel Dimension Alternative Clustering (KDAC). We propose a novel Iterative\nSpectral Method (ISM) that greatly improves the scalability of KDAC. Our\nalgorithm is intuitive, relies on easily implementable spectral decompositions,\nand comes with theoretical guarantees. Its computation time improves upon\nexisting implementations of KDAC by as much as 5 orders of magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 12:15:20 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wu", "Chieh", ""], ["Ioannidis", "Stratis", ""], ["Sznaier", "Mario", ""], ["Li", "Xiangyu", ""], ["Kaeli", "David", ""], ["Dy", "Jennifer G.", ""]]}, {"id": "1909.03442", "submitter": "Ambedkar Dukkipati", "authors": "Sourabh Balgi and Ambedkar Dukkipati", "title": "CUDA: Contradistinguisher for Unsupervised Domain Adaptation", "comments": "International Conference on Data Mining, ICDM 2019", "journal-ref": null, "doi": "10.1109/ICDM.2019.00012", "report-no": "8970790", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple model referred as Contradistinguisher\n(CTDR) for unsupervised domain adaptation whose objective is to jointly learn\nto contradistinguish on unlabeled target domain in a fully unsupervised manner\nalong with prior knowledge acquired by supervised learning on an entirely\ndifferent domain. Most recent works in domain adaptation rely on an indirect\nway of first aligning the source and target domain distributions and then learn\na classifier on a labeled source domain to classify target domain. This\napproach of an indirect way of addressing the real task of unlabeled target\ndomain classification has three main drawbacks. (i) The sub-task of obtaining a\nperfect alignment of the domain in itself might be impossible due to large\ndomain shift (e.g., language domains). (ii) The use of multiple classifiers to\nalign the distributions unnecessarily increases the complexity of the neural\nnetworks leading to over-fitting in many cases. (iii) Due to distribution\nalignment, the domain-specific information is lost as the domains get morphed.\nIn this work, we propose a simple and direct approach that does not require\ndomain alignment. We jointly learn CTDR on both source and target distribution\nfor unsupervised domain adaptation task using contradistinguish loss for the\nunlabeled target domain in conjunction with a supervised loss for labeled\nsource domain. Our experiments show that avoiding domain alignment by directly\naddressing the task of unlabeled target domain classification using CTDR\nachieves state-of-the-art results on eight visual and four language benchmark\ndomain adaptation datasets.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 12:16:33 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Balgi", "Sourabh", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1909.03464", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva, Wouter Kouw, Isabelle Augenstein", "title": "Back to the Future -- Sequential Alignment of Text Representations", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language evolves over time in many ways relevant to natural language\nprocessing tasks. For example, recent occurrences of tokens 'BERT' and 'ELMO'\nin publications refer to neural network architectures rather than persons. This\ntype of temporal signal is typically overlooked, but is important if one aims\nto deploy a machine learning model over an extended period of time. In\nparticular, language evolution causes data drift between time-steps in\nsequential decision-making tasks. Examples of such tasks include prediction of\npaper acceptance for yearly conferences (regular intervals) or author stance\nprediction for rumours on Twitter (irregular intervals). Inspired by successes\nin computer vision, we tackle data drift by sequentially aligning learned\nrepresentations. We evaluate on three challenging tasks varying in terms of\ntime-scales, linguistic units, and domains. These tasks show our method\noutperforming several strong baselines, including using all available data. We\nargue that, due to its low computational expense, sequential alignment is a\npractical solution to dealing with language evolution.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 13:35:12 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:00:30 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 11:55:47 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bjerva", "Johannes", ""], ["Kouw", "Wouter", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1909.03495", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi", "title": "Shapley Values of Reconstruction Errors of PCA for Explaining Anomaly\n  Detection", "comments": "Workshop on Learning and Mining with Industrial Data (LMID) 2019.\n  typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to compute the Shapley values of reconstruction errors of\nprincipal component analysis (PCA), which is particularly useful in explaining\nthe results of anomaly detection based on PCA. Because features are usually\ncorrelated when PCA-based anomaly detection is applied, care must be taken in\ncomputing a value function for the Shapley values. We utilize the probabilistic\nview of PCA, particularly its conditional distribution, to exactly compute a\nvalue function for the Shapely values. We also present numerical examples,\nwhich imply that the Shapley values are advantageous for explaining detected\nanomalies than raw reconstruction errors of each feature.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:09:31 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 08:50:05 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Takeishi", "Naoya", ""]]}, {"id": "1909.03496", "submitter": "Yaqin Zhou", "authors": "Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, Yang Liu", "title": "Devign: Effective Vulnerability Identification by Learning Comprehensive\n  Program Semantics via Graph Neural Networks", "comments": "accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability identification is crucial to protect the software systems from\nattacks for cyber security. It is especially important to localize the\nvulnerable functions among the source code to facilitate the fix. However, it\nis a challenging and tedious process, and also requires specialized security\nexpertise. Inspired by the work on manually-defined patterns of vulnerabilities\nfrom various code representation graphs and the recent advance on graph neural\nnetworks, we propose Devign, a general graph neural network based model for\ngraph-level classification through learning on a rich set of code semantic\nrepresentations. It includes a novel Conv module to efficiently extract useful\nfeatures in the learned rich node representations for graph-level\nclassification. The model is trained over manually labeled datasets built on 4\ndiversified large-scale open-source C projects that incorporate high complexity\nand variety of real source code instead of synthesis code used in previous\nworks. The results of the extensive evaluation on the datasets demonstrate that\nDevign outperforms the state of the arts significantly with an average of\n10.51% higher accuracy and 8.68\\% F1 score, increases averagely 4.66% accuracy\nand 6.37% F1 by the Conv module.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:14:31 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Yaqin", ""], ["Liu", "Shangqing", ""], ["Siow", "Jingkai", ""], ["Du", "Xiaoning", ""], ["Liu", "Yang", ""]]}, {"id": "1909.03500", "submitter": "Zhining Liu", "authors": "Zhining Liu, Wei Cao, Zhifeng Gao, Jiang Bian, Hechang Chen, Yi Chang,\n  Tie-Yan Liu", "title": "Self-paced Ensemble for Highly Imbalanced Massive Data Classification", "comments": "IEEE 36th International Conference on Data Engineering (ICDE 2020)", "journal-ref": "2020 IEEE 36th International Conference on Data Engineering\n  (ICDE). IEEE, 2020: 841-852", "doi": "10.1109/ICDE48307.2020.00078", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications reveal difficulties in learning classifiers from\nimbalanced data. The rising big data era has been witnessing more\nclassification tasks with large-scale but extremely imbalance and low-quality\ndatasets. Most of existing learning methods suffer from poor performance or low\ncomputation efficiency under such a scenario. To tackle this problem, we\nconduct deep investigations into the nature of class imbalance, which reveals\nthat not only the disproportion between classes, but also other difficulties\nembedded in the nature of data, especially, noises and class overlapping,\nprevent us from learning effective classifiers. Taking those factors into\nconsideration, we propose a novel framework for imbalance classification that\naims to generate a strong ensemble by self-paced harmonizing data hardness via\nunder-sampling. Extensive experiments have shown that this new framework, while\nbeing very computationally efficient, can lead to robust performance even under\nhighly overlapping classes and extremely skewed distribution. Note that, our\nmethods can be easily adapted to most of existing learning methods (e.g., C4.5,\nSVM, GBDT and Neural Network) to boost their performance on imbalanced data.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:32:47 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 10:39:57 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 13:49:17 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Liu", "Zhining", ""], ["Cao", "Wei", ""], ["Gao", "Zhifeng", ""], ["Bian", "Jiang", ""], ["Chen", "Hechang", ""], ["Chang", "Yi", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1909.03508", "submitter": "Martin Andrews", "authors": "Yew Ken Chia, Sam Witteveen, Martin Andrews", "title": "Transformer to CNN: Label-scarce distillation for efficient text\n  classification", "comments": "Accepted paper for CDNNRIA workshop at NeurIPS 2018. (3 pages +\n  references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made in Natural Language Processing (NLP)\nmodelling since the beginning of 2018. The new approaches allow for accurate\nresults, even when there is little labelled data, because these NLP models can\nbenefit from training on both task-agnostic and task-specific unlabelled data.\nHowever, these advantages come with significant size and computational costs.\nThis workshop paper outlines how our proposed convolutional student\narchitecture, having been trained by a distillation process from a large-scale\nmodel, can achieve 300x inference speedup and 39x reduction in parameter count.\nIn some cases, the student model performance surpasses its teacher on the\nstudied tasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:57:26 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "1909.03550", "submitter": "Elad Hazan", "authors": "Elad Hazan", "title": "Lecture Notes: Optimization for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lecture notes on optimization for machine learning, derived from a course at\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\nSimons Foundation, Berkeley.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 21:49:42 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Hazan", "Elad", ""]]}, {"id": "1909.03564", "submitter": "Artit Wangperawong", "authors": "Xinyi Liu and Artit Wangperawong", "title": "Transfer Learning Robustness in Multi-Class Categorization by\n  Fine-Tuning Pre-Trained Contextualized Language Models", "comments": "Pre-trained models and code available at\n  https://github.com/artitw/text2class", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares the effectiveness and robustness of multi-class\ncategorization of Amazon product data using transfer learning on pre-trained\ncontextualized language models. Specifically, we fine-tuned BERT and XLNet, two\nbidirectional models that have achieved state-of-the-art performance on many\nnatural language tasks and benchmarks, including text classification. While\nexisting classification studies and benchmarks focus on binary targets, with\nthe exception of ordinal ranking tasks, here we examine the robustness of such\nmodels as the number of classes grows from 1 to 20. Our experiments demonstrate\nan approximately linear decrease in performance metrics (i.e., precision,\nrecall, $F_1$ score, and accuracy) with the number of class labels. BERT\nconsistently outperforms XLNet using identical hyperparameters on the entire\nrange of class label quantities for categorizing products based on their\ntextual descriptions. BERT is also more affordable than XLNet in terms of the\ncomputational cost (i.e., time and memory) required for training. In all cases\nstudied, the performance degradation rates were estimated to be 1% per\nadditional class label.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 23:35:00 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 17:54:14 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Liu", "Xinyi", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1909.03569", "submitter": "Prince Zizhuang Wang", "authors": "Prince Zizhuang Wang and William Yang Wang", "title": "Neural Gaussian Copula for Variational Autoencoder", "comments": "11 pages", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational language models seek to estimate the posterior of latent\nvariables with an approximated variational posterior. The model often assumes\nthe variational posterior to be factorized even when the true posterior is not.\nThe learned variational posterior under this assumption does not capture the\ndependency relationships over latent variables. We argue that this would cause\na typical training problem called posterior collapse observed in all other\nvariational language models. We propose Gaussian Copula Variational Autoencoder\n(VAE) to avert this problem. Copula is widely used to model correlation and\ndependencies of high-dimensional random variables, and therefore it is helpful\nto maintain the dependency relationships that are lost in VAE. The empirical\nresults show that by modeling the correlation of latent variables explicitly\nusing a neural parametric copula, we can avert this training difficulty while\ngetting competitive results among all other VAE approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 00:10:58 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Prince Zizhuang", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.03577", "submitter": "Christopher Jung", "authors": "Christopher Jung, Katrina Ligett, Seth Neel, Aaron Roth, Saeed\n  Sharifi-Malvajerdi, Moshe Shenfeld", "title": "A New Analysis of Differential Privacy's Generalization Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new proof of the \"transfer theorem\" underlying adaptive data\nanalysis: that any mechanism for answering adaptively chosen statistical\nqueries that is differentially private and sample-accurate is also accurate\nout-of-sample. Our new proof is elementary and gives structural insights that\nwe expect will be useful elsewhere. We show: 1) that differential privacy\nensures that the expectation of any query on the posterior distribution on\ndatasets induced by the transcript of the interaction is close to its true\nvalue on the data distribution, and 2) sample accuracy on its own ensures that\nany query answer produced by the mechanism is close to its posterior\nexpectation with high probability. This second claim follows from a thought\nexperiment in which we imagine that the dataset is resampled from the posterior\ndistribution after the mechanism has committed to its answers. The transfer\ntheorem then follows by summing these two bounds, and in particular, avoids the\n\"monitor argument\" used to derive high probability bounds in prior work. An\nupshot of our new proof technique is that the concrete bounds we obtain are\nsubstantially better than the best previously known bounds, even though the\nimprovements are in the constants, rather than the asymptotics (which are known\nto be tight). As we show, our new bounds outperform the naive\n\"sample-splitting\" baseline at dramatically smaller dataset sizes compared to\nthe previous state of the art, bringing techniques from this literature closer\nto practicality.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 00:49:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Jung", "Christopher", ""], ["Ligett", "Katrina", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Sharifi-Malvajerdi", "Saeed", ""], ["Shenfeld", "Moshe", ""]]}, {"id": "1909.03585", "submitter": "Jingyu Shao Mr.", "authors": "Jingyu Shao, Qing Wang and Fangbing Liu", "title": "Learning to Sample: an Active Learning Framework", "comments": "Accepted by ICDM'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning algorithms for active learning are emerging as a promising\nparadigm for learning the ``best'' active learning strategy. However, current\nlearning-based active learning approaches still require sufficient training\ndata so as to generalize meta-learning models for active learning. This is\ncontrary to the nature of active learning which typically starts with a small\nnumber of labeled samples. The unavailability of large amounts of labeled\nsamples for training meta-learning models would inevitably lead to poor\nperformance (e.g., instabilities and overfitting). In our paper, we tackle\nthese issues by proposing a novel learning-based active learning framework,\ncalled Learning To Sample (LTS). This framework has two key components: a\nsampling model and a boosting model, which can mutually learn from each other\nin iterations to improve the performance of each other. Within this framework,\nthe sampling model incorporates uncertainty sampling and diversity sampling\ninto a unified process for optimization, enabling us to actively select the\nmost representative and informative samples based on an optimized integration\nof uncertainty and diversity. To evaluate the effectiveness of the LTS\nframework, we have conducted extensive experiments on three different\nclassification tasks: image classification, salary level prediction, and entity\nresolution. The experimental results show that our LTS framework significantly\noutperforms all the baselines when the label budget is limited, especially for\ndatasets with highly imbalanced classes. In addition to this, our LTS framework\ncan effectively tackle the cold start problem occurring in many existing active\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 01:51:32 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shao", "Jingyu", ""], ["Wang", "Qing", ""], ["Liu", "Fangbing", ""]]}, {"id": "1909.03586", "submitter": "Ajay Tripathi", "authors": "Ajay Shanker Tripathi, Benjamin W. Domingue", "title": "Curve Fitting from Probabilistic Emissions and Applications to Dynamic\n  Item Response Theory", "comments": "Full version of our IEEE International Conference on Data Mining\n  (ICDM) 2019 paper. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item response theory (IRT) models are widely used in psychometrics and\neducational measurement, being deployed in many high stakes tests such as the\nGRE aptitude test. IRT has largely focused on estimation of a single latent\ntrait (e.g. ability) that remains static through the collection of item\nresponses. However, in contemporary settings where item responses are being\ncontinuously collected, such as Massive Open Online Courses (MOOCs), interest\nwill naturally be on the dynamics of ability, thus complicating usage of\ntraditional IRT models. We propose DynAEsti, an augmentation of the traditional\nIRT Expectation Maximization algorithm that allows ability to be a continuously\nvarying curve over time. In the process, we develop CurvFiFE, a novel\nnon-parametric continuous-time technique that handles the\ncurve-fitting/regression problem extended to address more general probabilistic\nemissions (as opposed to simply noisy data points). Furthermore, to accomplish\nthis, we develop a novel technique called grafting, which can successfully\napproximate distributions represented by graphical models when other popular\ntechniques like Loopy Belief Propogation (LBP) and Variational Inference (VI)\nfail. The performance of DynAEsti is evaluated through simulation, where we\nachieve results comparable to the optimal of what is observed in the static\nability scenario. Finally, DynAEsti is applied to a longitudinal performance\ndataset (80-years of competitive golf at the 18-hole Masters Tournament) to\ndemonstrate its ability to recover key properties of human performance and the\nheterogeneous characteristics of the different holes. Python code for CurvFiFE\nand DynAEsti is publicly available at github.com/chausies/DynAEstiAndCurvFiFE.\nThis is the full version of our ICDM 2019 paper.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 01:54:12 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tripathi", "Ajay Shanker", ""], ["Domingue", "Benjamin W.", ""]]}, {"id": "1909.03600", "submitter": "Majid Abdolshah", "authors": "Majid Abdolshah, Alistair Shilton, Santu Rana, Sunil Gupta, Svetha\n  Venkatesh", "title": "Cost-aware Multi-objective Bayesian optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of expense in Bayesian optimisation generally refers to the\nuniformly expensive cost of function evaluations over the whole search space.\nHowever, in some scenarios, the cost of evaluation for black-box objective\nfunctions is non-uniform since different inputs from search space may incur\ndifferent costs for function evaluations. We introduce a cost-aware\nmulti-objective Bayesian optimisation with non-uniform evaluation cost over\nobjective functions by defining cost-aware constraints over the search space.\nThe cost-aware constraints are a sorted tuple of indexes that demonstrate the\nordering of dimensions of the search space based on the user's prior knowledge\nabout their cost of usage. We formulate a new multi-objective Bayesian\noptimisation acquisition function with detailed analysis of the convergence\nthat incorporates this cost-aware constraints while optimising the objective\nfunctions. We demonstrate our algorithm based on synthetic and real-world\nproblems in hyperparameter tuning of neural networks and random forests.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 02:49:17 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Abdolshah", "Majid", ""], ["Shilton", "Alistair", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1909.03601", "submitter": "Yuta Saito", "authors": "Yuta Saito, Suguru Yaginuma, Yuta Nishino, Hayato Sakata, Kazuhide\n  Nakata", "title": "Unbiased Recommender Learning from Missing-Not-At-Random Implicit\n  Feedback", "comments": "accepted at WSDM'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems widely use implicit feedback such as click data because\nof its general availability. Although the presence of clicks signals the users'\npreference to some extent, the lack of such clicks does not necessarily\nindicate a negative response from the users, as it is possible that the users\nwere not exposed to the items (positive-unlabeled problem). This leads to a\ndifficulty in predicting the users' preferences from implicit feedback.\nPrevious studies addressed the positive-unlabeled problem by uniformly\nupweighting the loss for the positive feedback data or estimating the\nconfidence of each data having relevance information via the EM-algorithm.\nHowever, these methods failed to address the missing-not-at-random problem in\nwhich popular or frequently recommended items are more likely to be clicked\nthan other items even if a user does not have a considerable interest in them.\nTo overcome these limitations, we first define an ideal loss function to be\noptimized to realize recommendations that maximize the relevance and propose an\nunbiased estimator for the ideal loss. Subsequently, we analyze the variance of\nthe proposed unbiased estimator and further propose a clipped estimator that\nincludes the unbiased estimator as a special case. We demonstrate that the\nclipped estimator is expected to improve the performance of the recommender\nsystem, by considering the bias-variance trade-off. We conduct semi-synthetic\nand real-world experiments and demonstrate that the proposed method largely\noutperforms the baselines. In particular, the proposed method works better for\nrare items that are less frequently observed in the training data. The findings\nindicate that the proposed method can better achieve the objective of\nrecommending items with the highest relevance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 02:54:20 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 20:39:18 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 07:28:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Saito", "Yuta", ""], ["Yaginuma", "Suguru", ""], ["Nishino", "Yuta", ""], ["Sakata", "Hayato", ""], ["Nakata", "Kazuhide", ""]]}, {"id": "1909.03615", "submitter": "Chun-Ting Liu", "authors": "Chun-Ting Liu", "title": "Neural Architecture Search in Embedding Space", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural architecture search (NAS) algorithm with reinforcement learning\ncan be a powerful and novel framework for the automatic discovering process of\nneural architectures. However, its application is restricted by noncontinuous\nand high-dimensional search spaces, which result in difficulty in optimization.\nTo resolve these problems, we proposed NAS in embedding space (NASES), which is\na novel framework. Unlike other NAS with reinforcement learning approaches that\nsearch over a discrete and high-dimensional architecture space, this approach\nenables reinforcement learning to search in an embedding space by using\narchitecture encoders and decoders. The current experiment demonstrated that\nthe performance of the final architecture network using the NASES procedure is\ncomparable with that of other popular NAS approaches for the image\nclassification task on CIFAR-10. The results of the experiment were efficient\nand indicated that NASES was highly efficient to discover final architecture\nonly in $<$3.5 GPU hours. The beneficial-performance and effectiveness of NASES\nwas impressive when the architecture-embedding searching and weight\ninitialization were applied.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:28:55 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 01:55:48 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 08:06:33 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Liu", "Chun-Ting", ""]]}, {"id": "1909.03620", "submitter": "S Indrapriyadarsini", "authors": "S. Indrapriyadarsini, Shahrzad Mahboubi, Hiroshi Ninomiya and Hideki\n  Asai", "title": "An Adaptive Stochastic Nesterov Accelerated Quasi Newton Method for\n  Training RNNs", "comments": "Accepted in NOLTA 2019, IEICE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in training neural networks is the vanishing and/or\nexploding gradient problem which is more prominently seen in training of\nRecurrent Neural Networks (RNNs). Thus several algorithms have been proposed\nfor training RNNs. This paper proposes a novel adaptive stochastic Nesterov\naccelerated quasiNewton (aSNAQ) method for training RNNs. The proposed method\naSNAQ is an accelerated method that uses the Nesterov's gradient term along\nwith second order curvature information. The performance of the proposed method\nis evaluated in Tensorflow on benchmark sequence modeling problems. The results\nshow an improved performance while maintaining a low per-iteration cost and\nthus can be effectively used to train RNNs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:35:50 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Indrapriyadarsini", "S.", ""], ["Mahboubi", "Shahrzad", ""], ["Ninomiya", "Hiroshi", ""], ["Asai", "Hideki", ""]]}, {"id": "1909.03621", "submitter": "S Indrapriyadarsini", "authors": "S. Indrapriyadarsini, Shahrzad Mahboubi, Hiroshi Ninomiya and Hideki\n  Asai", "title": "A Stochastic Quasi-Newton Method with Nesterov's Accelerated Gradient", "comments": "Accepted at ECML-PKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-46150-8_43", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating second order curvature information in gradient based methods\nhave shown to improve convergence drastically despite its computational\nintensity. In this paper, we propose a stochastic (online) quasi-Newton method\nwith Nesterov's accelerated gradient in both its full and limited memory forms\nfor solving large scale non-convex optimization problems in neural networks.\nThe performance of the proposed algorithm is evaluated in Tensorflow on\nbenchmark classification and regression problems. The results show improved\nperformance compared to the classical second order oBFGS and oLBFGS methods and\npopular first order stochastic methods such as SGD and Adam. The performance\nwith different momentum rates and batch sizes have also been illustrated.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:36:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Indrapriyadarsini", "S.", ""], ["Mahboubi", "Shahrzad", ""], ["Ninomiya", "Hiroshi", ""], ["Asai", "Hideki", ""]]}, {"id": "1909.03622", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Transfer Reward Learning for Policy Gradient-Based Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-specific scores are often used to optimize for and evaluate the\nperformance of conditional text generation systems. However, such scores are\nnon-differentiable and cannot be used in the standard supervised learning\nparadigm. Hence, policy gradient methods are used since the gradient can be\ncomputed without requiring a differentiable objective.\n  However, we argue that current n-gram overlap based measures that are used as\nrewards can be improved by using model-based rewards transferred from tasks\nthat directly compare the similarity of sentence pairs. These reward models\neither output a score of sentence-level syntactic and semantic similarity\nbetween entire predicted and target sentences as the expected return, or for\nintermediate phrases as segmented accumulative rewards.\n  We demonstrate that using a \\textit{Transferable Reward Learner} leads to\nimproved results on semantical evaluation measures in policy-gradient models\nfor image captioning tasks. Our InferSent actor-critic model improves over a\nBLEU trained actor-critic model on MSCOCO when evaluated on a Word Mover's\nDistance similarity measure by 6.97 points, also improving on a Sliding Window\nCosine Similarity measure by 10.48 points. Similar performance improvements are\nalso obtained on the smaller Flickr-30k dataset, demonstrating the general\napplicability of the proposed transfer learning method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:36:42 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1909.03631", "submitter": "Weiyu Li", "authors": "Weiyu Li, Tianyi Chen, Liping Li, Zhaoxian Wu, Qing Ling", "title": "Communication-Censored Distributed Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a communication-efficient algorithm to solve the\nstochastic optimization problem defined over a distributed network, aiming at\nreducing the burdensome communication in applications such as distributed\nmachine learning.Different from the existing works based on quantization and\nsparsification, we introduce a communication-censoring technique to reduce the\ntransmissions of variables, which leads to our communication-Censored\ndistributed Stochastic Gradient Descent (CSGD) algorithm. Specifically, in\nCSGD, the latest mini-batch stochastic gradient at a worker will be transmitted\nto the server if and only if it is sufficiently informative. When the latest\ngradient is not available, the stale one will be reused at the server. To\nimplement this communication-censoring strategy, the batch-size is increasing\nin order to alleviate the effect of stochastic gradient noise. Theoretically,\nCSGD enjoys the same order of convergence rate as that of SGD, but effectively\nreduces communication. Numerical experiments demonstrate the sizable\ncommunication saving of CSGD.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 04:27:57 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 07:34:20 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Li", "Weiyu", ""], ["Chen", "Tianyi", ""], ["Li", "Liping", ""], ["Wu", "Zhaoxian", ""], ["Ling", "Qing", ""]]}, {"id": "1909.03634", "submitter": "Yuka Hashimoto", "authors": "Yuka Hashimoto, Isao Ishikawa, Masahiro Ikeda, Yoichi Matsuo,\n  Yoshinobu Kawahara", "title": "Krylov Subspace Method for Nonlinear Dynamical Systems with Random Noise", "comments": null, "journal-ref": "Journal of Machine Learning Research, 21(172):1-29, 2020\n  (http://jmlr.org/papers/v21/19-993.html)", "doi": null, "report-no": null, "categories": "cs.LG math.DS math.FA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Operator-theoretic analysis of nonlinear dynamical systems has attracted much\nattention in a variety of engineering and scientific fields, endowed with\npractical estimation methods using data such as dynamic mode decomposition. In\nthis paper, we address a lifted representation of nonlinear dynamical systems\nwith random noise based on transfer operators, and develop a novel Krylov\nsubspace method for estimating the operators using finite data, with\nconsideration of the unboundedness of operators. For this purpose, we first\nconsider Perron-Frobenius operators with kernel-mean embeddings for such\nsystems. We then extend the Arnoldi method, which is the most classical type of\nKryov subspace method, so that it can be applied to the current case.\nMeanwhile, the Arnoldi method requires the assumption that the operator is\nbounded, which is not necessarily satisfied for transfer operators on nonlinear\nsystems. We accordingly develop the shift-invert Arnoldi method for\nPerron-Frobenius operators to avoid this problem. Also, we describe an approach\nof evaluating predictive accuracy by estimated operators on the basis of the\nmaximum mean discrepancy, which is applicable, for example, to anomaly\ndetection in complex systems. The empirical performance of our methods is\ninvestigated using synthetic and real-world healthcare data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 05:17:44 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 02:03:20 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 23:08:53 GMT"}, {"version": "v4", "created": "Thu, 24 Sep 2020 13:07:43 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Hashimoto", "Yuka", ""], ["Ishikawa", "Isao", ""], ["Ikeda", "Masahiro", ""], ["Matsuo", "Yoichi", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1909.03637", "submitter": "Lori Dalton", "authors": "Ali Foroughi pour and Lori A. Dalton", "title": "Theory of Optimal Bayesian Feature Filtering", "comments": "51 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Bayesian feature filtering (OBF) is a supervised screening method\ndesigned for biomarker discovery. In this article, we prove two major\ntheoretical properties of OBF. First, optimal Bayesian feature selection under\na general family of Bayesian models reduces to filtering if and only if the\nunderlying Bayesian model assumes all features are mutually independent.\nTherefore, OBF is optimal if and only if one assumes all features are mutually\nindependent, and OBF is the only filter method that is optimal under at least\none model in the general Bayesian framework. Second, OBF under independent\nGaussian models is consistent under very mild conditions, including cases where\nthe data is non-Gaussian with correlated features. This result provides\nconditions where OBF is guaranteed to identify the correct feature set given\nenough data, and it justifies the use of OBF in non-design settings where its\nassumptions are invalid.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 05:41:10 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["pour", "Ali Foroughi", ""], ["Dalton", "Lori A.", ""]]}, {"id": "1909.03638", "submitter": "Hyungseok Song", "authors": "Hyungseok Song, Hyeryung Jang, Hai H. Tran, Se-eun Yoon, Kyunghwan\n  Son, Donggyu Yun, Hyoju Chung, Yung Yi", "title": "Solving Continual Combinatorial Selection via Deep Reinforcement\n  Learning", "comments": "Accepted to IJCAI 2019,14 pages,8 figures", "journal-ref": "Proceedings of the Twenty-Eighth International Joint Conference\n  Artificial Intelligence, {IJCAI-19} (2019), 3467--3474", "doi": "10.24963/ijcai.2019/481", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Markov Decision Process (MDP) of selecting a subset of items\nat each step, termed the Select-MDP (S-MDP). The large state and action spaces\nof S-MDPs make them intractable to solve with typical reinforcement learning\n(RL) algorithms especially when the number of items is huge. In this paper, we\npresent a deep RL algorithm to solve this issue by adopting the following key\nideas. First, we convert the original S-MDP into an Iterative Select-MDP\n(IS-MDP), which is equivalent to the S-MDP in terms of optimal actions. IS-MDP\ndecomposes a joint action of selecting K items simultaneously into K iterative\nselections resulting in the decrease of actions at the expense of an\nexponential increase of states. Second, we overcome this state space explo-sion\nby exploiting a special symmetry in IS-MDPs with novel weight shared\nQ-networks, which prov-ably maintain sufficient expressive power. Various\nexperiments demonstrate that our approach works well even when the item space\nis large and that it scales to environments with item spaces different from\nthose used in training.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 05:45:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Song", "Hyungseok", ""], ["Jang", "Hyeryung", ""], ["Tran", "Hai H.", ""], ["Yoon", "Se-eun", ""], ["Son", "Kyunghwan", ""], ["Yun", "Donggyu", ""], ["Chung", "Hyoju", ""], ["Yi", "Yung", ""]]}, {"id": "1909.03676", "submitter": "Mansooreh Pakravan", "authors": "Mansooreh Pakravan and Mohammad Bagher Shamsollahi", "title": "Joint, Partially-joint, and Individual Independent Component Analysis in\n  Multi-Subject fMRI Data", "comments": null, "journal-ref": null, "doi": "10.1109/TBME.2019.2953274", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Objective: Joint analysis of multi-subject brain imaging datasets has wide\napplications in biomedical engineering. In these datasets, some sources belong\nto all subjects (joint), a subset of subjects (partially-joint), or a single\nsubject (individual). In this paper, this source model is referred to as\njoint/partially-joint/individual multiple datasets multidimensional (JpJI-MDM),\nand accordingly, a source extraction method is developed. Method: We present a\ndeflation-based algorithm utilizing higher order cumulants to analyze the\nJpJI-MDM source model. The algorithm maximizes a cost function which leads to\nan eigenvalue problem solved with thin-SVD (singular value decomposition)\nfactorization. Furthermore, we introduce the JpJI-feature which indicates the\nspatial shape of each source and the amount of its jointness with other\nsubjects. We use this feature to determine the type of sources. Results: We\nevaluate our algorithm by analyzing simulated data and two real functional\nmagnetic resonance imaging (fMRI) datasets. In our simulation study, we will\nshow that the proposed algorithm determines the type of sources with the\naccuracy of 95% and 100% for 2-class and 3-class clustering scenarios,\nrespectively. Furthermore, our algorithm extracts meaningful joint and\npartially-joint sources from the two real datasets, which are consistent with\nthe existing neuroscience studies. Conclusion: Our results in analyzing the\nreal datasets reveal that both datasets follow the JpJI-MDM source model. This\nsource model improves the accuracy of source extraction methods developed for\nmulti-subject datasets. Significance: The proposed joint blind source\nseparation algorithm is robust and avoids parameters which are difficult to\nfine-tune.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 07:34:08 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 18:33:59 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Pakravan", "Mansooreh", ""], ["Shamsollahi", "Mohammad Bagher", ""]]}, {"id": "1909.03681", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov and Ho Hon Leung", "title": "Outlier Detection in High Dimensional Data", "comments": null, "journal-ref": "Journal of Information & Knowledge Management (2020)", "doi": "10.1142/S0219649220400134", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data poses unique challenges in outlier detection process.\nMost of the existing algorithms fail to properly address the issues stemming\nfrom a large number of features. In particular, outlier detection algorithms\nperform poorly on data set of small size with a large number of features. In\nthis paper, we propose a novel outlier detection algorithm based on principal\ncomponent analysis and kernel density estimation. The proposed method is\ndesigned to address the challenges of dealing with high-dimensional data by\nprojecting the original data onto a smaller space and using the innate\nstructure of the data to calculate anomaly scores for each data point.\nNumerical experiments on synthetic and real-life data show that our method\nperforms well on high-dimensional data. In particular, the proposed method\noutperforms the benchmark methods as measured by the $F_1$-score. Our method\nalso produces better-than-average execution times compared to the benchmark\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 07:43:47 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kamalov", "Firuz", ""], ["Leung", "Ho Hon", ""]]}, {"id": "1909.03704", "submitter": "Yuan Meng", "authors": "Yuan Meng", "title": "Estimating Granger Causality with Unobserved Confounders via Deep\n  Latent-Variable Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality analysis, as one of the most popular time series causality\nmethods, has been widely used in the economics, neuroscience. However,\nunobserved confounders is a fundamental problem in the observational studies,\nwhich is still not solved for the non-linear Granger causality. The application\nworks often deal with this problem in virtue of the proxy variables, who can be\ntreated as a measure of the confounder with noise. But the proxy variables has\nbeen proved to be unreliable, because of the bias it may induce. In this paper,\nwe try to \"recover\" the unobserved confounders for the Granger causality. We\nuse a generative model with latent variable to build the relationship between\nthe unobserved confounders and the observed variables(tested variable and the\nproxy variables). The posterior distribution of the latent variable is adopted\nto represent the confounders distribution, which can be sampled to get the\nestimated confounders. We adopt the variational autoencoder to estimate the\nintractable posterior distribution. The recurrent neural network is applied to\nbuild the temporal relationship in the data. We evaluate our method in the\nsynthetic and semi-synthetic dataset. The result shows our estimated\nconfounders has a better performance than the proxy variables in the non-linear\nGranger causality with multiple proxies in the semi-synthetic dataset. But the\nperformances of the synthetic dataset and the different noise level of proxy\nseem terrible. Any advice can really help.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 08:49:22 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Meng", "Yuan", ""]]}, {"id": "1909.03705", "submitter": "Sophie Fosson", "authors": "Vito Cerone, Sophie M. Fosson, Diego Regruto", "title": "Sparse linear regression with compressed and low-precision data via\n  concave quadratic programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of the recovery of a k-sparse vector from compressed\nlinear measurements when data are corrupted by a quantization noise. When the\nnumber of measurements is not sufficiently large, different $k$-sparse\nsolutions may be present in the feasible set, and the classical l1 approach may\nbe unsuccessful. For this motivation, we propose a non-convex quadratic\nprogramming method, which exploits prior information on the magnitude of the\nnon-zero parameters. This results in a more efficient support recovery. We\nprovide sufficient conditions for successful recovery and numerical simulations\nto illustrate the practical feasibility of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 08:55:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Cerone", "Vito", ""], ["Fosson", "Sophie M.", ""], ["Regruto", "Diego", ""]]}, {"id": "1909.03712", "submitter": "Zhao Kang", "authors": "Xiaofan Bo and Zhao Kang and Zhitong Zhao and Yuanzhang Su and Wenyu\n  Chen", "title": "Latent Multi-view Semi-Supervised Classification", "comments": "ACML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To explore underlying complementary information from multiple views, in this\npaper, we propose a novel Latent Multi-view Semi-Supervised Classification\n(LMSSC) method. Unlike most existing multi-view semi-supervised classification\nmethods that learn the graph using original features, our method seeks an\nunderlying latent representation and performs graph learning and label\npropagation based on the learned latent representation. With the\ncomplementarity of multiple views, the latent representation could depict the\ndata more comprehensively than every single view individually, accordingly\nmaking the graph more accurate and robust as well. Finally, LMSSC integrates\nlatent representation learning, graph construction, and label propagation into\na unified framework, which makes each subtask optimized. Experimental results\non real-world benchmark datasets validate the effectiveness of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:18:39 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Bo", "Xiaofan", ""], ["Kang", "Zhao", ""], ["Zhao", "Zhitong", ""], ["Su", "Yuanzhang", ""], ["Chen", "Wenyu", ""]]}, {"id": "1909.03723", "submitter": "Marco Virgolin", "authors": "Marco Virgolin, Ziyuan Wang, Tanja Alderliesten, Peter A. N. Bosman", "title": "Machine learning for automatic construction of pseudo-realistic\n  pediatric abdominal phantoms", "comments": "Currently submitted to SPIE Medical Imaging journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.med-ph stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is proving extremely beneficial in many healthcare\napplications. In pediatric oncology, retrospective studies that investigate the\nrelationship between treatment and late adverse effects still rely on simple\nheuristics. To assess the effects of radiation therapy, treatment plans are\ntypically simulated on phantoms, i.e., virtual surrogates of patient anatomy.\nCurrently, phantoms are built according to reasonable, yet simple,\nhuman-designed criteria. This often results in a lack of individualization. We\npresent a novel approach that combines imaging and ML to build individualized\nphantoms automatically. Given the features of a patient treated historically\n(only 2D radiographs available), and a database of 3D Computed Tomography (CT)\nimaging with organ segmentations and relative patient features, our approach\nuses ML to predict how to assemble a patient-specific phantom automatically.\nExperiments on 60 abdominal CTs of pediatric patients show that our approach\nconstructs significantly more representative phantoms than using current\nphantom building criteria, in terms of location and shape of the abdomen and of\ntwo considered organs, the liver and the spleen. Among several ML algorithms\nconsidered, the Gene-pool Optimal Mixing Evolutionary Algorithm for Genetic\nProgramming (GP-GOMEA) is found to deliver the best performing models, which\nare, moreover, transparent and interpretable mathematical expressions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:38:22 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Virgolin", "Marco", ""], ["Wang", "Ziyuan", ""], ["Alderliesten", "Tanja", ""], ["Bosman", "Peter A. N.", ""]]}, {"id": "1909.03731", "submitter": "Bo Liu", "authors": "Bo Liu, Yi Liang", "title": "Optimal Function Approximation with Relu Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider in this paper the optimal approximations of convex univariate\nfunctions with feed-forward Relu neural networks. We are interested in the\nfollowing question: what is the minimal approximation error given the number of\napproximating linear pieces? We establish the necessary and sufficient\nconditions and uniqueness of optimal approximations, and give lower and upper\nbounds of the optimal approximation errors. Relu neural network architectures\nare then presented to generate these optimal approximations. Finally, we\npropose an algorithm to find the optimal approximations, as well as prove its\nconvergence and validate it with experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:53:28 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:00:44 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Liu", "Bo", ""], ["Liang", "Yi", ""]]}, {"id": "1909.03739", "submitter": "Guy Tennenholtz", "authors": "Guy Tennenholtz, Shie Mannor, Uri Shalit", "title": "Off-Policy Evaluation in Partially Observable Environments", "comments": "Accepted to AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of batch off-policy evaluation for\nReinforcement Learning in partially observable environments. Off-policy\nevaluation under partial observability is inherently prone to bias, with risk\nof arbitrarily large errors. We define the problem of off-policy evaluation for\nPartially Observable Markov Decision Processes (POMDPs) and establish what we\nbelieve is the first off-policy evaluation result for POMDPs. In addition, we\nformulate a model in which observed and unobserved variables are decoupled into\ntwo dynamic processes, called a Decoupled POMDP. We show how off-policy\nevaluation can be performed under this new model, mitigating estimation errors\ninherent to general POMDPs. We demonstrate the pitfalls of off-policy\nevaluation in POMDPs using a well-known off-policy method, Importance Sampling,\nand compare it with our result on synthetic medical data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:13:09 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:51:04 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2019 07:10:15 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tennenholtz", "Guy", ""], ["Mannor", "Shie", ""], ["Shalit", "Uri", ""]]}, {"id": "1909.03742", "submitter": "Jary Pomponi", "authors": "Jary Pomponi, Simone Scardapane, Vincenzo Lomonaco, Aurelio Uncini", "title": "Efficient Continual Learning in Neural Networks with Embedding\n  Regularization", "comments": null, "journal-ref": "Neurocomputing, 397, pp. 139-148, 2020", "doi": "10.1016/j.neucom.2020.01.093", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning of deep neural networks is a key requirement for scaling\nthem up to more complex applicative scenarios and for achieving real lifelong\nlearning of these architectures. Previous approaches to the problem have\nconsidered either the progressive increase in the size of the networks, or have\ntried to regularize the network behavior to equalize it with respect to\npreviously observed tasks. In the latter case, it is essential to understand\nwhat type of information best represents this past behavior. Common techniques\ninclude regularizing the past outputs, gradients, or individual weights. In\nthis work, we propose a new, relatively simple and efficient method to perform\ncontinual learning by regularizing instead the network internal embeddings. To\nmake the approach scalable, we also propose a dynamic sampling strategy to\nreduce the memory footprint of the required external storage. We show that our\nmethod performs favorably with respect to state-of-the-art approaches in the\nliterature, while requiring significantly less space in memory and\ncomputational time. In addition, inspired inspired by to recent works, we\nevaluate the impact of selecting a more flexible model for the activation\nfunctions inside the network, evaluating the impact of catastrophic forgetting\non the activation functions themselves.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:16:47 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 14:24:29 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Pomponi", "Jary", ""], ["Scardapane", "Simone", ""], ["Lomonaco", "Vincenzo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1909.03749", "submitter": "Fabio Ferreira", "authors": "Fabio Ferreira, Lin Shao, Tamim Asfour, Jeannette Bohg", "title": "Learning Visual Dynamics Models of Rigid Objects using Relational\n  Inductive Biases", "comments": "short paper (4 pages, two figures), accepted to NeurIPS 2019 Graph\n  Representation Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endowing robots with human-like physical reasoning abilities remains\nchallenging. We argue that existing methods often disregard spatio-temporal\nrelations and by using Graph Neural Networks (GNNs) that incorporate a\nrelational inductive bias, we can shift the learning process towards exploiting\nrelations. In this work, we learn action-conditional forward dynamics models of\na simulated manipulation task from visual observations involving cluttered and\nirregularly shaped objects. We investigate two GNN approaches and empirically\nassess their capability to generalize to scenarios with novel and an increasing\nnumber of objects. The first, Graph Networks (GN) based approach, considers\nexplicitly defined edge attributes and not only does it consistently\nunderperform an auto-encoder baseline that we modified to predict future\nstates, our results indicate how different edge attributes can significantly\ninfluence the predictions. Consequently, we develop the Auto-Predictor that\ndoes not rely on explicitly defined edge attributes. It outperforms the\nbaseline and the GN-based models. Overall, our results show the sensitivity of\nGNN-based approaches to the task representation, the efficacy of relational\ninductive biases and advocate choosing lightweight approaches that implicitly\nreason about relations over ones that leave these decisions to human designers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:43:56 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 21:00:07 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 17:32:04 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Ferreira", "Fabio", ""], ["Shao", "Lin", ""], ["Asfour", "Tamim", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1909.03765", "submitter": "Shuyu Lin", "authors": "Shuyu Lin, Stephen Roberts, Niki Trigoni, Ronald Clark", "title": "Balancing Reconstruction Quality and Regularisation in ELBO for VAEs", "comments": "8 pages for main contents and 15 pages for supplemental materials\n  that include data pre-processing, model architectures and more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A trade-off exists between reconstruction quality and the prior\nregularisation in the Evidence Lower Bound (ELBO) loss that Variational\nAutoencoder (VAE) models use for learning. There are few satisfactory\napproaches to deal with a balance between the prior and reconstruction\nobjective, with most methods dealing with this problem through heuristics. In\nthis paper, we show that the noise variance (often set as a fixed value) in the\nGaussian likelihood p(x|z) for real-valued data can naturally act to provide\nsuch a balance. By learning this noise variance so as to maximise the ELBO\nloss, we automatically obtain an optimal trade-off between the reconstruction\nerror and the prior constraint on the posteriors. This variance can be\ninterpreted intuitively as the necessary noise level for the current model to\nbe the best explanation of the observed dataset. Further, by allowing the\nvariance inference to be more flexible it can conveniently be used as an\nuncertainty estimator for reconstructed or generated samples. We demonstrate\nthat optimising the noise variance is a crucial component of VAE learning, and\nshowcase the performance on MNIST, Fashion MNIST and CelebA datasets. We find\nour approach can significantly improve the quality of generated samples whilst\nmaintaining a smooth latent-space manifold to represent the data. The method\nalso offers an indication of uncertainty in the final generative model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:18:52 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Lin", "Shuyu", ""], ["Roberts", "Stephen", ""], ["Trigoni", "Niki", ""], ["Clark", "Ronald", ""]]}, {"id": "1909.03767", "submitter": "Julius Ruseckas", "authors": "Julius Ruseckas", "title": "Differential equations as models of deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we systematically analyze general properties of differential\nequations used as machine learning models. We demonstrate that the gradient of\nthe loss function with respect to to the hidden state can be considered as a\ngeneralized momentum conjugate to the hidden state, allowing application of the\ntools of classical mechanics. In addition, we show that not only residual\nnetworks, but also feedforward neural networks with small nonlinearities and\nthe weights matrices deviating only slightly from identity matrices can be\nrelated to the differential equations. We propose a differential equation\ndescribing such networks and investigate its properties.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:19:29 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 09:48:10 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ruseckas", "Julius", ""]]}, {"id": "1909.03772", "submitter": "Nicolai Anton Lynnerup", "authors": "Nicolai A. Lynnerup, Laura Nolling, Rasmus Hasle, John Hallam", "title": "A Survey on Reproducibility by Evaluating Deep Reinforcement Learning\n  Algorithms on Real-World Robots", "comments": "Appears in Proceedings of the Third Conference on Robot Learning\n  (CoRL 2019). Companion source code at\n  https://github.com/dti-research/SenseActExperiments/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As reinforcement learning (RL) achieves more success in solving complex\ntasks, more care is needed to ensure that RL research is reproducible and that\nalgorithms herein can be compared easily and fairly with minimal bias. RL\nresults are, however, notoriously hard to reproduce due to the algorithms'\nintrinsic variance, the environments' stochasticity, and numerous (potentially\nunreported) hyper-parameters. In this work we investigate the many issues\nleading to irreproducible research and how to manage those. We further show how\nto utilise a rigorous and standardised evaluation approach for easing the\nprocess of documentation, evaluation and fair comparison of different\nalgorithms, where we emphasise the importance of choosing the right measurement\nmetrics and conducting proper statistics on the results, for unbiased reporting\nof the results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:33:09 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 07:42:00 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Lynnerup", "Nicolai A.", ""], ["Nolling", "Laura", ""], ["Hasle", "Rasmus", ""], ["Hallam", "John", ""]]}, {"id": "1909.03773", "submitter": "Xinqiang Cai", "authors": "Xin-Qiang Cai, Yao-Xiang Ding, Yuan Jiang, Zhi-Hua Zhou", "title": "Imitation Learning from Pixel-Level Demonstrations by HashReward", "comments": "Accepted by AAMAS-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key issues for imitation learning lies in making policy learned\nfrom limited samples to generalize well in the whole state-action space. This\nproblem is much more severe in high-dimensional state environments, such as\ngame playing with raw pixel inputs. Under this situation, even state-of-the-art\nadversary-based imitation learning algorithms fail. Through empirical studies,\nwe find that the main cause lies in the failure of training a powerful\ndiscriminator to generate meaningful rewards in high-dimensional environments.\nAlthough it seems that dimensionality reduction can help, a straightforward\napplication of off-the-shelf methods cannot achieve good performance. In this\nwork, we show in theory that the balance between dimensionality reduction and\ndiscriminative training is essential for effective learning. To achieve this\ntarget, we propose HashReward, which utilizes the idea of supervised hashing to\nrealize such an ideal balance. Experimental results show that HashReward could\noutperform state-of-the-art methods for a large gap under the challenging\nhigh-dimensional environments.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:37:09 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 10:08:18 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 08:19:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Cai", "Xin-Qiang", ""], ["Ding", "Yao-Xiang", ""], ["Jiang", "Yuan", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1909.03790", "submitter": "Daniele Zambon", "authors": "Daniele Zambon, Cesare Alippi, Lorenzo Livi", "title": "Graph Random Neural Features for Distance-Preserving Graph\n  Representations", "comments": "to be published in Proceedings of the 37th International Conference\n  on Machine Learning, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Graph Random Neural Features (GRNF), a novel embedding method from\ngraph-structured data to real vectors based on a family of graph neural\nnetworks. The embedding naturally deals with graph isomorphism and preserves\nthe metric structure of the graph domain, in probability. In addition to being\nan explicit embedding method, it also allows us to efficiently and effectively\napproximate graph metric distances (as well as complete kernel functions); a\ncriterion to select the embedding dimension trading off the approximation\naccuracy with the computational cost is also provided. GRNF can be used within\ntraditional processing methods or as a training-free input layer of a graph\nneural network. The theoretical guarantees that accompany GRNF ensure that the\nconsidered graph distance is metric, hence allowing to distinguish any pair of\nnon-isomorphic graphs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:13:46 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:22:46 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 08:37:17 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Zambon", "Daniele", ""], ["Alippi", "Cesare", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1909.03798", "submitter": "Feng Chen", "authors": "Xin Su, Shangqi Guo and Feng Chen", "title": "Subjectivity Learning Theory towards Artificial General Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of artificial general intelligence (AGI) was a long-term\ngoal of AI research aiming to deal with the complex data in the real world and\nmake reasonable judgments in various cases like a human. However, the current\nAI creations, referred to as \"Narrow AI\", are limited to a specific problem.\nThe constraints come from two basic assumptions of data, which are independent\nand identical distributed samples and single-valued mapping between inputs and\noutputs. We completely break these constraints and develop the subjectivity\nlearning theory for general intelligence. We assign the mathematical meaning\nfor the philosophical concept of subjectivity and build the data representation\nof general intelligence. Under the subjectivity representation, then the global\nrisk is constructed as the new learning goal. We prove that subjectivity\nlearning holds a lower risk bound than traditional machine learning. Moreover,\nwe propose the principle of empirical global risk minimization (EGRM) as the\nsubjectivity learning process in practice, establish the condition of\nconsistency, and present triple variables for controlling the total risk bound.\nThe subjectivity learning is a novel learning theory for unconstrained real\ndata and provides a path to develop AGI.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:29:32 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 03:20:11 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Su", "Xin", ""], ["Guo", "Shangqi", ""], ["Chen", "Feng", ""]]}, {"id": "1909.03818", "submitter": "Ioan Gabriel Bucur", "authors": "Ioan Gabriel Bucur, Tom Claassen, Tom Heskes", "title": "Large-Scale Local Causal Inference of Gene Regulatory Relationships", "comments": "32 pages, 9 figures, 2 tables. This manuscript version has been\n  accepted for publication in the International Journal of Approximate\n  Reasoning. It incorporates reviewer comments and has a new title. This\n  manuscript constitutes an extended version of a previous paper shared on\n  arXiv (arXiv:1809.06827) that has been published in the proceedings of the\n  PGM 2018 conference", "journal-ref": null, "doi": "10.1016/j.ijar.2019.08.012", "report-no": null, "categories": "stat.ML cs.LG q-bio.GN q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene regulatory networks play a crucial role in controlling an organism's\nbiological processes, which is why there is significant interest in developing\ncomputational methods that are able to extract their structure from\nhigh-throughput genetic data. Many of these computational methods are designed\nto infer individual regulatory relationships among genes from data on gene\nexpression. We propose a novel efficient Bayesian method for discovering local\ncausal relationships among triplets of (normally distributed) variables. In our\napproach, we score covariance structures for each triplet in one go and\nincorporate available background knowledge in the form of priors to derive\nposterior probabilities over local causal structures. Our method is flexible in\nthe sense that it allows for different types of causal structures and\nassumptions. We apply our approach to the task of learning causal regulatory\nrelationships among genes. We show that the proposed algorithm produces stable\nand conservative posterior probability estimates over local causal structures\nthat can be used to derive an honest ranking of the most meaningful regulatory\nrelationships. We demonstrate the stability and efficacy of our method both on\nsimulated data and on real-world data from an experiment on yeast.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:54:33 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 13:36:39 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Bucur", "Ioan Gabriel", ""], ["Claassen", "Tom", ""], ["Heskes", "Tom", ""]]}, {"id": "1909.03830", "submitter": "Di Wang", "authors": "Di Wang, Feiqing Huang, Jingyu Zhao, Guodong Li, Guangjian Tian", "title": "Compact Autoregressive Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive networks can achieve promising performance in many sequence\nmodeling tasks with short-range dependence. However, when handling\nhigh-dimensional inputs and outputs, the huge amount of parameters in the\nnetwork lead to expensive computational cost and low learning efficiency. The\nproblem can be alleviated slightly by introducing one more narrow hidden layer\nto the network, but the sample size required to achieve a certain training\nerror is still large. To address this challenge, we rearrange the weight\nmatrices of a linear autoregressive network into a tensor form, and then make\nuse of Tucker decomposition to represent low-rank structures. This leads to a\nnovel compact autoregressive network, called Tucker AutoRegressive (TAR) net.\nInterestingly, the TAR net can be applied to sequences with long-range\ndependence since the dimension along the sequential order is reduced.\nTheoretical studies show that the TAR net improves the learning efficiency, and\nrequires much fewer samples for model training. Experiments on synthetic and\nreal-world datasets demonstrate the promising performance of the proposed\ncompact network.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:20:08 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Di", ""], ["Huang", "Feiqing", ""], ["Zhao", "Jingyu", ""], ["Li", "Guodong", ""], ["Tian", "Guangjian", ""]]}, {"id": "1909.03835", "submitter": "Haochuan Lu", "authors": "Haochuan Lu and Huanlin Xu and Nana Liu and Yangfan Zhou and Xin Wang", "title": "Data Sanity Check for Deep Learning Systems via Learnt Assertions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliability is a critical consideration to DL-based systems. But the\nstatistical nature of DL makes it quite vulnerable to invalid inputs, i.e.,\nthose cases that are not considered in the training phase of a DL model. This\npaper proposes to perform data sanity check to identify invalid inputs, so as\nto enhance the reliability of DL-based systems. We design and implement a tool\nto detect behavior deviation of a DL model when processing an input case. This\ntool extracts the data flow footprints and conducts an assertion-based\nvalidation mechanism. The assertions are built automatically, which are\nspecifically-tailored for DL model data flow analysis. Our experiments\nconducted with real-world scenarios demonstrate that such an assertion-based\ndata sanity check mechanism is effective in identifying invalid input cases.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:15:21 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 11:47:40 GMT"}, {"version": "v3", "created": "Sat, 28 Sep 2019 09:55:00 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lu", "Haochuan", ""], ["Xu", "Huanlin", ""], ["Liu", "Nana", ""], ["Zhou", "Yangfan", ""], ["Wang", "Xin", ""]]}, {"id": "1909.03848", "submitter": "Zvezdin Besarabov", "authors": "Zvezdin Besarabov and Todor Kolev", "title": "Distributed creation of Machine learning agents for Blockchain analysis", "comments": "arXiv admin note: text overlap with arXiv:1810.06696", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating efficient deep neural networks involves repetitive manual\noptimization of the topology and the hyperparameters. This human intervention\nsignificantly inhibits the process. Recent publications propose various Neural\nArchitecture Search (NAS) algorithms that automate this work. We have applied a\ncustomized NAS algorithm with network morphism and Bayesian optimization to the\nproblem of cryptocurrency predictions, where it achieved results on par with\nour best manually designed models. This is consistent with the findings of\nother teams, while several known experiments suggest that given enough\ncomputing power, NAS algorithms can surpass state-of-the-art neural network\nmodels designed by humans. In this paper, we propose a blockchain network\nprotocol that incentivises independent computing nodes to run NAS algorithms\nand compete in finding better neural network models for a particular task. If\nimplemented, such network can be an autonomous and self-improving source of\nmachine learning models, significantly boosting and democratizing the access to\nAI capabilities for many industries.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:52:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Besarabov", "Zvezdin", ""], ["Kolev", "Todor", ""]]}, {"id": "1909.03881", "submitter": "Sahil Garg", "authors": "Sahil Garg, Aram Galstyan, Greg Ver Steeg, Guillermo Cecchi", "title": "Nearly-Unsupervised Hashcode Representations for Relation Extraction", "comments": "Proceedings of EMNLP-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, kernelized locality sensitive hashcodes have been successfully\nemployed as representations of natural language text, especially showing high\nrelevance to biomedical relation extraction tasks. In this paper, we propose to\noptimize the hashcode representations in a nearly unsupervised manner, in which\nwe only use data points, but not their class labels, for learning. The\noptimized hashcode representations are then fed to a supervised classifier\nfollowing the prior work. This nearly unsupervised approach allows fine-grained\noptimization of each hash function, which is particularly suitable for building\nhashcode representations generalizing from a training set to a test set. We\nempirically evaluate the proposed approach for biomedical relation extraction\ntasks, obtaining significant accuracy improvements w.r.t. state-of-the-art\nsupervised and semi-supervised approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:20:05 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Garg", "Sahil", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""], ["Cecchi", "Guillermo", ""]]}, {"id": "1909.03890", "submitter": "Sebastian P\\\"olsterl", "authors": "Sebastian P\\\"olsterl, Ignacio Sarasua, Benjam\\'in Guti\\'errez-Becker,\n  Christian Wachinger", "title": "A Wide and Deep Neural Network for Survival Analysis from Anatomical\n  Shape and Tabular Clinical Data", "comments": "Data and Machine Learning Advances with Multiple Views Workshop,\n  ECML-PKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-43823-4_37", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a wide and deep neural network for prediction of progression\nfrom patients with mild cognitive impairment to Alzheimer's disease.\nInformation from anatomical shape and tabular clinical data (demographics,\nbiomarkers) are fused in a single neural network. The network is invariant to\nshape transformations and avoids the need to identify point correspondences\nbetween shapes. To account for right censored time-to-event data, i.e., when it\nis only known that a patient did not develop Alzheimer's disease up to a\nparticular time point, we employ a loss commonly used in survival analysis. Our\nnetwork is trained end-to-end to combine information from a patient's\nhippocampus shape and clinical biomarkers. Our experiments on data from the\nAlzheimer's Disease Neuroimaging Initiative demonstrate that our proposed model\nis able to learn a shape descriptor that augments clinical biomarkers and\noutperforms a deep neural network on shape alone and a linear model on common\nclinical biomarkers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:37:47 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["P\u00f6lsterl", "Sebastian", ""], ["Sarasua", "Ignacio", ""], ["Guti\u00e9rrez-Becker", "Benjam\u00edn", ""], ["Wachinger", "Christian", ""]]}, {"id": "1909.03891", "submitter": "Hamed Yazdanpanah", "authors": "Hamed Yazdanpanah", "title": "On Data-Selective Learning", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive filters are applied in several electronic and communication devices\nlike smartphones, advanced headphones, DSP chips, smart antenna, and\nteleconference systems. Also, they have application in many areas such as\nsystem identification, channel equalization, noise reduction, echo\ncancellation, interference cancellation, signal prediction, and stock market.\nTherefore, reducing the energy consumption of the adaptive filtering algorithms\nhas great importance, particularly in green technologies and in devices using\nbattery.\n  In this thesis, data-selective adaptive filters, in particular the\nset-membership (SM) adaptive filters, are the tools to reach the goal. There\nare well known SM adaptive filters in literature. This work introduces new\nalgorithms based on the classical ones in order to improve their performances\nand reduce the number of required arithmetic operations at the same time.\nTherefore, firstly, we analyze the robustness of the classical SM adaptive\nfiltering algorithms. Secondly, we extend the SM technique to trinion and\nquaternion systems. Thirdly, by combining SM filtering and partial-updating, we\nintroduce a new improved set-membership affine projection algorithm with\nconstrained step size to improve its stability behavior. Fourthly, we propose\nsome new least-mean-square (LMS) based and recursive least-squares based\nadaptive filtering algorithms with low computational complexity for sparse\nsystems. Finally, we derive some feature LMS algorithms to exploit the hidden\nsparsity in the parameters.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 00:04:46 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Yazdanpanah", "Hamed", ""]]}, {"id": "1909.03892", "submitter": "Donghoon Lee", "authors": "Donghoon Lee and Georgios B. Giannakis", "title": "A Variational Bayes Approach to Adaptive Radio Tomography", "comments": "submitted to IEEE Transactions on Signal Processing. arXiv admin\n  note: substantial text overlap with arXiv:1804.02084", "journal-ref": null, "doi": "10.1109/TSP.2020.3003130", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio tomographic imaging (RTI) is an emerging technology for localization of\nphysical objects in a geographical area covered by wireless networks. With\nattenuation measurements collected at spatially distributed sensors, RTI\ncapitalizes on spatial loss fields (SLFs) measuring the absorption of radio\nfrequency waves at spatial locations along the propagation path. These SLFs can\nbe utilized for interference management in wireless communication networks,\nenvironmental monitoring, and survivor localization after natural disasters\nsuch as earthquakes. Key to the success of RTI is to accurately model shadowing\nas the weighted line integral of the SLF. To learn the SLF exhibiting\nstatistical heterogeneity induced by spatially diverse environments, the\npresent work develops a Bayesian framework entailing a piecewise homogeneous\nSLF with an underlying hidden Markov random field model. Utilizing variational\nBayes techniques, the novel approach yields efficient field estimators at\naffordable complexity. A data-adaptive sensor selection strategy is also\nintroduced to collect informative measurements for effective reconstruction of\nthe SLF. Numerical tests using synthetic and real datasets demonstrate the\ncapabilities of the proposed approach to radio tomography and channel-gain\nestimation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:32:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lee", "Donghoon", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1909.03894", "submitter": "Lev Utkin", "authors": "Lev V. Utkin, Mikhail V. Kots, Viacheslav S. Chukanov", "title": "Estimation of Personalized Heterogeneous Treatment Effects Using\n  Concatenation and Augmentation of Feature Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new meta-algorithm for estimating the conditional average treatment effects\nis proposed in the paper. The main idea underlying the algorithm is to consider\na new dataset consisting of feature vectors produced by means of concatenation\nof examples from control and treatment groups, which are close to each other.\nOutcomes of new data are defined as the difference between outcomes of the\ncorresponding examples comprising new feature vectors. The second idea is based\non the assumption that the number of controls is rather large and the control\noutcome function is precisely determined. This assumption allows us to augment\ntreatments by generating feature vectors which are closed to available\ntreatments. The outcome regression function constructed on the augmented set of\nconcatenated feature vectors can be viewed as an estimator of the conditional\naverage treatment effects. A simple modification of the Co-learner based on the\nrandom subspace method or the feature bagging is also proposed. Various\nnumerical simulation experiments illustrate the proposed algorithm and show its\noutperformance in comparison with the well-known T-learner and X-learner for\nseveral types of the control and treatment outcome functions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:43:30 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Utkin", "Lev V.", ""], ["Kots", "Mikhail V.", ""], ["Chukanov", "Viacheslav S.", ""]]}, {"id": "1909.03895", "submitter": "Sebastian Gomez-Gonzalez", "authors": "Sebastian Gomez-Gonzalez, Sergey Prokudin, Bernhard Scholkopf and Jan\n  Peters", "title": "Real Time Trajectory Prediction Using Deep Conditional Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data driven methods for time series forecasting that quantify uncertainty\nopen new important possibilities for robot tasks with hard real time\nconstraints, allowing the robot system to make decisions that trade off between\nreaction time and accuracy in the predictions. Despite the recent advances in\ndeep learning, it is still challenging to make long term accurate predictions\nwith the low latency required by real time robotic systems. In this paper, we\npropose a deep conditional generative model for trajectory prediction that is\nlearned from a data set of collected trajectories. Our method uses encoder and\ndecoder deep networks that maps complete or partial trajectories to a Gaussian\ndistributed latent space and back, allowing for fast inference of the future\nvalues of a trajectory given previous observations. The encoder and decoder\nnetworks are trained using stochastic gradient variational Bayes. In the\nexperiments, we show that our model provides more accurate long term\npredictions with a lower latency that popular models for trajectory forecasting\nlike recurrent neural networks or physical models based on differential\nequations. Finally, we test our proposed approach in a robot table tennis\nscenario to evaluate the performance of the proposed method in a robotic task\nwith hard real time constraints.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:46:16 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:37:50 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Gomez-Gonzalez", "Sebastian", ""], ["Prokudin", "Sergey", ""], ["Scholkopf", "Bernhard", ""], ["Peters", "Jan", ""]]}, {"id": "1909.03939", "submitter": "Qingpeng Cai", "authors": "Qingpeng Cai, Ling Pan, Pingzhong Tang", "title": "Deterministic Value-Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms such as the deep deterministic policy\ngradient algorithm (DDPG) has been widely used in continuous control tasks.\nHowever, the model-free DDPG algorithm suffers from high sample complexity. In\nthis paper we consider the deterministic value gradients to improve the sample\nefficiency of deep reinforcement learning algorithms. Previous works consider\ndeterministic value gradients with the finite horizon, but it is too myopic\ncompared with infinite horizon. We firstly give a theoretical guarantee of the\nexistence of the value gradients in this infinite setting. Based on this\ntheoretical guarantee, we propose a class of the deterministic value gradient\nalgorithm (DVG) with infinite horizon, and different rollout steps of the\nanalytical gradients by the learned model trade off between the variance of the\nvalue gradients and the model bias. Furthermore, to better combine the\nmodel-based deterministic value gradient estimators with the model-free\ndeterministic policy gradient estimator, we propose the deterministic\nvalue-policy gradient (DVPG) algorithm. We finally conduct extensive\nexperiments comparing DVPG with state-of-the-art methods on several standard\ncontinuous control benchmarks. Results demonstrate that DVPG substantially\noutperforms other baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:37:04 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 11:58:48 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Cai", "Qingpeng", ""], ["Pan", "Ling", ""], ["Tang", "Pingzhong", ""]]}, {"id": "1909.03947", "submitter": "Gabriel Laberge", "authors": "G. Laberge and S. Shirzad and P. Diehl and H. Kaiser and S. Prudhomme\n  and A. Lemoine", "title": "Scheduling optimization of parallel linear algebra algorithms using\n  Supervised Learning", "comments": "Accepted at HPCML19", "journal-ref": null, "doi": "10.1109/MLHPC49564.2019.00009", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear algebra algorithms are used widely in a variety of domains, e.g\nmachine learning, numerical physics and video games graphics. For all these\napplications, loop-level parallelism is required to achieve high performance.\nHowever, finding the optimal way to schedule the workload between threads is a\nnon-trivial problem because it depends on the structure of the algorithm being\nparallelized and the hardware the executable is run on. In the realm of\nAsynchronous Many Task runtime systems, a key aspect of the scheduling problem\nis predicting the proper chunk-size, where the chunk-size is defined as the\nnumber of iterations of a for-loop assigned to a thread as one task. In this\npaper, we study the applications of supervised learning models to predict the\nchunk-size which yields maximum performance on multiple parallel linear algebra\noperations using the HPX backend of Blaze's linear algebra library. More\nprecisely, we generate our training and tests sets by measuring performance of\nthe application with different chunk-sizes for multiple linear algebra\noperations; vector-addition, matrix-vector-multiplication, matrix-matrix\naddition and matrix-matrix-multiplication. We compare the use of logistic\nregression, neural networks and decision trees with a newly developed decision\ntree based model in order to predict the optimal value for chunk-size. Our\nresults show that classical decision trees and our custom decision tree model\nare able to forecast a chunk-size which results in good performance for the\nlinear algebra operations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:54:35 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 19:10:27 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Laberge", "G.", ""], ["Shirzad", "S.", ""], ["Diehl", "P.", ""], ["Kaiser", "H.", ""], ["Prudhomme", "S.", ""], ["Lemoine", "A.", ""]]}, {"id": "1909.03951", "submitter": "Vikrant Singhal", "authors": "Gautam Kamath, Or Sheffet, Vikrant Singhal, Jonathan Ullman", "title": "Differentially Private Algorithms for Learning Mixtures of Separated\n  Gaussians", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the parameters of Gaussian mixture models is a fundamental and\nwidely studied problem with numerous applications. In this work, we give new\nalgorithms for learning the parameters of a high-dimensional, well separated,\nGaussian mixture model subject to the strong constraint of differential\nprivacy. In particular, we give a differentially private analogue of the\nalgorithm of Achlioptas and McSherry. Our algorithm has two key properties not\nachieved by prior work: (1) The algorithm's sample complexity matches that of\nthe corresponding non-private algorithm up to lower order terms in a wide range\nof parameters. (2) The algorithm does not require strong a priori bounds on the\nparameters of the mixture components.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:58:52 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 21:48:40 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kamath", "Gautam", ""], ["Sheffet", "Or", ""], ["Singhal", "Vikrant", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1909.03953", "submitter": "Bernhard Gahr", "authors": "Bernhard Gahr, Shu Liu, Kevin Koch, Filipe Barata, Andr\\'e Dahlinger,\n  Benjamin Ryder, Elgar Fleisch, Felix Wortmann", "title": "Driver Identification via the Steering Wheel", "comments": "10 pages, 16 figures, 6 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driver identification has emerged as a vital research field, where both\npractitioners and researchers investigate the potential of driver\nidentification to enable a personalized driving experience. Within recent\nyears, a selection of studies have reported that individuals could be perfectly\nidentified based on their driving behavior under controlled conditions.\nHowever, research investigating the potential of driver identification under\nnaturalistic conditions claim accuracies only marginally higher than random\nguess. The paper at hand provides a comprehensive summary of the recent work,\nhighlighting the main discrepancies in the design of the machine learning\napproaches, primarily the window length parameter that was considered. Key\nfindings further indicate that the longitudinal vehicle control information is\nparticularly useful for driver identification, leaving the research gap on the\nextent to which the lateral vehicle control can be used for reliable\nidentification. Building upon existing work, we provide a novel approach for\nthe design of the window length parameter that provides evidence that reliable\ndriver identification can be achieved with data limited to the steering wheel\nonly. The results and insights in this paper are based on data collected from\nthe largest naturalistic driving study conducted in this field. Overall, a\nneural network based on GRUs was found to provide better identification\nperformance than traditional methods, increasing the prediction accuracy from\nunder 15\\% to over 65\\% for 15 drivers. When leveraging the full field study\ndataset, comprising 72 drivers, the accuracy of identification prediction of\nthe approach improved a random guess approach by a factor of 25.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:00:50 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gahr", "Bernhard", ""], ["Liu", "Shu", ""], ["Koch", "Kevin", ""], ["Barata", "Filipe", ""], ["Dahlinger", "Andr\u00e9", ""], ["Ryder", "Benjamin", ""], ["Fleisch", "Elgar", ""], ["Wortmann", "Felix", ""]]}, {"id": "1909.03977", "submitter": "Ulrich A\\\"ivodji", "authors": "Ulrich A\\\"ivodji, Julien Ferry, S\\'ebastien Gambs, Marie-Jos\\'e\n  Huguet, Mohamed Siala", "title": "Learning Fair Rule Lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of black-box models becomes ubiquitous in high stake\ndecision-making systems, demands for fair and interpretable models are\nincreasing. While it has been shown that interpretable models can be as\naccurate as black-box models in several critical domains, existing fair\nclassification techniques that are interpretable by design often display poor\naccuracy/fairness tradeoffs in comparison with their non-interpretable\ncounterparts. In this paper, we propose FairCORELS, a fair classification\ntechnique interpretable by design, whose objective is to learn fair rule lists.\nOur solution is a multi-objective variant of CORELS, a branch-and-bound\nalgorithm to learn rule lists, that supports several statistical notions of\nfairness. Examples of such measures include statistical parity, equal\nopportunity and equalized odds. The empirical evaluation of FairCORELS on\nreal-world datasets demonstrates that it outperforms state-of-the-art fair\nclassification techniques that are interpretable by design while being\ncompetitive with non-interpretable ones.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:37:14 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 01:57:23 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Ferry", "Julien", ""], ["Gambs", "S\u00e9bastien", ""], ["Huguet", "Marie-Jos\u00e9", ""], ["Siala", "Mohamed", ""]]}, {"id": "1909.03978", "submitter": "Saavan Patel", "authors": "Saavan Patel and Sayeef Salahuddin", "title": "Combining Learned Representations for Combinatorial Optimization", "comments": "Submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to combine Restricted Boltzmann Machines (RBMs)\nthat can be used to solve combinatorial optimization problems. This allows\nsynthesis of larger models from smaller RBMs that have been pretrained, thus\neffectively bypassing the problem of learning in large RBMs, and creating a\nsystem able to model a large, complex multi-modal space. We validate this\napproach by using learned representations to create ``invertible boolean\nlogic'', where we can use Markov chain Monte Carlo (MCMC) approaches to find\nthe solution to large scale boolean satisfiability problems and show viability\ntowards other combinatorial optimization problems. Using this method, we are\nable to solve 64 bit addition based problems, as well as factorize 16 bit\nnumbers. We find that these combined representations can provide a more\naccurate result for the same sample size as compared to a fully trained model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:38:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Patel", "Saavan", ""], ["Salahuddin", "Sayeef", ""]]}, {"id": "1909.03980", "submitter": "Damian Campo", "authors": "Damian Campo, Vahid Bastani, Lucio Marcenaro, Carlo Regazzoni", "title": "Incremental learning of environment interactive structures from\n  trajectories of individuals", "comments": null, "journal-ref": "2016 19th International Conference on Information Fusion (FUSION)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel method for estimating the influence that unknown\nstatic objects might have over mobile agents. Since the motion of agents can be\naffected by the presence of fixed objects, it is possible use the information\nabout trajectories deviations to infer the presence of obstacles and estimate\nthe forces involved in a scene. Artificial neural networks are used to estimate\na non-parametric function related to the velocity field influencing moving\nagents. The proposed method is able to incrementally learn the velocity fields\ndue to external static objects within the monitored environment. It determines\nwhether an object has a repulsive or an attractive influence and provides an\nestimation of its position and size. As stationarity is assumed, i.e.,\ntime-invariance of force fields, learned observation models can be used as\nprior knowledge for estimating hierarchically the properties of new objects in\na scene.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:39:08 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Campo", "Damian", ""], ["Bastani", "Vahid", ""], ["Marcenaro", "Lucio", ""], ["Regazzoni", "Carlo", ""]]}, {"id": "1909.03984", "submitter": "Alberto Maria Metelli", "authors": "Alberto Maria Metelli, Guglielmo Manneschi, Marcello Restelli", "title": "Policy Space Identification in Configurable Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying the policy space of a learning agent,\nhaving access to a set of demonstrations generated by its optimal policy. We\nintroduce an approach based on statistical testing to identify the set of\npolicy parameters the agent can control, within a larger parametric policy\nspace. After presenting two identification rules (combinatorial and\nsimplified), applicable under different assumptions on the policy space, we\nprovide a probabilistic analysis of the simplified one in the case of linear\npolicies belonging to the exponential family. To improve the performance of our\nidentification rules, we frame the problem in the recently introduced framework\nof the Configurable Markov Decision Processes, exploiting the opportunity of\nconfiguring the environment to induce the agent revealing which parameters it\ncan control. Finally, we provide an empirical evaluation, on both discrete and\ncontinuous domains, to prove the effectiveness of our identification rules.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:47:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Metelli", "Alberto Maria", ""], ["Manneschi", "Guglielmo", ""], ["Restelli", "Marcello", ""]]}, {"id": "1909.03991", "submitter": "Changlin Wan", "authors": "Changlin Wan, Wennan Chang, Tong Zhao, Mengya Li, Sha Cao, Chi Zhang", "title": "Fast And Efficient Boolean Matrix Factorization By Geometric\n  Segmentation", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean matrix has been used to represent digital information in many fields,\nincluding bank transaction, crime records, natural language processing,\nprotein-protein interaction, etc. Boolean matrix factorization (BMF) aims to\nfind an approximation of a binary matrix as the Boolean product of two low rank\nBoolean matrices, which could generate vast amount of information for the\npatterns of relationships between the features and samples. Inspired by binary\nmatrix permutation theories and geometric segmentation, we developed a fast and\nefficient BMF approach called MEBF (Median Expansion for Boolean\nFactorization). Overall, MEBF adopted a heuristic approach to locate binary\npatterns presented as submatrices that are dense in 1's. At each iteration,\nMEBF permutates the rows and columns such that the permutated matrix is\napproximately Upper Triangular-Like (UTL) with so-called Simultaneous\nConsecutive-ones Property (SC1P). The largest submatrix dense in 1 would lies\non the upper triangular area of the permutated matrix, and its location was\ndetermined based on a geometric segmentation of a triangular. We compared MEBF\nwith other state of the art approaches on data scenarios with different\nsparsity and noise levels. MEBF demonstrated superior performances in lower\nreconstruction error, and higher computational efficiency, as well as more\naccurate sparse patterns than popular methods such as ASSO, PANDA and MP. We\ndemonstrated the application of MEBF on both binary and non-binary data sets,\nand revealed its further potential in knowledge retrieving and data denoising.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:02:57 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 19:17:30 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Wan", "Changlin", ""], ["Chang", "Wennan", ""], ["Zhao", "Tong", ""], ["Li", "Mengya", ""], ["Cao", "Sha", ""], ["Zhang", "Chi", ""]]}, {"id": "1909.03999", "submitter": "Amit Livne", "authors": "Amit Livne, Moshe Unger, Bracha Shapira and Lior Rokach", "title": "Deep Context-Aware Recommender System Utilizing Sequential Latent\n  Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-aware recommender systems (CARSs) apply sensing and analysis of user\ncontext in order to provide personalized services. Adding context to a\nrecommendation model is challenging, since the addition of context may\nincreases both the dimensionality and sparsity of the model. Recent research\nhas shown that modeling contextual information as a latent vector may address\nthe sparsity and dimensionality challenges. We suggest a new latent modeling of\nsequential context by generating sequences of contextual information and\nreducing their contextual space to a compressed latent space.We train a long\nshort-term memory (LSTM) encoder-decoder network on sequences of contextual\ninformation and extract sequential latent context from the hidden layer of the\nnetwork in order to represent a compressed representation of sequential data.\nWe propose new context-aware recommendation models that extend the neural\ncollaborative filtering approach and learn nonlinear interactions between\nlatent features of users, items, and contexts which take into account the\nsequential latent context representation as part of the recommendation process.\nWe deployed our approach using two context-aware datasets with different\ncontext dimensions. Empirical analysis of our results validates that our\nproposed sequential latent context-aware model (SLCM), surpasses state of the\nart CARS models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:20:15 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 06:57:30 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Livne", "Amit", ""], ["Unger", "Moshe", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1909.04010", "submitter": "Damian Campo", "authors": "Damian Campo, Alejandro Betancourt, Lucio Marcenaro, Carlo Regazzoni", "title": "Static force field representation of environments based on agents\n  nonlinear motions", "comments": null, "journal-ref": "EURASIP Journal on Advances in Signal Processing, December 2017,\n  2017:13", "doi": "10.1186/s13634-017-0444-5", "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology that aims at the incremental representation\nof areas inside environments in terms of attractive forces. It is proposed a\nparametric representation of velocity fields ruling the dynamics of moving\nagents. It is assumed that attractive spots in the environment are responsible\nfor modifying the motion of agents. A switching model is used to describe near\nand far velocity fields, which in turn are used to learn attractive\ncharacteristics of environments. The effect of such areas is considered radial\nover all the scene. Based on the estimation of attractive areas, a map that\ndescribes their effects in terms of their localizations, ranges of action, and\nintensities is derived in an online way. Information of static attractive areas\nis added dynamically into a set of filters that describes possible interactions\nbetween moving agents and an environment. The proposed approach is first\nevaluated on synthetic data; posteriorly, the method is applied on real\ntrajectories coming from moving pedestrians in an indoor environment.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:46:16 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Campo", "Damian", ""], ["Betancourt", "Alejandro", ""], ["Marcenaro", "Lucio", ""], ["Regazzoni", "Carlo", ""]]}, {"id": "1909.04013", "submitter": "Maciej Koch-Janusz", "authors": "Vlad Pushkarov, Jonathan Efroni, Mykola Maksymenko and Maciej\n  Koch-Janusz", "title": "Training Deep Neural Networks by optimizing over nonlocal paths in\n  hyperparameter space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization is both a practical issue and an interesting\ntheoretical problem in training of deep architectures. Despite many recent\nadvances the most commonly used methods almost universally involve training\nmultiple and decoupled copies of the model, in effect sampling the\nhyperparameter space. We show that at a negligible additional computational\ncost, results can be improved by sampling nonlocal paths instead of points in\nhyperparameter space. To this end we interpret hyperparameters as controlling\nthe level of correlated noise in training, which can be mapped to an effective\ntemperature. The usually independent instances of the model are coupled and\nallowed to exchange their hyperparameters throughout the training using the\nwell established parallel tempering technique of statistical physics. Each\nsimulation corresponds then to a unique path, or history, in the joint\nhyperparameter/model-parameter space. We provide empirical tests of our method,\nin particular for dropout and learning rate optimization. We observed faster\ntraining and improved resistance to overfitting and showed a systematic\ndecrease in the absolute validation error, improving over benchmark results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:49:15 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pushkarov", "Vlad", ""], ["Efroni", "Jonathan", ""], ["Maksymenko", "Mykola", ""], ["Koch-Janusz", "Maciej", ""]]}, {"id": "1909.04019", "submitter": "Yang Li", "authors": "Yang Li and Jos\\'e M. F. Moura", "title": "Forecaster: A Graph Transformer for Forecasting Spatial and\n  Time-Dependent Data", "comments": null, "journal-ref": "in European Conference on Artificial Intelligence (ECAI), pp. 1293\n  - 1300, 2020", "doi": "10.3233/FAIA200231", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial and time-dependent data is of interest in many applications. This\ntask is difficult due to its complex spatial dependency, long-range temporal\ndependency, data non-stationarity, and data heterogeneity. To address these\nchallenges, we propose Forecaster, a graph Transformer architecture.\nSpecifically, we start by learning the structure of the graph that\nparsimoniously represents the spatial dependency between the data at different\nlocations. Based on the topology of the graph, we sparsify the Transformer to\naccount for the strength of spatial dependency, long-range temporal dependency,\ndata non-stationarity, and data heterogeneity. We evaluate Forecaster in the\nproblem of forecasting taxi ride-hailing demand and show that our proposed\narchitecture significantly outperforms the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:58:43 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 20:41:59 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 12:19:38 GMT"}, {"version": "v4", "created": "Tue, 14 Jan 2020 19:53:12 GMT"}, {"version": "v5", "created": "Fri, 21 Feb 2020 00:00:14 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Li", "Yang", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "1909.04021", "submitter": "Yosuke Shinya", "authors": "Yosuke Shinya, Edgar Simo-Serra, Taiji Suzuki", "title": "Understanding the Effects of Pre-Training for Object Detectors via\n  Eigenspectrum", "comments": "ICCV 2019 Workshop on Neural Architects (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ImageNet pre-training has been regarded as essential for training accurate\nobject detectors for a long time. Recently, it has been shown that object\ndetectors trained from randomly initialized weights can be on par with those\nfine-tuned from ImageNet pre-trained models. However, the effects of\npre-training and the differences caused by pre-training are still not fully\nunderstood. In this paper, we analyze the eigenspectrum dynamics of the\ncovariance matrix of each feature map in object detectors. Based on our\nanalysis on ResNet-50, Faster R-CNN with FPN, and Mask R-CNN, we show that\nobject detectors trained from ImageNet pre-trained models and those trained\nfrom scratch behave differently from each other even if both object detectors\nhave similar accuracy. Furthermore, we propose a method for automatically\ndetermining the widths (the numbers of channels) of object detectors based on\nthe eigenspectrum. We train Faster R-CNN with FPN from randomly initialized\nweights, and show that our method can reduce ~27% of the parameters of\nResNet-50 without increasing Multiply-Accumulate operations and losing\naccuracy. Our results indicate that we should develop more appropriate methods\nfor transferring knowledge from image classification to object detection (or\nother tasks).\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:59:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shinya", "Yosuke", ""], ["Simo-Serra", "Edgar", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1909.04060", "submitter": "Alireza Vafaei Sadr", "authors": "Alireza Vafaei Sadr, Bruce A. Bassett and Martin Kunz", "title": "A Flexible Framework for Anomaly Detection via Dimensionality Reduction", "comments": "6 pages", "journal-ref": "Proceeding, 6th International Conference on Soft Computing &\n  Machine Intelligence (ISCMI), Johannesburg, South Africa, 2019, pp. 106-110", "doi": "10.1109/ISCMI47871.2019.9004400", "report-no": null, "categories": "cs.LG astro-ph.IM cs.AI stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is challenging, especially for large datasets in high\ndimensions. Here we explore a general anomaly detection framework based on\ndimensionality reduction and unsupervised clustering. We release DRAMA, a\ngeneral python package that implements the general framework with a wide range\nof built-in options. We test DRAMA on a wide variety of simulated and real\ndatasets, in up to 3000 dimensions, and find it robust and highly competitive\nwith commonly-used anomaly detection algorithms, especially in high dimensions.\nThe flexibility of the DRAMA framework allows for significant optimization once\nsome examples of anomalies are available, making it ideal for online anomaly\ndetection, active learning and highly unbalanced datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:00:12 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Sadr", "Alireza Vafaei", ""], ["Bassett", "Bruce A.", ""], ["Kunz", "Martin", ""]]}, {"id": "1909.04063", "submitter": "Thomas Barrett Dr", "authors": "Thomas D. Barrett, William R. Clements, Jakob N. Foerster, A. I.\n  Lvovsky", "title": "Exploratory Combinatorial Optimization with Reinforcement Learning", "comments": "In Proceedings of the 34th National Conference on Artificial\n  Intelligence, AAAI 2020", "journal-ref": "Proceedings of Thirty-fourth AAAI conference on artificial\n  intelligence, 3243-3250 (2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems can be reduced to combinatorial optimization on a\ngraph, where the subset or ordering of vertices that maximize some objective\nfunction must be found. With such tasks often NP-hard and analytically\nintractable, reinforcement learning (RL) has shown promise as a framework with\nwhich efficient heuristic methods to tackle these problems can be learned.\nPrevious works construct the solution subset incrementally, adding one element\nat a time, however, the irreversible nature of this approach prevents the agent\nfrom revising its earlier decisions, which may be necessary given the\ncomplexity of the optimization task. We instead propose that the agent should\nseek to continuously improve the solution by learning to explore at test time.\nOur approach of exploratory combinatorial optimization (ECO-DQN) is, in\nprinciple, applicable to any combinatorial problem that can be defined on a\ngraph. Experimentally, we show our method to produce state-of-the-art RL\nperformance on the Maximum Cut problem. Moreover, because ECO-DQN can start\nfrom any arbitrary configuration, it can be combined with other search methods\nto further improve performance, which we demonstrate using a simple random\nsearch.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:00:24 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 13:38:56 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Barrett", "Thomas D.", ""], ["Clements", "William R.", ""], ["Foerster", "Jakob N.", ""], ["Lvovsky", "A. I.", ""]]}, {"id": "1909.04068", "submitter": "Pratyush Maini", "authors": "Pratyush Maini, Eric Wong and J. Zico Kolter", "title": "Adversarial Robustness Against the Union of Multiple Perturbation Models", "comments": "ICML 2020 Final Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the susceptibility of deep learning systems to adversarial attacks,\nthere has been a great deal of work in developing (both empirically and\ncertifiably) robust classifiers. While most work has defended against a single\ntype of attack, recent work has looked at defending against multiple\nperturbation models using simple aggregations of multiple attacks. However,\nthese methods can be difficult to tune, and can easily result in imbalanced\ndegrees of robustness to individual perturbation models, resulting in a\nsub-optimal worst-case loss over the union. In this work, we develop a natural\ngeneralization of the standard PGD-based procedure to incorporate multiple\nperturbation models into a single attack, by taking the worst-case over all\nsteepest descent directions. This approach has the advantage of directly\nconverging upon a trade-off between different perturbation models which\nminimizes the worst-case performance over the union. With this approach, we are\nable to train standard architectures which are simultaneously robust against\n$\\ell_\\infty$, $\\ell_2$, and $\\ell_1$ attacks, outperforming past approaches on\nthe MNIST and CIFAR10 datasets and achieving adversarial accuracy of 47.0%\nagainst the union of ($\\ell_\\infty$, $\\ell_2$, $\\ell_1$) perturbations with\nradius = (0.03, 0.5, 12) on the latter, improving upon previous approaches\nwhich achieve 40.6% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:02:09 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 21:44:04 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Maini", "Pratyush", ""], ["Wong", "Eric", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1909.04078", "submitter": "Riccardo La Grassa", "authors": "Riccardo La Grassa, Ignazio Gallo, Alessandro Calefati, Dimitri\n  Ognibene", "title": "A Classification Methodology based on Subspace Graphs Learning", "comments": "8 pages, Dicta Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a design methodology for one-class classifiers\nusing an ensemble-of-classifiers approach. The objective is to select the best\nstructures created during the training phase using an ensemble of spanning\ntrees. It takes the best classifier, partitioning the area near a pattern into\n$\\gamma^{\\gamma-2}$ sub-spaces and combining all possible spanning trees that\ncan be created starting from $\\gamma$ nodes. The proposed method leverages on a\nsupervised classification methodology and the concept of minimum distance. We\nevaluate our approach on well-known benchmark datasets and results obtained\ndemonstrate that it achieves comparable and, in many cases, state-of-the-art\nresults. Moreover, it obtains good performance even with unbalanced datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:10:06 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["La Grassa", "Riccardo", ""], ["Gallo", "Ignazio", ""], ["Calefati", "Alessandro", ""], ["Ognibene", "Dimitri", ""]]}, {"id": "1909.04079", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Bindya Venkatesh, Prasanna Sattigeri,\n  Peer-Timo Bremer", "title": "Building Calibrated Deep Models via Uncertainty Matching with Auxiliary\n  Interval Predictors", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid adoption of deep learning in critical applications, the question\nof when and how much to trust these models often arises, which drives the need\nto quantify the inherent uncertainties. While identifying all sources that\naccount for the stochasticity of models is challenging, it is common to augment\npredictions with confidence intervals to convey the expected variations in a\nmodel's behavior. We require prediction intervals to be well-calibrated,\nreflect the true uncertainties, and to be sharp. However, existing techniques\nfor obtaining prediction intervals are known to produce unsatisfactory results\nin at least one of these criteria. To address this challenge, we develop a\nnovel approach for building calibrated estimators. More specifically, we use\nseparate models for prediction and interval estimation, and pose a bi-level\noptimization problem that allows the former to leverage estimates from the\nlatter through an \\textit{uncertainty matching} strategy. Using experiments in\nregression, time-series forecasting, and object localization, we show that our\napproach achieves significant improvements over existing uncertainty\nquantification methods, both in terms of model fidelity and calibration error.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:10:50 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 17:40:26 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Venkatesh", "Bindya", ""], ["Sattigeri", "Prasanna", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1909.04115", "submitter": "Pierluca D'Oro", "authors": "Pierluca D'Oro, Alberto Maria Metelli, Andrea Tirinzoni, Matteo\n  Papini, Marcello Restelli", "title": "Gradient-Aware Model-based Policy Search", "comments": null, "journal-ref": null, "doi": "10.1609/aaai.v34i04.5791", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional model-based reinforcement learning approaches learn a model of\nthe environment dynamics without explicitly considering how it will be used by\nthe agent. In the presence of misspecified model classes, this can lead to poor\nestimates, as some relevant available information is ignored. In this paper, we\nintroduce a novel model-based policy search approach that exploits the\nknowledge of the current agent policy to learn an approximate transition model,\nfocusing on the portions of the environment that are most relevant for policy\nimprovement. We leverage a weighting scheme, derived from the minimization of\nthe error on the model-based policy gradient estimator, in order to define a\nsuitable objective function that is optimized for learning the approximate\ntransition model. Then, we integrate this procedure into a batch policy\nimprovement algorithm, named Gradient-Aware Model-based Policy Search (GAMPS),\nwhich iteratively learns a transition model and uses it, together with the\ncollected trajectories, to compute the new policy parameters. Finally, we\nempirically validate GAMPS on benchmark domains analyzing and discussing its\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:26:27 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 22:17:37 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["D'Oro", "Pierluca", ""], ["Metelli", "Alberto Maria", ""], ["Tirinzoni", "Andrea", ""], ["Papini", "Matteo", ""], ["Restelli", "Marcello", ""]]}, {"id": "1909.04121", "submitter": "Andrey Kurenkov", "authors": "Andrey Kurenkov, Ajay Mandlekar, Roberto Martin-Martin, Silvio\n  Savarese, Animesh Garg", "title": "AC-Teach: A Bayesian Actor-Critic Method for Policy Learning with an\n  Ensemble of Suboptimal Teachers", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration mechanism used by a Deep Reinforcement Learning (RL) agent\nplays a key role in determining its sample efficiency. Thus, improving over\nrandom exploration is crucial to solve long-horizon tasks with sparse rewards.\nWe propose to leverage an ensemble of partial solutions as teachers that guide\nthe agent's exploration with action suggestions throughout training. While the\nsetup of learning with teachers has been previously studied, our proposed\napproach - Actor-Critic with Teacher Ensembles (AC-Teach) - is the first to\nwork with an ensemble of suboptimal teachers that may solve only part of the\nproblem or contradict other each other, forming a unified algorithmic solution\nthat is compatible with a broad range of teacher ensembles. AC-Teach leverages\na probabilistic representation of the expected outcome of the teachers' and\nstudent's actions to direct exploration, reduce dithering, and adapt to the\ndynamically changing quality of the learner. We evaluate a variant of AC-Teach\nthat guides the learning of a Bayesian DDPG agent on three tasks - path\nfollowing, robotic pick and place, and robotic cube sweeping using a hook - and\nshow that it improves largely on sampling efficiency over a set of baselines,\nboth for our target scenario of unconstrained suboptimal teachers and for\neasier setups with optimal or single teachers. Additional results and videos at\nhttps://sites.google.com/view/acteach/home.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:38:25 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 09:14:07 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 00:15:26 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kurenkov", "Andrey", ""], ["Mandlekar", "Ajay", ""], ["Martin-Martin", "Roberto", ""], ["Savarese", "Silvio", ""], ["Garg", "Animesh", ""]]}, {"id": "1909.04131", "submitter": "Hristos Tyralis", "authors": "Hristos Tyralis, Georgia Papacharalampous, Andreas Langousis", "title": "Super ensemble learning for daily streamflow forecasting: Large-scale\n  demonstration and comparison with multiple machine learning algorithms", "comments": null, "journal-ref": "Neural Computing and Applications 33 (2021) 3053-3068", "doi": "10.1007/s00521-020-05172-3", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Daily streamflow forecasting through data-driven approaches is traditionally\nperformed using a single machine learning algorithm. Existing applications are\nmostly restricted to examination of few case studies, not allowing accurate\nassessment of the predictive performance of the algorithms involved. Here we\npropose super learning (a type of ensemble learning) by combining 10 machine\nlearning algorithms. We apply the proposed algorithm in one-step ahead\nforecasting mode. For the application, we exploit a big dataset consisting of\n10-year long time series of daily streamflow, precipitation and temperature\nfrom 511 basins. The super learner improves over the performance of the linear\nregression algorithm by 20.06%, outperforming the \"hard to beat in practice\"\nequal weight combiner. The latter improves over the performance of the linear\nregression algorithm by 19.21%. The best performing individual machine learning\nalgorithm is neural networks, which improves over the performance of the linear\nregression algorithm by 16.73%, followed by extremely randomized trees\n(16.40%), XGBoost (15.92%), loess (15.36%), random forests (12.75%), polyMARS\n(12.36%), MARS (4.74%), lasso (0.11%) and support vector regression (-0.45%).\nBased on the obtained large-scale results, we propose super learning for daily\nstreamflow forecasting.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:01:53 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 18:50:47 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Tyralis", "Hristos", ""], ["Papacharalampous", "Georgia", ""], ["Langousis", "Andreas", ""]]}, {"id": "1909.04134", "submitter": "Rahul Ramesh", "authors": "Arjun Manoharan, Rahul Ramesh, and Balaraman Ravindran", "title": "Option Encoder: A Framework for Discovering a Policy Basis in\n  Reinforcement Learning", "comments": "ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Option discovery and skill acquisition frameworks are integral to the\nfunctioning of a Hierarchically organized Reinforcement learning agent.\nHowever, such techniques often yield a large number of options or skills, which\ncan potentially be represented succinctly by filtering out any redundant\ninformation. Such a reduction can reduce the required computation while also\nimproving the performance on a target task. In order to compress an array of\noption policies, we attempt to find a policy basis that accurately captures the\nset of all options. In this work, we propose Option Encoder, an auto-encoder\nbased framework with intelligently constrained weights, that helps discover a\ncollection of basis policies. The policy basis can be used as a proxy for the\noriginal set of skills in a suitable hierarchically organized framework. We\ndemonstrate the efficacy of our method on a collection of grid-worlds and on\nthe high-dimensional Fetch-Reach robotic manipulation task by evaluating the\nobtained policy basis on a set of downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:10:12 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 05:50:15 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 08:12:02 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Manoharan", "Arjun", ""], ["Ramesh", "Rahul", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1909.04142", "submitter": "Lin Xu", "authors": "Justin Quan, Lin Xu, Rene Xu, Tyrael Tong, and Jean Su", "title": "DaTscan SPECT Image Classification for Parkinson's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's Disease (PD) is a neurodegenerative disease that currently does\nnot have a cure. In order to facilitate disease management and reduce the speed\nof symptom progression, early diagnosis is essential. The current clinical,\ndiagnostic approach is to have radiologists perform human visual analysis of\nthe degeneration of dopaminergic neurons in the substantia nigra region of the\nbrain. Clinically, dopamine levels are monitored through observing dopamine\ntransporter (DaT) activity. One method of DaT activity analysis is performed\nwith the injection of an Iodine-123 fluoropropyl (123I-FP-CIT) tracer combined\nwith single photon emission computerized tomography (SPECT) imaging. The tracer\nillustrates the region of interest in the resulting DaTscan SPECT images. Human\nvisual analysis is slow and vulnerable to subjectivity between radiologists, so\nthe goal was to develop an introductory implementation of a deep convolutional\nneural network that can objectively and accurately classify DaTscan SPECT\nimages as Parkinson's Disease or normal. This study illustrates the approach of\nusing a deep convolutional neural network and evaluates its performance on\nDaTscan SPECT image classification. The data used in this study was obtained\nthrough a database provided by the Parkinson's Progression Markers Initiative\n(PPMI). The deep neural network in this study utilizes the InceptionV3\narchitecture, 1st runner up in the 2015 ImageNet Large Scale Visual Recognition\nCompetition (ILSVRC), as a base model. A custom, binary classifier block was\nadded on top of this base. In order to account for the small dataset size, a\nten fold cross validation was implemented to evaluate the model's performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:35:23 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Quan", "Justin", ""], ["Xu", "Lin", ""], ["Xu", "Rene", ""], ["Tong", "Tyrael", ""], ["Su", "Jean", ""]]}, {"id": "1909.04157", "submitter": "Liang Lu", "authors": "Liang Lu, Eric Sun and Yifan Gong", "title": "Self-Teaching Networks", "comments": "5 pages, Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose self-teaching networks to improve the generalization capacity of\ndeep neural networks. The idea is to generate soft supervision labels using the\noutput layer for training the lower layers of the network. During the network\ntraining, we seek an auxiliary loss that drives the lower layer to mimic the\nbehavior of the output layer. The connection between the two network layers\nthrough the auxiliary loss can help the gradient flow, which works similar to\nthe residual networks. Furthermore, the auxiliary loss also works as a\nregularizer, which improves the generalization capacity of the network. We\nevaluated the self-teaching network with deep recurrent neural networks on\nspeech recognition tasks, where we trained the acoustic model using 30 thousand\nhours of data. We tested the acoustic model using data collected from 4\nscenarios. We show that the self-teaching network can achieve consistent\nimprovements and outperform existing methods such as label smoothing and\nconfidence penalization.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:11:35 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lu", "Liang", ""], ["Sun", "Eric", ""], ["Gong", "Yifan", ""]]}, {"id": "1909.04170", "submitter": "Giacomo Spigler", "authors": "Giacomo Spigler", "title": "Meta-learnt priors slow down catastrophic forgetting in neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current training regimes for deep learning usually involve exposure to a\nsingle task / dataset at a time. Here we start from the observation that in\nthis context the trained model is not given any knowledge of anything outside\nits (single-task) training distribution, and has thus no way to learn\nparameters (i.e., feature detectors or policies) that could be helpful to solve\nother tasks, and to limit future interference with the acquired knowledge, and\nthus catastrophic forgetting. Here we show that catastrophic forgetting can be\nmitigated in a meta-learning context, by exposing a neural network to multiple\ntasks in a sequential manner during training. Finally, we present SeqFOMAML, a\nmeta-learning algorithm that implements these principles, and we evaluate it on\nsequential learning problems composed by Omniglot and MiniImageNet\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:46:19 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 16:39:32 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Spigler", "Giacomo", ""]]}, {"id": "1909.04188", "submitter": "Zheyuan Zhu", "authors": "Zheyuan Zhu, Yangyang Sun, Johnathon White, Zenghu Chang and Shuo Pang", "title": "Signal retrieval with measurement system knowledge using variational\n  generative model", "comments": "8 pages, 5 figures. Initial submission to IEEE Transactions on\n  Computational Imaging", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2978435", "report-no": null, "categories": "eess.IV cs.LG eess.SP physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal retrieval from a series of indirect measurements is a common task in\nmany imaging, metrology and characterization platforms in science and\nengineering. Because most of the indirect measurement processes are\nwell-described by physical models, signal retrieval can be solved with an\niterative optimization that enforces measurement consistency and prior\nknowledge on the signal. These iterative processes are time-consuming and only\naccommodate a linear measurement process and convex signal constraints.\nRecently, neural networks have been widely adopted to supersede iterative\nsignal retrieval methods by approximating the inverse mapping of the\nmeasurement model. However, networks with deterministic processes have failed\nto distinguish signal ambiguities in an ill-posed measurement system, and\nretrieved signals often lack consistency with the measurement. In this work we\nintroduce a variational generative model to capture the distribution of all\npossible signals, given a particular measurement. By exploiting the known\nmeasurement model in the variational generative framework, our signal retrieval\nprocess resolves the ambiguity in the forward process, and learns to retrieve\nsignals that satisfy the measurement with high fidelity in a variety of linear\nand nonlinear ill-posed systems, including ultrafast pulse retrieval, coded\naperture compressive video sensing and image retrieval from Fresnel hologram.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 22:41:33 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zhu", "Zheyuan", ""], ["Sun", "Yangyang", ""], ["White", "Johnathon", ""], ["Chang", "Zenghu", ""], ["Pang", "Shuo", ""]]}, {"id": "1909.04190", "submitter": "Nhan Nguyen-Thanh", "authors": "Nhan Nguyen-Thanh, Dana Marinca, Kinda Khawam, David Rohde, Flavian\n  Vasile, Elena Simona Lohan, Steven Martin, Dominique Quadri", "title": "Recommendation System-based Upper Confidence Bound for Online\n  Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the method UCB-RS, which resorts to recommendation system (RS)\nfor enhancing the upper-confidence bound algorithm UCB, is presented. The\nproposed method is used for dealing with non-stationary and large-state spaces\nmulti-armed bandit problems. The proposed method has been targeted to the\nproblem of the product recommendation in the online advertising. Through\nextensive testing with RecoGym, an OpenAI Gym-based reinforcement learning\nenvironment for the product recommendation in online advertising, the proposed\nmethod outperforms the widespread reinforcement learning schemes such as\n$\\epsilon$-Greedy, Upper Confidence (UCB1) and Exponential Weights for\nExploration and Exploitation (EXP3).\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 22:43:33 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Nguyen-Thanh", "Nhan", ""], ["Marinca", "Dana", ""], ["Khawam", "Kinda", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""], ["Lohan", "Elena Simona", ""], ["Martin", "Steven", ""], ["Quadri", "Dominique", ""]]}, {"id": "1909.04196", "submitter": "Yohei Sawada", "authors": "Yohei Sawada", "title": "Machine learning accelerates parameter optimization and uncertainty\n  assessment of a land surface model", "comments": "53 pages, 19 figures", "journal-ref": null, "doi": "10.1029/2020JD032688", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of land surface models (LSMs) significantly affects the\nunderstanding of atmospheric and related processes. Many of the LSMs' soil and\nvegetation parameters were unknown so that it is crucially important to\nefficiently optimize them. Here I present a globally applicable and\ncomputationally efficient method for parameter optimization and uncertainty\nassessment of the LSM by combining Markov Chain Monte Carlo (MCMC) with machine\nlearning. First, I performed the long-term (decadal scales) ensemble simulation\nof the LSM, in which each ensemble member has different parameters' values, and\ncalculated the gap between simulation and observation, or the cost function,\nfor each ensemble member. Second, I developed the statistical machine learning\nbased surrogate model, which is computationally cheap but accurately mimics the\nrelationship between parameters and the cost function, by applying the Gaussian\nprocess regression to learn the model simulation. Third, we applied MCMC by\nrepeatedly driving the surrogate model to get the posterior probabilistic\ndistribution of parameters. Using satellite passive microwave brightness\ntemperature observations, both synthetic and real-data experiments in the Sahel\nregion of west Africa were performed to optimize unknown soil and vegetation\nparameters of the LSM. The primary findings are (1) the proposed method is\n50,000 times as fast as the direct application of MCMC to the full LSM; (2) the\nskill of the LSM to simulate both soil moisture and vegetation dynamics can be\nimproved; (3) I successfully quantify the characteristics of equifinality by\nobtaining the full non-parametric probabilistic distribution of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 23:47:03 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 00:53:45 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sawada", "Yohei", ""]]}, {"id": "1909.04200", "submitter": "Isaac Ahern", "authors": "Isaac Ahern, Adam Noack, Luis Guzman-Nateras, Dejing Dou, Boyang Li,\n  and Jun Huan", "title": "NormLime: A New Feature Importance Metric for Explaining Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of explaining deep learning models, and model predictions\ngenerally, has attracted intensive interest recently. Many successful\napproaches forgo global approximations in order to provide more faithful local\ninterpretations of the model's behavior. LIME develops multiple interpretable\nmodels, each approximating a large neural network on a small region of the data\nmanifold and SP-LIME aggregates the local models to form a global\ninterpretation. Extending this line of research, we propose a simple yet\neffective method, NormLIME for aggregating local models into global and\nclass-specific interpretations. A human user study strongly favored\nclass-specific interpretations created by NormLIME to other feature importance\nmetrics. Numerical experiments confirm that NormLIME is effective at\nrecognizing important features.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 00:01:51 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 04:43:35 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Ahern", "Isaac", ""], ["Noack", "Adam", ""], ["Guzman-Nateras", "Luis", ""], ["Dou", "Dejing", ""], ["Li", "Boyang", ""], ["Huan", "Jun", ""]]}, {"id": "1909.04202", "submitter": "Baihong Jin", "authors": "Baihong Jin, Yingshui Tan, Yuxin Chen, Alberto Sangiovanni-Vincentelli", "title": "Augmenting Monte Carlo Dropout Classification Models with Unsupervised\n  Learning Tasks for Detecting and Diagnosing Out-of-Distribution Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Monte Carlo dropout method has proved to be a scalable and easy-to-use\napproach for estimating the uncertainty of deep neural network predictions.\nThis approach was recently applied to Fault Detection and Di-agnosis (FDD)\napplications to improve the classification performance on incipient faults. In\nthis paper, we propose a novel approach of augmenting the classification model\nwith an additional unsupervised learning task. We justify our choice of\nalgorithm design via an information-theoretical analysis. Our experimental\nresults on three datasets from diverse application domains show that the\nproposed method leads to improved fault detection and diagnosis performance,\nespecially on out-of-distribution examples including both incipient and unknown\nfaults.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 00:07:28 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Jin", "Baihong", ""], ["Tan", "Yingshui", ""], ["Chen", "Yuxin", ""], ["Sangiovanni-Vincentelli", "Alberto", ""]]}, {"id": "1909.04203", "submitter": "C.B. Scott", "authors": "C.B. Scott, Eric Mjolsness", "title": "Novel diffusion-derived distance measures for graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define a new family of similarity and distance measures on graphs, and\nexplore their theoretical properties in comparison to conventional distance\nmetrics. These measures are defined by the solution(s) to an optimization\nproblem which attempts find a map minimizing the discrepancy between two graph\nLaplacian exponential matrices, under norm-preserving and sparsity constraints.\nVariants of the distance metric are introduced to consider such optimized maps\nunder sparsity constraints as well as fixed time-scaling between the two\nLaplacians. The objective function of this optimization is multimodal and has\ndiscontinuous slope, and is hence difficult for univariate optimizers to solve.\nWe demonstrate a novel procedure for efficiently calculating these optima for\ntwo of our distance measure variants. We present numerical experiments\ndemonstrating that (a) upper bounds of our distance metrics can be used to\ndistinguish between lineages of related graphs; (b) our procedure is faster at\nfinding the required optima, by as much as a factor of 10^3; and (c) the upper\nbounds satisfy the triangle inequality exactly under some assumptions and\napproximately under others. We also derive an upper bound for the distance\nbetween two graph products, in terms of the distance between the two pairs of\nfactors. Additionally, we present several possible applications, including the\nconstruction of infinite \"graph limits\" by means of Cauchy sequences of graphs\nrelated to one another by our distance measure.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 00:17:18 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Scott", "C. B.", ""], ["Mjolsness", "Eric", ""]]}, {"id": "1909.04217", "submitter": "Xinyi Ding", "authors": "Xinyi Ding, Zohreh Raziei, Eric C. Larson, Eli V. Olinick, Paul\n  Krueger, Michael Hahsler", "title": "Swapped Face Detection using Deep Learning and Subjective Assessment", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous success of deep learning for imaging applications has resulted\nin numerous beneficial advances. Unfortunately, this success has also been a\ncatalyst for malicious uses such as photo-realistic face swapping of parties\nwithout consent. Transferring one person's face from a source image to a target\nimage of another person, while keeping the image photo-realistic overall has\nbecome increasingly easy and automatic, even for individuals without much\nknowledge of image processing. In this study, we use deep transfer learning for\nface swapping detection, showing true positive rates >96% with very few false\nalarms. Distinguished from existing methods that only provide detection\naccuracy, we also provide uncertainty for each prediction, which is critical\nfor trust in the deployment of such detection systems. Moreover, we provide a\ncomparison to human subjects. To capture human recognition performance, we\nbuild a website to collect pairwise comparisons of images from human subjects.\nBased on these comparisons, images are ranked from most real to most fake. We\ncompare this ranking to the outputs from our automatic model, showing good, but\nimperfect, correspondence with linear correlations >0.75. Overall, the results\nshow the effectiveness of our method. As part of this study, we create a novel,\npublicly available dataset that is, to the best of our knowledge, the largest\npublic swapped face dataset created using still images. Our goal of this study\nis to inspire more research in the field of image forensics through the\ncreation of a public dataset and initial analysis.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 01:06:43 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Ding", "Xinyi", ""], ["Raziei", "Zohreh", ""], ["Larson", "Eric C.", ""], ["Olinick", "Eli V.", ""], ["Krueger", "Paul", ""], ["Hahsler", "Michael", ""]]}, {"id": "1909.04236", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Mohammad Ghavamzadeh, Shie Mannor", "title": "Online Planning with Lookahead Policies", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real Time Dynamic Programming (RTDP) is an online algorithm based on Dynamic\nProgramming (DP) that acts by 1-step greedy planning. Unlike DP, RTDP does not\nrequire access to the entire state space, i.e., it explicitly handles the\nexploration. This fact makes RTDP particularly appealing when the state space\nis large and it is not possible to update all states simultaneously. In this we\ndevise a multi-step greedy RTDP algorithm, which we call $h$-RTDP, that\nreplaces the 1-step greedy policy with a $h$-step lookahead policy. We analyze\n$h$-RTDP in its exact form and establish that increasing the lookahead horizon,\n$h$, results in an improved sample complexity, with the cost of additional\ncomputations. This is the first work that proves improved sample complexity as\na result of {\\em increasing} the lookahead horizon in online planning. We then\nanalyze the performance of $h$-RTDP in three approximate settings: approximate\nmodel, approximate value updates, and approximate state representation. For\nthese cases, we prove that the asymptotic performance of $h$-RTDP remains the\nsame as that of a corresponding approximate DP algorithm, the best one can hope\nfor without further assumptions on the approximation errors.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:00:52 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 16:38:35 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Efroni", "Yonathan", ""], ["Ghavamzadeh", "Mohammad", ""], ["Mannor", "Shie", ""]]}, {"id": "1909.04239", "submitter": "Yitong Meng", "authors": "Yitong Meng, Xinyan Dai, Xiao Yan, James Cheng, Weiwen Liu, Benben\n  Liao, Jun Guo, Guangyong Chen", "title": "PMD: An Optimal Transportation-based User Distance for Recommender\n  Systems", "comments": "This paper is accepted by European Conference on Information\n  Retrieval (ECIR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering, a widely-used recommendation technique, predicts a\nuser's preference by aggregating the ratings from similar users. As a result,\nthese measures cannot fully utilize the rating information and are not suitable\nfor real world sparse data. To solve these issues, we propose a novel user\ndistance measure named Preference Mover's Distance (PMD) which makes full use\nof all ratings made by each user. Our proposed PMD can properly measure the\ndistance between a pair of users even if they have no co-rated items. We show\nthat this measure can be cast as an instance of the Earth Mover's Distance, a\nwell-studied transportation problem for which several highly efficient solvers\nhave been developed. Experimental results show that PMD can help achieve\nsuperior recommendation accuracy than state-of-the-art methods, especially when\ntraining data is very sparse.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:06:57 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 07:05:41 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Meng", "Yitong", ""], ["Dai", "Xinyan", ""], ["Yan", "Xiao", ""], ["Cheng", "James", ""], ["Liu", "Weiwen", ""], ["Liao", "Benben", ""], ["Guo", "Jun", ""], ["Chen", "Guangyong", ""]]}, {"id": "1909.04240", "submitter": "Stephan Hoyer", "authors": "Stephan Hoyer, Jascha Sohl-Dickstein, Sam Greydanus", "title": "Neural reparameterization improves structural optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural optimization is a popular method for designing objects such as\nbridge trusses, airplane wings, and optical devices. Unfortunately, the quality\nof solutions depends heavily on how the problem is parameterized. In this\npaper, we propose using the implicit bias over functions induced by neural\nnetworks to improve the parameterization of structural optimization. Rather\nthan directly optimizing densities on a grid, we instead optimize the\nparameters of a neural network which outputs those densities. This\nreparameterization leads to different and often better solutions. On a\nselection of 116 structural optimization tasks, our approach produces the best\ndesign 50% more often than the best baseline method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:07:09 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 00:22:41 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hoyer", "Stephan", ""], ["Sohl-Dickstein", "Jascha", ""], ["Greydanus", "Sam", ""]]}, {"id": "1909.04246", "submitter": "Yuanfu Lu", "authors": "Yuanfu Lu, Xiao Wang, Chuan Shi, Philip S. Yu, Yanfang Ye", "title": "Temporal Network Embedding with Micro- and Macro-dynamics", "comments": "CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding aims to embed nodes into a low-dimensional space, while\ncapturing the network structures and properties. Although quite a few promising\nnetwork embedding methods have been proposed, most of them focus on static\nnetworks. In fact, temporal networks, which usually evolve over time in terms\nof microscopic and macroscopic dynamics, are ubiquitous. The micro-dynamics\ndescribe the formation process of network structures in a detailed manner,\nwhile the macro-dynamics refer to the evolution pattern of the network scale.\nBoth micro- and macro-dynamics are the key factors to network evolution;\nhowever, how to elegantly capture both of them for temporal network embedding,\nespecially macro-dynamics, has not yet been well studied. In this paper, we\npropose a novel temporal network embedding method with micro- and\nmacro-dynamics, named $\\rm{M^2DNE}$. Specifically, for micro-dynamics, we\nregard the establishments of edges as the occurrences of chronological events\nand propose a temporal attention point process to capture the formation process\nof network structures in a fine-grained manner. For macro-dynamics, we define a\ngeneral dynamics equation parameterized with network embeddings to capture the\ninherent evolution pattern and impose constraints in a higher structural level\non network embeddings. Mutual evolutions of micro- and macro-dynamics in a\ntemporal network alternately affect the process of learning node embeddings.\nExtensive experiments on three real-world temporal networks demonstrate that\n$\\rm{M^2DNE}$ significantly outperforms the state-of-the-arts not only in\ntraditional tasks, e.g., network reconstruction, but also in temporal\ntendency-related tasks, e.g., scale prediction.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:43:43 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lu", "Yuanfu", ""], ["Wang", "Xiao", ""], ["Shi", "Chuan", ""], ["Yu", "Philip S.", ""], ["Ye", "Yanfang", ""]]}, {"id": "1909.04261", "submitter": "Wei Xie", "authors": "Wei Xie and Bo Wang and Cheng Li and Dongming Xie and Jared Auclair", "title": "Interpretable Biomanufacturing Process Risk and Sensitivity Analyses for\n  Quality-by-Design and Stability Control", "comments": "41 pages, 8 figures", "journal-ref": "Naval Research Logistics, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While biomanufacturing plays a significant role in supporting the economy and\nensuring public health, it faces critical challenges, including complexity,\nhigh variability, lengthy lead time, and very limited process data, especially\nfor personalized new cell and gene biotherapeutics. Driven by these challenges,\nwe propose an interpretable semantic bioprocess probabilistic knowledge graph\nand develop a game theory based risk and sensitivity analyses for production\nprocess to facilitate quality-by-design and stability control. Specifically, by\nexploring the causal relationships and interactions of critical process\nparameters and quality attributes (CPPs/CQAs), we create a Bayesian network\nbased probabilistic knowledge graph characterizing the complex causal\ninterdependencies of all factors. Then, we introduce a Shapley value based\nsensitivity analysis, which can correctly quantify the variation contribution\nfrom each input factor on the outputs (i.e., productivity, product quality).\nSince the bioprocess model coefficients are learned from limited process\nobservations, we derive the Bayesian posterior distribution to quantify model\nuncertainty and further develop the Shapley value based sensitivity analysis to\nevaluate the impact of estimation uncertainty from each set of model\ncoefficients. Therefore, the proposed bioprocess risk and sensitivity analyses\ncan identify the bottlenecks, guide the reliable process specifications and the\nmost \"informative\" data collection, and improve production stability.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 03:26:01 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 22:10:27 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 14:58:08 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 16:01:25 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Xie", "Wei", ""], ["Wang", "Bo", ""], ["Li", "Cheng", ""], ["Xie", "Dongming", ""], ["Auclair", "Jared", ""]]}, {"id": "1909.04266", "submitter": "Yitong Meng", "authors": "Yitong Meng, Guangyong Chen, Benben Liao, Jun Guo, Weiwen Liu", "title": "Wasserstein Collaborative Filtering for Item Cold-start Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The item cold-start problem seriously limits the recommendation performance\nof Collaborative Filtering (CF) methods when new items have either none or very\nlittle interactions. To solve this issue, many modern Internet applications\npropose to predict a new item's interaction from the possessing contents.\nHowever, it is difficult to design and learn a map between the item's\ninteraction history and the corresponding contents. In this paper, we apply the\nWasserstein distance to address the item cold-start problem. Given item content\ninformation, we can calculate the similarity between the interacted items and\ncold-start ones, so that a user's preference on cold-start items can be\ninferred by minimizing the Wasserstein distance between the distributions over\nthese two types of items. We further adopt the idea of CF and propose\nWasserstein CF (WCF) to improve the recommendation performance on cold-start\nitems. Experimental results demonstrate the superiority of WCF over\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 03:32:05 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Meng", "Yitong", ""], ["Chen", "Guangyong", ""], ["Liao", "Benben", ""], ["Guo", "Jun", ""], ["Liu", "Weiwen", ""]]}, {"id": "1909.04288", "submitter": "Zhenxin Xiao", "authors": "Zhenxin Xiao, Puyudi Yang, Yuchen Jiang, Kai-Wei Chang, Cho-Jui Hsieh", "title": "BOSH: An Efficient Meta Algorithm for Decision-based Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial example generation becomes a viable method for evaluating the\nrobustness of a machine learning model. In this paper, we consider hard-label\nblack-box attacks (a.k.a. decision-based attacks), which is a challenging\nsetting that generates adversarial examples based on only a series of black-box\nhard-label queries. This type of attacks can be used to attack discrete and\ncomplex models, such as Gradient Boosting Decision Tree (GBDT) and\ndetection-based defense models. Existing decision-based attacks based on\niterative local updates often get stuck in a local minimum and fail to generate\nthe optimal adversarial example with the smallest distortion. To remedy this\nissue, we propose an efficient meta algorithm called BOSH-attack, which\ntremendously improves existing algorithms through Bayesian Optimization (BO)\nand Successive Halving (SH). In particular, instead of traversing a single\nsolution path when searching an adversarial example, we maintain a pool of\nsolution paths to explore important regions. We show empirically that the\nproposed algorithm converges to a better solution than existing approaches,\nwhile the query count is smaller than applying multiple random initializations\nby a factor of 10.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:00:06 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 21:31:26 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 14:14:57 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xiao", "Zhenxin", ""], ["Yang", "Puyudi", ""], ["Jiang", "Yuchen", ""], ["Chang", "Kai-Wei", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1909.04293", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Christoph Bergmeir and Hansika Hewamalage", "title": "LSTM-MSNet: Leveraging Forecasts on Sets of Related Time Series with\n  Multiple Seasonal Patterns", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.2985720", "report-no": null, "categories": "stat.AP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating forecasts for time series with multiple seasonal cycles is an\nimportant use-case for many industries nowadays. Accounting for the\nmulti-seasonal patterns becomes necessary to generate more accurate and\nmeaningful forecasts in these contexts. In this paper, we propose Long\nShort-Term Memory Multi-Seasonal Net (LSTM-MSNet), a decomposition based,\nunified prediction framework to forecast time series with multiple seasonal\npatterns. The current state of the art in this space are typically univariate\nmethods, in which the model parameters of each time series are estimated\nindependently. Consequently, these models are unable to include key patterns\nand structures that may be shared by a collection of time series. In contrast,\nLSTM-MSNet is a globally trained Long Short-Term Memory network (LSTM), where a\nsingle prediction model is built across all the available time series to\nexploit the cross series knowledge in a group of related time series.\nFurthermore, our methodology combines a series of state-of-the-art\nmultiseasonal decomposition techniques to supplement the LSTM learning\nprocedure. In our experiments, we are able to show that on datasets from\ndisparate data sources, like e.g. the popular M4 forecasting competition, a\ndecomposition step is beneficial, whereas in the common real-world situation of\nhomogeneous series from a single application, exogenous seasonal variables or\nno seasonal preprocessing at all are better choices. All options are readily\nincluded in the framework and allow us to achieve competitive results for both\ncases, outperforming many state-of-the-art multi-seasonal forecasting methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:15:24 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 12:52:37 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bandara", "Kasun", ""], ["Bergmeir", "Christoph", ""], ["Hewamalage", "Hansika", ""]]}, {"id": "1909.04299", "submitter": "Gang Wang", "authors": "Gang Wang, Bingcong Li, Georgios B. Giannakis", "title": "A Multistep Lyapunov Approach for Finite-Time Analysis of Biased\n  Stochastic Approximation", "comments": "28 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the widespread use of temporal-difference (TD-) and Q-learning\nalgorithms in reinforcement learning, this paper studies a class of biased\nstochastic approximation (SA) procedures under a mild \"ergodic-like\" assumption\non the underlying stochastic noise sequence. Building upon a carefully designed\nmultistep Lyapunov function that looks ahead to several future updates to\naccommodate the stochastic perturbations (for control of the gradient bias), we\nprove a general result on the convergence of the iterates, and use it to derive\nnon-asymptotic bounds on the mean-square error in the case of constant\nstepsizes. This novel looking-ahead viewpoint renders finite-time analysis of\nbiased SA algorithms under a large family of stochastic perturbations possible.\nFor direct comparison with existing contributions, we also demonstrate these\nbounds by applying them to TD- and Q-learning with linear function\napproximation, under the practical Markov chain observation model. The\nresultant finite-time error bound for both the TD- as well as the Q-learning\nalgorithms is the first of its kind, in the sense that it holds i) for the\nunmodified versions (i.e., without making any modifications to the parameter\nupdates) using even nonlinear function approximators; as well as for Markov\nchains ii) under general mixing conditions and iii) starting from any initial\ndistribution, at least one of which has to be violated for existing results to\nbe applicable.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:27:58 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 03:25:23 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 13:54:24 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wang", "Gang", ""], ["Li", "Bingcong", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1909.04305", "submitter": "Junghyo Jo", "authors": "Junghyo Jo and Danh-Tai Hoang and Vipul Periwal", "title": "Inverse Ising inference from high-temperature re-weighting of\n  observations", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. E 101, 032107 (2020)", "doi": "10.1103/PhysRevE.101.032107", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Likelihood Estimation (MLE) is the bread and butter of system\ninference for stochastic systems. In some generality, MLE will converge to the\ncorrect model in the infinite data limit. In the context of physical approaches\nto system inference, such as Boltzmann machines, MLE requires the arduous\ncomputation of partition functions summing over all configurations, both\nobserved and unobserved. We present here a conceptually and computationally\ntransparent data-driven approach to system inference that is based on the\nsimple question: How should the Boltzmann weights of observed configurations be\nmodified to make the probability distribution of observed configurations close\nto a flat distribution? This algorithm gives accurate inference by using only\nobserved configurations for systems with a large number of degrees of freedom\nwhere other approaches are intractable.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:02:07 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Jo", "Junghyo", ""], ["Hoang", "Danh-Tai", ""], ["Periwal", "Vipul", ""]]}, {"id": "1909.04311", "submitter": "Byunggill Joe", "authors": "Byunggill Joe, Sung Ju Hwang, Insik Shin", "title": "Learning to Disentangle Robust and Vulnerable Features for Adversarial\n  Detection", "comments": "main: 10 pages appendix: 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks have shown promising performances on various\ntasks, even achieving human-level performance on some, they are shown to be\nsusceptible to incorrect predictions even with imperceptibly small\nperturbations to an input. There exists a large number of previous works which\nproposed to defend against such adversarial attacks either by robust inference\nor detection of adversarial inputs. Yet, most of them cannot effectively defend\nagainst whitebox attacks where an adversary has a knowledge of the model and\ndefense. More importantly, they do not provide a convincing reason why the\ngenerated adversarial inputs successfully fool the target models. To address\nthese shortcomings of the existing approaches, we hypothesize that the\nadversarial inputs are tied to latent features that are susceptible to\nadversarial perturbation, which we call vulnerable features. Then based on this\nintuition, we propose a minimax game formulation to disentangle the latent\nfeatures of each instance into robust and vulnerable ones, using variational\nautoencoders with two latent spaces. We thoroughly validate our model for both\nblackbox and whitebox attacks on MNIST, Fashion MNIST5, and Cat & Dog datasets,\nwhose results show that the adversarial inputs cannot bypass our detector\nwithout changing its semantics, in which case the attack has failed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:17:06 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Joe", "Byunggill", ""], ["Hwang", "Sung Ju", ""], ["Shin", "Insik", ""]]}, {"id": "1909.04324", "submitter": "Xianglei Xing", "authors": "Xianglei Xing, Tianfu Wu, Song-Chun Zhu, Ying Nian Wu", "title": "Inducing Hierarchical Compositional Model by Sparsifying Generator\n  Network", "comments": "This is the CVPR version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to learn hierarchical compositional AND-OR model for\ninterpretable image synthesis by sparsifying the generator network. The\nproposed method adopts the scene-objects-parts-subparts-primitives hierarchy in\nimage representation. A scene has different types (i.e., OR) each of which\nconsists of a number of objects (i.e., AND). This can be recursively formulated\nacross the scene-objects-parts-subparts hierarchy and is terminated at the\nprimitive level (e.g., wavelets-like basis). To realize this AND-OR hierarchy\nin image synthesis, we learn a generator network that consists of the following\ntwo components: (i) Each layer of the hierarchy is represented by an\nover-complete set of convolutional basis functions. Off-the-shelf convolutional\nneural architectures are exploited to implement the hierarchy. (ii)\nSparsity-inducing constraints are introduced in end-to-end training, which\ninduces a sparsely activated and sparsely connected AND-OR model from the\ninitially densely connected generator network. A straightforward\nsparsity-inducing constraint is utilized, that is to only allow the top-$k$\nbasis functions to be activated at each layer (where $k$ is a hyper-parameter).\nThe learned basis functions are also capable of image reconstruction to explain\nthe input images. In experiments, the proposed method is tested on four\nbenchmark datasets. The results show that meaningful and interpretable\nhierarchical representations are learned with better qualities of image\nsynthesis and reconstruction obtained than baselines.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 07:06:33 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 05:02:00 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Xing", "Xianglei", ""], ["Wu", "Tianfu", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1909.04344", "submitter": "Vinay Verma Kumar", "authors": "Vinay Kumar Verma, Dhanajit Brahma and Piyush Rai", "title": "A Meta-Learning Framework for Generalized Zero-Shot Learning", "comments": "Under Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to classify unseen class samples at test time is popularly referred\nto as zero-shot learning (ZSL). If test samples can be from training (seen) as\nwell as unseen classes, it is a more challenging problem due to the existence\nof strong bias towards seen classes. This problem is generally known as\n\\emph{generalized} zero-shot learning (GZSL). Thanks to the recent advances in\ngenerative models such as VAEs and GANs, sample synthesis based approaches have\ngained considerable attention for solving this problem. These approaches are\nable to handle the problem of class bias by synthesizing unseen class samples.\nHowever, these ZSL/GZSL models suffer due to the following key limitations:\n$(i)$ Their training stage learns a class-conditioned generator using only\n\\emph{seen} class data and the training stage does not \\emph{explicitly} learn\nto generate the unseen class samples; $(ii)$ They do not learn a generic\noptimal parameter which can easily generalize for both seen and unseen class\ngeneration; and $(iii)$ If we only have access to a very few samples per seen\nclass, these models tend to perform poorly. In this paper, we propose a\nmeta-learning based generative model that naturally handles these limitations.\nThe proposed model is based on integrating model-agnostic meta learning with a\nWasserstein GAN (WGAN) to handle $(i)$ and $(iii)$, and uses a novel task\ndistribution to handle $(ii)$. Our proposed model yields significant\nimprovements on standard ZSL as well as more challenging GZSL setting. In ZSL\nsetting, our model yields 4.5\\%, 6.0\\%, 9.8\\%, and 27.9\\% relative improvements\nover the current state-of-the-art on CUB, AWA1, AWA2, and aPY datasets,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 08:11:46 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Verma", "Vinay Kumar", ""], ["Brahma", "Dhanajit", ""], ["Rai", "Piyush", ""]]}, {"id": "1909.04390", "submitter": "Alex Frid", "authors": "Alex Frid, Larry M. Manevitz, Norberto Eiji Nawa", "title": "Classifying the Valence of Autobiographical Memories from fMRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that fMRI analysis using machine learning tools are sufficient to\ndistinguish valence (i.e., positive or negative) of freely retrieved\nautobiographical memories in a cross-participant setting. Our methodology uses\nfeature selection (ReliefF) in combination with boosting methods, both applied\ndirectly to data represented in voxel space. In previous work using the same\ndata set, Nawa and Ando showed that whole-brain based classification could\nachieve above-chance classification accuracy only when both training and\ntesting data came from the same individual. In a cross-participant setting,\nclassification results were not statistically significant. Additionally, on\naverage the classification accuracy obtained when using ReliefF is\nsubstantially higher than previous results - 81% for the within-participant\nclassification, and 62% for the cross-participant classification. Furthermore,\nsince features are defined in voxel space, it is possible to show brain maps\nindicating the regions of that are most relevant in determining the results of\nthe classification. Interestingly, the voxels that were selected using the\nproposed computational pipeline seem to be consistent with current\nneurophysiological theories regarding the brain regions actively involved in\nautobiographical memory processes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:24:44 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 06:24:34 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Frid", "Alex", ""], ["Manevitz", "Larry M.", ""], ["Nawa", "Norberto Eiji", ""]]}, {"id": "1909.04402", "submitter": "Mitja Nikolaus", "authors": "Mitja Nikolaus, Mostafa Abdou, Matthew Lamm, Rahul Aralikatte and\n  Desmond Elliott", "title": "Compositional Generalization in Image Captioning", "comments": "To appear at CoNLL 2019, EMNLP", "journal-ref": "Proceedings of the 23rd Conference on Computational Natural\n  Language Learning (CoNLL), pp. 87--98, ACL, 2019", "doi": "10.18653/v1/K19-1009", "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning models are usually evaluated on their ability to describe a\nheld-out set of images, not on their ability to generalize to unseen concepts.\nWe study the problem of compositional generalization, which measures how well a\nmodel composes unseen combinations of concepts when describing images.\nState-of-the-art image captioning models show poor generalization performance\non this task. We propose a multi-task model to address the poor performance,\nthat combines caption generation and image--sentence ranking, and uses a\ndecoding mechanism that re-ranks the captions according their similarity to the\nimage. This model is substantially better at generalizing to unseen\ncombinations of concepts compared to state-of-the-art captioning models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:55:56 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 15:53:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Nikolaus", "Mitja", ""], ["Abdou", "Mostafa", ""], ["Lamm", "Matthew", ""], ["Aralikatte", "Rahul", ""], ["Elliott", "Desmond", ""]]}, {"id": "1909.04406", "submitter": "Gokularam Muthukrishnan", "authors": "Vishnu Menon, Gokularam M, Sheetal Kalyani", "title": "Subspace clustering without knowing the number of clusters: A parameter\n  free approach", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3018665", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering, the task of clustering high dimensional data when the\ndata points come from a union of subspaces is one of the fundamental tasks in\nunsupervised machine learning. Most of the existing algorithms for this task\nrequire prior knowledge of the number of clusters along with few additional\nparameters which need to be set or tuned apriori according to the type of data\nto be clustered. In this work, a parameter free method for subspace clustering\nis proposed, where the data points are clustered on the basis of the difference\nin statistical distribution of the angles subtended by the data points within a\nsubspace and those by points belonging to different subspaces. Given an initial\nfine clustering, the proposed algorithm merges the clusters until a final\nclustering is obtained. This, unlike many existing methods, does not require\nthe number of clusters apriori. Also, the proposed algorithm does not involve\nthe use of an unknown parameter or tuning for one. %through cross validation. A\nparameter free method for producing a fine initial clustering is also\ndiscussed, making the whole process of subspace clustering parameter free. The\ncomparison of proposed algorithm's performance with that of the existing\nstate-of-the-art techniques in synthetic and real data sets, shows the\nsignificance of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 11:03:55 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 19:37:00 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 15:54:27 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Menon", "Vishnu", ""], ["M", "Gokularam", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1909.04421", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Dimitrios Athanasakis, Hamed Haddadi and Benjamin\n  Livshits", "title": "Privacy-Preserving Bandits", "comments": "13 pages, 7 figures", "journal-ref": "In Proceedings of the 3rd Conference on Machine Learning and\n  Systems (MLSys 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms~(CBAs) often rely on personal data to provide\nrecommendations. Centralized CBA agents utilize potentially sensitive data from\nrecent interactions to provide personalization to end-users. Keeping the\nsensitive data locally, by running a local agent on the user's device, protects\nthe user's privacy, however, the agent requires longer to produce useful\nrecommendations, as it does not leverage feedback from other users. This paper\nproposes a technique we call Privacy-Preserving Bandits (P2B); a system that\nupdates local agents by collecting feedback from other local agents in a\ndifferentially-private manner. Comparisons of our proposed approach with a\nnon-private, as well as a fully-private (local) system, show competitive\nperformance on both synthetic benchmarks and real-world data. Specifically, we\nobserved only a decrease of 2.6% and 3.6% in multi-label classification\naccuracy, and a CTR increase of 0.0025 in online advertising for a privacy\nbudget $\\epsilon \\approx 0.693$. These results suggest P2B is an effective\napproach to challenges arising in on-device privacy-preserving personalization.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 11:39:58 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 22:36:09 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:12:00 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 12:39:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Athanasakis", "Dimitrios", ""], ["Haddadi", "Hamed", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1909.04436", "submitter": "Martin Shepperd", "authors": "Martin Shepperd, Yuchen Guo, Ning Li, Mahir Arzoky, Andrea Capiluppi,\n  Steve Counsell, Giuseppe Destefanis, Stephen Swift, Allan Tucker, and Leila\n  Yousefi", "title": "The Prevalence of Errors in Machine Learning Experiments", "comments": "20th International Conference on Intelligent Data Engineering and\n  Automated Learning (IDEAL), 14--16 November 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Context: Conducting experiments is central to research machine learning\nresearch to benchmark, evaluate and compare learning algorithms. Consequently\nit is important we conduct reliable, trustworthy experiments. Objective: We\ninvestigate the incidence of errors in a sample of machine learning experiments\nin the domain of software defect prediction. Our focus is simple arithmetical\nand statistical errors. Method: We analyse 49 papers describing 2456 individual\nexperimental results from a previously undertaken systematic review comparing\nsupervised and unsupervised defect prediction classifiers. We extract the\nconfusion matrices and test for relevant constraints, e.g., the marginal\nprobabilities must sum to one. We also check for multiple statistical\nsignificance testing errors. Results: We find that a total of 22 out of 49\npapers contain demonstrable errors. Of these 7 were statistical and 16 related\nto confusion matrix inconsistency (one paper contained both classes of error).\nConclusions: Whilst some errors may be of a relatively trivial nature, e.g.,\ntranscription errors their presence does not engender confidence. We strongly\nurge researchers to follow open science principles so errors can be more easily\nbe detected and corrected, thus as a community reduce this worryingly high\nerror rate with our computational experiments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:32:00 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Shepperd", "Martin", ""], ["Guo", "Yuchen", ""], ["Li", "Ning", ""], ["Arzoky", "Mahir", ""], ["Capiluppi", "Andrea", ""], ["Counsell", "Steve", ""], ["Destefanis", "Giuseppe", ""], ["Swift", "Stephen", ""], ["Tucker", "Allan", ""], ["Yousefi", "Leila", ""]]}, {"id": "1909.04443", "submitter": "Hui-Po Wang", "authors": "Hui-Po Wang, Wen-Hsiao Peng, and Wei-Jan Ko", "title": "Learning Priors for Adversarial Autoencoders", "comments": "Accepted by APSIPA ASC, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep latent factor models choose simple priors for simplicity,\ntractability or not knowing what prior to use. Recent studies show that the\nchoice of the prior may have a profound effect on the expressiveness of the\nmodel,especially when its generative network has limited capacity. In this\npaper, we propose to learn a proper prior from data for adversarial\nautoencoders(AAEs). We introduce the notion of code generators to transform\nmanually selected simple priors into ones that can better characterize the data\ndistribution. Experimental results show that the proposed model can generate\nbetter image quality and learn better disentangled representations than AAEs in\nboth supervised and unsupervised settings. Lastly, we present its ability to do\ncross-domain translation in a text-to-image synthesis task.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:42:32 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wang", "Hui-Po", ""], ["Peng", "Wen-Hsiao", ""], ["Ko", "Wei-Jan", ""]]}, {"id": "1909.04454", "submitter": "Saber Salehkaleybar", "authors": "M. Reza Heydari, Saber Salehkaleybar, Kun Zhang", "title": "Adversarial Orthogonal Regression: Two non-Linear Regressions for Causal\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two nonlinear regression methods, named Adversarial Orthogonal\nRegression (AdOR) for additive noise models and Adversarial Orthogonal\nStructural Equation Model (AdOSE) for the general case of structural equation\nmodels. Both methods try to make the residual of regression independent from\nregressors while putting no assumption on noise distribution. In both methods,\ntwo adversarial networks are trained simultaneously where a regression network\noutputs predictions and a loss network that estimates mutual information (in\nAdOR) and KL-divergence (in AdOSE). These methods can be formulated as a\nminimax two-player game; at equilibrium, AdOR finds a deterministic map between\ninputs and output and estimates mutual information between residual and inputs,\nwhile AdOSE estimates a conditional probability distribution of output given\ninputs. The proposed methods can be used as subroutines to address several\nlearning problems in causality, such as causal direction determination (or more\ngenerally, causal structure learning) and causal model estimation. Synthetic\nand real-world experiments demonstrate that the proposed methods have a\nremarkable performance with respect to previous solutions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:59:59 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Heydari", "M. Reza", ""], ["Salehkaleybar", "Saber", ""], ["Zhang", "Kun", ""]]}, {"id": "1909.04474", "submitter": "Sabine Wieluch", "authors": "Sabine Wieluch, Dr. Friedhelm Schwenker", "title": "Dropout Induced Noise for Co-Creative GAN Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates how Dropout can be used in Generative Adversarial\nNetworks to generate multiple different outputs to one input. This method is\nthought as an alternative to latent space exploration, especially if\nconstraints in the input should be preserved, like in A-to-B translation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:38:56 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wieluch", "Sabine", ""], ["Schwenker", "Dr. Friedhelm", ""]]}, {"id": "1909.04491", "submitter": "Zi-Jing Liu", "authors": "Zijing Liu, Mauricio Barahona", "title": "Graph-based data clustering via multiscale community detection", "comments": "16 pages, 5 figures", "journal-ref": "Appl Netw Sci (2020) 5: 3", "doi": "10.1007/s41109-019-0248-7", "report-no": null, "categories": "cs.IR cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graph-theoretical approach to data clustering, which combines\nthe creation of a graph from the data with Markov Stability, a multiscale\ncommunity detection framework. We show how the multiscale capabilities of the\nmethod allow the estimation of the number of clusters, as well as alleviating\nthe sensitivity to the parameters in graph construction. We use both synthetic\nand benchmark real datasets to compare and evaluate several graph construction\nmethods and clustering algorithms, and show that multiscale graph-based\nclustering achieves improved performance compared to popular clustering methods\nwithout the need to set externally the number of clusters.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:44:26 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 10:21:45 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Liu", "Zijing", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1909.04503", "submitter": "Arquimedes Canedo", "authors": "Arquimedes Canedo and Palash Goyal and Di Huang and Amit Pandey and\n  Gustavo Quiros", "title": "ArduCode: Predictive Framework for Automation Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation engineering is the task of integrating, via software, various\nsensors, actuators, and controls for automating a real-world process. Today,\nautomation engineering is supported by a suite of software tools including\nintegrated development environments (IDE), hardware configurators, compilers,\nand runtimes. These tools focus on the automation code itself, but leave the\nautomation engineer unassisted in their decision making. This can lead to\nincreased time for software development because of imperfections in decision\nmaking leading to multiple iterations between software and hardware. To address\nthis, this paper defines multiple challenges often faced in automation\nengineering and propose solutions using machine learning to assist engineers\ntackle such challenges. We show that machine learning can be leveraged to\nassist the automation engineer in classifying automation, finding similar code\nsnippets, and reasoning about the hardware selection of sensors and actuators.\nWe validate our architecture on two real datasets consisting of 2,927 Arduino\nprojects, and 683 Programmable Logic Controller (PLC) projects. Our results\nshow that paragraph embedding techniques can be utilized to classify automation\nusing code snippets with precision close to human annotation, giving an\nF1-score of 72%. Further, we show that such embedding techniques can help us\nfind similar code snippets with high accuracy. Finally, we use autoencoder\nmodels for hardware recommendation and achieve a p@3 of 0.79 and p@5 of 0.95.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:19:05 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 07:53:53 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 17:12:44 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 01:09:08 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Canedo", "Arquimedes", ""], ["Goyal", "Palash", ""], ["Huang", "Di", ""], ["Pandey", "Amit", ""], ["Quiros", "Gustavo", ""]]}, {"id": "1909.04525", "submitter": "Andre Pacheco", "authors": "Andre G. C. Pacheco and Abder-Rahman Ali and Thomas Trappenberg", "title": "Skin cancer detection based on deep learning and entropy to detect\n  outlier samples", "comments": "3rd and 4th places in tasks 1 and 2 respectively, at ISIC challenge\n  2019 @ MICCAI workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe our methods that achieved the 3rd and 4th places in tasks 1 and\n2, respectively, at ISIC challenge 2019. The goal of this challenge is to\nprovide the diagnostic for skin cancer using images and meta-data. There are\nnine classes in the dataset, nonetheless, one of them is an outlier and is not\npresent on it. To tackle the challenge, we apply an ensemble of classifiers,\nwhich has 13 convolutional neural networks (CNN), we develop two approaches to\nhandle the outlier class and we propose a straightforward method to use the\nmeta-data along with the images. Throughout this report, we detail each\nmethodology and parameters to make it easy to replicate our work. The results\nobtained are in accordance with the previous challenges and the approaches to\ndetect the outlier class and to address the meta-data seem to be work properly.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:36:16 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 22:45:19 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Pacheco", "Andre G. C.", ""], ["Ali", "Abder-Rahman", ""], ["Trappenberg", "Thomas", ""]]}, {"id": "1909.04532", "submitter": "Haibo Yang", "authors": "Haibo Yang, Xin Zhang, Minghong Fang, and Jia Liu", "title": "Byzantine-Resilient Stochastic Gradient Descent for Distributed\n  Learning: A Lipschitz-Inspired Coordinate-wise Median Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the resilience of distributed algorithms based on\nstochastic gradient descent (SGD) in distributed learning with potentially\nByzantine attackers, who could send arbitrary information to the parameter\nserver to disrupt the training process. Toward this end, we propose a new\nLipschitz-inspired coordinate-wise median approach (LICM-SGD) to mitigate\nByzantine attacks. We show that our LICM-SGD algorithm can resist up to half of\nthe workers being Byzantine attackers, while still converging almost surely to\na stationary region in non-convex settings. Also, our LICM-SGD method does not\nrequire any information about the number of attackers and the Lipschitz\nconstant, which makes it attractive for practical implementations. Moreover,\nour LICM-SGD method enjoys the optimal $O(md)$ computational time-complexity in\nthe sense that the time-complexity is the same as that of the standard SGD\nunder no attacks. We conduct extensive experiments to show that our LICM-SGD\nalgorithm consistently outperforms existing methods in training multi-class\nlogistic regression and convolutional neural networks with MNIST and CIFAR-10\ndatasets. In our experiments, LICM-SGD also achieves a much faster running time\nthanks to its low computational time-complexity.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:45:21 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yang", "Haibo", ""], ["Zhang", "Xin", ""], ["Fang", "Minghong", ""], ["Liu", "Jia", ""]]}, {"id": "1909.04567", "submitter": "Eyy\\\"ub Sari", "authors": "Ramchalam Kinattinkara Ramakrishnan and Eyy\\\"ub Sari, Vahid Partovi\n  Nia", "title": "Differentiable Mask for Pruning Convolutional and Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is one of the most effective model reduction techniques. Deep\nnetworks require massive computation and such models need to be compressed to\nbring them on edge devices. Most existing pruning techniques are focused on\nvision-based models like convolutional networks, while text-based models are\nstill evolving. The emergence of multi-modal multi-task learning calls for a\ngeneral method that works on vision and text architectures simultaneously. We\nintroduce a \\emph{differentiable mask}, that induces sparsity on various\ngranularity to fill this gap. We apply our method successfully to prune\nweights, filters, subnetwork of a convolutional architecture, as well as nodes\nof a recurrent network.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:25:43 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 14:03:18 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Ramakrishnan", "Ramchalam Kinattinkara", ""], ["Sari", "Eyy\u00fcb", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "1909.04568", "submitter": "Henry Chai", "authors": "Shali Jiang, Henry Chai, Javier Gonzalez, Roman Garnett", "title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design", "comments": "13 pages, 4 figures, 6 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-horizon sequential experimental design (SED) arises naturally in many\ncontexts, including hyperparameter tuning in machine learning among more\ntraditional settings. Computing the optimal policy for such problems requires\nsolving Bellman equations, which are generally intractable. Most existing work\nresorts to severely myopic approximations by limiting the decision horizon to\nonly a single time-step, which can underweight exploration in favor of\nexploitation. We present BINOCULARS: Batch-Informed NOnmyopic Choices, Using\nLong-horizons for Adaptive, Rapid SED, a general framework for deriving\nefficient, nonmyopic approximations to the optimal experimental policy. Our key\nidea is simple and surprisingly effective: we first compute a one-step optimal\nbatch of experiments, then select a single point from this batch to evaluate.\nWe realize BINOCULARS for Bayesian optimization and Bayesian quadrature -- two\nnotable SED problems with radically different objectives -- and demonstrate\nthat BINOCULARS significantly outperforms myopic alternatives in real-world\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:26:55 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 03:21:42 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 06:23:53 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Jiang", "Shali", ""], ["Chai", "Henry", ""], ["Gonzalez", "Javier", ""], ["Garnett", "Roman", ""]]}, {"id": "1909.04570", "submitter": "Dominik Linzner", "authors": "Dominik Linzner, Michael Schmidt and Heinz Koeppl", "title": "Scalable Structure Learning of Continuous-Time Bayesian Networks from\n  Incomplete Data", "comments": "Accepted at NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time Bayesian Networks (CTBNs) represent a compact yet powerful\nframework for understanding multivariate time-series data. Given complete data,\nparameters and structure can be estimated efficiently in closed-form. However,\nif data is incomplete, the latent states of the CTBN have to be estimated by\nlaboriously simulating the intractable dynamics of the assumed CTBN. This is a\nproblem, especially for structure learning tasks, where this has to be done for\neach element of a super-exponentially growing set of possible structures. In\norder to circumvent this notorious bottleneck, we develop a novel\ngradient-based approach to structure learning. Instead of sampling and scoring\nall possible structures individually, we assume the generator of the CTBN to be\ncomposed as a mixture of generators stemming from different structures. In this\nframework, structure learning can be performed via a gradient-based\noptimization of mixture weights. We combine this approach with a new\nvariational method that allows for a closed-form calculation of this mixture\nmarginal likelihood. We show the scalability of our method by learning\nstructures of previously inaccessible sizes from synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:29:46 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 08:28:06 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 09:16:13 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Linzner", "Dominik", ""], ["Schmidt", "Michael", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1909.04596", "submitter": "Mehul S. Raval", "authors": "Rupal Agravat, Mehul S Raval", "title": "Prediction of Overall Survival of Brain Tumor Patients", "comments": "5 pages, IEEE TENCON 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated brain tumor segmentation plays an important role in the diagnosis\nand prognosis of the patient. In addition, features from the tumorous brain\nhelp in predicting patients overall survival. The main focus of this paper is\nto segment tumor from BRATS 2018 benchmark dataset and use age, shape and\nvolumetric features to predict overall survival of patients. The random forest\nclassifier achieves overall survival accuracy of 59% on the test dataset and\n67% on the dataset with resection status as gross total resection. The proposed\napproach uses fewer features but achieves better accuracy than state of the art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:09:12 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Agravat", "Rupal", ""], ["Raval", "Mehul S", ""]]}, {"id": "1909.04605", "submitter": "Jose Rodrigues Jr", "authors": "Jose F Rodrigues-Jr, Gabriel Spadon, Bruno Brandoli, Sihem Amer-Yahia", "title": "Patient trajectory prediction in the Mimic-III dataset, challenges and\n  pitfalls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated medical prognosis has gained interest as artificial intelligence\nevolves and the potential for computer-aided medicine becomes evident.\nNevertheless, it is challenging to design an effective system that, given a\npatient's medical history, is able to predict probable future conditions.\nPrevious works, mostly carried out over private datasets, have tackled the\nproblem by using artificial neural network architectures that cannot deal with\nlow-cardinality datasets, or by means of non-generalizable inference\napproaches. We introduce a Deep Learning architecture whose design results from\nan intensive experimental process. The final architecture is based on two\nparallel Minimal Gated Recurrent Unit networks working in bi-directional\nmanner, which was extensively tested with the open-access Mimic-III dataset.\nOur results demonstrate significant improvements in automated medical\nprognosis, as measured with Recall@k. We summarize our experience as a set of\nrelevant insights for the design of Deep Learning architectures. Our work\nimproves the performance of computer-aided medicine and can serve as a guide in\ndesigning artificial neural networks used in prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:30:24 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 12:05:15 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 08:45:00 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 13:07:08 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Rodrigues-Jr", "Jose F", ""], ["Spadon", "Gabriel", ""], ["Brandoli", "Bruno", ""], ["Amer-Yahia", "Sihem", ""]]}, {"id": "1909.04630", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Chelsea Finn, Sham Kakade, Sergey Levine", "title": "Meta-Learning with Implicit Gradients", "comments": "NeurIPS 2019. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core capability of intelligent systems is the ability to quickly learn new\ntasks by drawing on prior experience. Gradient (or optimization) based\nmeta-learning has recently emerged as an effective approach for few-shot\nlearning. In this formulation, meta-parameters are learned in the outer loop,\nwhile task-specific models are learned in the inner-loop, by using only a small\namount of data from the current task. A key challenge in scaling these\napproaches is the need to differentiate through the inner loop learning\nprocess, which can impose considerable computational and memory burdens. By\ndrawing upon implicit differentiation, we develop the implicit MAML algorithm,\nwhich depends only on the solution to the inner level optimization and not the\npath taken by the inner loop optimizer. This effectively decouples the\nmeta-gradient computation from the choice of inner loop optimizer. As a result,\nour approach is agnostic to the choice of inner loop optimizer and can\ngracefully handle many gradient steps without vanishing gradients or memory\nconstraints. Theoretically, we prove that implicit MAML can compute accurate\nmeta-gradients with a memory footprint that is, up to small constant factors,\nno more than that which is required to compute a single inner loop gradient and\nat no overall increase in the total computational cost. Experimentally, we show\nthat these benefits of implicit MAML translate into empirical gains on few-shot\nimage recognition benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:14:14 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Finn", "Chelsea", ""], ["Kakade", "Sham", ""], ["Levine", "Sergey", ""]]}, {"id": "1909.04648", "submitter": "Kirk Swanson", "authors": "Kirk Swanson, Shubhendu Trivedi, Joshua Lequieu, Kyle Swanson, Risi\n  Kondor", "title": "Deep Learning for Automated Classification and Characterization of\n  Amorphous Materials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.dis-nn cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to quantify structure-property relationships and to identify\nstructural features of complex materials. The characterization of amorphous\nmaterials is especially challenging because their lack of long-range order\nmakes it difficult to define structural metrics. In this work, we apply deep\nlearning algorithms to accurately classify amorphous materials and characterize\ntheir structural features. Specifically, we show that convolutional neural\nnetworks and message passing neural networks can classify two-dimensional\nliquids and liquid-cooled glasses from molecular dynamics simulations with\ngreater than 0.98 AUC, with no a priori assumptions about local particle\nrelationships, even when the liquids and glasses are prepared at the same\ninherent structure energy. Furthermore, we demonstrate that message passing\nneural networks surpass convolutional neural networks in this context in both\naccuracy and interpretability. We extract a clear interpretation of how message\npassing neural networks evaluate liquid and glass structures by using a\nself-attention mechanism. Using this interpretation, we derive three novel\nstructural metrics that accurately characterize glass formation. The methods\npresented here provide us with a procedure to identify important structural\nfeatures in materials that could be missed by standard techniques and give us a\nunique insight into how these neural networks process data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:49:04 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Swanson", "Kirk", ""], ["Trivedi", "Shubhendu", ""], ["Lequieu", "Joshua", ""], ["Swanson", "Kyle", ""], ["Kondor", "Risi", ""]]}, {"id": "1909.04653", "submitter": "Tianyi Liu", "authors": "Tianyi Liu, Minshuo Chen, Mo Zhou, Simon S. Du, Enlu Zhou and Tuo Zhao", "title": "Towards Understanding the Importance of Shortcut Connections in Residual\n  Networks", "comments": "Thirty-third Conference on Neural Information Processing Systems,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual Network (ResNet) is undoubtedly a milestone in deep learning. ResNet\nis equipped with shortcut connections between layers, and exhibits efficient\ntraining using simple first order algorithms. Despite of the great empirical\nsuccess, the reason behind is far from being well understood. In this paper, we\nstudy a two-layer non-overlapping convolutional ResNet. Training such a network\nrequires solving a non-convex optimization problem with a spurious local\noptimum. We show, however, that gradient descent combined with proper\nnormalization, avoids being trapped by the spurious local optimum, and\nconverges to a global optimum in polynomial time, when the weight of the first\nlayer is initialized at 0, and that of the second layer is initialized\narbitrarily in a ball. Numerical experiments are provided to support our\ntheory.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:55:03 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 01:49:50 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 15:55:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Tianyi", ""], ["Chen", "Minshuo", ""], ["Zhou", "Mo", ""], ["Du", "Simon S.", ""], ["Zhou", "Enlu", ""], ["Zhao", "Tuo", ""]]}, {"id": "1909.04697", "submitter": "Zheyu Yan", "authors": "Zheyu Yan, Yiyu Shi, Wang Liao, Masanori Hashimoto, Xichuan Zhou,\n  Cheng Zhuo", "title": "When Single Event Upset Meets Deep Neural Networks: Observations,\n  Explorations, and Remedies", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network has proved its potential in various perception tasks and\nhence become an appealing option for interpretation and data processing in\nsecurity sensitive systems. However, security-sensitive systems demand not only\nhigh perception performance, but also design robustness under various\ncircumstances. Unlike prior works that study network robustness from software\nlevel, we investigate from hardware perspective about the impact of Single\nEvent Upset (SEU) induced parameter perturbation (SIPP) on neural networks. We\nsystematically define the fault models of SEU and then provide the definition\nof sensitivity to SIPP as the robustness measure for the network. We are then\nable to analytically explore the weakness of a network and summarize the key\nfindings for the impact of SIPP on different types of bits in a floating point\nparameter, layer-wise robustness within the same network and impact of network\ndepth. Based on those findings, we propose two remedy solutions to protect DNNs\nfrom SIPPs, which can mitigate accuracy degradation from 28% to 0.27% for\nResNet with merely 0.24-bit SRAM area overhead per parameter.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:24:43 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Yan", "Zheyu", ""], ["Shi", "Yiyu", ""], ["Liao", "Wang", ""], ["Hashimoto", "Masanori", ""], ["Zhou", "Xichuan", ""], ["Zhuo", "Cheng", ""]]}, {"id": "1909.04711", "submitter": "David Gagne", "authors": "David John Gagne II, Hannah M. Christensen, Aneesh C. Subramanian, and\n  Adam H. Monahan", "title": "Machine Learning for Stochastic Parameterization: Generative Adversarial\n  Networks in the Lorenz '96 Model", "comments": "Submitted to Journal of Advances in Modeling Earth Systems (JAMES)", "journal-ref": null, "doi": "10.1029/2019MS001896", "report-no": null, "categories": "physics.ao-ph cs.LG nlin.CD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic parameterizations account for uncertainty in the representation of\nunresolved sub-grid processes by sampling from the distribution of possible\nsub-grid forcings. Some existing stochastic parameterizations utilize\ndata-driven approaches to characterize uncertainty, but these approaches\nrequire significant structural assumptions that can limit their scalability.\nMachine learning models, including neural networks, are able to represent a\nwide range of distributions and build optimized mappings between a large number\nof inputs and sub-grid forcings. Recent research on machine learning\nparameterizations has focused only on deterministic parameterizations. In this\nstudy, we develop a stochastic parameterization using the generative\nadversarial network (GAN) machine learning framework. The GAN stochastic\nparameterization is trained and evaluated on output from the Lorenz '96 model,\nwhich is a common baseline model for evaluating both parameterization and data\nassimilation techniques. We evaluate different ways of characterizing the input\nnoise for the model and perform model runs with the GAN parameterization at\nweather and climate timescales. Some of the GAN configurations perform better\nthan a baseline bespoke parameterization at both timescales, and the networks\nclosely reproduce the spatio-temporal correlations and regimes of the Lorenz\n'96 system. We also find that in general those models which produce skillful\nforecasts are also associated with the best climate simulations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:19:14 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Gagne", "David John", "II"], ["Christensen", "Hannah M.", ""], ["Subramanian", "Aneesh C.", ""], ["Monahan", "Adam H.", ""]]}, {"id": "1909.04715", "submitter": "Ahmed Khaled", "authors": "Ahmed Khaled and Konstantin Mishchenko and Peter Richt\\'arik", "title": "First Analysis of Local GD on Heterogeneous Data", "comments": "NeurIPS 2019 Workshop on Federated Learning for Data Privacy and\n  Confidentiality. 11 pages, 4 lemmas, 1 theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first convergence analysis of local gradient descent for\nminimizing the average of smooth and convex but otherwise arbitrary functions.\nProblems of this form and local gradient descent as a solution method are of\nimportance in federated learning, where each function is based on private data\nstored by a user on a mobile device, and the data of different users can be\narbitrarily heterogeneous. We show that in a low accuracy regime, the method\nhas the same communication complexity as gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:46:13 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:25:03 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Khaled", "Ahmed", ""], ["Mishchenko", "Konstantin", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1909.04716", "submitter": "Ahmed Khaled", "authors": "Ahmed Khaled and Peter Richt\\'arik", "title": "Gradient Descent with Compressed Iterates", "comments": "NeurIPS 2019 Workshop on Federated Learning for Data Privacy and\n  Confidentiality. 10 pages, 1 algorithm, 1 theorem, 5 lemmas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a new type of stochastic first order method: gradient\ndescent with compressed iterates (GDCI). GDCI in each iteration first\ncompresses the current iterate using a lossy randomized compression technique,\nand subsequently takes a gradient step. This method is a distillation of a key\ningredient in the current practice of federated learning, where a model needs\nto be compressed by a mobile device before it is sent back to a server for\naggregation. Our analysis provides a step towards closing the gap between the\ntheory and practice of federated learning, and opens the possibility for many\nextensions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:52:09 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:35:45 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Khaled", "Ahmed", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1909.04724", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, Alan Colman, Jun Han, A.S.M. Kayes and Paul Watters", "title": "CalBehav: A Machine Learning based Personalized Calendar Behavioral\n  Model using Time-Series Smartphone Data", "comments": "16 pages, double column", "journal-ref": "The Computer Journal, Section C: Computational Intelligence,\n  Machine Learning and Data Analytics, Publisher: Oxford University Press, UK,\n  2019", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electronic calendar is a valuable resource nowadays for managing our\ndaily life appointments or schedules, also known as events, ranging from\nprofessional to highly personal. Researchers have studied various types of\ncalendar events to predict smartphone user behavior for incoming mobile\ncommunications. However, these studies typically do not take into account\nbehavioral variations between individuals. In the real world, smartphone users\ncan differ widely from each other in how they respond to incoming\ncommunications during their scheduled events. Moreover, an individual user may\nrespond the incoming communications differently in different contexts subject\nto what type of event is scheduled in her personal calendar. Thus, a static\ncalendar-based behavioral model for individual smartphone users does not\nnecessarily reflect their behavior to the incoming communications. In this\npaper, we present a machine learning based context-aware model that is\npersonalized and dynamically identifies individual's dominant behavior for\ntheir scheduled events using logged time-series smartphone data, and shortly\nname as ``CalBehav''. The experimental results based on real datasets from\ncalendar and phone logs, show that this data-driven personalized model is more\neffective for intelligently managing the incoming mobile communications\ncompared to existing calendar-based approaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:26:11 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Colman", "Alan", ""], ["Han", "Jun", ""], ["Kayes", "A. S. M.", ""], ["Watters", "Paul", ""]]}, {"id": "1909.04746", "submitter": "Ahmed Khaled", "authors": "Ahmed Khaled and Konstantin Mishchenko and Peter Richt\\'arik", "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data", "comments": "To appear in AISTATS 2020. 31 pages, 1 algorithm, 5 theorems, 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new analysis of local SGD, removing unnecessary assumptions and\nelaborating on the difference between two data regimes: identical and\nheterogeneous. In both cases, we improve the existing theory and provide values\nof the optimal stepsize and optimal number of local iterations. Our bounds are\nbased on a new notion of variance that is specific to local SGD methods with\ndifferent data. The tightness of our results is guaranteed by recovering known\nstatements when we plug $H=1$, where $H$ is the number of local steps. The\nempirical evidence further validates the severe impact of data heterogeneity on\nthe performance of local SGD.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 20:47:10 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 08:17:47 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 21:27:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Khaled", "Ahmed", ""], ["Mishchenko", "Konstantin", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1909.04747", "submitter": "Madeleine Bartlett Miss", "authors": "Madeleine Bartlett, Daniel Hernandez Garcia, Serge Thill and Tony\n  Belpaeme", "title": "Recognizing Human Internal States: A Conceptor-Based Approach", "comments": "4 pages, 1 figure, HRI conference workshop", "journal-ref": null, "doi": null, "report-no": "SREC/2019/04", "categories": "cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The past few decades has seen increased interest in the application of social\nrobots to interventions for Autism Spectrum Disorder as behavioural coaches\n[4]. We consider that robots embedded in therapies could also provide\nquantitative diagnostic information by observing patient behaviours. The social\nnature of ASD symptoms means that, to achieve this, robots need to be able to\nrecognize the internal states their human interaction partners are\nexperiencing, e.g. states of confusion, engagement etc. Approaching this\nproblem can be broken down into two questions: (1) what information, accessible\nto robots, can be used to recognize internal states, and (2) how can a system\nclassify internal states such that it allows for sufficiently detailed\ndiagnostic information? In this paper we discuss these two questions in depth\nand propose a novel, conceptor-based classifier. We report the initial results\nof this system in a proof-of-concept study and outline plans for future work.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 13:10:52 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Bartlett", "Madeleine", ""], ["Garcia", "Daniel Hernandez", ""], ["Thill", "Serge", ""], ["Belpaeme", "Tony", ""]]}, {"id": "1909.04751", "submitter": "Yue Zheng", "authors": "Yue Zheng", "title": "Reinforcement Learning and Video Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has exceeded human-level performance in game playing\nAI with deep learning methods according to the experiments from DeepMind on Go\nand Atari games. Deep learning solves high dimension input problems which stop\nthe development of reinforcement for many years. This study uses both two\ntechniques to create several agents with different algorithms that successfully\nlearn to play T-rex Runner. Deep Q network algorithm and three types of\nimprovements are implemented to train the agent. The results from some of them\nare far from satisfactory but others are better than human experts. Batch\nnormalization is a method to solve internal covariate shift problems in deep\nneural network. The positive influence of this on reinforcement learning has\nalso been proved in this study.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 20:51:42 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Zheng", "Yue", ""]]}, {"id": "1909.04760", "submitter": "Venktesh Pandey", "authors": "Venktesh Pandey, Evana Wang, and Stephen D. Boyles", "title": "Deep Reinforcement Learning Algorithm for Dynamic Pricing of Express\n  Lanes with Multiple Access Locations", "comments": null, "journal-ref": null, "doi": "10.1016/j.trc.2020.102715", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article develops a deep reinforcement learning (Deep-RL) framework for\ndynamic pricing on managed lanes with multiple access locations and\nheterogeneity in travelers' value of time, origin, and destination. This\nframework relaxes assumptions in the literature by considering multiple origins\nand destinations, multiple access locations to the managed lane, en route\ndiversion of travelers, partial observability of the sensor readings, and\nstochastic demand and observations. The problem is formulated as a partially\nobservable Markov decision process (POMDP) and policy gradient methods are used\nto determine tolls as a function of real-time observations. Tolls are modeled\nas continuous and stochastic variables, and are determined using a feedforward\nneural network. The method is compared against a feedback control method used\nfor dynamic pricing. We show that Deep-RL is effective in learning toll\npolicies for maximizing revenue, minimizing total system travel time, and other\njoint weighted objectives, when tested on real-world transportation networks.\nThe Deep-RL toll policies outperform the feedback control heuristic for the\nrevenue maximization objective by generating revenues up to 9.5% higher than\nthe heuristic and for the objective minimizing total system travel time (TSTT)\nby generating TSTT up to 10.4% lower than the heuristic. We also propose reward\nshaping methods for the POMDP to overcome the undesired behavior of toll\npolicies, like the jam-and-harvest behavior of revenue-maximizing policies.\nAdditionally, we test transferability of the algorithm trained on one set of\ninputs for new input distributions and offer recommendations on real-time\nimplementations of Deep-RL algorithms. The source code for our experiments is\navailable online at https://github.com/venktesh22/ExpressLanes_Deep-RL\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:20:59 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Pandey", "Venktesh", ""], ["Wang", "Evana", ""], ["Boyles", "Stephen D.", ""]]}, {"id": "1909.04766", "submitter": "Yongjune Kim", "authors": "Yongjune Kim, Yuval Cassuto, Lav R. Varshney", "title": "Boosting Classifiers with Noisy Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a principled framework to address resource allocation for\nrealizing boosting algorithms on substrates with communication or computation\nnoise. Boosting classifiers (e.g., AdaBoost) make a final decision via a\nweighted vote from the outputs of many base classifiers (weak classifiers).\nSuppose that the base classifiers' outputs are noisy or communicated over noisy\nchannels; these noisy outputs will degrade the final classification accuracy.\nWe show that this degradation can be effectively reduced by allocating more\nsystem resources for more important base classifiers. We formulate resource\noptimization problems in terms of importance metrics for boosting. Moreover, we\nshow that the optimized noisy boosting classifiers can be more robust than\nbagging for the noise during inference (test stage). We provide numerical\nevidence to demonstrate the benefits of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:38:56 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 01:10:44 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kim", "Yongjune", ""], ["Cassuto", "Yuval", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1909.04778", "submitter": "Robert Podschwadt", "authors": "Robert Podschwadt, Hassan Takabi", "title": "Effectiveness of Adversarial Examples and Defenses for Malware\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks have been successfully used for many different\nclassification tasks including malware detection and distinguishing between\nmalicious and non-malicious programs. Although artificial neural networks\nperform very well on these tasks, they are also vulnerable to adversarial\nexamples. An adversarial example is a sample that has minor modifications made\nto it so that the neural network misclassifies it. Many techniques have been\nproposed, both for crafting adversarial examples and for hardening neural\nnetworks against them. Most previous work has been done in the image domain.\nSome of the attacks have been adopted to work in the malware domain which\ntypically deals with binary feature vectors. In order to better understand the\nspace of adversarial examples in malware classification, we study different\napproaches of crafting adversarial examples and defense techniques in the\nmalware domain and compare their effectiveness on multiple datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 22:20:32 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Podschwadt", "Robert", ""], ["Takabi", "Hassan", ""]]}, {"id": "1909.04779", "submitter": "Eitan Rothberg", "authors": "Eitan Rothberg, Tingting Chen, Luo Jie, Hao Ji", "title": "Localized Adversarial Training for Increased Accuracy and Robustness in\n  Image Classification", "comments": "4 pages (excluding references). Presented at AdvML: 1st Workshop on\n  Adversarial Learning Methods for Machine Learning and Data Mining at KDD '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's state-of-the-art image classifiers fail to correctly classify\ncarefully manipulated adversarial images. In this work, we develop a new,\nlocalized adversarial attack that generates adversarial examples by\nimperceptibly altering the backgrounds of normal images. We first use this\nattack to highlight the unnecessary sensitivity of neural networks to changes\nin the background of an image, then use it as part of a new training technique:\nlocalized adversarial training. By including locally adversarial images in the\ntraining set, we are able to create a classifier that suffers less loss than a\nnon-adversarially trained counterpart model on both natural and adversarial\ninputs. The evaluation of our localized adversarial training algorithm on MNIST\nand CIFAR-10 datasets shows decreased accuracy loss on natural images, and\nincreased robustness against adversarial inputs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 22:26:48 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Rothberg", "Eitan", ""], ["Chen", "Tingting", ""], ["Jie", "Luo", ""], ["Ji", "Hao", ""]]}, {"id": "1909.04791", "submitter": "Alireza Ghods", "authors": "Alireza Ghods and Diane J Cook", "title": "A Survey of Techniques All Classifiers Can Learn from Deep Networks:\n  Models, Optimizations, and Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have introduced novel and useful tools to the machine\nlearning community. Other types of classifiers can potentially make use of\nthese tools as well to improve their performance and generality. This paper\nreviews the current state of the art for deep learning classifier technologies\nthat are being used outside of deep neural networks. Non-network classifiers\ncan employ many components found in deep neural network architectures. In this\npaper, we review the feature learning, optimization, and regularization methods\nthat form a core of deep network technologies. We then survey non-neural\nnetwork learning algorithms that make innovative use of these methods to\nimprove classification. Because many opportunities and challenges still exist,\nwe discuss directions that can be pursued to expand the area of deep learning\nfor a variety of classification algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 23:33:19 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 17:50:42 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ghods", "Alireza", ""], ["Cook", "Diane J", ""]]}, {"id": "1909.04803", "submitter": "Ehsan Amid", "authors": "Ehsan Amid and Manfred K. Warmuth", "title": "An Implicit Form of Krasulina's k-PCA Update without the Orthonormality\n  Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We shed new insights on the two commonly used updates for the online $k$-PCA\nproblem, namely, Krasulina's and Oja's updates. We show that Krasulina's update\ncorresponds to a projected gradient descent step on the Stiefel manifold of the\northonormal $k$-frames, while Oja's update amounts to a gradient descent step\nusing the unprojected gradient. Following these observations, we derive a more\n\\emph{implicit} form of Krasulina's $k$-PCA update, i.e. a version that uses\nthe information of the future gradient as much as possible. Most interestingly,\nour implicit Krasulina update avoids the costly QR-decomposition step by\nbypassing the orthonormality constraint. We show that the new update in fact\ncorresponds to an online EM step applied to a probabilistic $k$-PCA model. The\nprobabilistic view of the updates allows us to combine multiple models in a\ndistributed setting. We show experimentally that the implicit Krasulina update\nyields superior convergence while being significantly faster. We also give\nstrong evidence that the new update can benefit from parallelism and is more\nstable w.r.t. tuning of the learning rate.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 00:36:22 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Amid", "Ehsan", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1909.04807", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Machiko Toyoda, Shotaro Tora, Naonori Ueda", "title": "Anomaly Detection with Inexact Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a supervised anomaly detection method for data with inexact\nanomaly labels, where each label, which is assigned to a set of instances,\nindicates that at least one instance in the set is anomalous. Although many\nanomaly detection methods have been proposed, they cannot handle inexact\nanomaly labels. To measure the performance with inexact anomaly labels, we\ndefine the inexact AUC, which is our extension of the area under the ROC curve\n(AUC) for inexact labels. The proposed method trains an anomaly score function\nso that the smooth approximation of the inexact AUC increases while anomaly\nscores for non-anomalous instances become low. We model the anomaly score\nfunction by a neural network-based unsupervised anomaly detection method, e.g.,\nautoencoders. The proposed method performs well even when only a small number\nof inexact labels are available by incorporating an unsupervised anomaly\ndetection mechanism with inexact AUC maximization. Using various datasets, we\nexperimentally demonstrate that our proposed method improves the anomaly\ndetection performance with inexact anomaly labels, and outperforms existing\nunsupervised and supervised anomaly detection and multiple instance learning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 01:30:38 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Toyoda", "Machiko", ""], ["Tora", "Shotaro", ""], ["Ueda", "Naonori", ""]]}, {"id": "1909.04823", "submitter": "Haidong Rong", "authors": "Haidong Rong, Yangzihao Wang, Feihu Zhou, Junjie Zhai, Haiyang Wu, Rui\n  Lan, Fan Li, Han Zhang, Yuekui Yang, Zhenyu Guo, Di Wang", "title": "Distributed Equivalent Substitution Training for Large-Scale Recommender\n  Systems", "comments": "Accepted by SIGIR '2020. Proceedings of the 43rd International ACM\n  SIGIR Conference on Research and Development in Information Retrieval. 2020", "journal-ref": null, "doi": "10.1145/3397271.3401113", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Distributed Equivalent Substitution (DES) training, a novel\ndistributed training framework for large-scale recommender systems with dynamic\nsparse features. DES introduces fully synchronous training to large-scale\nrecommendation system for the first time by reducing communication, thus making\nthe training of commercial recommender systems converge faster and reach better\nCTR. DES requires much less communication by substituting the weights-rich\noperators with the computationally equivalent sub-operators and aggregating\npartial results instead of transmitting the huge sparse weights directly\nthrough the network. Due to the use of synchronous training on large-scale Deep\nLearning Recommendation Models (DLRMs), DES achieves higher AUC(Area Under\nROC). We successfully apply DES training on multiple popular DLRMs of\nindustrial scenarios. Experiments show that our implementation outperforms the\nstate-of-the-art PS-based training framework, achieving up to 68.7%\ncommunication savings and higher throughput compared to other PS-based\nrecommender systems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:16:26 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 13:38:06 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 12:17:32 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 10:19:28 GMT"}, {"version": "v5", "created": "Sat, 30 May 2020 07:28:00 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Rong", "Haidong", ""], ["Wang", "Yangzihao", ""], ["Zhou", "Feihu", ""], ["Zhai", "Junjie", ""], ["Wu", "Haiyang", ""], ["Lan", "Rui", ""], ["Li", "Fan", ""], ["Zhang", "Han", ""], ["Yang", "Yuekui", ""], ["Guo", "Zhenyu", ""], ["Wang", "Di", ""]]}, {"id": "1909.04825", "submitter": "Guillaume Godin", "authors": "Ruud van Deursen, Peter Ertl, Igor V. Tetko and Guillaume Godin", "title": "GEN: Highly Efficient SMILES Explorer Using Autodidactic Generative\n  Examination Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recurrent neural networks have been widely used to generate millions of de\nnovo molecules in a known chemical space. These deep generative models are\ntypically setup with LSTM or GRU units and trained with canonical SMILEs. In\nthis study, we introduce a new robust architecture, Generative Examination\nNetworks GEN, based on bidirectional RNNs with concatenated sub-models to learn\nand generate molecular SMILES with a trained target space. GENs autonomously\nlearn the target space in a few epochs while being subjected to an independent\nonline examination mechanism to measure the quality of the generated set. Here\nwe have used online statistical quality control (SQC) on the percentage of\nvalid molecules SMILES as an examination measure to select the earliest\navailable stable model weights. Very high levels of valid SMILES (95-98%) can\nbe generated using multiple parallel encoding layers in combination with SMILES\naugmentation using unrestricted SMILES randomization. Our architecture combines\nan excellent novelty rate (85-90%) while generating SMILES with a strong\nconservation of the property space (95-99%). Our flexible examination mechanism\nis open to other quality criteria.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:44:04 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["van Deursen", "Ruud", ""], ["Ertl", "Peter", ""], ["Tetko", "Igor V.", ""], ["Godin", "Guillaume", ""]]}, {"id": "1909.04826", "submitter": "Pratik Ratadiya", "authors": "Pratik Ratadiya, Rahul Moorthy", "title": "Spam filtering on forums: A synthetic oversampling based approach for\n  imbalanced data classification", "comments": "Presented at SciPy India Conference 2018, IIT Bombay", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Forums play an important role in providing a platform for community\ninteraction. The introduction of irrelevant content or spam by individuals for\ncommercial and social gains tends to degrade the professional experience\npresented to the forum users. Automated moderation of the relevancy of posted\ncontent is desired. Machine learning is used for text classification and finds\napplications in spam email detection, fraudulent transaction detection etc. The\nbalance of classes in training data is essential in the case of classification\nalgorithms to make the learning efficient and accurate. However, in the case of\nforums, the spam content is sparse compared to the relevant content giving rise\nto a bias towards the latter while training. A model trained on such biased\ndata will fail to classify a spam sample. An approach based on Synthetic\nMinority Over-sampling Technique(SMOTE) is presented in this paper to tackle\nimbalanced training data. It involves synthetically creating new minority class\nsamples from the existing ones until balance in data is achieved. The enhanced\ndata is then passed through various classifiers for which the performance is\nrecorded. The results were analyzed on the data of forums of Spoken Tutorial,\nIIT Bombay over standard performance metrics and revealed that models trained\nafter Synthetic Minority oversampling outperform the ones trained on imbalanced\ndata by substantial margins. An empirical comparison of the results obtained by\nboth SMOTE and without SMOTE for various supervised classification algorithms\nhave been presented in this paper. Synthetic oversampling proves to be a\ncritical technique for achieving uniform class distribution which in turn\nyields commendable results in text classification. The presented approach can\nbe further extended to content categorization on educational websites thus\nhelping to improve the overall digital learning experience.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 11:22:37 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Ratadiya", "Pratik", ""], ["Moorthy", "Rahul", ""]]}, {"id": "1909.04837", "submitter": "Xiaojun Jia", "authors": "Xiaojun Jia, Xingxing Wei, Xiaochun Cao", "title": "Identifying and Resisting Adversarial Videos Using Temporal Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Video classification is a challenging task in computer vision. Although Deep\nNeural Networks (DNNs) have achieved excellent performance in video\nclassification, recent research shows adding imperceptible perturbations to\nclean videos can make the well-trained models output wrong labels with high\nconfidence. In this paper, we propose an effective defense framework to\ncharacterize and defend adversarial videos. The proposed method contains two\nphases: (1) adversarial video detection using temporal consistency between\nadjacent frames, and (2) adversarial perturbation reduction via denoisers in\nthe spatial and temporal domains respectively. Specifically, because of the\nlinear nature of DNNs, the imperceptible perturbations will enlarge with the\nincreasing of DNNs depth, which leads to the inconsistency of DNNs output\nbetween adjacent frames. However, the benign video frames often have the same\noutputs with their neighbor frames owing to the slight changes. Based on this\nobservation, we can distinguish between adversarial videos and benign videos.\nAfter that, we utilize different defense strategies against different attacks.\nWe propose the temporal defense, which reconstructs the polluted frames with\ntheir temporally neighbor clean frames, to deal with the adversarial videos\nwith sparse polluted frames. For the videos with dense polluted frames, we use\nan efficient adversarial denoiser to process each frame in the spatial domain,\nand thus purify the perturbations (we call it as spatial defense). A series of\nexperiments conducted on the UCF-101 dataset demonstrate that the proposed\nmethod significantly improves the robustness of video classifiers against\nadversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:11:52 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Jia", "Xiaojun", ""], ["Wei", "Xingxing", ""], ["Cao", "Xiaochun", ""]]}, {"id": "1909.04839", "submitter": "Hang Yu", "authors": "Hang Yu, Aishan Liu, Xianglong Liu, Gengchao Li, Ping Luo, Ran Cheng,\n  Jichen Yang, Chongzhi Zhang", "title": "PDA: Progressive Data Augmentation for General Robustness of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial images are designed to mislead deep neural networks (DNNs),\nattracting great attention in recent years. Although several defense strategies\nachieved encouraging robustness against adversarial samples, most of them fail\nto improve the robustness on common corruptions such as noise, blur, and\nweather/digital effects (e.g. frost, pixelate). To address this problem, we\npropose a simple yet effective method, named Progressive Data Augmentation\n(PDA), which enables general robustness of DNNs by progressively injecting\ndiverse adversarial noises during training. In other words, DNNs trained with\nPDA are able to obtain more robustness against both adversarial attacks as well\nas common corruptions than the recent state-of-the-art methods. We also find\nthat PDA is more efficient than prior arts and able to prevent accuracy drop on\nclean samples without being attacked. Furthermore, we theoretically show that\nPDA can control the perturbation bound and guarantee better generalization\nability than existing work. Extensive experiments on many benchmarks such as\nCIFAR-10, SVHN, and ImageNet demonstrate that PDA significantly outperforms its\ncounterparts in various experimental setups.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:27:54 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 05:01:22 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 11:58:05 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yu", "Hang", ""], ["Liu", "Aishan", ""], ["Liu", "Xianglong", ""], ["Li", "Gengchao", ""], ["Luo", "Ping", ""], ["Cheng", "Ran", ""], ["Yang", "Jichen", ""], ["Zhang", "Chongzhi", ""]]}, {"id": "1909.04844", "submitter": "Jonas Mueller", "authors": "Jonas Mueller, Alex Smola", "title": "Recognizing Variables from their Data via Deep Embeddings of\n  Distributions", "comments": "IEEE International Conference on Data Mining (ICDM), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key obstacle in automated analytics and meta-learning is the inability to\nrecognize when different datasets contain measurements of the same variable.\nBecause provided attribute labels are often uninformative in practice, this\ntask may be more robustly addressed by leveraging the data values themselves\nrather than just relying on their arbitrarily selected variable names. Here, we\npresent a computationally efficient method to identify high-confidence variable\nmatches between a given set of data values and a large repository of previously\nencountered datasets. Our approach enjoys numerous advantages over\ndistributional similarity based techniques because we leverage learned vector\nembeddings of datasets which adaptively account for natural forms of data\nvariation encountered in practice. Based on the neural architecture of deep\nsets, our embeddings can be computed for both numeric and string data. In\ndataset search and schema matching tasks, our methods outperform standard\nstatistical techniques and we find that the learned embeddings generalize well\nto new data sources.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:10:48 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Mueller", "Jonas", ""], ["Smola", "Alex", ""]]}, {"id": "1909.04847", "submitter": "Eugene Ie", "authors": "Eugene Ie, Chih-wei Hsu, Martin Mladenov, Vihan Jain, Sanmit Narvekar,\n  Jing Wang, Rui Wu, Craig Boutilier", "title": "RecSim: A Configurable Simulation Platform for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose RecSim, a configurable platform for authoring simulation\nenvironments for recommender systems (RSs) that naturally supports sequential\ninteraction with users. RecSim allows the creation of new environments that\nreflect particular aspects of user behavior and item structure at a level of\nabstraction well-suited to pushing the limits of current reinforcement learning\n(RL) and RS techniques in sequential interactive recommendation problems.\nEnvironments can be easily configured that vary assumptions about: user\npreferences and item familiarity; user latent state and its dynamics; and\nchoice models and other user response behavior. We outline how RecSim offers\nvalue to RL and RS researchers and practitioners, and how it can serve as a\nvehicle for academic-industrial collaboration.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:43:45 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 13:30:53 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ie", "Eugene", ""], ["Hsu", "Chih-wei", ""], ["Mladenov", "Martin", ""], ["Jain", "Vihan", ""], ["Narvekar", "Sanmit", ""], ["Wang", "Jing", ""], ["Wu", "Rui", ""], ["Boutilier", "Craig", ""]]}, {"id": "1909.04857", "submitter": "Jacob Priddle", "authors": "Jacob W. Priddle, Scott A. Sisson, David T. Frazier, Christopher\n  Drovandi", "title": "Efficient Bayesian synthetic likelihood with whitening transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-free methods are an established approach for performing\napproximate Bayesian inference for models with intractable likelihood\nfunctions. However, they can be computationally demanding. Bayesian synthetic\nlikelihood (BSL) is a popular such method that approximates the likelihood\nfunction of the summary statistic with a known, tractable distribution --\ntypically Gaussian -- and then performs statistical inference using standard\nlikelihood-based techniques. However, as the number of summary statistics\ngrows, the number of model simulations required to accurately estimate the\ncovariance matrix for this likelihood rapidly increases. This poses significant\nchallenge for the application of BSL, especially in cases where model\nsimulation is expensive. In this article we propose whitening BSL (wBSL) -- an\nefficient BSL method that uses approximate whitening transformations to\ndecorrelate the summary statistics at each algorithm iteration. We show\nempirically that this can reduce the number of model simulations required to\nimplement BSL by more than an order of magnitude, without much loss of\naccuracy. We explore a range of whitening procedures and demonstrate the\nperformance of wBSL on a range of simulated and real modelling scenarios from\necology and biology.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 05:25:40 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 03:37:37 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Priddle", "Jacob W.", ""], ["Sisson", "Scott A.", ""], ["Frazier", "David T.", ""], ["Drovandi", "Christopher", ""]]}, {"id": "1909.04883", "submitter": "Jian Li", "authors": "Jian Li, Yong Liu, and Weiping Wang", "title": "Semi-supervised Vector-valued Learning: From Theory to Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector-valued learning, where the output space admits a vector-valued\nstructure, is an important problem that covers a broad family of important\ndomains, e.g. multi-label learning and multi-class classification. Using local\nRademacher complexity and unlabeled data, we derive novel data-dependent excess\nrisk bounds for learning vector-valued functions in both the kernel space and\nlinear space. The derived bounds are much sharper than existing ones, where\nconvergence rates are improved from $\\mathcal{O}(1/\\sqrt{n})$ to\n$\\mathcal{O}(1/\\sqrt{n+u}),$ and $\\mathcal{O}(1/n)$ in special cases. Motivated\nby our theoretical analysis, we propose a unified framework for learning\nvector-valued functions, incorporating both local Rademacher complexity and\nLaplacian regularization. Empirical results on a wide number of benchmark\ndatasets show that the proposed algorithm significantly outperforms baseline\nmethods, which coincides with our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:30:53 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 08:42:05 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 03:28:10 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Li", "Jian", ""], ["Liu", "Yong", ""], ["Wang", "Weiping", ""]]}, {"id": "1909.04885", "submitter": "Michael Kaufmann", "authors": "Michael Kaufmann, Kornilios Kourtis, Celestine Mendler-D\\\"unner,\n  Adrian Sch\\\"upbach, Thomas Parnell", "title": "Addressing Algorithmic Bottlenecks in Elastic Machine Learning with\n  Chicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning training is one of the most common and important\nworkloads running on data centers today, but it is rarely executed alone.\nInstead, to reduce costs, computing resources are consolidated and shared by\ndifferent applications. In this scenario, elasticity and proper load balancing\nare vital to maximize efficiency, fairness, and utilization. Currently, most\ndistributed training frameworks do not support the aforementioned properties. A\nfew exceptions that do support elasticity, imitate generic distributed\nframeworks and use micro-tasks. In this paper we illustrate that micro-tasks\nare problematic for machine learning applications, because they require a high\ndegree of parallelism which hinders the convergence of distributed training at\na pure algorithmic level (i.e., ignoring overheads and scalability\nlimitations). To address this, we propose Chicle, a new elastic distributed\ntraining framework which exploits the nature of machine learning algorithms to\nimplement elasticity and load balancing without micro-tasks. We use Chicle to\ntrain deep neural network as well as generalized linear models, and show that\nChicle achieves performance competitive with state of the art rigid frameworks,\nwhile efficiently enabling elastic execution and dynamic load balancing.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:37:05 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kaufmann", "Michael", ""], ["Kourtis", "Kornilios", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Sch\u00fcpbach", "Adrian", ""], ["Parnell", "Thomas", ""]]}, {"id": "1909.04886", "submitter": "Arvind Easwaran", "authors": "Xiaozhe Gu and Arvind Easwaran", "title": "Towards Safe Machine Learning for CPS: Infer Uncertainty from Training\n  Data", "comments": "Publication rights licensed to ACM", "journal-ref": "In Proceedings of the 10th ACM/IEEE International Conference on\n  Cyber-Physical Systems (ICCPS), 2019. ACM, New York, NY, USA, pages 249-258", "doi": "10.1145/3302509.3311038", "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) techniques are increasingly applied to decision-making\nand control problems in Cyber-Physical Systems among which many are\nsafety-critical, e.g., chemical plants, robotics, autonomous vehicles. Despite\nthe significant benefits brought by ML techniques, they also raise additional\nsafety issues because 1) most expressive and powerful ML models are not\ntransparent and behave as a black box and 2) the training data which plays a\ncrucial role in ML safety is usually incomplete. An important technique to\nachieve safety for ML models is \"Safe Fail\", i.e., a model selects a reject\noption and applies the backup solution, a traditional controller or a human\noperator for example, when it has low confidence in a prediction.\n  Data-driven models produced by ML algorithms learn from training data, and\nhence they are only as good as the examples they have learnt. As pointed in\n[17], ML models work well in the \"training space\" (i.e., feature space with\nsufficient training data), but they could not extrapolate beyond the training\nspace. As observed in many previous studies, a feature space that lacks\ntraining data generally has a much higher error rate than the one that contains\nsufficient training samples [31]. Therefore, it is essential to identify the\ntraining space and avoid extrapolating beyond the training space. In this\npaper, we propose an efficient Feature Space Partitioning Tree (FSPT) to\naddress this problem. Using experiments, we also show that, a strong\nrelationship exists between model performance and FSPT score.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:38:53 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Gu", "Xiaozhe", ""], ["Easwaran", "Arvind", ""]]}, {"id": "1909.04890", "submitter": "Guillaume Maillard", "authors": "Guillaume Maillard (LMO), Sylvain Arlot (LM-Orsay), Matthieu Lerasle\n  (LM-Orsay)", "title": "Aggregated Hold-Out", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregated hold-out (Agghoo) is a method which averages learning rules\nselected by hold-out (that is, cross-validation with a single split). We\nprovide the first theoretical guarantees on Agghoo, ensuring that it can be\nused safely: Agghoo performs at worst like the hold-out when the risk is\nconvex. The same holds true in classification with the 0-1 risk, with an\nadditional constant factor. For the hold-out, oracle inequalities are known for\nbounded losses, as in binary classification. We show that similar results can\nbe proved, under appropriate assumptions, for other risk-minimization problems.\nIn particular, we obtain an oracle inequality for regularized kernel regression\nwith a Lip-schitz loss, without requiring that the Y variable or the regressors\nbe bounded. Numerical experiments show that aggregation brings a significant\nimprovement over the hold-out and that Agghoo is competitive with\ncross-validation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:46:09 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Maillard", "Guillaume", "", "LMO"], ["Arlot", "Sylvain", "", "LM-Orsay"], ["Lerasle", "Matthieu", "", "LM-Orsay"]]}, {"id": "1909.04894", "submitter": "Jian Li", "authors": "Jian Li, Yong Liu and Weiping Wang", "title": "Automated Spectral Kernel Learning", "comments": "Publised in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization performance of kernel methods is largely determined by the\nkernel, but common kernels are stationary thus input-independent and\noutput-independent, that limits their applications on complicated tasks. In\nthis paper, we propose a powerful and efficient spectral kernel learning\nframework and learned kernels are dependent on both inputs and outputs, by\nusing non-stationary spectral kernels and flexibly learning the spectral\nmeasure from the data. Further, we derive a data-dependent generalization error\nbound based on Rademacher complexity, which estimates the generalization\nability of the learning framework and suggests two regularization terms to\nimprove performance. Extensive experimental results validate the effectiveness\nof the proposed algorithm and confirm our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:54:17 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 11:34:48 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Li", "Jian", ""], ["Liu", "Yong", ""], ["Wang", "Weiping", ""]]}, {"id": "1909.04904", "submitter": "Yurii Rebryk", "authors": "Igor E. Kuralenok, Yurii Rebryk, Ruslan Solovev, Anton Ermilov", "title": "Factorized MultiClass Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new approach to multiclass classification\nproblem. We decompose the problem into a series of regression tasks, that are\nsolved with CART trees. The proposed method works significantly faster than\nstate-of-the-art solutions while giving the same level of model quality. The\nalgorithm is also robust to imbalanced datasets, allowing to reach high-quality\nresults in significantly less time without class re-balancing.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 08:18:16 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kuralenok", "Igor E.", ""], ["Rebryk", "Yurii", ""], ["Solovev", "Ruslan", ""], ["Ermilov", "Anton", ""]]}, {"id": "1909.04919", "submitter": "Tomasz Ku\\'smierczyk", "authors": "Tomasz Ku\\'smierczyk, Joseph Sakaya, Arto Klami", "title": "Correcting Predictions for Approximate Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian models quantify uncertainty and facilitate optimal decision-making\nin downstream applications. For most models, however, practitioners are forced\nto use approximate inference techniques that lead to sub-optimal decisions due\nto incorrect posterior predictive distributions. We present a novel approach\nthat corrects for inaccuracies in posterior inference by altering the\ndecision-making process. We train a separate model to make optimal decisions\nunder the approximate posterior, combining interpretable Bayesian modeling with\noptimization of direct predictive accuracy in a principled fashion. The\nsolution is generally applicable as a plug-in module for predictive\ndecision-making for arbitrary probabilistic programs, irrespective of the\nposterior inference strategy. We demonstrate the approach empirically in\nseveral problems, confirming its potential.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 08:42:25 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Ku\u015bmierczyk", "Tomasz", ""], ["Sakaya", "Joseph", ""], ["Klami", "Arto", ""]]}, {"id": "1909.04928", "submitter": "Vinay Jethava", "authors": "Vinay Jethava", "title": "On weighted uncertainty sampling in active learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note explores probabilistic sampling weighted by uncertainty in active\nlearning. This method has been previously used and authors have tangentially\nremarked on its efficacy. The scheme has several benefits: (1) it is\ncomputationally cheap, (2) it can be implemented in a single-pass streaming\nfashion which is a benefit when deployed in real-world systems where different\nsubsystems perform the suggestion scoring and extraction of user feedback, and\n(3) it is easily parameterizable. In this paper, we show on publicly available\ndatasets that using probabilistic weighting is often beneficial and strikes a\ngood compromise between exploration and representation especially when the\nstarting set of labelled points is biased.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 08:59:14 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Jethava", "Vinay", ""]]}, {"id": "1909.04930", "submitter": "Mustafa Teke", "authors": "Mustafa Teke and Yasemin Yard{\\i}mc{\\i}", "title": "Multi-Year Vector Dynamic Time Warping Based Crop Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent automated crop mapping via supervised learning-based methods have\ndemonstrated unprecedented improvement over classical techniques. However, most\ncrop mapping studies are limited to same-year crop mapping in which the present\nyear's labeled data is used to predict the same year's crop map. Classification\naccuracies of these methods degrade considerably in cross-year mapping.\nCross-year crop mapping is more useful as it allows the prediction of the\nfollowing years' crop maps using previously labeled data. We propose Vector\nDynamic Time Warping (VDTW), a novel multi-year classification approach based\non warping of angular distances between phenological vectors. The results prove\nthat the proposed VDTW method is robust to temporal and spectral variations\ncompensating for different farming practices, climate and atmospheric effects,\nand measurement errors between years. We also describe a method for determining\nthe most discriminative time window that allows high classification accuracies\nwith limited data. We carried out tests of our approach with Landsat 8\ntime-series imagery from years 2013 to 2016 for classification of corn and\ncotton in the Harran Plain, and corn, cotton, and soybean in the Bismil Plain\nof Southeastern Turkey. In addition, we tested VDTW corn and soybean in Kansas,\nthe US for 2017 and 2018 with the Harmonized Landsat Sentinel data. The VDTW\nmethod achieved 99.85% and 99.74% overall accuracies for the same and cross\nyears, respectively with fewer training samples compared to other\nstate-of-the-art approaches, i.e. spectral angle mapper (SAM), dynamic time\nwarping (DTW), time-weighted DTW (TWDTW), random forest (RF), support vector\nmachine (SVM) and deep long short-term memory (LSTM) methods. The proposed\nmethod could be expanded for other crop types and/or geographical areas.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 09:05:05 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 08:28:22 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Teke", "Mustafa", ""], ["Yard\u0131mc\u0131", "Yasemin", ""]]}, {"id": "1909.04931", "submitter": "Jiaxiang Tang", "authors": "Jiaxiang Tang, Wei Hu, Xiang Gao, Zongming Guo", "title": "Joint Learning of Graph Representation and Node Features in Graph\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Neural Networks (GCNNs) extend classical CNNs to graph\ndata domain, such as brain networks, social networks and 3D point clouds. It is\ncritical to identify an appropriate graph for the subsequent graph convolution.\nExisting methods manually construct or learn one fixed graph for all the layers\nof a GCNN. In order to adapt to the underlying structure of node features in\ndifferent layers, we propose dynamic learning of graphs and node features\njointly in GCNNs. In particular, we cast the graph optimization problem as\ndistance metric learning to capture pairwise similarities of features in each\nlayer. We deploy the Mahalanobis distance metric and further decompose the\nmetric matrix into a low-dimensional matrix, which converts graph learning to\nthe optimization of a low-dimensional matrix for efficient implementation.\nExtensive experiments on point clouds and citation network datasets demonstrate\nthe superiority of the proposed method in terms of both accuracies and\nrobustness.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 09:09:40 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Tang", "Jiaxiang", ""], ["Hu", "Wei", ""], ["Gao", "Xiang", ""], ["Guo", "Zongming", ""]]}, {"id": "1909.04939", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Benjamin Lucas, Germain Forestier, Charlotte\n  Pelletier, Daniel F. Schmidt, Jonathan Weber, Geoffrey I. Webb, Lhassane\n  Idoumghar, Pierre-Alain Muller, Fran\\c{c}ois Petitjean", "title": "InceptionTime: Finding AlexNet for Time Series Classification", "comments": null, "journal-ref": null, "doi": "10.1007/s10618-020-00710-y", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper brings deep learning at the forefront of research into Time Series\nClassification (TSC). TSC is the area of machine learning tasked with the\ncategorization (or labelling) of time series. The last few decades of work in\nthis area have led to significant progress in the accuracy of classifiers, with\nthe state of the art now represented by the HIVE-COTE algorithm. While\nextremely accurate, HIVE-COTE cannot be applied to many real-world datasets\nbecause of its high training time complexity in O(N2 * T4) for a dataset with N\ntime series of length T. For example, it takes HIVE-COTE more than 8 days to\nlearn from a small dataset with N = 1500 time series of short length T = 46.\nMeanwhile deep learning has received enormous attention because of its high\naccuracy and scalability. Recent approaches to deep learning for TSC have been\nscalable, but less accurate than HIVE-COTE. We introduce InceptionTime - an\nensemble of deep Convolutional Neural Network (CNN) models, inspired by the\nInception-v4 architecture. Our experiments show that InceptionTime is on par\nwith HIVE-COTE in terms of accuracy while being much more scalable: not only\ncan it learn from 1,500 time series in one hour but it can also learn from 8M\ntime series in 13 hours, a quantity of data that is fully out of reach of\nHIVE-COTE.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 09:32:40 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 14:28:15 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 18:11:29 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Lucas", "Benjamin", ""], ["Forestier", "Germain", ""], ["Pelletier", "Charlotte", ""], ["Schmidt", "Daniel F.", ""], ["Weber", "Jonathan", ""], ["Webb", "Geoffrey I.", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""], ["Petitjean", "Fran\u00e7ois", ""]]}, {"id": "1909.04985", "submitter": "Edouard Delasalles", "authors": "Edouard Delasalles, Sylvain Lamprier, Ludovic Denoyer", "title": "Learning Dynamic Author Representations with Temporal Language Models", "comments": "International Conference on Data Mining, ICDM 2019", "journal-ref": null, "doi": "10.1109/ICDM.2019.00022", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are at the heart of numerous works, notably in the text\nmining and information retrieval communities. These statistical models aim at\nextracting word distributions, from simple unigram models to recurrent\napproaches with latent variables that capture subtle dependencies in texts.\nHowever, those models are learned from word sequences only, and authors'\nidentities, as well as publication dates, are seldom considered. We propose a\nneural model, based on recurrent language modeling, which aims at capturing\nlanguage diffusion tendencies in author communities through time. By\nconditioning language models with author and temporal vector states, we are\nable to leverage the latent dependencies between the text contexts. This allows\nus to beat several temporal and non-temporal language baselines on two\nreal-world corpora, and to learn meaningful author representations that vary\nthrough time.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 11:51:43 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Delasalles", "Edouard", ""], ["Lamprier", "Sylvain", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1909.04999", "submitter": "Yongseok Choi", "authors": "Yongseok Choi, Junyoung Park, Subin Yi, Dong-Yeon Cho", "title": "Domain-Agnostic Few-Shot Classification by Learning Disparate Modulators", "comments": "Presented at NeurIPS 2019 Workshop on Meta-Learning (MetaLearn 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although few-shot learning research has advanced rapidly with the help of\nmeta-learning, its practical usefulness is still limited because most of them\nassumed that all meta-training and meta-testing examples came from a single\ndomain. We propose a simple but effective way for few-shot classification in\nwhich a task distribution spans multiple domains including ones never seen\nduring meta-training. The key idea is to build a pool of models to cover this\nwide task distribution and learn to select the best one for a particular task\nthrough cross-domain meta-learning. All models in the pool share a base network\nwhile each model has a separate modulator to refine the base network in its own\nway. This framework allows the pool to have representational diversity without\nlosing beneficial domain-invariant features. We verify the effectiveness of the\nproposed algorithm through experiments on various datasets across diverse\ndomains.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 12:18:15 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 12:09:35 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Choi", "Yongseok", ""], ["Park", "Junyoung", ""], ["Yi", "Subin", ""], ["Cho", "Dong-Yeon", ""]]}, {"id": "1909.05004", "submitter": "Arpan Kusari", "authors": "Arpan Kusari and Jonathan P. How", "title": "Predicting optimal value functions by interpolating reward functions in\n  scalarized multi-objective reinforcement learning", "comments": "Accepted at ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach for defining a reward function for Multi-objective\nReinforcement Learning (MORL) problems is the weighted sum of the multiple\nobjectives. The weights are then treated as design parameters dependent on the\nexpertise (and preference) of the person performing the learning, with the\ntypical result that a new solution is required for any change in these\nsettings. This paper investigates the relationship between the reward function\nand the optimal value function for MORL; specifically addressing the question\nof how to approximate the optimal value function well beyond the set of weights\nfor which the optimization problem was actually solved, thereby avoiding the\nneed to recompute for any particular choice. We prove that the value function\ntransforms smoothly given a transformation of weights of the reward function\n(and thus a smooth interpolation in the policy space). A Gaussian process is\nused to obtain a smooth interpolation over the reward function weights of the\noptimal value function for three well-known examples: GridWorld, Objectworld\nand Pendulum. The results show that the interpolation can provide very robust\nvalues for sample states and action space in discrete and continuous domain\nproblems. Significant advantages arise from utilizing this interpolation\ntechnique in the domain of autonomous vehicles: easy, instant adaptation of\nuser preferences while driving and true randomization of obstacle vehicle\nbehavior preferences during training.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 12:26:42 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 20:58:20 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 01:59:01 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 17:17:51 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Kusari", "Arpan", ""], ["How", "Jonathan P.", ""]]}, {"id": "1909.05006", "submitter": "Sanzo Miyazawa", "authors": "Sanzo Miyazawa", "title": "Boltzmann machine learning and regularization methods for inferring\n  evolutionary fields and couplings from a multiple sequence alignment", "comments": "In this version, the value of selective temperature for protein\n  PF00153, $T_s$ in Table 5 and $k_B T_s$ in the last line of the section 2.8,\n  has been corrected. The version 2 (arXiv:1909.05006v2) was published in the\n  IEEE/ACM Transactions on Computational Biology and Bioinformatics. The\n  program and multiple sequence alignments are available from\n  https://gitlab.com/sanzo.miyazawa/BM/", "journal-ref": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,\n  2020, Early Access Article", "doi": "10.1109/TCBB.2020.2993232", "report-no": null, "categories": "q-bio.PE cond-mat.stat-mech cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse Potts problem to infer a Boltzmann distribution for homologous\nprotein sequences from their single-site and pairwise amino acid frequencies\nrecently attracts a great deal of attention in the studies of protein structure\nand evolution. We study regularization and learning methods and how to tune\nregularization parameters to correctly infer interactions in Boltzmann machine\nlearning. Using $L_2$ regularization for fields, group $L_1$ for couplings is\nshown to be very effective for sparse couplings in comparison with $L_2$ and\n$L_1$. Two regularization parameters are tuned to yield equal values for both\nthe sample and ensemble averages of evolutionary energy. Both averages smoothly\nchange and converge, but their learning profiles are very different between\nlearning methods. The Adam method is modified to make stepsize proportional to\nthe gradient for sparse couplings and to use a soft-thresholding function for\ngroup $L_1$. It is shown by first inferring interactions from protein sequences\nand then from Monte Carlo samples that the fields and couplings can be well\nrecovered, but that recovering the pairwise correlations in the resolution of a\ntotal energy is harder for the natural proteins than for the protein-like\nsequences. Selective temperature for folding/structural constrains in protein\nevolution is also estimated.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 08:41:19 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 04:47:06 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 05:41:55 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Miyazawa", "Sanzo", ""]]}, {"id": "1909.05007", "submitter": "Daron Anderson", "authors": "Daron Anderson, Douglas Leith", "title": "Optimality of the Subgradient Algorithm in the Stochastic Setting", "comments": "6 figures, Corrected off-by-one errors coming from proof in Appendix\n  A. Replaced with newer Version April 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG cs.SY eess.SY math.OC math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Subgradient algorithm is universal for online learning on\nthe simplex in the sense that it simultaneously achieves $O(\\sqrt N)$ regret\nfor adversarial costs and $O(1)$ pseudo-regret for i.i.d costs. To the best of\nour knowledge this is the first demonstration of a universal algorithm on the\nsimplex that is not a variant of Hedge. Since Subgradient is a popular and\nwidely used algorithm our results have immediate broad application.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:44:30 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 14:33:20 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 12:22:22 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 12:02:47 GMT"}, {"version": "v5", "created": "Thu, 31 Oct 2019 12:50:45 GMT"}, {"version": "v6", "created": "Fri, 3 Apr 2020 17:04:11 GMT"}, {"version": "v7", "created": "Fri, 27 Nov 2020 14:31:37 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Anderson", "Daron", ""], ["Leith", "Douglas", ""]]}, {"id": "1909.05024", "submitter": "Lu Liu", "authors": "Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Learning to Propagate for Graph Meta-Learning", "comments": "Accepted to NeurIPS 2019, code at\n  https://github.com/liulu112601/Gated-Propagation-Net, slides at\n  https://liulu112601.github.io/resources/GPN-NeurIPS-Slides-revised.pdf,\n  Poster at\n  https://liulu112601.github.io/resources/Graph-Meta-Learning-Poster-revised.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning extracts common knowledge from learning different tasks and\nuses it for unseen tasks. It can significantly improve tasks that suffer from\ninsufficient training data, e.g., few shot learning. In most meta-learning\nmethods, tasks are implicitly related by sharing parameters or optimizer. In\nthis paper, we show that a meta-learner that explicitly relates tasks on a\ngraph describing the relations of their output dimensions (e.g., classes) can\nsignificantly improve few shot learning. The graph's structure is usually free\nor cheap to obtain but has rarely been explored in previous works. We develop a\nnovel meta-learner of this type for prototype-based classification, in which a\nprototype is generated for each class, such that the nearest neighbor search\namong the prototypes produces an accurate classification. The meta-learner,\ncalled \"Gated Propagation Network (GPN)\", learns to propagate messages between\nprototypes of different classes on the graph, so that learning the prototype of\neach class benefits from the data of other related classes. In GPN, an\nattention mechanism aggregates messages from neighboring classes of each class,\nwith a gate choosing between the aggregated message and the message from the\nclass itself. We train GPN on a sequence of tasks from many-shot to few shot\ngenerated by subgraph sampling. During training, it is able to reuse and update\npreviously achieved prototypes from the memory in a life-long learning cycle.\nIn experiments, under different training-test discrepancy and test task\ngeneration settings, GPN outperforms recent meta-learning methods on two\nbenchmark datasets. The code of GPN and dataset generation is available at\nhttps://github.com/liulu112601/Gated-Propagation-Net.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:00:24 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 08:46:48 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Lu", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1909.05030", "submitter": "Chamin Hewa Koneputugodage", "authors": "Chamin Hewa Koneputugodage, Rhys Healy, Sean Lamont, Ian Mallett, Matt\n  Brown, Matt Walters, Ushini Attanayake, Libo Zhang, Roger T. Dean, Alexander\n  Hunter, Charles Gretton, Christian Walder", "title": "Computer Assisted Composition in Continuous Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of combining sequence models of symbolic music with\nuser defined constraints. For typical models this is non-trivial as only the\nconditional distribution of each symbol given the earlier symbols is available,\nwhile the constraints correspond to arbitrary times. Previously this has been\naddressed by assuming a discrete time model of fixed rhythm. We generalise to\ncontinuous time and arbitrary rhythm by introducing a simple, novel, and\nefficient particle filter scheme, applicable to general continuous time point\nprocesses. Extensive experimental evaluations demonstrate that in comparison\nwith a more traditional beam search baseline, the particle filter exhibits\nsuperior statistical properties and yields more agreeable results in an\nextensive human listening test experiment.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:57:58 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Koneputugodage", "Chamin Hewa", ""], ["Healy", "Rhys", ""], ["Lamont", "Sean", ""], ["Mallett", "Ian", ""], ["Brown", "Matt", ""], ["Walters", "Matt", ""], ["Attanayake", "Ushini", ""], ["Zhang", "Libo", ""], ["Dean", "Roger T.", ""], ["Hunter", "Alexander", ""], ["Gretton", "Charles", ""], ["Walder", "Christian", ""]]}, {"id": "1909.05032", "submitter": "Tatiana Gabruseva", "authors": "Tatiana Gabruseva, Sergey Zlobin, Peter Wang", "title": "Photometric light curves classification with machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Large Synoptic Survey Telescope will complete its survey in 2022 and\nproduce terabytes of imaging data each night. To work with this massive onset\nof data, automated algorithms to classify astronomical light curves are\ncrucial. Here, we present a method for automated classification of photometric\nlight curves for a range of astronomical objects. Our approach is based on the\ngradient boosting of decision trees, feature extraction and selection, and\naugmentation. The solution was developed in the context of The Photometric LSST\nAstronomical Time Series Classification Challenge (PLAsTiCC) and achieved one\nof the top results in the challenge.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 01:28:19 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Gabruseva", "Tatiana", ""], ["Zlobin", "Sergey", ""], ["Wang", "Peter", ""]]}, {"id": "1909.05040", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Sparse and Imperceivable Adversarial Attacks", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been proven to be vulnerable to a variety of adversarial\nattacks. From a safety perspective, highly sparse adversarial attacks are\nparticularly dangerous. On the other hand the pixelwise perturbations of sparse\nattacks are typically large and thus can be potentially detected. We propose a\nnew black-box technique to craft adversarial examples aiming at minimizing\n$l_0$-distance to the original image. Extensive experiments show that our\nattack is better or competitive to the state of the art. Moreover, we can\nintegrate additional bounds on the componentwise perturbation. Allowing pixels\nto change only in region of high variation and avoiding changes along\naxis-aligned edges makes our adversarial examples almost non-perceivable.\nMoreover, we adapt the Projected Gradient Descent attack to the $l_0$-norm\nintegrating componentwise constraints. This allows us to do adversarial\ntraining to enhance the robustness of classifiers against sparse and\nimperceivable adversarial manipulations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:28:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1909.05044", "submitter": "Jonas Schouterden", "authors": "Jonas Schouterden, Jesse Davis, Hendrik Blockeel", "title": "LazyBum: Decision tree learning using lazy propositionalization", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": "10.1007/978-3-030-49210-6_9", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositionalization is the process of summarizing relational data into a\ntabular (attribute-value) format. The resulting table can next be used by any\npropositional learner. This approach makes it possible to apply a wide variety\nof learning methods to relational data. However, the transformation from\nrelational to propositional format is generally not lossless: different\nrelational structures may be mapped onto the same feature vector. At the same\ntime, features may be introduced that are not needed for the learning task at\nhand. In general, it is hard to define a feature space that contains all and\nonly those features that are needed for the learning task. This paper presents\nLazyBum, a system that can be considered a lazy version of the recently\nproposed OneBM method for propositionalization. LazyBum interleaves OneBM's\nfeature construction method with a decision tree learner. This learner both\nuses and guides the propositionalization process. It indicates when and where\nto look for new features. This approach is similar to what has elsewhere been\ncalled dynamic propositionalization. In an experimental comparison with the\noriginal OneBM and with two other recently proposed propositionalization\nmethods (nFOIL and MODL, which respectively perform dynamic and static\npropositionalization), LazyBum achieves a comparable accuracy with a lower\nexecution time on most of the datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:33:27 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Schouterden", "Jonas", ""], ["Davis", "Jesse", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1909.05062", "submitter": "Naman Agarwal", "authors": "Naman Agarwal, Elad Hazan, Karan Singh", "title": "Logarithmic Regret for Online Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study optimal regret bounds for control in linear dynamical systems under\nadversarially changing strongly convex cost functions, given the knowledge of\ntransition dynamics. This includes several well studied and fundamental\nframeworks such as the Kalman filter and the linear quadratic regulator. State\nof the art methods achieve regret which scales as $O(\\sqrt{T})$, where $T$ is\nthe time horizon.\n  We show that the optimal regret in this setting can be significantly smaller,\nscaling as $O(\\text{poly}(\\log T))$. This regret bound is achieved by two\ndifferent efficient iterative methods, online gradient descent and online\nnatural gradient.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:59:40 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Agarwal", "Naman", ""], ["Hazan", "Elad", ""], ["Singh", "Karan", ""]]}, {"id": "1909.05063", "submitter": "Jan St\\\"uhmer", "authors": "Jan St\\\"uhmer, Richard E. Turner, Sebastian Nowozin", "title": "Independent Subspace Analysis for Unsupervised Learning of Disentangled\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been an increased interest in unsupervised learning of\ndisentangled representations using the Variational Autoencoder (VAE) framework.\nMost of the existing work has focused largely on modifying the variational cost\nfunction to achieve this goal. We first show that these modifications, e.g.\nbeta-VAE, simplify the tendency of variational inference to underfit causing\npathological over-pruning and over-orthogonalization of learned components.\nSecond we propose a complementary approach: to modify the probabilistic model\nwith a structured latent prior. This prior allows to discover latent variable\nrepresentations that are structured into a hierarchy of independent vector\nspaces. The proposed prior has three major advantages: First, in contrast to\nthe standard VAE normal prior the proposed prior is not rotationally invariant.\nThis resolves the problem of unidentifiability of the standard VAE normal\nprior. Second, we demonstrate that the proposed prior encourages a disentangled\nlatent representation which facilitates learning of disentangled\nrepresentations. Third, extensive quantitative experiments demonstrate that the\nprior significantly mitigates the trade-off between reconstruction loss and\ndisentanglement over the state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:58:49 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["St\u00fchmer", "Jan", ""], ["Turner", "Richard E.", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "1909.05073", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Fu-Ming Guo, Wei Niu, Xue Lin, Jian Tang, Kaisheng Ma,\n  Bin Ren, Yanzhi Wang", "title": "PCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for\n  Real-time Execution on Mobile Devices", "comments": "To appear in Proceedings of the 34th AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression techniques on Deep Neural Network (DNN) have been widely\nacknowledged as an effective way to achieve acceleration on a variety of\nplatforms, and DNN weight pruning is a straightforward and effective method.\nThere are currently two mainstreams of pruning methods representing two\nextremes of pruning regularity: non-structured, fine-grained pruning can\nachieve high sparsity and accuracy, but is not hardware friendly; structured,\ncoarse-grained pruning exploits hardware-efficient structures in pruning, but\nsuffers from accuracy drop when the pruning rate is high. In this paper, we\nintroduce PCONV, comprising a new sparsity dimension, -- fine-grained pruning\npatterns inside the coarse-grained structures. PCONV comprises two types of\nsparsities, Sparse Convolution Patterns (SCP) which is generated from\nintra-convolution kernel pruning and connectivity sparsity generated from\ninter-convolution kernel pruning. Essentially, SCP enhances accuracy due to its\nspecial vision properties, and connectivity sparsity increases pruning rate\nwhile maintaining balanced workload on filter computation. To deploy PCONV, we\ndevelop a novel compiler-assisted DNN inference framework and execute PCONV\nmodels in real-time without accuracy compromise, which cannot be achieved in\nprior work. Our experimental results show that, PCONV outperforms three\nstate-of-art end-to-end DNN frameworks, TensorFlow-Lite, TVM, and Alibaba\nMobile Neural Network with speedup up to 39.2x, 11.4x, and 6.3x, respectively,\nwith no accuracy loss. Mobile devices can achieve real-time inference on\nlarge-scale DNNs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 03:58:29 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 01:33:36 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 00:18:07 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 19:39:06 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ma", "Xiaolong", ""], ["Guo", "Fu-Ming", ""], ["Niu", "Wei", ""], ["Lin", "Xue", ""], ["Tang", "Jian", ""], ["Ma", "Kaisheng", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1909.05075", "submitter": "James Edwards", "authors": "James Edwards", "title": "Practical Calculation of Gittins Indices for Multi-armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gittins indices provide an optimal solution to the classical multi-armed\nbandit problem. An obstacle to their use has been the common perception that\ntheir computation is very difficult. This paper demonstrates an accessible\ngeneral methodology for the calculating Gittins indices for the multi-armed\nbandit with a detailed study on the cases of Bernoulli and Gaussian rewards.\nWith accompanying easy-to-use open source software, this work removes\ncomputation as a barrier to using Gittins indices in these commonly found\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:24:43 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Edwards", "James", ""]]}, {"id": "1909.05076", "submitter": "Ryan Bernstein", "authors": "Ryan Bernstein", "title": "Static Analysis for Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming is a powerful abstraction for statistical machine\nlearning. Applying static analysis methods to probabilistic programs could\nserve to optimize the learning process, automatically verify properties of\nmodels, and improve the programming interface for users. This field of static\nanalysis for probabilistic programming (SAPP) is young and unorganized,\nconsisting of a constellation of techniques with various goals and limitations.\nThe primary aim of this work is to synthesize the major contributions of the\nSAPP field within an organizing structure and context. We provide technical\nbackground for static analysis and probabilistic programming, suggest a\nfunctional taxonomy for probabilistic programming languages, and analyze the\napplicability of major ideas in the SAPP field. We conclude that, while current\nstatic analysis techniques for probabilistic programs have practical\nlimitations, there are a number of future directions with high potential to\nimprove the state of statistical machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:34:10 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Bernstein", "Ryan", ""]]}, {"id": "1909.05095", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Lassance, Vincent Gripon, Jian Tang, Antonio Ortega", "title": "Structural Robustness for Deep Learning Architectures", "comments": null, "journal-ref": null, "doi": "10.1109/DSW.2019.8755564", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Networks have been shown to provide state-of-the-art performance in many\nmachine learning challenges. Unfortunately, they are susceptible to various\ntypes of noise, including adversarial attacks and corrupted inputs. In this\nwork we introduce a formal definition of robustness which can be viewed as a\nlocalized Lipschitz constant of the network function, quantified in the domain\nof the data to be classified. We compare this notion of robustness to existing\nones, and study its connections with methods in the literature. We evaluate\nthis metric by performing experiments on various competitive vision datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:52:18 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Lassance", "Carlos", ""], ["Gripon", "Vincent", ""], ["Tang", "Jian", ""], ["Ortega", "Antonio", ""]]}, {"id": "1909.05097", "submitter": "Chieh Wu T", "authors": "Chieh Wu, Jared Miller, Yale Chang, Mario Sznaier, Jennifer Dy", "title": "Spectral Non-Convex Optimization for Dimension Reduction with\n  Hilbert-Schmidt Independence Criterion", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.03093", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hilbert Schmidt Independence Criterion (HSIC) is a kernel dependence\nmeasure that has applications in various aspects of machine learning.\nConveniently, the objectives of different dimensionality reduction applications\nusing HSIC often reduce to the same optimization problem. However, the\nnonconvexity of the objective function arising from non-linear kernels poses a\nserious challenge to optimization efficiency and limits the potential of\nHSIC-based formulations. As a result, only linear kernels have been\ncomputationally tractable in practice. This paper proposes a spectral-based\noptimization algorithm that extends beyond the linear kernel. The algorithm\nidentifies a family of suitable kernels and provides the first and second-order\nlocal guarantees when a fixed point is reached. Furthermore, we propose a\nprincipled initialization strategy, thereby removing the need to repeat the\nalgorithm at random initialization points. Compared to state-of-the-art\noptimization algorithms, our empirical results on real data show a run-time\nimprovement by as much as a factor of $10^5$ while consistently achieving lower\ncost and classification/clustering errors. The implementation source code is\npublicly available on https://github.com/endsley.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:41:04 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Wu", "Chieh", ""], ["Miller", "Jared", ""], ["Chang", "Yale", ""], ["Sznaier", "Mario", ""], ["Dy", "Jennifer", ""]]}, {"id": "1909.05099", "submitter": "Cl\\'ement Christophe", "authors": "Cl\\'ement Christophe, Julien Velcin, Jairo Cugliari, Philippe\n  Suignard, Manel Boumghar", "title": "How to detect novelty in textual data streams? A comparative study of\n  existing methods", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since datasets with annotation for novelty at the document and/or word level\nare not easily available, we present a simulation framework that allows us to\ncreate different textual datasets in which we control the way novelty occurs.\nWe also present a benchmark of existing methods for novelty detection in\ntextual data streams. We define a few tasks to solve and compare several\nstate-of-the-art methods. The simulation framework allows us to evaluate their\nperformances according to a set of limited scenarios and test their sensitivity\nto some parameters. Finally, we experiment with the same methods on different\nkinds of novelty in the New York Times Annotated Dataset.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:55:02 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Christophe", "Cl\u00e9ment", ""], ["Velcin", "Julien", ""], ["Cugliari", "Jairo", ""], ["Suignard", "Philippe", ""], ["Boumghar", "Manel", ""]]}, {"id": "1909.05106", "submitter": "Bastian Alt", "authors": "Bastian Alt, Adrian \\v{S}o\\v{s}i\\'c, Heinz Koeppl", "title": "Correlation Priors for Reinforcement Learning", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many decision-making problems naturally exhibit pronounced structures\ninherited from the characteristics of the underlying environment. In a Markov\ndecision process model, for example, two distinct states can have inherently\nrelated semantics or encode resembling physical state configurations. This\noften implies locally correlated transition dynamics among the states. In order\nto complete a certain task in such environments, the operating agent usually\nneeds to execute a series of temporally and spatially correlated actions.\nThough there exists a variety of approaches to capture these correlations in\ncontinuous state-action domains, a principled solution for discrete\nenvironments is missing. In this work, we present a Bayesian learning framework\nbased on P\\'olya-Gamma augmentation that enables an analogous reasoning in such\ncases. We demonstrate the framework on a number of common decision-making\nrelated problems, such as imitation learning, subgoal extraction, system\nidentification and Bayesian reinforcement learning. By explicitly modeling the\nunderlying correlation structures of these problems, the proposed approach\nyields superior predictive performance compared to correlation-agnostic models,\neven when trained on data sets that are an order of magnitude smaller in size.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:01:31 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 11:01:39 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Alt", "Bastian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1909.05114", "submitter": "Jannis Born", "authors": "Jannis Born, Matteo Manica, Ali Oskooei, Joris Cadow, Karsten\n  Borgwardt, Mar\\'ia Rodr\\'iguez Mart\\'inez", "title": "PaccMann$^{RL}$: Designing anticancer drugs from transcriptomic data via\n  reinforcement learning", "comments": "18 pages total (12 pages main text, 4 pages references, 11 pages\n  appendix) 8 figures", "journal-ref": "International Conference on Research in Computational Molecular\n  Biology 2020", "doi": "10.1007/978-3-030-45257-5_18", "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of deep generative models in computational chemistry, in\nsilico anticancer drug design has undergone an unprecedented transformation.\nWhile state-of-the-art deep learning approaches have shown potential in\ngenerating compounds with desired chemical properties, they disregard the\ngenetic profile and properties of the target disease. Here, we introduce the\nfirst generative model capable of tailoring anticancer compounds for a specific\nbiomolecular profile. Using a RL framework, the transcriptomic profiles of\ncancer cells are used as a context for the generation of candidate molecules.\nOur molecule generator combines two separately pretrained variational\nautoencoders (VAEs) - the first VAE encodes transcriptomic profiles into a\nsmooth, latent space which in turn is used to condition a second VAE to\ngenerate novel molecular structures on the given transcriptomic profile. The\ngenerative process is optimized through PaccMann, a previously developed drug\nsensitivity prediction model to obtain effective anticancer compounds for the\ngiven context (i.e., transcriptomic profile). We demonstrate how the molecule\ngeneration can be biased towards compounds with high predicted inhibitory\neffect against individual cell lines or specific cancer sites. We verify our\napproach by investigating candidate drugs generated against specific cancer\ntypes and find the highest structural similarity to existing compounds with\nknown efficacy against these cancer types. We envision our approach to\ntransform in silico anticancer drug design by leveraging the biomolecular\ncharacteristics of the disease in order to increase success rates in lead\ncompound discovery.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:27:27 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 10:08:35 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 21:08:45 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2020 18:25:28 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Born", "Jannis", ""], ["Manica", "Matteo", ""], ["Oskooei", "Ali", ""], ["Cadow", "Joris", ""], ["Borgwardt", "Karsten", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""]]}, {"id": "1909.05122", "submitter": "Varun Kanade", "authors": "Tomas Va\\v{s}kevi\\v{c}ius, Varun Kanade and Patrick Rebeschini", "title": "Implicit Regularization for Optimal Sparse Recovery", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate implicit regularization schemes for gradient descent methods\napplied to unpenalized least squares regression to solve the problem of\nreconstructing a sparse signal from an underdetermined system of linear\nmeasurements under the restricted isometry assumption. For a given\nparametrization yielding a non-convex optimization problem, we show that\nprescribed choices of initialization, step size and stopping time yield a\nstatistically and computationally optimal algorithm that achieves the minimax\nrate with the same cost required to read the data up to poly-logarithmic\nfactors. Beyond minimax optimality, we show that our algorithm adapts to\ninstance difficulty and yields a dimension-independent rate when the\nsignal-to-noise ratio is high enough. Key to the computational efficiency of\nour method is an increasing step size scheme that adapts to refined estimates\nof the true solution. We validate our findings with numerical experiments and\ncompare our algorithm against explicit $\\ell_{1}$ penalization. Going from hard\ninstances to easy ones, our algorithm is seen to undergo a phase transition,\neventually matching least squares with an oracle knowledge of the true support.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:15:08 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Va\u0161kevi\u010dius", "Tomas", ""], ["Kanade", "Varun", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "1909.05125", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Luis Mu\\~noz-Gonz\\'alez, Kenneth T. Co, Emil C. Lupu", "title": "Byzantine-Robust Federated Machine Learning through Adaptive Model\n  Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables training collaborative machine learning models at\nscale with many participants whilst preserving the privacy of their datasets.\nStandard federated learning techniques are vulnerable to Byzantine failures,\nbiased local datasets, and poisoning attacks. In this paper we introduce\nAdaptive Federated Averaging, a novel algorithm for robust federated learning\nthat is designed to detect failures, attacks, and bad updates provided by\nparticipants in a collaborative model. We propose a Hidden Markov Model to\nmodel and learn the quality of model updates provided by each participant\nduring training. In contrast to existing robust federated learning schemes, we\npropose a robust aggregation rule that detects and discards bad or malicious\nlocal model updates at each training iteration. This includes a mechanism that\nblocks unwanted participants, which also increases the computational and\ncommunication efficiency. Our experimental evaluation on 4 real datasets show\nthat our algorithm is significantly more robust to faulty, noisy and malicious\nparticipants, whilst being computationally more efficient than other\nstate-of-the-art robust federated learning methods such as Multi-KRUM and\ncoordinate-wise median.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:19:36 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Co", "Kenneth T.", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1909.05142", "submitter": "Majnu John", "authors": "Sujit Vettam, Majnu John", "title": "Regularized deep learning with nonconvex penalties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization methods are often employed in deep learning neural networks\n(DNNs) to prevent overfitting. For penalty based DNN regularization methods,\nconvex penalties are typically considered because of their optimization\nguarantees. Recent theoretical work have shown that nonconvex penalties that\nsatisfy certain regularity conditions are also guaranteed to perform well with\nstandard optimization algorithms. In this paper, we examine new and currently\nexisting nonconvex penalties for DNN regularization. We provide theoretical\njustifications for the new penalties and also assess the performance of all\npenalties with DNN analyses of seven datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:32:44 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:48:42 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 18:24:15 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 19:56:37 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Vettam", "Sujit", ""], ["John", "Majnu", ""]]}, {"id": "1909.05167", "submitter": "Kacper Sokol", "authors": "Kacper Sokol, Raul Santos-Rodriguez, Peter Flach", "title": "FAT Forensics: A Python Toolbox for Algorithmic Fairness, Accountability\n  and Transparency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms can take important decisions, sometimes legally\nbinding, about our everyday life. In most cases, however, these systems and\ndecisions are neither regulated nor certified. Given the potential harm that\nthese algorithms can cause, qualities such as fairness, accountability and\ntransparency of predictive systems are of paramount importance. Recent\nliterature suggested voluntary self-reporting on these aspects of predictive\nsystems -- e.g., data sheets for data sets -- but their scope is often limited\nto a single component of a machine learning pipeline, and producing them\nrequires manual labour. To resolve this impasse and ensure high-quality, fair,\ntransparent and reliable machine learning systems, we developed an open source\ntoolbox that can inspect selected fairness, accountability and transparency\naspects of these systems to automatically and objectively report them back to\ntheir engineers and users. We describe design, scope and usage examples of this\nPython toolbox in this paper. The toolbox provides functionality for inspecting\nfairness, accountability and transparency of all aspects of the machine\nlearning process: data (and their features), models and predictions. It is\navailable to the public under the BSD 3-Clause open source licence.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:11:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Sokol", "Kacper", ""], ["Santos-Rodriguez", "Raul", ""], ["Flach", "Peter", ""]]}, {"id": "1909.05176", "submitter": "Ling Feng", "authors": "Ling Feng, Lin Zhang and Choy Heng Lai", "title": "Optimal Machine Intelligence at the Edge of Chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE nlin.AO nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been suggested that the biological brain operates at some\ncritical point between two different phases, possibly order and chaos. Despite\nmany indirect empirical evidence from the brain and analytical indication on\nsimple neural networks, the foundation of this hypothesis on generic non-linear\nsystems remains unclear. Here we develop a general theory that reveals the\nexact edge of chaos is the boundary between the chaotic phase and the\n(pseudo)periodic phase arising from Neimark-Sacker bifurcation. This edge is\nanalytically determined by the asymptotic Jacobian norm values of the\nnon-linear operator and influenced by the dimensionality of the system. The\noptimality at the edge of chaos is associated with the highest information\ntransfer between input and output at this point similar to that of the logistic\nmap. As empirical validations, our experiments on the various deep learning\nmodels in computer vision demonstrate the optimality of the models near the\nedge of chaos, and we observe that the state-of-art training algorithms push\nthe models towards such edge as they become more accurate. We further\nestablishes the theoretical understanding of deep learning model generalization\nthrough asymptotic stability.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:23:13 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 10:16:34 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Feng", "Ling", ""], ["Zhang", "Lin", ""], ["Lai", "Choy Heng", ""]]}, {"id": "1909.05207", "submitter": "Elad Hazan", "authors": "Elad Hazan", "title": "Introduction to Online Convex Optimization", "comments": "arXiv admin note: text overlap with arXiv:1909.03550", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript portrays optimization as a process. In many practical\napplications the environment is so complex that it is infeasible to lay out a\ncomprehensive theoretical model and use classical algorithmic theory and\nmathematical optimization. It is necessary as well as beneficial to take a\nrobust approach, by applying an optimization method that learns as one goes\nalong, learning from experience as more aspects of the problem are observed.\nThis view of optimization as a process has become prominent in varied fields\nand has led to some spectacular success in modeling and systems that are now\npart of our daily lives.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 19:06:23 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Hazan", "Elad", ""]]}, {"id": "1909.05215", "submitter": "Ellen Zhong", "authors": "Ellen D. Zhong, Tristan Bepler, Joseph H. Davis, Bonnie Berger", "title": "Reconstructing continuous distributions of 3D protein structure from\n  cryo-EM images", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryo-electron microscopy (cryo-EM) is a powerful technique for determining\nthe structure of proteins and other macromolecular complexes at near-atomic\nresolution. In single particle cryo-EM, the central problem is to reconstruct\nthe three-dimensional structure of a macromolecule from $10^{4-7}$ noisy and\nrandomly oriented two-dimensional projections. However, the imaged protein\ncomplexes may exhibit structural variability, which complicates reconstruction\nand is typically addressed using discrete clustering approaches that fail to\ncapture the full range of protein dynamics. Here, we introduce a novel method\nfor cryo-EM reconstruction that extends naturally to modeling continuous\ngenerative factors of structural heterogeneity. This method encodes structures\nin Fourier space using coordinate-based deep neural networks, and trains these\nnetworks from unlabeled 2D cryo-EM images by combining exact inference over\nimage orientation with variational inference for structural heterogeneity. We\ndemonstrate that the proposed method, termed cryoDRGN, can perform ab initio\nreconstruction of 3D protein complexes from simulated and real 2D cryo-EM image\ndata. To our knowledge, cryoDRGN is the first neural network-based approach for\ncryo-EM reconstruction and the first end-to-end method for directly\nreconstructing continuous ensembles of protein structures from cryo-EM images.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:13:06 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 23:45:23 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 04:31:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhong", "Ellen D.", ""], ["Bepler", "Tristan", ""], ["Davis", "Joseph H.", ""], ["Berger", "Bonnie", ""]]}, {"id": "1909.05229", "submitter": "Rui Zhang", "authors": "Alexander Shapiro, Yao Xie, Rui Zhang", "title": "Goodness-of-fit tests on manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general theory for the goodness-of-fit test to non-linear\nmodels. In particular, we assume that the observations are noisy samples of a\nsubmanifold defined by a \\yao{sufficiently smooth non-linear map}. The\nobservation noise is additive Gaussian. Our main result shows that the\n\"residual\" of the model fit, by solving a non-linear least-square problem,\nfollows a (possibly noncentral) $\\chi^2$ distribution. The parameters of the\n$\\chi^2$ distribution are related to the model order and dimension of the\nproblem. We further present a method to select the model orders sequentially.\nWe demonstrate the broad application of the general theory in machine learning\nand signal processing, including determining the rank of low-rank (possibly\ncomplex-valued) matrices and tensors from noisy, partial, or indirect\nobservations, determining the number of sources in signal demixing, and\npotential applications in determining the number of hidden nodes in neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:38:25 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 21:32:24 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shapiro", "Alexander", ""], ["Xie", "Yao", ""], ["Zhang", "Rui", ""]]}, {"id": "1909.05236", "submitter": "Thiago D. Sim\\~ao", "authors": "Thiago D. Sim\\~ao, Romain Laroche, R\\'emi Tachet des Combes", "title": "Safe Policy Improvement with an Estimated Baseline Policy", "comments": "Published at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous work has shown the unreliability of existing algorithms in the batch\nReinforcement Learning setting, and proposed the theoretically-grounded Safe\nPolicy Improvement with Baseline Bootstrapping (SPIBB) fix: reproduce the\nbaseline policy in the uncertain state-action pairs, in order to control the\nvariance on the trained policy performance. However, in many real-world\napplications such as dialogue systems, pharmaceutical tests or crop management,\ndata is collected under human supervision and the baseline remains unknown. In\nthis paper, we apply SPIBB algorithms with a baseline estimate built from the\ndata. We formally show safe policy improvement guarantees over the true\nbaseline even without direct access to it. Our empirical experiments on finite\nand continuous states tasks support the theoretical findings. It shows little\nloss of performance in comparison with SPIBB when the baseline policy is given,\nand more importantly, drastically and significantly outperforms competing\nalgorithms both in safe policy improvement, and in average performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:48:00 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 20:25:07 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sim\u00e3o", "Thiago D.", ""], ["Laroche", "Romain", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "1909.05244", "submitter": "Liyang Sun", "authors": "Rahul Singh and Liyang Sun", "title": "De-biased Machine Learning in Instrumental Variable Models for Treatment\n  Effects", "comments": "41 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a de-biased machine learning (DML) approach to estimating\ncomplier parameters with high-dimensional data. Complier parameters include\nlocal average treatment effect, average complier characteristics, and complier\ncounterfactual outcome distributions. In our approach, the de-biasing is itself\nperformed by machine learning, a variant called automatic de-biased machine\nlearning (Auto-DML). By regularizing the balancing weights, it does not require\nad hoc trimming or censoring. We prove our estimator is consistent,\nasymptotically normal, and semi-parametrically efficient. We use the new\napproach to estimate the effect of 401(k) participation on the distribution of\nnet financial assets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:08:54 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:41:14 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 05:06:29 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Singh", "Rahul", ""], ["Sun", "Liyang", ""]]}, {"id": "1909.05246", "submitter": "Mansour Saffar Mehrjardi", "authors": "Mansour Saffar Mehrjardi, Amine Trabelsi, Osmar R. Zaiane", "title": "Self-Attentional Models Application in Task-Oriented Dialogue Generation\n  Systems", "comments": "Appeared in proceedings of Recent Advances in Natural Language\n  Processing (RANLP) Conference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-attentional models are a new paradigm for sequence modelling tasks which\ndiffer from common sequence modelling methods, such as recurrence-based and\nconvolution-based sequence learning, in the way that their architecture is only\nbased on the attention mechanism. Self-attentional models have been used in the\ncreation of the state-of-the-art models in many NLP tasks such as neural\nmachine translation, but their usage has not been explored for the task of\ntraining end-to-end task-oriented dialogue generation systems yet. In this\nstudy, we apply these models on the three different datasets for training\ntask-oriented chatbots. Our finding shows that self-attentional models can be\nexploited to create end-to-end task-oriented chatbots which not only achieve\nhigher evaluation scores compared to recurrence-based models, but also do so\nmore efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:40:26 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Mehrjardi", "Mansour Saffar", ""], ["Trabelsi", "Amine", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "1909.05288", "submitter": "Shuyang Dai", "authors": "Shuyang Dai, Yu Cheng, Yizhe Zhang, Zhe Gan, Jingjing Liu, Lawrence\n  Carin", "title": "Contrastively Smoothed Class Alignment for Unsupervised Domain\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent unsupervised approaches to domain adaptation primarily focus on\nminimizing the gap between the source and the target domains through refining\nthe feature generator, in order to learn a better alignment between the two\ndomains. This minimization can be achieved via a domain classifier to detect\ntarget-domain features that are divergent from source-domain features. However,\nby optimizing via such domain classification discrepancy, ambiguous target\nsamples that are not smoothly distributed on the low-dimensional data manifold\nare often missed. To solve this issue, we propose a novel Contrastively\nSmoothed Class Alignment (CoSCA) model, that explicitly incorporates both\nintra- and inter-class domain discrepancy to better align ambiguous target\nsamples with the source domain. CoSCA estimates the underlying label hypothesis\nof target samples, and simultaneously adapts their feature representations by\noptimizing a proposed contrastive loss. In addition, Maximum Mean Discrepancy\n(MMD) is utilized to directly match features between source and target samples\nfor better global alignment. Experiments on several benchmark datasets\ndemonstrate that CoSCA can outperform state-of-the-art approaches for\nunsupervised domain adaptation by producing more discriminative features.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:32:00 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 18:30:08 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 19:29:52 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 21:09:02 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Dai", "Shuyang", ""], ["Cheng", "Yu", ""], ["Zhang", "Yizhe", ""], ["Gan", "Zhe", ""], ["Liu", "Jingjing", ""], ["Carin", "Lawrence", ""]]}, {"id": "1909.05289", "submitter": "Baptiste Barreau", "authors": "Baptiste Barreau, Laurent Carlier, Damien Challet", "title": "Deep Prediction of Investor Interest: a Supervised Clustering Approach", "comments": null, "journal-ref": "Algorithmic Finance, vol. 8, no. 3-4, pp. 77-89, 2020", "doi": "10.3233/AF-200296", "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep learning architecture suitable for the prediction of\ninvestor interest for a given asset in a given time frame. This architecture\nperforms both investor clustering and modelling at the same time. We first\nverify its superior performance on a synthetic scenario inspired by real data\nand then apply it to two real-world databases, a publicly available dataset\nabout the position of investors in Spanish stock market and proprietary data\nfrom BNP Paribas Corporate and Institutional Banking.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:32:06 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 06:56:22 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 13:28:01 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Barreau", "Baptiste", ""], ["Carlier", "Laurent", ""], ["Challet", "Damien", ""]]}, {"id": "1909.05299", "submitter": "Yuta Saito", "authors": "Yuta Saito, Shota Yasui", "title": "Counterfactual Cross-Validation: Stable Model Selection Procedure for\n  Causal Inference Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the model selection problem in conditional average treatment effect\n(CATE) prediction. Unlike previous works on this topic, we focus on preserving\nthe rank order of the performance of candidate CATE predictors to enable\naccurate and stable model selection. To this end, we analyze the model\nperformance ranking problem and formulate guidelines to obtain a better\nevaluation metric. We then propose a novel metric that can identify the ranking\nof the performance of CATE predictors with high confidence. Empirical\nevaluations demonstrate that our metric outperforms existing metrics in both\nmodel selection and hyperparameter tuning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:43:32 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 07:11:53 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 01:58:25 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 21:27:48 GMT"}, {"version": "v5", "created": "Thu, 16 Jul 2020 23:41:00 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Saito", "Yuta", ""], ["Yasui", "Shota", ""]]}, {"id": "1909.05304", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Yiannis Kantaros, Alessandro Abate, Daniel\n  Kroening, George J. Pappas, Insup Lee", "title": "Reinforcement Learning for Temporal Logic Control Synthesis with\n  Probabilistic Satisfaction Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has emerged as an efficient method of choice for\nsolving complex sequential decision making problems in automatic control,\ncomputer science, economics, and biology. In this paper we present a model-free\nRL algorithm to synthesize control policies that maximize the probability of\nsatisfying high-level control objectives given as Linear Temporal Logic (LTL)\nformulas. Uncertainty is considered in the workspace properties, the structure\nof the workspace, and the agent actions, giving rise to a\nProbabilistically-Labeled Markov Decision Process (PL-MDP) with unknown graph\nstructure and stochastic behaviour, which is even more general case than a\nfully unknown MDP. We first translate the LTL specification into a Limit\nDeterministic Buchi Automaton (LDBA), which is then used in an on-the-fly\nproduct with the PL-MDP. Thereafter, we define a synchronous reward function\nbased on the acceptance condition of the LDBA. Finally, we show that the RL\nalgorithm delivers a policy that maximizes the satisfaction probability\nasymptotically. We provide experimental results that showcase the efficiency of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:48:02 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Kantaros", "Yiannis", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""], ["Pappas", "George J.", ""], ["Lee", "Insup", ""]]}, {"id": "1909.05310", "submitter": "Tomasz Danel", "authors": "Tomasz Danel, Przemys{\\l}aw Spurek, Jacek Tabor, Marek \\'Smieja,\n  {\\L}ukasz Struski, Agnieszka S{\\l}owik, {\\L}ukasz Maziarka", "title": "Spatial Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have recently become the primary choice\nfor learning from graph-structured data, superseding hash fingerprints in\nrepresenting chemical compounds. However, GCNs lack the ability to take into\naccount the ordering of node neighbors, even when there is a geometric\ninterpretation of the graph vertices that provides an order based on their\nspatial positions. To remedy this issue, we propose Spatial Graph Convolutional\nNetwork (SGCN) which uses spatial features to efficiently learn from graphs\nthat can be naturally located in space. Our contribution is threefold: we\npropose a GCN-inspired architecture which (i) leverages node positions, (ii) is\na proper generalization of both GCNs and Convolutional Neural Networks (CNNs),\n(iii) benefits from augmentation which further improves the performance and\nassures invariance with respect to the desired properties. Empirically, SGCN\noutperforms state-of-the-art graph-based methods on image classification and\nchemical tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:59:41 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 14:29:14 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Danel", "Tomasz", ""], ["Spurek", "Przemys\u0142aw", ""], ["Tabor", "Jacek", ""], ["\u015amieja", "Marek", ""], ["Struski", "\u0141ukasz", ""], ["S\u0142owik", "Agnieszka", ""], ["Maziarka", "\u0141ukasz", ""]]}, {"id": "1909.05314", "submitter": "Xueyuan She", "authors": "Xueyuan She, Yun Long, Daehyun Kim, Saibal Mukhopadhyay", "title": "ScieNet: Deep Learning with Spike-assisted Contextual Information\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) provide high image classification accuracy, but\nexperience significant performance degradation when perturbation from various\nsources are present in the input. The lack of resilience to input perturbations\nmakes DNN less reliable for systems interacting with physical world such as\nautonomous vehicles, robotics, to name a few, where imperfect input is the\nnormal condition. We present a hybrid deep network architecture with\nspike-assisted contextual information extraction (ScieNet). ScieNet integrates\nunsupervised learning using spiking neural network (SNN) for unsupervised\ncontextual informationextraction with a back-end DNN trained for\nclassification. The integrated network demonstrates high resilience to input\nperturbations without relying on prior training on perturbed inputs. We\ndemonstrate ScieNet with different back-end DNNs for image classification using\nCIFAR dataset considering stochastic (noise) and structured (rain) input\nperturbations. Experimental results demonstrate significant improvement in\naccuracy on noisy and rainy images without prior training, while maintaining\nstate-of-the-art accuracy on clean images.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 19:10:07 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["She", "Xueyuan", ""], ["Long", "Yun", ""], ["Kim", "Daehyun", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "1909.05330", "submitter": "Arindrima Datta", "authors": "Anjuli Kannan, Arindrima Datta, Tara N. Sainath, Eugene Weinstein,\n  Bhuvana Ramabhadran, Yonghui Wu, Ankur Bapna, Zhifeng Chen, Seungji Lee", "title": "Large-Scale Multilingual Speech Recognition with a Streaming End-to-End\n  Model", "comments": "Accepted in Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual end-to-end (E2E) models have shown great promise in expansion of\nautomatic speech recognition (ASR) coverage of the world's languages. They have\nshown improvement over monolingual systems, and have simplified training and\nserving by eliminating language-specific acoustic, pronunciation, and language\nmodels. This work presents an E2E multilingual system which is equipped to\noperate in low-latency interactive applications, as well as handle a key\nchallenge of real world data: the imbalance in training data across languages.\nUsing nine Indic languages, we compare a variety of techniques, and find that a\ncombination of conditioning on a language vector and training language-specific\nadapter layers produces the best model. The resulting E2E multilingual model\nachieves a lower word error rate (WER) than both monolingual E2E models (eight\nof nine languages) and monolingual conventional systems (all nine languages).\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 19:46:21 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Kannan", "Anjuli", ""], ["Datta", "Arindrima", ""], ["Sainath", "Tara N.", ""], ["Weinstein", "Eugene", ""], ["Ramabhadran", "Bhuvana", ""], ["Wu", "Yonghui", ""], ["Bapna", "Ankur", ""], ["Chen", "Zhifeng", ""], ["Lee", "Seungji", ""]]}, {"id": "1909.05350", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich, Sai Praneeth Karimireddy", "title": "The Error-Feedback Framework: Better Rates for SGD with Delayed\n  Gradients and Compressed Communication", "comments": "Submitted 9/19, Published 9/20", "journal-ref": "Journal of Machine Learning Research (JMLR), 21(237):1-36, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze (stochastic) gradient descent (SGD) with delayed updates on smooth\nquasi-convex and non-convex functions and derive concise, non-asymptotic,\nconvergence rates. We show that the rate of convergence in all cases consists\nof two terms: (i) a stochastic term which is not affected by the delay, and\n(ii) a higher order deterministic term which is only linearly slowed down by\nthe delay. Thus, in the presence of noise, the effects of the delay become\nnegligible after a few iterations and the algorithm converges at the same\noptimal rate as standard SGD. This result extends a line of research that\nshowed similar results in the asymptotic regime or for strongly-convex\nquadratic functions only. We further show similar results for SGD with more\nintricate form of delayed gradients -- compressed gradients under error\ncompensation and for local~SGD where multiple workers perform local steps\nbefore communicating with each other. In all of these settings, we improve upon\nthe best known rates. These results show that SGD is robust to compressed\nand/or delayed stochastic gradient updates. This is in particular important for\ndistributed parallel implementations, where asynchronous and communication\nefficient methods are the key to achieve linear speedups for optimization with\nmultiple devices.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 20:54:49 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 15:44:47 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Stich", "Sebastian U.", ""], ["Karimireddy", "Sai Praneeth", ""]]}, {"id": "1909.05352", "submitter": "Junfeng Wen", "authors": "Junfeng Wen, Russell Greiner, Dale Schuurmans", "title": "Domain Aggregation Networks for Multi-Source Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, we want to exploit multiple source datasets\nof similar tasks to learn a model for a different but related target dataset --\ne.g., recognizing characters of a new font using a set of different fonts.\nWhile most recent research has considered ad-hoc combination rules to address\nthis problem, we extend previous work on domain discrepancy minimization to\ndevelop a finite-sample generalization bound, and accordingly propose a\ntheoretically justified optimization procedure. The algorithm we develop,\nDomain AggRegation Network (DARN), is able to effectively adjust the weight of\neach source domain during training to ensure relevant domains are given more\nimportance for adaptation. We evaluate the proposed method on real-world\nsentiment analysis and digit recognition datasets and show that DARN can\nsignificantly outperform the state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 21:02:40 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 07:15:37 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wen", "Junfeng", ""], ["Greiner", "Russell", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1909.05356", "submitter": "Alankar Jain", "authors": "Alankar Jain, Bhargavi Paranjape, Zachary C. Lipton", "title": "Entity Projection via Machine Translation for Cross-Lingual NER", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although over 100 languages are supported by strong off-the-shelf machine\ntranslation systems, only a subset of them possess large annotated corpora for\nnamed entity recognition. Motivated by this fact, we leverage machine\ntranslation to improve annotation-projection approaches to cross-lingual named\nentity recognition. We propose a system that improves over prior\nentity-projection methods by: (a) leveraging machine translation systems twice:\nfirst for translating sentences and subsequently for translating entities; (b)\nmatching entities based on orthographic and phonetic similarity; and (c)\nidentifying matches based on distributional statistics derived from the\ndataset. Our approach improves upon current state-of-the-art methods for\ncross-lingual named entity recognition on 5 diverse languages by an average of\n4.1 points. Further, our method achieves state-of-the-art F_1 scores for\nArmenian, outperforming even a monolingual model trained on Armenian source\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 17:40:21 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 06:44:24 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Jain", "Alankar", ""], ["Paranjape", "Bhargavi", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1909.05357", "submitter": "Ming Tan", "authors": "Ming Tan, Yang Yu, Haoyu Wang, Dakuo Wang, Saloni Potdar, Shiyu Chang,\n  Mo Yu", "title": "Out-of-Domain Detection for Low-Resource Text Classification Tasks", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-domain (OOD) detection for low-resource text classification is a\nrealistic but understudied task. The goal is to detect the OOD cases with\nlimited in-domain (ID) training data, since we observe that training data is\noften insufficient in machine learning applications. In this work, we propose\nan OOD-resistant Prototypical Network to tackle this zero-shot OOD detection\nand few-shot ID classification task. Evaluation on real-world datasets show\nthat the proposed solution outperforms state-of-the-art methods in zero-shot\nOOD detection task, while maintaining a competitive performance on ID\nclassification task.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 20:23:26 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Tan", "Ming", ""], ["Yu", "Yang", ""], ["Wang", "Haoyu", ""], ["Wang", "Dakuo", ""], ["Potdar", "Saloni", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""]]}, {"id": "1909.05362", "submitter": "Mayank Sharma", "authors": "Prabhakar Gupta, Mayank Sharma, Kartik Pitale, Keshav Kumar", "title": "Problems with automating translation of movie/TV show subtitles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present 27 problems encountered in automating the translation of movie/TV\nshow subtitles. We categorize each problem in one of the three categories viz.\nproblems directly related to textual translation, problems related to subtitle\ncreation guidelines, and problems due to adaptability of machine translation\n(MT) engines. We also present the findings of a translation quality evaluation\nexperiment where we share the frequency of 16 key problems. We show that the\nsystems working at the frontiers of Natural Language Processing do not perform\nwell for subtitles and require some post-processing solutions for redressal of\nthese problems\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:45:51 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Gupta", "Prabhakar", ""], ["Sharma", "Mayank", ""], ["Pitale", "Kartik", ""], ["Kumar", "Keshav", ""]]}, {"id": "1909.05367", "submitter": "Giuseppe Marra", "authors": "Marco Maggini, Giuseppe Marra, Stefano Melacci, Andrea Zugarini", "title": "Learning in Text Streams: Discovery and Disambiguation of Entity and\n  Relation Instances", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2955597", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scenario where an artificial agent is reading a stream of text\ncomposed of a set of narrations, and it is informed about the identity of some\nof the individuals that are mentioned in the text portion that is currently\nbeing read. The agent is expected to learn to follow the narrations, thus\ndisambiguating mentions and discovering new individuals. We focus on the case\nin which individuals are entities and relations, and we propose an end-to-end\ntrainable memory network that learns to discover and disambiguate them in an\nonline manner, performing one-shot learning, and dealing with a small number of\nsparse supervisions. Our system builds a not-given-in-advance knowledge base,\nand it improves its skills while reading unsupervised text. The model deals\nwith abrupt changes in the narration, taking into account their effects when\nresolving co-references. We showcase the strong disambiguation and discovery\nskills of our model on a corpus of Wikipedia documents and on a newly\nintroduced dataset, that we make publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:01:07 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:55:41 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 18:07:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Maggini", "Marco", ""], ["Marra", "Giuseppe", ""], ["Melacci", "Stefano", ""], ["Zugarini", "Andrea", ""]]}, {"id": "1909.05370", "submitter": "Yun Zhao", "authors": "Yun Zhao", "title": "An Auxiliary Classifier Generative Adversarial Framework for Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction models suffer from limited qualified training data. Using\nhuman annotators to label sentences is too expensive and does not scale well\nespecially when dealing with large datasets. In this paper, we use Auxiliary\nClassifier Generative Adversarial Networks (AC-GANs) to generate high-quality\nrelational sentences and to improve the performance of relation classifier in\nend-to-end models. In AC-GAN, the discriminator gives not only a probability\ndistribution over the real source, but also a probability distribution over the\nrelation labels. This helps to generate meaningful relational sentences.\nExperimental results show that our proposed data augmentation method\nsignificantly improves the performance of relation extraction compared to\nstate-of-the-art methods\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:24:51 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zhao", "Yun", ""]]}, {"id": "1909.05371", "submitter": "Paul Atzberger", "authors": "Nathaniel Trask, Ravi G.Patel, Ben J. Gross, Paul J. Atzberger", "title": "GMLS-Nets: A framework for learning from unstructured data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data fields sampled on irregularly spaced points arise in many applications\nin the sciences and engineering. For regular grids, Convolutional Neural\nNetworks (CNNs) have been successfully used to gaining benefits from weight\nsharing and invariances. We generalize CNNs by introducing methods for data on\nunstructured point clouds based on Generalized Moving Least Squares (GMLS).\nGMLS is a non-parametric technique for estimating linear bounded functionals\nfrom scattered data, and has recently been used in the literature for solving\npartial differential equations. By parameterizing the GMLS estimator, we obtain\nlearning methods for operators with unstructured stencils. In GMLS-Nets the\nnecessary calculations are local, readily parallelizable, and the estimator is\nsupported by a rigorous approximation theory. We show how the framework may be\nused for unstructured physical data sets to perform functional regression to\nidentify associated differential operators and to regress quantities of\ninterest. The results suggest the architectures to be an attractive foundation\nfor data-driven model development in scientific machine learning applications.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 01:07:33 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 18:39:29 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Trask", "Nathaniel", ""], ["Patel", "Ravi G.", ""], ["Gross", "Ben J.", ""], ["Atzberger", "Paul J.", ""]]}, {"id": "1909.05388", "submitter": "Dong Wang", "authors": "Yang Zhang, Daniel Zhang, Nathan Vance, Dong Wang", "title": "An Online Reinforcement Learning Approach to Quality-Cost-Aware Task\n  Allocation for Multi-Attribute Social Sensing", "comments": "The paper has been accepted to Elsevier Pervasive and Mobile\n  Computing (PMC) in September 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social sensing has emerged as a new sensing paradigm where humans (or devices\non their behalf) collectively report measurements about the physical world.\nThis paper focuses on a quality-cost-aware task allocation problem in\nmulti-attribute social sensing applications. The goal is to identify a task\nallocation strategy (i.e., decide when and where to collect sensing data) to\nachieve an optimized tradeoff between the data quality and the sensing cost.\nWhile recent progress has been made to tackle similar problems, three important\nchallenges have not been well addressed: (i) \"online task allocation\": the task\nallocation schemes need to respond quickly to the potentially large dynamics of\nthe measured variables in social sensing; (ii) \"multi-attribute constrained\noptimization\": minimizing the overall sensing error given the dependencies and\nconstraints of multiple attributes of the measured variables is a non-trivial\nproblem to solve; (iii) \"nonuniform task allocation cost\": the task allocation\ncost in social sensing often has a nonuniform distribution which adds\nadditional complexity to the optimized task allocation problem. This paper\ndevelops a Quality-Cost-Aware Online Task Allocation (QCO-TA) scheme to address\nthe above challenges using a principled online reinforcement learning\nframework. We evaluate the QCO-TA scheme through a real-world social sensing\napplication and the results show that our scheme significantly outperforms the\nstate-of-the-art baselines in terms of both sensing accuracy and cost.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 21:56:33 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zhang", "Yang", ""], ["Zhang", "Daniel", ""], ["Vance", "Nathan", ""], ["Wang", "Dong", ""]]}, {"id": "1909.05414", "submitter": "Mei Wang", "authors": "Mei Wang, Weizhi Li, Yan Yan", "title": "Time-weighted Attentional Session-Aware Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Session-based Recurrent Neural Networks (RNNs) are gaining increasing\npopularity for recommendation task, due to the high autocorrelation of user's\nbehavior on the latest session and the effectiveness of RNN to capture the\nsequence order information. However, most existing session-based RNN\nrecommender systems still solely focus on the short-term interactions within a\nsingle session and completely discard all the other long-term data across\ndifferent sessions. While traditional Collaborative Filtering (CF) methods have\nmany advanced research works on exploring long-term dependency, which show\ngreat value to be explored and exploited in deep learning models. Therefore, in\nthis paper, we propose ASARS, a novel framework that effectively imports the\ntemporal dynamics methodology in CF into session-based RNN system in DL, such\nthat the temporal info can act as scalable weights by a parallel attentional\nnetwork. Specifically, we first conduct an extensive data analysis to show the\ndistribution and importance of such temporal interactions data both within\nsessions and across sessions. And then, our ASARS framework promotes two novel\nmodels: (1) an inter-session temporal dynamic model that captures the long-term\nuser interaction for RNN recommender system. We integrate the time changes in\nsession RNN and add user preferences as model drifting; and (2) a novel\ntriangle parallel attention network that enhances the original RNN model by\nincorporating time information. Such triangle parallel network is also\nspecially designed for realizing data argumentation in sequence-to-scalar RNN\narchitecture, and thus it can be trained very efficiently. Our extensive\nexperiments on four real datasets from different domains demonstrate the\neffectiveness and large improvement of ASARS for personalized recommendation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 00:31:23 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Wang", "Mei", ""], ["Li", "Weizhi", ""], ["Yan", "Yan", ""]]}, {"id": "1909.05433", "submitter": "Matteo Sesia", "authors": "Matteo Sesia, Emmanuel J. Cand\\`es", "title": "A comparison of some conformal quantile regression methods", "comments": "20 pages, 9 figures, 3 tables", "journal-ref": "Stat. 2020; 9:e261", "doi": "10.1002/sta4.261", "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare two recently proposed methods that combine ideas from conformal\ninference and quantile regression to produce locally adaptive and marginally\nvalid prediction intervals under sample exchangeability (Romano et al., 2019;\nKivaranovic et al., 2019). First, we prove that these two approaches are\nasymptotically efficient in large samples, under some additional assumptions.\nThen we compare them empirically on simulated and real data. Our results\ndemonstrate that the method in Romano et al. (2019) typically yields tighter\nprediction intervals in finite samples. Finally, we discuss how to tune these\nprocedures by fixing the relative proportions of observations used for training\nand conformalization.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 01:48:11 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Sesia", "Matteo", ""], ["Cand\u00e8s", "Emmanuel J.", ""]]}, {"id": "1909.05443", "submitter": "Chang Song", "authors": "Chang Song, Zuoguan Wang, Hai Li", "title": "Feedback Learning for Improving the Robustness of Neural Networks", "comments": "Accepted by ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research studies revealed that neural networks are vulnerable to\nadversarial attacks. State-of-the-art defensive techniques add various\nadversarial examples in training to improve models' adversarial robustness.\nHowever, these methods are not universal and can't defend unknown or\nnon-adversarial evasion attacks. In this paper, we analyze the model robustness\nin the decision space. A feedback learning method is then proposed, to\nunderstand how well a model learns and to facilitate the retraining process of\nremedying the defects. The evaluations according to a set of distance-based\ncriteria show that our method can significantly improve models' accuracy and\nrobustness against different types of evasion attacks. Moreover, we observe the\nexistence of inter-class inequality and propose to compensate it by changing\nthe proportions of examples generated in different classes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 03:50:28 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Song", "Chang", ""], ["Wang", "Zuoguan", ""], ["Li", "Hai", ""]]}, {"id": "1909.05447", "submitter": "Mohammad Pirhooshyaran", "authors": "Mohammad Pirhooshyaran, Katya Scheinberg, Lawrence V. Snyder", "title": "Feature Engineering and Forecasting via Derivative-free Optimization and\n  Ensemble of Sequence-to-sequence Networks with Applications in Renewable\n  Energy", "comments": null, "journal-ref": null, "doi": "10.1016/j.energy.2020.117136", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study introduces a framework for the forecasting, reconstruction and\nfeature engineering of multivariate processes along with its renewable energy\napplications. We integrate derivative-free optimization with an ensemble of\nsequence-to-sequence networks and design a new resampling technique called\nadditive resampling, which, along with Bootstrap aggregating (bagging)\nresampling, are applied to initialize the ensemble structure. Moreover, we\nexplore the proposed framework performance on three renewable energy\nsources---wind, solar and ocean wave---and conduct several short- to long-term\nforecasts showing the superiority of the proposed method compared to numerous\nmachine learning techniques. The findings indicate that the introduced method\nperforms more accurately when the forecasting horizon becomes longer. In\naddition, we modify the framework for automated feature selection. The model\nrepresents a clear interpretation of the selected features. Furthermore, we\ninvestigate the effects of different environmental and marine factors on the\nwind speed and ocean output power, respectively, and report the selected\nfeatures. Finally, we explore the online forecasting setting and illustrate\nthat the model outperforms alternatives through different measurement errors.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 04:14:25 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 00:49:53 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 02:52:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Pirhooshyaran", "Mohammad", ""], ["Scheinberg", "Katya", ""], ["Snyder", "Lawrence V.", ""]]}, {"id": "1909.05477", "submitter": "Dexter Scobee", "authors": "Dexter R.R. Scobee and S. Shankar Sastry", "title": "Maximum Likelihood Constraint Inference for Inverse Reinforcement\n  Learning", "comments": "Published as a conference paper at the International Conference on\n  Learning Representations (ICLR), 2020 (at\n  https://openreview.net/forum?id=BJliakStvH )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most approaches to the problem of Inverse Reinforcement Learning (IRL)\nfocus on estimating a reward function that best explains an expert agent's\npolicy or demonstrated behavior on a control task, it is often the case that\nsuch behavior is more succinctly represented by a simple reward combined with a\nset of hard constraints. In this setting, the agent is attempting to maximize\ncumulative rewards subject to these given constraints on their behavior. We\nreformulate the problem of IRL on Markov Decision Processes (MDPs) such that,\ngiven a nominal model of the environment and a nominal reward function, we seek\nto estimate state, action, and feature constraints in the environment that\nmotivate an agent's behavior. Our approach is based on the Maximum Entropy IRL\nframework, which allows us to reason about the likelihood of an expert agent's\ndemonstrations given our knowledge of an MDP. Using our method, we can infer\nwhich constraints can be added to the MDP to most increase the likelihood of\nobserving these demonstrations. We present an algorithm which iteratively\ninfers the Maximum Likelihood Constraint to best explain observed behavior, and\nwe evaluate its efficacy using both simulated behavior and recorded data of\nhumans navigating around an obstacle.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 06:38:46 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 00:13:16 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Scobee", "Dexter R. R.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1909.05479", "submitter": "Vishnu Suresh Lokhande", "authors": "Vishnu Suresh Lokhande, Songwong Tasneeyapant, Abhay Venkatesh, Sathya\n  N. Ravi and Vikas Singh", "title": "Generating Accurate Pseudo-labels in Semi-Supervised Learning and\n  Avoiding Overconfident Predictions via Hermite Polynomial Activations", "comments": "Accepted at 2020 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rectified Linear Units (ReLUs) are among the most widely used activation\nfunction in a broad variety of tasks in vision. Recent theoretical results\nsuggest that despite their excellent practical performance, in various cases, a\nsubstitution with basis expansions (e.g., polynomials) can yield significant\nbenefits from both the optimization and generalization perspective.\nUnfortunately, the existing results remain limited to networks with a couple of\nlayers, and the practical viability of these results is not yet known.\nMotivated by some of these results, we explore the use of Hermite polynomial\nexpansions as a substitute for ReLUs in deep networks. While our experiments\nwith supervised learning do not provide a clear verdict, we find that this\nstrategy offers considerable benefits in semi-supervised learning (SSL) /\ntransductive learning settings. We carefully develop this idea and show how the\nuse of Hermite polynomials based activations can yield improvements in\npseudo-label accuracies and sizable financial savings (due to concurrent\nruntime benefits). Further, we show via theoretical analysis, that the networks\n(with Hermite activations) offer robustness to noise and other attractive\nmathematical properties.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 06:42:08 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 06:01:54 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Lokhande", "Vishnu Suresh", ""], ["Tasneeyapant", "Songwong", ""], ["Venkatesh", "Abhay", ""], ["Ravi", "Sathya N.", ""], ["Singh", "Vikas", ""]]}, {"id": "1909.05494", "submitter": "Faicel Chamroukhi", "authors": "Fa\u007f\\\"icel Chamroukhi, Florian Lecocq, and Hien D. Nguyen", "title": "Regularized Estimation and Feature Selection in Mixtures of\n  Gaussian-Gated Experts Models", "comments": "Research School on Statistics and Data Science - RSSDS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures-of-Experts models and their maximum likelihood estimation (MLE) via\nthe EM algorithm have been thoroughly studied in the statistics and machine\nlearning literature. They are subject of a growing investigation in the context\nof modeling with high-dimensional predictors with regularized MLE. We examine\nMoE with Gaussian gating network, for clustering and regression, and propose an\n$\\ell_1$-regularized MLE to encourage sparse models and deal with the\nhigh-dimensional setting. We develop an EM-Lasso algorithm to perform parameter\nestimation and utilize a BIC-like criterion to select the model parameters,\nincluding the sparsity tuning hyperparameters. Experiments conducted on\nsimulated data show the good performance of the proposed regularized MLE\ncompared to the standard MLE with the EM algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 07:56:27 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chamroukhi", "Fa\u007f\u00efcel", ""], ["Lecocq", "Florian", ""], ["Nguyen", "Hien D.", ""]]}, {"id": "1909.05501", "submitter": "G\\'abor Petneh\\'azi", "authors": "G\\'abor Petneh\\'azi and J\\'ozsef G\\'all", "title": "Mortality rate forecasting: can recurrent neural networks beat the\n  Lee-Carter model?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article applies a long short-term memory recurrent neural network to\nmortality rate forecasting. The model can be trained jointly on the mortality\nrate history of different countries, ages, and sexes. The RNN-based method\nseems to outperform the popular Lee-Carter model.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:22:56 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 06:55:55 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Petneh\u00e1zi", "G\u00e1bor", ""], ["G\u00e1ll", "J\u00f3zsef", ""]]}, {"id": "1909.05503", "submitter": "Ruoqi Shen", "authors": "Ruoqi Shen, Yin Tat Lee", "title": "The Randomized Midpoint Method for Log-Concave Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling from log-concave distributions is a well researched problem that has\nmany applications in statistics and machine learning. We study the\ndistributions of the form $p^{*}\\propto\\exp(-f(x))$, where\n$f:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ has an $L$-Lipschitz gradient and is\n$m$-strongly convex. In our paper, we propose a Markov chain Monte Carlo (MCMC)\nalgorithm based on the underdamped Langevin diffusion (ULD). It can achieve\n$\\epsilon\\cdot D$ error (in 2-Wasserstein distance) in\n$\\tilde{O}\\left(\\kappa^{7/6}/\\epsilon^{1/3}+\\kappa/\\epsilon^{2/3}\\right)$\nsteps, where $D\\overset{\\mathrm{def}}{=}\\sqrt{\\frac{d}{m}}$ is the effective\ndiameter of the problem and $\\kappa\\overset{\\mathrm{def}}{=}\\frac{L}{m}$ is the\ncondition number. Our algorithm performs significantly faster than the\npreviously best known algorithm for solving this problem, which requires\n$\\tilde{O}\\left(\\kappa^{1.5}/\\epsilon\\right)$ steps. Moreover, our algorithm\ncan be easily parallelized to require only $O(\\kappa\\log\\frac{1}{\\epsilon})$\nparallel steps.\n  To solve the sampling problem, we propose a new framework to discretize\nstochastic differential equations. We apply this framework to discretize and\nsimulate ULD, which converges to the target distribution $p^{*}$. The framework\ncan be used to solve not only the log-concave sampling problem, but any problem\nthat involves simulating (stochastic) differential equations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:32:39 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Shen", "Ruoqi", ""], ["Lee", "Yin Tat", ""]]}, {"id": "1909.05504", "submitter": "Christoph Stanik", "authors": "Christoph Stanik, Marlo Haering and Walid Maalej", "title": "Classifying Multilingual User Feedback using Traditional Machine\n  Learning and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of social media like Twitter and of software distribution\nplatforms like app stores, users got various ways to express their opinion\nabout software products. Popular software vendors get user feedback\nthousandfold per day. Research has shown that such feedback contains valuable\ninformation for software development teams such as problem reports or feature\nand support inquires. Since the manual analysis of user feedback is cumbersome\nand hard to manage many researchers and tool vendors suggested to use automated\nanalyses based on traditional supervised machine learning approaches. In this\nwork, we compare the results of traditional machine learning and deep learning\nin classifying user feedback in English and Italian into problem reports,\ninquiries, and irrelevant. Our results show that using traditional machine\nlearning, we can still achieve comparable results to deep learning, although we\ncollected thousands of labels.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:35:54 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Stanik", "Christoph", ""], ["Haering", "Marlo", ""], ["Maalej", "Walid", ""]]}, {"id": "1909.05527", "submitter": "J\\\"org Martin", "authors": "J\\\"org Martin, Clemens Elster", "title": "Inspecting adversarial examples using the Fisher information", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are slight perturbations that are designed to fool\nartificial neural networks when fed as an input. In this work the usability of\nthe Fisher information for the detection of such adversarial attacks is\nstudied. We discuss various quantities whose computation scales well with the\nnetwork size, study their behavior on adversarial examples and show how they\ncan highlight the importance of single input neurons, thereby providing a\nvisual tool for further analyzing (un-)reasonable behavior of a neural network.\nThe potential of our methods is demonstrated by applications to the MNIST,\nCIFAR10 and Fruits-360 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 09:26:30 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Martin", "J\u00f6rg", ""], ["Elster", "Clemens", ""]]}, {"id": "1909.05557", "submitter": "Yutian Chen", "authors": "Yutian Chen, Abram L. Friesen, Feryal Behbahani, Arnaud Doucet, David\n  Budden, Matthew W. Hoffman, Nando de Freitas", "title": "Modular Meta-Learning with Shrinkage", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems, including multi-speaker text-to-speech synthesis,\ncan greatly benefit from the ability to meta-learn large models with only a few\ntask-specific components. Updating only these task-specific modules then allows\nthe model to be adapted to low-data tasks for as many steps as necessary\nwithout risking overfitting. Unfortunately, existing meta-learning methods\neither do not scale to long adaptation or else rely on handcrafted\ntask-specific architectures. Here, we propose a meta-learning approach that\nobviates the need for this often sub-optimal hand-selection. In particular, we\ndevelop general techniques based on Bayesian shrinkage to automatically\ndiscover and learn both task-specific and general reusable modules.\nEmpirically, we demonstrate that our method discovers a small set of meaningful\ntask-specific modules and outperforms existing meta-learning approaches in\ndomains like few-shot text-to-speech that have little task data and long\nadaptation horizons. We also show that existing meta-learning methods including\nMAML, iMAML, and Reptile emerge as special cases of our method.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 10:40:13 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 11:08:35 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 20:37:23 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 16:45:20 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chen", "Yutian", ""], ["Friesen", "Abram L.", ""], ["Behbahani", "Feryal", ""], ["Doucet", "Arnaud", ""], ["Budden", "David", ""], ["Hoffman", "Matthew W.", ""], ["de Freitas", "Nando", ""]]}, {"id": "1909.05580", "submitter": "Yannik Potdevin", "authors": "Yannik Potdevin, Dirk Nowotka and Vijay Ganesh", "title": "An Empirical Investigation of Randomized Defenses against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Neural Networks (DNNs) have had a dramatic impact on a\nvariety of problems that were long considered very difficult, e. g., image\nclassification and automatic language translation to name just a few. The\naccuracy of modern DNNs in classification tasks is remarkable indeed. At the\nsame time, attackers have devised powerful methods to construct\nspecially-crafted malicious inputs (often referred to as adversarial examples)\nthat can trick DNNs into mis-classifying them. What is worse is that despite\nthe many defense mechanisms proposed to protect DNNs against adversarial\nattacks, attackers are often able to circumvent these defenses, rendering them\nuseless. This state of affairs is extremely worrying, especially since machine\nlearning systems get adopted at scale.\n  In this paper, we propose a scientific evaluation methodology aimed at\nassessing the quality, efficacy, robustness and efficiency of randomized\ndefenses to protect DNNs against adversarial examples. Using this methodology,\nwe evaluate a variety of defense mechanisms. In addition, we also propose a\ndefense mechanism we call Randomly Perturbed Ensemble Neural Networks (RPENNs).\nWe provide a thorough and comprehensive evaluation of the considered defense\nmechanisms against a white-box attacker model, six different adversarial attack\nmethods and using the ILSVRC2012 validation data set.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 11:44:33 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Potdevin", "Yannik", ""], ["Nowotka", "Dirk", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1909.05622", "submitter": "Matin Hosseini", "authors": "Matin Hosseini, Anthony S. Maida, Majid Hosseini, Gottumukkala Raju", "title": "Inception-inspired LSTM for Next-frame Video Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of video frame prediction has received much interest due to its\nrelevance to many computer vision applications such as autonomous vehicles or\nrobotics. Supervised methods for video frame prediction rely on labeled data,\nwhich may not always be available. In this paper, we provide a novel\nunsupervised deep-learning method called Inception-based LSTM for video frame\nprediction. The general idea of inception networks is to implement wider\nnetworks instead of deeper networks. This network design was shown to improve\nthe performance of image classification. The proposed method is evaluated on\nboth Inception-v1 and Inception-v2 structures. The proposed Inception LSTM\nmethods are compared with convolutional LSTM when applied using PredNet\npredictive coding framework for both the KITTI and KTH data sets. We observed\nthat the Inception based LSTM outperforms the convolutional LSTM. Also,\nInception LSTM has better prediction performance compared to Inception v2 LSTM.\nHowever, Inception v2 LSTM has a lower computational cost compared to Inception\nLSTM.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 03:49:07 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:06:36 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Hosseini", "Matin", ""], ["Maida", "Anthony S.", ""], ["Hosseini", "Majid", ""], ["Raju", "Gottumukkala", ""]]}, {"id": "1909.05623", "submitter": "Jiancheng Lyu", "authors": "Jiancheng Lyu and Spencer Sheen", "title": "A Channel-Pruned and Weight-Binarized Convolutional Neural Network for\n  Keyword Spotting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study channel number reduction in combination with weight binarization\n(1-bit weight precision) to trim a convolutional neural network for a keyword\nspotting (classification) task. We adopt a group-wise splitting method based on\nthe group Lasso penalty to achieve over 50% channel sparsity while maintaining\nthe network performance within 0.25% accuracy loss. We show an effective\nthree-stage procedure to balance accuracy and sparsity in network training.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 13:22:25 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Lyu", "Jiancheng", ""], ["Sheen", "Spencer", ""]]}, {"id": "1909.05624", "submitter": "Vaidheeswaran Archana", "authors": "Murugesan Vadivel, SelvaKumar Murugan, Suriyadeepan Ramamoorthy,\n  Vaidheeswaran Archana, Malaikannan Sankarasubbu", "title": "Detecting Parking Spaces in a Parcel using Satellite Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote Sensing Images from satellites have been used in various domains for\ndetecting and understanding structures on the ground surface. In this work,\nsatellite images were used for localizing parking spaces and vehicles in\nparking lots for a given parcel using an RCNN based Neural Network\nArchitectures. Parcel shapefiles and raster images from USGS image archive were\nused for developing images for both training and testing. Feature Pyramid based\nMask RCNN yields average class accuracy of 97.56% for both parking spaces and\nvehicles\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 07:00:13 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 13:37:07 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Vadivel", "Murugesan", ""], ["Murugan", "SelvaKumar", ""], ["Ramamoorthy", "Suriyadeepan", ""], ["Archana", "Vaidheeswaran", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "1909.05630", "submitter": "Walid Abdullah Al", "authors": "Walid Abdullah Al, Il Dong Yun", "title": "Reinforcing Medical Image Classifier to Improve Generalization on Small\n  Datasets", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advents of deep learning, improved image classification with complex\ndiscriminative models has been made possible. However, such deep models with\nincreased complexity require a huge set of labeled samples to generalize the\ntraining. Such classification models can easily overfit when applied for\nmedical images because of limited training data, which is a common problem in\nthe field of medical image analysis. This paper proposes and investigates a\nreinforced classifier for improving the generalization under a few available\ntraining data. Partially following the idea of reinforcement learning, the\nproposed classifier uses a generalization-feedback from a subset of the\ntraining data to update its parameter instead of only using the conventional\ncross-entropy loss about the training data. We evaluate the improvement of the\nproposed classifier by applying it on three different classification problems\nagainst the standard deep classifiers equipped with existing\noverfitting-prevention techniques. Besides an overall improvement in\nclassification performance, the proposed classifier showed remarkable\ncharacteristics of generalized learning, which can have great potential in\nmedical classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 09:12:36 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 04:28:33 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Al", "Walid Abdullah", ""], ["Yun", "Il Dong", ""]]}, {"id": "1909.05631", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Simon Alford, Vijay Gadepally, Michael Jones, Lauren\n  Milechin, Ryan Robinett, Sid Samsi", "title": "Sparse Deep Neural Network Graph Challenge", "comments": "7 pages, 5 figures, 3 tables, 60 references, accepted to IEEE HPEC\n  2019. arXiv admin note: substantial text overlap with arXiv:1807.03165,\n  arXiv:1708.02937, arXiv:1708.06866", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916336", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MIT/IEEE/Amazon GraphChallenge.org encourages community approaches to\ndeveloping new solutions for analyzing graphs and sparse data. Sparse AI\nanalytics present unique scalability difficulties. The proposed Sparse Deep\nNeural Network (DNN) Challenge draws upon prior challenges from machine\nlearning, high performance computing, and visual analytics to create a\nchallenge that is reflective of emerging sparse AI systems. The Sparse DNN\nChallenge is based on a mathematically well-defined DNN inference computation\nand can be implemented in any programming environment. Sparse DNN inference is\namenable to both vertex-centric implementations and array-based implementations\n(e.g., using the GraphBLAS.org standard). The computations are simple enough\nthat performance predictions can be made based on simple computing hardware\nmodels. The input data sets are derived from the MNIST handwritten letters. The\nsurrounding I/O and verification provide the context for each sparse DNN\ninference that allows rigorous definition of both the input and the output.\nFurthermore, since the proposed sparse DNN challenge is scalable in both\nproblem size and hardware, it can be used to measure and quantitatively compare\na wide range of present day and future systems. Reference implementations have\nbeen implemented and their serial and parallel performance have been measured.\nSpecifications, data, and software are publicly available at GraphChallenge.org\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 02:29:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kepner", "Jeremy", ""], ["Alford", "Simon", ""], ["Gadepally", "Vijay", ""], ["Jones", "Michael", ""], ["Milechin", "Lauren", ""], ["Robinett", "Ryan", ""], ["Samsi", "Sid", ""]]}, {"id": "1909.05637", "submitter": "Tao-Yang Fu", "authors": "Tao-yang Fu, Wang-Chien Lee", "title": "DeepIST: Deep Image-based Spatio-Temporal Network for Travel Time\n  Estimation", "comments": "10 pages, accepted by The 28th ACM International Conference on\n  Information and Knowledge Management (CIKM) 2019", "journal-ref": "The 28th ACM International Conference on Information and Knowledge\n  Management (CIKM) 2019", "doi": "10.1145/3357384.3357870", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the travel time for a given path is a fundamental problem in many\nurban transportation systems. However, prior works fail to well capture moving\nbehaviors embedded in paths and thus do not estimate the travel time\naccurately. To fill in this gap, in this work, we propose a novel neural\nnetwork framework, namely {\\em Deep Image-based Spatio-Temporal network\n(DeepIST)}, for travel time estimation of a given path. The novelty of DeepIST\nlies in the following aspects: 1) we propose to plot a path as a sequence of\n\"generalized images\" which include sub-paths along with additional information,\nsuch as traffic conditions, road network and traffic signals, in order to\nharness the power of convolutional neural network model (CNN) on image\nprocessing; 2) we design a novel two-dimensional CNN, namely {\\em PathCNN}, to\nextract spatial patterns for lines in images by regularization and adopting\nmultiple pooling methods; and 3) we apply a one-dimensional CNN to capture\ntemporal patterns among the spatial patterns along the paths for the\nestimation. Empirical results show that DeepIST soundly outperforms the\nstate-of-the-art travel time estimation models by 24.37\\% to 25.64\\% of mean\nabsolute error (MAE) in multiple large-scale real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 04:38:42 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Fu", "Tao-yang", ""], ["Lee", "Wang-Chien", ""]]}, {"id": "1909.05638", "submitter": "Lahiru D. Chamain Hewa Gamage", "authors": "Lahiru D. Chamain, Zhi Ding", "title": "Faster and Accurate Classification for JPEG2000 Compressed Images in\n  Networked Applications", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  JPEG2000 (j2k) is a highly popular format for image and video\ncompression.With the rapidly growing applications of cloud based image\nclassification, most existing j2k-compatible schemes would stream compressed\ncolor images from the source before reconstruction at the processing center as\ninputs to deep CNNs. We propose to remove the computationally costly\nreconstruction step by training a deep CNN image classifier using the CDF 9/7\nDiscrete Wavelet Transformed (DWT) coefficients directly extracted from\nj2k-compressed images. We demonstrate additional computation savings by\nutilizing shallower CNN to achieve classification of good accuracy in the DWT\ndomain. Furthermore, we show that traditional augmentation transforms such as\nflipping/shifting are ineffective in the DWT domain and present different\naugmentation transformations to achieve more accurate classification without\nany additional cost. This way, faster and more accurate classification is\npossible for j2k encoded images without image reconstruction. Through\nexperiments on CIFAR-10 and Tiny ImageNet data sets, we show that the\nperformance of the proposed solution is consistent for image transmission over\nlimited channel bandwidth.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:03:35 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chamain", "Lahiru D.", ""], ["Ding", "Zhi", ""]]}, {"id": "1909.05659", "submitter": "Nutan Chen Ph.D.", "authors": "Nutan Chen, G\\\"oran Westling, Benoni B. Edin, Patrick van der Smagt", "title": "Estimating Fingertip Forces, Torques, and Local Curvatures from\n  Fingernail Images", "comments": "Robotica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of dexterous manipulation has provided important insights in humans\nsensorimotor control as well as inspiration for manipulation strategies in\nrobotic hands. Previous work focused on experimental environment with\nrestrictions. Here we describe a method using the deformation and color\ndistribution of the fingernail and its surrounding skin, to estimate the\nfingertip forces, torques and contact surface curvatures for various objects,\nincluding the shape and material of the contact surfaces and the weight of the\nobjects. The proposed method circumvents limitations associated with sensorized\nobjects, gloves or fixed contact surface type. In addition, compared with\nprevious single finger estimation in an experimental environment, we extend the\napproach to multiple finger force estimation, which can be used for\napplications such as human grasping analysis. Four algorithms are used, c.q.,\nGaussian process (GP), Convolutional Neural Networks (CNN), Neural Networks\nwith Fast Dropout (NN-FD) and Recurrent Neural Networks with Fast Dropout\n(RNN-FD), to model a mapping from images to the corresponding labels. The\nresults further show that the proposed method has high accuracy to predict\nforce, torque and contact surface.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:22:32 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chen", "Nutan", ""], ["Westling", "G\u00f6ran", ""], ["Edin", "Benoni B.", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1909.05660", "submitter": "Juan Miguel Valverde", "authors": "Juan Miguel Valverde, Vandad Imani, John D. Lewis, Jussi Tohka", "title": "Predicting intelligence based on cortical WM/GM contrast, cortical\n  thickness and volumetry", "comments": "Submission to the ABCD Neurocognitive Prediction Challenge at MICCAI\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a four-layer fully-connected neural network (FNN) for predicting\nfluid intelligence scores from T1-weighted MR images for the ABCD-challenge. In\naddition to the volumes of brain structures, the FNN uses cortical WM/GM\ncontrast and cortical thickness at 78 cortical regions. These last two\nmeasurements were derived from the T1-weighted MR images using cortical\nsurfaces produced by the CIVET pipeline. The age and gender of the subjects and\nthe scanner manufacturer are also used as features for the learning algorithm.\nThis yielded 283 features provided to the FNN with two hidden layers of 20 and\n15 nodes. The method was applied to the data from the ABCD study. Trained with\na training set of 3736 subjects, the proposed method achieved a MSE of 71.596\nand a correlation of 0.151 in the validation set of 415 subjects. For the final\nsubmission, the model was trained with 3568 subjects and it achieved a MSE of\n94.0270 in the test set comprised of 4383 subjects.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:53:19 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Valverde", "Juan Miguel", ""], ["Imani", "Vandad", ""], ["Lewis", "John D.", ""], ["Tohka", "Jussi", ""]]}, {"id": "1909.05667", "submitter": "Liam Hiley BSc", "authors": "Liam Hiley, Alun Preece, Yulia Hicks", "title": "Explainable Deep Learning for Video Recognition Tasks: A Framework &\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of Deep Learning for real-world applications is ever-growing.\nWith the introduction of high performance hardware, applications are no longer\nlimited to image recognition. With the introduction of more complex problems\ncomes more and more complex solutions, and the increasing need for explainable\nAI. Deep Neural Networks for Video tasks are amongst the most complex models,\nwith at least twice the parameters of their Image counterparts. However,\nexplanations for these models are often ill-adapted to the video domain. The\ncurrent work in explainability for video models is still overshadowed by Image\ntechniques, while Video Deep Learning itself is quickly gaining on methods for\nstill images. This paper seeks to highlight the need for explainability methods\ndesigned with video deep learning models, and by association spatio-temporal\ninput in mind, by first illustrating the cutting edge for video deep learning,\nand then noting the scarcity of research into explanations for these methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 19:34:48 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Hiley", "Liam", ""], ["Preece", "Alun", ""], ["Hicks", "Yulia", ""]]}, {"id": "1909.05677", "submitter": "Anthony Bourached", "authors": "Anthony Bourached, George Cann", "title": "Raiders of the Lost Art", "comments": "Submitted to NeurIPS workshop on Machine Learning for Creativity and\n  Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural style transfer, first proposed by Gatys et al. (2015), can be used to\ncreate novel artistic work through rendering a content image in the form of a\nstyle image. We present a novel method of reconstructing lost artwork, by\napplying neural style transfer to x-radiographs of artwork with secondary\ninterior artwork beneath a primary exterior, so as to reconstruct lost artwork.\nFinally we reflect on AI art exhibitions and discuss the social, cultural,\nethical, and philosophical impact of these technical innovations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:14:04 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Bourached", "Anthony", ""], ["Cann", "George", ""]]}, {"id": "1909.05682", "submitter": "Jin Cao", "authors": "Huseyin Uzunalioglu, Jin Cao, Chitra Phadke, Gerald Lehmann, Ahmet\n  Akyamac, Ran He, Jeongran Lee, and Maria Able", "title": "Augmented Data Science: Towards Industrialization and Democratization of\n  Data Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversion of raw data into insights and knowledge requires substantial\namounts of effort from data scientists. Despite breathtaking advances in\nMachine Learning (ML) and Artificial Intelligence (AI), data scientists still\nspend the majority of their effort in understanding and then preparing the raw\ndata for ML/AI. The effort is often manual and ad hoc, and requires some level\nof domain knowledge. The complexity of the effort increases dramatically when\ndata diversity, both in form and context, increases. In this paper, we\nintroduce our solution, Augmented Data Science (ADS), towards addressing this\n\"human bottleneck\" in creating value from diverse datasets. ADS is a\ndata-driven approach and relies on statistics and ML to extract insights from\nany data set in a domain-agnostic way to facilitate the data science process.\nKey features of ADS are the replacement of rudimentary data exploration and\nprocessing steps with automation and the augmentation of data scientist\njudgment with automatically-generated insights. We present building blocks of\nour end-to-end solution and provide a case study to exemplify its capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:00:03 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Uzunalioglu", "Huseyin", ""], ["Cao", "Jin", ""], ["Phadke", "Chitra", ""], ["Lehmann", "Gerald", ""], ["Akyamac", "Ahmet", ""], ["He", "Ran", ""], ["Lee", "Jeongran", ""], ["Able", "Maria", ""]]}, {"id": "1909.05707", "submitter": "Seungjoon Lee", "authors": "Seungjoon Lee, Mahdi Kooshkbaghi, Konstantinos Spiliotis, Constantinos\n  I. Siettos, Ioannis G. Kevrekidis", "title": "Coarse-scale PDEs from fine-scale observations via machine learning", "comments": null, "journal-ref": null, "doi": "10.1063/1.5126869", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex spatiotemporal dynamics of physicochemical processes are often\nmodeled at a microscopic level (through e.g. atomistic, agent-based or lattice\nmodels) based on first principles. Some of these processes can also be\nsuccessfully modeled at the macroscopic level using e.g. partial differential\nequations (PDEs) describing the evolution of the right few macroscopic\nobservables (e.g. concentration and momentum fields). Deriving good macroscopic\ndescriptions (the so-called \"closure problem\") is often a time-consuming\nprocess requiring deep understanding/intuition about the system of interest.\nRecent developments in data science provide alternative ways to effectively\nextract/learn accurate macroscopic descriptions approximating the underlying\nmicroscopic observations. In this paper, we introduce a data-driven framework\nfor the identification of unavailable coarse-scale PDEs from microscopic\nobservations via machine learning algorithms. Specifically, using Gaussian\nProcesses, Artificial Neural Networks, and/or Diffusion Maps, the proposed\nframework uncovers the relation between the relevant macroscopic space fields\nand their time evolution (the right-hand-side of the explicitly unavailable\nmacroscopic PDE). Interestingly, several choices equally representative of the\ndata can be discovered. The framework will be illustrated through the\ndata-driven discovery of macroscopic, concentration-level PDEs resulting from a\nfine-scale, Lattice Boltzmann level model of a reaction/transport process. Once\nthe coarse evolution law is identified, it can be simulated to produce\nlong-term macroscopic predictions. Different features (pros as well as cons) of\nalternative machine learning algorithms for performing this task (Gaussian\nProcesses and Artificial Neural Networks), are presented and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:21:07 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 18:47:55 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lee", "Seungjoon", ""], ["Kooshkbaghi", "Mahdi", ""], ["Spiliotis", "Konstantinos", ""], ["Siettos", "Constantinos I.", ""], ["Kevrekidis", "Ioannis G.", ""]]}, {"id": "1909.05729", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Lin Meng", "title": "GResNet: Graph Residual Network for Reviving Deep GNNs from Suspended\n  Animation", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing graph neural networks (GNNs) based on the spectral graph\nconvolutional operator have been criticized for its performance degradation,\nwhich is especially common for the models with deep architectures. In this\npaper, we further identify the suspended animation problem with the existing\nGNNs. Such a problem happens when the model depth reaches the suspended\nanimation limit, and the model will not respond to the training data any more\nand become not learnable. Analysis about the causes of the suspended animation\nproblem with existing GNNs will be provided in this paper, whereas several\nother peripheral factors that will impact the problem will be reported as well.\nTo resolve the problem, we introduce the GResNet (Graph Residual Network)\nframework in this paper, which creates extensively connected highways to\ninvolve nodes' raw features or intermediate representations throughout the\ngraph for all the model layers. Different from the other learning settings, the\nextensive connections in the graph data will render the existing simple\nresidual learning methods fail to work. We prove the effectiveness of the\nintroduced new graph residual terms from the norm preservation perspective,\nwhich will help avoid dramatic changes to the node's representations between\nsequential layers. Detailed studies about the GResNet framework for many\nexisting GNNs, including GCN, GAT and LoopyNet, will be reported in the paper\nwith extensive empirical experiments on real-world benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:46:12 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 17:13:36 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zhang", "Jiawei", ""], ["Meng", "Lin", ""]]}, {"id": "1909.05738", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, Franz Kir\\'aly, Markus L\\\"oning, Matthew Middlehurst\n  and George Oastler", "title": "A tale of two toolkits, report the first: benchmarking time series\n  classification algorithms for correctness and efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  sktime is an open source, Python based, sklearn compatible toolkit for time\nseries analysis developed by researchers at the University of East Anglia\n(UEA), University College London and the Alan Turing Institute. A key initial\ngoal for sktime was to provide time series classification functionality\nequivalent to that available in a related java package, tsml, also developed at\nUEA. We describe the implementation of six such classifiers in sktime and\ncompare them to their tsml equivalents. We demonstrate correctness through\nequivalence of accuracy on a range of standard test problems and compare the\nbuild time of the different implementations. We find that there is significant\ndifference in accuracy on only one of the six algorithms we look at (Proximity\nForest). This difference is causing us some pain in debugging. We found a much\nwider range of difference in efficiency. Again, this was not unexpected, but it\ndoes highlight ways both toolkits could be improved.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:01:30 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 19:38:02 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 10:46:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Bagnall", "Anthony", ""], ["Kir\u00e1ly", "Franz", ""], ["L\u00f6ning", "Markus", ""], ["Middlehurst", "Matthew", ""], ["Oastler", "George", ""]]}, {"id": "1909.05755", "submitter": "Kristian Miok", "authors": "Kristian Miok, Dong Nguyen-Doan, Daniela Zaharie and Marko\n  Robnik-\\v{S}ikonja", "title": "Generating Data using Monte Carlo Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many analytical problems the challenge is to handle huge amounts of\navailable data. However, there are data science application areas where\ncollecting information is difficult and costly, e.g., in the study of\ngeological phenomena, rare diseases, faults in complex systems, insurance\nfrauds, etc. In many such cases, generators of synthetic data with the same\nstatistical and predictive properties as the actual data allow efficient\nsimulations and development of tools and applications. In this work, we propose\nthe incorporation of Monte Carlo Dropout method within Autoencoder (MCD-AE) and\nVariational Autoencoder (MCD-VAE) as efficient generators of synthetic data\nsets. As the Variational Autoencoder (VAE) is one of the most popular generator\ntechniques, we explore its similarities and differences to the proposed\nmethods. We compare the generated data sets with the original data based on\nstatistical properties, structural similarity, and predictive similarity. The\nresults obtained show a strong similarity between the results of VAE, MCD-VAE\nand MCD-AE; however, the proposed methods are faster and can generate values\nsimilar to specific selected initial instances.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:33:20 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 13:07:17 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Miok", "Kristian", ""], ["Nguyen-Doan", "Dong", ""], ["Zaharie", "Daniela", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1909.05800", "submitter": "Silvia Chiappa", "authors": "Silvia Chiappa", "title": "Explicit-Duration Markov Switching Models", "comments": null, "journal-ref": "Foundations and Trends in Machine Learning, Volume 7, Issue 6,\n  pages 803-886, 2014", "doi": "10.1561/2200000054", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov switching models (MSMs) are probabilistic models that employ multiple\nsets of parameters to describe different dynamic regimes that a time series may\nexhibit at different periods of time. The switching mechanism between regimes\nis controlled by unobserved random variables that form a first-order Markov\nchain. Explicit-duration MSMs contain additional variables that explicitly\nmodel the distribution of time spent in each regime. This allows to define\nduration distributions of any form, but also to impose complex dependence\nbetween the observations and to reset the dynamics to initial conditions.\nModels that focus on the first two properties are most commonly known as hidden\nsemi-Markov models or segment models, whilst models that focus on the third\nproperty are most commonly known as changepoint models or reset models. In this\nmonograph, we provide a description of explicit-duration modelling by\ncategorizing the different approaches into three groups, which differ in\nencoding in the explicit-duration variables different information about regime\nchange/reset boundaries. The approaches are described using the formalism of\ngraphical models, which allows to graphically represent and assess statistical\ndependence and therefore to easily describe the structure of complex models and\nderive inference routines. The presentation is intended to be pedagogical,\nfocusing on providing a characterization of the three groups in terms of model\nstructure constraints and inference properties. The monograph is supplemented\nwith a software package that contains most of the models and examples\ndescribed. The material presented should be useful to both researchers wishing\nto learn about these models and researchers wishing to develop them further.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:54:16 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chiappa", "Silvia", ""]]}, {"id": "1909.05822", "submitter": "Pascale Gourdeau", "authors": "Pascale Gourdeau, Varun Kanade, Marta Kwiatkowska, James Worrell", "title": "On the Hardness of Robust Classification", "comments": "To appear in the proceedings of Neural Information Processing Systems\n  Conference (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is becoming increasingly important to understand the vulnerability of\nmachine learning models to adversarial attacks. In this paper we study the\nfeasibility of robust learning from the perspective of computational learning\ntheory, considering both sample and computational complexity. In particular,\nour definition of robust learnability requires polynomial sample complexity. We\nstart with two negative results. We show that no non-trivial concept class can\nbe robustly learned in the distribution-free setting against an adversary who\ncan perturb just a single input bit. We show moreover that the class of\nmonotone conjunctions cannot be robustly learned under the uniform distribution\nagainst an adversary who can perturb $\\omega(\\log n)$ input bits. However if\nthe adversary is restricted to perturbing $O(\\log n)$ bits, then the class of\nmonotone conjunctions can be robustly learned with respect to a general class\nof distributions (that includes the uniform distribution). Finally, we provide\na simple proof of the computational hardness of robust learning on the boolean\nhypercube. Unlike previous results of this nature, our result does not rely on\nanother computational model (e.g. the statistical query model) nor on any\nhardness assumption other than the existence of a hard learning problem in the\nPAC framework.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:29:08 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Gourdeau", "Pascale", ""], ["Kanade", "Varun", ""], ["Kwiatkowska", "Marta", ""], ["Worrell", "James", ""]]}, {"id": "1909.05829", "submitter": "Suraj Nair", "authors": "Suraj Nair, Chelsea Finn", "title": "Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks\n  via Visual Subgoal Generation", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video prediction models combined with planning algorithms have shown promise\nin enabling robots to learn to perform many vision-based tasks through only\nself-supervision, reaching novel goals in cluttered scenes with unseen objects.\nHowever, due to the compounding uncertainty in long horizon video prediction\nand poor scalability of sampling-based planning optimizers, one significant\nlimitation of these approaches is the ability to plan over long horizons to\nreach distant goals. To that end, we propose a framework for subgoal generation\nand planning, hierarchical visual foresight (HVF), which generates subgoal\nimages conditioned on a goal image, and uses them for planning. The subgoal\nimages are directly optimized to decompose the task into easy to plan segments,\nand as a result, we observe that the method naturally identifies semantically\nmeaningful states as subgoals. Across three out of four simulated vision-based\nmanipulation tasks, we find that our method achieves nearly a 200% performance\nimprovement over planning without subgoals and model-free RL approaches.\nFurther, our experiments illustrate that our approach extends to real,\ncluttered visual scenes. Project page:\nhttps://sites.google.com/stanford.edu/hvf\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:36:45 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Nair", "Suraj", ""], ["Finn", "Chelsea", ""]]}, {"id": "1909.05830", "submitter": "Jeffrey Li", "authors": "Jeffrey Li, Mikhail Khodak, Sebastian Caldas, Ameet Talwalkar", "title": "Differentially Private Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter-transfer is a well-known and versatile approach for meta-learning,\nwith applications including few-shot learning, federated learning, and\nreinforcement learning. However, parameter-transfer algorithms often require\nsharing models that have been trained on the samples from specific tasks, thus\nleaving the task-owners susceptible to breaches of privacy. We conduct the\nfirst formal study of privacy in this setting and formalize the notion of\ntask-global differential privacy as a practical relaxation of more commonly\nstudied threat models. We then propose a new differentially private algorithm\nfor gradient-based parameter transfer that not only satisfies this privacy\nrequirement but also retains provable transfer learning guarantees in convex\nsettings. Empirically, we apply our analysis to the problems of federated\nlearning with personalization and few-shot classification, showing that\nallowing the relaxation to task-global privacy from the more commonly studied\nnotion of local privacy leads to dramatically increased performance in\nrecurrent neural language modeling and image classification.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:37:08 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 17:08:10 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Li", "Jeffrey", ""], ["Khodak", "Mikhail", ""], ["Caldas", "Sebastian", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1909.05844", "submitter": "Boyue Li", "authors": "Boyue Li, Shicong Cen, Yuxin Chen, Yuejie Chi", "title": "Communication-Efficient Distributed Optimization in Networks with\n  Gradient Tracking and Variance Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in large-scale machine learning and optimization\nover decentralized networks, e.g. in the context of multi-agent learning and\nfederated learning. Due to the imminent need to alleviate the communication\nburden, the investigation of communication-efficient distributed optimization\nalgorithms - particularly for empirical risk minimization - has flourished in\nrecent years. A large fraction of these algorithms have been developed for the\nmaster/slave setting, relying on a central parameter server that can\ncommunicate with all agents. This paper focuses on distributed optimization\nover networks, or decentralized optimization, where each agent is only allowed\nto aggregate information from its neighbors. By properly adjusting the global\ngradient estimate via local averaging in conjunction with proper correction, we\ndevelop a communication-efficient approximate Newton-type method Network-DANE,\nwhich generalizes DANE to the decentralized scenarios. Our key ideas can be\napplied in a systematic manner to obtain decentralized versions of other\nmaster/slave distributed algorithms. A notable development is\nNetwork-SVRG/SARAH, which employs variance reduction to further accelerate\nlocal computation. We establish linear convergence of Network-DANE and\nNetwork-SVRG for strongly convex losses, and Network-SARAH for quadratic\nlosses, which shed light on the impacts of data homogeneity, network\nconnectivity, and local averaging upon the rate of convergence. We further\nextend Network-DANE to composite optimization by allowing a nonsmooth penalty\nterm. Numerical evidence is provided to demonstrate the appealing performance\nof our algorithms over competitive baselines, in terms of both communication\nand computation efficiency. Our work suggests that performing a certain amount\nof local communications and computations per iteration can substantially\nimprove the overall efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:50:03 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 01:00:16 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 19:31:46 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Li", "Boyue", ""], ["Cen", "Shicong", ""], ["Chen", "Yuxin", ""], ["Chi", "Yuejie", ""]]}, {"id": "1909.05850", "submitter": "Nathan Kallus", "authors": "Nathan Kallus and Masatoshi Uehara", "title": "Efficiently Breaking the Curse of Horizon in Off-Policy Evaluation with\n  Double Reinforcement Learning", "comments": "In V3, we significantly changed the derivation of the efficiency\n  bound to follow standard (iid) semiparametric theory. We also derive the\n  efficient influence function. In V4, we add an experiment in a\n  continuous-state environment employing function approximation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) in reinforcement learning is notoriously\ndifficult in long- and infinite-horizon settings due to diminishing overlap\nbetween behavior and target policies. In this paper, we study the role of\nMarkovian and time-invariant structure in efficient OPE. We first derive the\nefficiency bounds for OPE when one assumes each of these structures. This\nprecisely characterizes the curse of horizon: in time-variant processes, OPE is\nonly feasible in the near-on-policy setting, where behavior and target policies\nare sufficiently similar. But, in time-invariant Markov decision processes, our\nbounds show that truly-off-policy evaluation is feasible, even with only just\none dependent trajectory, and provide the limits of how well we could hope to\ndo. We develop a new estimator based on Double Reinforcement Learning (DRL)\nthat leverages this structure for OPE using the efficient influence function we\nderive. Our DRL estimator simultaneously uses estimated stationary density\nratios and $q$-functions and remains efficient when both are estimated at slow,\nnonparametric rates and remains consistent when either is estimated\nconsistently. We investigate these properties and the performance benefits of\nleveraging the problem structure for more efficient OPE.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:52:55 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 10:10:10 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 17:57:41 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2021 04:35:06 GMT"}, {"version": "v5", "created": "Mon, 3 May 2021 15:27:23 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "1909.05862", "submitter": "Miles Cranmer", "authors": "Miles D. Cranmer, Rui Xu, Peter Battaglia, Shirley Ho", "title": "Learning Symbolic Physics with Graph Networks", "comments": "6 pages; references added + improvements to writing and clarity;\n  accepted for an oral presentation at Machine Learning and the Physical\n  Sciences Workshop @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach for imposing physically motivated inductive biases\non graph networks to learn interpretable representations and improved zero-shot\ngeneralization. Our experiments show that our graph network models, which\nimplement this inductive bias, can learn message representations equivalent to\nthe true force vector when trained on n-body gravitational and spring-like\nsimulations. We use symbolic regression to fit explicit algebraic equations to\nour trained model's message function and recover the symbolic form of Newton's\nlaw of gravitation without prior knowledge. We also show that our model\ngeneralizes better at inference time to systems with more bodies than had been\nexperienced during training. Our approach is extensible, in principle, to any\nunknown interaction law learned by a graph network, and offers a valuable\ntechnique for interpreting and inferring explicit causal theories about the\nworld from implicit knowledge captured by deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:33:25 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Cranmer", "Miles D.", ""], ["Xu", "Rui", ""], ["Battaglia", "Peter", ""], ["Ho", "Shirley", ""]]}, {"id": "1909.05885", "submitter": "Ishita Dasgupta", "authors": "Ishita Dasgupta, Demi Guo, Samuel J. Gershman and Noah D. Goodman", "title": "Analyzing machine-learned representations: A natural language case study", "comments": "This article supersedes a previous article arXiv:1802.04302", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As modern deep networks become more complex, and get closer to human-like\ncapabilities in certain domains, the question arises of how the representations\nand decision rules they learn compare to the ones in humans. In this work, we\nstudy representations of sentences in one such artificial system for natural\nlanguage processing. We first present a diagnostic test dataset to examine the\ndegree of abstract composable structure represented. Analyzing performance on\nthese diagnostic tests indicates a lack of systematicity in the representations\nand decision rules, and reveals a set of heuristic strategies. We then\ninvestigate the effect of the training distribution on learning these heuristic\nstrategies, and study changes in these representations with various\naugmentations to the training set. Our results reveal parallels to the\nanalogous representations in people. We find that these systems can learn\nabstract rules and generalize them to new contexts under certain circumstances\n-- similar to human zero-shot reasoning. However, we also note some\nshortcomings in this generalization behavior -- similar to human judgment\nerrors like belief bias. Studying these parallels suggests new ways to\nunderstand psychological phenomena in humans as well as informs best strategies\nfor building artificial intelligence with human-like language understanding.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:03:17 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Dasgupta", "Ishita", ""], ["Guo", "Demi", ""], ["Gershman", "Samuel J.", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1909.05886", "submitter": "Lingda Wang", "authors": "Lingda Wang, Huozhi Zhou, Bingcong Li, Lav R. Varshney, Zhizhen Zhao", "title": "Nearly Optimal Algorithms for Piecewise-Stationary Cascading Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cascading bandit (CB) is a popular model for web search and online\nadvertising, where an agent aims to learn the $K$ most attractive items out of\na ground set of size $L$ during the interaction with a user. However, the\nstationary CB model may be too simple to apply to real-world problems, where\nuser preferences may change over time. Considering piecewise-stationary\nenvironments, two efficient algorithms, \\texttt{GLRT-CascadeUCB} and\n\\texttt{GLRT-CascadeKL-UCB}, are developed and shown to ensure regret upper\nbounds on the order of $\\mathcal{O}(\\sqrt{NLT\\log{T}})$, where $N$ is the\nnumber of piecewise-stationary segments, and $T$ is the number of time slots.\nAt the crux of the proposed algorithms is an almost parameter-free change-point\ndetector, the generalized likelihood ratio test (GLRT). Comparing with existing\nworks, the GLRT-based algorithms: i) are free of change-point-dependent\ninformation for choosing parameters; ii) have fewer tuning parameters; iii)\nimprove at least the $L$ dependence in regret upper bounds. In addition, we\nshow that the proposed algorithms are optimal (up to a logarithm factor) in\nterms of regret by deriving a minimax lower bound on the order of\n$\\Omega(\\sqrt{NLT})$ for piecewise-stationary CB. The efficiency of the\nproposed algorithms relative to state-of-the-art approaches is validated\nthrough numerical experiments on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:04:12 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 14:19:02 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 15:06:18 GMT"}, {"version": "v4", "created": "Mon, 7 Oct 2019 15:00:06 GMT"}, {"version": "v5", "created": "Mon, 17 Feb 2020 17:16:08 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Lingda", ""], ["Zhou", "Huozhi", ""], ["Li", "Bingcong", ""], ["Varshney", "Lav R.", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1909.05892", "submitter": "Sen Na", "authors": "Sen Na, Mladen Kolar, Oluwasanmi Koyejo", "title": "Estimating Differential Latent Variable Graphical Models with\n  Applications to Brain Connectivity", "comments": "60 pages", "journal-ref": "Biometrika 2020", "doi": "10.1093/biomet/asaa066", "report-no": null, "categories": "math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential graphical models are designed to represent the difference\nbetween the conditional dependence structures of two groups, thus are of\nparticular interest for scientific investigation. Motivated by modern\napplications, this manuscript considers an extended setting where each group is\ngenerated by a latent variable Gaussian graphical model. Due to the existence\nof latent factors, the differential network is decomposed into sparse and\nlow-rank components, both of which are symmetric indefinite matrices. We\nestimate these two components simultaneously using a two-stage procedure: (i)\nan initialization stage, which computes a simple, consistent estimator, and\n(ii) a convergence stage, implemented using a projected alternating gradient\ndescent algorithm applied to a nonconvex objective, initialized using the\noutput of the first stage. We prove that given the initialization, the\nestimator converges linearly with a nontrivial, minimax optimal statistical\nerror. Experiments on synthetic and real data illustrate that the proposed\nnonconvex procedure outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:12:46 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 23:58:09 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Na", "Sen", ""], ["Kolar", "Mladen", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1909.05894", "submitter": "Georgi Nalbantov", "authors": "Georgi Nalbantov and Svetoslav Ivanov", "title": "A Note on Posterior Probability Estimation for Classifiers", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central themes in the classification task is the estimation of\nclass posterior probability at a new point $\\bf{x}$. The vast majority of\nclassifiers output a score for $\\bf{x}$, which is monotonically related to the\nposterior probability via an unknown relationship. There are many attempts in\nthe literature to estimate this latter relationship. Here, we provide a way to\nestimate the posterior probability without resorting to using classification\nscores. Instead, we vary the prior probabilities of classes in order to derive\nthe ratio of pdf's at point $\\bf{x}$, which is directly used to determine class\nposterior probabilities. We consider here the binary classification problem.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:19:00 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Nalbantov", "Georgi", ""], ["Ivanov", "Svetoslav", ""]]}, {"id": "1909.05926", "submitter": "Rodney LaLonde III", "authors": "Rodney LaLonde, Drew Torigian, Ulas Bagci", "title": "Encoding Visual Attributes in Capsules for Explainable Medical Diagnoses", "comments": "Accepted for publication at MICCAI 2020 (23rd International\n  Conference on Medical Image Computing and Computer Assisted Intervention).\n  Code is publicly available at https://github.com/lalonderodney/X-Caps", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network based systems have largely failed to be adopted\nin many high-risk application areas, including healthcare, military, security,\ntransportation, finance, and legal, due to their highly uninterpretable\n\"black-box\" nature. Towards solving this deficiency, we teach a novel\nmulti-task capsule network to improve the explainability of predictions by\nembodying the same high-level language used by human-experts. Our explainable\ncapsule network, X-Caps, encodes high-level visual object attributes within the\nvectors of its capsules, then forms predictions based solely on these\nhuman-interpretable features. To encode attributes, X-Caps utilizes a new\nrouting sigmoid function to independently route information from child capsules\nto parents. Further, to provide radiologists with an estimate of model\nconfidence, we train our network on a distribution of expert labels, modeling\ninter-observer agreement and punishing over/under confidence during training,\nsupervised by human-experts' agreement. X-Caps simultaneously learns attribute\nand malignancy scores from a multi-center dataset of over 1000 CT scans of lung\ncancer screening patients. We demonstrate a simple 2D capsule network can\noutperform a state-of-the-art deep dense dual-path 3D CNN at capturing\nvisually-interpretable high-level attributes and malignancy prediction, while\nproviding malignancy prediction scores approaching that of non-explainable 3D\nCNNs. To the best of our knowledge, this is the first study to investigate\ncapsule networks for making predictions based on radiologist-level\ninterpretable attributes and its applications to medical image diagnosis. Code\nis publicly available at https://github.com/lalonderodney/X-Caps .\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 20:04:16 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 07:58:34 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 17:58:42 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 03:02:06 GMT"}, {"version": "v5", "created": "Sat, 20 Jun 2020 23:52:39 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["LaLonde", "Rodney", ""], ["Torigian", "Drew", ""], ["Bagci", "Ulas", ""]]}, {"id": "1909.05948", "submitter": "Filippo Maria Bianchi", "authors": "Luigi T. Luppino, Filippo M. Bianchi, Gabriele Moser, Stian N.\n  Anfinsen", "title": "Unsupervised Image Regression for Heterogeneous Change Detection", "comments": "arXiv admin note: text overlap with arXiv:1807.11766", "journal-ref": null, "doi": "10.1109/TGRS.2019.2930348", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change detection in heterogeneous multitemporal satellite images is an\nemerging and challenging topic in remote sensing. In particular, one of the\nmain challenges is to tackle the problem in an unsupervised manner. In this\npaper we propose an unsupervised framework for bitemporal heterogeneous change\ndetection based on the comparison of affinity matrices and image regression.\nFirst, our method quantifies the similarity of affinity matrices computed from\nco-located image patches in the two images. This is done to automatically\nidentify pixels that are likely to be unchanged. With the identified pixels as\npseudo-training data, we learn a transformation to map the first image to the\ndomain of the other image, and vice versa. Four regression methods are selected\nto carry out the transformation: Gaussian process regression, support vector\nregression, random forest regression, and a recently proposed kernel regression\nmethod called homogeneous pixel transformation. To evaluate the potentials and\nlimitations of our framework, and also the benefits and disadvantages of each\nregression method, we perform experiments on two real data sets. The results\nindicate that the comparison of the affinity matrices can already be considered\na change detection method by itself. However, image regression is shown to\nimprove the results obtained by the previous step alone and produces accurate\nchange detection maps despite of the heterogeneity of the multitemporal input\ndata. Notably, the random forest regression approach excels by achieving\nsimilar accuracy as the other methods, but with a significantly lower\ncomputational cost and with fast and robust tuning of hyperparameters.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 12:26:11 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Luppino", "Luigi T.", ""], ["Bianchi", "Filippo M.", ""], ["Moser", "Gabriele", ""], ["Anfinsen", "Stian N.", ""]]}, {"id": "1909.05950", "submitter": "Felix Leibfried", "authors": "Felix Leibfried and Jordi Grau-Moya", "title": "Mutual-Information Regularization in Markov Decision Processes and\n  Actor-Critic Learning", "comments": "Proceedings of the 3rd Conference on Robot Learning (CoRL), Osaka,\n  Japan, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cumulative entropy regularization introduces a regulatory signal to the\nreinforcement learning (RL) problem that encourages policies with high-entropy\nactions, which is equivalent to enforcing small deviations from a uniform\nreference marginal policy. This has been shown to improve exploration and\nrobustness, and it tackles the value overestimation problem. It also leads to a\nsignificant performance increase in tabular and high-dimensional settings, as\ndemonstrated via algorithms such as soft Q-learning (SQL) and soft actor-critic\n(SAC). Cumulative entropy regularization has been extended to optimize over the\nreference marginal policy instead of keeping it fixed, yielding a\nregularization that minimizes the mutual information between states and\nactions. While this has been initially proposed for Markov Decision Processes\n(MDPs) in tabular settings, it was recently shown that a similar principle\nleads to significant improvements over vanilla SQL in RL for high-dimensional\ndomains with discrete actions and function approximators.\n  Here, we follow the motivation of mutual-information regularization from an\ninference perspective and theoretically analyze the corresponding Bellman\noperator. Inspired by this Bellman operator, we devise a novel\nmutual-information regularized actor-critic learning (MIRACLE) algorithm for\ncontinuous action spaces that optimizes over the reference marginal policy. We\nempirically validate MIRACLE in the Mujoco robotics simulator, where we\ndemonstrate that it can compete with contemporary RL methods. Most notably, it\ncan improve over the model-free state-of-the-art SAC algorithm which implicitly\nassumes a fixed reference policy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:43:25 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Leibfried", "Felix", ""], ["Grau-Moya", "Jordi", ""]]}, {"id": "1909.05966", "submitter": "Alvin Chua", "authors": "Alvin J. K. Chua, Michele Vallisneri", "title": "Learning Bayesian posteriors with neural networks for gravitational-wave\n  inference", "comments": "(Superior-to-)published version; source code and trained networks\n  available at https://github.com/vallis/truebayes", "journal-ref": "Phys. Rev. Lett. 124, 041102 (2020)", "doi": "10.1103/PhysRevLett.124.041102", "report-no": null, "categories": "gr-qc astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to achieve the Holy Grail of Bayesian inference for\ngravitational-wave astronomy: using deep-learning techniques to instantly\nproduce the posterior $p(\\theta|D)$ for the source parameters $\\theta$, given\nthe detector data $D$. To do so, we train a deep neural network to take as\ninput a signal + noise data set (drawn from the astrophysical source-parameter\nprior and the sampling distribution of detector noise), and to output a\nparametrized approximation of the corresponding posterior. We rely on a compact\nrepresentation of the data based on reduced-order modeling, which we generate\nefficiently using a separate neural-network waveform interpolant [A. J. K.\nChua, C. R. Galley & M. Vallisneri, Phys. Rev. Lett. 122, 211101 (2019)]. Our\nscheme has broad relevance to gravitational-wave applications such as\nlow-latency parameter estimation and characterizing the science returns of\nfuture experiments. Source code and trained networks are available online at\nhttps://github.com/vallis/truebayes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:15:09 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 21:51:13 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 21:30:31 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Chua", "Alvin J. K.", ""], ["Vallisneri", "Michele", ""]]}, {"id": "1909.05989", "submitter": "Boris Hanin", "authors": "Boris Hanin, Mihai Nica", "title": "Finite Depth and Width Corrections to the Neural Tangent Kernel", "comments": "27 pages, 2 figures, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the precise scaling, at finite depth and width, for the mean and\nvariance of the neural tangent kernel (NTK) in a randomly initialized ReLU\nnetwork. The standard deviation is exponential in the ratio of network depth to\nwidth. Thus, even in the limit of infinite overparameterization, the NTK is not\ndeterministic if depth and width simultaneously tend to infinity. Moreover, we\nprove that for such deep and wide networks, the NTK has a non-trivial evolution\nduring training by showing that the mean of its first SGD update is also\nexponential in the ratio of network depth to width. This is sharp contrast to\nthe regime where depth is fixed and network width is very large. Our results\nsuggest that, unlike relatively shallow and wide networks, deep and wide ReLU\nnetworks are capable of learning data-dependent features even in the so-called\nlazy training regime.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 00:21:53 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Hanin", "Boris", ""], ["Nica", "Mihai", ""]]}, {"id": "1909.06008", "submitter": "Zhao Kang", "authors": "Zhao Kang and Zipeng Guo and Shudong Huang and Siying Wang and Wenyu\n  Chen and Yuanzhang Su and Zenglin Xu", "title": "Multiple Partitions Aligned Clustering", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering is an important yet challenging task due to the\ndifficulty of integrating the information from multiple representations. Most\nexisting multi-view clustering methods explore the heterogeneous information in\nthe space where the data points lie. Such common practice may cause significant\ninformation loss because of unavoidable noise or inconsistency among views.\nSince different views admit the same cluster structure, the natural space\nshould be all partitions. Orthogonal to existing techniques, in this paper, we\npropose to leverage the multi-view information by fusing partitions.\nSpecifically, we align each partition to form a consensus cluster indicator\nmatrix through a distinct rotation matrix. Moreover, a weight is assigned for\neach view to account for the clustering capacity differences of views. Finally,\nthe basic partitions, weights, and consensus clustering are jointly learned in\na unified framework. We demonstrate the effectiveness of our approach on\nseveral real datasets, where significant improvement is found over other\nstate-of-the-art multi-view clustering methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 02:45:13 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Kang", "Zhao", ""], ["Guo", "Zipeng", ""], ["Huang", "Shudong", ""], ["Wang", "Siying", ""], ["Chen", "Wenyu", ""], ["Su", "Yuanzhang", ""], ["Xu", "Zenglin", ""]]}, {"id": "1909.06019", "submitter": "Michael Katehakis", "authors": "Wesley Cowan, Michael N. Katehakis, Daniel Pirutinsky", "title": "Reinforcement Learning: a Comparison of UCB Versus Alternative Adaptive\n  Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the basic version of Reinforcement Learning (RL)\nthat involves computing optimal data driven (adaptive) policies for Markovian\ndecision process with unknown transition probabilities. We provide a brief\nsurvey of the state of the art of the area and we compare the performance of\nthe classic UCB policy of \\cc{bkmdp97} with a new policy developed herein which\nwe call MDP-Deterministic Minimum Empirical Divergence (MDP-DMED), and a method\nbased on Posterior sampling (MDP-PS).\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 03:43:19 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Cowan", "Wesley", ""], ["Katehakis", "Michael N.", ""], ["Pirutinsky", "Daniel", ""]]}, {"id": "1909.06034", "submitter": "Tamir Blum", "authors": "Tamir Blum, William Jones and Kazuya Yoshida", "title": "Deep Learned Path Planning via Randomized Reward-Linked-Goals and\n  Potential Space Applications", "comments": "8 pages, 3 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space exploration missions have seen use of increasingly sophisticated\nrobotic systems with ever more autonomy. Deep learning promises to take this\neven a step further, and has applications for high-level tasks, like path\nplanning, as well as low-level tasks, like motion control, which are critical\ncomponents for mission efficiency and success. Using deep reinforcement\nend-to-end learning with randomized reward function parameters during training,\nwe teach a simulated 8 degree-of-freedom quadruped ant-like robot to travel\nanywhere within a perimeter, conducting path plan and motion control on a\nsingle neural network, without any system model or prior knowledge of the\nterrain or environment. Our approach also allows for user specified waypoints,\nwhich could translate well to either fully autonomous or\nsemi-autonomous/teleoperated space applications that encounter delay times. We\ntrained the agent using randomly generated waypoints linked to the reward\nfunction and passed waypoint coordinates as inputs to the neural network. Such\napplications show promise on a variety of space exploration robots, including\nhigh speed rovers for fast locomotion and legged cave robots for rough terrain.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 04:58:52 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Blum", "Tamir", ""], ["Jones", "William", ""], ["Yoshida", "Kazuya", ""]]}, {"id": "1909.06039", "submitter": "Neil G. Marchant", "authors": "Neil G. Marchant, Andee Kaplan, Daniel N. Elazar, Benjamin I. P.\n  Rubinstein, Rebecca C. Steorts", "title": "d-blink: Distributed End-to-End Bayesian Entity Resolution", "comments": "32 pages, 6 figures, 5 tables. Includes 22 pages of supplementary\n  material. This revision incorporates a case study on the 2010 U.S. Decennial\n  Census", "journal-ref": null, "doi": "10.1080/10618600.2020.1825451", "report-no": null, "categories": "stat.CO cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution (ER; also known as record linkage or de-duplication) is the\nprocess of merging noisy databases, often in the absence of unique identifiers.\nA major advancement in ER methodology has been the application of Bayesian\ngenerative models, which provide a natural framework for inferring latent\nentities with rigorous quantification of uncertainty. Despite these advantages,\nexisting models are severely limited in practice, as standard inference\nalgorithms scale quadratically in the number of records. While scaling can be\nmanaged by fitting the model on separate blocks of the data, such a na\\\"ive\napproach may induce significant error in the posterior. In this paper, we\npropose a principled model for scalable Bayesian ER, called \"distributed\nBayesian linkage\" or d-blink, which jointly performs blocking and ER without\ncompromising posterior correctness. Our approach relies on several key ideas,\nincluding: (i) an auxiliary variable representation that induces a partition of\nthe entities and records into blocks; (ii) a method for constructing\nwell-balanced blocks based on k-d trees; (iii) a distributed\npartially-collapsed Gibbs sampler with improved mixing; and (iv) fast\nalgorithms for performing Gibbs updates. Empirical studies on six data\nsets---including a case study on the 2010 Decennial Census---demonstrate the\nscalability and effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:28:37 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 00:58:17 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 13:42:27 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Marchant", "Neil G.", ""], ["Kaplan", "Andee", ""], ["Elazar", "Daniel N.", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Steorts", "Rebecca C.", ""]]}, {"id": "1909.06040", "submitter": "Yanghua Peng", "authors": "Yanghua Peng, Yixin Bao, Yangrui Chen, Chuan Wu, Chen Meng, Wei Lin", "title": "DL2: A Deep Learning-driven Scheduler for Deep Learning Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more companies have deployed machine learning (ML) clusters, where\ndeep learning (DL) models are trained for providing various AI-driven services.\nEfficient resource scheduling is essential for maximal utilization of expensive\nDL clusters. Existing cluster schedulers either are agnostic to ML workload\ncharacteristics, or use scheduling heuristics based on operators' understanding\nof particular ML framework and workload, which are less efficient or not\ngeneral enough. In this paper, we show that DL techniques can be adopted to\ndesign a generic and efficient scheduler. DL2 is a DL-driven scheduler for DL\nclusters, targeting global training job expedition by dynamically resizing\nresources allocated to jobs. DL2 advocates a joint supervised learning and\nreinforcement learning approach: a neural network is warmed up via offline\nsupervised learning based on job traces produced by the existing cluster\nscheduler; then the neural network is plugged into the live DL cluster,\nfine-tuned by reinforcement learning carried out throughout the training\nprogress of the DL jobs, and used for deciding job resource allocation in an\nonline fashion. By applying past decisions made by the existing cluster\nscheduler in the preparatory supervised learning phase, our approach enables a\nsmooth transition from existing scheduler, and renders a high-quality scheduler\nin minimizing average training completion time. We implement DL2 on Kubernetes\nand enable dynamic resource scaling in DL jobs on MXNet. Extensive evaluation\nshows that DL2 outperforms fairness scheduler (i.e., DRF) by 44.1% and expert\nheuristic scheduler (i.e., Optimus) by 17.5% in terms of average job completion\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:30:11 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Peng", "Yanghua", ""], ["Bao", "Yixin", ""], ["Chen", "Yangrui", ""], ["Wu", "Chuan", ""], ["Meng", "Chen", ""], ["Lin", "Wei", ""]]}, {"id": "1909.06041", "submitter": "Neema Kachappilly Davis", "authors": "Neema Davis, Gaurav Raina, Krishna Jagannathan", "title": "LSTM-Based Anomaly Detection: Detection Rules from Extreme Value Theory", "comments": "Proceedings of the EPIA Conference on Artificial Intelligence 2019.\n  The final publication is available at Springer via\n  https://doi.org/10.1007/978-3-030-30241-2_48", "journal-ref": null, "doi": "10.1007/978-3-030-30241-2_48", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore various statistical techniques for anomaly\ndetection in conjunction with the popular Long Short-Term Memory (LSTM) deep\nlearning model for transportation networks. We obtain the prediction errors\nfrom an LSTM model, and then apply three statistical models based on (i) the\nGaussian distribution, (ii) Extreme Value Theory (EVT), and (iii) the Tukey's\nmethod. Using statistical tests and numerical studies, we find strong evidence\nagainst the widely employed Gaussian distribution based detection rule on the\nprediction errors. Next, motivated by fundamental results from Extreme Value\nTheory, we propose a detection technique that does not assume any parent\ndistribution on the prediction errors. Through numerical experiments conducted\non several real-world traffic data sets, we show that the EVT-based detection\nrule is superior to other detection rules, and is supported by statistical\nevidence.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:31:07 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Davis", "Neema", ""], ["Raina", "Gaurav", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "1909.06064", "submitter": "Yu Inatsu", "authors": "Yu Inatsu, Masayuki Karasuyama, Keiichi Inoue, Ichiro Takeuchi", "title": "Active learning for level set estimation under cost-dependent input\n  uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of a quality control process in manufacturing it is often necessary\nto test whether all parts of a product satisfy a required property, with as few\ninspections as possible. When multiple inspection apparatuses with different\ncosts and precision exist, it is desirable that testing can be carried out\ncost-effectively by properly controlling the trade-off between the costs and\nthe precision. In this paper, we formulate this as a level set estimation (LSE)\nproblem under cost-dependent input uncertainty - LSE being a type of active\nlearning for estimating the level set, i.e., the subset of the input space in\nwhich an unknown function value is greater or smaller than a pre-determined\nthreshold. Then, we propose a new algorithm for LSE under cost-dependent input\nuncertainty with theoretical convergence guarantee. We demonstrate the\neffectiveness of the proposed algorithm by applying it to synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 07:11:12 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Inatsu", "Yu", ""], ["Karasuyama", "Masayuki", ""], ["Inoue", "Keiichi", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1909.06108", "submitter": "Nikita Kozodoi", "authors": "Nikita Kozodoi, Panagiotis Katsas, Stefan Lessmann, Luis\n  Moreira-Matias, Konstantinos Papakonstantinou", "title": "Shallow Self-Learning for Reject Inference in Credit Scoring", "comments": "Preprint of the paper accepted to ECML PKDD 2019", "journal-ref": "ECML PKDD 2019. Lecture Notes in Computer Science, vol 11908.\n  Springer, Cham", "doi": "10.1007/978-3-030-46133-1_31", "report-no": null, "categories": "stat.ML cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit scoring models support loan approval decisions in the financial\nservices industry. Lenders train these models on data from previously granted\ncredit applications, where the borrowers' repayment behavior has been observed.\nThis approach creates sample bias. The scoring model (i.e., classifier) is\ntrained on accepted cases only. Applying the resulting model to screen credit\napplications from the population of all borrowers degrades model performance.\nReject inference comprises techniques to overcome sampling bias through\nassigning labels to rejected cases. The paper makes two contributions. First,\nwe propose a self-learning framework for reject inference. The framework is\ngeared toward real-world credit scoring requirements through considering\ndistinct training regimes for iterative labeling and model training. Second, we\nintroduce a new measure to assess the effectiveness of reject inference\nstrategies. Our measure leverages domain knowledge to avoid artificial labeling\nof rejected cases during strategy evaluation. We demonstrate this approach to\noffer a robust and operational assessment of reject inference strategies.\nExperiments on a real-world credit scoring data set confirm the superiority of\nthe adjusted self-learning framework over regular self-learning and previous\nreject inference strategies. We also find strong evidence in favor of the\nproposed evaluation measure assessing reject inference strategies more\nreliably, raising the performance of the eventual credit scoring model.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 09:37:24 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Kozodoi", "Nikita", ""], ["Katsas", "Panagiotis", ""], ["Lessmann", "Stefan", ""], ["Moreira-Matias", "Luis", ""], ["Papakonstantinou", "Konstantinos", ""]]}, {"id": "1909.06116", "submitter": "Simone Riggi", "authors": "S. Riggi, F. Vitello, U. Becciani, C. Buemi, F. Bufano, A. Calanducci,\n  F. Cavallaro, A. Costa, A. Ingallinera, P. Leto, S. Loru, R.P. Norris, F.\n  Schillir\\`o, E. Sciacca, C. Trigilio, G. Umana", "title": "CAESAR source finder: recent developments and testing", "comments": "15 pages, 10 figures", "journal-ref": "Publications of the Astronomical Society of Australia, 2019, 36,\n  E037", "doi": "10.1017/pasa.2019.29", "report-no": null, "categories": "astro-ph.IM stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new era in radioastronomy will begin with the upcoming large-scale surveys\nplanned at the Australian Square Kilometre Array Pathfinder (ASKAP). ASKAP\nstarted its Early Science program in October 2017 and several target fields\nwere observed during the array commissioning phase. The SCORPIO field was the\nfirst observed in the Galactic Plane in Band 1 (792-1032 MHz) using 15\ncommissioned antennas. The achieved sensitivity and large field of view already\nallow to discover new sources and survey thousands of existing ones with\nimproved precision with respect to previous surveys. Data analysis is currently\nongoing to deliver the first source catalogue. Given the increased scale of the\ndata, source extraction and characterization, even in this Early Science phase,\nhave to be carried out in a mostly automated way. This process presents\nsignificant challenges due to the presence of extended objects and diffuse\nemission close to the Galactic Plane. In this context we have extended and\noptimized a novel source finding tool, named CAESAR , to allow extraction of\nboth compact and extended sources from radio maps. A number of developments\nhave been done driven by the analysis of the SCORPIO map and in view of the\nfuture ASKAP Galactic Plane survey. The main goals are the improvement of\nalgorithm performances and scalability as well as of software maintainability\nand usability within the radio community. In this paper we present the current\nstatus of CAESAR and report a first systematic characterization of its\nperformance for both compact and extended sources using simulated maps. Future\nprospects are discussed in light of the obtained results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 09:51:43 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Riggi", "S.", ""], ["Vitello", "F.", ""], ["Becciani", "U.", ""], ["Buemi", "C.", ""], ["Bufano", "F.", ""], ["Calanducci", "A.", ""], ["Cavallaro", "F.", ""], ["Costa", "A.", ""], ["Ingallinera", "A.", ""], ["Leto", "P.", ""], ["Loru", "S.", ""], ["Norris", "R. P.", ""], ["Schillir\u00f2", "F.", ""], ["Sciacca", "E.", ""], ["Trigilio", "C.", ""], ["Umana", "G.", ""]]}, {"id": "1909.06134", "submitter": "Yuming Huang", "authors": "Yuming Huang, Ashkan Panahi, Hamid Krim, Yiyi Yu, Spencer L. Smith", "title": "Deep Adversarial Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel adversarial framework for training deep belief networks\n(DBNs), which includes replacing the generator network in the methodology of\ngenerative adversarial networks (GANs) with a DBN and developing a highly\nparallelizable numerical algorithm for training the resulting architecture in a\nstochastic manner. Unlike the existing techniques, this framework can be\napplied to the most general form of DBNs with no requirement for back\npropagation. As such, it lays a new foundation for developing DBNs on a par\nwith GANs with various regularization units, such as pooling and normalization.\nForegoing back-propagation, our framework also exhibits superior scalability as\ncompared to other DBN and GAN learning techniques. We present a number of\nnumerical experiments in computer vision as well as neurosciences to illustrate\nthe main advantages of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 10:53:48 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:01:48 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Huang", "Yuming", ""], ["Panahi", "Ashkan", ""], ["Krim", "Hamid", ""], ["Yu", "Yiyi", ""], ["Smith", "Spencer L.", ""]]}, {"id": "1909.06137", "submitter": "Chaomin Shen", "authors": "Chaomin Shen, Yaxin Peng, Guixu Zhang, Jinsong Fan", "title": "Defending Against Adversarial Attacks by Suppressing the Largest\n  Eigenvalue of Fisher Information Matrix", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scheme for defending against adversarial attacks by suppressing\nthe largest eigenvalue of the Fisher information matrix (FIM). Our starting\npoint is one explanation on the rationale of adversarial examples. Based on the\nidea of the difference between a benign sample and its adversarial example is\nmeasured by the Euclidean norm, while the difference between their\nclassification probability densities at the last (softmax) layer of the network\ncould be measured by the Kullback-Leibler (KL) divergence, the explanation\nshows that the output difference is a quadratic form of the input difference.\nIf the eigenvalue of this quadratic form (a.k.a. FIM) is large, the output\ndifference becomes large even when the input difference is small, which\nexplains the adversarial phenomenon. This makes the adversarial defense\npossible by controlling the eigenvalues of the FIM. Our solution is adding one\nterm representing the trace of the FIM to the loss function of the original\nnetwork, as the largest eigenvalue is bounded by the trace. Our defensive\nscheme is verified by experiments using a variety of common attacking methods\non typical deep neural networks, e.g. LeNet, VGG and ResNet, with datasets\nMNIST, CIFAR-10, and German Traffic Sign Recognition Benchmark (GTSRB). Our new\nnetwork, after adopting the novel loss function and retraining, has an\neffective and robust defensive capability, as it decreases the fooling ratio of\nthe generated adversarial examples, and remains the classification accuracy of\nthe original network.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:00:48 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Shen", "Chaomin", ""], ["Peng", "Yaxin", ""], ["Zhang", "Guixu", ""], ["Fan", "Jinsong", ""]]}, {"id": "1909.06143", "submitter": "Yadong Li", "authors": "Yadong Li and Xin Cui", "title": "Shapley Interpretation and Activation in Neural Networks", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Shapley value approach to help address neural networks'\ninterpretability and \"vanishing gradient\" problems. Our method is based on an\naccurate analytical approximation to the Shapley value of a neuron with ReLU\nactivation. This analytical approximation admits a linear propagation of\nrelevance across neural network layers, resulting in a simple, fast and\nsensible interpretation of neural networks' decision making process.\n  We then derived a globally continuous and non-vanishing Shapley gradient,\nwhich can replace the conventional gradient in training neural network layers\nwith ReLU activation, and leading to better training performance. We further\nderived a Shapley Activation (SA) function, which is a close approximation to\nReLU but features the Shapley gradient. The SA is easy to implement in existing\nmachine learning frameworks. Numerical tests show that SA consistently\noutperforms ReLU in training convergence, accuracy and stability.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:13:27 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 00:26:36 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Li", "Yadong", ""], ["Cui", "Xin", ""]]}, {"id": "1909.06153", "submitter": "Michael Lutter", "authors": "Michael Lutter, Boris Belousov, Kim Listmann, Debora Clever, Jan\n  Peters", "title": "HJB Optimal Feedback Control with Deep Differential Value Functions and\n  Action Constraints", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning optimal feedback control laws capable of executing optimal\ntrajectories is essential for many robotic applications. Such policies can be\nlearned using reinforcement learning or planned using optimal control. While\nreinforcement learning is sample inefficient, optimal control only plans an\noptimal trajectory from a specific starting configuration. In this paper we\npropose deep optimal feedback control to learn an optimal feedback policy\nrather than a single trajectory. By exploiting the inherent structure of the\nrobot dynamics and strictly convex action cost, we can derive principled cost\nfunctions such that the optimal policy naturally obeys the action limits, is\nglobally optimal and stable on the training domain given the optimal value\nfunction. The corresponding optimal value function is learned end-to-end by\nembedding a deep differential network in the Hamilton-Jacobi-Bellmann\ndifferential equation and minimizing the error of this equality while\nsimultaneously decreasing the discounting from short- to far-sighted to enable\nthe learning. Our proposed approach enables us to learn an optimal feedback\ncontrol law in continuous time, that in contrast to existing approaches\ngenerates an optimal trajectory from any point in state-space without the need\nof replanning. The resulting approach is evaluated on non-linear systems and\nachieves optimal feedback control, where standard optimal control methods\nrequire frequent replanning.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:34:40 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 07:21:39 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Lutter", "Michael", ""], ["Belousov", "Boris", ""], ["Listmann", "Kim", ""], ["Clever", "Debora", ""], ["Peters", "Jan", ""]]}, {"id": "1909.06189", "submitter": "Guang Cheng", "authors": "Fang Chen, Hong Wan, Hua Cai, and Guang Cheng", "title": "Machine Learning in/for Blockchain: Future and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and blockchain are two of the most noticeable technologies\nin recent years. The first one is the foundation of artificial intelligence and\nbig data, and the second one has significantly disrupted the financial\nindustry. Both technologies are data-driven, and thus there are rapidly growing\ninterests in integrating them for more secure and efficient data sharing and\nanalysis. In this paper, we review the research on combining blockchain and\nmachine learning technologies and demonstrate that they can collaborate\nefficiently and effectively. In the end, we point out some future directions\nand expect more researches on deeper integration of the two promising\ntechnologies.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:37:42 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 01:29:16 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 23:50:57 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Chen", "Fang", ""], ["Wan", "Hong", ""], ["Cai", "Hua", ""], ["Cheng", "Guang", ""]]}, {"id": "1909.06236", "submitter": "Sohrab Ferdowsi", "authors": "Sohrab Ferdowsi, Maurits Diephuis, Shideh Rezaeifar, Slava\n  Voloshynovskiy", "title": "$\\rho$-VAE: Autoregressive parametrization of the VAE encoder", "comments": "Submitted to NeurIPS workshop on Bayesian deep learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make a minimal, but very effective alteration to the VAE model. This is\nabout a drop-in replacement for the (sample-dependent) approximate posterior to\nchange it from the standard white Gaussian with diagonal covariance to the\nfirst-order autoregressive Gaussian. We argue that this is a more reasonable\nchoice to adopt for natural signals like images, as it does not force the\nexisting correlation in the data to disappear in the posterior. Moreover, it\nallows more freedom for the approximate posterior to match the true posterior.\nThis allows for the repararametrization trick, as well as the KL-divergence\nterm to still have closed-form expressions, obviating the need for its\nsample-based estimation. Although providing more freedom to adapt to correlated\ndistributions, our parametrization has even less number of parameters than the\ndiagonal covariance, as it requires only two scalars, $\\rho$ and $s$, to\ncharacterize correlation and scaling, respectively. As validated by the\nexperiments, our proposition noticeably and consistently improves the quality\nof image generation in a plug-and-play manner, needing no further parameter\ntuning, and across all setups. The code to reproduce our experiments is\navailable at \\url{https://github.com/sssohrab/rho_VAE/}.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:01:33 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Ferdowsi", "Sohrab", ""], ["Diephuis", "Maurits", ""], ["Rezaeifar", "Shideh", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1909.06271", "submitter": "Ziming Zhang", "authors": "Zudi Lin and Hanspeter Pfister and Ziming Zhang", "title": "White-Box Adversarial Defense via Self-Supervised Data Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of how to defend classifiers against\nadversarial attacks that fool the classifiers using subtly modified input data.\nIn contrast to previous works, here we focus on the white-box adversarial\ndefense where the attackers are granted full access to not only the classifiers\nbut also defenders to produce as strong attacks as possible. In such a context\nwe propose viewing a defender as a functional, a higher-order function that\ntakes functions as its argument to represent a function space, rather than\nfixed functions conventionally. From this perspective, a defender should be\nrealized and optimized individually for each adversarial input. To this end, we\npropose RIDE, an efficient and provably convergent self-supervised learning\nalgorithm for individual data estimation to protect the predictions from\nadversarial attacks. We demonstrate the significant improvement of adversarial\ndefense performance on image recognition, eg, 98%, 76%, 43% test accuracy on\nMNIST, CIFAR-10, and ImageNet datasets respectively under the state-of-the-art\nBPDA attacker.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:51:50 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Lin", "Zudi", ""], ["Pfister", "Hanspeter", ""], ["Zhang", "Ziming", ""]]}, {"id": "1909.06293", "submitter": "Lucas Cassano", "authors": "Lucas Cassano and Ali H. Sayed", "title": "ISL: A novel approach for deep exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we explore an alternative approach to address deep\nexploration and we introduce the ISL algorithm, which is efficient at\nperforming deep exploration. Similarly to maximum entropy RL, we derive the\nalgorithm by augmenting the traditional RL objective with a novel\nregularization term. A distinctive feature of our approach is that, as opposed\nto other works that tackle the problem of deep exploration, in our derivation\nboth the learning equations and the exploration-exploitation strategy are\nderived in tandem as the solution to a well-posed optimization problem whose\nminimization leads to the optimal value function. Empirically we show that our\nmethod exhibits state of the art performance on a range of challenging\ndeep-exploration benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:28:09 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 21:15:14 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 10:12:19 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 15:10:00 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Cassano", "Lucas", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1909.06297", "submitter": "Han Liu", "authors": "Han Liu, Zhizhong Han, Yu-Shen Liu, Ming Gu", "title": "Fast Low-rank Metric Learning for Large-scale and High-dimensional Data", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank metric learning aims to learn better discrimination of data subject\nto low-rank constraints. It keeps the intrinsic low-rank structure of datasets\nand reduces the time cost and memory usage in metric learning. However, it is\nstill a challenge for current methods to handle datasets with both high\ndimensions and large numbers of samples. To address this issue, we present a\nnovel fast low-rank metric learning (FLRML) method.FLRML casts the low-rank\nmetric learning problem into an unconstrained optimization on the Stiefel\nmanifold, which can be efficiently solved by searching along the descent curves\nof the manifold.FLRML significantly reduces the complexity and memory usage in\noptimization, which makes the method scalable to both high dimensions and large\nnumbers of samples.Furthermore, we introduce a mini-batch version of FLRML to\nmake the method scalable to larger datasets which are hard to be loaded and\ndecomposed in limited memory. The outperforming experimental results show that\nour method is with high accuracy and much faster than the state-of-the-art\nmethods under several benchmarks with large numbers of high-dimensional data.\nCode has been made available at https://github.com/highan911/FLRML\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:42:21 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Liu", "Han", ""], ["Han", "Zhizhong", ""], ["Liu", "Yu-Shen", ""], ["Gu", "Ming", ""]]}, {"id": "1909.06301", "submitter": "Alessandro Fanfarillo", "authors": "Alessandro Fanfarillo, Davide Del Vento", "title": "AITuning: Machine Learning-based Tuning Tool for Run-Time Communication\n  Libraries", "comments": "11 pages, 1 figure, ParCo 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the problem of tuning communication libraries by\nusing a deep reinforcement learning approach. Reinforcement learning is a\nmachine learning technique incredibly effective in solving game-like\nsituations. In fact, tuning a set of parameters in a communication library in\norder to get better performance in a parallel application can be expressed as a\ngame: Find the right combination/path that provides the best reward. Even\nthough AITuning has been designed to be utilized with different run-time\nlibraries, we focused this work on applying it to the OpenCoarrays run-time\ncommunication library, built on top of MPI-3. This work not only shows the\npotential of using a reinforcement learning algorithm for tuning communication\nlibraries, but also demonstrates how the MPI Tool Information Interface,\nintroduced by the MPI-3 standard, can be used effectively by run-time libraries\nto improve the performance without human intervention.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:48:16 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Fanfarillo", "Alessandro", ""], ["Del Vento", "Davide", ""]]}, {"id": "1909.06312", "submitter": "Stanislav Morozov", "authors": "Sergei Popov, Stanislav Morozov, Artem Babenko", "title": "Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, deep neural networks (DNNs) have become the main instrument for\nmachine learning tasks within a wide range of domains, including vision, NLP,\nand speech. Meanwhile, in an important case of heterogenous tabular data, the\nadvantage of DNNs over shallow counterparts remains questionable. In\nparticular, there is no sufficient evidence that deep learning machinery allows\nconstructing methods that outperform gradient boosting decision trees (GBDT),\nwhich are often the top choice for tabular problems. In this paper, we\nintroduce Neural Oblivious Decision Ensembles (NODE), a new deep learning\narchitecture, designed to work with any tabular data. In a nutshell, the\nproposed NODE architecture generalizes ensembles of oblivious decision trees,\nbut benefits from both end-to-end gradient-based optimization and the power of\nmulti-layer hierarchical representation learning. With an extensive\nexperimental comparison to the leading GBDT packages on a large number of\ntabular datasets, we demonstrate the advantage of the proposed NODE\narchitecture, which outperforms the competitors on most of the tasks. We\nopen-source the PyTorch implementation of NODE and believe that it will become\na universal framework for machine learning on tabular data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:11:28 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 13:30:23 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Popov", "Sergei", ""], ["Morozov", "Stanislav", ""], ["Babenko", "Artem", ""]]}, {"id": "1909.06319", "submitter": "Yang Li", "authors": "Yang Li, Shoaib Akbar, Junier B. Oliva", "title": "Flow Models for Arbitrary Conditional Likelihoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dependencies among features of a dataset is at the core of\nmost unsupervised learning tasks. However, a majority of generative modeling\napproaches are focused solely on the joint distribution $p(x)$ and utilize\nmodels where it is intractable to obtain the conditional distribution of some\narbitrary subset of features $x_u$ given the rest of the observed covariates\n$x_o$: $p(x_u \\mid x_o)$. Traditional conditional approaches provide a model\nfor a fixed set of covariates conditioned on another fixed set of observed\ncovariates. Instead, in this work we develop a model that is capable of\nyielding all conditional distributions $p(x_u \\mid x_o)$ (for arbitrary $x_u$)\nvia tractable conditional likelihoods. We propose a novel extension of (change\nof variables based) flow generative models, arbitrary conditioning flow models\n(AC-Flow), that can be conditioned on arbitrary subsets of observed covariates,\nwhich was previously infeasible. We apply AC-Flow to the imputation of\nfeatures, and also develop a unified platform for both multiple and single\nimputation by introducing an auxiliary objective that provides a principled\nsingle \"best guess\" for flow models. Extensive empirical evaluations show that\nour models achieve state-of-the-art performance in both single and multiple\nimputation across image inpainting and feature imputation in synthetic and\nreal-world datasets. Code is available at https://github.com/lupalab/ACFlow.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:35:17 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 13:30:33 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Li", "Yang", ""], ["Akbar", "Shoaib", ""], ["Oliva", "Junier B.", ""]]}, {"id": "1909.06322", "submitter": "Quanquan Gu", "authors": "Lingxiao Wang and Quanquan Gu", "title": "A Knowledge Transfer Framework for Differentially Private Sparse\n  Learning", "comments": "24 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating high dimensional models with underlying\nsparse structures while preserving the privacy of each training example. We\ndevelop a differentially private high-dimensional sparse learning framework\nusing the idea of knowledge transfer. More specifically, we propose to distill\nthe knowledge from a \"teacher\" estimator trained on a private dataset, by\ncreating a new dataset from auxiliary features, and then train a differentially\nprivate \"student\" estimator using this new dataset. In addition, we establish\nthe linear convergence rate as well as the utility guarantee for our proposed\nmethod. For sparse linear regression and sparse logistic regression, our method\nachieves improved utility guarantees compared with the best known results\n(Kifer et al., 2012; Wang and Gu, 2019). We further demonstrate the superiority\nof our framework through both synthetic and real-world data experiments.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:46:02 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Wang", "Lingxiao", ""], ["Gu", "Quanquan", ""]]}, {"id": "1909.06335", "submitter": "Tzu-Ming Harry Hsu", "authors": "Tzu-Ming Harry Hsu, Hang Qi, Matthew Brown", "title": "Measuring the Effects of Non-Identical Data Distribution for Federated\n  Visual Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables visual models to be trained in a\nprivacy-preserving way using real-world data from mobile devices. Given their\ndistributed nature, the statistics of the data across these devices is likely\nto differ significantly. In this work, we look at the effect such non-identical\ndata distributions has on visual classification via Federated Learning. We\npropose a way to synthesize datasets with a continuous range of identicalness\nand provide performance measures for the Federated Averaging algorithm. We show\nthat performance degrades as distributions differ more, and propose a\nmitigation strategy via server momentum. Experiments on CIFAR-10 demonstrate\nimproved classification performance over a range of non-identicalness, with\nclassification accuracy improved from 30.1% to 76.9% in the most skewed\nsettings.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:26:20 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Hsu", "Tzu-Ming Harry", ""], ["Qi", "Hang", ""], ["Brown", "Matthew", ""]]}, {"id": "1909.06342", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly,\n  Yunhan Jia, Joydeep Ghosh, Ruchir Puri, Jos\\'e M. F. Moura, Peter Eckersley", "title": "Explainable Machine Learning in Deployment", "comments": "ACM Conference on Fairness, Accountability, and Transparency 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable machine learning offers the potential to provide stakeholders\nwith insights into model behavior by using various methods such as feature\nimportance scores, counterfactual explanations, or influential training data.\nYet there is little understanding of how organizations use these methods in\npractice. This study explores how organizations view and use explainability for\nstakeholder consumption. We find that, currently, the majority of deployments\nare not for end users affected by the model but rather for machine learning\nengineers, who use explainability to debug the model itself. There is thus a\ngap between explainability in practice and the goal of transparency, since\nexplanations primarily serve internal stakeholders rather than external ones.\nOur study synthesizes the limitations of current explainability techniques that\nhamper their use for end users. To facilitate end user interaction, we develop\na framework for establishing clear goals for explainability. We end by\ndiscussing concerns raised regarding explainability.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:35:53 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:30:09 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 17:31:01 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 13:53:00 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bhatt", "Umang", ""], ["Xiang", "Alice", ""], ["Sharma", "Shubham", ""], ["Weller", "Adrian", ""], ["Taly", "Ankur", ""], ["Jia", "Yunhan", ""], ["Ghosh", "Joydeep", ""], ["Puri", "Ruchir", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Eckersley", "Peter", ""]]}, {"id": "1909.06349", "submitter": "Vincent Chen", "authors": "Vincent S. Chen and Sen Wu and Zhenzhen Weng and Alexander Ratner and\n  Christopher R\\'e", "title": "Slice-based Learning: A Programming Model for Residual Learning in\n  Critical Data Slices", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world machine learning applications, data subsets correspond to\nespecially critical outcomes: vulnerable cyclist detections are safety-critical\nin an autonomous driving task, and \"question\" sentences might be important to a\ndialogue agent's language understanding for product purposes. While machine\nlearning models can achieve high quality performance on coarse-grained metrics\nlike F1-score and overall accuracy, they may underperform on critical\nsubsets---we define these as slices, the key abstraction in our approach. To\naddress slice-level performance, practitioners often train separate \"expert\"\nmodels on slice subsets or use multi-task hard parameter sharing. We propose\nSlice-based Learning, a new programming model in which the slicing function\n(SF), a programming interface, specifies critical data subsets for which the\nmodel should commit additional capacity. Any model can leverage SFs to learn\nslice expert representations, which are combined with an attention mechanism to\nmake slice-aware predictions. We show that our approach maintains a\nparameter-efficient representation while improving over baselines by up to 19.0\nF1 on slices and 4.6 F1 overall on datasets spanning language understanding\n(e.g. SuperGLUE), computer vision, and production-scale industrial systems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:49:20 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 06:56:36 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Vincent S.", ""], ["Wu", "Sen", ""], ["Weng", "Zhenzhen", ""], ["Ratner", "Alexander", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1909.06362", "submitter": "Nasim Sonboli", "authors": "Kun Lin, Nasim Sonboli, Bamshad Mobasher, Robin Burke", "title": "Crank up the volume: preference bias amplification in collaborative\n  recommendation", "comments": "Presented at the RMSE workshop held in conjunction with the 13th ACM\n  Conference on Recommender Systems (RecSys), 2019, in Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems are personalized: we expect the results given to a\nparticular user to reflect that user's preferences. Some researchers have\nstudied the notion of calibration, how well recommendations match users' stated\npreferences, and bias disparity the extent to which mis-calibration affects\ndifferent user groups. In this paper, we examine bias disparity over a range of\ndifferent algorithms and for different item categories and demonstrate\nsignificant differences between model-based and memory-based algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 03:23:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lin", "Kun", ""], ["Sonboli", "Nasim", ""], ["Mobasher", "Bamshad", ""], ["Burke", "Robin", ""]]}, {"id": "1909.06389", "submitter": "Bamdad Hosseini Dr.", "authors": "Franca Hoffmann and Bamdad Hosseini and Assad A. Oberai and Andrew M.\n  Stuart", "title": "Spectral Analysis Of Weighted Laplacians Arising In Data Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.SP math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Laplacians computed from weighted adjacency matrices are widely used to\nidentify geometric structure in data, and clusters in particular; their\nspectral properties play a central role in a number of unsupervised and\nsemi-supervised learning algorithms. When suitably scaled, graph Laplacians\napproach limiting continuum operators in the large data limit. Studying these\nlimiting operators, therefore, sheds light on learning algorithms. This paper\nis devoted to the study of a parameterized family of divergence form elliptic\noperators that arise as the large data limit of graph Laplacians. The link\nbetween a three-parameter family of graph Laplacians and a three-parameter\nfamily of differential operators is explained. The spectral properties of these\ndifferential operators are analyzed in the situation where the data comprises\ntwo nearly separated clusters, in a sense which is made precise. In particular,\nwe investigate how the spectral gap depends on the three parameters entering\nthe graph Laplacian, and on a parameter measuring the size of the perturbation\nfrom the perfectly clustered case. Numerical results are presented which\nexemplify and extend the analysis: the computations study situations in which\nthere are two nearly separated clusters, but which violate the assumptions used\nin our theory; situations in which more than two clusters are present, also\ngoing beyond our theory; and situations which demonstrate the relevance of our\nstudies of differential operators for the understanding of finite data problems\nvia the graph Laplacian. The findings provide insight into parameter choices\nmade in learning algorithms which are based on weighted adjacency matrices;\nthey also provide the basis for analysis of the consistency of various\nunsupervised and semi-supervised learning algorithms, in the large data limit.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 18:02:34 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 17:09:19 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Hoffmann", "Franca", ""], ["Hosseini", "Bamdad", ""], ["Oberai", "Assad A.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "1909.06397", "submitter": "Stefan Sommer", "authors": "Stefan Sommer, Alex Bronstein", "title": "Horizontal Flows and Manifold Stochastics in Geometric Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two constructions in geometric deep learning for 1) transporting\norientation-dependent convolutional filters over a manifold in a continuous way\nand thereby defining a convolution operator that naturally incorporates the\nrotational effect of holonomy; and 2) allowing efficient evaluation of manifold\nconvolution layers by sampling manifold valued random variables that center\naround a weighted diffusion mean. Both methods are inspired by stochastics on\nmanifolds and geometric statistics, and provide examples of how stochastic\nmethods -- here horizontal frame bundle flows and non-linear bridge sampling\nschemes, can be used in geometric deep learning. We outline the theoretical\nfoundation of the two methods, discuss their relation to Euclidean deep\nnetworks and existing methodology in geometric deep learning, and establish\nimportant properties of the proposed constructions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 18:27:02 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 13:28:51 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 19:00:10 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Sommer", "Stefan", ""], ["Bronstein", "Alex", ""]]}, {"id": "1909.06429", "submitter": "Rinat Khaziev", "authors": "Rinat Khaziev, Bryce Casavant, Pearce Washabaugh, Amy A. Winecoff, and\n  Matthew Graham", "title": "Recommendation or Discrimination?: Quantifying Distribution Parity in\n  Information Retrieval Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information retrieval (IR) systems often leverage query data to suggest\nrelevant items to users. This introduces the possibility of unfairness if the\nquery (i.e., input) and the resulting recommendations unintentionally correlate\nwith latent factors that are protected variables (e.g., race, gender, and age).\nFor instance, a visual search system for fashion recommendations may pick up on\nfeatures of the human models rather than fashion garments when generating\nrecommendations. In this work, we introduce a statistical test for\n\"distribution parity\" in the top-K IR results, which assesses whether a given\nset of recommendations is fair with respect to a specific protected variable.\nWe evaluate our test using both simulated and empirical results. First, using\nartificially biased recommendations, we demonstrate the trade-off between\nstatistically detectable bias and the size of the search catalog. Second, we\napply our test to a visual search system for fashion garments, specifically\ntesting for recommendation bias based on the skin tone of fashion models. Our\ndistribution parity test can help ensure that IR systems' results are fair and\nproduce a good experience for all users.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:17:19 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Khaziev", "Rinat", ""], ["Casavant", "Bryce", ""], ["Washabaugh", "Pearce", ""], ["Winecoff", "Amy A.", ""], ["Graham", "Matthew", ""]]}, {"id": "1909.06434", "submitter": "Sebastien Jean", "authors": "S\\'ebastien Jean, Orhan Firat, Melvin Johnson", "title": "Adaptive Scheduling for Multi-Task Learning", "comments": "Continual Learning Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To train neural machine translation models simultaneously on multiple tasks\n(languages), it is common to sample each task uniformly or in proportion to\ndataset sizes. As these methods offer little control over performance\ntrade-offs, we explore different task scheduling approaches. We first consider\nexisting non-adaptive techniques, then move on to adaptive schedules that\nover-sample tasks with poorer results compared to their respective baseline. As\nexplicit schedules can be inefficient, especially if one task is highly\nover-sampled, we also consider implicit schedules, learning to scale learning\nrates or gradients of individual tasks instead. These techniques allow training\nmultilingual models that perform better for low-resource language pairs (tasks\nwith small amount of data), while minimizing negative effects on high-resource\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:23:40 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Jean", "S\u00e9bastien", ""], ["Firat", "Orhan", ""], ["Johnson", "Melvin", ""]]}, {"id": "1909.06442", "submitter": "Devin Taylor", "authors": "Devin Taylor, Simeon Spasov and Pietro Li\\`o", "title": "Co-Attentive Cross-Modal Deep Learning for Medical Evidence Synthesis\n  and Decision Making", "comments": "7 pages, 2 figures, Machine Learning for Health (ML4H) at NeurIPS\n  2019 - Extended Abstract, clarified graph and math notation, typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern medicine requires generalised approaches to the synthesis and\nintegration of multimodal data, often at different biological scales, that can\nbe applied to a variety of evidence structures, such as complex disease\nanalyses and epidemiological models. However, current methods are either slow\nand expensive, or ineffective due to the inability to model the complex\nrelationships between data modes which differ in scale and format. We address\nthese issues by proposing a cross-modal deep learning architecture and\nco-attention mechanism to accurately model the relationships between the\ndifferent data modes, while further reducing patient diagnosis time.\nDifferentiating Parkinson's Disease (PD) patients from healthy patients forms\nthe basis of the evaluation. The model outperforms the previous\nstate-of-the-art unimodal analysis by 2.35%, while also being 53% more\nparameter efficient than the industry standard cross-modal model. Furthermore,\nthe evaluation of the attention coefficients allows for qualitative insights to\nbe obtained. Through the coupling with bioinformatics, a novel link between the\ninterferon-gamma-mediated pathway, DNA methylation and PD was identified. We\nbelieve that our approach is general and could optimise the process of medical\nevidence synthesis and decision making in an actionable way.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:49:55 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 06:58:53 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Taylor", "Devin", ""], ["Spasov", "Simeon", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1909.06473", "submitter": "Ali Siahkoohi", "authors": "Felix J. Herrmann, Ali Siahkoohi, Gabrio Rizzuti", "title": "Learned imaging with constraints and uncertainty quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline new approaches to incorporate ideas from deep learning into\nwave-based least-squares imaging. The aim, and main contribution of this work,\nis the combination of handcrafted constraints with deep convolutional neural\nnetworks, as a way to harness their remarkable ease of generating natural\nimages. The mathematical basis underlying our method is the\nexpectation-maximization framework, where data are divided in batches and\ncoupled to additional \"latent\" unknowns. These unknowns are pairs of elements\nfrom the original unknown space (but now coupled to a specific data batch) and\nnetwork inputs. In this setting, the neural network controls the similarity\nbetween these additional parameters, acting as a \"center\" variable. The\nresulting problem amounts to a maximum-likelihood estimation of the network\nparameters when the augmented data model is marginalized over the latent\nvariables.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 22:14:36 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 08:01:20 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Herrmann", "Felix J.", ""], ["Siahkoohi", "Ali", ""], ["Rizzuti", "Gabrio", ""]]}, {"id": "1909.06493", "submitter": "William Koch", "authors": "William Koch", "title": "Flight Controller Synthesis Via Deep Reinforcement Learning", "comments": "206 pages, PhD Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditional control methods are inadequate in many deployment settings\ninvolving control of Cyber-Physical Systems (CPS). In such settings, CPS\ncontrollers must operate and respond to unpredictable interactions, conditions,\nor failure modes. Dealing with such unpredictability requires the use of\nexecutive and cognitive control functions that allow for planning and\nreasoning. Motivated by the sport of drone racing, this dissertation addresses\nthese concerns for state-of-the-art flight control by investigating the use of\ndeep neural networks to bring essential elements of higher-level cognition for\nconstructing low level flight controllers.\n  This thesis reports on the development and release of an open source, full\nsolution stack for building neuro-flight controllers. This stack consists of\nthe methodology for constructing a multicopter digital twin for synthesize the\nflight controller unique to a specific aircraft, a tuning framework for\nimplementing training environments (GymFC), and a firmware for the world's\nfirst neural network supported flight controller (Neuroflight). GymFC's novel\napproach fuses together the digital twinning paradigm for flight control\ntraining to provide seamless transfer to hardware. Additionally, this thesis\nexamines alternative reward system functions as well as changes to the software\nenvironment to bridge the gap between the simulation and real world deployment\nenvironments.\n  Work summarized in this thesis demonstrates that reinforcement learning is\nable to be leveraged for training neural network controllers capable, not only\nof maintaining stable flight, but also precision aerobatic maneuvers in real\nworld settings. As such, this work provides a foundation for developing the\nnext generation of flight control systems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 00:35:21 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Koch", "William", ""]]}, {"id": "1909.06511", "submitter": "Alden Bradford", "authors": "Mireille Boutin and Alden Bradford", "title": "A highly likely clusterable data model with no clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model for a dataset in ${\\mathbb R}^D$ that does not contain any\nclusters but yet is such that a projection of the points on a random\none-dimensional subspace is likely to yield a clustering of the points. This\nmodel is compatible with some recent empirical observations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 02:38:31 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Boutin", "Mireille", ""], ["Bradford", "Alden", ""]]}, {"id": "1909.06541", "submitter": "Haitao Liu", "authors": "Haitao Liu, Yew-Soon Ong, Ziwei Yu, Jianfei Cai, Xiaobo Shen", "title": "Scalable Gaussian Process Classification with Additive Noise for Various\n  Likelihoods", "comments": "11 pages, 5 figures, preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process classification (GPC) provides a flexible and powerful\nstatistical framework describing joint distributions over function space.\nConventional GPCs however suffer from (i) poor scalability for big data due to\nthe full kernel matrix, and (ii) intractable inference due to the non-Gaussian\nlikelihoods. Hence, various scalable GPCs have been proposed through (i) the\nsparse approximation built upon a small inducing set to reduce the time\ncomplexity; and (ii) the approximate inference to derive analytical evidence\nlower bound (ELBO). However, these scalable GPCs equipped with analytical ELBO\nare limited to specific likelihoods or additional assumptions. In this work, we\npresent a unifying framework which accommodates scalable GPCs using various\nlikelihoods. Analogous to GP regression (GPR), we introduce additive noises to\naugment the probability space for (i) the GPCs with step, (multinomial) probit\nand logit likelihoods via the internal variables; and particularly, (ii) the\nGPC using softmax likelihood via the noise variables themselves. This leads to\nunified scalable GPCs with analytical ELBO by using variational inference.\nEmpirically, our GPCs showcase better results than state-of-the-art scalable\nGPCs for extensive binary/multi-class classification tasks with up to two\nmillion data points.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 06:24:38 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liu", "Haitao", ""], ["Ong", "Yew-Soon", ""], ["Yu", "Ziwei", ""], ["Cai", "Jianfei", ""], ["Shen", "Xiaobo", ""]]}, {"id": "1909.06543", "submitter": "Yiwei Sun", "authors": "Yiwei Sun, Suhang Wang, Xianfeng Tang, Tsung-Yu Hsieh, Vasant Honavar", "title": "Node Injection Attacks on Graphs via Reinforcement Learning", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world graph applications, such as advertisements and product\nrecommendations make profits based on accurately classify the label of the\nnodes. However, in such scenarios, there are high incentives for the\nadversaries to attack such graph to reduce the node classification performance.\nPrevious work on graph adversarial attacks focus on modifying existing graph\nstructures, which is infeasible in most real-world applications. In contrast,\nit is more practical to inject adversarial nodes into existing graphs, which\ncan also potentially reduce the performance of the classifier. In this paper,\nwe study the novel node injection poisoning attacks problem which aims to\npoison the graph. We describe a reinforcement learning based method, namely\nNIPA, to sequentially modify the adversarial information of the injected nodes.\nWe report the results of experiments using several benchmark data sets that\nshow the superior performance of the proposed method NIPA, relative to the\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 06:35:22 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Sun", "Yiwei", ""], ["Wang", "Suhang", ""], ["Tang", "Xianfeng", ""], ["Hsieh", "Tsung-Yu", ""], ["Honavar", "Vasant", ""]]}, {"id": "1909.06576", "submitter": "Tristan Deleu", "authors": "Tristan Deleu, Tobias W\\\"urfl, Mandana Samiei, Joseph Paul Cohen,\n  Yoshua Bengio", "title": "Torchmeta: A Meta-Learning library for PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constant introduction of standardized benchmarks in the literature has\nhelped accelerating the recent advances in meta-learning research. They offer a\nway to get a fair comparison between different algorithms, and the wide range\nof datasets available allows full control over the complexity of this\nevaluation. However, for a large majority of code available online, the data\npipeline is often specific to one dataset, and testing on another dataset\nrequires significant rework. We introduce Torchmeta, a library built on top of\nPyTorch that enables seamless and consistent evaluation of meta-learning\nalgorithms on multiple datasets, by providing data-loaders for most of the\nstandard benchmarks in few-shot classification and regression, with a new\nmeta-dataset abstraction. It also features some extensions for PyTorch to\nsimplify the development of models compatible with meta-learning algorithms.\nThe code is available here: https://github.com/tristandeleu/pytorch-meta\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 10:58:53 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Deleu", "Tristan", ""], ["W\u00fcrfl", "Tobias", ""], ["Samiei", "Mandana", ""], ["Cohen", "Joseph Paul", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1909.06588", "submitter": "Jingyue Lu", "authors": "Rudy Bunel, Jingyue Lu, Ilker Turkaslan, Philip H.S. Torr, Pushmeet\n  Kohli, M. Pawan Kumar", "title": "Branch and Bound for Piecewise Linear Neural Network Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Learning and its potential use in many safety-critical\napplications has motivated research on formal verification of Neural Network\n(NN) models. In this context, verification involves proving or disproving that\nan NN model satisfies certain input-output properties. Despite the reputation\nof learned NN models as black boxes, and the theoretical hardness of proving\nuseful properties about them, researchers have been successful in verifying\nsome classes of models by exploiting their piecewise linear structure and\ntaking insights from formal methods such as Satisifiability Modulo Theory.\nHowever, these methods are still far from scaling to realistic neural networks.\nTo facilitate progress on this crucial area, we exploit the Mixed Integer\nLinear Programming (MIP) formulation of verification to propose a family of\nalgorithms based on Branch-and-Bound (BaB). We show that our family contains\nprevious verification methods as special cases. With the help of the BaB\nframework, we make three key contributions. Firstly, we identify new methods\nthat combine the strengths of multiple existing approaches, accomplishing\nsignificant performance improvements over previous state of the art. Secondly,\nwe introduce an effective branching strategy on ReLU non-linearities. This\nbranching strategy allows us to efficiently and successfully deal with high\ninput dimensional problems with convolutional network architecture, on which\nprevious methods fail frequently. Finally, we propose comprehensive test data\nsets and benchmarks which includes a collection of previously released\ntestcases. We use the data sets to conduct a thorough experimental comparison\nof existing and new algorithms and to provide an inclusive analysis of the\nfactors impacting the hardness of verification problems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 12:44:35 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:50:30 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 23:49:41 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 10:33:37 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bunel", "Rudy", ""], ["Lu", "Jingyue", ""], ["Turkaslan", "Ilker", ""], ["Torr", "Philip H. S.", ""], ["Kohli", "Pushmeet", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1909.06609", "submitter": "Fabrizio Frasca", "authors": "Fabrizio Frasca, Diego Galeano, Guadalupe Gonzalez, Ivan Laponogov,\n  Kirill Veselkov, Alberto Paccanaro and Michael M. Bronstein", "title": "Learning Interpretable Disease Self-Representations for Drug\n  Repositioning", "comments": "10 pages, 2 figures, v2 corresponds to the camera ready version\n  accepted at the Graph Representation Learning Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug repositioning is an attractive cost-efficient strategy for the\ndevelopment of treatments for human diseases. Here, we propose an interpretable\nmodel that learns disease self-representations for drug repositioning. Our\nself-representation model represents each disease as a linear combination of a\nfew other diseases. We enforce proximity in the learnt representations in a way\nto preserve the geometric structure of the human phenome network - a\ndomain-specific knowledge that naturally adds relational inductive bias to the\ndisease self-representations. We prove that our method is globally optimal and\nshow results outperforming state-of-the-art drug repositioning approaches. We\nfurther show that the disease self-representations are biologically\ninterpretable.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 15:11:37 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 21:28:29 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Frasca", "Fabrizio", ""], ["Galeano", "Diego", ""], ["Gonzalez", "Guadalupe", ""], ["Laponogov", "Ivan", ""], ["Veselkov", "Kirill", ""], ["Paccanaro", "Alberto", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "1909.06628", "submitter": "Sawyer Birnbaum", "authors": "Sawyer Birnbaum, Volodymyr Kuleshov, Zayd Enam, Pang Wei Koh, Stefano\n  Ermon", "title": "Temporal FiLM: Capturing Long-Range Sequence Dependencies with\n  Feature-Wise Modulations", "comments": "Presented at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations that accurately capture long-range dependencies in\nsequential inputs -- including text, audio, and genomic data -- is a key\nproblem in deep learning. Feed-forward convolutional models capture only\nfeature interactions within finite receptive fields while recurrent\narchitectures can be slow and difficult to train due to vanishing gradients.\nHere, we propose Temporal Feature-Wise Linear Modulation (TFiLM) -- a novel\narchitectural component inspired by adaptive batch normalization and its\nextensions -- that uses a recurrent neural network to alter the activations of\na convolutional model. This approach expands the receptive field of\nconvolutional sequence models with minimal computational overhead. Empirically,\nwe find that TFiLM significantly improves the learning speed and accuracy of\nfeed-forward neural networks on a range of generative and discriminative\nlearning tasks, including text classification and audio super-resolution\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 16:44:35 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 00:03:01 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 02:26:20 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Birnbaum", "Sawyer", ""], ["Kuleshov", "Volodymyr", ""], ["Enam", "Zayd", ""], ["Koh", "Pang Wei", ""], ["Ermon", "Stefano", ""]]}, {"id": "1909.06674", "submitter": "Edward Raff", "authors": "Edward Raff", "title": "A Step Toward Quantifying Independently Reproducible Machine Learning\n  Research", "comments": "to appear in Proc. Neural Information Processing Systems (NeurIPS),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes a paper independently reproducible? Debates on reproducibility\ncenter around intuition or assumptions but lack empirical results. Our field\nfocuses on releasing code, which is important, but is not sufficient for\ndetermining reproducibility. We take the first step toward a quantifiable\nanswer by manually attempting to implement 255 papers published from 1984 until\n2017, recording features of each paper, and performing statistical analysis of\nthe results. For each paper, we did not look at the authors code, if released,\nin order to prevent bias toward discrepancies between code and paper.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 20:53:16 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Raff", "Edward", ""]]}, {"id": "1909.06677", "submitter": "Charles Marx", "authors": "Charles T. Marx, Flavio du Pin Calmon, Berk Ustun", "title": "Predictive Multiplicity in Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction problems often admit competing models that perform almost equally\nwell. This effect challenges key assumptions in machine learning when competing\nmodels assign conflicting predictions. In this paper, we define predictive\nmultiplicity as the ability of a prediction problem to admit competing models\nwith conflicting predictions. We introduce formal measures to evaluate the\nseverity of predictive multiplicity and develop integer programming tools to\ncompute them exactly for linear classification problems. We apply our tools to\nmeasure predictive multiplicity in recidivism prediction problems. Our results\nshow that real-world datasets may admit competing models that assign wildly\nconflicting predictions, and motivate the need to measure and report predictive\nmultiplicity in model development.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 21:12:04 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 08:39:47 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 05:10:08 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 04:58:29 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Marx", "Charles T.", ""], ["Calmon", "Flavio du Pin", ""], ["Ustun", "Berk", ""]]}, {"id": "1909.06678", "submitter": "Khe Sim", "authors": "Khe Chai Sim, Petr Zadrazil, Fran\\c{c}oise Beaufays", "title": "An Investigation Into On-device Personalization of End-to-end Automatic\n  Speech Recognition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker-independent speech recognition systems trained with data from many\nusers are generally robust against speaker variability and work well for a\nlarge population of speakers. However, these systems do not always generalize\nwell for users with very different speech characteristics. This issue can be\naddressed by building personalized systems that are designed to work well for\neach specific user. In this paper, we investigate the idea of securely training\npersonalized end-to-end speech recognition models on mobile devices so that\nuser data and models never leave the device and are never stored on a server.\nWe study how the mobile training environment impacts performance by simulating\non-device data consumption. We conduct experiments using data collected from\nspeech impaired users for personalization. Our results show that\npersonalization achieved 63.7\\% relative word error rate reduction when trained\nin a server environment and 58.1% in a mobile environment. Moving to on-device\npersonalization resulted in 18.7% performance degradation, in exchange for\nimproved scalability and data privacy. To train the model on device, we split\nthe gradient computation into two and achieved 45% memory reduction at the\nexpense of 42% increase in training time.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 21:12:38 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Sim", "Khe Chai", ""], ["Zadrazil", "Petr", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "1909.06686", "submitter": "Shenyang Huang", "authors": "Shenyang Huang, Vincent Fran\\c{c}ois-Lavet, Guillaume Rabusseau", "title": "Neural Architecture Search for Class-incremental Learning", "comments": "8 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In class-incremental learning, a model learns continuously from a sequential\ndata stream in which new classes occur. Existing methods often rely on static\narchitectures that are manually crafted. These methods can be prone to capacity\nsaturation because a neural network's ability to generalize to new concepts is\nlimited by its fixed capacity. To understand how to expand a continual learner,\nwe focus on the neural architecture design problem in the context of\nclass-incremental learning: at each time step, the learner must optimize its\nperformance on all classes observed so far by selecting the most competitive\nneural architecture. To tackle this problem, we propose Continual Neural\nArchitecture Search (CNAS): an autoML approach that takes advantage of the\nsequential nature of class-incremental learning to efficiently and adaptively\nidentify strong architectures in a continual learning setting. We employ a task\nnetwork to perform the classification task and a reinforcement learning agent\nas the meta-controller for architecture search. In addition, we apply network\ntransformations to transfer weights from previous learning step and to reduce\nthe size of the architecture search space, thus saving a large amount of\ncomputational resources. We evaluate CNAS on the CIFAR-100 dataset under varied\nincremental learning scenarios with limited computational power (1 GPU).\nExperimental results demonstrate that CNAS outperforms architectures that are\noptimized for the entire dataset. In addition, CNAS is at least an order of\nmagnitude more efficient than naively using existing autoML methods.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 22:16:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Huang", "Shenyang", ""], ["Fran\u00e7ois-Lavet", "Vincent", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "1909.06695", "submitter": "Qian Yang", "authors": "Qian Yang, Zhouyuan Huo, Wenlin Wang, Heng Huang, Lawrence Carin", "title": "Ouroboros: On Accelerating Training of Transformer-Based Language Models", "comments": "To appear in the proceedings of Neural Information Processing Systems\n  Conference (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are essential for natural language processing (NLP) tasks,\nsuch as machine translation and text summarization. Remarkable performance has\nbeen demonstrated recently across many NLP domains via a Transformer-based\nlanguage model with over a billion parameters, verifying the benefits of model\nsize. Model parallelism is required if a model is too large to fit in a single\ncomputing device. Current methods for model parallelism either suffer from\nbackward locking in backpropagation or are not applicable to language models.\nWe propose the first model-parallel algorithm that speeds the training of\nTransformer-based language models. We also prove that our proposed algorithm is\nguaranteed to converge to critical points for non-convex problems. Extensive\nexperiments on Transformer and Transformer-XL language models demonstrate that\nthe proposed algorithm obtains a much faster speedup beyond data parallelism,\nwith comparable or better accuracy. Code to reproduce experiments is to be\nfound at \\url{https://github.com/LaraQianYang/Ouroboros}.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 23:21:56 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yang", "Qian", ""], ["Huo", "Zhouyuan", ""], ["Wang", "Wenlin", ""], ["Huang", "Heng", ""], ["Carin", "Lawrence", ""]]}, {"id": "1909.06708", "submitter": "Zhuohan Li", "authors": "Zhuohan Li, Zi Lin, Di He, Fei Tian, Tao Qin, Liwei Wang, Tie-Yan Liu", "title": "Hint-Based Training for Non-Autoregressive Machine Translation", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the unparallelizable nature of the autoregressive factorization,\nAutoRegressive Translation (ART) models have to generate tokens sequentially\nduring decoding and thus suffer from high inference latency. Non-AutoRegressive\nTranslation (NART) models were proposed to reduce the inference time, but could\nonly achieve inferior translation accuracy. In this paper, we proposed a novel\napproach to leveraging the hints from hidden states and word alignments to help\nthe training of NART models. The results achieve significant improvement over\nprevious NART models for the WMT14 En-De and De-En datasets and are even\ncomparable to a strong LSTM-based ART baseline but one order of magnitude\nfaster in inference.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 01:39:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Li", "Zhuohan", ""], ["Lin", "Zi", ""], ["He", "Di", ""], ["Tian", "Fei", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1909.06717", "submitter": "Yuhong Guo", "authors": "Yan Yan and Yuhong Guo", "title": "Adversarial Partial Multi-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial multi-label learning (PML), which tackles the problem of learning\nmulti-label prediction models from instances with overcomplete noisy\nannotations, has recently started gaining attention from the research\ncommunity. In this paper, we propose a novel adversarial learning model,\nPML-GAN, under a generalized encoder-decoder framework for partial multi-label\nlearning. The PML-GAN model uses a disambiguation network to identify noisy\nlabels and uses a multi-label prediction network to map the training instances\nto the disambiguated label vectors, while deploying a generative adversarial\nnetwork as an inverse mapping from label vectors to data samples in the input\nfeature space. The learning of the overall model corresponds to a minimax\nadversarial game, which enhances the correspondence of input features with the\noutput labels in a bi-directional mapping. Extensive experiments are conducted\non multiple datasets, while the proposed model demonstrates the\nstate-of-the-art performance for partial multi-label learning.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 02:34:07 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 04:11:26 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Yan", "Yan", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.06718", "submitter": "Rheeya Uppaal", "authors": "Rheeya Uppaal", "title": "LRS-DAG: Low Resource Supervised Domain Adaptation with Generalization\n  Across Domains", "comments": "10 pages, 3 figures. Accepted to NewInML Workshop at NeurIPS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current state of the art methods in Domain Adaptation follow adversarial\napproaches, making training a challenge. Existing non-adversarial methods learn\nmappings between the source and target domains, to achieve reasonable\nperformance. However, even these methods do not focus on a key aspect:\nmaintaining performance on the source domain, even after optimizing over the\ntarget domain. Additionally, there exist very few methods in low resource\nsupervised domain adaptation. This work proposes a method, LRS-DAG, that aims\nto solve these current issues in the field. By adding a set of \"encoder layers\"\nwhich map the target domain to the source, and can be removed when dealing\ndirectly with the source data, the model learns to perform optimally on both\ndomains. LRS-DAG showcases its uniqueness by being a new algorithm for low\nresource domain adaptation which maintains performance over the source domain,\nwith a new metric for learning mappings between domains being introduced. We\nshow that, in the case of FCNs, when transferring from MNIST to SVHN, LRS-DAG\nperforms comparably to fine tuning, with the advantage of maintaining\nperformance over the source domain. LRS-DAG outperforms fine tuning when\ntransferring to a synthetic dataset similar to MNIST, which is a setting more\nrepresentative of low resource supervised domain adaptation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 02:38:49 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 03:57:30 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Uppaal", "Rheeya", ""]]}, {"id": "1909.06724", "submitter": "Weiyu Li", "authors": "Weiyu Li, Yaohua Liu, Zhi Tian, Qing Ling", "title": "Communication-Censored Linearized ADMM for Decentralized Consensus\n  Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSIPN.2019.2957719", "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a communication- and computation-efficient\nalgorithm to solve a convex consensus optimization problem defined over a\ndecentralized network. A remarkable existing algorithm to solve this problem is\nthe alternating direction method of multipliers (ADMM), in which at every\niteration every node updates its local variable through combining neighboring\nvariables and solving an optimization subproblem. The proposed algorithm,\ncalled as COmmunication-censored Linearized ADMM (COLA), leverages a\nlinearization technique to reduce the iteration-wise computation cost of ADMM\nand uses a communication-censoring strategy to alleviate the communication\ncost. To be specific, COLA introduces successive linearization approximations\nto the local cost functions such that the resultant computation is first-order\nand light-weight. Since the linearization technique slows down the convergence\nspeed, COLA further adopts the communication-censoring strategy to avoid\ntransmissions of less informative messages. A node is allowed to transmit only\nif the distance between the current local variable and its previously\ntransmitted one is larger than a censoring threshold. COLA is proven to be\nconvergent when the local cost functions have Lipschitz continuous gradients\nand the censoring threshold is summable. When the local cost functions are\nfurther strongly convex, we establish the linear (sublinear) convergence rate\nof COLA, given that the censoring threshold linearly (sublinearly) decays to 0.\nNumerical experiments corroborate with the theoretical findings and demonstrate\nthe satisfactory communication-computation tradeoff of COLA.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 03:39:46 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Li", "Weiyu", ""], ["Liu", "Yaohua", ""], ["Tian", "Zhi", ""], ["Ling", "Qing", ""]]}, {"id": "1909.06730", "submitter": "Xiuting Li", "authors": "Ye Yuan, Junlin Li, Liang Li, Frank Jiang, Xiuchuan Tang, Fumin Zhang,\n  Sheng Liu, Jorge Goncalves, Henning U.Voss, Xiuting Li, J\\\"urgen Kurths, and\n  Han Ding", "title": "Machine Discovery of Partial Differential Equations from Spatiotemporal\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study presents a general framework for discovering underlying Partial\nDifferential Equations (PDEs) using measured spatiotemporal data. The method,\ncalled Sparse Spatiotemporal System Discovery ($\\text{S}^3\\text{d}$), decides\nwhich physical terms are necessary and which can be removed (because they are\nphysically negligible in the sense that they do not affect the dynamics too\nmuch) from a pool of candidate functions. The method is built on the recent\ndevelopment of Sparse Bayesian Learning; which enforces the sparsity in the\nto-be-identified PDEs, and therefore can balance the model complexity and\nfitting error with theoretical guarantees. Without leveraging prior knowledge\nor assumptions in the discovery process, we use an automated approach to\ndiscover ten types of PDEs, including the famous Navier-Stokes and sine-Gordon\nequations, from simulation data alone. Moreover, we demonstrate our data-driven\ndiscovery process with the Complex Ginzburg-Landau Equation (CGLE) using data\nmeasured from a traveling-wave convection experiment. Our machine discovery\napproach presents solutions that has the potential to inspire, support and\nassist physicists for the establishment of physical laws from measured\nspatiotemporal data, especially in notorious fields that are often too complex\nto allow a straightforward establishment of physical law, such as biophysics,\nfluid dynamics, neuroscience or nonlinear optics.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 04:30:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yuan", "Ye", ""], ["Li", "Junlin", ""], ["Li", "Liang", ""], ["Jiang", "Frank", ""], ["Tang", "Xiuchuan", ""], ["Zhang", "Fumin", ""], ["Liu", "Sheng", ""], ["Goncalves", "Jorge", ""], ["Voss", "Henning U.", ""], ["Li", "Xiuting", ""], ["Kurths", "J\u00fcrgen", ""], ["Ding", "Han", ""]]}, {"id": "1909.06737", "submitter": "Dongha Kim", "authors": "Dongha Kim, Yongchan Choi, Yongdai Kim", "title": "Understanding and Improving Virtual Adversarial Training", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-supervised learning, virtual adversarial training (VAT) approach is\none of the most attractive method due to its intuitional simplicity and\npowerful performances. VAT finds a classifier which is robust to data\nperturbation toward the adversarial direction. In this study, we provide a\nfundamental explanation why VAT works well in semi-supervised learning case and\npropose new techniques which are simple but powerful to improve the VAT method.\nEspecially we employ the idea of Bad GAN approach, which utilizes bad samples\ndistributed on complement of the support of the input data, without any\nadditional deep generative architectures. We generate bad samples of\nhigh-quality by use of the adversarial training used in VAT and also give\ntheoretical explanations why the adversarial training is good at both\ngenerating bad samples. An advantage of our proposed method is to achieve the\ncompetitive performances compared with other recent studies with much fewer\ncomputations. We demonstrate advantages our method by various experiments with\nwell known benchmark image datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 05:03:08 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kim", "Dongha", ""], ["Choi", "Yongchan", ""], ["Kim", "Yongdai", ""]]}, {"id": "1909.06769", "submitter": "Voot Tangkaratt", "authors": "Voot Tangkaratt, Bo Han, Mohammad Emtiyaz Khan, and Masashi Sugiyama", "title": "VILD: Variational Imitation Learning with Diverse-quality Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of imitation learning (IL) is to learn a good policy from\nhigh-quality demonstrations. However, the quality of demonstrations in reality\ncan be diverse, since it is easier and cheaper to collect demonstrations from a\nmix of experts and amateurs. IL in such situations can be challenging,\nespecially when the level of demonstrators' expertise is unknown. We propose a\nnew IL method called \\underline{v}ariational \\underline{i}mitation\n\\underline{l}earning with \\underline{d}iverse-quality demonstrations (VILD),\nwhere we explicitly model the level of demonstrators' expertise with a\nprobabilistic graphical model and estimate it along with a reward function. We\nshow that a naive approach to estimation is not suitable to large state and\naction spaces, and fix its issues by using a variational approach which can be\neasily implemented using existing reinforcement learning methods. Experiments\non continuous-control benchmarks demonstrate that VILD outperforms\nstate-of-the-art methods. Our work enables scalable and data-efficient IL under\nmore realistic settings than before.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 09:42:33 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Tangkaratt", "Voot", ""], ["Han", "Bo", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1909.06772", "submitter": "Orpaz Goldstein", "authors": "Orpaz Goldstein, Mohammad Kachuee, Kimmo Karkkainen, Majid Sarrafzadeh", "title": "Target-Focused Feature Selection Using a Bayesian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world scenarios where data is high dimensional, test time\nacquisition of features is a non-trivial task due to costs associated with\nfeature acquisition and evaluating feature value. The need for highly confident\nmodels with an extremely frugal acquisition of features can be addressed by\nallowing a feature selection method to become target aware. We introduce an\napproach to feature selection that is based on Bayesian learning, allowing us\nto report target-specific levels of uncertainty, false positive, and false\nnegative rates. In addition, measuring uncertainty lifts the restriction on\nfeature selection being target agnostic, allowing for feature acquisition based\non a single target of focus out of many. We show that acquiring features for a\nspecific target is at least as good as common linear feature selection\napproaches for small non-sparse datasets, and surpasses these when faced with\nreal-world healthcare data that is larger in scale and in sparseness.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 09:58:35 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Goldstein", "Orpaz", ""], ["Kachuee", "Mohammad", ""], ["Karkkainen", "Kimmo", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1909.06788", "submitter": "Zhenyu Liao", "authors": "Zhenyu Liao, Romain Couillet", "title": "Inner-product Kernels are Asymptotically Equivalent to Binary Discrete\n  Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the eigenspectrum of the inner product-type kernel\nmatrix $\\sqrt{p} \\mathbf{K}=\\{f( \\mathbf{x}_i^{\\sf T}\n\\mathbf{x}_j/\\sqrt{p})\\}_{i,j=1}^n $ under a binary mixture model in the high\ndimensional regime where the number of data $n$ and their dimension $p$ are\nboth large and comparable. Based on recent advances in random matrix theory, we\nshow that, for a wide range of nonlinear functions $f$, the eigenspectrum\nbehavior is asymptotically equivalent to that of an (at most) cubic function.\nThis sheds new light on the understanding of nonlinearity in large dimensional\nproblems. As a byproduct, we propose a simple function prototype valued in $\n(-1,0,1) $ that, while reducing both storage memory and running time, achieves\nthe same (asymptotic) classification performance as any arbitrary function $f$.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 11:52:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liao", "Zhenyu", ""], ["Couillet", "Romain", ""]]}, {"id": "1909.06841", "submitter": "Ernesto Araya Valdivia", "authors": "Ernesto Araya and Yohann De Castro", "title": "Latent Distance Estimation for Random Geometric Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random geometric graphs are a popular choice for a latent points generative\nmodel for networks. Their definition is based on a sample of $n$ points\n$X_1,X_2,\\cdots,X_n$ on the Euclidean sphere~$\\mathbb{S}^{d-1}$ which\nrepresents the latent positions of nodes of the network. The connection\nprobabilities between the nodes are determined by an unknown function (referred\nto as the \"link\" function) evaluated at the distance between the latent points.\nWe introduce a spectral estimator of the pairwise distance between latent\npoints and we prove that its rate of convergence is the same as the\nnonparametric estimation of a function on $\\mathbb{S}^{d-1}$, up to a\nlogarithmic factor. In addition, we provide an efficient spectral algorithm to\ncompute this estimator without any knowledge on the nonparametric link\nfunction. As a byproduct, our method can also consistently estimate the\ndimension $d$ of the latent space.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 17:30:03 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Araya", "Ernesto", ""], ["De Castro", "Yohann", ""]]}, {"id": "1909.06844", "submitter": "Michael Schaarschmidt", "authors": "Michael Schaarschmidt, Kai Fricke, Eiko Yoneki", "title": "Wield: Systematic Reinforcement Learning With Progressive Randomization", "comments": "10 pages, draft paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning frameworks have introduced abstractions to implement\nand execute algorithms at scale. They assume standardized simulator interfaces\nbut are not concerned with identifying suitable task representations. We\npresent Wield, a first-of-its kind system to facilitate task design for\npractical reinforcement learning. Through software primitives, Wield enables\npractitioners to decouple system-interface and deployment-specific\nconfiguration from state and action design. To guide experimentation, Wield\nfurther introduces a novel task design protocol and classification scheme\ncentred around staged randomization to incrementally evaluate model\ncapabilities.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 17:36:26 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Schaarschmidt", "Michael", ""], ["Fricke", "Kai", ""], ["Yoneki", "Eiko", ""]]}, {"id": "1909.06851", "submitter": "Zhizhong Li", "authors": "Lanxin Lei and Zhizhong Li and Dahua Lin", "title": "Biased Estimates of Advantages over Path Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of advantage is crucial for a number of reinforcement learning\nalgorithms, as it directly influences the choices of future paths. In this\nwork, we propose a family of estimates based on the order statistics over the\npath ensemble, which allows one to flexibly drive the learning process, towards\nor against risks. On top of this formulation, we systematically study the\nimpacts of different methods for estimating advantages. Our findings reveal\nthat biased estimates, when chosen appropriately, can result in significant\nbenefits. In particular, for the environments with sparse rewards, optimistic\nestimates would lead to more efficient exploration of the policy space; while\nfor those where individual actions can have critical impacts, conservative\nestimates are preferable. On various benchmarks, including MuJoCo continuous\ncontrol, Terrain locomotion, Atari games, and sparse-reward environments, the\nproposed biased estimation schemes consistently demonstrate improvement over\nmainstream methods, not only accelerating the learning process but also\nobtaining substantial performance gains.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 18:16:18 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lei", "Lanxin", ""], ["Li", "Zhizhong", ""], ["Lin", "Dahua", ""]]}, {"id": "1909.06859", "submitter": "Shihao Zou", "authors": "Shihao Zou, Zhonghua Li, Mohammad Akbari, Jun Wang, Peng Zhang", "title": "MarlRank: Multi-agent Reinforced Learning to Rank", "comments": "CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When estimating the relevancy between a query and a document, ranking models\nlargely neglect the mutual information among documents. A common wisdom is that\nif two documents are similar in terms of the same query, they are more likely\nto have similar relevance score. To mitigate this problem, in this paper, we\npropose a multi-agent reinforced ranking model, named MarlRank. In particular,\nby considering each document as an agent, we formulate the ranking process as a\nmulti-agent Markov Decision Process (MDP), where the mutual interactions among\ndocuments are incorporated in the ranking process. To compute the ranking list,\neach document predicts its relevance to a query considering not only its own\nquery-document features but also its similar documents features and actions. By\ndefining reward as a function of NDCG, we can optimize our model directly on\nthe ranking performance measure. Our experimental results on two LETOR\nbenchmark datasets show that our model has significant performance gains over\nthe state-of-art baselines. We also find that the NDCG shows an overall\nincreasing trend along with the step of interactions, which demonstrates that\nthe mutual information among documents helps improve the ranking performance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:08:08 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zou", "Shihao", ""], ["Li", "Zhonghua", ""], ["Akbari", "Mohammad", ""], ["Wang", "Jun", ""], ["Zhang", "Peng", ""]]}, {"id": "1909.06860", "submitter": "Guido F. Montufar", "authors": "Alex Tong Lin, Yonatan Dukler, Wuchen Li, Guido Montufar", "title": "Wasserstein Diffusion Tikhonov Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose regularization strategies for learning discriminative models that\nare robust to in-class variations of the input data. We use the Wasserstein-2\ngeometry to capture semantically meaningful neighborhoods in the space of\nimages, and define a corresponding input-dependent additive noise data\naugmentation model. Expanding and integrating the augmented loss yields an\neffective Tikhonov-type Wasserstein diffusion smoothness regularizer. This\napproach allows us to apply high levels of regularization and train functions\nthat have low variability within classes but remain flexible across classes. We\nprovide efficient methods for computing the regularizer at a negligible cost in\ncomparison to training with adversarial data augmentation. Initial experiments\ndemonstrate improvements in generalization performance under adversarial\nperturbations and also large in-class variations of the input data.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:10:16 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lin", "Alex Tong", ""], ["Dukler", "Yonatan", ""], ["Li", "Wuchen", ""], ["Montufar", "Guido", ""]]}, {"id": "1909.06861", "submitter": "Guy Rom", "authors": "Vincent Cohen-Addad, Benjamin Guedj, Varun Kanade, Guy Rom", "title": "Online k-means Clustering", "comments": "11 pages, 1 figure", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS), PMLR 130:1126-1134, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online clustering where a clustering algorithm has to\nassign a new point that arrives to one of $k$ clusters. The specific\nformulation we use is the $k$-means objective: At each time step the algorithm\nhas to maintain a set of k candidate centers and the loss incurred is the\nsquared distance between the new point and the closest center. The goal is to\nminimize regret with respect to the best solution to the $k$-means objective\n($\\mathcal{C}$) in hindsight. We show that provided the data lies in a bounded\nregion, an implementation of the Multiplicative Weights Update Algorithm (MWUA)\nusing a discretized grid achieves a regret bound of $\\tilde{O}(\\sqrt{T})$ in\nexpectation. We also present an online-to-offline reduction that shows that an\nefficient no-regret online algorithm (despite being allowed to choose a\ndifferent set of candidate centres at each round) implies an offline efficient\nalgorithm for the $k$-means problem. In light of this hardness, we consider the\nslightly weaker requirement of comparing regret with respect to $(1 + \\epsilon)\n\\mathcal{C}$ and present a no-regret algorithm with runtime\n$O\\left(T(\\mathrm{poly}(log(T),k,d,1/\\epsilon)^{k(d+O(1))}\\right)$. Our\nalgorithm is based on maintaining an incremental coreset and an adaptive\nvariant of the MWUA. We show that na\\\"{i}ve online algorithms, such as\n\\emph{Follow The Leader}, fail to produce sublinear regret in the worst case.\nWe also report preliminary experiments with synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:20:36 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Guedj", "Benjamin", ""], ["Kanade", "Varun", ""], ["Rom", "Guy", ""]]}, {"id": "1909.06865", "submitter": "Miles Q. Li", "authors": "Miles Q. Li, Benjamin C. M. Fung, Philippe Charland, Steven H.H. Ding", "title": "I-MAD: Interpretable Malware Detector Using Galaxy Transformer", "comments": "Published by Elsevier Computers & Security", "journal-ref": null, "doi": "10.1016/j.cose.2021.102371", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware currently presents a number of serious threats to computer users.\nSignature-based malware detection methods are limited in detecting new malware\nsamples that are significantly different from known ones. Therefore, machine\nlearning-based methods have been proposed, but there are two challenges these\nmethods face. The first is to model the full semantics behind the assembly code\nof malware. The second challenge is to provide interpretable results while\nkeeping excellent detection performance. In this paper, we propose an\nInterpretable MAlware Detector (I-MAD) that outperforms state-of-the-art static\nmalware detection models regarding accuracy with excellent interpretability. To\nimprove the detection performance, I-MAD incorporates a novel network component\ncalled the Galaxy Transformer network that can understand assembly code at the\nbasic block, function, and executable levels. It also incorporates our proposed\ninterpretable feed-forward neural network to provide interpretations for its\ndetection results by quantifying the impact of each feature with respect to the\nprediction. Experiment results show that our model significantly outperforms\nexisting state-of-the-art static malware detection models and presents\nmeaningful interpretations.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:40:38 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 14:37:26 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 01:33:26 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Li", "Miles Q.", ""], ["Fung", "Benjamin C. M.", ""], ["Charland", "Philippe", ""], ["Ding", "Steven H. H.", ""]]}, {"id": "1909.06868", "submitter": "Ali Khodadadi", "authors": "Ali Khodadadi, Seyed Abbas Hosseini, Ehsan Pajouheshgar, Farnam\n  Mansouri, and Hamid R. Rabiee", "title": "ChOracle: A Unified Statistical Framework for Churn Prediction", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User churn is an important issue in online services that threatens the health\nand profitability of services. Most of the previous works on churn prediction\nconvert the problem into a binary classification task where the users are\nlabeled as churned and non-churned. More recently, some works have tried to\nconvert the user churn prediction problem into the prediction of user return\ntime. In this approach which is more realistic in real world online services,\nat each time-step the model predicts the user return time instead of predicting\na churn label. However, the previous works in this category suffer from lack of\ngenerality and require high computational complexity. In this paper, we\nintroduce \\emph{ChOracle}, an oracle that predicts the user churn by modeling\nthe user return times to service by utilizing a combination of Temporal Point\nProcesses and Recurrent Neural Networks. Moreover, we incorporate latent\nvariables into the proposed recurrent neural network to model the latent user\nloyalty to the system. We also develop an efficient approximate variational\nalgorithm for learning parameters of the proposed RNN by using back propagation\nthrough time. Finally, we demonstrate the superior performance of ChOracle on a\nwide variety of real world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:59:13 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Khodadadi", "Ali", ""], ["Hosseini", "Seyed Abbas", ""], ["Pajouheshgar", "Ehsan", ""], ["Mansouri", "Farnam", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1909.06872", "submitter": "Gilad Cohen", "authors": "Gilad Cohen, Guillermo Sapiro, Raja Giryes", "title": "Detecting Adversarial Samples Using Influence Functions and Nearest\n  Neighbors", "comments": "Paper accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are notorious for their vulnerability to\nadversarial attacks, which are small perturbations added to their input images\nto mislead their prediction. Detection of adversarial examples is, therefore, a\nfundamental requirement for robust classification frameworks. In this work, we\npresent a method for detecting such adversarial attacks, which is suitable for\nany pre-trained neural network classifier. We use influence functions to\nmeasure the impact of every training sample on the validation set data. From\nthe influence scores, we find the most supportive training samples for any\ngiven validation example. A k-nearest neighbor (k-NN) model fitted on the DNN's\nactivation layers is employed to search for the ranking of these supporting\ntraining samples. We observe that these samples are highly correlated with the\nnearest neighbors of the normal inputs, while this correlation is much weaker\nfor adversarial inputs. We train an adversarial detector using the k-NN ranks\nand distances and show that it successfully distinguishes adversarial examples,\ngetting state-of-the-art results on six attack methods with three datasets.\nCode is available at https://github.com/giladcohen/NNIF_adv_defense.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 20:07:48 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 10:41:34 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Cohen", "Gilad", ""], ["Sapiro", "Guillermo", ""], ["Giryes", "Raja", ""]]}, {"id": "1909.06878", "submitter": "Yilun Du", "authors": "Yilun Du, Toru Lin, Igor Mordatch", "title": "Model Based Planning with Energy Based Models", "comments": "CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based planning holds great promise for improving both sample efficiency\nand generalization in reinforcement learning (RL). We show that energy-based\nmodels (EBMs) are a promising class of models to use for model-based planning.\nEBMs naturally support inference of intermediate states given start and goal\nstate distributions. We provide an online algorithm to train EBMs while\ninteracting with the environment, and show that EBMs allow for significantly\nbetter online learning than corresponding feed-forward networks. We further\nshow that EBMs support maximum entropy state inference and are able to generate\ndiverse state space plans. We show that inference purely in state space -\nwithout planning actions - allows for better generalization to previously\nunseen obstacles in the environment and prevents the planner from exploiting\nthe dynamics model by applying uncharacteristic action sequences. Finally, we\nshow that online EBM training naturally leads to intentionally planned state\nexploration which performs significantly better than random exploration.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 20:28:03 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 05:02:16 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Du", "Yilun", ""], ["Lin", "Toru", ""], ["Mordatch", "Igor", ""]]}, {"id": "1909.06893", "submitter": "Daniel Wilke", "authors": "Younghwan Chae and Daniel N. Wilke", "title": "Empirical study towards understanding line search approximations for\n  training neural networks", "comments": "30 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing appropriate step sizes is critical for reducing the computational\ncost of training large-scale neural network models. Mini-batch sub-sampling\n(MBSS) is often employed for computational tractability. However, MBSS\nintroduces a sampling error, that can manifest as a bias or variance in a line\nsearch. This is because MBSS can be performed statically, where the mini-batch\nis updated only when the search direction changes, or dynamically, where the\nmini-batch is updated every-time the function is evaluated. Static MBSS results\nin a smooth loss function along a search direction, reflecting low variance but\nlarge bias in the estimated \"true\" (or full batch) minimum. Conversely, dynamic\nMBSS results in a point-wise discontinuous function, with computable gradients\nusing backpropagation, along a search direction, reflecting high variance but\nlower bias in the estimated \"true\" (or full batch) minimum. In this study,\nquadratic line search approximations are considered to study the quality of\nfunction and derivative information to construct approximations for dynamic\nMBSS loss functions. An empirical study is conducted where function and\nderivative information are enforced in various ways for the quadratic\napproximations. The results for various neural network problems show that being\nselective on what information is enforced helps to reduce the variance of\npredicted step sizes.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 22:01:57 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chae", "Younghwan", ""], ["Wilke", "Daniel N.", ""]]}, {"id": "1909.06918", "submitter": "Konstantin Mishchenko", "authors": "Konstantin Mishchenko", "title": "Sinkhorn Algorithm as a Special Case of Stochastic Mirror Descent", "comments": "7 pages, 2 algorithms, 1 theorem, 1 lemma", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new perspective on the celebrated Sinkhorn algorithm by showing\nthat is a special case of incremental/stochastic mirror descent. In order to\nsee this, one should simply plug Kullback-Leibler divergence in both mirror map\nand the objective function. Since the problem has unbounded domain, the\nobjective function is neither smooth nor it has bounded gradients. However, one\ncan still approach the problem using the notion of relative smoothness,\nobtaining that the stochastic objective is 1-relative smooth. The discovered\nequivalence allows us to propose 1) new methods for optimal transport, 2) an\nextension of Sinkhorn algorithm beyond two constraints.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 00:58:17 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mishchenko", "Konstantin", ""]]}, {"id": "1909.06927", "submitter": "Ece Calikus", "authors": "Ece Calikus, Slawomir Nowaczyk, Anita Sant'Anna and Onur Dikmen", "title": "No Free Lunch But A Cheaper Supper: A General Framework for Streaming\n  Anomaly Detection", "comments": "Submitted to Expert Systems with Applications", "journal-ref": null, "doi": "10.1016/j.eswa.2020.113453", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been increased research interest in detecting\nanomalies in temporal streaming data. A variety of algorithms have been\ndeveloped in the data mining community, which can be divided into two\ncategories (i.e., general and ad hoc). In most cases, general approaches assume\nthe one-size-fits-all solution model where a single anomaly detector can detect\nall anomalies in any domain. To date, there exists no single general method\nthat has been shown to outperform the others across different anomaly types,\nuse cases and datasets. In this paper, we propose SAFARI, a general framework\nformulated by abstracting and unifying the fundamental tasks in streaming\nanomaly detection, which provides a flexible and extensible anomaly detection\nprocedure to overcome the limitations of one-size-fits-all solutions. SAFARI\nhelps to facilitate more elaborate algorithm comparisons by allowing us to\nisolate the effects of shared and unique characteristics of different\nalgorithms on detection performance. Using SAFARI, we have implemented various\nanomaly detectors and identified a research gap that motivates us to propose a\nnovel learning strategy in this work. We conducted an extensive evaluation\nstudy of 20 detectors that are composed using SAFARI and compared their\nperformances using real-world benchmark datasets with different properties. The\nresults indicate that there is no single superior detector that works well for\nevery case, proving our hypothesis that \"there is no free lunch\" in the\nstreaming anomaly detection world. Finally, we discuss the benefits and\ndrawbacks of each method in-depth and draw a set of conclusions to guide future\nusers of SAFARI.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 01:40:02 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 12:38:15 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 17:06:44 GMT"}, {"version": "v4", "created": "Sat, 18 Apr 2020 16:46:44 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Calikus", "Ece", ""], ["Nowaczyk", "Slawomir", ""], ["Sant'Anna", "Anita", ""], ["Dikmen", "Onur", ""]]}, {"id": "1909.06929", "submitter": "Andrew Steen", "authors": "James K. Senter, Taylor M. Royalty, Andrew D. Steen, Amir Sadovnik", "title": "Unaligned Sequence Similarity Search Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene annotation has traditionally required direct comparison of DNA sequences\nbetween an unknown gene and a database of known ones using string comparison\nmethods. However, these methods do not provide useful information when a gene\ndoes not have a close match in the database. In addition, each comparison can\nbe costly when the database is large since it requires alignments and a series\nof string comparisons. In this work we propose a novel approach: using\nrecurrent neural networks to embed DNA or amino-acid sequences in a\nlow-dimensional space in which distances correlate with functional similarity.\nThis embedding space overcomes both shortcomings of the method of aligning\nsequences and comparing homology. First, it allows us to obtain information\nabout genes which do not have exact matches by measuring their similarity to\nother ones in the database. If our database is labeled this can provide labels\nfor a query gene as is done in traditional methods. However, even if the\ndatabase is unlabeled it allows us to find clusters and infer some\ncharacteristics of the gene population. In addition, each comparison is much\nfaster than traditional methods since the distance metric is reduced to the\nEuclidean distance, and thus efficient approximate nearest neighbor algorithms\ncan be used to find the best match. We present results showing the advantage of\nour algorithm. More specifically we show how our embedding can be useful for\nboth classification tasks when our labels are known, and clustering tasks where\nour sequences belong to classes which have not been seen before.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 01:42:17 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Senter", "James K.", ""], ["Royalty", "Taylor M.", ""], ["Steen", "Andrew D.", ""], ["Sadovnik", "Amir", ""]]}, {"id": "1909.06930", "submitter": "Rudrajit Das", "authors": "Rudrajit Das and Subhasis Chaudhuri", "title": "On the Separability of Classes with the Cross-Entropy Loss Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the separability of classes with the cross-entropy\nloss function for classification problems by theoretically analyzing the\nintra-class distance and inter-class distance (i.e. the distance between any\ntwo points belonging to the same class and different classes, respectively) in\nthe feature space, i.e. the space of representations learnt by neural networks.\nSpecifically, we consider an arbitrary network architecture having a fully\nconnected final layer with Softmax activation and trained using the\ncross-entropy loss. We derive expressions for the value and the distribution of\nthe squared L2 norm of the product of a network dependent matrix and a random\nintra-class and inter-class distance vector (i.e. the vector between any two\npoints belonging to the same class and different classes), respectively, in the\nlearnt feature space (or the transformation of the original data) just before\nSoftmax activation, as a function of the cross-entropy loss value. The main\nresult of our analysis is the derivation of a lower bound for the probability\nwith which the inter-class distance is more than the intra-class distance in\nthis feature space, as a function of the loss value. We do so by leveraging\nsome empirical statistical observations with mild assumptions and sound\ntheoretical analysis. As per intuition, the probability with which the\ninter-class distance is more than the intra-class distance decreases as the\nloss value increases, i.e. the classes are better separated when the loss value\nis low. To the best of our knowledge, this is the first work of theoretical\nnature trying to explain the separability of classes in the feature space\nlearnt by neural networks trained with the cross-entropy loss function.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 01:47:24 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Das", "Rudrajit", ""], ["Chaudhuri", "Subhasis", ""]]}, {"id": "1909.06940", "submitter": "Zhao Kang", "authors": "Zhao Kang and Guoxin Shi and Shudong Huang and Wenyu Chen and Xiaorong\n  Pu and Joey Tianyi Zhou and Zenglin Xu", "title": "Multi-graph Fusion for Multi-view Spectral Clustering", "comments": "submitted to Knowledge-based Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A panoply of multi-view clustering algorithms has been developed to deal with\nprevalent multi-view data. Among them, spectral clustering-based methods have\ndrawn much attention and demonstrated promising results recently. Despite\nprogress, there are still two fundamental questions that stay unanswered to\ndate. First, how to fuse different views into one graph. More often than not,\nthe similarities between samples may be manifested differently by different\nviews. Many existing algorithms either simply take the average of multiple\nviews or just learn a common graph. These simple approaches fail to consider\nthe flexible local manifold structures of all views. Hence, the rich\nheterogeneous information is not fully exploited. Second, how to learn the\nexplicit cluster structure. Most existing methods don't pay attention to the\nquality of the graphs and perform graph learning and spectral clustering\nseparately. Those unreliable graphs might lead to suboptimal clustering\nresults. To fill these gaps, in this paper, we propose a novel multi-view\nspectral clustering model which performs graph fusion and spectral clustering\nsimultaneously. The fusion graph approximates the original graph of each\nindividual view but maintains an explicit cluster structure. Experiments on\nfour widely used data sets confirm the superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 02:22:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kang", "Zhao", ""], ["Shi", "Guoxin", ""], ["Huang", "Shudong", ""], ["Chen", "Wenyu", ""], ["Pu", "Xiaorong", ""], ["Zhou", "Joey Tianyi", ""], ["Xu", "Zenglin", ""]]}, {"id": "1909.06945", "submitter": "Sim\\'on Rodr\\'iguez", "authors": "Sim\\'on Rodr\\'iguez Santana, Daniel Hern\\'andez-Lobato", "title": "Adversarial $\\alpha$-divergence Minimization for Bayesian Approximate\n  Inference", "comments": "47 pages, 10 figures (41 pages for the main article, 6 for the\n  supplementary material)", "journal-ref": null, "doi": "10.1016/j.neucom.2020.09.076", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are popular state-of-the-art models for many different\ntasks.They are often trained via back-propagation to find a value of the\nweights that correctly predicts the observed data. Although back-propagation\nhas shown good performance in many applications, it cannot easily output an\nestimate of the uncertainty in the predictions made. Estimating the uncertainty\nin the predictions is a critical aspect with important applications, and one\nmethod to obtain this information is following a Bayesian approach to estimate\na posterior distribution on the model parameters. This posterior distribution\nsummarizes which parameter values are compatible with the data, but is usually\nintractable and has to be approximated. Several mechanisms have been considered\nfor solving this problem. We propose here a general method for approximate\nBayesian inference that is based on minimizing{\\alpha}-divergences and that\nallows for flexible approximate distributions. The method is evaluated in the\ncontext of Bayesian neural networks on extensive experiments. The results show\nthat, in regression problems, it often gives better performance in terms of the\ntest log-likelihoodand sometimes in terms of the squared error. In\nclassification problems, however, it gives competitive results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 08:27:58 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 08:39:51 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 16:45:25 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Santana", "Sim\u00f3n Rodr\u00edguez", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "1909.06946", "submitter": "Luo Luo", "authors": "Luo Luo, Cheng Chen, Yujun Li, Guangzeng Xie, Zhihua Zhang", "title": "A Stochastic Proximal Point Algorithm for Saddle-Point Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider saddle point problems which objective functions are the average\nof $n$ strongly convex-concave individual components. Recently, researchers\nexploit variance reduction methods to solve such problems and achieve\nlinear-convergence guarantees. However, these methods have a slow convergence\nwhen the condition number of the problem is very large. In this paper, we\npropose a stochastic proximal point algorithm, which accelerates the variance\nreduction method SAGA for saddle point problems. Compared with the catalyst\nframework, our algorithm reduces a logarithmic term of condition number for the\niteration complexity. We adopt our algorithm to policy evaluation and the\nempirical results show that our method is much more efficient than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:50:13 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Luo", "Luo", ""], ["Chen", "Cheng", ""], ["Li", "Yujun", ""], ["Xie", "Guangzeng", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1909.06964", "submitter": "Qing Yang", "authors": "Qing Yang, Jiachen Mao, Zuoguan Wang, Hai Li", "title": "DASNet: Dynamic Activation Sparsity for Neural Network Efficiency\n  Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the execution speed and efficiency of neural networks in embedded\nsystems, it is crucial to decrease the model size and computational complexity.\nIn addition to conventional compression techniques, e.g., weight pruning and\nquantization, removing unimportant activations can reduce the amount of data\ncommunication and the computation cost. Unlike weight parameters, the pattern\nof activations is directly related to input data and thereby changes\ndynamically. To regulate the dynamic activation sparsity (DAS), in this work,\nwe propose a generic low-cost approach based on winners-take-all (WTA) dropout\ntechnique. The network enhanced by the proposed WTA dropout, namely\n\\textit{DASNet}, features structured activation sparsity with an improved\nsparsity level. Compared to the static feature map pruning methods, DASNets\nprovide better computation cost reduction. The WTA technique can be easily\napplied in deep neural networks without incurring additional training\nvariables. More importantly, DASNet can be seamlessly integrated with other\ncompression techniques, such as weight pruning and quantization, without\ncompromising on accuracy. Our experiments on various networks and datasets\npresent significant run-time speedups with negligible accuracy loss.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 03:53:39 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yang", "Qing", ""], ["Mao", "Jiachen", ""], ["Wang", "Zuoguan", ""], ["Li", "Hai", ""]]}, {"id": "1909.06965", "submitter": "Nikos Ar\\'echiga PhD", "authors": "Nikos Arechiga, Jonathan DeCastro, Soonho Kong, Karen Leung", "title": "Better AI through Logical Scaffolding", "comments": "CAV Workshop on Formal Methods for ML-enabled Autonomous Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the concept of logical scaffolds, which can be used to improve\nthe quality of software that relies on AI components. We explain how some of\nthe existing ideas on runtime monitors for perception systems can be seen as a\nspecific instance of logical scaffolds. Furthermore, we describe how logical\nscaffolds may be useful for improving AI programs beyond perception systems, to\ninclude general prediction systems and agent behavior models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 05:41:25 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Arechiga", "Nikos", ""], ["DeCastro", "Jonathan", ""], ["Kong", "Soonho", ""], ["Leung", "Karen", ""]]}, {"id": "1909.06970", "submitter": "Montserrat Alvarado", "authors": "Alicia Montserrat Alvarado-Gonzalez, Gibran Fuentes-Pineda and Jorge\n  Cervantes-Ojeda", "title": "A few filters are enough: Convolutional Neural Network for P300\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, convolutional neural networks (CNNs) have become the\ndriving force of an ever-increasing set of applications, achieving\nstate-of-the-art performance. Most of the modern CNN architectures are composed\nof many convolutional and fully connected layers and typically require\nthousands or millions of parameters to learn. CNNs have also been effective in\nthe detection of Event-Related Potentials from electroencephalogram (EEG)\nsignals, notably the P300 component which is frequently employed in\nBrain-Computer Interfaces (BCIs). However, for this task, the increase in\ndetection rates compared to approaches based on human-engineered features has\nnot been as impressive as in other areas and might not justify such a large\nnumber of parameters. In this paper, we study the performances of existing CNN\narchitectures with diverse complexities for single-trial within-subject and\ncross-subject P300 detection on four different datasets. We also proposed\nSepConv1D, a very simple CNN architecture consisting of a single depthwise\nseparable 1D convolutional layer followed by a fully connected Sigmoid\nclassification neuron. We found that with as few as four filters in its\nconvolutional layer and a small overall number of parameters, SepConv1D\nobtained competitive performances in the four datasets. We believe this may\nrepresent an important step towards building simpler, cheaper, faster, and more\nportable BCIs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 03:48:28 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:27:09 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 19:38:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Alvarado-Gonzalez", "Alicia Montserrat", ""], ["Fuentes-Pineda", "Gibran", ""], ["Cervantes-Ojeda", "Jorge", ""]]}, {"id": "1909.06984", "submitter": "Bahman Moraffah", "authors": "Bahman Moraffah", "title": "Inference for multiple object tracking: A Bayesian nonparametric\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, multi object tracking (MOT) problem has drawn attention to\nit and has been studied in various research areas. However, some of the\nchallenging problems including time dependent cardinality, unordered\nmeasurement set, and object labeling remain unclear. In this paper, we propose\nrobust nonparametric methods to model the state prior for MOT problem. These\nmodels are shown to be more flexible and robust compared to existing methods.\nIn particular, the overall approach estimates time dependent object\ncardinality, provides object labeling, and identifies object associated\nmeasurements. Moreover, our proposed framework dynamically contends with the\nbirth/death and survival of the objects through dependent nonparametric\nprocesses. We present Inference algorithms that demonstrate the utility of the\ndependent nonparametric models for tracking. We employ Monte Carlo sampling\nmethods to demonstrate the proposed algorithms efficiently learn the trajectory\nof objects from noisy measurements. The computational results display the\nperformance of the proposed algorithms and comparison not only between one\nanother, but also between proposed algorithms and labeled multi Bernoulli\ntracker.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 04:42:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Moraffah", "Bahman", ""]]}, {"id": "1909.07018", "submitter": "Jing Liu", "authors": "Jing Liu, Fei Gao and Jiang Zhang", "title": "Gumbel-softmax Optimization: A Simple General Framework for\n  Combinatorial Optimization Problems on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in real life can be converted to combinatorial optimization\nproblems (COPs) on graphs, that is to find a best node state configuration or a\nnetwork structure such that the designed objective function is optimized under\nsome constraints. However, these problems are notorious for their hardness to\nsolve because most of them are NP-hard or NP-complete. Although traditional\ngeneral methods such as simulated annealing (SA), genetic algorithms (GA) and\nso forth have been devised to these hard problems, their accuracy and time\nconsumption are not satisfying in practice. In this work, we proposed a simple,\nfast, and general algorithm framework called Gumbel-softmax Optimization (GSO)\nfor COPs. By introducing Gumbel-softmax technique which is developed in machine\nlearning community, we can optimize the objective function directly by gradient\ndescent algorithm regardless of the discrete nature of variables. We test our\nalgorithm on four different problems including Sherrington-Kirkpatrick (SK)\nmodel, maximum independent set (MIS) problem, modularity optimization, and\nstructural optimization problem. High-quality solutions can be obtained with\nmuch less time consuming compared to traditional approaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 06:43:46 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liu", "Jing", ""], ["Gao", "Fei", ""], ["Zhang", "Jiang", ""]]}, {"id": "1909.07040", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury and Aditya Gopalan", "title": "Bayesian Optimization under Heavy-tailed Payoffs", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider black box optimization of an unknown function in the\nnonparametric Gaussian process setting when the noise in the observed function\nvalues can be heavy tailed. This is in contrast to existing literature that\ntypically assumes sub-Gaussian noise distributions for queries. Under the\nassumption that the unknown function belongs to the Reproducing Kernel Hilbert\nSpace (RKHS) induced by a kernel, we first show that an adaptation of the\nwell-known GP-UCB algorithm with reward truncation enjoys sublinear\n$\\tilde{O}(T^{\\frac{2 + \\alpha}{2(1+\\alpha)}})$ regret even with only the\n$(1+\\alpha)$-th moments, $\\alpha \\in (0,1]$, of the reward distribution being\nbounded ($\\tilde{O}$ hides logarithmic factors). However, for the common\nsquared exponential (SE) and Mat\\'{e}rn kernels, this is seen to be\nsignificantly larger than a fundamental $\\Omega(T^{\\frac{1}{1+\\alpha}})$ lower\nbound on regret. We resolve this gap by developing novel Bayesian optimization\nalgorithms, based on kernel approximation techniques, with regret bounds\nmatching the lower bound in order for the SE kernel. We numerically benchmark\nthe algorithms on environments based on both synthetic models and real-world\ndata sets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 07:44:39 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1909.07053", "submitter": "Yuantao Fan", "authors": "Yuantao Fan and S{\\l}awomir Nowaczyk and Thorsteinn R\\\"ognvaldsson", "title": "Transfer learning for Remaining Useful Life Prediction Based on\n  Consensus Self-Organizing Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional paradigm for developing machine prognostics usually relies on\ngeneralization from data acquired in experiments under controlled conditions\nprior to deployment of the equipment. Detecting or predicting failures and\nestimating machine health in this way assumes that future field data will have\na very similar distribution to the experiment data. However, many complex\nmachines operate under dynamic environmental conditions and are used in many\ndifferent ways. This makes collecting comprehensive data very challenging, and\nthe assumption that pre-deployment data and post-deployment data follow very\nsimilar distributions is unlikely to hold. Transfer Learning (TL) refers to\nmethods for transferring knowledge learned in one setting (the source domain)\nto another setting (the target domain). In this work, we present a TL method\nfor predicting Remaining Useful Life (RUL) of equipment, under the assumption\nthat labels are available only for the source domain and not the target domain.\nThis setting corresponds to generalizing from a limited number of\nrun-to-failure experiments performed prior to deployment into making\nprognostics with data coming from deployed equipment that is being used under\nmultiple new operating conditions and experiencing previously unseen faults. We\nemploy a deviation detection method, Consensus Self-Organizing Models (COSMO),\nto create transferable features for building the RUL regression model. These\nfeatures capture how different target equipment is in comparison to its peers.\nThe efficiency of the proposed TL method is demonstrated using the NASA\nTurbofan Engine Degradation Simulation Data Set. Models using the COSMO\ntransferable features show better performance than other methods on predicting\nRUL when the target domain is more complex than the source domain.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 08:31:08 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 02:45:27 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 18:00:37 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Fan", "Yuantao", ""], ["Nowaczyk", "S\u0142awomir", ""], ["R\u00f6gnvaldsson", "Thorsteinn", ""]]}, {"id": "1909.07054", "submitter": "Sebastien Cossin", "authors": "Marine Qu\\'erou\\'e, Agn\\`es Lash\\'eras-Bauduin, Vianney Jouhet, Frantz\n  Thiessard, Jean-Marc Vital, Anne-Marie Rogues, S\\'ebastien Cossin (UB)", "title": "Automatic detection of surgical site infections from a clinical data\n  warehouse", "comments": "in French", "journal-ref": "TALMED 2019, Aug 2019, Lyon, France", "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the incidence of surgical site infections (SSIs) is one of the\nobjectives of the French nosocomial infection control program. Manual\nmonitoring of SSIs is carried out each year by the hospital hygiene team and\nsurgeons at the University Hospital of Bordeaux. Our goal was to develop an\nautomatic detection algorithm based on hospital information system data. Three\nyears (2015, 2016 and 2017) of manual spine surgery monitoring have been used\nas a gold standard to extract features and train machine learning algorithms.\nThe dataset contained 22 SSIs out of 2133 spine surgeries. Two different\napproaches were compared. The first used several data sources and achieved the\nbest performance but is difficult to generalize to other institutions. The\nsecond was based on free text only with semiautomatic extraction of\ndiscriminant terms. The algorithms managed to identify all the SSIs with 20 and\n26 false positives respectively on the dataset. Another evaluation is underway.\nThese results are encouraging for the development of semi-automated\nsurveillance methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 08:31:20 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Qu\u00e9rou\u00e9", "Marine", "", "UB"], ["Lash\u00e9ras-Bauduin", "Agn\u00e8s", "", "UB"], ["Jouhet", "Vianney", "", "UB"], ["Thiessard", "Frantz", "", "UB"], ["Vital", "Jean-Marc", "", "UB"], ["Rogues", "Anne-Marie", "", "UB"], ["Cossin", "S\u00e9bastien", "", "UB"]]}, {"id": "1909.07063", "submitter": "Marc Dymetman", "authors": "Tetiana Parshakova and Jean-Marc Andreoli and Marc Dymetman", "title": "Global Autoregressive Models for Data-Efficient Sequence Learning", "comments": "To appear in CONLL (The SIGNLL Conference on Computational Natural\n  Language Learning) Hong Kong, Nov. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard autoregressive seq2seq models are easily trained by max-likelihood,\nbut tend to show poor results under small-data conditions. We introduce a class\nof seq2seq models, GAMs (Global Autoregressive Models), which combine an\nautoregressive component with a log-linear component, allowing the use of\nglobal \\textit{a priori} features to compensate for lack of data. We train\nthese models in two steps. In the first step, we obtain an \\emph{unnormalized}\nGAM that maximizes the likelihood of the data, but is improper for fast\ninference or evaluation. In the second step, we use this GAM to train (by\ndistillation) a second autoregressive model that approximates the\n\\emph{normalized} distribution associated with the GAM, and can be used for\nfast inference and evaluation. Our experiments focus on language modelling\nunder synthetic conditions and show a strong perplexity reduction of using the\nsecond autoregressive model over the standard one.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 08:46:30 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 19:40:01 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Parshakova", "Tetiana", ""], ["Andreoli", "Jean-Marc", ""], ["Dymetman", "Marc", ""]]}, {"id": "1909.07102", "submitter": "Marco Dinarelli", "authors": "Marco Dinarelli and Lo\\\"ic Grobol", "title": "Hybrid Neural Models For Sequence Modelling: The Best Of Three Worlds", "comments": "12 pages + bibliography. English version, and slight improvement, of\n  the paper published at the French conference TALN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a neural architecture with the main characteristics of the most\nsuccessful neural models of the last years: bidirectional RNNs,\nencoder-decoder, and the Transformer model. Evaluation on three sequence\nlabelling tasks yields results that are close to the state-of-the-art for all\ntasks and better than it for some of them, showing the pertinence of this\nhybrid architecture for this kind of tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:19:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Dinarelli", "Marco", ""], ["Grobol", "Lo\u00efc", ""]]}, {"id": "1909.07105", "submitter": "Yu Yol Shin", "authors": "Yuyol Shin, Yoonjin Yoon", "title": "Incorporating dynamicity of transportation network with multi-weight\n  traffic graph convolutional network for traffic forecasting", "comments": "11 pages, 7 figures, Accepted to IEEE Transactions on Intelligent\n  Transportation Systems (2020)", "journal-ref": "IEEE Trans. Intell. Transp. Syst., 0 (2020) 1-11", "doi": "10.1109/TITS.2020.3031331", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting problem remains a challenging task in the intelligent\ntransportation system due to its spatio-temporal complexity. Although temporal\ndependency has been well studied and discussed, spatial dependency is\nrelatively less explored due to its large variations, especially in the urban\nenvironment. In this study, a novel graph convolutional network model,\nMulti-Weight Traffic Graph Convolutional (MW-TGC) network, is proposed and\napplied to two urban networks with contrasting geometric constraints. The model\nconducts graph convolution operations on speed data with multi-weighted\nadjacency matrices to combine the features, including speed limit, distance,\nand angle. The spatially isolated dimension reduction operation is conducted on\nthe combined features to learn the dependencies among the features and reduce\nthe size of the output to a computationally feasible level. The output of\nmulti-weight graph convolution is applied to the sequence-to-sequence model\nwith Long Short-Term Memory units to learn temporal dependencies. When applied\nto two urban sites, urban-core and urban-mix, MW-TGC network not only\noutperformed the comparative models in both sites but also reduced variance in\nthe heterogeneous urban-mix network. We conclude that MW-TGC network can\nprovide a robust traffic forecasting performance across the variations in\nspatial complexity, which can be a strong advantage in urban traffic\nforecasting.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:30:53 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 06:34:44 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 07:07:17 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Shin", "Yuyol", ""], ["Yoon", "Yoonjin", ""]]}, {"id": "1909.07115", "submitter": "YuChuan Chuang", "authors": "Yi-Ta Chen, Yu-Chuan Chuang, An-Yeu (Andy) Wu", "title": "AdaBoost-assisted Extreme Learning Machine for Efficient Online\n  Sequential Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an AdaBoost-assisted extreme learning machine for\nefficient online sequential classification (AOS-ELM). In order to achieve\nbetter accuracy in online sequential learning scenarios, we utilize the\ncost-sensitive algorithm-AdaBoost, which diversifying the weak classifiers, and\nadding the forgetting mechanism, which stabilizing the performance during the\ntraining procedure. Hence, AOS-ELM adapts better to sequentially arrived data\ncompared with other voting based methods. The experiment results show AOS-ELM\ncan achieve 94.41% accuracy on MNIST dataset, which is the theoretical accuracy\nbound performed by an original batch learning algorithm, AdaBoost-ELM.\nMoreover, with the forgetting mechanism, the standard deviation of accuracy\nduring the online sequential learning process is reduced to 8.26x.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:48:00 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chen", "Yi-Ta", "", "Andy"], ["Chuang", "Yu-Chuan", "", "Andy"], ["An-Yeu", "", "", "Andy"], ["Wu", "", ""]]}, {"id": "1909.07140", "submitter": "Thomas Parnell", "authors": "Dimitrios Sarigiannis, Thomas Parnell, Haris Pozidis", "title": "Weighted Sampling for Combined Model Selection and Hyperparameter Tuning", "comments": "Accepted for presentation at The Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combined algorithm selection and hyperparameter tuning (CASH) problem is\ncharacterized by large hierarchical hyperparameter spaces. Model-free\nhyperparameter tuning methods can explore such large spaces efficiently since\nthey are highly parallelizable across multiple machines. When no prior\nknowledge or meta-data exists to boost their performance, these methods\ncommonly sample random configurations following a uniform distribution. In this\nwork, we propose a novel sampling distribution as an alternative to uniform\nsampling and prove theoretically that it has a better chance of finding the\nbest configuration in a worst-case setting. In order to compare competing\nmethods rigorously in an experimental setting, one must perform statistical\nhypothesis testing. We show that there is little-to-no agreement in the\nautomated machine learning literature regarding which methods should be used.\nWe contrast this disparity with the methods recommended by the broader\nstatistics literature, and identify a suitable approach. We then select three\npopular model-free solutions to CASH and evaluate their performance, with\nuniform sampling as well as the proposed sampling scheme, across 67 datasets\nfrom the OpenML platform. We investigate the trade-off between exploration and\nexploitation across the three algorithms, and verify empirically that the\nproposed sampling distribution improves performance in all cases.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 12:01:12 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 07:57:49 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 12:19:57 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sarigiannis", "Dimitrios", ""], ["Parnell", "Thomas", ""], ["Pozidis", "Haris", ""]]}, {"id": "1909.07142", "submitter": "Shenglan Liu", "authors": "Shenglan Liu, Yang Yu, Yang Liu, Hong Qiao, Lin Feng, Jiashi Feng", "title": "Hierarchic Neighbors Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning now plays a very important role in machine learning and\nmany relevant applications. Although its superior performance in dealing with\nnonlinear data distribution, data sparsity is always a thorny knot. There are\nfew researches to well handle it in manifold learning. In this paper, we\npropose Hierarchic Neighbors Embedding (HNE), which enhance local connection by\nthe hierarchic combination of neighbors. After further analyzing topological\nconnection and reconstruction performance, three different versions of HNE are\ngiven. The experimental results show that our methods work well on both\nsynthetic data and high-dimensional real-world tasks. HNE develops the\noutstanding advantages in dealing with general data. Furthermore, comparing\nwith other popular manifold learning methods, the performance on sparse samples\nand weak-connected manifolds is better for HNE.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 12:07:08 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liu", "Shenglan", ""], ["Yu", "Yang", ""], ["Liu", "Yang", ""], ["Qiao", "Hong", ""], ["Feng", "Lin", ""], ["Feng", "Jiashi", ""]]}, {"id": "1909.07155", "submitter": "Pankaj Malhotra", "authors": "Jyoti Narwariya, Pankaj Malhotra, Lovekesh Vig, Gautam Shroff, Vishnu\n  Tv", "title": "Meta-Learning for Few-Shot Time Series Classification", "comments": "CoDS COMAD 2020: Proceedings of the 7th ACM IKDD CoDS and 25th COMAD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved state-of-the-art results on time\nseries classification (TSC) tasks. In this work, we focus on leveraging DNNs in\nthe often-encountered practical scenario where access to labeled training data\nis difficult, and where DNNs would be prone to overfitting. We leverage recent\nadvancements in gradient-based meta-learning, and propose an approach to train\na residual neural network with convolutional layers as a meta-learning agent\nfor few-shot TSC. The network is trained on a diverse set of few-shot tasks\nsampled from various domains (e.g. healthcare, activity recognition, etc.) such\nthat it can solve a target task from another domain using only a small number\nof training samples from the target task. Most existing meta-learning\napproaches are limited in practice as they assume a fixed number of target\nclasses across tasks. We overcome this limitation in order to train a common\nagent across domains with each domain having different number of target\nclasses, we utilize a triplet-loss based learning procedure that does not\nrequire any constraints to be enforced on the number of classes for the\nfew-shot TSC tasks. To the best of our knowledge, we are the first to use\nmeta-learning based pre-training for TSC. Our approach sets a new benchmark for\nfew-shot TSC, outperforming several strong baselines on few-shot tasks sampled\nfrom 41 datasets in UCR TSC Archive. We observe that pre-training under the\nmeta-learning paradigm allows the network to quickly adapt to new unseen tasks\nwith small number of labeled instances.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:13:29 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:03:45 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 12:58:41 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Narwariya", "Jyoti", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""], ["Tv", "Vishnu", ""]]}, {"id": "1909.07156", "submitter": "Masanari Kimura", "authors": "Masanari Kimura, Masayuki Tanaka", "title": "New Perspective of Interpretability of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known as black-box models. In other words, it\nis difficult to interpret the internal state of the model. Improving the\ninterpretability of DNNs is one of the hot research topics. However, at\npresent, the definition of interpretability for DNNs is vague, and the question\nof what is a highly explanatory model is still controversial. To address this\nissue, we provide the definition of the human predictability of the model, as a\npart of the interpretability of the DNNs. The human predictability proposed in\nthis paper is defined by easiness to predict the change of the inference when\nperturbating the model of the DNNs. In addition, we introduce one example of\nhigh human-predictable DNNs. We discuss that our definition will help to the\nresearch of the interpretability of the DNNs considering various types of\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 07:24:20 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kimura", "Masanari", ""], ["Tanaka", "Masayuki", ""]]}, {"id": "1909.07158", "submitter": "Kristian Miok", "authors": "Kristian Miok, Dong Nguyen-Doan, Bla\\v{z} \\v{S}krlj, Daniela Zaharie\n  and Marko Robnik-\\v{S}ikonja", "title": "Prediction Uncertainty Estimation for Hate Speech Classification", "comments": "The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-31372-2_24", "journal-ref": "Statistical Language and Speech Processing 2019 Proceedings", "doi": "10.1007/978-3-030-31372-2_24", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of social network popularity, in recent years, hate speech\nphenomenon has significantly increased. Due to its harmful effect on minority\ngroups as well as on large communities, there is a pressing need for hate\nspeech detection and filtering. However, automatic approaches shall not\njeopardize free speech, so they shall accompany their decisions with\nexplanations and assessment of uncertainty. Thus, there is a need for\npredictive machine learning models that not only detect hate speech but also\nhelp users understand when texts cross the line and become unacceptable. The\nreliability of predictions is usually not addressed in text classification. We\nfill this gap by proposing the adaptation of deep neural networks that can\nefficiently estimate prediction uncertainty. To reliably detect hate speech, we\nuse Monte Carlo dropout regularization, which mimics Bayesian inference within\nneural networks. We evaluate our approach using different text embedding\nmethods. We visualize the reliability of results with a novel technique that\naids in understanding the classification reliability and errors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 12:43:17 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 14:29:59 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 11:59:54 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Miok", "Kristian", ""], ["Nguyen-Doan", "Dong", ""], ["\u0160krlj", "Bla\u017e", ""], ["Zaharie", "Daniela", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1909.07182", "submitter": "Marco Henrique de Almeida In\\'acio", "authors": "Marco Henrique de Almeida In\\'acio and Rafael Izbicki and B\\'alint\n  Gyires-T\\'oth", "title": "Distance Assessment and Hypothesis Testing of High-Dimensional Samples\n  using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two distinct datasets, an important question is if they have arisen\nfrom the the same data generating function or alternatively how their data\ngenerating functions diverge from one another. In this paper, we introduce an\napproach for measuring the distance between two datasets with high\ndimensionality using variational autoencoders. This approach is augmented by a\npermutation hypothesis test in order to check the hypothesis that the data\ngenerating distributions are the same within a significance level. We evaluate\nboth the distance measurement and hypothesis testing approaches on generated\nand on public datasets. According to the results the proposed approach can be\nused for data exploration (e.g. by quantifying the discrepancy/separability\nbetween categories of images), which can be particularly useful in the early\nphases of the pipeline of most machine learning projects.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 13:19:14 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["In\u00e1cio", "Marco Henrique de Almeida", ""], ["Izbicki", "Rafael", ""], ["Gyires-T\u00f3th", "B\u00e1lint", ""]]}, {"id": "1909.07192", "submitter": "Morteza Noshad Iranzad", "authors": "Morteza Noshad, Li Xu, Alfred Hero", "title": "Learning to Benchmark: Determining Best Achievable Misclassification\n  Error from Training Data", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning to benchmark the best achievable\nclassifier performance. In this problem the objective is to establish\nstatistically consistent estimates of the Bayes misclassification error rate\nwithout having to learn a Bayes-optimal classifier. Our learning to benchmark\nframework improves on previous work on learning bounds on Bayes\nmisclassification rate since it learns the {\\it exact} Bayes error rate instead\nof a bound on error rate. We propose a benchmark learner based on an ensemble\nof $\\epsilon$-ball estimators and Chebyshev approximation. Under a smoothness\nassumption on the class densities we show that our estimator achieves an\noptimal (parametric) mean squared error (MSE) rate of $O(N^{-1})$, where $N$ is\nthe number of samples. Experiments on both simulated and real datasets\nestablish that our proposed benchmark learning algorithm produces estimates of\nthe Bayes error that are more accurate than previous approaches for learning\nbounds on Bayes error probability.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 13:37:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Noshad", "Morteza", ""], ["Xu", "Li", ""], ["Hero", "Alfred", ""]]}, {"id": "1909.07218", "submitter": "Thomas Parnell", "authors": "Johanna Sommer, Dimitrios Sarigiannis, Thomas Parnell", "title": "Learning to Tune XGBoost with XGBoost", "comments": "Accepted for presentation at The 3rd Workshop on Meta-Learning\n  (Meta-Learn 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper we investigate whether meta-learning techniques can be\nused to more effectively tune the hyperparameters of machine learning models\nusing successive halving (SH). We propose a novel variant of the SH algorithm\n(MeSH), that uses meta-regressors to determine which candidate configurations\nshould be eliminated at each round. We apply MeSH to the problem of tuning the\nhyperparameters of a gradient-boosted decision tree model. By training and\ntuning our meta-regressors using existing tuning jobs from 95 datasets, we\ndemonstrate that MeSH can often find a superior solution to both SH and random\nsearch.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:09:55 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 09:47:33 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 08:20:12 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 13:00:45 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sommer", "Johanna", ""], ["Sarigiannis", "Dimitrios", ""], ["Parnell", "Thomas", ""]]}, {"id": "1909.07268", "submitter": "Jessica Rivera Villicana", "authors": "Jessica Rivera-Villicana, Fabio Zambetta, James Harland, Marsha Berry", "title": "Exploring Apprenticeship Learning for Player Modelling in Interactive\n  Narratives", "comments": "Extended Abstracts of the 2019 Annual Symposium on Computer-Human\n  Interaction in Play (CHI Play)", "journal-ref": null, "doi": "10.1145/3341215.3356314", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an early Apprenticeship Learning approach to mimic\nthe behaviour of different players in a short adaption of the interactive\nfiction Anchorhead. Our motivation is the need to understand and simulate\nplayer behaviour to create systems to aid the design and personalisation of\nInteractive Narratives (INs). INs are partially observable for the players and\ntheir goals are dynamic as a result. We used Receding Horizon IRL (RHIRL) to\nlearn players' goals in the form of reward functions, and derive policies to\nimitate their behaviour. Our preliminary results suggest that RHIRL is able to\nlearn action sequences to complete a game, and provided insights towards\ngenerating behaviour more similar to specific players.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:15:57 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Rivera-Villicana", "Jessica", ""], ["Zambetta", "Fabio", ""], ["Harland", "James", ""], ["Berry", "Marsha", ""]]}, {"id": "1909.07279", "submitter": "Felipe Tobar", "authors": "Felipe Tobar", "title": "Band-Limited Gaussian Processes: The Sinc Kernel", "comments": "To appear at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel class of Gaussian processes (GPs) whose spectra have\ncompact support, meaning that their sample trajectories are almost-surely band\nlimited. As a complement to the growing literature on spectral design of\ncovariance kernels, the core of our proposal is to model power spectral\ndensities through a rectangular function, which results in a kernel based on\nthe sinc function with straightforward extensions to non-centred (around zero\nfrequency) and frequency-varying cases. In addition to its use in regression,\nthe relationship between the sinc kernel and the classic theory is illuminated,\nin particular, the Shannon-Nyquist theorem is interpreted as posterior\nreconstruction under the proposed kernel. Additionally, we show that the sinc\nkernel is instrumental in two fundamental signal processing applications:\nfirst, in stereo amplitude modulation, where the non-centred sinc kernel arises\nnaturally. Second, for band-pass filtering, where the proposed kernel allows\nfor a Bayesian treatment that is robust to observation noise and missing data.\nThe developed theory is complemented with illustrative graphic examples and\nvalidated experimentally using real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:31:58 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Tobar", "Felipe", ""]]}, {"id": "1909.07294", "submitter": "Peter Morales", "authors": "Peter Morales, Rajmonda Sulo Caceres, Tina Eliassi-Rad", "title": "Selective Network Discovery via Deep Reinforcement Learning on Embedded\n  Spaces", "comments": "Submitted for review to the journal of applied network science\n  (2020). This adds several new sections from the original complex networks\n  submission which can be viewed under v1 or at\n  https://link.springer.com/chapter/10.1007/978-3-030-36687-2_75", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks are often either too large for full exploration, partially\naccessible, or partially observed. Downstream learning tasks on these\nincomplete networks can produce low quality results. In addition, reducing the\nincompleteness of the network can be costly and nontrivial. As a result,\nnetwork discovery algorithms optimized for specific downstream learning tasks\ngiven resource collection constraints are of great interest. In this paper, we\nformulate the task-specific network discovery problem in an incomplete network\nsetting as a sequential decision making problem. Our downstream task is\nselective harvesting, the optimal collection of vertices with a particular\nattribute. We propose a framework, called Network Actor Critic (NAC), which\nlearns a policy and notion of future reward in an offline setting via a deep\nreinforcement learning algorithm. The NAC paradigm utilizes a task-specific\nnetwork embedding to reduce the state space complexity. A detailed comparative\nanalysis of popular network embeddings is presented with respect to their role\nin supporting offline planning. Furthermore, a quantitative study is presented\non several synthetic and real benchmarks using NAC and several baselines. We\nshow that offline models of reward and network discovery policies lead to\nsignificantly improved performance when compared to competitive online\ndiscovery algorithms. Finally, we outline learning regimes where planning is\ncritical in addressing sparse and changing reward signals.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:51:27 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 21:47:28 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Morales", "Peter", ""], ["Caceres", "Rajmonda Sulo", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "1909.07310", "submitter": "Ole-Christoffer Granmo", "authors": "Saeed Rahimi Gorji, Ole-Christoffer Granmo, Adrian Phoulady, Morten\n  Goodwin", "title": "A Tsetlin Machine with Multigranular Clauses", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced Tsetlin Machine (TM) has provided competitive pattern\nrecognition accuracy in several benchmarks, however, requires a 3-dimensional\nhyperparameter search. In this paper, we introduce the Multigranular Tsetlin\nMachine (MTM). The MTM eliminates the specificity hyperparameter, used by the\nTM to control the granularity of the conjunctive clauses that it produces for\nrecognizing patterns. Instead of using a fixed global specificity, we encode\nvarying specificity as part of the clauses, rendering the clauses\nmultigranular. This makes it easier to configure the TM because the\ndimensionality of the hyperparameter search space is reduced to only two\ndimensions. Indeed, it turns out that there is significantly less\nhyperparameter tuning involved in applying the MTM to new problems. Further, we\ndemonstrate empirically that the MTM provides similar performance to what is\nachieved with a finely specificity-optimized TM, by comparing their performance\non both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 16:09:34 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Gorji", "Saeed Rahimi", ""], ["Granmo", "Ole-Christoffer", ""], ["Phoulady", "Adrian", ""], ["Goodwin", "Morten", ""]]}, {"id": "1909.07328", "submitter": "Nuri Cingillioglu", "authors": "Nuri Cingillioglu and Alessandra Russo", "title": "Learning Invariants through Soft Unification", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human reasoning involves recognising common underlying principles across many\nexamples. The by-products of such reasoning are invariants that capture\npatterns such as \"if someone went somewhere then they are there\", expressed\nusing variables \"someone\" and \"somewhere\" instead of mentioning specific people\nor places. Humans learn what variables are and how to use them at a young age.\nThis paper explores whether machines can also learn and use variables solely\nfrom examples without requiring human pre-engineering. We propose Unification\nNetworks, an end-to-end differentiable neural network approach capable of\nlifting examples into invariants and using those invariants to solve a given\ntask. The core characteristic of our architecture is soft unification between\nexamples that enables the network to generalise parts of the input into\nvariables, thereby learning invariants. We evaluate our approach on five\ndatasets to demonstrate that learning invariants captures patterns in the data\nand can improve performance over baselines.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 16:48:52 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 10:24:14 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Cingillioglu", "Nuri", ""], ["Russo", "Alessandra", ""]]}, {"id": "1909.07373", "submitter": "Zac Wellmer", "authors": "Zac Wellmer, James Kwok", "title": "Policy Prediction Network: Model-Free Behavior Policy with Model-Based\n  Learning in Continuous Action Space", "comments": "Published at ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel deep reinforcement learning architecture that was\ninspired by previous tree structured architectures which were only useable in\ndiscrete action spaces. Policy Prediction Network offers a way to improve\nsample complexity and performance on continuous control problems in exchange\nfor extra computation at training time but at no cost in computation at rollout\ntime. Our approach integrates a mix between model-free and model-based\nreinforcement learning. Policy Prediction Network is the first to introduce\nimplicit model-based learning to Policy Gradient algorithms for continuous\naction space and is made possible via the empirically justified clipping\nscheme. Our experiments are focused on the MuJoCo environments so that they can\nbe compared with similar work done in this area.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 12:39:02 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wellmer", "Zac", ""], ["Kwok", "James", ""]]}, {"id": "1909.07374", "submitter": "Yanlong Huang", "authors": "Yanlong Huang and Darwin G. Caldwell", "title": "A Linearly Constrained Nonparametric Framework for Imitation Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a myriad of advanced results have been reported in the\ncommunity of imitation learning, ranging from parametric to non-parametric,\nprobabilistic to non-probabilistic and Bayesian to frequentist approaches.\nMeanwhile, ample applications (e.g., grasping tasks and human-robot\ncollaborations) further show the applicability of imitation learning in a wide\nrange of domains. While numerous literature is dedicated to the learning of\nhuman skills in unconstrained environment, the problem of learning constrained\nmotor skills, however, has not received equal attention yet. In fact,\nconstrained skills exist widely in robotic systems. For instance, when a robot\nis demanded to write letters on a board, its end-effector trajectory must\ncomply with the plane constraint from the board. In this paper, we aim to\ntackle the problem of imitation learning with linear constraints. Specifically,\nwe propose to exploit the probabilistic properties of multiple demonstrations,\nand subsequently incorporate them into a linearly constrained optimization\nproblem, which finally leads to a non-parametric solution. In addition, a\nconnection between our framework and the classical model predictive control is\nprovided. Several examples including simulated writing and locomotion tasks are\npresented to show the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 13:34:34 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Huang", "Yanlong", ""], ["Caldwell", "Darwin G.", ""]]}, {"id": "1909.07425", "submitter": "Abdul Fatir Ansari", "authors": "Abdul Fatir Ansari, Jonathan Scarlett, Harold Soh", "title": "A Characteristic Function Approach to Deep Implicit Generative Modeling", "comments": "CVPR 2020 (Oral), Code available at\n  https://github.com/clear-nus/OCFGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit Generative Models (IGMs) such as GANs have emerged as effective\ndata-driven models for generating samples, particularly images. In this paper,\nwe formulate the problem of learning an IGM as minimizing the expected distance\nbetween characteristic functions. Specifically, we minimize the distance\nbetween characteristic functions of the real and generated data distributions\nunder a suitably-chosen weighting distribution. This distance metric, which we\nterm as the characteristic function distance (CFD), can be (approximately)\ncomputed with linear time-complexity in the number of samples, in contrast with\nthe quadratic-time Maximum Mean Discrepancy (MMD). By replacing the discrepancy\nmeasure in the critic of a GAN with the CFD, we obtain a model that is simple\nto implement and stable to train. The proposed metric enjoys desirable\ntheoretical properties including continuity and differentiability with respect\nto generator parameters, and continuity in the weak topology. We further\npropose a variation of the CFD in which the weighting distribution parameters\nare also optimized during training; this obviates the need for manual tuning,\nand leads to an improvement in test power relative to CFD. We demonstrate\nexperimentally that our proposed method outperforms WGAN and MMD-GAN variants\non a variety of unsupervised image generation benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 18:19:49 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 18:19:16 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ansari", "Abdul Fatir", ""], ["Scarlett", "Jonathan", ""], ["Soh", "Harold", ""]]}, {"id": "1909.07440", "submitter": "Jeremy Welborn", "authors": "Jeremy Welborn, Michael Schaarschmidt, Eiko Yoneki", "title": "Learning Index Selection with Structured Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configuration spaces for computer systems can be challenging for traditional\nand automatic tuning strategies. Injecting task-specific knowledge into the\ntuner for a task may allow for more efficient exploration of candidate\nconfigurations. We apply this idea to the task of index set selection to\naccelerate database workloads. Index set selection has been amenable to recent\napplications of vanilla deep RL, but real deployments remain out of reach. In\nthis paper, we explore how learning index selection can be enhanced with\ntask-specific inductive biases, specifically by encoding these inductive biases\nin better action structures. Index selection-specific action representations\narise when the problem is reformulated in terms of permutation learning and we\nrely on recent work for learning RL policies on permutations. Through this\napproach, we build an indexing agent that is able to achieve improved indexing\nand validate its behavior with task-specific statistics. Early experiments\nreveal that our agent can find configurations that are up to 40% smaller for\nthe same levels of latency as compared with other approaches and indicate more\nintuitive indexing behavior.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 19:16:41 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Welborn", "Jeremy", ""], ["Schaarschmidt", "Michael", ""], ["Yoneki", "Eiko", ""]]}, {"id": "1909.07444", "submitter": "Ephrem Admasu Yekun", "authors": "Ephrem Admasu Yekun and Abrahaley Teklay", "title": "Student Performance Prediction with Optimum Multilabel Ensemble Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the important measures of quality of education is the performance of\nstudents in the academic settings. Nowadays, abundant data is stored in\neducational institutions about students which can help to discover insight on\nhow students are learning and how to improve their performance ahead of time\nusing data mining techniques. In this paper, we developed a student performance\nprediction model that predicts the performance of high school students for the\nnext semester for five courses. We modeled our prediction system as a\nmulti-label classification task and used support vector machine (SVM), Random\nForest (RF), K-nearest Neighbors (KNN), and Mult-layer perceptron (MLP) as\nbase-classifiers to train our model. We further improved the performance of the\nprediction model using state-of-the-art partitioning schemes to divide the\nlabel space into smaller spaces and use Label Powerset (LP) transformation\nmethod to transform each labelset into a multi-class classification task. The\nproposed model achieved better performance in terms of different evaluation\nmetrics when compared to other multi-label learning tasks such as binary\nrelevance and classifier chains.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:59:26 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Yekun", "Ephrem Admasu", ""], ["Teklay", "Abrahaley", ""]]}, {"id": "1909.07452", "submitter": "Paritosh Ramanan", "authors": "Paritosh Ramanan, Kiyoshi Nakayama", "title": "BAFFLE : Blockchain Based Aggregator Free Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key aspect of Federated Learning (FL) is the requirement of a centralized\naggregator to maintain and update the global model. However, in many cases\norchestrating a centralized aggregator might be infeasible due to numerous\noperational constraints. In this paper, we introduce BAFFLE, an aggregator\nfree, blockchain driven, FL environment that is inherently decentralized.\nBAFFLE leverages Smart Contracts (SC) to coordinate the round delineation,\nmodel aggregation and update tasks in FL. BAFFLE boosts computational\nperformance by decomposing the global parameter space into distinct chunks\nfollowed by a score and bid strategy. In order to characterize the performance\nof BAFFLE, we conduct experiments on a private Ethereum network and use the\ncentralized and aggregator driven methods as our benchmark. We show that BAFFLE\nsignificantly reduces the gas costs for FL on the blockchain as compared to a\ndirect adaptation of the aggregator based method. Our results also show that\nBAFFLE achieves high scalability and computational efficiency while delivering\nsimilar accuracy as the benchmark methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 19:47:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 23:00:13 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 17:57:29 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ramanan", "Paritosh", ""], ["Nakayama", "Kiyoshi", ""]]}, {"id": "1909.07464", "submitter": "Xiaotong Liu", "authors": "Xiaotong Liu, Hong Xuan, Zeyu Zhang, Abby Stylianou, Robert Pless", "title": "Visualizing How Embeddings Generalize", "comments": "8 pages,4 figures, published in ICML workshop:Understanding and\n  Improving Generalization in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep metric learning is often used to learn an embedding function that\ncaptures the semantic differences within a dataset. A key factor in many\nproblem domains is how this embedding generalizes to new classes of data. In\nobserving many triplet selection strategies for Metric Learning, we find that\nthe best performance consistently arises from approaches that focus on a few,\nwell selected triplets.We introduce visualization tools to illustrate how an\nembedding generalizes beyond measuring accuracy on validation data, and we\nillustrate the behavior of a range of triplet selection strategies.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:18:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Liu", "Xiaotong", ""], ["Xuan", "Hong", ""], ["Zhang", "Zeyu", ""], ["Stylianou", "Abby", ""], ["Pless", "Robert", ""]]}, {"id": "1909.07480", "submitter": "Xiao-Yun Zhou", "authors": "Peichao Li, Xiao-Yun Zhou, Zhao-Yang Wang and Guang-Zhong Yang", "title": "Z-Net: an Anisotropic 3D DCNN for Medical CT Volume Segmentation", "comments": "8 pages, 9 figures, two tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate volume segmentation from the Computed Tomography (CT) scan is a\ncommon prerequisite for pre-operative planning, intra-operative guidance and\nquantitative assessment of therapeutic outcomes in robot-assisted Minimally\nInvasive Surgery (MIS). 3D Deep Convolutional Neural Network (DCNN) is a viable\nsolution for this task, but is memory intensive. Small isotropic patches are\ncropped from the original and large CT volume to mitigate this issue in\npractice, but it may cause discontinuities between the adjacent patches and\nsevere class-imbalances within individual sub-volumes. This paper presents a\nnew 3D DCNN framework, namely Z-Net, to tackle the discontinuity and\nclass-imbalance issue by preserving a full field-of-view of the objects in the\nXY planes using anisotropic spatial separable convolutions. The proposed Z-Net\ncan be seamlessly integrated into existing 3D DCNNs with isotropic convolutions\nsuch as 3D U-Net and V-Net, with improved volume segmentation Intersection over\nUnion (IoU) - up to $12.6\\%$. Detailed validation of Z-Net is provided for CT\naortic, liver and lung segmentation, demonstrating the effectiveness and\npractical value of Z-Net for intra-operative 3D navigation in robot-assisted\nMIS.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:56:13 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 16:12:39 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Li", "Peichao", ""], ["Zhou", "Xiao-Yun", ""], ["Wang", "Zhao-Yang", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1909.07481", "submitter": "Shenhao Wang", "authors": "Shenhao Wang, Baichuan Mo, Jinhua Zhao", "title": "Deep Neural Networks for Choice Analysis: Architectural Design with\n  Alternative-Specific Utility Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas deep neural network (DNN) is increasingly applied to choice analysis,\nit is challenging to reconcile domain-specific behavioral knowledge with\ngeneric-purpose DNN, to improve DNN's interpretability and predictive power,\nand to identify effective regularization methods for specific tasks. This study\ndesigns a particular DNN architecture with alternative-specific utility\nfunctions (ASU-DNN) by using prior behavioral knowledge. Unlike a fully\nconnected DNN (F-DNN), which computes the utility value of an alternative k by\nusing the attributes of all the alternatives, ASU-DNN computes it by using only\nk's own attributes. Theoretically, ASU-DNN can dramatically reduce the\nestimation error of F-DNN because of its lighter architecture and sparser\nconnectivity. Empirically, ASU-DNN has 2-3% higher prediction accuracy than\nF-DNN over the whole hyperparameter space in a private dataset that we\ncollected in Singapore and a public dataset in R mlogit package. The\nalternative-specific connectivity constraint, as a domain-knowledge-based\nregularization method, is more effective than the most popular generic-purpose\nexplicit and implicit regularization methods and architectural hyperparameters.\nASU-DNN is also more interpretable because it provides a more regular\nsubstitution pattern of travel mode choices than F-DNN does. The comparison\nbetween ASU-DNN and F-DNN can also aid in testing the behavioral knowledge. Our\nresults reveal that individuals are more likely to compute utility by using an\nalternative's own attributes, supporting the long-standing practice in choice\nmodeling. Overall, this study demonstrates that prior behavioral knowledge\ncould be used to guide the architecture design of DNN, to function as an\neffective domain-knowledge-based regularization method, and to improve both the\ninterpretability and predictive power of DNN in choice analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:01:23 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 22:38:28 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wang", "Shenhao", ""], ["Mo", "Baichuan", ""], ["Zhao", "Jinhua", ""]]}, {"id": "1909.07490", "submitter": "Rayan Mosli", "authors": "Rayan Mosli, Matthew Wright, Bo Yuan and Yin Pan", "title": "They Might NOT Be Giants: Crafting Black-Box Adversarial Examples with\n  Fewer Queries Using Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been found to be susceptible to adversarial\nexamples that are often indistinguishable from the original inputs. These\nadversarial examples are created by applying adversarial perturbations to input\nsamples, which would cause them to be misclassified by the target models.\nAttacks that search and apply the perturbations to create adversarial examples\nare performed in both white-box and black-box settings, depending on the\ninformation available to the attacker about the target. For black-box attacks,\nthe only capability available to the attacker is the ability to query the\ntarget with specially crafted inputs and observing the labels returned by the\nmodel. Current black-box attacks either have low success rates, requires a high\nnumber of queries, or produce adversarial examples that are easily\ndistinguishable from their sources. In this paper, we present AdversarialPSO, a\nblack-box attack that uses fewer queries to create adversarial examples with\nhigh success rates. AdversarialPSO is based on the evolutionary search\nalgorithm Particle Swarm Optimization, a populationbased gradient-free\noptimization algorithm. It is flexible in balancing the number of queries\nsubmitted to the target vs the quality of imperceptible adversarial examples.\nThe attack has been evaluated using the image classification benchmark datasets\nCIFAR-10, MNIST, and Imagenet, achieving success rates of 99.6%, 96.3%, and\n82.0%, respectively, while submitting substantially fewer queries than the\nstate-of-the-art. We also present a black-box method for isolating salient\nfeatures used by models when making classifications. This method, called Swarms\nwith Individual Search Spaces or SWISS, creates adversarial examples by finding\nand modifying the most important features in the input.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:24:19 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Mosli", "Rayan", ""], ["Wright", "Matthew", ""], ["Yuan", "Bo", ""], ["Pan", "Yin", ""]]}, {"id": "1909.07502", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Scott Siegel, Martin Heesacker, Sherry Benton, and\n  Parisa Rashidi", "title": "Automatic Detection and Classification of Cognitive Distortions in\n  Mental Health Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cognitive psychology, automatic and self-reinforcing irrational thought\npatterns are known as cognitive distortions. Left unchecked, patients\nexhibiting these types of thoughts can become stuck in negative feedback loops\nof unhealthy thinking, leading to inaccurate perceptions of reality commonly\nassociated with anxiety and depression. In this paper, we present a machine\nlearning framework for the automatic detection and classification of 15 common\ncognitive distortions in two novel mental health free text datasets collected\nfrom both crowdsourcing and a real-world online therapy program. When\ndifferentiating between distorted and non-distorted passages, our model\nachieved a weighted F1 score of 0.88. For classifying distorted passages into\none of 15 distortion categories, our model yielded weighted F1 scores of 0.68\nin the larger crowdsourced dataset and 0.45 in the smaller online counseling\ndataset, both of which outperformed random baseline metrics by a large margin.\nFor both tasks, we also identified the most discriminative words and phrases\nbetween classes to highlight common thematic elements for improving targeted\nand therapist-guided mental health treatment. Furthermore, we performed an\nexploratory analysis using unsupervised content-based clustering and topic\nmodeling algorithms as first efforts towards a data-driven perspective on the\nthematic relationship between similar cognitive distortions traditionally\ndeemed unique. Finally, we highlight the difficulties in applying mental\nhealth-based machine learning in a real-world setting and comment on the\nimplications and benefits of our framework for improving automated delivery of\ntherapeutic treatment in conjunction with traditional cognitive-behavioral\ntherapy.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 22:21:27 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 00:50:07 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Shickel", "Benjamin", ""], ["Siegel", "Scott", ""], ["Heesacker", "Martin", ""], ["Benton", "Sherry", ""], ["Rashidi", "Parisa", ""]]}, {"id": "1909.07528", "submitter": "Bowen Baker", "authors": "Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell,\n  Bob McGrew, Igor Mordatch", "title": "Emergent Tool Use From Multi-Agent Autocurricula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through multi-agent competition, the simple objective of hide-and-seek, and\nstandard reinforcement learning algorithms at scale, we find that agents create\na self-supervised autocurriculum inducing multiple distinct rounds of emergent\nstrategy, many of which require sophisticated tool use and coordination. We\nfind clear evidence of six emergent phases in agent strategy in our\nenvironment, each of which creates a new pressure for the opposing team to\nadapt; for instance, agents learn to build multi-object shelters using moveable\nboxes which in turn leads to agents discovering that they can overcome\nobstacles using ramps. We further provide evidence that multi-agent competition\nmay scale better with increasing environment complexity and leads to behavior\nthat centers around far more human-relevant skills than other self-supervised\nreinforcement learning methods such as intrinsic motivation. Finally, we\npropose transfer and fine-tuning as a way to quantitatively evaluate targeted\ncapabilities, and we compare hide-and-seek agents to both intrinsic motivation\nand random initialization baselines in a suite of domain-specific intelligence\ntests.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 00:17:02 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 00:56:50 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Baker", "Bowen", ""], ["Kanitscheider", "Ingmar", ""], ["Markov", "Todor", ""], ["Wu", "Yi", ""], ["Powell", "Glenn", ""], ["McGrew", "Bob", ""], ["Mordatch", "Igor", ""]]}, {"id": "1909.07543", "submitter": "Bogdan Mazoure", "authors": "Thang Doan, Bogdan Mazoure, Moloud Abdar, Audrey Durand, Joelle\n  Pineau, R Devon Hjelm", "title": "Attraction-Repulsion Actor-Critic for Continuous Control Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous control tasks in reinforcement learning are important because they\nprovide an important framework for learning in high-dimensional state spaces\nwith deceptive rewards, where the agent can easily become trapped into\nsuboptimal solutions. One way to avoid local optima is to use a population of\nagents to ensure coverage of the policy space, yet learning a population with\nthe \"best\" coverage is still an open problem. In this work, we present a novel\napproach to population-based RL in continuous control that leverages properties\nof normalizing flows to perform attractive and repulsive operations between\ncurrent members of the population and previously observed policies. Empirical\nresults on the MuJoCo suite demonstrate a high performance gain for our\nalgorithm compared to prior work, including Soft-Actor Critic (SAC).\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 01:28:20 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 16:29:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 13:51:16 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Doan", "Thang", ""], ["Mazoure", "Bogdan", ""], ["Abdar", "Moloud", ""], ["Durand", "Audrey", ""], ["Pineau", "Joelle", ""], ["Hjelm", "R Devon", ""]]}, {"id": "1909.07547", "submitter": "Abdelrhman Saleh", "authors": "Abdelrhman Saleh, Natasha Jaques, Asma Ghandeharioun, Judy Hanwen\n  Shen, Rosalind Picard", "title": "Hierarchical Reinforcement Learning for Open-Domain Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialog generation is a challenging problem; maximum likelihood\ntraining can lead to repetitive outputs, models have difficulty tracking\nlong-term conversational goals, and training on standard movie or online\ndatasets may lead to the generation of inappropriate, biased, or offensive\ntext. Reinforcement Learning (RL) is a powerful framework that could\npotentially address these issues, for example by allowing a dialog model to\noptimize for reducing toxicity and repetitiveness. However, previous approaches\nwhich apply RL to open-domain dialog generation do so at the word level, making\nit difficult for the model to learn proper credit assignment for long-term\nconversational rewards. In this paper, we propose a novel approach to\nhierarchical reinforcement learning, VHRL, which uses policy gradients to tune\nthe utterance-level embedding of a variational sequence model. This\nhierarchical approach provides greater flexibility for learning long-term,\nconversational rewards. We use self-play and RL to optimize for a set of\nhuman-centered conversation metrics, and show that our approach provides\nsignificant improvements -- in terms of both human evaluation and automatic\nmetrics -- over state-of-the-art dialog models, including Transformers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 01:57:18 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 14:25:28 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 21:23:04 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Saleh", "Abdelrhman", ""], ["Jaques", "Natasha", ""], ["Ghandeharioun", "Asma", ""], ["Shen", "Judy Hanwen", ""], ["Picard", "Rosalind", ""]]}, {"id": "1909.07554", "submitter": "Yining Wang", "authors": "Yining Wang, Mingzhe Chen, Zhaohui Yang, Xue Hao, Tao Luo, and Walid\n  Saad", "title": "Gated Recurrent Units Learning for Optimal Deployment of Visible Light\n  Communications Enabled UAVs", "comments": "This paper has been accepted by the 2019 IEEE Global Communications\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of optimizing the deployment of unmanned aerial\nvehicles (UAVs) equipped with visible light communication (VLC) capabilities is\nstudied. In the studied model, the UAVs can simultaneously provide\ncommunications and illumination to service ground users. Ambient illumination\nincreases the interference over VLC links while reducing the illumination\nthreshold of the UAVs. Therefore, it is necessary to consider the illumination\ndistribution of the target area for UAV deployment optimization. This problem\nis formulated as an optimization problem whose goal is to minimize the total\ntransmit power while meeting the illumination and communication requirements of\nusers. To solve this problem, an algorithm based on the machine learning\nframework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can\nmodel the long-term historical illumination distribution and predict the future\nillumination distribution. In order to reduce the complexity of the prediction\nalgorithm while accurately predicting the illumination distribution, a Gaussian\nmixture model (GMM) is used to fit the illumination distribution of the target\narea at each time slot. Based on the predicted illumination distribution, the\noptimization problem is proved to be a convex optimization problem that can be\nsolved by using duality. Simulations using real data from the Earth\nobservations group (EOG) at NOAA/NCEI show that the proposed approach can\nachieve up to 22.1% reduction in transmit power compared to a conventional\noptimal UAV deployment that does not consider the illumination distribution.\nThe results also show that UAVs must hover at areas having strong illumination,\nthus providing useful guidelines on the deployment of VLC-enabled UAVs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 02:22:09 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wang", "Yining", ""], ["Chen", "Mingzhe", ""], ["Yang", "Zhaohui", ""], ["Hao", "Xue", ""], ["Luo", "Tao", ""], ["Saad", "Walid", ""]]}, {"id": "1909.07561", "submitter": "Jun Li", "authors": "Zixuan Song, Jun Li", "title": "Variable selection with false discovery rate control in deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are famous for their high prediction accuracy,\nbut they are also known for their black-box nature and poor interpretability.\nWe consider the problem of variable selection, that is, selecting the input\nvariables that have significant predictive power on the output, in DNNs. We\npropose a backward elimination procedure called SurvNet, which is based on a\nnew measure of variable importance that applies to a wide variety of networks.\nMore importantly, SurvNet is able to estimate and control the false discovery\nrate of selected variables, while no existing methods provide such a quality\ncontrol. Further, SurvNet adaptively determines how many variables to eliminate\nat each step in order to maximize the selection efficiency. To study its\nvalidity, SurvNet is applied to image data and gene expression data, as well as\nvarious simulation datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 03:00:16 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Song", "Zixuan", ""], ["Li", "Jun", ""]]}, {"id": "1909.07578", "submitter": "Amir Ghasemian", "authors": "Amir Ghasemian, Homa Hosseinmardi, Aram Galstyan, Edoardo M. Airoldi,\n  Aaron Clauset", "title": "Stacking Models for Nearly Optimal Link Prediction in Complex Networks", "comments": "30 pages, 9 figures, 22 tables", "journal-ref": "Proc. Natl. Acad. Sci. USA 117(38), 23393-23400 (2020)", "doi": "10.1073/pnas.1914950117", "report-no": null, "categories": "stat.ML cs.LG cs.SI physics.data-an q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world networks are incompletely observed. Algorithms that can\naccurately predict which links are missing can dramatically speedup the\ncollection of network data and improve the validity of network models. Many\nalgorithms now exist for predicting missing links, given a partially observed\nnetwork, but it has remained unknown whether a single best predictor exists,\nhow link predictability varies across methods and networks from different\ndomains, and how close to optimality current methods are. We answer these\nquestions by systematically evaluating 203 individual link predictor\nalgorithms, representing three popular families of methods, applied to a large\ncorpus of 548 structurally diverse networks from six scientific domains. We\nfirst show that individual algorithms exhibit a broad diversity of prediction\nerrors, such that no one predictor or family is best, or worst, across all\nrealistic inputs. We then exploit this diversity via meta-learning to construct\na series of \"stacked\" models that combine predictors into a single algorithm.\nApplied to a broad range of synthetic networks, for which we may analytically\ncalculate optimal performance, these stacked models achieve optimal or nearly\noptimal levels of accuracy. Applied to real-world networks, stacked models are\nalso superior, but their accuracy varies strongly by domain, suggesting that\nlink prediction may be fundamentally easier in social networks than in\nbiological or technological networks. These results indicate that the\nstate-of-the-art for link prediction comes from combining individual\nalgorithms, which achieves nearly optimal predictions. We close with a brief\ndiscussion of limitations and opportunities for further improvement of these\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:11:19 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Ghasemian", "Amir", ""], ["Hosseinmardi", "Homa", ""], ["Galstyan", "Aram", ""], ["Airoldi", "Edoardo M.", ""], ["Clauset", "Aaron", ""]]}, {"id": "1909.07587", "submitter": "Sayan Putatunda PhD", "authors": "Sayan Putatunda", "title": "A Hybrid Deep Learning Approach for Diagnosis of the Erythemato-Squamous\n  Disease", "comments": "Pre-review version of the paper accepted at the 2020 IEEE\n  International Conference on Electronics, Computing and Communication\n  Technologies (CONECCT)", "journal-ref": "2020 IEEE International Conference on Electronics, Computing and\n  Communication Technologies (CONECCT)", "doi": "10.1109/CONECCT50063.2020.9198447", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diagnosis of the Erythemato-squamous disease (ESD) is accepted as a\ndifficult problem in dermatology. ESD is a form of skin disease. It generally\ncauses redness of the skin and also may cause loss of skin. They are generally\ndue to genetic or environmental factors. ESD comprises six classes of skin\nconditions namely, pityriasis rubra pilaris, lichen planus, chronic dermatitis,\npsoriasis, seboreic dermatitis and pityriasis rosea. The automated diagnosis of\nESD can help doctors and dermatologists in reducing the efforts from their end\nand in taking faster decisions for treatment. The literature is replete with\nworks that used conventional machine learning methods for the diagnosis of ESD.\nHowever, there isn't much instances of application of Deep learning for the\ndiagnosis of ESD. In this paper, we propose a novel hybrid deep learning\napproach i.e. Derm2Vec for the diagnosis of the ESD. Derm2Vec is a hybrid deep\nlearning model that consists of both Autoencoders and Deep Neural Networks. We\nalso apply a conventional Deep Neural Network (DNN) for the classification of\nESD. We apply both Derm2Vec and DNN along with other traditional machine\nlearning methods on a real world dermatology dataset. The Derm2Vec method is\nfound to be the best performer (when taking the prediction accuracy into\naccount) followed by DNN and Extreme Gradient Boosting.The mean CV score of\nDerm2Vec, DNN and Extreme Gradient Boosting are 96.92 percent, 96.65 percent\nand 95.80 percent respectively.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:50:28 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 04:52:54 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Putatunda", "Sayan", ""]]}, {"id": "1909.07588", "submitter": "Tianyi Chen", "authors": "Jun Sun, Tianyi Chen, Georgios B. Giannakis, and Zaiyue Yang", "title": "Communication-Efficient Distributed Learning via Lazily Aggregated\n  Quantized Gradients", "comments": "Accepted in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper develops a novel aggregated gradient approach for\ndistributed machine learning that adaptively compresses the gradient\ncommunication. The key idea is to first quantize the computed gradients, and\nthen skip less informative quantized gradient communications by reusing\noutdated gradients. Quantizing and skipping result in `lazy' worker-server\ncommunications, which justifies the term Lazily Aggregated Quantized gradient\nthat is henceforth abbreviated as LAQ. Our LAQ can provably attain the same\nlinear convergence rate as the gradient descent in the strongly convex case,\nwhile effecting major savings in the communication overhead both in transmitted\nbits as well as in communication rounds. Empirically, experiments with real\ndata corroborate a significant communication reduction compared to existing\ngradient- and stochastic gradient-based algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:53:24 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Sun", "Jun", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""], ["Yang", "Zaiyue", ""]]}, {"id": "1909.07594", "submitter": "Lalith Srikanth Chintalapati", "authors": "Lalith Srikanth Chintalapati, Raghunatha Sarma Rachakonda", "title": "Conformal Prediction based Spectral Clustering", "comments": "Under review in a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Clustering(SC) is a prominent data clustering technique of recent\ntimes which has attracted much attention from researchers. It is a highly\ndata-driven method and makes no strict assumptions on the structure of the data\nto be clustered. One of the central pieces of spectral clustering is the\nconstruction of an affinity matrix based on a similarity measure between data\npoints. The way the similarity measure is defined between data points has a\ndirect impact on the performance of the SC technique. Several attempts have\nbeen made in the direction of strengthening the pairwise similarity measure to\nenhance the spectral clustering. In this work, we have defined a novel affinity\nmeasure by employing the concept of non-conformity used in Conformal\nPrediction(CP) framework. The non-conformity based affinity captures the\nrelationship between neighborhoods of data points and has the power to\ngeneralize the notion of contextual similarity. We have shown that this\nformulation of affinity measure gives good results and compares well with the\nstate of the art methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:09:01 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Chintalapati", "Lalith Srikanth", ""], ["Rachakonda", "Raghunatha Sarma", ""]]}, {"id": "1909.07627", "submitter": "Rahul Sharma", "authors": "Rahul Sharma, Abhishek Kumar, Piyush Rai", "title": "Refined $\\alpha$-Divergence Variational Inference via Rejection Sampling", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approximate inference method, based on a synergistic\ncombination of R\\'enyi $\\alpha$-divergence variational inference (RDVI) and\nrejection sampling (RS). RDVI is based on minimization of R\\'enyi\n$\\alpha$-divergence $D_\\alpha(p||q)$ between the true distribution $p(x)$ and a\nvariational approximation $q(x)$; RS draws samples from a distribution $p(x) =\n\\tilde{p}(x)/Z_{p}$ using a proposal $q(x)$, s.t. $Mq(x) \\geq \\tilde{p}(x),\n\\forall x$. Our inference method is based on a crucial observation that\n$D_\\infty(p||q)$ equals $\\log M(\\theta)$ where $M(\\theta)$ is the optimal value\nof the RS constant for a given proposal $q_\\theta(x)$. This enables us to\ndevelop a \\emph{two-stage} hybrid inference algorithm. Stage-1 performs RDVI to\nlearn $q_\\theta$ by minimizing an estimator of $D_\\alpha(p||q)$, and uses the\nlearned $q_\\theta$ to find an (approximately) optimal $\\tilde{M}(\\theta)$.\nStage-2 performs RS using the constant $\\tilde{M}(\\theta)$ to improve the\napproximate distribution $q_\\theta$ and obtain a sample-based approximation. We\nprove that this two-stage method allows us to learn considerably more accurate\napproximations of the target distribution as compared to RDVI. We demonstrate\nour method's efficacy via several experiments on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 07:28:05 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 04:35:09 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 05:37:38 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Sharma", "Rahul", ""], ["Kumar", "Abhishek", ""], ["Rai", "Piyush", ""]]}, {"id": "1909.07654", "submitter": "Tomaso Fontanini", "authors": "Tomaso Fontanini, Eleonora Iotti and Andrea Prati", "title": "MetalGAN: a Cluster-based Adaptive Training for Few-Shot Adversarial\n  Colorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the majority of works on deep-learning-based image\ncolorization have focused on how to make a good use of the enormous datasets\ncurrently available. What about when the data at disposal are scarce? The main\nobjective of this work is to prove that a network can be trained and can\nprovide excellent colorization results even without a large quantity of data.\nThe adopted approach is a mixed one, which uses an adversarial method for the\nactual colorization, and a meta-learning technique to enhance the generator\nmodel. Also, a clusterization a-priori of the training dataset ensures a\ntask-oriented division useful for meta-learning, and at the same time reduces\nthe per-step number of images. This paper describes in detail the method and\nits main motivations, and a discussion of results and future developments is\nprovided.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 08:54:12 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Fontanini", "Tomaso", ""], ["Iotti", "Eleonora", ""], ["Prati", "Andrea", ""]]}, {"id": "1909.07670", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata and Takuma Otsuka", "title": "Efficient Transfer Bayesian Optimization with Auxiliary Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient transfer Bayesian optimization method, which finds\nthe maximum of an expensive-to-evaluate black-box function by using data on\nrelated optimization tasks. Our method uses auxiliary information that\nrepresents the task characteristics to effectively transfer knowledge for\nestimating a distribution over target functions. In particular, we use a\nGaussian process, in which the mean and covariance functions are modeled with\nneural networks that simultaneously take both the auxiliary information and\nfeature vectors as input. With a neural network mean function, we can estimate\nthe target function even without evaluations. By using the neural network\ncovariance function, we can extract nonlinear correlation among feature vectors\nthat are shared across related tasks. Our Gaussian process-based formulation\nnot only enables an analytic calculation of the posterior distribution but also\nswiftly adapts the target function to observations. Our method is also\nadvantageous because the computational costs scale linearly with the number of\nsource tasks. Through experiments using a synthetic dataset and datasets for\nfinding the optimal pedestrian traffic regulations and optimal machine learning\nalgorithms, we demonstrate that our method identifies the optimal points with\nfewer target function evaluations than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:28:42 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Otsuka", "Takuma", ""]]}, {"id": "1909.07689", "submitter": "Sergio Garrido", "authors": "Sergio Garrido, Stanislav S. Borysov, Francisco C. Pereira, Jeppe Rich", "title": "Prediction of rare feature combinations in population synthesis:\n  Application of deep generative modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In population synthesis applications, when considering populations with many\nattributes, a fundamental problem is the estimation of rare combinations of\nfeature attributes. Unsurprisingly, it is notably more difficult to reliably\nrepresentthe sparser regions of such multivariate distributions and in\nparticular combinations of attributes which are absent from the original\nsample. In the literature this is commonly known as sampling zeros for which no\nsystematic solution has been proposed so far. In this paper, two machine\nlearning algorithms, from the family of deep generative models,are proposed for\nthe problem of population synthesis and with particular attention to the\nproblem of sampling zeros. Specifically, we introduce the Wasserstein\nGenerative Adversarial Network (WGAN) and the Variational Autoencoder(VAE), and\nadapt these algorithms for a large-scale population synthesis application. The\nmodels are implemented on a Danish travel survey with a feature-space of more\nthan 60 variables. The models are validated in a cross-validation scheme and a\nset of new metrics for the evaluation of the sampling-zero problem is proposed.\nResults show how these models are able to recover sampling zeros while keeping\nthe estimation of truly impossible combinations, the structural zeros, at a\ncomparatively low level. Particularly, for a low dimensional experiment, the\nVAE, the marginal sampler and the fully random sampler generate 5%, 21% and\n26%, respectively, more structural zeros per sampling zero generated by the\nWGAN, while for a high dimensional case, these figures escalate to 44%, 2217%\nand 170440%, respectively. This research directly supports the development of\nagent-based systems and in particular cases where detailed socio-economic or\ngeographical representations are required.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:58:45 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Garrido", "Sergio", ""], ["Borysov", "Stanislav S.", ""], ["Pereira", "Francisco C.", ""], ["Rich", "Jeppe", ""]]}, {"id": "1909.07694", "submitter": "V\\'aclav Barto\\v{s}", "authors": "Vaclav Bartos, Martin Zadnik, Sheikh Mahbub Habib, Emmanouil\n  Vasilomanolakis", "title": "Network entity characterization and attack prediction", "comments": "30 pages, 8 figures", "journal-ref": "Future Generation Computer Systems 97 (2019) 674-686", "doi": "10.1016/j.future.2019.03.016", "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The devastating effects of cyber-attacks, highlight the need for novel attack\ndetection and prevention techniques. Over the last years, considerable work has\nbeen done in the areas of attack detection as well as in collaborative defense.\nHowever, an analysis of the state of the art suggests that many challenges\nexist in prioritizing alert data and in studying the relation between a\nrecently discovered attack and the probability of it occurring again. In this\narticle, we propose a system that is intended for characterizing network\nentities and the likelihood that they will behave maliciously in the future.\nOur system, namely Network Entity Reputation Database System (NERDS), takes\ninto account all the available information regarding a network entity (e. g. IP\naddress) to calculate the probability that it will act maliciously. The latter\npart is achieved via the utilization of machine learning. Our experimental\nresults show that it is indeed possible to precisely estimate the probability\nof future attacks from each entity using information about its previous\nmalicious behavior and other characteristics. Ranking the entities by this\nprobability has practical applications in alert prioritization, assembly of\nhighly effective blacklists of a limited length and other use cases.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:12:55 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Bartos", "Vaclav", ""], ["Zadnik", "Martin", ""], ["Habib", "Sheikh Mahbub", ""], ["Vasilomanolakis", "Emmanouil", ""]]}, {"id": "1909.07697", "submitter": "Naif Alshammari PhD", "authors": "Naif Alshammari, Samet Ak\\c{c}ay, Toby P. Breckon", "title": "Multi-Task Learning for Automotive Foggy Scene Understanding via Domain\n  Adaptation to an Illumination-Invariant Representation", "comments": "Conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint scene understanding and segmentation for automotive applications is a\nchallenging problem in two key aspects:- (1) classifying every pixel in the\nentire scene and (2) performing this task under unstable weather and\nillumination changes (e.g. foggy weather), which results in poor outdoor scene\nvisibility. This poor outdoor scene visibility leads to a non-optimal\nperformance of deep convolutional neural network-based scene understanding and\nsegmentation. In this paper, we propose an efficient end-to-end contemporary\nautomotive semantic scene understanding approach under foggy weather\nconditions, employing domain adaptation and illumination-invariant image\nper-transformation. As a multi-task pipeline, our proposed model provides:- (1)\ntransferring images from extreme to clear-weather condition using domain\ntransfer approach and (2) semantically segmenting a scene using a competitive\nencoder-decoder convolutional neural network (CNN) with dense connectivity,\nskip connections and fusion-based techniques. We evaluate our approach on\nchallenging foggy datasets, including synthetic dataset (Foggy Cityscapes) as\nwell as real-world datasets (Foggy Zurich and Foggy Driving). By incorporating\nRGB, depth, and illumination-invariant information, our approach outperforms\nthe state-of-the-art within automotive scene understanding, under foggy weather\ncondition.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:18:14 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Alshammari", "Naif", ""], ["Ak\u00e7ay", "Samet", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1909.07698", "submitter": "Ieva Kazlauskaite", "authors": "Ivan Ustyuzhaninov, Ieva Kazlauskaite, Markus Kaiser, Erik Bodin,\n  Neill D. F. Campbell, Carl Henrik Ek", "title": "Compositional uncertainty in deep Gaussian processes", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are nonparametric priors over functions. Fitting a\nGP implies computing a posterior distribution of functions consistent with the\nobserved data. Similarly, deep Gaussian processes (DGPs) should allow us to\ncompute a posterior distribution of compositions of multiple functions giving\nrise to the observations. However, exact Bayesian inference is intractable for\nDGPs, motivating the use of various approximations. We show that the\napplication of simplifying mean-field assumptions across the hierarchy leads to\nthe layers of a DGP collapsing to near-deterministic transformations. We argue\nthat such an inference scheme is suboptimal, not taking advantage of the\npotential of the model to discover the compositional structure in the data. To\naddress this issue, we examine alternative variational inference schemes\nallowing for dependencies across different layers and discuss their advantages\nand limitations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:19:02 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 09:58:36 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 21:19:12 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ustyuzhaninov", "Ivan", ""], ["Kazlauskaite", "Ieva", ""], ["Kaiser", "Markus", ""], ["Bodin", "Erik", ""], ["Campbell", "Neill D. F.", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1909.07707", "submitter": "Florin Leon", "authors": "Florin Leon, Marius Gavrilescu", "title": "A Review of Tracking, Prediction and Decision Making Methods for\n  Autonomous Driving", "comments": "36 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This literature review focuses on three important aspects of an autonomous\ncar system: tracking (assessing the identity of the actors such as cars,\npedestrians or obstacles in a sequence of observations), prediction (predicting\nthe future motion of surrounding vehicles in order to navigate through various\ntraffic scenarios) and decision making (analyzing the available actions of the\nego car and their consequences to the entire driving context). For tracking and\nprediction, approaches based on (deep) neural networks and other, especially\nstochastic techniques, are reported. For decision making, deep reinforcement\nlearning algorithms are presented, together with methods used to explore\ndifferent alternative actions, such as Monte Carlo Tree Search.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:41:40 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Leon", "Florin", ""], ["Gavrilescu", "Marius", ""]]}, {"id": "1909.07729", "submitter": "Abhisek Kundu", "authors": "Abhisek Kundu, Alex Heinecke, Dhiraj Kalamkar, Sudarshan Srinivasan,\n  Eric C. Qin, Naveen K. Mellempudi, Dipankar Das, Kunal Banerjee, Bharat Kaul,\n  Pradeep Dubey", "title": "K-TanH: Efficient TanH For Deep Learning", "comments": "6 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose K-TanH, a novel, highly accurate, hardware efficient approximation\nof popular activation function TanH for Deep Learning. K-TanH consists of\nparameterized low-precision integer operations, such as, shift and add/subtract\n(no floating point operation needed) where parameters are stored in very small\nlook-up tables that can fit in CPU registers. K-TanH can work on various\nnumerical formats, such as, Float32 and BFloat16. High quality approximations\nto other activation functions, e.g., Sigmoid, Swish and GELU, can be derived\nfrom K-TanH. Our AVX512 implementation of K-TanH demonstrates $>5\\times$ speed\nup over Intel SVML, and it is consistently superior in efficiency over other\napproximations that use floating point arithmetic. Finally, we achieve\nstate-of-the-art Bleu score and convergence results for training language\ntranslation model GNMT on WMT16 data sets with approximate TanH obtained via\nK-TanH on BFloat16 inputs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 11:43:23 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 05:05:39 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 10:02:50 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kundu", "Abhisek", ""], ["Heinecke", "Alex", ""], ["Kalamkar", "Dhiraj", ""], ["Srinivasan", "Sudarshan", ""], ["Qin", "Eric C.", ""], ["Mellempudi", "Naveen K.", ""], ["Das", "Dipankar", ""], ["Banerjee", "Kunal", ""], ["Kaul", "Bharat", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1909.07750", "submitter": "Raghu Rajan", "authors": "Raghu Rajan, Jessica Lizeth Borja Diaz, Suresh Guttikonda, Fabio\n  Ferreira, Andr\\'e Biedenkapp, Jan Ole von Hartz and Frank Hutter", "title": "MDP Playground: A Design and Debug Testbed for Reinforcement Learning", "comments": "NeurIPS 2021 Data and Benchmark Track submission (with slight\n  formatting differences, most notably citation style)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present \\emph{MDP Playground}, an efficient testbed for Reinforcement\nLearning (RL) agents with \\textit{orthogonal} dimensions that can be controlled\nindependently to challenge agents in different ways and obtain varying degrees\nof hardness in generated environments. We consider and allow control over a\nwide variety of dimensions, including \\textit{delayed rewards},\n\\textit{rewardable sequences}, \\textit{density of rewards},\n\\textit{stochasticity}, \\textit{image representations}, \\textit{irrelevant\nfeatures}, \\textit{time unit}, \\textit{action range} and more. We define a\nparameterised collection of fast-to-run toy environments in \\textit{OpenAI Gym}\nby varying these dimensions and propose to use these for the initial design and\ndevelopment of agents. We also provide wrappers that inject these dimensions\ninto complex environments from \\textit{Atari} and \\textit{Mujoco} to allow for\nevaluating agent robustness. We further provide various example use-cases and\ninstructions on how to use \\textit{MDP Playground} to design and debug agents.\nWe believe that \\textit{MDP Playground} is a valuable testbed for researchers\ndesigning new, adaptive and intelligent RL agents and those wanting to unit\ntest their agents.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:41:20 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 12:46:17 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 13:06:35 GMT"}, {"version": "v4", "created": "Fri, 25 Jun 2021 12:38:37 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Rajan", "Raghu", ""], ["Diaz", "Jessica Lizeth Borja", ""], ["Guttikonda", "Suresh", ""], ["Ferreira", "Fabio", ""], ["Biedenkapp", "Andr\u00e9", ""], ["von Hartz", "Jan Ole", ""], ["Hutter", "Frank", ""]]}, {"id": "1909.07774", "submitter": "Qidong Liu", "authors": "Qidong Liu and Ruisheng Zhang", "title": "Global Optimal Path-Based Clustering Algorithm", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization problems for clustering are known to be NP-hard.\nMost optimization methods are not able to find the global optimum solution for\nall datasets. To solve this problem, we propose a global optimal path-based\nclustering (GOPC) algorithm in this paper. The GOPC algorithm is based on two\nfacts: (1) medoids have the minimum degree in their clusters; (2) the minimax\ndistance between two objects in one cluster is smaller than the minimax\ndistance between objects in different clusters. Extensive experiments are\nconducted on synthetic and real-world datasets to evaluate the performance of\nthe GOPC algorithm. The results on synthetic datasets show that the GOPC\nalgorithm can recognize all kinds of clusters regardless of their shapes,\nsizes, or densities. Experimental results on real-world datasets demonstrate\nthe effectiveness and efficiency of the GOPC algorithm. In addition, the GOPC\nalgorithm needs only one parameter, i.e., the number of clusters, which can be\nestimated by the decision graph. The advantages mentioned above make GOPC a\ngood candidate as a general clustering algorithm. Codes are available at\nhttps://github.com/Qidong-Liu/Clustering.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:24:48 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Liu", "Qidong", ""], ["Zhang", "Ruisheng", ""]]}, {"id": "1909.07782", "submitter": "Satya Narayan Shukla", "authors": "Satya Narayan Shukla and Benjamin M. Marlin", "title": "Interpolation-Prediction Networks for Irregularly Sampled Time Series", "comments": "International Conference on Learning Representations. arXiv admin\n  note: substantial text overlap with arXiv:1812.00531", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new deep learning architecture for addressing the\nproblem of supervised learning with sparse and irregularly sampled multivariate\ntime series. The architecture is based on the use of a semi-parametric\ninterpolation network followed by the application of a prediction network. The\ninterpolation network allows for information to be shared across multiple\ndimensions of a multivariate time series during the interpolation stage, while\nany standard deep learning model can be used for the prediction network. This\nwork is motivated by the analysis of physiological time series data in\nelectronic health records, which are sparse, irregularly sampled, and\nmultivariate. We investigate the performance of this architecture on both\nclassification and regression tasks, showing that our approach outperforms a\nrange of baseline and recently proposed models.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 21:18:06 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "1909.07843", "submitter": "Rui Chen", "authors": "Rui Chen, Wenshuo Wang, Zirui Zhao and Ding Zhao", "title": "Active Learning for Risk-Sensitive Inverse Reinforcement Learning", "comments": "8 pages without acknowledgment, 7 figures, submitted to RA-L and ICRA\n  2020 for the IEEE Robotics and Automation Letters (RA-L)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One typical assumption in inverse reinforcement learning (IRL) is that human\nexperts act to optimize the expected utility of a stochastic cost with a fixed\ndistribution. This assumption deviates from actual human behaviors under\nambiguity. Risk-sensitive inverse reinforcement learning (RS-IRL) bridges such\ngap by assuming that humans act according to a random cost with respect to a\nset of subjectively distorted distributions instead of a fixed one. Such\nassumption provides the additional flexibility to model human's risk\npreferences, represented by a risk envelope, in safe-critical tasks. However,\nlike other learning from demonstration techniques, RS-IRL could also suffer\ninefficient learning due to redundant demonstrations. Inspired by the concept\nof active learning, this research derives a probabilistic disturbance sampling\nscheme to enable an RS-IRL agent to query expert support that is likely to\nexpose unrevealed boundaries of the expert's risk envelope. Experimental\nresults confirm that our approach accelerates the convergence of RS-IRL\nalgorithms with lower variance while still guaranteeing unbiased convergence.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 00:57:50 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 23:45:50 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Chen", "Rui", ""], ["Wang", "Wenshuo", ""], ["Zhao", "Zirui", ""], ["Zhao", "Ding", ""]]}, {"id": "1909.07862", "submitter": "Tudor Manole", "authors": "Tudor Manole, Sivaraman Balakrishnan, Larry Wasserman", "title": "Minimax Confidence Intervals for the Sliced Wasserstein Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the growing popularity of variants of the Wasserstein distance\nin statistics and machine learning, we study statistical inference for the\nSliced Wasserstein distance--an easily computable variant of the Wasserstein\ndistance. Specifically, we construct confidence intervals for the Sliced\nWasserstein distance which have finite-sample validity under no assumptions or\nunder mild moment assumptions. These intervals are adaptive in length to the\nregularity of the underlying distributions. We also bound the minimax risk of\nestimating the Sliced Wasserstein distance, and as a consequence establish that\nthe lengths of our proposed confidence intervals are minimax optimal over\nappropriate distribution classes. To motivate the choice of these classes, we\nalso study minimax rates of estimating a distribution under the Sliced\nWasserstein distance. These theoretical findings are complemented with a\nsimulation study demonstrating the deficiencies of the classical bootstrap, and\nthe advantages of our proposed methods. We also show strong correspondences\nbetween our theoretical predictions and the adaptivity of our confidence\ninterval lengths in simulations. We conclude by demonstrating the use of our\nconfidence intervals in the setting of simulator-based likelihood-free\ninference. In this setting, contrasting popular approximate Bayesian\ncomputation methods, we develop uncertainty quantification methods with\nrigorous frequentist coverage guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 14:51:17 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 17:20:09 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Manole", "Tudor", ""], ["Balakrishnan", "Sivaraman", ""], ["Wasserman", "Larry", ""]]}, {"id": "1909.07869", "submitter": "Amin Babadi", "authors": "Perttu H\\\"am\\\"al\\\"ainen, Juuso Toikka, Amin Babadi, C. Karen Liu", "title": "Visualizing Movement Control Optimization Landscapes", "comments": "Accepted to IEEE Transactions on Visualization and Computer Graphics\n  (IEEE TVCG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of animation research focuses on optimization of movement\ncontrol, either as action sequences or policy parameters. However, as\nclosed-form expressions of the objective functions are often not available, our\nunderstanding of the optimization problems is limited. Building on recent work\non analyzing neural network training, we contribute novel visualizations of\nhigh-dimensional control optimization landscapes; this yields insights into why\ncontrol optimization is hard and why common practices like early termination\nand spline-based action parameterizations make optimization easier. For\nexample, our experiments show how trajectory optimization can become\nincreasingly ill-conditioned with longer trajectories, but parameterizing\ncontrol as partial target states---e.g., target angles converted to torques\nusing a PD-controller---can act as an efficient preconditioner. Both our\nvisualizations and quantitative empirical data also indicate that neural\nnetwork policy optimization scales better than trajectory optimization for long\nplanning horizons. Our work advances the understanding of movement optimization\nand our visualizations should also provide value in educational use.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:02:50 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 06:42:11 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 07:42:56 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""], ["Toikka", "Juuso", ""], ["Babadi", "Amin", ""], ["Liu", "C. Karen", ""]]}, {"id": "1909.07872", "submitter": "Markus L\\\"oning", "authors": "Markus L\\\"oning and Anthony Bagnall and Sajaysurya Ganesh and Viktor\n  Kazakov and Jason Lines and Franz J. Kir\\'aly", "title": "sktime: A Unified Interface for Machine Learning with Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sktime -- a new scikit-learn compatible Python library with a\nunified interface for machine learning with time series. Time series data gives\nrise to various distinct but closely related learning tasks, such as\nforecasting and time series classification, many of which can be solved by\nreducing them to related simpler tasks. We discuss the main rationale for\ncreating a unified interface, including reduction, as well as the design of\nsktime's core API, supported by a clear overview of common time series tasks\nand reduction approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:04:08 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["L\u00f6ning", "Markus", ""], ["Bagnall", "Anthony", ""], ["Ganesh", "Sajaysurya", ""], ["Kazakov", "Viktor", ""], ["Lines", "Jason", ""], ["Kir\u00e1ly", "Franz J.", ""]]}, {"id": "1909.07873", "submitter": "Prashanth Vijayaraghavan", "authors": "Prashanth Vijayaraghavan, Deb Roy", "title": "Generating Black-Box Adversarial Examples for Text Classifiers Using a\n  Deep Reinforced Model", "comments": "16 pages, 3 figures, ECML PKDD 2019", "journal-ref": "Joint European Conference on Machine Learning and Knowledge\n  Discovery in Databases. Springer, Cham, 2019", "doi": "10.1007/978-3-030-46147-8_43", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, generating adversarial examples has become an important means of\nmeasuring robustness of a deep learning model. Adversarial examples help us\nidentify the susceptibilities of the model and further counter those\nvulnerabilities by applying adversarial training techniques. In natural\nlanguage domain, small perturbations in the form of misspellings or paraphrases\ncan drastically change the semantics of the text. We propose a reinforcement\nlearning based approach towards generating adversarial examples in black-box\nsettings. We demonstrate that our method is able to fool well-trained models\nfor (a) IMDB sentiment classification task and (b) AG's news corpus news\ncategorization task with significantly high success rates. We find that the\nadversarial examples generated are semantics-preserving perturbations to the\noriginal text.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:05:31 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Vijayaraghavan", "Prashanth", ""], ["Roy", "Deb", ""]]}, {"id": "1909.07908", "submitter": "Tayfun Gokmen", "authors": "Tayfun Gokmen, Wilfried Haensch", "title": "Algorithm for Training Neural Networks on Resistive Device Arrays", "comments": "26 pages, 7 fiures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware architectures composed of resistive cross-point device arrays can\nprovide significant power and speed benefits for deep neural network training\nworkloads using stochastic gradient descent (SGD) and backpropagation (BP)\nalgorithm. The training accuracy on this imminent analog hardware however\nstrongly depends on the switching characteristics of the cross-point elements.\nOne of the key requirements is that these resistive devices must change\nconductance in a symmetrical fashion when subjected to positive or negative\npulse stimuli. Here, we present a new training algorithm, so-called the\n\"Tiki-Taka\" algorithm, that eliminates this stringent symmetry requirement. We\nshow that device asymmetry introduces an unintentional implicit cost term into\nthe SGD algorithm, whereas in the \"Tiki-Taka\" algorithm a coupled dynamical\nsystem simultaneously minimizes the original objective function of the neural\nnetwork and the unintentional cost term due to device asymmetry in a\nself-consistent fashion. We tested the validity of this new algorithm on a\nrange of network architectures such as fully connected, convolutional and LSTM\nnetworks. Simulation results on these various networks show that whatever\naccuracy is achieved using the conventional SGD algorithm with symmetric\n(ideal) device switching characteristics the same accuracy is also achieved\nusing the \"Tiki-Taka\" algorithm with non-symmetric (non-ideal) device switching\ncharacteristics. Moreover, all the operations performed on the arrays are still\nparallel and therefore the implementation cost of this new algorithm on array\narchitectures is minimal; and it maintains the aforementioned power and speed\nbenefits. These algorithmic improvements are crucial to relax the material\nspecification and to realize technologically viable resistive crossbar arrays\nthat outperform digital accelerators for similar training tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:52:28 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Gokmen", "Tayfun", ""], ["Haensch", "Wilfried", ""]]}, {"id": "1909.07922", "submitter": "Andrea Schioppa", "authors": "Andrea Schioppa", "title": "Distributed Function Minimization in Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on an open-source implementation for distributed function\nminimization on top of Apache Spark by using gradient and quasi-Newton methods.\nWe show-case it with an application to Optimal Transport and some scalability\ntests on classification and regression problems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:38:13 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Schioppa", "Andrea", ""]]}, {"id": "1909.07926", "submitter": "Alexandre Gilotte", "authors": "Alexandre Gilotte", "title": "Ranking metrics on non-shuffled traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking metrics are a family of metrics largely used to evaluate recommender\nsystems. However they typically suffer from the fact the reward is affected by\nthe order in which recommended items are displayed to the user. A classical way\nto overcome this position bias is to uniformly shuffle a proportion of the\nrecommendations, but this method may result in a bad user experience. It is\nnevertheless common to use a stochastic policy to generate the recommendations,\nand we suggest a new method to overcome the position bias, by leveraging the\nstochasticity of the policy used to collect the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:46:47 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Gilotte", "Alexandre", ""]]}, {"id": "1909.07930", "submitter": "Piero Molino", "authors": "Piero Molino, Yaroslav Dudin, Sai Sumanth Miryala", "title": "Ludwig: a type-based declarative deep learning toolbox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present Ludwig, a flexible, extensible and easy to use\ntoolbox which allows users to train deep learning models and use them for\nobtaining predictions without writing code. Ludwig implements a novel approach\nto deep learning model building based on two main abstractions: data types and\ndeclarative configuration files. The data type abstraction allows for easier\ncode and sub-model reuse, and the standardized interfaces imposed by this\nabstraction allow for encapsulation and make the code easy to extend.\nDeclarative model definition configuration files enable inexperienced users to\nobtain effective models and increase the productivity of expert users.\nAlongside these two innovations, Ludwig introduces a general modularized deep\nlearning architecture called Encoder-Combiner-Decoder that can be instantiated\nto perform a vast amount of machine learning tasks. These innovations make it\npossible for engineers, scientists from other fields and, in general, a much\nbroader audience to adopt deep learning models for their tasks, concretely\nhelping in its democratization.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:54:29 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Molino", "Piero", ""], ["Dudin", "Yaroslav", ""], ["Miryala", "Sai Sumanth", ""]]}, {"id": "1909.07944", "submitter": "Omid Shams Solari", "authors": "Omid Shams Solari, Rojin Safavi, James B. Brown", "title": "BLOCCS: Block Sparse Canonical Correlation Analysis With Application To\n  Interpretable Omics Integration", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Block Sparse Canonical Correlation Analysis which estimates\nmultiple pairs of canonical directions (together a \"block\") at once, resulting\nin significantly improved orthogonality of the sparse directions which, we\ndemonstrate, translates to more interpretable solutions. Our approach builds on\nthe sparse CCA method of (Solari, Brown, and Bickel 2019) in that we also\nexpress the bi-convex objective of our block formulation as a concave\nminimization problem over an orthogonal k-frame in a unit Euclidean ball, which\nin turn, due to concavity of the objective, is shrunk to a Stiefel manifold,\nwhich is optimized via gradient descent algorithm. Our simulations show that\nour method outperforms existing sCCA algorithms and implementations in terms of\ncomputational cost and stability, mainly due to the drastic shrinkage of our\nsearch space, and the correlation within and orthogonality between pairs of\nestimated canonical covariates. Finally, we apply our method, available as an\nR-package called BLOCCS, to multi-omic data on Lung Squamous Cell\nCarcinoma(LUSC) obtained via The Cancer Genome Atlas, and demonstrate its\ncapability in capturing meaningful biological associations relevant to the\nhypothesis under study rather than spurious dominant variations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:28:18 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 20:09:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Solari", "Omid Shams", ""], ["Safavi", "Rojin", ""], ["Brown", "James B.", ""]]}, {"id": "1909.07947", "submitter": "Omid Shams Solari", "authors": "Omid S. Solari, James B. Brown, Peter J. Bickel", "title": "Sparse Canonical Correlation Analysis via Concave Minimization", "comments": "45 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to the sparse Canonical Correlation Analysis (sCCA)is proposed\nwith the aim of discovering interpretable associations in very high-dimensional\nmulti-view, i.e.observations of multiple sets of variables on the same\nsubjects, problems. Inspired by the sparse PCA approach of Journee et al.\n(2010), we also show that the sparse CCA formulation, while non-convex, is\nequivalent to a maximization program of a convex objective over a compact set\nfor which we propose a first-order gradient method. This result helps us reduce\nthe search space drastically to the boundaries of the set. Consequently, we\npropose a two-step algorithm, where we first infer the sparsity pattern of the\ncanonical directions using our fast algorithm, then we shrink each view, i.e.\nobservations of a set of covariates, to contain observations on the sets of\ncovariates selected in the previous step, and compute their canonical\ndirections via any CCA algorithm. We also introduceDirected Sparse CCA, which\nis able to find associations which are aligned with a specified experiment\ndesign, andMulti-View sCCA which is used to discover associations between\nmultiple sets of covariates. Our simulations establish the superior convergence\nproperties and computational efficiency of our algorithm as well as accuracy in\nterms of the canonical correlation and its ability to recover the supports of\nthe canonical directions. We study the associations between metabolomics,\ntrasncriptomics and microbiomics in a multi-omic study usingMuLe, which is an\nR-package that implements our approach, in order to form hypotheses on\nmechanisms of adaptations of Drosophila Melanogaster to high doses of\nenvironmental toxicants, specifically Atrazine, which is a commonly used\nchemical fertilizer.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:29:12 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Solari", "Omid S.", ""], ["Brown", "James B.", ""], ["Bickel", "Peter J.", ""]]}, {"id": "1909.07972", "submitter": "Mingzhe Chen", "authors": "Mingzhe Chen, Zhaohui Yang, Walid Saad, Changchuan Yin, H. Vincent\n  Poor, and Shuguang Cui", "title": "A Joint Learning and Communications Framework for Federated Learning\n  over Wireless Networks", "comments": "This paper has been accepted by IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of training federated learning (FL) algorithms\nover a realistic wireless network is studied. In particular, in the considered\nmodel, wireless users execute an FL algorithm while training their local FL\nmodels using their own data and transmitting the trained local FL models to a\nbase station (BS) that will generate a global FL model and send it back to the\nusers. Since all training parameters are transmitted over wireless links, the\nquality of the training will be affected by wireless factors such as packet\nerrors and the availability of wireless resources. Meanwhile, due to the\nlimited wireless bandwidth, the BS must select an appropriate subset of users\nto execute the FL algorithm so as to build a global FL model accurately. This\njoint learning, wireless resource allocation, and user selection problem is\nformulated as an optimization problem whose goal is to minimize an FL loss\nfunction that captures the performance of the FL algorithm. To address this\nproblem, a closed-form expression for the expected convergence rate of the FL\nalgorithm is first derived to quantify the impact of wireless factors on FL.\nThen, based on the expected convergence rate of the FL algorithm, the optimal\ntransmit power for each user is derived, under a given user selection and\nuplink resource block (RB) allocation scheme. Finally, the user selection and\nuplink RB allocation is optimized so as to minimize the FL loss function.\nSimulation results show that the proposed joint federated learning and\ncommunication framework can reduce the FL loss function value by up to 10% and\n16%, respectively, compared to: 1) An optimal user selection algorithm with\nrandom resource allocation and 2) a standard FL algorithm with random user\nselection and resource allocation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 02:38:21 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 01:15:35 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 01:47:28 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Chen", "Mingzhe", ""], ["Yang", "Zhaohui", ""], ["Saad", "Walid", ""], ["Yin", "Changchuan", ""], ["Poor", "H. Vincent", ""], ["Cui", "Shuguang", ""]]}, {"id": "1909.07974", "submitter": "William Leeb", "authors": "William Leeb", "title": "Properties of Laplacian Pyramids for Extension and Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Laplacian pyramids algorithm of Rabin and Coifman for\nextending and denoising a function sampled on a discrete set of points. We\nprovide mild conditions under which the algorithm converges, and prove\nstability bounds on the extended function. We also consider the iterative\napplication of truncated Laplacian pyramids kernels for denoising signals by\nnon-local means.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:28:24 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Leeb", "William", ""]]}, {"id": "1909.08072", "submitter": "Han Xu", "authors": "Han Xu, Yao Ma, Haochen Liu, Debayan Deb, Hui Liu, Jiliang Tang, Anil\n  K. Jain", "title": "Adversarial Attacks and Defenses in Images, Graphs and Text: A Review", "comments": "survey, adversarial attacks, defenses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have achieved unprecedented success in numerous\nmachine learning tasks in various domains. However, the existence of\nadversarial examples has raised concerns about applying deep learning to\nsafety-critical applications. As a result, we have witnessed increasing\ninterests in studying attack and defense mechanisms for DNN models on different\ndata types, such as images, graphs and text. Thus, it is necessary to provide a\nsystematic and comprehensive overview of the main threats of attacks and the\nsuccess of corresponding countermeasures. In this survey, we review the state\nof the art algorithms for generating adversarial examples and the\ncountermeasures against adversarial examples, for the three popular data types,\ni.e., images, graphs and text.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:07:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:58:43 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Xu", "Han", ""], ["Ma", "Yao", ""], ["Liu", "Haochen", ""], ["Deb", "Debayan", ""], ["Liu", "Hui", ""], ["Tang", "Jiliang", ""], ["Jain", "Anil K.", ""]]}, {"id": "1909.08074", "submitter": "Beakal Gizachew Assefa Dr", "authors": "Beakal Gizachew Assefa, Oznur Ozkasap", "title": "HyMER: A Hybrid Machine Learning Framework for Energy Efficient Routing\n  in SDN", "comments": "Double column 12 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined networks (SDN) with programmable data plane and machine\nlearning for discovering patterns are utilized in security, traffic\nclassification, quality of services prediction, and network performance, that\nhas increasing research attention. Addressing the significance of energy\nefficiency in networks, we propose a novel hybrid machine learning-based\nframework named HyMER that combines the capabilities of SDN and machine\nlearning for traffic-aware energy efficient routing. To the best of our\nknowledge, HyMER is the first that utilizes a hybrid machine learning solution\nwith supervised and reinforcement learning components for energy efficiency and\nnetwork performance in SDN. The supervised learning component consists of\nfeature extraction, training, and testing. The reinforcement learning component\nlearns from existing data or from scratch by iteratively interacting with the\nnetwork environment. The HyMER framework is developed on POX controller and is\nevaluated on Mininet using real-world topologies and dynamic traffic traces.\nExperimental results show that the supervised component achieves up to 70%\nfeature size reduction and more than 80\\% accuracy in parameter prediction. We\ndemonstrate that combining the supervised and reinforcement methods not only\ndoes capture the dynamic change more efficiently but also increases the\nconvergence speed. As compared to state-of-the-art utility based energy saving\napproaches, HyMER heuristics has shown up to 50% link saving, and also exhibits\nup to 14.7 watts less power consumption for realistic network topology and\ntraffic traces.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:42:36 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 09:57:02 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Assefa", "Beakal Gizachew", ""], ["Ozkasap", "Oznur", ""]]}, {"id": "1909.08079", "submitter": "Ugo Tanielian", "authors": "Ugo Tanielian, Flavian Vasile", "title": "Relaxed Softmax for learning from Positive and Unlabeled data", "comments": "9 pages, 5 figures, 2 tables, published at RecSys 2019", "journal-ref": "RecSys 2019 Proceedings of the 13th ACM Conference on Recommender\n  Systems", "doi": "10.1145/3298689.3347034", "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the softmax model and its fast approximations have become\nthe de-facto loss functions for deep neural networks when dealing with\nmulti-class prediction. This loss has been extended to language modeling and\nrecommendation, two fields that fall into the framework of learning from\nPositive and Unlabeled data. In this paper, we stress the different drawbacks\nof the current family of softmax losses and sampling schemes when applied in a\nPositive and Unlabeled learning setup. We propose both a Relaxed Softmax loss\n(RS) and a new negative sampling scheme based on Boltzmann formulation. We show\nthat the new training objective is better suited for the tasks of density\nestimation, item similarity and next-event prediction by driving uplifts in\nperformance on textual and recommendation datasets against classical softmax.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:29:57 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Tanielian", "Ugo", ""], ["Vasile", "Flavian", ""]]}, {"id": "1909.08081", "submitter": "Hui Hu", "authors": "Hui Hu, Yijun Liu, Zhen Wang, Chao Lan", "title": "A Distributed Fair Machine Learning Framework with Private Demographic\n  Data Protection", "comments": "9 pages,4 figures,International Conference of Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair machine learning has become a significant research topic with broad\nsocietal impact. However, most fair learning methods require direct access to\npersonal demographic data, which is increasingly restricted to use for\nprotecting user privacy (e.g. by the EU General Data Protection Regulation). In\nthis paper, we propose a distributed fair learning framework for protecting the\nprivacy of demographic data. We assume this data is privately held by a third\nparty, which can communicate with the data center (responsible for model\ndevelopment) without revealing the demographic information. We propose a\nprincipled approach to design fair learning methods under this framework,\nexemplify four methods and show they consistently outperform their existing\ncounterparts in both fairness and accuracy across three real-world data sets.\nWe theoretically analyze the framework, and prove it can learn models with high\nfairness or high accuracy, with their trade-offs balanced by a threshold\nvariable.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:30:16 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Hu", "Hui", ""], ["Liu", "Yijun", ""], ["Wang", "Zhen", ""], ["Lan", "Chao", ""]]}, {"id": "1909.08093", "submitter": "Rozhina Ghanavi", "authors": "Rozhina Ghanavi, Maryam Sabbaghian, and Halim Yanikomeroglu", "title": "Q-Learning Based Aerial Base Station Placement for Fairness Enhancement\n  in Mobile Networks", "comments": "Accepted in IEEE GlobalSIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use an aerial base station (aerial-BS) to enhance fairness\nin a dynamic environment with user mobility. The problem of optimally placing\nthe aerial-BS is a non-deterministic polynomial-time hard (NP-hard) problem.\nMoreover, the network topology is subject to continuous changes due to the user\nmobility. These issues intensify the quest to develop an adaptive and fast\nalgorithm for 3D placement of the aerial-BS. To this end, we propose a method\nbased on reinforcement learning to achieve these goals. Simulation results show\nthat our method increases fairness among users in a reasonable computing time,\nwhile the solution is comparatively close to the optimal solution obtained by\nexhaustive search.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:33:15 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Ghanavi", "Rozhina", ""], ["Sabbaghian", "Maryam", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "1909.08128", "submitter": "Luke Merrick", "authors": "Luke Merrick and Ankur Taly", "title": "The Explanation Game: Explaining Machine Learning Models Using Shapley\n  Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of techniques have been proposed to explain a machine learning\nmodel's prediction by attributing it to the corresponding input features.\nPopular among these are techniques that apply the Shapley value method from\ncooperative game theory. While existing papers focus on the axiomatic\nmotivation of Shapley values, and efficient techniques for computing them, they\noffer little justification for the game formulations used, and do not address\nthe uncertainty implicit in their methods' outputs. For instance, the popular\nSHAP algorithm's formulation may give substantial attributions to features that\nplay no role in the model. In this work, we illustrate how subtle differences\nin the underlying game formulations of existing methods can cause large\ndifferences in the attributions for a prediction. We then present a general\ngame formulation that unifies existing methods, and enables straightforward\nconfidence intervals on their attributions. Furthermore, it allows us to\ninterpret the attributions as contrastive explanations of an input relative to\na distribution of reference inputs. We tie this idea to classic research in\ncognitive psychology on contrastive explanations, and propose a conceptual\nframework for generating and interpreting explanations for ML models, called\nformulate, approximate, explain (FAE). We apply this framework to explain\nblack-box models trained on two UCI datasets and a Lending Club dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 22:15:09 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 20:09:55 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 23:18:21 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Merrick", "Luke", ""], ["Taly", "Ankur", ""]]}, {"id": "1909.08156", "submitter": "Jiaoyang Huang", "authors": "Jiaoyang Huang and Horng-Tzer Yau", "title": "Dynamics of Deep Neural Networks and Neural Tangent Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of a deep neural network trained by the gradient descent can be\ndescribed by its neural tangent kernel (NTK) as introduced in [20], where it\nwas proven that in the infinite width limit the NTK converges to an explicit\nlimiting kernel and it stays constant during training. The NTK was also\nimplicit in some other recent papers [6,13,14]. In the overparametrization\nregime, a fully-trained deep neural network is indeed equivalent to the kernel\nregression predictor using the limiting NTK. And the gradient descent achieves\nzero training loss for a deep overparameterized neural network. However, it was\nobserved in [5] that there is a performance gap between the kernel regression\nusing the limiting NTK and the deep neural networks. This performance gap is\nlikely to originate from the change of the NTK along training due to the finite\nwidth effect. The change of the NTK along the training is central to describe\nthe generalization features of deep neural networks.\n  In the current paper, we study the dynamic of the NTK for finite width deep\nfully-connected neural networks. We derive an infinite hierarchy of ordinary\ndifferential equations, the neural tangent hierarchy (NTH) which captures the\ngradient descent dynamic of the deep neural network. Moreover, under certain\nconditions on the neural network width and the data set dimension, we prove\nthat the truncated hierarchy of NTH approximates the dynamic of the NTK up to\narbitrary precision. This description makes it possible to directly study the\nchange of the NTK for deep neural networks, and sheds light on the observation\nthat deep neural networks outperform kernel regressions using the corresponding\nlimiting NTK.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 00:51:05 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Huang", "Jiaoyang", ""], ["Yau", "Horng-Tzer", ""]]}, {"id": "1909.08159", "submitter": "Brent Davis", "authors": "Brent D. Davis, Ethan Jackson, Daniel J. Lizotte", "title": "Decision-Directed Data Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm, Decision-Directed Data Decomposition (D4), which\ndecomposes a dataset into two components. The first contains most of the useful\ninformation for a specified supervised learning task. The second orthogonal\ncomponent contains little information about the task but retains associations\nand information that were not targeted. The algorithm is simple and scalable.\nWe illustrate its application in image and text processing domains. Our results\nshow that 1) post-hoc application of D4 to an image representation space can\nremove information about specified concepts without impacting other concepts,\n2) D4 is able to improve predictive generalization in certain settings, and 3)\napplying D4 to word embedding representations produces state-of-the-art results\nin debiasing.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 01:20:27 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 20:10:09 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Davis", "Brent D.", ""], ["Jackson", "Ethan", ""], ["Lizotte", "Daniel J.", ""]]}, {"id": "1909.08167", "submitter": "Minlong Peng", "authors": "Minlong Peng, Qi Zhang, Xuanjing Huang", "title": "Weighed Domain-Invariant Representation Learning for Cross-domain\n  Sentiment Analysis", "comments": "Address the problem of the domain-invariant representation learning\n  framework under target shift", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain sentiment analysis is currently a hot topic in the research and\nengineering areas. One of the most popular frameworks in this field is the\ndomain-invariant representation learning (DIRL) paradigm, which aims to learn a\ndistribution-invariant feature representation across domains. However, in this\nwork, we find out that applying DIRL may harm domain adaptation when the label\ndistribution $\\rm{P}(\\rm{Y})$ changes across domains. To address this problem,\nwe propose a modification to DIRL, obtaining a novel weighted domain-invariant\nrepresentation learning (WDIRL) framework. We show that it is easy to transfer\nexisting SOTA DIRL models to WDIRL. Empirical studies on extensive cross-domain\nsentiment analysis tasks verified our statements and showed the effectiveness\nof our proposed solution.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:03:03 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Peng", "Minlong", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1909.08180", "submitter": "Chen Chen", "authors": "Chen Chen, Jaewoo Lee", "title": "Renyi Differentially Private ADMM for Non-Smooth Regularized\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of minimizing composite objective\nfunctions consisting of a convex differentiable loss function plus a non-smooth\nregularization term, such as $L_1$ norm or nuclear norm, under R\\'enyi\ndifferential privacy (RDP). To solve the problem, we propose two stochastic\nalternating direction method of multipliers (ADMM) algorithms: ssADMM based on\ngradient perturbation and mpADMM based on output perturbation. Both algorithms\ndecompose the original problem into sub-problems that have closed-form\nsolutions. The first algorithm, ssADMM, applies the recent privacy\namplification result for RDP to reduce the amount of noise to add. The second\nalgorithm, mpADMM, numerically computes the sensitivity of ADMM variable\nupdates and releases the updated parameter vector at the end of each epoch. We\ncompare the performance of our algorithms with several baseline algorithms on\nboth real and simulated datasets. Experimental results show that, in high\nprivacy regimes (small $\\epsilon$), ssADMM and mpADMM outperform other baseline\nalgorithms in terms of classification and feature selection performance,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:45:12 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 23:35:42 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Chen", "Chen", ""], ["Lee", "Jaewoo", ""]]}, {"id": "1909.08181", "submitter": "Long Nguyen", "authors": "Long H. Nguyen, Zhenhe Pan, Opeyemi Openiyi, Hashim Abu-gellban, Mahdi\n  Moghadasi, Fang Jin", "title": "Self-boosted Time-series Forecasting with Multi-task and Multi-view\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust model for time series forecasting is highly important in many\ndomains, including but not limited to financial forecast, air temperature and\nelectricity consumption. To improve forecasting performance, traditional\napproaches usually require additional feature sets. However, adding more\nfeature sets from different sources of data is not always feasible due to its\naccessibility limitation. In this paper, we propose a novel self-boosted\nmechanism in which the original time series is decomposed into multiple time\nseries. These time series played the role of additional features in which the\nclosely related time series group is used to feed into multi-task learning\nmodel, and the loosely related group is fed into multi-view learning part to\nutilize its complementary information. We use three real-world datasets to\nvalidate our model and show the superiority of our proposed method over\nexisting state-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 00:16:31 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nguyen", "Long H.", ""], ["Pan", "Zhenhe", ""], ["Openiyi", "Opeyemi", ""], ["Abu-gellban", "Hashim", ""], ["Moghadasi", "Mahdi", ""], ["Jin", "Fang", ""]]}, {"id": "1909.08182", "submitter": "Anupiya Nugaliyadde Mr", "authors": "Anupiya Nugaliyadde, Upeka Somaratne and Kok Wai Wong", "title": "Predicting Electricity Consumption using Deep Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity consumption has increased exponentially during the past few\ndecades. This increase is heavily burdening the electricity distributors.\nTherefore, predicting the future demand for electricity consumption will\nprovide an upper hand to the electricity distributor. Predicting electricity\nconsumption requires many parameters. The paper presents two approaches with\none using a Recurrent Neural Network (RNN) and another one using a Long Short\nTerm Memory (LSTM) network, which only considers the previous electricity\nconsumption to predict the future electricity consumption. These models were\ntested on the publicly available London smart meter dataset. To assess the\napplicability of the RNN and the LSTM network to predict electricity\nconsumption, they were tested to predict for an individual house and a block of\nhouses for a given time period. The predictions were done for daily, trimester\nand 13 months, which covers short term, mid-term and long term prediction. Both\nthe RNN and the LSTM network have achieved an average Root Mean Square error of\n0.1.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:49:05 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nugaliyadde", "Anupiya", ""], ["Somaratne", "Upeka", ""], ["Wong", "Kok Wai", ""]]}, {"id": "1909.08184", "submitter": "Jindong Wang Dr.", "authors": "Chaohui Yu, Jindong Wang, Yiqiang Chen, Meiyu Huang", "title": "Transfer Learning with Dynamic Adversarial Adaptation Network", "comments": "ICDM 2019 long paper (9.08% acceptance rate); 9 pages; code available\n  at http://transferlearning.xyz", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep transfer learning reveal that adversarial\nlearning can be embedded into deep networks to learn more transferable features\nto reduce the distribution discrepancy between two domains. Existing\nadversarial domain adaptation methods either learn a single domain\ndiscriminator to align the global source and target distributions or pay\nattention to align subdomains based on multiple discriminators. However, in\nreal applications, the marginal (global) and conditional (local) distributions\nbetween domains are often contributing differently to the adaptation. There is\ncurrently no method to dynamically and quantitatively evaluate the relative\nimportance of these two distributions for adversarial learning. In this paper,\nwe propose a novel Dynamic Adversarial Adaptation Network (DAAN) to dynamically\nlearn domain-invariant representations while quantitatively evaluate the\nrelative importance of global and local domain distributions. To the best of\nour knowledge, DAAN is the first attempt to perform dynamic adversarial\ndistribution adaptation for deep adversarial learning. DAAN is extremely easy\nto implement and train in real applications. We theoretically analyze the\neffectiveness of DAAN, and it can also be explained in an attention strategy.\nExtensive experiments demonstrate that DAAN achieves better classification\naccuracy compared to state-of-the-art deep and adversarial methods. Results\nalso imply the necessity and effectiveness of the dynamic distribution\nadaptation in adversarial transfer learning.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 03:00:46 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Yu", "Chaohui", ""], ["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Huang", "Meiyu", ""]]}, {"id": "1909.08187", "submitter": "Yuhong Guo", "authors": "Xinyuan Lu and Yuhong Guo", "title": "Learning to Generate Questions with Adaptive Copying Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation is an important problem in natural language\nprocessing. In this paper we propose a novel adaptive copying recurrent neural\nnetwork model to tackle the problem of question generation from sentences and\nparagraphs. The proposed model adds a copying mechanism component onto a\nbidirectional LSTM architecture to generate more suitable questions adaptively\nfrom the input data. Our experimental results show the proposed model can\noutperform the state-of-the-art question generation methods in terms of BLEU\nand ROUGE evaluation scores.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:27:45 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Lu", "Xinyuan", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.08188", "submitter": "Abdelkerim Amari", "authors": "Abdelkerim Amari, Xiang Lin, Octavia A. Dobre, Ramachandran\n  Venkatesan, Alex Alvarado", "title": "Fiber Nonlinearity Mitigation via the Parzen Window Classifier for\n  Dispersion Managed and Unmanaged Links", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": "10.1109/ICTON.2019.8840250", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have recently received significant attention as\npromising approaches to deal with the optical channel impairments, and in\nparticular, the nonlinear effects. In this work, a machine learning-based\nclassification technique, known as the Parzen window (PW) classifier, is\napplied to mitigate the nonlinear effects in the optical channel. The PW\nclassifier is used as a detector with improved nonlinear decision boundaries\nmore adapted to the nonlinear fiber channel. Performance improvement is\nobserved when applying the PW in the context of dispersion managed and\ndispersion unmanaged systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:47:05 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Amari", "Abdelkerim", ""], ["Lin", "Xiang", ""], ["Dobre", "Octavia A.", ""], ["Venkatesan", "Ramachandran", ""], ["Alvarado", "Alex", ""]]}, {"id": "1909.08189", "submitter": "Libby Hemphill", "authors": "Libby Hemphill and Angela M. Sch\\\"opke-Gonzalez", "title": "Two Computational Models for Analyzing Political Attention in Social\n  Media", "comments": "Accepted for publication in the International AAAI Conference on Web\n  and Social Media (ICWSM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how political attention is divided and over what subjects is\ncrucial for research on areas such as agenda setting, framing, and political\nrhetoric. Existing methods for measuring attention, such as manual labeling\naccording to established codebooks, are expensive and can be restrictive. We\ndescribe two computational models that automatically distinguish topics in\npoliticians' social media content. Our models---one supervised classifier and\none unsupervised topic model---provide different benefits. The supervised\nclassifier reduces the labor required to classify content according to\npre-determined topic list. However, tweets do more than communicate policy\npositions. Our unsupervised model uncovers both political topics and other\nTwitter uses (e.g., constituent service). These models are effective,\ninexpensive computational tools for political communication and social media\nresearch. We demonstrate their utility and discuss the different analyses they\nafford by applying both models to the tweets posted by members of the 115th\nU.S. Congress.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:00:14 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Hemphill", "Libby", ""], ["Sch\u00f6pke-Gonzalez", "Angela M.", ""]]}, {"id": "1909.08190", "submitter": "Yueru Chen", "authors": "Yueru Chen, C.-C. Jay Kuo", "title": "PixelHop: A Successive Subspace Learning (SSL) Method for Object\n  Classification", "comments": "17 pages, 11 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new machine learning methodology, called successive subspace learning\n(SSL), is introduced in this work. SSL contains four key ingredients: 1)\nsuccessive near-to-far neighborhood expansion; 2) unsupervised dimension\nreduction via subspace approximation; 3) supervised dimension reduction via\nlabel-assisted regression (LAG); and 4) feature concatenation and decision\nmaking. An image-based object classification method, called PixelHop, is\nproposed to illustrate the SSL design. It is shown by experimental results that\nthe PixelHop method outperforms the classic CNN model of similar model\ncomplexity in three benchmarking datasets (MNIST, Fashion MNIST and CIFAR-10).\nAlthough SSL and deep learning (DL) have some high-level concept in common,\nthey are fundamentally different in model formulation, the training process and\ntraining complexity. Extensive discussion on the comparison of SSL and DL is\nmade to provide further insights into the potential of SSL.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:14:19 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Chen", "Yueru", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1909.08203", "submitter": "Yuhong Guo", "authors": "Yuan Wu, Yuhong Guo", "title": "Dual Adversarial Co-Learning for Multi-Domain Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel dual adversarial co-learning approach for\nmulti-domain text classification (MDTC). The approach learns shared-private\nnetworks for feature extraction and deploys dual adversarial regularizations to\nalign features across different domains and between labeled and unlabeled data\nsimultaneously under a discrepancy based co-learning framework, aiming to\nimprove the classifiers' generalization capacity with the learned features. We\nconduct experiments on multi-domain sentiment classification datasets. The\nresults show the proposed approach achieves the state-of-the-art MDTC\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 04:15:43 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wu", "Yuan", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.08210", "submitter": "Jiangsheng You Dr.", "authors": "Jiangsheng You", "title": "Data Mapping and Finite Difference Learning", "comments": "14 pages with 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Restricted Boltzmann machine (RBM) is a two-layer neural network constructed\nas a probabilistic model and its training is to maximize a product of\nprobabilities by the contrastive divergence (CD) scheme. In this paper a data\nmapping is proposed to describe the relationship between the visible and hidden\nlayers and the training is to minimize a squared error on the visible layer by\na finite difference learning. This paper presents three new properties in using\nthe RBM: 1) nodes on the visible and hidden layers can take real-valued matrix\ndata without a probabilistic interpretation; 2) the famous CD1 is a finite\ndifference approximation of the gradient descent; 3) the activation can take\nnon-sigmoid functions such as identity, relu and softsign. The data mapping\nprovides a unified framework on the dimensionality reduction, the feature\nextraction and the data representation pioneered and developed by Hinton and\nhis colleagues. As an approximation of the gradient descent, the finite\ndifference learning is applicable to both directed and undirected graphs.\nNumerical experiments are performed to verify these new properties on the very\nlow dimensionality reduction, the collinearity of timer series data and the use\nof flexible activations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 04:58:25 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 01:04:01 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 01:21:51 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["You", "Jiangsheng", ""]]}, {"id": "1909.08299", "submitter": "Konstantin G\\\"orgen", "authors": "Konstantin G\\\"orgen, Melanie Schienle", "title": "How have German University Tuition Fees Affected Enrollment Rates:\n  Robust Model Selection and Design-based Inference in High-Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use official data for all 16 federal German states to study the causal\neffect of a flat 1000 Euro state-dependent university tuition fee on the\nenrollment behavior of students during the years 2006-2014. In particular, we\nshow how the variation in the introduction scheme across states and times can\nbe exploited to identify the federal average causal effect of tuition fees by\ncontrolling for a large amount of potentially influencing attributes for state\nheterogeneity. We suggest a stability post-double selection methodology to\nrobustly determine the causal effect across types in the transparently modeled\nunknown response components. The proposed stability resampling scheme in the\ntwo LASSO selection steps efficiently mitigates the risk of model\nunderspecification and thus biased effects when the tuition fee policy decision\nalso depends on relevant variables for the state enrollment rates. Correct\ninference for the full cross-section state population in the sample requires\nadequate design -- rather than sampling-based standard errors. With the\ndata-driven model selection and explicit control for spatial cross-effects we\ndetect that tuition fees induce substantial migration effects where the\nmobility occurs both from fee but also from non-fee states suggesting also a\ngeneral movement for quality. Overall, we find a significant negative impact of\nup to 4.5 percentage points of fees on student enrollment. This is in contrast\nto plain one-step LASSO or previous empirical studies with full fixed effects\nlinear panel regressions which generally underestimate the size and get an only\ninsignificant effect.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:12:54 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 09:04:11 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["G\u00f6rgen", "Konstantin", ""], ["Schienle", "Melanie", ""]]}, {"id": "1909.08314", "submitter": "Mark Collier", "authors": "Mark Collier and Joeran Beel", "title": "Memory-Augmented Neural Networks for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-augmented neural networks (MANNs) have been shown to outperform other\nrecurrent neural network architectures on a series of artificial sequence\nlearning tasks, yet they have had limited application to real-world tasks. We\nevaluate direct application of Neural Turing Machines (NTM) and Differentiable\nNeural Computers (DNC) to machine translation. We further propose and evaluate\ntwo models which extend the attentional encoder-decoder with capabilities\ninspired by memory augmented neural networks. We evaluate our proposed models\non IWSLT Vietnamese to English and ACL Romanian to English datasets. Our\nproposed models and the memory augmented neural networks perform similarly to\nthe attentional encoder-decoder on the Vietnamese to English translation task\nwhile have a 0.3-1.9 lower BLEU score for the Romanian to English task.\nInterestingly, our analysis shows that despite being equipped with additional\nflexibility and being randomly initialized memory augmented neural networks\nlearn an algorithm for machine translation almost identical to the attentional\nencoder-decoder.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:39:14 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Collier", "Mark", ""], ["Beel", "Joeran", ""]]}, {"id": "1909.08329", "submitter": "Renjie Gu", "authors": "Renjie Gu, Shuo Yang, Fan Wu", "title": "Distributed Machine Learning on Mobile Devices: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, mobile devices have gained increasingly development with\nstronger computation capability and larger storage. Some of the\ncomputation-intensive machine learning and deep learning tasks can now be run\non mobile devices. To take advantage of the resources available on mobile\ndevices and preserve users' privacy, the idea of mobile distributed machine\nlearning is proposed. It uses local hardware resources and local data to solve\nmachine learning sub-problems on mobile devices, and only uploads computation\nresults instead of original data to contribute to the optimization of the\nglobal model. This architecture can not only relieve computation and storage\nburden on servers, but also protect the users' sensitive information. Another\nbenefit is the bandwidth reduction, as various kinds of local data can now\nparticipate in the training process without being uploaded to the server. In\nthis paper, we provide a comprehensive survey on recent studies of mobile\ndistributed machine learning. We survey a number of widely-used mobile\ndistributed machine learning methods. We also present an in-depth discussion on\nthe challenges and future directions in this area. We believe that this survey\ncan demonstrate a clear overview of mobile distributed machine learning and\nprovide guidelines on applying mobile distributed machine learning to real\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:09:02 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Gu", "Renjie", ""], ["Yang", "Shuo", ""], ["Wu", "Fan", ""]]}, {"id": "1909.08332", "submitter": "Juan Cruz Barsce", "authors": "Juan Cruz Barsce and Jorge A. Palombarini and Ernesto Mart\\'inez", "title": "A Hierarchical Two-tier Approach to Hyper-parameter Optimization in\n  Reinforcement Learning", "comments": "Short paper presented in the Jornadas Argentinas de Inform\\'atica\n  (JAIIO) 2019 (Salta, Argentina), describing an ongoing research on RL\n  hyper-parameter tuning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of hyper-parameters in reinforcement learning (RL) algorithms is\na key task, because they determine how the agent will learn its policy by\ninteracting with its environment, and thus what data is gathered. In this work,\nan approach that uses Bayesian optimization to perform a two-step optimization\nis proposed: first, categorical RL structure hyper-parameters are taken as\nbinary variables and optimized with an acquisition function tailored for such\nvariables. Then, at a lower level of abstraction, solution-level\nhyper-parameters are optimized by resorting to the expected improvement\nacquisition function, while using the best categorical hyper-parameters found\nin the optimization at the upper-level of abstraction. This two-tier approach\nis validated in a simulated control task. Results obtained are promising and\nopen the way for more user-independent applications of reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:14:47 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Barsce", "Juan Cruz", ""], ["Palombarini", "Jorge A.", ""], ["Mart\u00ednez", "Ernesto", ""]]}, {"id": "1909.08375", "submitter": "Thodoris Lykouris", "authors": "Avrim Blum, Thodoris Lykouris", "title": "Advancing subgroup fairness via sleeping experts", "comments": "To appear in ITCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods for improving fairness to subgroups in settings with\noverlapping populations and sequential predictions. Classical notions of\nfairness focus on the balance of some property across different populations.\nHowever, in many applications the goal of the different groups is not to be\npredicted equally but rather to be predicted well. We demonstrate that the task\nof satisfying this guarantee for multiple overlapping groups is not\nstraightforward and show that for the simple objective of unweighted average of\nfalse negative and false positive rate, satisfying this for overlapping\npopulations can be statistically impossible even when we are provided\npredictors that perform well separately on each subgroup. On the positive side,\nwe show that when individuals are equally important to the different groups\nthey belong to, this goal is achievable; to do so, we draw a connection to the\nsleeping experts literature in online learning. Motivated by the one-sided\nfeedback in natural settings of interest, we extend our results to such a\nfeedback model. We also provide a game-theoretic interpretation of our results,\nexamining the incentives of participants to join the system and to provide the\nsystem full information about predictors they may possess. We end with several\ninteresting open problems concerning the strength of guarantees that can be\nachieved in a computationally efficient manner.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 11:51:27 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 02:29:52 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Blum", "Avrim", ""], ["Lykouris", "Thodoris", ""]]}, {"id": "1909.08381", "submitter": "Laurenz Wiskott", "authors": "Laurenz Wiskott and Fabian Sch\\\"onfeld", "title": "Laplacian Matrix for Dimensionality Reduction and Clustering", "comments": "lecture notes, 30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in machine learning can be expressed by means of a graph with\nnodes representing training samples and edges representing the relationship\nbetween samples in terms of similarity, temporal proximity, or label\ninformation. Graphs can in turn be represented by matrices. A special example\nis the Laplacian matrix, which allows us to assign each node a value that\nvaries only little between strongly connected nodes and more between distant\nnodes. Such an assignment can be used to extract a useful feature\nrepresentation, find a good embedding of data in a low dimensional space, or\nperform clustering on the original samples. In these lecture notes we first\nintroduce the Laplacian matrix and then present a small number of algorithms\ndesigned around it.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 11:59:49 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wiskott", "Laurenz", ""], ["Sch\u00f6nfeld", "Fabian", ""]]}, {"id": "1909.08383", "submitter": "Matthias De Lange", "authors": "Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia,\n  Ales Leonardis, Gregory Slabaugh and Tinne Tuytelaars", "title": "A continual learning survey: Defying forgetting in classification tasks", "comments": "Accepted TPAMI paper, including Appendix, code publicly available", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3057446", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks thrive in solving the classification problem for a\nparticular rigid task, acquiring knowledge through generalized learning\nbehaviour from a distinct training phase. The resulting network resembles a\nstatic entity of knowledge, with endeavours to extend this knowledge without\ntargeting the original task resulting in a catastrophic forgetting. Continual\nlearning shifts this paradigm towards networks that can continually accumulate\nknowledge over different tasks without the need to retrain from scratch. We\nfocus on task incremental classification, where tasks arrive sequentially and\nare delineated by clear boundaries. Our main contributions concern 1) a\ntaxonomy and extensive overview of the state-of-the-art, 2) a novel framework\nto continually determine the stability-plasticity trade-off of the continual\nlearner, 3) a comprehensive experimental comparison of 11 state-of-the-art\ncontinual learning methods and 4 baselines. We empirically scrutinize method\nstrengths and weaknesses on three benchmarks, considering Tiny Imagenet and\nlarge-scale unbalanced iNaturalist and a sequence of recognition datasets. We\nstudy the influence of model capacity, weight decay and dropout regularization,\nand the order in which the tasks are presented, and qualitatively compare\nmethods in terms of required memory, computation time, and storage.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 12:07:36 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 15:48:11 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 17:53:39 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["De Lange", "Matthias", ""], ["Aljundi", "Rahaf", ""], ["Masana", "Marc", ""], ["Parisot", "Sarah", ""], ["Jia", "Xu", ""], ["Leonardis", "Ales", ""], ["Slabaugh", "Gregory", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1909.08386", "submitter": "Cesar A. Gomez", "authors": "Cesar A. Gomez, Xianbin Wang, and Abdallah Shami", "title": "Intelligent Active Queue Management Using Explicit Congestion\n  Notification", "comments": "To be presented at the IEEE Global Communications Conference\n  -GLOBECOM- 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more end devices are getting connected, the Internet will become more\ncongested. Various congestion control techniques have been developed either on\ntransport or network layers. Active Queue Management (AQM) is a paradigm that\naims to mitigate the congestion on the network layer through active buffer\ncontrol to avoid overflow. However, finding the right parameters for an AQM\nscheme is challenging, due to the complexity and dynamics of the networks. On\nthe other hand, the Explicit Congestion Notification (ECN) mechanism is a\nsolution that makes visible incipient congestion on the network layer to the\ntransport layer. In this work, we propose to exploit the ECN information to\nimprove AQM algorithms by applying Machine Learning techniques. Our intelligent\nmethod uses an artificial neural network to predict congestion and an AQM\nparameter tuner based on reinforcement learning. The evaluation results show\nthat our solution can enhance the performance of deployed AQM, using the\nexisting TCP congestion control mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 00:16:48 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Gomez", "Cesar A.", ""], ["Wang", "Xianbin", ""], ["Shami", "Abdallah", ""]]}, {"id": "1909.08401", "submitter": "Yannick Deville", "authors": "Yannick Deville, Alain Deville", "title": "Quantum process tomography with unknown single-preparation input states", "comments": null, "journal-ref": "Phys. Rev. A 101, 042332 (2020)", "doi": "10.1103/PhysRevA.101.042332", "report-no": null, "categories": "quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Process Tomography (QPT) methods aim at identifying, i.e. estimating,\na given quantum process. QPT is a major quantum information processing tool,\nsince it especially allows one to characterize the actual behavior of quantum\ngates, which are the building blocks of quantum computers. However, usual QPT\nprocedures are complicated, since they set several constraints on the quantum\nstates used as inputs of the process to be characterized. In this paper, we\nextend QPT so as to avoid two such constraints. On the one hand, usual QPT\nmethods requires one to know, hence to precisely control (i.e. prepare), the\nspecific quantum states used as inputs of the considered quantum process, which\nis cumbersome. We therefore propose a Blind, or unsupervised, extension of QPT\n(i.e. BQPT), which means that this approach uses input quantum states whose\nvalues are unknown and arbitrary, except that they are requested to meet some\ngeneral known properties (and this approach exploits the output states of the\nconsidered quantum process). On the other hand, usual QPT methods require one\nto be able to prepare many copies of the same (known) input state, which is\nconstraining. On the contrary, we propose \"single-preparation methods\", i.e.\nmethods which can operate with only one instance of each considered input\nstate. These two new concepts are here illustrated with practical BQPT methods\nwhich are numerically validated, in the case when: i) random pure states are\nused as inputs and their required properties are especially related to the\nstatistical independence of the random variables that define them, ii) the\nconsidered quantum process is based on cylindrical-symmetry Heisenberg spin\ncoupling. These concepts may be extended to a much wider class of processes and\nto BQPT methods based on other input quantum state properties.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 12:40:21 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Deville", "Yannick", ""], ["Deville", "Alain", ""]]}, {"id": "1909.08410", "submitter": "William Taylor", "authors": "William Taylor", "title": "Learnability Can Be Independent of ZFC Axioms: Explanations and\n  Implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Ben-David et al.'s \"Learnability Can Be Undecidable,\" they prove an\nindependence result in theoretical machine learning. In particular, they define\na new type of learnability, called Estimating The Maximum (EMX) learnability.\nThey argue that this type of learnability fits in with other notions such as\nPAC learnability, Vapnik's statistical learning setting, and other general\nlearning settings. However, using some set-theoretic techniques, they show that\nsome learning problems in the EMX setting are independent of ZFC. Specifically\nthey prove that ZFC cannot prove or disprove EMX learnability of the finite\nsubsets on the [0,1] interval. Moreover, the way they prove it shows that there\ncan be no characteristic dimension for EMX; and, hence, for general learning\nsettings. Here, I will explain their findings, discuss some limitations on\nthose findings, and offer some suggestions about how to excise that\nundecidability. Parts 2-3 will explain the results of the paper, part 4-5 will\ndiscuss some limitations and next steps, and I will conclude in part 6.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 23:26:17 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Taylor", "William", ""]]}, {"id": "1909.08417", "submitter": "Hongwei Lin", "authors": "Zhetong Dong, Hongwei Lin, Chi Zhou", "title": "Persistence B-Spline Grids: Stable Vector Representation of Persistence\n  Diagrams Based on Data Fitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decades, many attempts have been made to optimally integrate\nmachine learning (ML) and topological data analysis. A prominent problem in\napplying persistent homology to ML tasks is finding a vector representation of\na persistence diagram (PD), which is a summary diagram for representing\ntopological features. From the perspective of data fitting, a stable vector\nrepresentation, persistence B-spline grid (PB), is proposed based on the\nefficient technique of progressive-iterative approximation for least-squares\nB-spline surface fitting. Meanwhile, we theoretically prove that the PB method\nis stable with respect to the metrics defined on the PD space, i.e., the\n$p$-Wasserstein distance and the bottleneck distance. The proposed method was\ntested on a synthetic dataset, datasets of randomly generated PDs, data of a\ndynamical system, and 3D CAD models.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:09:43 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Dong", "Zhetong", ""], ["Lin", "Hongwei", ""], ["Zhou", "Chi", ""]]}, {"id": "1909.08423", "submitter": "Jan Hermann", "authors": "Jan Hermann, Zeno Sch\\\"atzle, Frank No\\'e", "title": "Deep neural network solution of the electronic Schr\\\"odinger equation", "comments": "Add notice about new results in journal-published version", "journal-ref": null, "doi": "10.1038/s41557-020-0544-y", "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [New and updated results were published in Nature Chemistry,\ndoi:10.1038/s41557-020-0544-y.] The electronic Schr\\\"odinger equation describes\nfundamental properties of molecules and materials, but can only be solved\nanalytically for the hydrogen atom. The numerically exact full\nconfiguration-interaction method is exponentially expensive in the number of\nelectrons. Quantum Monte Carlo is a possible way out: it scales well to large\nmolecules, can be parallelized, and its accuracy has, as yet, only been limited\nby the flexibility of the used wave function ansatz. Here we propose PauliNet,\na deep-learning wave function ansatz that achieves nearly exact solutions of\nthe electronic Schr\\\"odinger equation. PauliNet has a multireference\nHartree-Fock solution built in as a baseline, incorporates the physics of valid\nwave functions, and is trained using variational quantum Monte Carlo (VMC).\nPauliNet outperforms comparable state-of-the-art VMC ansatzes for atoms,\ndiatomic molecules and a strongly-correlated hydrogen chain by a margin and is\nyet computationally efficient. We anticipate that thanks to the favourable\nscaling with system size, this method may become a new leading method for\nhighly accurate electronic-strucutre calculations on medium-sized molecular\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:52:50 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 17:28:50 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 16:16:49 GMT"}, {"version": "v4", "created": "Thu, 30 Jul 2020 12:00:53 GMT"}, {"version": "v5", "created": "Wed, 23 Sep 2020 22:12:25 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Hermann", "Jan", ""], ["Sch\u00e4tzle", "Zeno", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1909.08471", "submitter": "Olivier Jeunen", "authors": "Olivier Jeunen, Dmytro Mykhaylov, David Rohde, Flavian Vasile,\n  Alexandre Gilotte, Martin Bompaire", "title": "Learning from Bandit Feedback: An Overview of the State-of-the-art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning we often try to optimise a decision rule that would have\nworked well over a historical dataset; this is the so called empirical risk\nminimisation principle. In the context of learning from recommender system\nlogs, applying this principle becomes a problem because we do not have\navailable the reward of decisions we did not do. In order to handle this\n\"bandit-feedback\" setting, several Counterfactual Risk Minimisation (CRM)\nmethods have been proposed in recent years, that attempt to estimate the\nperformance of different policies on historical data. Through importance\nsampling and various variance reduction techniques, these methods allow more\nrobust learning and inference than classical approaches. It is difficult to\naccurately estimate the performance of policies that frequently perform actions\nthat were infrequently done in the past and a number of different types of\nestimators have been proposed.\n  In this paper, we review several methods, based on different off-policy\nestimators, for learning from bandit feedback. We discuss key differences and\ncommonalities among existing approaches, and compare their empirical\nperformance on the RecoGym simulation environment. To the best of our\nknowledge, this work is the first comparison study for bandit algorithms in a\nrecommender system setting.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 14:26:28 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Jeunen", "Olivier", ""], ["Mykhaylov", "Dmytro", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""], ["Gilotte", "Alexandre", ""], ["Bompaire", "Martin", ""]]}, {"id": "1909.08496", "submitter": "Huanrui Yang", "authors": "Jingyang Zhang, Huanrui Yang, Fan Chen, Yitu Wang, Hai Li", "title": "Exploring Bit-Slice Sparsity in Deep Neural Networks for Efficient\n  ReRAM-Based Deployment", "comments": "To be appeared in the 5th Workshop on Energy Efficient Machine\n  Learning and Cognitive Computing (EMC2) co-located with NeurIPS 2019,\n  Vancouver, Canada. (Oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging resistive random-access memory (ReRAM) has recently been intensively\ninvestigated to accelerate the processing of deep neural networks (DNNs). Due\nto the in-situ computation capability, analog ReRAM crossbars yield significant\nthroughput improvement and energy reduction compared to traditional digital\nmethods. However, the power hungry analog-to-digital converters (ADCs) prevent\nthe practical deployment of ReRAM-based DNN accelerators on end devices with\nlimited chip area and power budget. We observe that due to the limited\nbit-density of ReRAM cells, DNN weights are bit sliced and correspondingly\nstored on multiple ReRAM bitlines. The accumulated current on bitlines resulted\nby weights directly dictates the overhead of ADCs. As such, bitwise weight\nsparsity rather than the sparsity of the full weight, is desirable for\nefficient ReRAM deployment. In this work, we propose bit-slice L1, the first\nalgorithm to induce bit-slice sparsity during the training of dynamic\nfixed-point DNNs. Experiment results show that our approach achieves 2x\nsparsity improvement compared to previous algorithms. The resulting sparsity\nallows the ADC resolution to be reduced to 1-bit of the most significant\nbit-slice and down to 3-bit for the others bits, which significantly speeds up\nprocessing and reduces power and area overhead.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:19:22 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 19:04:27 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Jingyang", ""], ["Yang", "Huanrui", ""], ["Chen", "Fan", ""], ["Wang", "Yitu", ""], ["Li", "Hai", ""]]}, {"id": "1909.08518", "submitter": "Ashesh Rambachan", "authors": "Ashesh Rambachan and Jonathan Roth", "title": "Bias In, Bias Out? Evaluating the Folk Wisdom", "comments": null, "journal-ref": "1st Symposium on Foundations of Responsible Computing (FORC 2020)", "doi": "10.4230/LIPIcs.FORC.2020.6", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the folk wisdom that algorithmic decision rules trained on data\nproduced by biased human decision-makers necessarily reflect this bias. We\nconsider a setting where training labels are only generated if a biased\ndecision-maker takes a particular action, and so \"biased\" training data arise\ndue to discriminatory selection into the training data. In our baseline model,\nthe more biased the decision-maker is against a group, the more the algorithmic\ndecision rule favors that group. We refer to this phenomenon as \"bias\nreversal.\" We then clarify the conditions that give rise to bias reversal.\nWhether a prediction algorithm reverses or inherits bias depends critically on\nhow the decision-maker affects the training data as well as the label used in\ntraining. We illustrate our main theoretical results in a simulation study\napplied to the New York City Stop, Question and Frisk dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:50:19 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 02:45:01 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 19:19:02 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Rambachan", "Ashesh", ""], ["Roth", "Jonathan", ""]]}, {"id": "1909.08525", "submitter": "Guan Wang", "authors": "Guan Wang, Charlie Xiaoqian Dang, Ziye Zhou", "title": "Measure Contribution of Participants in Federated Learning", "comments": "arXiv admin note: text overlap with arXiv:1905.04519", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Machine Learning (FML) creates an ecosystem for multiple parties to\ncollaborate on building models while protecting data privacy for the\nparticipants. A measure of the contribution for each party in FML enables fair\ncredits allocation. In this paper we develop simple but powerful techniques to\nfairly calculate the contributions of multiple parties in FML, in the context\nof both horizontal FML and vertical FML. For Horizontal FML we use deletion\nmethod to calculate the grouped instance influence. For Vertical FML we use\nShapley Values to calculate the grouped feature importance. Our methods open\nthe door for research in model contribution and credit allocation in the\ncontext of federated machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 06:13:04 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wang", "Guan", ""], ["Dang", "Charlie Xiaoqian", ""], ["Zhou", "Ziye", ""]]}, {"id": "1909.08526", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia and Neil Zhenqiang Gong", "title": "Defending against Machine Learning based Inference Attacks via\n  Adversarial Examples: Opportunities and Challenges", "comments": "Book chapter. arXiv admin note: substantial text overlap with\n  arXiv:1805.04810", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) becomes more and more powerful and easily\naccessible, attackers increasingly leverage ML to perform automated large-scale\ninference attacks in various domains. In such an ML-equipped inference attack,\nan attacker has access to some data (called public data) of an individual, a\nsoftware, or a system; and the attacker uses an ML classifier to automatically\ninfer their private data. Inference attacks pose severe privacy and security\nthreats to individuals and systems. Inference attacks are successful because\nprivate data are statistically correlated with public data, and ML classifiers\ncan capture such statistical correlations. In this chapter, we discuss the\nopportunities and challenges of defending against ML-equipped inference attacks\nvia adversarial examples. Our key observation is that attackers rely on ML\nclassifiers in inference attacks. The adversarial machine learning community\nhas demonstrated that ML classifiers have various vulnerabilities. Therefore,\nwe can turn the vulnerabilities of ML into defenses against inference attacks.\nFor example, ML classifiers are vulnerable to adversarial examples, which add\ncarefully crafted noise to normal examples such that an ML classifier makes\npredictions for the examples as we desire. To defend against inference attacks,\nwe can add carefully crafted noise into the public data to turn them into\nadversarial examples, such that attackers' classifiers make incorrect\npredictions for the private data. However, existing methods to construct\nadversarial examples are insufficient because they did not consider the unique\nchallenges and requirements for the crafted noise at defending against\ninference attacks. In this chapter, we take defending against inference attacks\nin online social networks as an example to illustrate the opportunities and\nchallenges.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:34:06 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 02:26:14 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1909.08528", "submitter": "Peyman Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Farhood Rismanchian, Peyman Hosseinzadeh\n  Kassani", "title": "k-Relevance Vectors: Considering Relevancy Beside Nearness", "comments": "Will be submitted to Applied Soft Computing Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study combines two different learning paradigms, k-nearest neighbor\n(k-NN) rule, as memory-based learning paradigm and relevance vector machines\n(RVM), as statistical learning paradigm. This combination is performed in\nkernel space and is called k-relevance vector (k-RV). The purpose is to improve\nthe performance of k-NN rule. The proposed model significantly prunes\nirrelevant attributes. We also introduced a new parameter, responsible for\nearly stopping of iterations in RVM. We show that the new parameter improves\nthe classification accuracy of k-RV. Intensive experiments are conducted on\nseveral classification datasets from University of California Irvine (UCI)\nrepository and two real datasets from computer vision domain. The performance\nof k-RV is highly competitive compared to a few state-of-the-arts in terms of\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 16:03:35 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 21:34:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Rismanchian", "Farhood", ""], ["Kassani", "Peyman Hosseinzadeh", ""]]}, {"id": "1909.08531", "submitter": "Jindong Wang", "authors": "Jindong Wang, Yiqiang Chen, Wenjie Feng, Han Yu, Meiyu Huang, Qiang\n  Yang", "title": "Transfer Learning with Dynamic Distribution Adaptation", "comments": "Accepted to ACM Transactions on Intelligent Systems and Technology\n  (ACM TIST) 2019, 25 pages. arXiv admin note: text overlap with\n  arXiv:1807.07258", "journal-ref": "ACM Transactions on Intelligent Systems and Technology (ACM TIST)\n  2019", "doi": "10.1145/3360309", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims to learn robust classifiers for the target domain by\nleveraging knowledge from a source domain. Since the source and the target\ndomains are usually from different distributions, existing methods mainly focus\non adapting the cross-domain marginal or conditional distributions. However, in\nreal applications, the marginal and conditional distributions usually have\ndifferent contributions to the domain discrepancy. Existing methods fail to\nquantitatively evaluate the different importance of these two distributions,\nwhich will result in unsatisfactory transfer performance. In this paper, we\npropose a novel concept called Dynamic Distribution Adaptation (DDA), which is\ncapable of quantitatively evaluating the relative importance of each\ndistribution. DDA can be easily incorporated into the framework of structural\nrisk minimization to solve transfer learning problems. On the basis of DDA, we\npropose two novel learning algorithms: (1) Manifold Dynamic Distribution\nAdaptation (MDDA) for traditional transfer learning, and (2) Dynamic\nDistribution Adaptation Network (DDAN) for deep transfer learning. Extensive\nexperiments demonstrate that MDDA and DDAN significantly improve the transfer\nlearning performance and setup a strong baseline over the latest deep and\nadversarial methods on digits recognition, sentiment analysis, and image\nclassification. More importantly, it is shown that marginal and conditional\ndistributions have different contributions to the domain divergence, and our\nDDA is able to provide good quantitative evaluation of their relative\nimportance which leads to better performance. We believe this observation can\nbe helpful for future research in transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 02:59:22 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Feng", "Wenjie", ""], ["Yu", "Han", ""], ["Huang", "Meiyu", ""], ["Yang", "Qiang", ""]]}, {"id": "1909.08540", "submitter": "Pier Giuseppe Sessa", "authors": "Pier Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, Andreas\n  Krause", "title": "No-Regret Learning in Unknown Games with Correlated Payoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to play a repeated multi-agent game with\nan unknown reward function. Single player online learning algorithms attain\nstrong regret bounds when provided with full information feedback, which\nunfortunately is unavailable in many real-world scenarios. Bandit feedback\nalone, i.e., observing outcomes only for the selected action, yields\nsubstantially worse performance. In this paper, we consider a natural model\nwhere, besides a noisy measurement of the obtained reward, the player can also\nobserve the opponents' actions. This feedback model, together with a regularity\nassumption on the reward function, allows us to exploit the correlations among\ndifferent game outcomes by means of Gaussian processes (GPs). We propose a\nnovel confidence-bound based bandit algorithm GP-MW, which utilizes the GP\nmodel for the reward function and runs a multiplicative weight (MW) method. We\nobtain novel kernel-dependent regret bounds that are comparable to the known\nbounds in the full information setting, while substantially improving upon the\nexisting bandit results. We experimentally demonstrate the effectiveness of\nGP-MW in random matrix games, as well as real-world problems of traffic routing\nand movie recommendation. In our experiments, GP-MW consistently outperforms\nseveral baselines, while its performance is often comparable to methods that\nhave access to full information feedback.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 16:09:09 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 09:08:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Sessa", "Pier Giuseppe", ""], ["Bogunovic", "Ilija", ""], ["Kamgarpour", "Maryam", ""], ["Krause", "Andreas", ""]]}, {"id": "1909.08574", "submitter": "Kadierdan Kaheman", "authors": "Kadierdan Kaheman, Eurika Kaiser, Benjamin Strom, J. Nathan Kutz,\n  Steven L. Brunton", "title": "Learning Discrepancy Models From Experimental Data", "comments": "8 pages, 5 figures, accepted by Conference on Decision and Control\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First principles modeling of physical systems has led to significant\ntechnological advances across all branches of science. For nonlinear systems,\nhowever, small modeling errors can lead to significant deviations from the\ntrue, measured behavior. Even in mechanical systems, where the equations are\nassumed to be well-known, there are often model discrepancies corresponding to\nnonlinear friction, wind resistance, etc. Discovering models for these\ndiscrepancies remains an open challenge for many complex systems. In this work,\nwe use the sparse identification of nonlinear dynamics (SINDy) algorithm to\ndiscover a model for the discrepancy between a simplified model and measurement\ndata. In particular, we assume that the model mismatch can be sparsely\nrepresented in a library of candidate model terms. We demonstrate the efficacy\nof our approach on several examples including experimental data from a double\npendulum on a cart. We further design and implement a feed-forward controller\nin simulations, showing improvement with a discrepancy model.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:04:03 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Kaheman", "Kadierdan", ""], ["Kaiser", "Eurika", ""], ["Strom", "Benjamin", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "1909.08593", "submitter": "Daniel M. Ziegler", "authors": "Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec\n  Radford, Dario Amodei, Paul Christiano, Geoffrey Irving", "title": "Fine-Tuning Language Models from Human Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward learning enables the application of reinforcement learning (RL) to\ntasks where reward is defined by human judgment, building a model of reward by\nasking humans questions. Most work on reward learning has used simulated\nenvironments, but complex information about values is often expressed in\nnatural language, and we believe reward learning for language is a key to\nmaking RL practical and safe for real-world tasks. In this paper, we build on\nadvances in generative pretraining of language models to apply reward learning\nto four natural language tasks: continuing text with positive sentiment or\nphysically descriptive language, and summarization tasks on the TL;DR and\nCNN/Daily Mail datasets. For stylistic continuation we achieve good results\nwith only 5,000 comparisons evaluated by humans. For summarization, models\ntrained with 60,000 comparisons copy whole sentences from the input but skip\nirrelevant preamble; this leads to reasonable ROUGE scores and very good\nperformance according to our human labelers, but may be exploiting the fact\nthat labelers rely on simple heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:33:39 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 23:02:36 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ziegler", "Daniel M.", ""], ["Stiennon", "Nisan", ""], ["Wu", "Jeffrey", ""], ["Brown", "Tom B.", ""], ["Radford", "Alec", ""], ["Amodei", "Dario", ""], ["Christiano", "Paul", ""], ["Irving", "Geoffrey", ""]]}, {"id": "1909.08610", "submitter": "Quanquan Gu", "authors": "Pan Xu and Felicia Gao and Quanquan Gu", "title": "Sample Efficient Policy Gradient Methods with Recursive Variance\n  Reduction", "comments": "22 pages, 2 figures, 3 tables. In ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the sample efficiency in reinforcement learning has been a\nlong-standing research problem. In this work, we aim to reduce the sample\ncomplexity of existing policy gradient methods. We propose a novel policy\ngradient algorithm called SRVR-PG, which only requires $O(1/\\epsilon^{3/2})$\nepisodes to find an $\\epsilon$-approximate stationary point of the nonconcave\nperformance function $J(\\boldsymbol{\\theta})$ (i.e., $\\boldsymbol{\\theta}$ such\nthat $\\|\\nabla J(\\boldsymbol{\\theta})\\|_2^2\\leq\\epsilon$). This sample\ncomplexity improves the existing result $O(1/\\epsilon^{5/3})$ for stochastic\nvariance reduced policy gradient algorithms by a factor of\n$O(1/\\epsilon^{1/6})$. In addition, we also propose a variant of SRVR-PG with\nparameter exploration, which explores the initial policy parameter from a prior\nprobability distribution. We conduct numerical experiments on classic control\nproblems in reinforcement learning to validate the performance of our proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:58:48 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:42:14 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Xu", "Pan", ""], ["Gao", "Felicia", ""], ["Gu", "Quanquan", ""]]}, {"id": "1909.08612", "submitter": "Arnaud Belletoile PhD", "authors": "Arnaud Bell\\'etoile (for the Cdiscount datascience team)", "title": "Large e-retailer image dataset for visual search and product\n  classification", "comments": "5 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results of deep convolutional networks in visual recognition\nchallenges open the path to a whole new set of disruptive user experiences such\nas visual search or recommendation. The list of companies offering this type of\nservice is growing everyday but the adoption rate and the relevancy of results\nmay vary a lot. We believe that the availability of large and diverse datasets\nis a necessary condition to improve the relevancy of such recommendation\nsystems and facilitate their adoption. For that purpose, we wish to share with\nthe community this dataset of more than 12M images of the 7M products of our\nonline store classified into 5K categories. This original dataset is introduced\nin this article and several features are described. We also present some\naspects of the winning solutions of our image classification challenge that was\norganized on the Kaggle platform around this set of images.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:21:53 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Bell\u00e9toile", "Arnaud", "", "for the Cdiscount datascience team"]]}, {"id": "1909.08749", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Martin J. Wainwright", "title": "Instance-dependent $\\ell_\\infty$-bounds for policy evaluation in tabular\n  reinforcement learning", "comments": "Version v2 is consistent with manuscript to appear in IEEE\n  Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov reward processes (MRPs) are used to model stochastic phenomena arising\nin operations research, control engineering, robotics, and artificial\nintelligence, as well as communication and transportation networks. In many of\nthese cases, such as in the policy evaluation problem encountered in\nreinforcement learning, the goal is to estimate the long-term value function of\nsuch a process without access to the underlying population transition and\nreward functions. Working with samples generated under the synchronous model,\nwe study the problem of estimating the value function of an infinite-horizon,\ndiscounted MRP on finitely many states in the $\\ell_\\infty$-norm. We analyze\nboth the standard plug-in approach to this problem and a more robust variant,\nand establish non-asymptotic bounds that depend on the (unknown) problem\ninstance, as well as data-dependent bounds that can be evaluated based on the\nobservations of state-transitions and rewards. We show that these approaches\nare minimax-optimal up to constant factors over natural sub-classes of MRPs.\nOur analysis makes use of a leave-one-out decoupling argument tailored to the\npolicy evaluation problem, one which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 00:38:10 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 18:20:33 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1909.08755", "submitter": "Banghua Zhu", "authors": "Banghua Zhu, Jiantao Jiao and Jacob Steinhardt", "title": "Generalized Resilience and Robust Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust statistics traditionally focuses on outliers, or perturbations in\ntotal variation distance. However, a dataset could be corrupted in many other\nways, such as systematic measurement errors and missing covariates. We\ngeneralize the robust statistics approach to consider perturbations under any\nWasserstein distance, and show that robust estimation is possible whenever a\ndistribution's population statistics are robust under a certain family of\nfriendly perturbations. This generalizes a property called resilience\npreviously employed in the special case of mean estimation with outliers. We\njustify the generalized resilience property by showing that it holds under\nmoment or hypercontractive conditions. Even in the total variation case, these\nsubsume conditions in the literature for mean estimation, regression, and\ncovariance estimation; the resulting analysis simplifies and sometimes improves\nthese known results in both population limit and finite-sample rate. Our robust\nestimators are based on minimum distance (MD) functionals (Donoho and Liu,\n1988), which project onto a set of distributions under a discrepancy related to\nthe perturbation. We present two approaches for designing MD estimators with\ngood finite-sample rates: weakening the discrepancy and expanding the set of\ndistributions. We also present connections to Gao et al. (2019)'s recent\nanalysis of generative adversarial networks for robust estimation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 01:08:06 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 06:36:12 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 07:50:19 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1909.08786", "submitter": "Artem Lutov", "authors": "Artem Lutov, Mourad Khayati and Philippe Cudr\\'e-Mauroux", "title": "DAOC: Stable Clustering of Large Networks", "comments": "IEEE BigData'19, Special Session on Intelligent Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.LG physics.soc-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering is a crucial component of many data mining systems involving the\nanalysis and exploration of various data. Data diversity calls for clustering\nalgorithms to be accurate while providing stable (i.e., deterministic and\nrobust) results on arbitrary input networks. Moreover, modern systems often\noperate with large datasets, which implicitly constrains the complexity of the\nclustering algorithm. Existing clustering techniques are only partially stable,\nhowever, as they guarantee either determinism or robustness. To address this\nissue, we introduce DAOC, a Deterministic and Agglomerative Overlapping\nClustering algorithm. DAOC leverages a new technique called Overlap\nDecomposition to identify fine-grained clusters in a deterministic way\ncapturing multiple optima. In addition, it leverages a novel consensus\napproach, Mutual Maximal Gain, to ensure robustness and further improve the\nstability of the results while still being capable of identifying micro-scale\nclusters. Our empirical results on both synthetic and real-world networks show\nthat DAOC yields stable clusters while being on average 25% more accurate than\nstate-of-the-art deterministic algorithms without requiring any tuning. Our\napproach has the ambition to greatly simplify and speed up data analysis tasks\ninvolving iterative processing (need for determinism) as well as data\nfluctuations (need for robustness) and to provide accurate and reproducible\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 03:12:05 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 20:47:56 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Lutov", "Artem", ""], ["Khayati", "Mourad", ""], ["Cudr\u00e9-Mauroux", "Philippe", ""]]}, {"id": "1909.08787", "submitter": "Viet Huynh", "authors": "Viet Huynh and Nhat Ho and Nhan Dam and XuanLong Nguyen and Mikhail\n  Yurochkin and Hung Bui and and Dinh Phung", "title": "On Efficient Multilevel Clustering via Wasserstein Distances", "comments": "32 pages, 8 figures, JMLR submission. arXiv admin note: substantial\n  text overlap with arXiv:1706.03883", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel approach to the problem of multilevel clustering, which\naims to simultaneously partition data in each group and discover grouping\npatterns among groups in a potentially large hierarchically structured corpus\nof data. Our method involves a joint optimization formulation over several\nspaces of discrete probability measures, which are endowed with Wasserstein\ndistance metrics. We propose several variants of this problem, which admit fast\noptimization algorithms, by exploiting the connection to the problem of finding\nWasserstein barycenters. Consistency properties are established for the\nestimates of both local and global clusters. Finally, experimental results with\nboth synthetic and real data are presented to demonstrate the flexibility and\nscalability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 03:23:13 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 03:40:15 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Huynh", "Viet", ""], ["Ho", "Nhat", ""], ["Dam", "Nhan", ""], ["Nguyen", "XuanLong", ""], ["Yurochkin", "Mikhail", ""], ["Bui", "Hung", ""], ["Phung", "and Dinh", ""]]}, {"id": "1909.08830", "submitter": "Sekitoshi Kanai", "authors": "Sekitoshi Kanai, Yasutoshi Ida, Yasuhiro Fujiwara, Masanori Yamada,\n  Shuichi Adachi", "title": "Absum: Simple Regularization Method for Reducing Structural Sensitivity\n  of Convolutional Neural Networks", "comments": "16 pages, 39 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Absum, which is a regularization method for improving adversarial\nrobustness of convolutional neural networks (CNNs). Although CNNs can\naccurately recognize images, recent studies have shown that the convolution\noperations in CNNs commonly have structural sensitivity to specific noise\ncomposed of Fourier basis functions. By exploiting this sensitivity, they\nproposed a simple black-box adversarial attack: Single Fourier attack. To\nreduce structural sensitivity, we can use regularization of convolution filter\nweights since the sensitivity of linear transform can be assessed by the norm\nof the weights. However, standard regularization methods can prevent\nminimization of the loss function because they impose a tight constraint for\nobtaining high robustness. To solve this problem, Absum imposes a loose\nconstraint; it penalizes the absolute values of the summation of the parameters\nin the convolution layers. Absum can improve robustness against single Fourier\nattack while being as simple and efficient as standard regularization methods\n(e.g., weight decay and L1 regularization). Our experiments demonstrate that\nAbsum improves robustness against single Fourier attack more than standard\nregularization methods. Furthermore, we reveal that robust CNNs with Absum are\nmore robust against transferred attacks due to decreasing the common\nsensitivity and against high-frequency noise than standard regularization\nmethods. We also reveal that Absum can improve robustness against\ngradient-based attacks (projected gradient descent) when used with adversarial\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 07:05:14 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Kanai", "Sekitoshi", ""], ["Ida", "Yasutoshi", ""], ["Fujiwara", "Yasuhiro", ""], ["Yamada", "Masanori", ""], ["Adachi", "Shuichi", ""]]}, {"id": "1909.08864", "submitter": "Michael Smith", "authors": "Michael Thomas Smith, Kathrin Grosse, Michael Backes, Mauricio A\n  Alvarez", "title": "Adversarial Vulnerability Bounds for Gaussian Process Classification", "comments": "10 pages + 2 pages references + 7 pages of supplementary. 12 figures.\n  Submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) classification is increasingly used in safety-critical\nsystems. Protecting ML classifiers from adversarial examples is crucial. We\npropose that the main threat is that of an attacker perturbing a confidently\nclassified input to produce a confident misclassification. To protect against\nthis we devise an adversarial bound (AB) for a Gaussian process classifier,\nthat holds for the entire input domain, bounding the potential for any future\nadversarial method to cause such misclassification. This is a formal guarantee\nof robustness, not just an empirically derived result. We investigate how to\nconfigure the classifier to maximise the bound, including the use of a sparse\napproximation, leading to the method producing a practical, useful and provably\nrobust classifier, which we test using a variety of datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:50:01 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Smith", "Michael Thomas", ""], ["Grosse", "Kathrin", ""], ["Backes", "Michael", ""], ["Alvarez", "Mauricio A", ""]]}, {"id": "1909.08891", "submitter": "\\'Alvaro Parafita Mart\\'inez", "authors": "\\'Alvaro Parafita, Jordi Vitri\\`a", "title": "Explaining Visual Models by Causal Attribution", "comments": "2019 ICCV Workshop on Interpreting and Explaining Visual Artificial\n  Intelligence Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model explanations based on pure observational data cannot compute the\neffects of features reliably, due to their inability to estimate how each\nfactor alteration could affect the rest. We argue that explanations should be\nbased on the causal model of the data and the derived intervened causal models,\nthat represent the data distribution subject to interventions. With these\nmodels, we can compute counterfactuals, new samples that will inform us how the\nmodel reacts to feature changes on our input. We propose a novel explanation\nmethodology based on Causal Counterfactuals and identify the limitations of\ncurrent Image Generative Models in their application to counterfactual\ncreation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:52:31 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Parafita", "\u00c1lvaro", ""], ["Vitri\u00e0", "Jordi", ""]]}, {"id": "1909.08929", "submitter": "Yong Goo Kang", "authors": "Yong Goo Kang, Kyung Ho Park, Huy Kang Kim", "title": "Automobile Theft Detection by Clustering Owner Driver Data", "comments": "15 pages, 7 figures, 3 tables, In Proceedings of the 17th escar\n  Europe 2019", "journal-ref": null, "doi": "10.13154/294-6675", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As automobiles become intelligent, automobile theft methods are evolving\nintelligently. Therefore automobile theft detection has become a major research\nchallenge. Data-mining, biometrics, and additional authentication methods have\nbeen proposed to address automobile theft, in previous studies. Among these\nmethods, data-mining can be used to analyze driving characteristics and\nidentify a driver comprehensively. However, it requires a labeled driving\ndataset to achieve high accuracy. It is impractical to use the actual\nautomobile theft detection system because real theft driving data cannot be\ncollected in advance. Hence, we propose a method to detect an automobile theft\nattempt using only owner driving data. We cluster the key features of the owner\ndriving data using the k-means algorithm. After reconstructing the driving data\ninto one of these clusters, theft is detected using an error from the original\ndriving data. To validate the proposed models, we tested our actual driving\ndata and obtained 99% accuracy from the best model. This result demonstrates\nthat our proposed method can detect vehicle theft by using only the car owner's\ndriving data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:56:57 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kang", "Yong Goo", ""], ["Park", "Kyung Ho", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1909.08961", "submitter": "Weimin Wang", "authors": "Weimin Wang, Weiran Wang, Ming Sun, Chao Wang", "title": "Acoustic scene analysis with multi-head attention networks", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic Scene Classification (ASC) is a challenging task, as a single scene\nmay involve multiple events that contain complex sound patterns. For example, a\ncooking scene may contain several sound sources including silverware clinking,\nchopping, frying, etc. What complicates ASC more is that classes of different\nactivities could have overlapping sounds patterns (e.g. both cooking and\ndishwashing could have silverware clinking sound). In this paper, we propose a\nmulti-head attention network to model the complex temporal input structures for\nASC. The proposed network takes the audio's time-frequency representation as\ninput, and it leverages standard VGG plus LSTM layers to extract high-level\nfeature representation. Further more, it applies multiple attention heads to\nsummarize various patterns of sound events into fixed dimensional\nrepresentation, for the purpose of final scene classification. The whole\nnetwork is trained in an end-to-end fashion with back-propagation. Experimental\nresults confirm that our model discovers meaningful sound patterns through the\nattention mechanism, without using explicit supervision in the alignment. We\nevaluated our proposed model using DCASE 2018 Task 5 dataset, and achieved\ncompetitive performance on par with previous winner's results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:53:18 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Wang", "Weimin", ""], ["Wang", "Weiran", ""], ["Sun", "Ming", ""], ["Wang", "Chao", ""]]}, {"id": "1909.08962", "submitter": "Boris Chidlovskii", "authors": "Boris Chidlovskii", "title": "Using Latent Codes for Class Imbalance Problem in Unsupervised Domain\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of severe class imbalance in unsupervised domain\nadaptation, when the class spaces in source and target domains diverge\nconsiderably. Till recently, domain adaptation methods assumed the aligned\nclass spaces, such that reducing distribution divergence makes the transfer\nbetween domains easier. Such an alignment assumption is invalidated in real\nworld scenarios where some source classes are often under-represented or simply\nabsent in the target domain. We revise the current approaches to class\nimbalance and propose a new one that uses latent codes in the adversarial\ndomain adaptation framework. We show how the latent codes can be used to\ndisentangle the silent structure of the target domain and to identify\nunder-represented classes. We show how to learn the latent code reconstruction\njointly with the domain invariant representation and use them to accurately\nestimate the target labels.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:26:53 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Chidlovskii", "Boris", ""]]}, {"id": "1909.08964", "submitter": "Loc Tran H", "authors": "Loc Tran, Linh Tran", "title": "To Detect Irregular Trade Behaviors In Stock Market By Using Graph Based\n  Ranking Methods", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To detect the irregular trade behaviors in the stock market is the important\nproblem in machine learning field. These irregular trade behaviors are\nobviously illegal. To detect these irregular trade behaviors in the stock\nmarket, data scientists normally employ the supervised learning techniques. In\nthis paper, we employ the three graph Laplacian based semi-supervised ranking\nmethods to solve the irregular trade behavior detection problem. Experimental\nresults show that that the un-normalized and symmetric normalized graph\nLaplacian based semi-supervised ranking methods outperform the random walk\nLaplacian based semi-supervised ranking method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:47:27 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Tran", "Loc", ""], ["Tran", "Linh", ""]]}, {"id": "1909.08975", "submitter": "Dieuwke Hupkes", "authors": "Jaap Jumelet, Willem Zuidema and Dieuwke Hupkes", "title": "Analysing Neural Language Models: Contextual Decomposition Reveals\n  Default Reasoning in Number and Gender Assignment", "comments": "To appear at CoNLL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive research has recently shown that recurrent neural language models\nare able to process a wide range of grammatical phenomena. How these models are\nable to perform these remarkable feats so well, however, is still an open\nquestion. To gain more insight into what information LSTMs base their decisions\non, we propose a generalisation of Contextual Decomposition (GCD). In\nparticular, this setup enables us to accurately distil which part of a\nprediction stems from semantic heuristics, which part truly emanates from\nsyntactic cues and which part arise from the model biases themselves instead.\nWe investigate this technique on tasks pertaining to syntactic agreement and\nco-reference resolution and discover that the model strongly relies on a\ndefault reasoning effect to perform these tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 13:24:29 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Jumelet", "Jaap", ""], ["Zuidema", "Willem", ""], ["Hupkes", "Dieuwke", ""]]}, {"id": "1909.08981", "submitter": "Jacob Deasy", "authors": "Jacob Deasy, Ari Ercole and Pietro Li\\`o", "title": "Impact of novel aggregation methods for flexible, time-sensitive EHR\n  prediction without variable selection or cleaning", "comments": "5 pages, 3 tables, 1 figure, preprint under review at the Machine\n  Learning for Health workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic assessment of patient status (e.g. by an automated, continuously\nupdated assessment of outcome) in the Intensive Care Unit (ICU) is of paramount\nimportance for early alerting, decision support and resource allocation.\nExtraction and cleaning of expert-selected clinical variables discards\ninformation and protracts collaborative efforts to introduce machine learning\nin medicine. We present improved aggregation methods for a flexible deep\nlearning architecture which learns a joint representation of patient chart, lab\nand output events. Our models outperform recent deep learning models for\npatient mortality classification using ICU timeseries, by embedding and\naggregating all events with no pre-processing or variable selection. Our model\nachieves a strong performance of AUROC 0.87 at 48 hours on the MIMIC-III\ndataset while using 13,233 unique un-preprocessed variables in an interpretable\nmanner via hourly softmax aggregation. This demonstrates how our method can be\neasily combined with existing electronic health record systems for automated,\ndynamic patient risk analysis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:48:48 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Deasy", "Jacob", ""], ["Ercole", "Ari", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1909.08982", "submitter": "Vasileios Iosifidis", "authors": "Vasileios Iosifidis and Eirini Ntoutsi", "title": "AdaFair: Cumulative Fairness Adaptive Boosting", "comments": "10 pages, to appear in proceedings of the 28th ACM International\n  Conference on Information and Knowledge Management (CIKM)", "journal-ref": null, "doi": "10.1145/3357384.3357974", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of ML-based decision making in domains with high societal\nimpact such as recidivism, job hiring and loan credit has raised a lot of\nconcerns regarding potential discrimination. In particular, in certain cases it\nhas been observed that ML algorithms can provide different decisions based on\nsensitive attributes such as gender or race and therefore can lead to\ndiscrimination. Although, several fairness-aware ML approaches have been\nproposed, their focus has been largely on preserving the overall classification\naccuracy while improving fairness in predictions for both protected and\nnon-protected groups (defined based on the sensitive attribute(s)). The overall\naccuracy however is not a good indicator of performance in case of class\nimbalance, as it is biased towards the majority class. As we will see in our\nexperiments, many of the fairness-related datasets suffer from class imbalance\nand therefore, tackling fairness requires also tackling the imbalance problem.\n  To this end, we propose AdaFair, a fairness-aware classifier based on\nAdaBoost that further updates the weights of the instances in each boosting\nround taking into account a cumulative notion of fairness based upon all\ncurrent ensemble members, while explicitly tackling class-imbalance by\noptimizing the number of ensemble members for balanced classification error.\nOur experiments show that our approach can achieve parity in true positive and\ntrue negative rates for both protected and non-protected groups, while it\nsignificantly outperforms existing fairness-aware methods up to 25% in terms of\nbalanced error.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:09:05 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Iosifidis", "Vasileios", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "1909.08986", "submitter": "Xiao-Yun Zhou", "authors": "Zhao-Yang Wang, Xiao-Yun Zhou, Peichao Li, and Celia Riga, and\n  Guang-Zhong Yang", "title": "Instantiation-Net: 3D Mesh Reconstruction from Single 2D Image for Right\n  Ventricle", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D shape instantiation which reconstructs the 3D shape of a target from\nlimited 2D images or projections is an emerging technique for surgical\nintervention. It improves the currently less-informative and insufficient 2D\nnavigation schemes for robot-assisted Minimally Invasive Surgery (MIS) to 3D\nnavigation. Previously, a general and registration-free framework was proposed\nfor 3D shape instantiation based on Kernel Partial Least Square Regression\n(KPLSR), requiring manually segmented anatomical structures as the\npre-requisite. Two hyper-parameters including the Gaussian width and component\nnumber also need to be carefully adjusted. Deep Convolutional Neural Network\n(DCNN) based framework has also been proposed to reconstruct a 3D point cloud\nfrom a single 2D image, with end-to-end and fully automatic learning. In this\npaper, an Instantiation-Net is proposed to reconstruct the 3D mesh of a target\nfrom its a single 2D image, by using DCNN to extract features from the 2D image\nand Graph Convolutional Network (GCN) to reconstruct the 3D mesh, and using\nFully Connected (FC) layers to connect the DCNN to GCN. Detailed validation was\nperformed to demonstrate the practical strength of the method and its potential\nclinical use.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:22:53 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Wang", "Zhao-Yang", ""], ["Zhou", "Xiao-Yun", ""], ["Li", "Peichao", ""], ["Riga", "Celia", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1909.08987", "submitter": "Mohammed Zubair Mohammed Shamim", "authors": "Mohammed Zubair M. Shamim, Sadatullah Syed, Mohammad Shiblee, Mohammed\n  Usman and Syed Ali", "title": "Automated detection of oral pre-cancerous tongue lesions using deep\n  learning for early diagnosis of oral cavity cancer", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.28808.16643", "report-no": "01", "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering oral cavity cancer (OCC) at an early stage is an effective way to\nincrease patient survival rate. However, current initial screening process is\ndone manually and is expensive for the average individual, especially in\ndeveloping countries worldwide. This problem is further compounded due to the\nlack of specialists in such areas. Automating the initial screening process\nusing artificial intelligence (AI) to detect pre-cancerous lesions can prove to\nbe an effective and inexpensive technique that would allow patients to be\ntriaged accordingly to receive appropriate clinical management. In this study,\nwe have applied and evaluated the efficacy of six deep convolutional neural\nnetwork (DCNN) models using transfer learning, for identifying pre-cancerous\ntongue lesions directly using a small data set of clinically annotated\nphotographic images to diagnose early signs of OCC. DCNN model based on Vgg19\narchitecture was able to differentiate between benign and pre-cancerous tongue\nlesions with a mean classification accuracy of 0.98, sensitivity 0.89 and\nspecificity 0.97. Additionally, the ResNet50 DCNN model was able to distinguish\nbetween five types of tongue lesions i.e. hairy tongue, fissured tongue,\ngeographic tongue, strawberry tongue and oral hairy leukoplakia with a mean\nclassification accuracy of 0.97. Preliminary results using an (AI+Physician)\nensemble model demonstrate that an automated initial screening process of\ntongue lesions using DCNNs can achieve near-human level classification\nperformance for diagnosing early signs of OCC in patients.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:35:18 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Shamim", "Mohammed Zubair M.", ""], ["Syed", "Sadatullah", ""], ["Shiblee", "Mohammad", ""], ["Usman", "Mohammed", ""], ["Ali", "Syed", ""]]}, {"id": "1909.08994", "submitter": "Mark Collier", "authors": "Mark Collier and Hector Urdiales", "title": "Scalable Deep Unsupervised Clustering with Concrete GMVAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete random variables are natural components of probabilistic clustering\nmodels. A number of VAE variants with discrete latent variables have been\ndeveloped. Training such methods requires marginalizing over the discrete\nlatent variables, causing training time complexity to be linear in the number\nclusters. By applying a continuous relaxation to the discrete variables in\nthese methods we can achieve a reduction in the training time complexity to be\nconstant in the number of clusters used. We demonstrate that in practice for\none such method, the Gaussian Mixture VAE, the use of a continuous relaxation\nhas no negative effect on the quality of the clustering but provides a\nsubstantial reduction in training time, reducing training time on CIFAR-100\nwith 20 clusters from 47 hours to less than 6 hours.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:29:36 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Collier", "Mark", ""], ["Urdiales", "Hector", ""]]}, {"id": "1909.08996", "submitter": "Andrea Loreggia", "authors": "Cristina Cornelio, Michele Donini, Andrea Loreggia, Maria Silvia Pini\n  and Francesca Rossi", "title": "Voting with Random Classifiers (VORACE): Theoretical and Experimental\n  Analysis", "comments": null, "journal-ref": "Autonomous Agents and Multi-Agent Systems volume 35, Article\n  number: 22 (2021)", "doi": "10.1007/s10458-021-09504-y", "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning scenarios, looking for the best classifier that fits\na particular dataset can be very costly in terms of time and resources.\nMoreover, it can require deep knowledge of the specific domain. We propose a\nnew technique which does not require profound expertise in the domain and\navoids the commonly used strategy of hyper-parameter tuning and model\nselection. Our method is an innovative ensemble technique that uses voting\nrules over a set of randomly-generated classifiers. Given a new input sample,\nwe interpret the output of each classifier as a ranking over the set of\npossible classes. We then aggregate these output rankings using a voting rule,\nwhich treats them as preferences over the classes. We show that our approach\nobtains good results compared to the state-of-the-art, both providing a\ntheoretical analysis and an empirical evaluation of the approach on several\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 08:13:53 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 09:37:08 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 08:00:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cornelio", "Cristina", ""], ["Donini", "Michele", ""], ["Loreggia", "Andrea", ""], ["Pini", "Maria Silvia", ""], ["Rossi", "Francesca", ""]]}, {"id": "1909.09020", "submitter": "Vincent Le Guen", "authors": "Vincent Le Guen (CNAM, EDF R&D), Nicolas Thome (CNAM)", "title": "Shape and Time Distortion Loss for Training Deep Time Series Forecasting\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of time series forecasting for\nnon-stationary signals and multiple future steps prediction. To handle this\nchallenging task, we introduce DILATE (DIstortion Loss including shApe and\nTimE), a new objective function for training deep neural networks. DILATE aims\nat accurately predicting sudden changes, and explicitly incorporates two terms\nsupporting precise shape and temporal change detection. We introduce a\ndifferentiable loss function suitable for training deep neural nets, and\nprovide a custom back-prop implementation for speeding up optimization. We also\nintroduce a variant of DILATE, which provides a smooth generalization of\ntemporally-constrained Dynamic Time Warping (DTW). Experiments carried out on\nvarious non-stationary datasets reveal the very good behaviour of DILATE\ncompared to models trained with the standard Mean Squared Error (MSE) loss\nfunction, and also to DTW and variants. DILATE is also agnostic to the choice\nof the model, and we highlight its benefit for training fully connected\nnetworks as well as specialized recurrent architectures, showing its capacity\nto improve over state-of-the-art trajectory forecasting approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 14:35:30 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:53:26 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 21:40:17 GMT"}, {"version": "v4", "created": "Sun, 10 Nov 2019 22:10:14 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Guen", "Vincent Le", "", "CNAM, EDF R&D"], ["Thome", "Nicolas", "", "CNAM"]]}, {"id": "1909.09036", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Lior Wolf", "title": "Hyper-Graph-Network Decoders for Block Codes", "comments": "Accepted to NeurIPS 2019. Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural decoders were shown to outperform classical message passing techniques\nfor short BCH codes. In this work, we extend these results to much larger\nfamilies of algebraic block codes, by performing message passing with graph\nneural networks. The parameters of the sub-network at each variable-node in the\nTanner graph are obtained from a hypernetwork that receives the absolute values\nof the current message as input. To add stability, we employ a simplified\nversion of the arctanh activation that is based on a high order Taylor\napproximation of this activation function. Our results show that for a large\nnumber of algebraic block codes, from diverse families of codes (BCH, LDPC,\nPolar), the decoding obtained with our method outperforms the vanilla belief\npropagation method as well as other learning techniques from the literature.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:47:35 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 12:30:20 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "1909.09132", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Yan Han, Mason Carnahan, Ahmed H Tewfik", "title": "Spoken Speech Enhancement using EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate spoken speech enhancement using\nelectroencephalography (EEG) signals using a generative adversarial network\n(GAN) based model, gated recurrent unit (GRU) regression based model, temporal\nconvolutional network (TCN) regression model and finally using a mixed TCN GRU\nregression model.\n  We compare our EEG based speech enhancement results with traditional log\nminimum mean-square error (MMSE) speech enhancement algorithm and our proposed\nmethods demonstrate significant improvement in speech enhancement quality\ncompared to the traditional method. Our overall results demonstrate that EEG\nfeatures can be used to clean speech recorded in presence of background noise.\nTo the best of our knowledge this is the first time a spoken speech enhancement\nis demonstrated using EEG features recorded in parallel with spoken speech.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 21:44:08 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 04:08:20 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:59:14 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 00:05:28 GMT"}, {"version": "v5", "created": "Wed, 13 Nov 2019 04:59:40 GMT"}, {"version": "v6", "created": "Fri, 14 Feb 2020 04:57:06 GMT"}, {"version": "v7", "created": "Wed, 19 Feb 2020 19:41:15 GMT"}, {"version": "v8", "created": "Sun, 19 Apr 2020 21:12:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Han", "Yan", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1909.09136", "submitter": "Herbert Gish", "authors": "Herbert Gish, Jan Silovsky, Man-Ling Sung, Man-Hung Siu, William\n  Hartmann and Zhuolin Jiang", "title": "Towards a New Understanding of the Training of Neural Networks with\n  Mislabeled Training Data", "comments": "13 pages with 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of machine learning with mislabeled training data.\nWe try to make the effects of mislabeled training better understood through\nanalysis of the basic model and equations that characterize the problem. This\nincludes results about the ability of the noisy model to make the same\ndecisions as the clean model and the effects of noise on model performance. In\naddition to providing better insights we also are able to show that the Maximum\nLikelihood (ML) estimate of the parameters of the noisy model determine those\nof the clean model. This property is obtained through the use of the ML\ninvariance property and leads to an approach to developing a classifier when\ntraining has been mislabeled: namely train the classifier on noisy data and\nadjust the decision threshold based on the noise levels and/or class priors. We\nshow how our approach to mislabeled training works with multi-layered\nperceptrons (MLPs).\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:30:14 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Gish", "Herbert", ""], ["Silovsky", "Jan", ""], ["Sung", "Man-Ling", ""], ["Siu", "Man-Hung", ""], ["Hartmann", "William", ""], ["Jiang", "Zhuolin", ""]]}, {"id": "1909.09138", "submitter": "Jennie Brand", "authors": "Jennie E. Brand, Jiahui Xu, Bernard Koch, and Pablo Geraldo", "title": "Uncovering Sociological Effect Heterogeneity using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals do not respond uniformly to treatments, events, or interventions.\nSociologists routinely partition samples into subgroups to explore how the\neffects of treatments vary by covariates like race, gender, and socioeconomic\nstatus. In so doing, analysts determine the key subpopulations based on\ntheoretical priors. Data-driven discoveries are also routine, yet the analyses\nby which sociologists typically go about them are problematic and seldom move\nus beyond our expectations, and biases, to explore new meaningful subgroups.\nEmerging machine learning methods allow researchers to explore sources of\nvariation that they may not have previously considered, or envisaged. In this\npaper, we use causal trees to recursively partition the sample and uncover\nsources of treatment effect heterogeneity. We use honest estimation, splitting\nthe sample into a training sample to grow the tree and an estimation sample to\nestimate leaf-specific effects. Assessing a central topic in the social\ninequality literature, college effects on wages, we compare what we learn from\nconventional approaches for exploring variation in effects to causal trees.\nGiven our use of observational data, we use leaf-specific matching and\nsensitivity analyses to address confounding and offer interpretations of\neffects based on observed and unobserved heterogeneity. We encourage\nresearchers to follow similar practices in their work on variation in\nsociological effects.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:09:17 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Brand", "Jennie E.", ""], ["Xu", "Jiahui", ""], ["Koch", "Bernard", ""], ["Geraldo", "Pablo", ""]]}, {"id": "1909.09139", "submitter": "Eyy\\\"ub Sari", "authors": "Eyy\\\"ub Sari, Mouloud Belbahri, Vahid Partovi Nia", "title": "How Does Batch Normalization Help Binary Training?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) are difficult to train, and suffer from drop of\naccuracy. It appears in practice that BNNs fail to train in the absence of\nBatch Normalization (BatchNorm) layer. We find the main role of BatchNorm is to\navoid exploding gradients in the case of BNNs. This finding suggests that the\ncommon initialization methods developed for full-precision networks are\nirrelevant to BNNs. We build a theoretical study on the role of BatchNorm in\nbinary training, backed up by numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:15:35 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 13:41:48 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 14:03:27 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Sari", "Eyy\u00fcb", ""], ["Belbahri", "Mouloud", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "1909.09140", "submitter": "Siyuan Shan", "authors": "Siyuan Shan and Yang Li and Junier Oliva", "title": "Meta-Neighborhoods", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making an adaptive prediction based on one's input is an important ability\nfor general artificial intelligence. In this work, we step forward in this\ndirection and propose a semi-parametric method, Meta-Neighborhoods, where\npredictions are made adaptively to the neighborhood of the input. We show that\nMeta-Neighborhoods is a generalization of $k$-nearest-neighbors. Due to the\nsimpler manifold structure around a local neighborhood, Meta-Neighborhoods\nrepresent the predictive distribution $p(y \\mid x)$ more accurately. To reduce\nmemory and computation overhead, we propose induced neighborhoods that\nsummarize the training data into a much smaller dictionary. A meta-learning\nbased training mechanism is then exploited to jointly learn the induced\nneighborhoods and the model. Extensive studies demonstrate the superiority of\nour method.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:37:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 18:47:41 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 21:01:45 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Shan", "Siyuan", ""], ["Li", "Yang", ""], ["Oliva", "Junier", ""]]}, {"id": "1909.09141", "submitter": "Elliot Creager", "authors": "Elliot Creager, David Madras, Toniann Pitassi, Richard Zemel", "title": "Causal Modeling for Fairness in Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application areas---lending, education, and online recommenders, for\nexample---fairness and equity concerns emerge when a machine learning system\ninteracts with a dynamically changing environment to produce both immediate and\nlong-term effects for individuals and demographic groups. We discuss causal\ndirected acyclic graphs (DAGs) as a unifying framework for the recent\nliterature on fairness in such dynamical systems. We show that this formulation\naffords several new directions of inquiry to the modeler, where causal\nassumptions can be expressed and manipulated. We emphasize the importance of\ncomputing interventional quantities in the dynamical fairness setting, and show\nhow causal assumptions enable simulation (when environment dynamics are known)\nand off-policy estimation (when dynamics are unknown) of intervention on short-\nand long-term outcomes, at both the group and individual levels.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:21:56 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 17:43:02 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Creager", "Elliot", ""], ["Madras", "David", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "1909.09142", "submitter": "Sai Krishnan Chandrasekar", "authors": "Hao Ren, Sai Krishnan Chandrasekar, Anitha Murugesan", "title": "Using Quantifier Elimination to Enhance the Safety Assurance of Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the field of Machine Learning and Deep Neural Networks (DNNs) has\nenabled rapid development of sophisticated and autonomous systems. However, the\ninherent complexity to rigorously assure the safe operation of such systems\nhinders their real-world adoption in safety-critical domains such as aerospace\nand medical devices. Hence, there is a surge in interest to explore the use of\nadvanced mathematical techniques such as formal methods to address this\nchallenge. In fact, the initial results of such efforts are promising. Along\nthese lines, we propose the use of quantifier elimination (QE) - a formal\nmethod technique, as a complimentary technique to the state-of-the-art static\nanalysis and verification procedures. Using an airborne collision avoidance DNN\nas a case example, we illustrate the use of QE to formulate the precise range\nforward propagation through a network as well as analyze its robustness. We\ndiscuss the initial results of this ongoing work and explore the future\npossibilities of extending this approach and/or integrating it with other\napproaches to perform advanced safety assurance of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:54:10 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Ren", "Hao", ""], ["Chandrasekar", "Sai Krishnan", ""], ["Murugesan", "Anitha", ""]]}, {"id": "1909.09143", "submitter": "Deepak Muralidharan", "authors": "Deepak Muralidharan, Justine Kao, Xiao Yang, Lin Li, Lavanya\n  Viswanathan, Mubarak Seyed Ibrahim, Kevin Luikens, Stephen Pulman, Ashish\n  Garg, Atish Kothari and Jason Williams", "title": "Leveraging User Engagement Signals For Entity Labeling in a Virtual\n  Assistant", "comments": "NeurIPS 2018 Conversational AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal assistant AI systems such as Siri, Cortana, and Alexa have become\nwidely used as a means to accomplish tasks through natural language commands.\nHowever, components in these systems generally rely on supervised machine\nlearning algorithms that require large amounts of hand-annotated training data,\nwhich is expensive and time consuming to collect. The ability to incorporate\nunsupervised, weakly supervised, or distantly supervised data holds significant\npromise in overcoming this bottleneck. In this paper, we describe a framework\nthat leverages user engagement signals (user behaviors that demonstrate a\npositive or negative response to content) to automatically create granular\nentity labels for training data augmentation. Strategies such as multi-task\nlearning and validation using an external knowledge base are employed to\nincorporate the engagement annotated data and to boost the model's accuracy on\na sequence labeling task. Our results show that learning from data\nautomatically labeled by user engagement signals achieves significant accuracy\ngains in a production deep learning system, when measured on both the sequence\nlabeling task as well as on user facing results produced by the system\nend-to-end. We believe this is the first use of user engagement signals to help\ngenerate training data for a sequence labeling task on a large scale, and can\nbe applied in practical settings to speed up new feature deployment when little\nhuman annotated data is available.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:02:35 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Muralidharan", "Deepak", ""], ["Kao", "Justine", ""], ["Yang", "Xiao", ""], ["Li", "Lin", ""], ["Viswanathan", "Lavanya", ""], ["Ibrahim", "Mubarak Seyed", ""], ["Luikens", "Kevin", ""], ["Pulman", "Stephen", ""], ["Garg", "Ashish", ""], ["Kothari", "Atish", ""], ["Williams", "Jason", ""]]}, {"id": "1909.09144", "submitter": "Romit Maulik", "authors": "Romit Maulik, Vishwas Rao, Sandeep Madireddy, Bethany Lusch, Prasanna\n  Balaprakash", "title": "Using recurrent neural networks for nonlinear component computation in\n  advection-dominated reduced-order models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid simulations of advection-dominated problems are vital for multiple\nengineering and geophysical applications. In this paper, we present a long\nshort-term memory neural network to approximate the nonlinear component of the\nreduced-order model (ROM) of an advection-dominated partial differential\nequation. This is motivated by the fact that the nonlinear term is the most\nexpensive component of a successful ROM. For our approach, we utilize a\nGalerkin projection to isolate the linear and the transient components of the\ndynamical system and then use discrete empirical interpolation to generate\ntraining data for supervised learning. We note that the numerical\ntime-advancement and linear-term computation of the system ensure a greater\npreservation of physics than does a process that is fully modeled. Our results\nshow that the proposed framework recovers transient dynamics accurately without\nnonlinear term computations in full-order space and represents a cost-effective\nalternative to solely equation-based ROMs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:37:37 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 05:02:39 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Maulik", "Romit", ""], ["Rao", "Vishwas", ""], ["Madireddy", "Sandeep", ""], ["Lusch", "Bethany", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1909.09145", "submitter": "Praneeth Vepakomma", "authors": "Abhishek Singh, Praneeth Vepakomma, Otkrist Gupta, Ramesh Raskar", "title": "Detailed comparison of communication efficiency of split learning and\n  federated learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare communication efficiencies of two compelling distributed machine\nlearning approaches of split learning and federated learning. We show useful\nsettings under which each method outperforms the other in terms of\ncommunication efficiency. We consider various practical scenarios of\ndistributed learning setup and juxtapose the two methods under various\nreal-life scenarios. We consider settings of small and large number of clients\nas well as small models (1M - 6M parameters), large models (10M - 200M\nparameters) and very large models (1 Billion-100 Billion parameters). We show\nthat increasing number of clients or increasing model size favors split\nlearning setup over the federated while increasing the number of data samples\nwhile keeping the number of clients or model size low makes federated learning\nmore communication efficient.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:43:33 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Singh", "Abhishek", ""], ["Vepakomma", "Praneeth", ""], ["Gupta", "Otkrist", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1909.09146", "submitter": "Olivier Cappe", "authors": "Yoan Russac (DI-ENS, VALDA), Claire Vernade, Olivier Capp\\'e (DI-ENS,\n  VALDA)", "title": "Weighted Linear Bandits for Non-Stationary Environments", "comments": null, "journal-ref": "NeurIPS 2019 - 33rd Conference on Neural Information Processing\n  Systems, Dec 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic linear bandit model in which the available actions\ncorrespond to arbitrary context vectors whose associated rewards follow a\nnon-stationary linear regression model. In this setting, the unknown regression\nparameter is allowed to vary in time. To address this problem, we propose\nD-LinUCB, a novel optimistic algorithm based on discounted linear regression,\nwhere exponential weights are used to smoothly forget the past. This involves\nstudying the deviations of the sequential weighted least-squares estimator\nunder generic assumptions. As a by-product, we obtain novel deviation results\nthat can be used beyond non-stationary environments. We provide theoretical\nguarantees on the behavior of D-LinUCB in both slowly-varying and\nabruptly-changing environments. We obtain an upper bound on the dynamic regret\nthat is of order d^{2/3} B\\_T^{1/3}T^{2/3}, where B\\_T is a measure of\nnon-stationarity (d and T being, respectively, dimension and horizon). This\nrate is known to be optimal. We also illustrate the empirical performance of\nD-LinUCB and compare it with recently proposed alternatives in simulated\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 06:57:33 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 13:49:18 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Russac", "Yoan", "", "DI-ENS, VALDA"], ["Vernade", "Claire", "", "DI-ENS,\n  VALDA"], ["Capp\u00e9", "Olivier", "", "DI-ENS,\n  VALDA"]]}, {"id": "1909.09147", "submitter": "Michael Smith", "authors": "Michael Thomas Smith, Mauricio A. Alvarez, Neil D. Lawrence", "title": "Differentially Private Regression and Classification with Sparse\n  Gaussian Processes", "comments": "26 pages, 6 figures. Submitted to JMLR 4th January, 2019 (in review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continuing challenge for machine learning is providing methods to perform\ncomputation on data while ensuring the data remains private. In this paper we\nbuild on the provable privacy guarantees of differential privacy which has been\ncombined with Gaussian processes through the previously published\n\\emph{cloaking method}. In this paper we solve several shortcomings of this\nmethod, starting with the problem of predictions in regions with low data\ndensity. We experiment with the use of inducing points to provide a sparse\napproximation and show that these can provide robust differential privacy in\noutlier areas and at higher dimensions. We then look at classification, and\nmodify the Laplace approximation approach to provide differentially private\npredictions. We then combine this with the sparse approximation and demonstrate\nthe capability to perform classification in high dimensions. We finally explore\nthe issue of hyperparameter selection and develop a method for their private\nselection. This paper and associated libraries provide a robust toolkit for\ncombining differential privacy and GPs in a practical manner.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 07:20:38 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Smith", "Michael Thomas", ""], ["Alvarez", "Mauricio A.", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1909.09148", "submitter": "Zhuoxun He", "authors": "Zhuoxun He, Lingxi Xie, Xin Chen, Ya Zhang, Yanfeng Wang and Qi Tian", "title": "Data Augmentation Revisited: Rethinking the Distribution Gap between\n  Clean and Augmented Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation has been widely applied as an effective methodology to\nimprove generalization in particular when training deep neural networks.\nRecently, researchers proposed a few intensive data augmentation techniques,\nwhich indeed improved accuracy, yet we notice that these methods augment data\nhave also caused a considerable gap between clean and augmented data. In this\npaper, we revisit this problem from an analytical perspective, for which we\nestimate the upper-bound of expected risk using two terms, namely, empirical\nrisk and generalization error, respectively. We develop an understanding of\ndata augmentation as regularization, which highlights the major features. As a\nresult, data augmentation significantly reduces the generalization error, but\nmeanwhile leads to a slightly higher empirical risk. On the assumption that\ndata augmentation helps models converge to a better region, the model can\nbenefit from a lower empirical risk achieved by a simple method, i.e., using\nless-augmented data to refine the model trained on fully-augmented data. Our\napproach achieves consistent accuracy gain on a few standard image\nclassification benchmarks, and the gain transfers to object detection.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:36:45 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 15:56:49 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["He", "Zhuoxun", ""], ["Xie", "Lingxi", ""], ["Chen", "Xin", ""], ["Zhang", "Ya", ""], ["Wang", "Yanfeng", ""], ["Tian", "Qi", ""]]}, {"id": "1909.09149", "submitter": "Sebastian Bayerl", "authors": "Marc Wenninger, Sebastian P. Bayerl, Jochen Schmidt, Korbinian\n  Riedhammer", "title": "Timage -- A Robust Time Series Classification Pipeline", "comments": "ICANN19, 28th International Conference on Artificial Neural Networks", "journal-ref": null, "doi": "10.1007/978-3-030-30490-4_36", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are series of values ordered by time. This kind of data can be\nfound in many real world settings. Classifying time series is a difficult task\nand an active area of research. This paper investigates the use of transfer\nlearning in Deep Neural Networks and a 2D representation of time series known\nas Recurrence Plots. In order to utilize the research done in the area of image\nclassification, where Deep Neural Networks have achieved very good results, we\nuse a Residual Neural Networks architecture known as ResNet. As preprocessing\nof time series is a major part of every time series classification pipeline,\nthe method proposed simplifies this step and requires only few parameters. For\nthe first time we propose a method for multi time series classification:\nTraining a single network to classify all datasets in the archive with one\nnetwork. We are among the first to evaluate the method on the latest 2018\nrelease of the UCR archive, a well established time series classification\nbenchmarking dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:37:54 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Wenninger", "Marc", ""], ["Bayerl", "Sebastian P.", ""], ["Schmidt", "Jochen", ""], ["Riedhammer", "Korbinian", ""]]}, {"id": "1909.09150", "submitter": "Anne Marie Delaney Ms", "authors": "Anne Marie Delaney, Eoin Brophy, Tomas E. Ward", "title": "Synthesis of Realistic ECG using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to medical data is highly restricted due to its sensitive nature,\npreventing communities from using this data for research or clinical training.\nCommon methods of de-identification implemented to enable the sharing of data\nare sometimes inadequate to protect the individuals contained in the data. For\nour research, we investigate the ability of generative adversarial networks\n(GANs) to produce realistic medical time series data which can be used without\nconcerns over privacy. The aim is to generate synthetic ECG signals\nrepresentative of normal ECG waveforms. GANs have been used successfully to\ngenerate good quality synthetic time series and have been shown to prevent\nre-identification of individual records. In this work, a range of GAN\narchitectures are developed to generate synthetic sine waves and synthetic ECG.\nTwo evaluation metrics are then used to quantitatively assess how suitable the\nsynthetic data is for real world applications such as clinical training and\ndata analysis. Finally, we discuss the privacy concerns associated with sharing\nsynthetic data produced by GANs and test their ability to withstand a simple\nmembership inference attack. For the first time we both quantitatively and\nqualitatively demonstrate that GAN architecture can successfully generate time\nseries signals that are not only structurally similar to the training sets but\nalso diverse in nature across generated samples. We also report on their\nability to withstand a simple membership inference attack, protecting the\nprivacy of the training set.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:28:36 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Delaney", "Anne Marie", ""], ["Brophy", "Eoin", ""], ["Ward", "Tomas E.", ""]]}, {"id": "1909.09153", "submitter": "Denis Kleyko", "authors": "Denis Kleyko, Mansour Kheffache, E. Paxon Frady, Urban Wiklund, and\n  Evgeny Osipov", "title": "Density Encoding Enables Resource-Efficient Randomly Connected Neural\n  Networks", "comments": "7 pages, 7 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (2020)", "doi": "10.1109/TNNLS.2020.3015971", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of machine learning algorithms on resource-constrained edge\ndevices is an important challenge from both theoretical and applied points of\nview. In this article, we focus on resource-efficient randomly connected neural\nnetworks known as Random Vector Functional Link (RVFL) networks since their\nsimple design and extremely fast training time make them very attractive for\nsolving many applied classification tasks. We propose to represent input\nfeatures via the density-based encoding known in the area of stochastic\ncomputing and use the operations of binding and bundling from the area of\nhyperdimensional computing for obtaining the activations of the hidden neurons.\nUsing a collection of 121 real-world datasets from the UCI Machine Learning\nRepository, we empirically show that the proposed approach demonstrates higher\naverage accuracy than the conventional RVFL. We also demonstrate that it is\npossible to represent the readout matrix using only integers in a limited range\nwith minimal loss in the accuracy. In this case, the proposed approach operates\nonly on small n-bits integers, which results in a computationally efficient\narchitecture. Finally, through hardware FPGA implementations, we show that such\nan approach consumes approximately eleven times less energy than that of the\nconventional RVFL.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 10:57:34 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Kleyko", "Denis", ""], ["Kheffache", "Mansour", ""], ["Frady", "E. Paxon", ""], ["Wiklund", "Urban", ""], ["Osipov", "Evgeny", ""]]}, {"id": "1909.09154", "submitter": "Alexander Schulz", "authors": "Alexander Schulz, Fabian Hinder, Barbara Hammer", "title": "DeepView: Visualizing Classification Boundaries of Deep Neural Networks\n  as Scatter Plots Using Discriminative Dimensionality Reduction", "comments": "This is published at IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/319", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms using deep architectures have been able to\nimplement increasingly powerful and successful models. However, they also\nbecome increasingly more complex, more difficult to comprehend and easier to\nfool. So far, most methods in the literature investigate the decision of the\nmodel for a single given input datum. In this paper, we propose to visualize a\npart of the decision function of a deep neural network together with a part of\nthe data set in two dimensions with discriminative dimensionality reduction.\nThis enables us to inspect how different properties of the data are treated by\nthe model, such as outliers, adversaries or poisoned data. Further, the\npresented approach is complementary to the mentioned interpretation methods\nfrom the literature and hence might be even more useful in combination with\nthose. Code is available at https://github.com/LucaHermes/DeepView .\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:22:56 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 15:41:21 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Schulz", "Alexander", ""], ["Hinder", "Fabian", ""], ["Hammer", "Barbara", ""]]}, {"id": "1909.09157", "submitter": "Aniruddh Raghu", "authors": "Aniruddh Raghu, Maithra Raghu, Samy Bengio, Oriol Vinyals", "title": "Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness\n  of MAML", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important research direction in machine learning has centered around\ndeveloping meta-learning algorithms to tackle few-shot learning. An especially\nsuccessful algorithm has been Model Agnostic Meta-Learning (MAML), a method\nthat consists of two optimization loops, with the outer loop finding a\nmeta-initialization, from which the inner loop can efficiently learn new tasks.\nDespite MAML's popularity, a fundamental open question remains -- is the\neffectiveness of MAML due to the meta-initialization being primed for rapid\nlearning (large, efficient changes in the representations) or due to feature\nreuse, with the meta initialization already containing high quality features?\nWe investigate this question, via ablation studies and analysis of the latent\nrepresentations, finding that feature reuse is the dominant factor. This leads\nto the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we\nremove the inner loop for all but the (task-specific) head of a MAML-trained\nnetwork. ANIL matches MAML's performance on benchmark few-shot image\nclassification and RL and offers computational improvements over MAML. We\nfurther study the precise contributions of the head and body of the network,\nshowing that performance on the test tasks is entirely determined by the\nquality of the learned features, and we can remove even the head of the network\n(the NIL algorithm). We conclude with a discussion of the rapid learning vs\nfeature reuse question for meta-learning algorithms more broadly.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 16:30:42 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 15:29:39 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Raghu", "Aniruddh", ""], ["Raghu", "Maithra", ""], ["Bengio", "Samy", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1909.09177", "submitter": "Qi Lyu", "authors": "Qi Lyu and Xiao Fu", "title": "Nonlinear Multiview Analysis: Identifiability and Neural\n  Network-assisted Implementation", "comments": "accepted version; IEEE transactions on signal processing", "journal-ref": null, "doi": "10.1109/TSP.2020.2986351", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiview analysis aims at extracting shared latent components from data\nsamples that are acquired in different domains, e.g., image, text, and audio.\nClassic multiview analysis, e.g., canonical correlation analysis (CCA), tackles\nthis problem via matching the linearly transformed views in a certain latent\ndomain. More recently, powerful nonlinear learning tools such as kernel methods\nand neural networks are utilized for enhancing the classic CCA. However, unlike\nlinear CCA whose theoretical aspects are clearly understood, nonlinear CCA\napproaches are largely intuition-driven. In particular, it is unclear under\nwhat conditions the shared latent components across the views can be\nidentified---while identifiability plays an essential role in many\napplications. In this work, we revisit nonlinear multiview analysis and address\nboth the theoretical and computational aspects. Our work leverages a useful\nnonlinear model, namely, the post-nonlinear model, from the nonlinear mixture\nseparation literature. Combining with multiview data, we take a nonlinear\nmultiview mixture learning viewpoint, which is a natural extension of the\nclassic generative models for linear CCA. From there, we derive a learning\ncriterion. We show that minimizing this criterion leads to identification of\nthe latent shared components up to certain ambiguities, under reasonable\nconditions. Our derivation and formulation also offer new insights and\ninterpretations to existing deep neural network-based CCA formulations. On the\ncomputation side, we propose an effective algorithm with simple and scalable\nupdate rules. A series of simulations and real-data experiments corroborate our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 18:08:41 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 06:25:14 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lyu", "Qi", ""], ["Fu", "Xiao", ""]]}, {"id": "1909.09192", "submitter": "Vardaan Pahuja", "authors": "Vardaan Pahuja, Jie Fu, Christopher J. Pal", "title": "Learning Sparse Mixture of Experts for Visual Question Answering", "comments": "Accepted in Visual Question Answering and Dialog Workshop, CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a rapid progress in the task of Visual Question Answering with\nimproved model architectures. Unfortunately, these models are usually\ncomputationally intensive due to their sheer size which poses a serious\nchallenge for deployment. We aim to tackle this issue for the specific task of\nVisual Question Answering (VQA). A Convolutional Neural Network (CNN) is an\nintegral part of the visual processing pipeline of a VQA model (assuming the\nCNN is trained along with entire VQA model). In this project, we propose an\nefficient and modular neural architecture for the VQA task with focus on the\nCNN module. Our experiments demonstrate that a sparsely activated CNN based VQA\nmodel achieves comparable performance to a standard CNN based VQA model\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 18:55:54 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Pahuja", "Vardaan", ""], ["Fu", "Jie", ""], ["Pal", "Christopher J.", ""]]}, {"id": "1909.09218", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Interpretable Discriminative Dimensionality Reduction and Feature\n  Selection on the Manifold", "comments": "16 pages, ECML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction (DR) on the manifold includes effective methods\nwhich project the data from an implicit relational space onto a vectorial\nspace. Regardless of the achievements in this area, these algorithms suffer\nfrom the lack of interpretation of the projection dimensions. Therefore, it is\noften difficult to explain the physical meaning behind the embedding\ndimensions. In this research, we propose the interpretable kernel DR algorithm\n(I-KDR) as a new algorithm which maps the data from the feature space to a\nlower dimensional space where the classes are more condensed with less\noverlapping. Besides, the algorithm creates the dimensions upon local\ncontributions of the data samples, which makes it easier to interpret them by\nclass labels. Additionally, we efficiently fuse the DR with feature selection\ntask to select the most relevant features of the original space to the\ndiscriminative objective. Based on the empirical evidence, I-KDR provides\nbetter interpretations for embedding dimensions as well as higher\ndiscriminative performance in the embedded space compared to the\nstate-of-the-art and popular DR algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 20:02:28 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1909.09223", "submitter": "Harsha Nori", "authors": "Harsha Nori and Samuel Jenkins and Paul Koch and Rich Caruana", "title": "InterpretML: A Unified Framework for Machine Learning Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  InterpretML is an open-source Python package which exposes machine learning\ninterpretability algorithms to practitioners and researchers. InterpretML\nexposes two types of interpretability - glassbox models, which are machine\nlearning models designed for interpretability (ex: linear models, rule lists,\ngeneralized additive models), and blackbox explainability techniques for\nexplaining existing systems (ex: Partial Dependence, LIME). The package enables\npractitioners to easily compare interpretability algorithms by exposing\nmultiple methods under a unified API, and by having a built-in, extensible\nvisualization platform. InterpretML also includes the first implementation of\nthe Explainable Boosting Machine, a powerful, interpretable, glassbox model\nthat can be as accurate as many blackbox models. The MIT licensed source code\ncan be downloaded from github.com/microsoft/interpret.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 20:22:32 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Nori", "Harsha", ""], ["Jenkins", "Samuel", ""], ["Koch", "Paul", ""], ["Caruana", "Rich", ""]]}, {"id": "1909.09246", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng", "title": "Machine Learning for Clinical Predictive Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we provide a brief overview of applying machine learning\ntechniques for clinical prediction tasks. We begin with a quick introduction to\nthe concepts of machine learning and outline some of the most common machine\nlearning algorithms. Next, we demonstrate how to apply the algorithms with\nappropriate toolkits to conduct machine learning experiments for clinical\nprediction tasks. The objectives of this chapter are to (1) understand the\nbasics of machine learning techniques and the reasons behind why they are\nuseful for solving clinical prediction problems, (2) understand the intuition\nbehind some machine learning models, including regression, decision trees, and\nsupport vector machines, and (3) understand how to apply these models to\nclinical prediction problems using publicly available datasets via case\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:02:00 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Weng", "Wei-Hung", ""]]}, {"id": "1909.09248", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng, Peter Szolovits", "title": "Representation Learning for Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information in electronic health records (EHR), such as clinical narratives,\nexamination reports, lab measurements, demographics, and other patient\nencounter entries, can be transformed into appropriate data representations\nthat can be used for downstream clinical machine learning tasks using\nrepresentation learning. Learning better representations is critical to improve\nthe performance of downstream tasks. Due to the advances in machine learning,\nwe now can learn better and meaningful representations from EHR through\ndisentangling the underlying factors inside data and distilling large amounts\nof information and knowledge from heterogeneous EHR sources. In this chapter,\nwe first introduce the background of learning representations and reasons why\nwe need good EHR representations in machine learning for medicine and\nhealthcare in Section 1. Next, we explain the commonly-used machine learning\nand evaluation methods for representation learning using a deep learning\napproach in Section 2. Following that, we review recent related studies of\nlearning patient state representation from EHR for clinical machine learning\ntasks in Section 3. Finally, in Section 4 we discuss more techniques, studies,\nand challenges for learning natural language representations when free texts,\nsuch as clinical notes, examination reports, or biomedical literature are used.\nWe also discuss challenges and opportunities in these rapidly growing research\nfields.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:12:30 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Weng", "Wei-Hung", ""], ["Szolovits", "Peter", ""]]}, {"id": "1909.09252", "submitter": "Devanshu Arya", "authors": "Devanshu Arya, Stevan Rudinac and Marcel Worring", "title": "HyperLearn: A Distributed Approach for Representation Learning in\n  Datasets With Many Modalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal datasets contain an enormous amount of relational information,\nwhich grows exponentially with the introduction of new modalities. Learning\nrepresentations in such a scenario is inherently complex due to the presence of\nmultiple heterogeneous information channels. These channels can encode both (a)\ninter-relations between the items of different modalities and (b)\nintra-relations between the items of the same modality. Encoding multimedia\nitems into a continuous low-dimensional semantic space such that both types of\nrelations are captured and preserved is extremely challenging, especially if\nthe goal is a unified end-to-end learning framework. The two key challenges\nthat need to be addressed are: 1) the framework must be able to merge complex\nintra and inter relations without losing any valuable information and 2) the\nlearning model should be invariant to the addition of new and potentially very\ndifferent modalities. In this paper, we propose a flexible framework which can\nscale to data streams from many modalities. To that end we introduce a\nhypergraph-based model for data representation and deploy Graph Convolutional\nNetworks to fuse relational information within and across modalities. Our\napproach provides an efficient solution for distributing otherwise extremely\ncomputationally expensive or even unfeasible training processes across\nmultiple-GPUs, without any sacrifices in accuracy. Moreover, adding new\nmodalities to our model requires only an additional GPU unit keeping the\ncomputational time unchanged, which brings representation learning to truly\nmultimodal datasets. We demonstrate the feasibility of our approach in the\nexperiments on multimedia datasets featuring second, third and fourth order\nrelations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:45:21 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Arya", "Devanshu", ""], ["Rudinac", "Stevan", ""], ["Worring", "Marcel", ""]]}, {"id": "1909.09264", "submitter": "Meyer Scetbon", "authors": "M. Scetbon, G. Varoquaux", "title": "Comparing distributions: $\\ell_1$ geometry improves kernel two-sample\n  testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are two sets of observations drawn from the same distribution? This problem\nis a two-sample test. Kernel methods lead to many appealing properties. Indeed\nstate-of-the-art approaches use the $L^2$ distance between kernel-based\ndistribution representatives to derive their test statistics. Here, we show\nthat $L^p$ distances (with $p\\geq 1$) between these distribution\nrepresentatives give metrics on the space of distributions that are\nwell-behaved to detect differences between distributions as they metrize the\nweak convergence. Moreover, for analytic kernels, we show that the $L^1$\ngeometry gives improved testing power for scalable computational procedures.\nSpecifically, we derive a finite dimensional approximation of the metric given\nas the $\\ell_1$ norm of a vector which captures differences of expectations of\nanalytic functions evaluated at spatial locations or frequencies (i.e,\nfeatures). The features can be chosen to maximize the differences of the\ndistributions and give interpretable indications of how they differs. Using an\n$\\ell_1$ norm gives better detection because differences between\nrepresentatives are dense as we use analytic kernels (non-zero almost\neverywhere). The tests are consistent, while much faster than state-of-the-art\nquadratic-time kernel-based tests. Experiments on artificial and real-world\nproblems demonstrate improved power/time tradeoff than the state of the art,\nbased on $\\ell_2$ norms, and in some cases, better outright power than even the\nmost expensive quadratic-time tests.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 23:59:44 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 01:17:31 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Scetbon", "M.", ""], ["Varoquaux", "G.", ""]]}, {"id": "1909.09285", "submitter": "Asma Ghandeharioun", "authors": "Asma Ghandeharioun, Brian Eoff, Brendan Jou, Rosalind W. Picard", "title": "Characterizing Sources of Uncertainty to Proxy Calibration and\n  Disambiguate Annotator and Data Bias", "comments": "Accepted for presentation at 2019 ICCV Workshop on Interpreting and\n  Explaining Visual Artificial Intelligence Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supporting model interpretability for complex phenomena where annotators can\nlegitimately disagree, such as emotion recognition, is a challenging machine\nlearning task. In this work, we show that explicitly quantifying the\nuncertainty in such settings has interpretability benefits. We use a simple\nmodification of a classical network inference using Monte Carlo dropout to give\nmeasures of epistemic and aleatoric uncertainty. We identify a significant\ncorrelation between aleatoric uncertainty and human annotator disagreement\n($r\\approx.3$). Additionally, we demonstrate how difficult and subjective\ntraining samples can be identified using aleatoric uncertainty and how\nepistemic uncertainty can reveal data bias that could result in unfair\npredictions. We identify the total uncertainty as a suitable surrogate for\nmodel calibration, i.e. the degree we can trust model's predicted confidence.\nIn addition to explainability benefits, we observe modest performance boosts\nfrom incorporating model uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 01:22:53 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 18:33:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ghandeharioun", "Asma", ""], ["Eoff", "Brian", ""], ["Jou", "Brendan", ""], ["Picard", "Rosalind W.", ""]]}, {"id": "1909.09292", "submitter": "Haiqin Yang", "authors": "Haiqin Yang", "title": "BERT Meets Chinese Word Segmentation", "comments": "13 pages; 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese word segmentation (CWS) is a fundamental task for Chinese language\nunderstanding. Recently, neural network-based models have attained superior\nperformance in solving the in-domain CWS task. Last year, Bidirectional Encoder\nRepresentation from Transformers (BERT), a new language representation model,\nhas been proposed as a backbone model for many natural language tasks and\nredefined the corresponding performance. The excellent performance of BERT\nmotivates us to apply it to solve the CWS task. By conducting intensive\nexperiments in the benchmark datasets from the second International Chinese\nWord Segmentation Bake-off, we obtain several keen observations. BERT can\nslightly improve the performance even when the datasets contain the issue of\nlabeling inconsistency. When applying sufficiently learned features, Softmax, a\nsimpler classifier, can attain the same performance as that of a more\ncomplicated classifier, e.g., Conditional Random Field (CRF). The performance\nof BERT usually increases as the model size increases. The features extracted\nby BERT can be also applied as good candidates for other neural network models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 01:53:19 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Yang", "Haiqin", ""]]}, {"id": "1909.09314", "submitter": "Lantao Yu", "authors": "Lantao Yu, Tianhe Yu, Chelsea Finn, Stefano Ermon", "title": "Meta-Inverse Reinforcement Learning with Probabilistic Context Variables", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing a suitable reward function to reinforcement learning can be\ndifficult in many real world applications. While inverse reinforcement learning\n(IRL) holds promise for automatically learning reward functions from\ndemonstrations, several major challenges remain. First, existing IRL methods\nlearn reward functions from scratch, requiring large numbers of demonstrations\nto correctly infer the reward for each task the agent may need to perform.\nSecond, existing methods typically assume homogeneous demonstrations for a\nsingle behavior or task, while in practice, it might be easier to collect\ndatasets of heterogeneous but related behaviors. To this end, we propose a deep\nlatent variable model that is capable of learning rewards from demonstrations\nof distinct but related tasks in an unsupervised way. Critically, our model can\ninfer rewards for new, structurally-similar tasks from a single demonstration.\nOur experiments on multiple continuous control tasks demonstrate the\neffectiveness of our approach compared to state-of-the-art imitation and\ninverse reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 04:22:13 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 21:15:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Yu", "Lantao", ""], ["Yu", "Tianhe", ""], ["Finn", "Chelsea", ""], ["Ermon", "Stefano", ""]]}, {"id": "1909.09338", "submitter": "Yucen Luo", "authors": "Yucen Luo, Jun Zhu, Tomas Pfister", "title": "A Simple yet Effective Baseline for Robust Deep Learning with Noisy\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep neural networks have shown their capacity to memorize training\ndata, even with noisy labels, which hurts generalization performance. To\nmitigate this issue, we provide a simple but effective baseline method that is\nrobust to noisy labels, even with severe noise. Our objective involves a\nvariance regularization term that implicitly penalizes the Jacobian norm of the\nneural network on the whole training set (including the noisy-labeled data),\nwhich encourages generalization and prevents overfitting to the corrupted\nlabels. Experiments on both synthetically generated incorrect labels and\nrealistic large-scale noisy datasets demonstrate that our approach achieves\nstate-of-the-art performance with a high tolerance to severe noise.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 06:15:13 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 04:29:39 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Luo", "Yucen", ""], ["Zhu", "Jun", ""], ["Pfister", "Tomas", ""]]}, {"id": "1909.09345", "submitter": "Shuaiwen Wang", "authors": "Shuaiwen Wang, Haolei Weng, Arian Maleki", "title": "Does SLOPE outperform bridge regression?", "comments": "51 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently proposed SLOPE estimator (arXiv:1407.3824) has been shown to\nadaptively achieve the minimax $\\ell_2$ estimation rate under high-dimensional\nsparse linear regression models (arXiv:1503.08393). Such minimax optimality\nholds in the regime where the sparsity level $k$, sample size $n$, and\ndimension $p$ satisfy $k/p \\rightarrow 0$, $k\\log p/n \\rightarrow 0$. In this\npaper, we characterize the estimation error of SLOPE under the complementary\nregime where both $k$ and $n$ scale linearly with $p$, and provide new insights\ninto the performance of SLOPE estimators. We first derive a concentration\ninequality for the finite sample mean square error (MSE) of SLOPE. The quantity\nthat MSE concentrates around takes a complicated and implicit form. With\ndelicate analysis of the quantity, we prove that among all SLOPE estimators,\nLASSO is optimal for estimating $k$-sparse parameter vectors that do not have\ntied non-zero components in the low noise scenario. On the other hand, in the\nlarge noise scenario, the family of SLOPE estimators are sub-optimal compared\nwith bridge regression such as the Ridge estimator.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 07:01:51 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 06:50:30 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Wang", "Shuaiwen", ""], ["Weng", "Haolei", ""], ["Maleki", "Arian", ""]]}, {"id": "1909.09347", "submitter": "Yohei Kawaguchi", "authors": "Harsh Purohit, Ryo Tanabe, Kenji Ichige, Takashi Endo, Yuki Nikaido,\n  Kaori Suefusa, and Yohei Kawaguchi", "title": "MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine\n  Investigation and Inspection", "comments": "5 pages, to appear in DCASE 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factory machinery is prone to failure or breakdown, resulting in significant\nexpenses for companies. Hence, there is a rising interest in machine monitoring\nusing different sensors including microphones. In the scientific community, the\nemergence of public datasets has led to advancements in acoustic detection and\nclassification of scenes and events, but there are no public datasets that\nfocus on the sound of industrial machines under normal and anomalous operating\nconditions in real factory environments. In this paper, we present a new\ndataset of industrial machine sounds that we call a sound dataset for\nmalfunctioning industrial machine investigation and inspection (MIMII dataset).\nNormal sounds were recorded for different types of industrial machines (i.e.,\nvalves, pumps, fans, and slide rails), and to resemble a real-life scenario,\nvarious anomalous sounds were recorded (e.g., contamination, leakage, rotating\nunbalance, and rail damage). The purpose of releasing the MIMII dataset is to\nassist the machine-learning and signal-processing community with their\ndevelopment of automated facility maintenance. The MIMII dataset is freely\navailable for download at: https://zenodo.org/record/3384388\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 07:17:34 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Purohit", "Harsh", ""], ["Tanabe", "Ryo", ""], ["Ichige", "Kenji", ""], ["Endo", "Takashi", ""], ["Nikaido", "Yuki", ""], ["Suefusa", "Kaori", ""], ["Kawaguchi", "Yohei", ""]]}, {"id": "1909.09365", "submitter": "Eugene Ndiaye", "authors": "Eugene Ndiaye and Ichiro Takeuchi", "title": "Computing Full Conformal Prediction Set with Approximate Homotopy", "comments": "Conference on Neural Information Processing Systems (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If you are predicting the label $y$ of a new object with $\\hat y$, how\nconfident are you that $y = \\hat y$? Conformal prediction methods provide an\nelegant framework for answering such question by building a $100 (1 -\n\\alpha)\\%$ confidence region without assumptions on the distribution of the\ndata. It is based on a refitting procedure that parses all the possibilities\nfor $y$ to select the most likely ones. Although providing strong coverage\nguarantees, conformal set is impractical to compute exactly for many regression\nproblems. We propose efficient algorithms to compute conformal prediction set\nusing approximated solution of (convex) regularized empirical risk\nminimization. Our approaches rely on a new homotopy continuation technique for\ntracking the solution path with respect to sequential changes of the\nobservations. We also provide a detailed analysis quantifying its complexity.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 08:15:37 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 06:40:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1909.09369", "submitter": "Rafael Poyiadzi", "authors": "Rafael Poyiadzi, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie,\n  Peter Flach", "title": "FACE: Feasible and Actionable Counterfactual Explanations", "comments": "Presented at AAAI/ACM Conference on AI, Ethics, and Society 2020", "journal-ref": null, "doi": "10.1145/3375627.3375850", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work in Counterfactual Explanations tends to focus on the principle of \"the\nclosest possible world\" that identifies small changes leading to the desired\noutcome. In this paper we argue that while this approach might initially seem\nintuitively appealing it exhibits shortcomings not addressed in the current\nliterature. First, a counterfactual example generated by the state-of-the-art\nsystems is not necessarily representative of the underlying data distribution,\nand may therefore prescribe unachievable goals(e.g., an unsuccessful life\ninsurance applicant with severe disability may be advised to do more sports).\nSecondly, the counterfactuals may not be based on a \"feasible path\" between the\ncurrent state of the subject and the suggested one, making actionable recourse\ninfeasible (e.g., low-skilled unsuccessful mortgage applicants may be told to\ndouble their salary, which may be hard without first increasing their skill\nlevel). These two shortcomings may render counterfactual explanations\nimpractical and sometimes outright offensive. To address these two major flaws,\nfirst of all, we propose a new line of Counterfactual Explanations research\naimed at providing actionable and feasible paths to transform a selected\ninstance into one that meets a certain goal. Secondly, we propose FACE: an\nalgorithmically sound way of uncovering these \"feasible paths\" based on the\nshortest path distances defined via density-weighted metrics. Our approach\ngenerates counterfactuals that are coherent with the underlying data\ndistribution and supported by the \"feasible paths\" of change, which are\nachievable and can be tailored to the problem at hand.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 08:29:35 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:39:07 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Sokol", "Kacper", ""], ["Santos-Rodriguez", "Raul", ""], ["De Bie", "Tijl", ""], ["Flach", "Peter", ""]]}, {"id": "1909.09370", "submitter": "Sothea Has", "authors": "Aur\\'elie Fisher (LPSM UMR 8001), Mathilde Mougeot (CMLA, ENSIIE, LPSM\n  UMR 8001), Sothea Has (LPSM UMR 8001)", "title": "A clusterwise supervised learning procedure based on aggregation of\n  distances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, many machine learning procedures are available on the shelve and\nmay be used easily to calibrate predictive models on supervised data. However,\nwhen the input data consists of more than one unknown cluster, and when\ndifferent underlying predictive models exist, fitting a model is a more\nchallenging task. We propose, in this paper, a procedure in three steps to\nautomatically solve this problem. The KFC procedure aggregates different models\nadaptively on data. The first step of the procedure aims at catching the\nclustering structure of the input data, which may be characterized by several\nstatistical distributions. It provides several partitions, given the\nassumptions on the distributions. For each partition, the second step fits a\nspecific predictive model based on the data in each cluster. The overall model\nis computed by a consensual aggregation of the models corresponding to the\ndifferent partitions. A comparison of the performances on different simulated\nand real data assesses the excellent performance of our method in a large\nvariety of prediction problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 08:37:04 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 13:20:31 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 15:51:30 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Fisher", "Aur\u00e9lie", "", "LPSM UMR 8001"], ["Mougeot", "Mathilde", "", "CMLA, ENSIIE, LPSM\n  UMR 8001"], ["Has", "Sothea", "", "LPSM UMR 8001"]]}, {"id": "1909.09399", "submitter": "Mehul S. Raval", "authors": "Rupal Agravat, Mehul S Raval", "title": "Brain Tumor Segmentation and Survival Prediction", "comments": "9 Pages", "journal-ref": "BraTS 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper demonstrates the use of the fully convolutional neural network for\nglioma segmentation on the BraTS 2019 dataset. Three-layers deep\nencoder-decoder architecture is used along with dense connection at encoder\npart to propagate the information from coarse layer to deep layers. This\narchitecture is used to train three tumor sub-components separately.\nSubcomponent training weights are initialized with whole tumor weights to get\nthe localization of the tumor within the brain. At the end, three segmentation\nresults were merged to get the entire tumor segmentation. Dice Similarity of\ntraining dataset with focal loss implementation for whole tumor, tumor core and\nenhancing tumor is 0.92, 0.90 and 0.79 respectively. Radiomic features along\nwith segmentation results and age are used to predict the overall survival of\npatients using random forest regressor to classify survival of patients in\nlong, medium and short survival classes. 55.4% of classification accuracy is\nreported for training dataset with the scans whose resection status is\ngross-total resection.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 10:00:32 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Agravat", "Rupal", ""], ["Raval", "Mehul S", ""]]}, {"id": "1909.09417", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Lieven Vandenberghe, Ali H. Sayed", "title": "Regularized Diffusion Adaptation via Conjugate Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work is to develop and study a distributed strategy for\nPareto optimization of an aggregate cost consisting of regularized risks. Each\nrisk is modeled as the expectation of some loss function with unknown\nprobability distribution while the regularizers are assumed deterministic, but\nare not required to be differentiable or even continuous. The individual,\nregularized, cost functions are distributed across a strongly-connected network\nof agents and the Pareto optimal solution is sought by appealing to a\nmulti-agent diffusion strategy. To this end, the regularizers are smoothed by\nmeans of infimal convolution and it is shown that the Pareto solution of the\napproximate, smooth problem can be made arbitrarily close to the solution of\nthe original, non-smooth problem. Performance bounds are established under\nconditions that are weaker than assumed before in the literature, and hence\napplicable to a broader class of adaptation and learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 10:39:45 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Vlaski", "Stefan", ""], ["Vandenberghe", "Lieven", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1909.09427", "submitter": "Konstantin Schall", "authors": "Konstantin Schall, Kai Uwe Barthel, Nico Hezel, Klaus Jung", "title": "Deep Metric Learning using Similarities from Nonlinear Rank\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep metric learning has achieved promising results in\nlearning high dimensional semantic feature embeddings where the spatial\nrelationships of the feature vectors match the visual similarities of the\nimages. Similarity search for images is performed by determining the vectors\nwith the smallest distances to a query vector. However, high retrieval quality\ndoes not depend on the actual distances of the feature vectors, but rather on\nthe ranking order of the feature vectors from similar images. In this paper, we\nintroduce a metric learning algorithm that focuses on identifying and modifying\nthose feature vectors that most strongly affect the retrieval quality. We\ncompute normalized approximated ranks and convert them to similarities by\napplying a nonlinear transfer function. These similarities are used in a newly\nproposed loss function that better contracts similar and disperses dissimilar\nsamples. Experiments demonstrate significant improvement over existing deep\nfeature embedding methods on the CUB-200-2011, Cars196, and Stanford Online\nProducts data sets for all embedding sizes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 11:07:15 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:49:42 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Schall", "Konstantin", ""], ["Barthel", "Kai Uwe", ""], ["Hezel", "Nico", ""], ["Jung", "Klaus", ""]]}, {"id": "1909.09432", "submitter": "SeyedAbolghasem Mirroshandel", "authors": "Erfan Miahi, Seyed Abolghasem Mirroshandel, Alexis Nasr", "title": "Genetic Neural Architecture Search for automatic assessment of human\n  sperm images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Male infertility is a disease which affects approximately 7% of men. Sperm\nmorphology analysis (SMA) is one of the main diagnosis methods for this\nproblem. Manual SMA is an inexact, subjective, non-reproducible, and hard to\nteach process. As a result, in this paper, we introduce a novel automatic SMA\nbased on a neural architecture search algorithm termed Genetic Neural\nArchitecture Search (GeNAS). For this purpose, we used a collection of images\ncalled MHSMA dataset contains 1,540 sperm images which have been collected from\n235 patients with infertility problems. GeNAS is a genetic algorithm that acts\nas a meta-controller which explores the constrained search space of plain\nconvolutional neural network architectures. Every individual of the genetic\nalgorithm is a convolutional neural network trained to predict morphological\ndeformities in different segments of human sperm (head, vacuole, and acrosome),\nand its fitness is calculated by a novel proposed method named GeNAS-WF\nespecially designed for noisy, low resolution, and imbalanced datasets. Also, a\nhashing method is used to save each trained neural architecture fitness, so we\ncould reuse them during fitness evaluation and speed up the algorithm. Besides,\nin terms of running time and computation power, our proposed architecture\nsearch method is far more efficient than most of the other existing neural\narchitecture search algorithms. Additionally, other proposed methods have been\nevaluated on balanced datasets, whereas GeNAS is built specifically for noisy,\nlow quality, and imbalanced datasets which are common in the field of medical\nimaging. In our experiments, the best neural architecture found by GeNAS has\nreached an accuracy of 91.66%, 77.33%, and 77.66% in the vacuole, head, and\nacrosome abnormality detection, respectively. In comparison to other proposed\nalgorithms for MHSMA dataset, GeNAS achieved state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 11:25:05 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 11:12:35 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Miahi", "Erfan", ""], ["Mirroshandel", "Seyed Abolghasem", ""], ["Nasr", "Alexis", ""]]}, {"id": "1909.09436", "submitter": "Miltiadis Allamanis", "authors": "Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, Marc\n  Brockschmidt", "title": "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search", "comments": "Updated evaluation numbers after fixing indexing bug", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic code search is the task of retrieving relevant code given a natural\nlanguage query. While related to other information retrieval tasks, it requires\nbridging the gap between the language used in code (often abbreviated and\nhighly technical) and natural language more suitable to describe vague concepts\nand ideas.\n  To enable evaluation of progress on code search, we are releasing the\nCodeSearchNet Corpus and are presenting the CodeSearchNet Challenge, which\nconsists of 99 natural language queries with about 4k expert relevance\nannotations of likely results from CodeSearchNet Corpus. The corpus contains\nabout 6 million functions from open-source code spanning six programming\nlanguages (Go, Java, JavaScript, PHP, Python, and Ruby). The CodeSearchNet\nCorpus also contains automatically generated query-like natural language for 2\nmillion functions, obtained from mechanically scraping and preprocessing\nassociated function documentation. In this article, we describe the methodology\nused to obtain the corpus and expert labels, as well as a number of simple\nbaseline solutions for the task.\n  We hope that CodeSearchNet Challenge encourages researchers and practitioners\nto study this interesting task further and will host a competition and\nleaderboard to track the progress on the challenge. We are also keen on\nextending CodeSearchNet Challenge to more queries and programming languages in\nthe future.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 11:52:45 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 09:21:21 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 09:09:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Husain", "Hamel", ""], ["Wu", "Ho-Hsiang", ""], ["Gazit", "Tiferet", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""]]}, {"id": "1909.09444", "submitter": "Hojjat Rakhshani", "authors": "Hojjat Rakhshani, Lhassane Idoumghar, Julien Lepagnot, and Mathieu\n  Brevilliers", "title": "From feature selection to continuous optimization", "comments": "Accepted for EA2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metaheuristic algorithms (MAs) have seen unprecedented growth thanks to their\nsuccessful applications in fields including engineering and health sciences. In\nthis work, we investigate the use of a deep learning (DL) model as an\nalternative tool to do so. The proposed method, called MaNet, is motivated by\nthe fact that most of the DL models often need to solve massive nasty\noptimization problems consisting of millions of parameters. Feature selection\nis the main adopted concepts in MaNet that helps the algorithm to skip\nirrelevant or partially relevant evolutionary information and uses those which\ncontribute most to the overall performance. The introduced model is applied on\nseveral unimodal and multimodal continuous problems. The experiments indicate\nthat MaNet is able to yield competitive results compared to one of the best\nhand-designed algorithms for the aforementioned problems, in terms of the\nsolution accuracy and scalability.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 12:13:27 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 09:49:30 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Rakhshani", "Hojjat", ""], ["Idoumghar", "Lhassane", ""], ["Lepagnot", "Julien", ""], ["Brevilliers", "Mathieu", ""]]}, {"id": "1909.09448", "submitter": "Kjetil Olsen Lye", "authors": "Kjetil O. Lye, Siddhartha Mishra, Roberto Molinaro", "title": "A Multi-level procedure for enhancing accuracy of machine learning\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-level method to increase the accuracy of machine learning\nalgorithms for approximating observables in scientific computing, particularly\nthose that arise in systems modeled by differential equations. The algorithm\nrelies on judiciously combining a large number of computationally cheap\ntraining data on coarse resolutions with a few expensive training samples on\nfine grid resolutions. Theoretical arguments for lowering the generalization\nerror, based on reducing the variance of the underlying maps, are provided and\nnumerical evidence, indicating significant gains over underlying single-level\nmachine learning algorithms, are presented. Moreover, we also apply the\nmulti-level algorithm in the context of forward uncertainty quantification and\nobserve a considerable speed-up over competing algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 12:21:14 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 13:00:12 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Lye", "Kjetil O.", ""], ["Mishra", "Siddhartha", ""], ["Molinaro", "Roberto", ""]]}, {"id": "1909.09453", "submitter": "Rahul Sucharitha", "authors": "Rahul Srinivas Sucharitha, Seokcheon Lee", "title": "Application of Clustering Analysis for Investigation of Food\n  Accessibility", "comments": "8 pages, 25th International Conference on Production Research\n  Manufacturing Innovation: Cyber Physical Manufacturing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to food assistance programs such as food pantries and food banks needs\nfocus in order to mitigate food insecurity. Accessibility to the food\nassistance programs is impacted by demographics of the population and geography\nof the location. It hence becomes imperative to define and identify food\nassistance deserts (Under-served areas) within a given region to find out the\nways to improve the accessibility of food. Food banks, the supplier of food to\nthe food agencies serving the people, can manage its resources more efficiently\nby targeting the food assistance deserts and increase the food supply in those\nregions. This paper will examine the characteristics and structure of the food\nassistance network in the region of Ohio by presenting the possible reasons of\nfood insecurity in this region and identify areas wherein food agencies are\nneeded or may not be needed. Gaussian Mixture Model (GMM) clustering technique\nis employed to identify the possible reasons and address this problem of food\naccessibility.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:09:45 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Sucharitha", "Rahul Srinivas", ""], ["Lee", "Seokcheon", ""]]}, {"id": "1909.09459", "submitter": "Qiang Zheng", "authors": "Qiang Zheng, Lingzao Zeng, Zhendan Cao, George Em Karniadakis", "title": "Physics-informed semantic inpainting: Application to geostatistical\n  modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in geostatistical modeling is to infer the\nheterogeneous geological field based on limited measurements and some prior\nspatial statistics. Semantic inpainting, a technique for image processing using\ndeep generative models, has been recently applied for this purpose,\ndemonstrating its effectiveness in dealing with complex spatial patterns.\nHowever, the original semantic inpainting framework incorporates only\ninformation from direct measurements, while in geostatistics indirect\nmeasurements are often plentiful. To overcome this limitation, here we propose\na physics-informed semantic inpainting framework, employing the Wasserstein\nGenerative Adversarial Network with Gradient Penalty (WGAN-GP) and jointly\nincorporating the direct and indirect measurements by exploiting the underlying\nphysical laws. Our simulation results for a high-dimensional problem with 512\ndimensions show that in the new method, the physical conservation laws are\nsatisfied and contribute in enhancing the inpainting performance compared to\nusing only the direct measurements.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:50:01 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 12:21:44 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Zheng", "Qiang", ""], ["Zeng", "Lingzao", ""], ["Cao", "Zhendan", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1909.09482", "submitter": "Christopher Ormerod", "authors": "Pedro Uria Rodriguez, Amir Jafari and Christopher M. Ormerod", "title": "Language models and Automated Essay Scoring", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new comparative study on automatic essay scoring\n(AES). The current state-of-the-art natural language processing (NLP) neural\nnetwork architectures are used in this work to achieve above human-level\naccuracy on the publicly available Kaggle AES dataset. We compare two powerful\nlanguage models, BERT and XLNet, and describe all the layers and network\narchitectures in these models. We elucidate the network architectures of BERT\nand XLNet using clear notation and diagrams and explain the advantages of\ntransformer architectures over traditional recurrent neural network\narchitectures. Linear algebra notation is used to clarify the functions of\ntransformers and attention mechanisms. We compare the results with more\ntraditional methods, such as bag of words (BOW) and long short term memory\n(LSTM) networks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:50:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Rodriguez", "Pedro Uria", ""], ["Jafari", "Amir", ""], ["Ormerod", "Christopher M.", ""]]}, {"id": "1909.09485", "submitter": "Iftitahu Ni'mah", "authors": "Iftitahu Ni'mah, Vlado Menkovski, Mykola Pechenizkiy", "title": "BSDAR: Beam Search Decoding with Attention Reward in Neural Keyphrase\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study mainly investigates two decoding problems in neural keyphrase\ngeneration: sequence length bias and beam diversity. We introduce an extension\nof beam search inference based on word-level and n-gram level attention score\nto adjust and constrain Seq2Seq prediction at test time. Results show that our\nproposed solution can overcome the algorithm bias to shorter and nearly\nidentical sequences, resulting in a significant improvement of the decoding\nperformance on generating keyphrases that are present and absent in source\ntext.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:44:54 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Ni'mah", "Iftitahu", ""], ["Menkovski", "Vlado", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1909.09490", "submitter": "Hussein Al-Natsheh", "authors": "Hesham Al-Bataineh, Wael Farhan, Ahmad Mustafa, Haitham Seelawi,\n  Hussein T. Al-Natsheh", "title": "Deep Contextualized Pairwise Semantic Similarity for Arabic Language\n  Questions", "comments": "Accepted at ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question semantic similarity is a challenging and active research problem\nthat is very useful in many NLP applications, such as detecting duplicate\nquestions in community question answering platforms such as Quora. Arabic is\nconsidered to be an under-resourced language, has many dialects, and rich in\nmorphology. Combined together, these challenges make identifying semantically\nsimilar questions in Arabic even more difficult. In this paper, we introduce a\nnovel approach to tackle this problem, and test it on two benchmarks; one for\nModern Standard Arabic (MSA), and another for the 24 major Arabic dialects. We\nare able to show that our new system outperforms state-of-the-art approaches by\nachieving 93% F1-score on the MSA benchmark and 82% on the dialectical one.\nThis is achieved by utilizing contextualized word representations (ELMo\nembeddings) trained on a text corpus containing MSA and dialectic sentences.\nThis in combination with a pairwise fine-grained similarity layer, helps our\nquestion-to-question similarity model to generalize predictions on different\ndialects while being trained only on question-to-question MSA data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:58:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Al-Bataineh", "Hesham", ""], ["Farhan", "Wael", ""], ["Mustafa", "Ahmad", ""], ["Seelawi", "Haitham", ""], ["Al-Natsheh", "Hussein T.", ""]]}, {"id": "1909.09493", "submitter": "Pierre Gouedard", "authors": "Pierre Gouedard", "title": "On Recovering Latent Factors From Sampling And Firing Graph", "comments": "38 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": "01", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a set of latent factors whose observable effect of activation is\ncaught on a measure space that appears as a grid of bits tacking value in $\\{0,\n1 \\}$. This paper intend to deliver a theoretical and practical answer to the\nquestion: Given that we have access to a perfect indicator of the activation of\nlatent factors that label a finite dataset of grid's activity, can we imagine a\nprocedure to build a generic identificator of factor's activations ?\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 13:23:14 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Gouedard", "Pierre", ""]]}, {"id": "1909.09501", "submitter": "Mario Lezcano-Casado", "authors": "Mario Lezcano-Casado", "title": "Trivializations for Gradient-Based Optimization on Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a framework to study the transformation of problems with\nmanifold constraints into unconstrained problems through parametrizations in\nterms of a Euclidean space. We call these parametrizations \"trivializations\".\nWe prove conditions under which a trivialization is sound in the context of\ngradient-based optimization and we show how two large families of\ntrivializations have overall favorable properties, but also suffer from a\nperformance issue. We then introduce \"dynamic trivializations\", which solve\nthis problem, and we show how these form a family of optimization methods that\nlie between trivializations and Riemannian gradient descent, and combine the\nbenefits of both of them. We then show how to implement these two families of\ntrivializations in practice for different matrix manifolds. To this end, we\nprove a formula for the gradient of the exponential of matrices, which can be\nof practical interest on its own. Finally, we show how dynamic trivializations\nimprove the performance of existing methods on standard tasks designed to test\nlong-term memory within neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 13:41:43 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 19:42:08 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lezcano-Casado", "Mario", ""]]}, {"id": "1909.09528", "submitter": "S\\\"oren Christensen", "authors": "S\\\"oren Christensen and Claudia Strauch", "title": "Nonparametric learning for impulse control problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental assumptions in stochastic control of continuous time\nprocesses is that the dynamics of the underlying (diffusion) process is known.\nThis is, however, usually obviously not fulfilled in practice. On the other\nhand, over the last decades, a rich theory for nonparametric estimation of the\ndrift (and volatility) for continuous time processes has been developed. The\naim of this paper is bringing together techniques from stochastic control with\nmethods from statistics for stochastic processes to find a way to both learn\nthe dynamics of the underlying process and control in a reasonable way at the\nsame time. More precisely, we study a long-term average impulse control\nproblem, a stochastic version of the classical Faustmann timber harvesting\nproblem. One of the problems that immediately arises is an\nexploration-exploitation dilemma as is well known for problems in machine\nlearning. We propose a way to deal with this issue by combining exploration and\nexploitation periods in a suitable way. Our main finding is that this\nconstruction can be based on the rates of convergence of estimators for the\ninvariant density. Using this, we obtain that the average cumulated regret is\nof uniform order $O({T^{-1/3}})$.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:32:08 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 13:15:44 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Christensen", "S\u00f6ren", ""], ["Strauch", "Claudia", ""]]}, {"id": "1909.09540", "submitter": "Shin-Ichi Maeda", "authors": "Shin-ichi Maeda, Hayato Watahiki, Shintarou Okada, Masanori Koyama", "title": "Reconnaissance and Planning algorithm for constrained MDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practical reinforcement learning problems are often formulated as constrained\nMarkov decision process (CMDP) problems, in which the agent has to maximize the\nexpected return while satisfying a set of prescribed safety constraints. In\nthis study, we propose a novel simulator-based method to approximately solve a\nCMDP problem without making any compromise on the safety constraints. We\nachieve this by decomposing the CMDP into a pair of MDPs; reconnaissance MDP\nand planning MDP. The purpose of reconnaissance MDP is to evaluate the set of\nactions that are safe, and the purpose of planning MDP is to maximize the\nreturn while using the actions authorized by reconnaissance MDP. RMDP can\ndefine a set of safe policies for any given set of safety constraint, and this\nset of safe policies can be used to solve another CMDP problem with different\nreward. Our method is not only computationally less demanding than the previous\nsimulator-based approaches to CMDP, but also capable of finding a competitive\nreward-seeking policy in a high dimensional environment, including those\ninvolving multiple moving obstacles.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:44:36 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Maeda", "Shin-ichi", ""], ["Watahiki", "Hayato", ""], ["Okada", "Shintarou", ""], ["Koyama", "Masanori", ""]]}, {"id": "1909.09552", "submitter": "Tong Wu", "authors": "Tong Wu, Liang Tong, Yevgeniy Vorobeychik", "title": "Defending Against Physically Realizable Attacks on Image Classification", "comments": "camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of defending deep neural network approaches for image\nclassification from physically realizable attacks. First, we demonstrate that\nthe two most scalable and effective methods for learning robust models,\nadversarial training with PGD attacks and randomized smoothing, exhibit very\nlimited effectiveness against three of the highest profile physical attacks.\nNext, we propose a new abstract adversarial model, rectangular occlusion\nattacks, in which an adversary places a small adversarially crafted rectangle\nin an image, and develop two approaches for efficiently computing the resulting\nadversarial examples. Finally, we demonstrate that adversarial training using\nour new attack yields image classification models that exhibit high robustness\nagainst the physically realizable attacks we study, offering the first\neffective generic defense against such attacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 15:11:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 20:07:55 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wu", "Tong", ""], ["Tong", "Liang", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1909.09557", "submitter": "Shigehiko Schamoni", "authors": "Shigehiko Schamoni, Holger A. Lindner, Verena Schneider-Lindner,\n  Manfred Thiel, Stefan Riezler", "title": "Leveraging Implicit Expert Knowledge for Non-Circular Machine Learning\n  in Sepsis Prediction", "comments": "Accepted for publication in Journal of Artificial Intelligence in\n  Medicine", "journal-ref": "Artificial Intelligence in Medicine, Volume 100, September 2019,\n  Pages 101725", "doi": "10.1016/j.artmed.2019.101725", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is the leading cause of death in non-coronary intensive care units.\nMoreover, a delay of antibiotic treatment of patients with severe sepsis by\nonly few hours is associated with increased mortality. This insight makes\naccurate models for early prediction of sepsis a key task in machine learning\nfor healthcare. Previous approaches have achieved high AUROC by learning from\nelectronic health records where sepsis labels were defined automatically\nfollowing established clinical criteria. We argue that the practice of\nincorporating the clinical criteria that are used to automatically define\nground truth sepsis labels as features of severity scoring models is inherently\ncircular and compromises the validity of the proposed approaches. We propose to\ncreate an independent ground truth for sepsis research by exploiting implicit\nknowledge of clinical practitioners via an electronic questionnaire which\nrecords attending physicians' daily judgements of patients' sepsis status. We\nshow that despite its small size, our dataset allows to achieve\nstate-of-the-art AUROC scores. An inspection of learned weights for\nstandardized features of the linear model lets us infer potentially surprising\nfeature contributions and allows to interpret seemingly counterintuitive\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 15:20:09 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Schamoni", "Shigehiko", ""], ["Lindner", "Holger A.", ""], ["Schneider-Lindner", "Verena", ""], ["Thiel", "Manfred", ""], ["Riezler", "Stefan", ""]]}, {"id": "1909.09569", "submitter": "Yao Shu", "authors": "Yao Shu, Wei Wang and Shaofeng Cai", "title": "Understanding Architectures Learnt by Cell-based Neural Architecture\n  Search", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) searches architectures automatically for\ngiven tasks, e.g., image classification and language modeling. Improving the\nsearch efficiency and effectiveness have attracted increasing attention in\nrecent years. However, few efforts have been devoted to understanding the\ngenerated architectures. In this paper, we first reveal that existing NAS\nalgorithms (e.g., DARTS, ENAS) tend to favor architectures with wide and\nshallow cell structures. These favorable architectures consistently achieve\nfast convergence and are consequently selected by NAS algorithms. Our empirical\nand theoretical study further confirms that their fast convergence derives from\ntheir smooth loss landscape and accurate gradient information. Nonetheless,\nthese architectures may not necessarily lead to better generalization\nperformance compared with other candidate architectures in the same search\nspace, and therefore further improvement is possible by revising existing NAS\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 15:49:45 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 12:14:40 GMT"}, {"version": "v3", "created": "Wed, 1 Jan 2020 13:57:23 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Shu", "Yao", ""], ["Wang", "Wei", ""], ["Cai", "Shaofeng", ""]]}, {"id": "1909.09571", "submitter": "Angelos Filos", "authors": "Angelos Filos", "title": "Reinforcement Learning for Portfolio Management", "comments": "Imperial College London MEng Thesis 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this thesis, we develop a comprehensive account of the expressive power,\nmodelling efficiency, and performance advantages of so-called trading agents\n(i.e., Deep Soft Recurrent Q-Network (DSRQN) and Mixture of Score Machines\n(MSM)), based on both traditional system identification (model-based approach)\nas well as on context-independent agents (model-free approach). The analysis\nprovides conclusive support for the ability of model-free reinforcement\nlearning methods to act as universal trading agents, which are not only capable\nof reducing the computational and memory complexity (owing to their linear\nscaling with the size of the universe), but also serve as generalizing\nstrategies across assets and markets, regardless of the trading universe on\nwhich they have been trained. The relatively low volume of daily returns in\nfinancial market data is addressed via data augmentation (a generative\napproach) and a choice of pre-training strategies, both of which are validated\nagainst current state-of-the-art models. For rigour, a risk-sensitive framework\nwhich includes transaction costs is considered, and its performance advantages\nare demonstrated in a variety of scenarios, from synthetic time-series\n(sinusoidal, sawtooth and chirp waves), simulated market series (surrogate data\nbased), through to real market data (S\\&P 500 and EURO STOXX 50). The analysis\nand simulations confirm the superiority of universal model-free reinforcement\nlearning agents over current portfolio management model in asset allocation\nstrategies, with the achieved performance advantage of as much as 9.2\\% in\nannualized cumulative returns and 13.4\\% in annualized Sharpe Ratio.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:28:24 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Filos", "Angelos", ""]]}, {"id": "1909.09587", "submitter": "Tsung-Yuan Hsu", "authors": "Tsung-yuan Hsu, Chi-liang Liu, Hung-yi Lee", "title": "Zero-shot Reading Comprehension by Cross-lingual Transfer Learning with\n  Multi-lingual Language Representation Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because it is not feasible to collect training data for every language, there\nis a growing interest in cross-lingual transfer learning. In this paper, we\nsystematically explore zero-shot cross-lingual transfer learning on reading\ncomprehension tasks with a language representation model pre-trained on\nmulti-lingual corpus. The experimental results show that with pre-trained\nlanguage representation zero-shot learning is feasible, and translating the\nsource data into the target language is not necessary and even degrades the\nperformance. We further explore what does the model learn in zero-shot setting.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 10:33:05 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Hsu", "Tsung-yuan", ""], ["Liu", "Chi-liang", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1909.09593", "submitter": "Vu Nguyen", "authors": "Vu Nguyen and Sebastian Schulze and Michael A Osborne", "title": "Bayesian Optimization for Iterative Learning", "comments": "Camera ready NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep (reinforcement) learning systems crucially depends on\nthe choice of hyperparameters. Their tuning is notoriously expensive, typically\nrequiring an iterative training process to run for numerous steps to\nconvergence. Traditional tuning algorithms only consider the final performance\nof hyperparameters acquired after many expensive iterations and ignore\nintermediate information from earlier training steps. In this paper, we present\na Bayesian optimization (BO) approach which exploits the iterative structure of\nlearning algorithms for efficient hyperparameter tuning. We propose to learn an\nevaluation function compressing learning progress at any stage of the training\nprocess into a single numeric score according to both training success and\nstability. Our BO framework is then balancing the benefit of assessing a\nhyperparameter setting over additional training steps against their computation\ncost. We further increase model efficiency by selectively including scores from\ndifferent training steps for any evaluated hyperparameter set. We demonstrate\nthe efficiency of our algorithm by tuning hyperparameters for the training of\ndeep reinforcement learning agents and convolutional neural networks. Our\nalgorithm outperforms all existing baselines in identifying optimal\nhyperparameters in minimal time.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 16:14:34 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:48:56 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 21:15:58 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 16:10:30 GMT"}, {"version": "v5", "created": "Sat, 16 Jan 2021 11:42:27 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Nguyen", "Vu", ""], ["Schulze", "Sebastian", ""], ["Osborne", "Michael A", ""]]}, {"id": "1909.09596", "submitter": "Konstantinos Nikolakakis", "authors": "Konstantinos E. Nikolakakis, Dionysios S. Kalogerias, Anand D. Sarwate", "title": "Optimal Rates for Learning Hidden Tree Structures", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide high probability finite sample complexity guarantees for hidden\nnon-parametric structure learning of tree-shaped graphical models, whose hidden\nand observable nodes are discrete random variables with either finite or\ncountable alphabets. We study a fundamental quantity called the (noisy)\ninformation threshold, which arises naturally from the error analysis of the\nChow-Liu algorithm and, as we discuss, provides explicit necessary and\nsufficient conditions on sample complexity, by effectively summarizing the\ndifficulty of the tree-structure learning problem. Specifically, we show that\nthe finite sample complexity of the Chow-Liu algorithm for ensuring exact\nstructure recovery from noisy data is inversely proportional to the information\nthreshold squared (provided it is positive), and scales almost logarithmically\nrelative to the number of nodes over a given probability of failure.\nConversely, we show that, if the number of samples is less than an absolute\nconstant times the inverse of information threshold squared, then no algorithm\ncan recover the hidden tree structure with probability greater than one half.\nAs a consequence, our upper and lower bounds match with respect to the\ninformation threshold, indicating that it is a fundamental quantity for the\nproblem of learning hidden tree-structured models. Further, the Chow-Liu\nalgorithm with noisy data as input achieves the optimal rate with respect to\nthe information threshold. Lastly, as a byproduct of our analysis, we resolve\nthe problem of tree structure learning in the presence of non-identically\ndistributed observation noise, providing conditions for convergence of the\nChow-Liu algorithm under this setting, as well.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 16:18:26 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 23:19:15 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 17:47:58 GMT"}, {"version": "v4", "created": "Wed, 31 Mar 2021 17:36:48 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Nikolakakis", "Konstantinos E.", ""], ["Kalogerias", "Dionysios S.", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "1909.09598", "submitter": "Heon Lee", "authors": "Samuel Yu, Heon Lee, Jung Hoon Kim", "title": "Street Crossing Aid Using Light-weight CNNs for the Visually Impaired", "comments": "10 pages, 5 figures, 7 tables, ICCV 2019 - 7th International Workshop\n  on Assistive Computer Vision and Robotics (ACVR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we address an issue that the visually impaired commonly face\nwhile crossing intersections and propose a solution that takes form as a mobile\napplication. The application utilizes a deep learning convolutional neural\nnetwork model, LytNetV2, to output necessary information that the visually\nimpaired may lack when without human companions or guide-dogs. A prototype of\nthe application runs on iOS devices of versions 11 or above. It is designed for\ncomprehensiveness, concision, accuracy, and computational efficiency through\ndelivering the two most important pieces of information, pedestrian traffic\nlight color and direction, required to cross the road in real-time.\nFurthermore, it is specifically aimed to support those facing financial burden\nas the solution takes the form of a free mobile application. Through the\nmodification and utilization of key principles in MobileNetV3 such as depthwise\nseperable convolutions and squeeze-excite layers, the deep neural network model\nachieves a classification accuracy of 96% and average angle error of 6.15\ndegrees, while running at a frame rate of 16.34 frames per second.\nAdditionally, the model is trained as an image classifier, allowing for a\nfaster and more accurate model. The network is able to outperform other methods\nsuch as object detection and non-deep learning algorithms in both accuracy and\nthoroughness. The information is delivered through both auditory signals and\nvibrations, and it has been tested on seven visually impaired and has received\nabove satisfactory responses.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 11:29:33 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Yu", "Samuel", ""], ["Lee", "Heon", ""], ["Kim", "Jung Hoon", ""]]}, {"id": "1909.09602", "submitter": "Brian Hutchinson", "authors": "Chris Careaga, Brian Hutchinson, Nathan Hodas and Lawrence Phillips", "title": "Metric-Based Few-Shot Learning for Video Action Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the few-shot scenario, a learner must effectively generalize to unseen\nclasses given a small support set of labeled examples. While a relatively large\namount of research has gone into few-shot learning for image classification,\nlittle work has been done on few-shot video classification. In this work, we\naddress the task of few-shot video action recognition with a set of two-stream\nmodels. We evaluate the performance of a set of convolutional and recurrent\nneural network video encoder architectures used in conjunction with three\npopular metric-based few-shot algorithms. We train and evaluate using a\nfew-shot split of the Kinetics 600 dataset. Our experiments confirm the\nimportance of the two-stream setup, and find prototypical networks and pooled\nlong short-term memory network embeddings to give the best performance as\nfew-shot method and video encoder, respectively. For a 5-shot 5-way task, this\nsetup obtains 84.2% accuracy on the test set and 59.4% on a special \"challenge\"\ntest set, composed of highly confusable classes.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 17:53:16 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Careaga", "Chris", ""], ["Hutchinson", "Brian", ""], ["Hodas", "Nathan", ""], ["Phillips", "Lawrence", ""]]}, {"id": "1909.09621", "submitter": "Elena Smirnova", "authors": "Elena Smirnova and Elvis Dohmatob", "title": "On the Convergence of Approximate and Regularized Policy Iteration\n  Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy regularized algorithms such as Soft Q-learning and Soft Actor-Critic,\nrecently showed state-of-the-art performance on a number of challenging\nreinforcement learning (RL) tasks. The regularized formulation modifies the\nstandard RL objective and thus generally converges to a policy different from\nthe optimal greedy policy of the original RL problem. Practically, it is\nimportant to control the sub-optimality of the regularized optimal policy. In\nthis paper, we establish sufficient conditions for convergence of a large class\nof regularized dynamic programming algorithms, unified under regularized\nmodified policy iteration (MPI) and conservative value iteration (VI) schemes.\nWe provide explicit convergence rates to the optimality depending on the\ndecrease rate of the regularization parameter. Our experiments show that the\nempirical error closely follows the established theoretical convergence rates.\nIn addition to optimality, we demonstrate two desirable behaviours of the\nregularized algorithms even in the absence of approximations: robustness to\nstochasticity of environment and safety of trajectories induced by the policy\niterates.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 17:13:59 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 12:04:49 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Smirnova", "Elena", ""], ["Dohmatob", "Elvis", ""]]}, {"id": "1909.09638", "submitter": "Sobhan Moosavi", "authors": "Sobhan Moosavi, Mohammad Hossein Samavatian, Srinivasan Parthasarathy,\n  Radu Teodorescu, Rajiv Ramnath", "title": "Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset\n  and Insights", "comments": "In Proceedings of the 27th ACM SIGSPATIAL, International Conference\n  on Advances in Geographic Information Systems (2019). arXiv admin note:\n  substantial text overlap with arXiv:1906.05409", "journal-ref": null, "doi": "10.1145/3347146.3359078", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing traffic accidents is an important public safety challenge,\ntherefore, accident analysis and prediction has been a topic of much research\nover the past few decades. Using small-scale datasets with limited coverage,\nbeing dependent on extensive set of data, and being not applicable for\nreal-time purposes are the important shortcomings of the existing studies. To\naddress these challenges, we propose a new solution for real-time traffic\naccident prediction using easy-to-obtain, but sparse data. Our solution relies\non a deep-neural-network model (which we have named DAP, for Deep Accident\nPrediction); which utilizes a variety of data attributes such as traffic\nevents, weather data, points-of-interest, and time. DAP incorporates multiple\ncomponents including a recurrent (for time-sensitive data), a fully connected\n(for time-insensitive data), and a trainable embedding component (to capture\nspatial heterogeneity). To fill the data gap, we have - through a comprehensive\nprocess of data collection, integration, and augmentation - created a\nlarge-scale publicly available database of accident information named\nUS-Accidents. By employing the US-Accidents dataset and through an extensive\nset of experiments across several large cities, we have evaluated our proposal\nagainst several baselines. Our analysis and results show significant\nimprovements to predict rare accident events. Further, we have shown the impact\nof traffic information, time, and points-of-interest data for real-time\naccident prediction.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:41:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Moosavi", "Sobhan", ""], ["Samavatian", "Mohammad Hossein", ""], ["Parthasarathy", "Srinivasan", ""], ["Teodorescu", "Radu", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1909.09656", "submitter": "Arber Zela", "authors": "Arber Zela, Thomas Elsken, Tonmoy Saikia, Yassine Marrakchi, Thomas\n  Brox, Frank Hutter", "title": "Understanding and Robustifying Differentiable Architecture Search", "comments": "In: International Conference on Learning Representations (ICLR 2020);\n  28 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable Architecture Search (DARTS) has attracted a lot of attention\ndue to its simplicity and small search costs achieved by a continuous\nrelaxation and an approximation of the resulting bi-level optimization problem.\nHowever, DARTS does not work robustly for new problems: we identify a wide\nrange of search spaces for which DARTS yields degenerate architectures with\nvery poor test performance. We study this failure mode and show that, while\nDARTS successfully minimizes validation loss, the found solutions generalize\npoorly when they coincide with high validation loss curvature in the\narchitecture space. We show that by adding one of various types of\nregularization we can robustify DARTS to find solutions with less curvature and\nbetter generalization properties. Based on these observations, we propose\nseveral simple variations of DARTS that perform substantially more robustly in\npractice. Our observations are robust across five search spaces on three image\nclassification tasks and also hold for the very different domains of disparity\nestimation (a dense regression task) and language modelling.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 18:03:06 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 14:14:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Zela", "Arber", ""], ["Elsken", "Thomas", ""], ["Saikia", "Tonmoy", ""], ["Marrakchi", "Yassine", ""], ["Brox", "Thomas", ""], ["Hutter", "Frank", ""]]}, {"id": "1909.09667", "submitter": "Anand Rajagopalan", "authors": "Aditya Krishna Menon, Anand Rajagopalan, Baris Sumengen, Gui Citovsky,\n  Qin Cao, Sanjiv Kumar", "title": "Online Hierarchical Clustering Approximations", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hierarchical clustering is a widely used approach for clustering datasets at\nmultiple levels of granularity. Despite its popularity, existing algorithms\nsuch as hierarchical agglomerative clustering (HAC) are limited to the offline\nsetting, and thus require the entire dataset to be available. This prohibits\ntheir use on large datasets commonly encountered in modern learning\napplications. In this paper, we consider hierarchical clustering in the online\nsetting, where points arrive one at a time. We propose two algorithms that seek\nto optimize the Moseley and Wang (MW) revenue function, a variant of the\nDasgupta cost. These algorithms offer different tradeoffs between efficiency\nand MW revenue performance. The first algorithm, OTD, is a highly efficient\nOnline Top Down algorithm which provably achieves a 1/3-approximation to the MW\nrevenue under a data separation assumption. The second algorithm, OHAC, is an\nonline counterpart to offline HAC, which is known to yield a 1/3-approximation\nto the MW revenue, and produce good quality clusters in practice. We show that\nOHAC approximates offline HAC by leveraging a novel split-merge procedure. We\nempirically show that OTD and OHAC offer significant efficiency and cluster\nquality gains respectively over baselines.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 18:29:59 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Menon", "Aditya Krishna", ""], ["Rajagopalan", "Anand", ""], ["Sumengen", "Baris", ""], ["Citovsky", "Gui", ""], ["Cao", "Qin", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1909.09690", "submitter": "Hossein Keshavarz", "authors": "Hossein Keshavarz, Shohreh Tabatabayi Seifi, Mohammad Izadi", "title": "A Deep Learning-Based Approach for Measuring the Domain Similarity of\n  Persian Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach for measuring the degree of\nsimilarity between categories of two pieces of Persian text, which were\npublished as descriptions of two separate advertisements. We built an\nappropriate dataset for this work using a dataset which consists of\nadvertisements posted on an e-commerce website. We generated a significant\nnumber of paired texts from this dataset and assigned each pair a score from 0\nto 3, which demonstrates the degree of similarity between the domains of the\npair. In this work, we represent words with word embedding vectors derived from\nword2vec. Then deep neural network models are used to represent texts.\nEventually, we employ concatenation of absolute difference and bit-wise\nmultiplication and a fully-connected neural network to produce a probability\ndistribution vector for the score of the pairs. Through a supervised learning\napproach, we trained our model on a GPU, and our best model achieved an F1\nscore of 0.9865.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:29:14 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:20:11 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Keshavarz", "Hossein", ""], ["Seifi", "Shohreh Tabatabayi", ""], ["Izadi", "Mohammad", ""]]}, {"id": "1909.09691", "submitter": "Hussein Al-Natsheh", "authors": "Haitham Seelawi, Ahmad Mustafa, Hesham Al-Bataineh, Wael Farhan,\n  Hussein T. Al-Natsheh", "title": "NSURL-2019 Shared Task 8: Semantic Question Similarity in Arabic", "comments": "8 pages, 2 figure, 3 tables, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question semantic similarity (Q2Q) is a challenging task that is very useful\nin many NLP applications, such as detecting duplicate questions and question\nanswering systems. In this paper, we present the results and findings of the\nshared task (Semantic Question Similarity in Arabic). The task was organized as\npart of the first workshop on NLP Solutions for Under Resourced Languages\n(NSURL 2019) The goal of the task is to predict whether two questions are\nsemantically similar or not, even if they are phrased differently. A total of 9\nteams participated in the task. The datasets created for this task are made\npublicly available to support further research on Arabic Q2Q.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:45:43 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Seelawi", "Haitham", ""], ["Mustafa", "Ahmad", ""], ["Al-Bataineh", "Hesham", ""], ["Farhan", "Wael", ""], ["Al-Natsheh", "Hussein T.", ""]]}, {"id": "1909.09699", "submitter": "Khyathi Raghavi Chandu", "authors": "Ruo-Ping Dong, Khyathi Raghavi Chandu, Alan W Black", "title": "Induction and Reference of Entities in a Visual Story", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are enveloped by stories of visual interpretations in our everyday lives.\nThe way we narrate a story often comprises of two stages, which are, forming a\ncentral mind map of entities and then weaving a story around them. A\ncontributing factor to coherence is not just basing the story on these entities\nbut also, referring to them using appropriate terms to avoid repetition. In\nthis paper, we address these two stages of introducing the right entities at\nseemingly reasonable junctures and also referring them coherently in the\ncontext of visual storytelling. The building blocks of the central mind map,\nalso known as entity skeleton are entity chains including nominal and\ncoreference expressions. This entity skeleton is also represented in different\nlevels of abstractions to compose a generalized frame to weave the story. We\nbuild upon an encoder-decoder framework to penalize the model when the decoded\nstory does not adhere to this entity skeleton. We establish a strong baseline\nfor skeleton informed generation and then extend this to have the capability of\nmultitasking by predicting the skeleton in addition to generating the story.\nFinally, we build upon this model and propose a glocal hierarchical attention\nmodel that attends to the skeleton both at the sentence (local) and the story\n(global) levels. We observe that our proposed models outperform the baseline in\nterms of automatic evaluation metric, METEOR. We perform various analysis\ntargeted to evaluate the performance of our task of enforcing the entity\nskeleton such as the number and diversity of the entities generated. We also\nconduct human evaluation from which it is concluded that the visual stories\ngenerated by our model are preferred 82% of the times. In addition, we show\nthat our glocal hierarchical attention model improves coherence by introducing\nmore pronouns as required by the presence of nouns.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 01:09:01 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Dong", "Ruo-Ping", ""], ["Chandu", "Khyathi Raghavi", ""], ["Black", "Alan W", ""]]}, {"id": "1909.09702", "submitter": "Karan Aggarwal", "authors": "Swaraj Khadanga, Karan Aggarwal, Shafiq Joty, Jaideep Srivastava", "title": "Using Clinical Notes with Time Series Data for ICU Management", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring patients in ICU is a challenging and high-cost task. Hence,\npredicting the condition of patients during their ICU stay can help provide\nbetter acute care and plan the hospital's resources. There has been continuous\nprogress in machine learning research for ICU management, and most of this work\nhas focused on using time series signals recorded by ICU instruments. In our\nwork, we show that adding clinical notes as another modality improves the\nperformance of the model for three benchmark tasks: in-hospital mortality\nprediction, modeling decompensation, and length of stay forecasting that play\nan important role in ICU management. While the time-series data is measured at\nregular intervals, doctor notes are charted at irregular times, making it\nchallenging to model them together. We propose a method to model them jointly,\nachieving considerable improvement across benchmark tasks over baseline\ntime-series model. Our implementation can be found at\n\\url{https://github.com/kaggarwal/ClinicalNotesICU}.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 04:27:32 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 18:21:02 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Khadanga", "Swaraj", ""], ["Aggarwal", "Karan", ""], ["Joty", "Shafiq", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "1909.09705", "submitter": "Hossein K. Mousavi", "authors": "Hossein K. Mousavi, Guangyi Liu, Weihang Yuan, Martin Tak\\'a\\v{c},\n  H\\'ector Mu\\~noz-Avila, Nader Motee", "title": "A Layered Architecture for Active Perception: Image Classification using\n  Deep Reinforcement Learning", "comments": "Submitted to ICRA-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a planning and perception mechanism for a robot (agent), that can\nonly observe the underlying environment partially, in order to solve an image\nclassification problem. A three-layer architecture is suggested that consists\nof a meta-layer that decides the intermediate goals, an action-layer that\nselects local actions as the agent navigates towards a goal, and a\nclassification-layer that evaluates the reward and makes a prediction. We\ndesign and implement these layers using deep reinforcement learning. A\ngeneralized policy gradient algorithm is utilized to learn the parameters of\nthese layers to maximize the expected reward. Our proposed methodology is\ntested on the MNIST dataset of handwritten digits, which provides us with a\nlevel of explainability while interpreting the agent's intermediate goals and\ncourse of action.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 19:52:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Mousavi", "Hossein K.", ""], ["Liu", "Guangyi", ""], ["Yuan", "Weihang", ""], ["Tak\u00e1\u010d", "Martin", ""], ["Mu\u00f1oz-Avila", "H\u00e9ctor", ""], ["Motee", "Nader", ""]]}, {"id": "1909.09706", "submitter": "Hassan Hafez Kolahi", "authors": "Hassan Hafez-Kolahi, Shohreh Kasaei, Mahdiyeh Soleymani-Baghshah", "title": "Do Compressed Representations Generalize Better?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most studied problems in machine learning is finding reasonable\nconstraints that guarantee the generalization of a learning algorithm. These\nconstraints are usually expressed as some simplicity assumptions on the target.\nFor instance, in the Vapnik-Chervonenkis (VC) theory the space of possible\nhypotheses is considered to have a limited VC dimension. In this paper, the\nconstraint on the entropy $H(X)$ of the input variable $X$ is studied as a\nsimplicity assumption. It is proven that the sample complexity to achieve an\n$\\epsilon$-$\\delta$ Probably Approximately Correct (PAC) hypothesis is bounded\nby $\\frac{2^{\n\\left.6H(X)\\middle/\\epsilon\\right.}+\\log{\\frac{1}{\\delta}}}{\\epsilon^2}$ which\nis sharp up to the $\\frac{1}{\\epsilon^2}$ factor. Morever, it is shown that if\na feature learning process is employed to learn the compressed representation\nfrom the dataset, this bound no longer exists. These findings have important\nimplications on the Information Bottleneck (IB) theory which had been utilized\nto explain the generalization power of Deep Neural Networks (DNNs), but its\napplicability for this purpose is currently under debate by researchers. In\nparticular, this is a rigorous proof for the previous heuristic that compressed\nrepresentations are exponentially easier to be learned. However, our analysis\npinpoints two factors preventing the IB, in its current form, to be applicable\nin studying neural networks. Firstly, the exponential dependence of sample\ncomplexity on $\\frac{1}{\\epsilon}$, which can lead to a dramatic effect on the\nbounds in practical applications when $\\epsilon$ is small. Secondly, our\nanalysis reveals that arguments based on input compression are inherently\ninsufficient to explain generalization of methods like DNNs in which the\nfeatures are also learned using available data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 19:54:42 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 09:38:27 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Hafez-Kolahi", "Hassan", ""], ["Kasaei", "Shohreh", ""], ["Soleymani-Baghshah", "Mahdiyeh", ""]]}, {"id": "1909.09712", "submitter": "Zhen Xu", "authors": "Zhen Xu, Andrew M. Dai, Jonas Kemp, Luke Metz", "title": "Learning an Adaptive Learning Rate Schedule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning rate is one of the most important hyper-parameters for model\ntraining and generalization. However, current hand-designed parametric learning\nrate schedules offer limited flexibility and the predefined schedule may not\nmatch the training dynamics of high dimensional and non-convex optimization\nproblems. In this paper, we propose a reinforcement learning based framework\nthat can automatically learn an adaptive learning rate schedule by leveraging\nthe information from past training histories. The learning rate dynamically\nchanges based on the current training dynamics. To validate this framework, we\nconduct experiments with different neural network architectures on the Fashion\nMINIST and CIFAR10 datasets. Experimental results show that the auto-learned\nlearning rate controller can achieve better test results. In addition, the\ntrained controller network is generalizable -- able to be trained on one data\nset and transferred to new problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 20:45:31 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Xu", "Zhen", ""], ["Dai", "Andrew M.", ""], ["Kemp", "Jonas", ""], ["Metz", "Luke", ""]]}, {"id": "1909.09734", "submitter": "Antonio Moretti", "authors": "Antonio Khalil Moretti, Zizhao Wang, Luhuan Wu, Iddo Drori, Itsik\n  Pe'er", "title": "Particle Smoothing Variational Objectives", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A body of recent work has focused on constructing a variational family of\nfiltered distributions using Sequential Monte Carlo (SMC). Inspired by this\nwork, we introduce Particle Smoothing Variational Objectives (SVO), a novel\nbackward simulation technique and smoothed approximate posterior defined\nthrough a subsampling process. SVO augments support of the proposal and boosts\nparticle diversity. Recent literature argues that increasing the number of\nsamples K to obtain tighter variational bounds may hurt the proposal learning,\ndue to a signal-to-noise ratio (SNR) of gradient estimators decreasing at the\nrate $\\mathcal{O}(1/\\sqrt{K})$. As a second contribution, we develop\ntheoretical and empirical analysis of the SNR in filtering SMC, which motivates\nour choice of biased gradient estimators. We prove that introducing bias by\ndropping Categorical terms from the gradient estimate or using Gumbel-Softmax\nmitigates the adverse effect on the SNR. We apply SVO to three nonlinear latent\ndynamics tasks and provide statistics to rigorously quantify the predictions of\nfiltered and smoothed objectives. SVO consistently outperforms filtered\nobjectives when given fewer Monte Carlo samples on three nonlinear systems of\nincreasing complexity.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 22:31:46 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Moretti", "Antonio Khalil", ""], ["Wang", "Zizhao", ""], ["Wu", "Luhuan", ""], ["Drori", "Iddo", ""], ["Pe'er", "Itsik", ""]]}, {"id": "1909.09757", "submitter": "Yixing Xu", "authors": "Yixing Xu, Yunhe Wang, Hanting Chen, Kai Han, Chunjing Xu, Dacheng\n  Tao, Chang Xu", "title": "Positive-Unlabeled Compression on the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many attempts have been done to extend the great success of convolutional\nneural networks (CNNs) achieved on high-end GPU servers to portable devices\nsuch as smart phones. Providing compression and acceleration service of deep\nlearning models on the cloud is therefore of significance and is attractive for\nend users. However, existing network compression and acceleration approaches\nusually fine-tuning the svelte model by requesting the entire original training\ndata (\\eg ImageNet), which could be more cumbersome than the network itself and\ncannot be easily uploaded to the cloud. In this paper, we present a novel\npositive-unlabeled (PU) setting for addressing this problem. In practice, only\na small portion of the original training set is required as positive examples\nand more useful training examples can be obtained from the massive unlabeled\ndata on the cloud through a PU classifier with an attention based multi-scale\nfeature extractor. We further introduce a robust knowledge distillation (RKD)\nscheme to deal with the class imbalance problem of these newly augmented\ntraining examples. The superiority of the proposed method is verified through\nexperiments conducted on the benchmark models and datasets. We can use only\n$8\\%$ of uniformly selected data from the ImageNet to obtain an efficient model\nwith comparable performance to the baseline ResNet-34.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 01:21:16 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 03:06:55 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Xu", "Yixing", ""], ["Wang", "Yunhe", ""], ["Chen", "Hanting", ""], ["Han", "Kai", ""], ["Xu", "Chunjing", ""], ["Tao", "Dacheng", ""], ["Xu", "Chang", ""]]}, {"id": "1909.09785", "submitter": "Hunter Lang", "authors": "Hunter Lang, Pengchuan Zhang, Lin Xiao", "title": "Using Statistics to Automate Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the development of numerous adaptive optimizers, tuning the learning\nrate of stochastic gradient methods remains a major roadblock to obtaining good\npractical performance in machine learning. Rather than changing the learning\nrate at each iteration, we propose an approach that automates the most common\nhand-tuning heuristic: use a constant learning rate until \"progress stops,\"\nthen drop. We design an explicit statistical test that determines when the\ndynamics of stochastic gradient descent reach a stationary distribution. This\ntest can be performed easily during training, and when it fires, we decrease\nthe learning rate by a constant multiplicative factor. Our experiments on\nseveral deep learning tasks demonstrate that this statistical adaptive\nstochastic approximation (SASA) method can automatically find good learning\nrate schedules and match the performance of hand-tuned methods using default\nsettings of its parameters. The statistical testing helps to control the\nvariance of this procedure and improves its robustness.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 07:27:48 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Lang", "Hunter", ""], ["Zhang", "Pengchuan", ""], ["Xiao", "Lin", ""]]}, {"id": "1909.09801", "submitter": "Saypraseuth Mounsaveng", "authors": "Saypraseuth Mounsaveng, David Vazquez, Ismail Ben Ayed, Marco\n  Pedersoli", "title": "Adversarial Learning of General Transformations for Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation (DA) is fundamental against overfitting in large\nconvolutional neural networks, especially with a limited training dataset. In\nimages, DA is usually based on heuristic transformations, like geometric or\ncolor transformations. Instead of using predefined transformations, our work\nlearns data augmentation directly from the training data by learning to\ntransform images with an encoder-decoder architecture combined with a spatial\ntransformer network. The transformed images still belong to the same class but\nare new, more complex samples for the classifier. Our experiments show that our\napproach is better than previous generative data augmentation methods, and\ncomparable to predefined transformation methods when training an image\nclassifier.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 09:43:24 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Mounsaveng", "Saypraseuth", ""], ["Vazquez", "David", ""], ["Ayed", "Ismail Ben", ""], ["Pedersoli", "Marco", ""]]}, {"id": "1909.09804", "submitter": "Mengyao Zheng", "authors": "Mengyao Zheng, Dixing Xu, Linshan Jiang, Chaojie Gu, Rui Tan, Peng\n  Cheng", "title": "Challenges of Privacy-Preserving Machine Learning in IoT", "comments": "In First International Workshop on Challenges in Artificial\n  Intelligence and Machine Learning (AIChallengeIoT'19) November 10-13, 2019. 7\n  pages", "journal-ref": null, "doi": "10.1145/3363347.3363357", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) will be a main data generation infrastructure\nfor achieving better system intelligence. However, the extensive data\ncollection and processing in IoT also engender various privacy concerns. This\npaper provides a taxonomy of the existing privacy-preserving machine learning\napproaches developed in the context of cloud computing and discusses the\nchallenges of applying them in the context of IoT. Moreover, we present a\nprivacy-preserving inference approach that runs a lightweight neural network at\nIoT objects to obfuscate the data before transmission and a deep neural network\nin the cloud to classify the obfuscated data. Evaluation based on the MNIST\ndataset shows satisfactory performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 10:12:48 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zheng", "Mengyao", ""], ["Xu", "Dixing", ""], ["Jiang", "Linshan", ""], ["Gu", "Chaojie", ""], ["Tan", "Rui", ""], ["Cheng", "Peng", ""]]}, {"id": "1909.09816", "submitter": "Ioannis Ivrissimtzis", "authors": "Luma Omar and Ioannis Ivrissimtzis", "title": "Using theoretical ROC curves for analysing machine learning binary\n  classifiers", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most binary classifiers work by processing the input to produce a scalar\nresponse and comparing it to a threshold value. The various measures of\nclassifier performance assume, explicitly or implicitly, probability\ndistributions $P_s$ and $P_n$ of the response belonging to either class,\nprobability distributions for the cost of each type of misclassification, and\ncompute a performance score from the expected cost.\n  In machine learning, classifier responses are obtained experimentally and\nperformance scores are computed directly from them, without any assumptions on\n$P_s$ and $P_n$. Here, we argue that the omitted step of estimating theoretical\ndistributions for $P_s$ and $P_n$ can be useful. In a biometric security\nexample, we fit beta distributions to the responses of two classifiers, one\nbased on logistic regression and one on ANNs, and use them to establish a\ncategorisation into a small number of classes with different extremal\nbehaviours at the ends of the ROC curves.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 11:48:19 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Omar", "Luma", ""], ["Ivrissimtzis", "Ioannis", ""]]}, {"id": "1909.09819", "submitter": "Beyrem Khalfaoui", "authors": "Beyrem Khalfaoui, Joseph Boyd and Jean-Philippe Vert", "title": "ASNI: Adaptive Structured Noise Injection for shallow and deep neural\n  networks", "comments": "All code concerning the real data experiments is available at\n  \\url{https://github.com/BeyremKh/ASNI}\\\\", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a regularisation technique in neural network training where unit\nactivations are randomly set to zero with a given probability\n\\emph{independently}. In this work, we propose a generalisation of dropout and\nother multiplicative noise injection schemes for shallow and deep neural\nnetworks, where the random noise applied to different units is not independent\nbut follows a joint distribution that is either fixed or estimated during\ntraining. We provide theoretical insights on why such adaptive structured noise\ninjection (ASNI) may be relevant, and empirically confirm that it helps boost\nthe accuracy of simple feedforward and convolutional neural networks,\ndisentangles the hidden layer representations, and leads to sparser\nrepresentations. Our proposed method is a straightforward modification of the\nclassical dropout and does not require additional computational overhead.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 13:02:56 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Khalfaoui", "Beyrem", ""], ["Boyd", "Joseph", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "1909.09823", "submitter": "Manu Airaksinen", "authors": "Manu Airaksinen, Okko R\\\"as\\\"anen, Elina Il\\'en, Taru H\\\"ayrinen, Anna\n  Kivi, Viviana Marchi, Anastasia Gallen, Sonja Blom, Anni Varhe, Nico\n  Kaartinen, Leena Haataja, Sampsa Vanhatalo", "title": "Automatic Posture and Movement Tracking of Infants with Wearable\n  Movement Sensors", "comments": "17 pages, 8 figures, preprint of manuscript accepted for publication\n  for publication in Nature Scientific Reports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Infants' spontaneous and voluntary movements mirror developmental integrity\nof brain networks since they require coordinated activation of multiple sites\nin the central nervous system. Accordingly, early detection of infants with\natypical motor development holds promise for recognizing those infants who are\nat risk for a wide range of neurodevelopmental disorders (e.g., cerebral palsy,\nautism spectrum disorders). Previously, novel wearable technology has shown\npromise for offering efficient, scalable and automated methods for movement\nassessment in adults. Here, we describe the development of an infant wearable,\na multi-sensor smart jumpsuit that allows mobile accelerometer and gyroscope\ndata collection during movements. Using this suit, we first recorded play\nsessions of 22 typically developing infants of approximately 7 months of age.\nThese data were manually annotated for infant posture and movement based on\nvideo recordings of the sessions, and using a novel annotation scheme\nspecifically designed to assess the overall movement pattern of infants in the\ngiven age group. A machine learning algorithm, based on deep convolutional\nneural networks (CNNs) was then trained for automatic detection of posture and\nmovement classes using the data and annotations. Our experiments show that the\nsetup can be used for quantitative tracking of infant movement activities with\na human equivalent accuracy, i.e., it meets the human inter-rater agreement\nlevels in infant posture and movement classification. We also quantify the\nambiguity of human observers in analyzing infant movements, and propose a\nmethod for utilizing this uncertainty for performance improvements in training\nof the automated classifier. Comparison of different sensor configurations also\nshows that four-limb recording leads to the best performance in posture and\nmovement classification.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 13:37:28 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 13:42:39 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Airaksinen", "Manu", ""], ["R\u00e4s\u00e4nen", "Okko", ""], ["Il\u00e9n", "Elina", ""], ["H\u00e4yrinen", "Taru", ""], ["Kivi", "Anna", ""], ["Marchi", "Viviana", ""], ["Gallen", "Anastasia", ""], ["Blom", "Sonja", ""], ["Varhe", "Anni", ""], ["Kaartinen", "Nico", ""], ["Haataja", "Leena", ""], ["Vanhatalo", "Sampsa", ""]]}, {"id": "1909.09836", "submitter": "Dana Yang", "authors": "Jiaming Xu, Kuang Xu and Dana Yang", "title": "Optimal query complexity for private sequential learning against\n  eavesdropping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of a learner-private sequential learning\nproblem, motivated by the privacy and security concerns due to eavesdropping\nthat arise in practical applications such as pricing and Federated Learning. A\nlearner tries to estimate an unknown scalar value, by sequentially querying an\nexternal database and receiving binary responses; meanwhile, a third-party\nadversary observes the learner's queries but not the responses. The learner's\ngoal is to design a querying strategy with the minimum number of queries\n(optimal query complexity) so that she can accurately estimate the true value,\nwhile the eavesdropping adversary even with the complete knowledge of her\nquerying strategy cannot.\n  We develop new querying strategies and analytical techniques and use them to\nprove tight upper and lower bounds on the optimal query complexity. The bounds\nalmost match across the entire parameter range, substantially improving upon\nexisting results. We thus obtain a complete picture of the optimal query\ncomplexity as a function of the estimation accuracy and the desired levels of\nprivacy. We also extend the results to sequential learning models in higher\ndimensions, and where the binary responses are noisy. Our analysis leverages a\ncrucial insight into the nature of private learning problem, which suggests\nthat the query trajectory of an optimal learner can be divided into distinct\nphases that focus on pure learning versus learning and obfuscation,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 14:39:02 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:28:08 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xu", "Jiaming", ""], ["Xu", "Kuang", ""], ["Yang", "Dana", ""]]}, {"id": "1909.09851", "submitter": "Anru Zhang", "authors": "T. Tony Cai, Anru Zhang, Yuchen Zhou", "title": "Sparse Group Lasso: Optimal Sample Complexity, Convergence Rate, and\n  Statistical Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we study sparse group Lasso for high-dimensional double sparse\nlinear regression, where the parameter of interest is simultaneously\nelement-wise and group-wise sparse. This problem is an important instance of\nthe simultaneously structured model -- an actively studied topic in statistics\nand machine learning. In the noiseless case, we provide matching upper and\nlower bounds on sample complexity for the exact recovery of sparse vectors and\nfor stable estimation of approximately sparse vectors, respectively. In the\nnoisy case, we develop upper and matching minimax lower bounds for estimation\nerror. We also consider the debiased sparse group Lasso and investigate its\nasymptotic property for the purpose of statistical inference. Finally,\nnumerical studies are provided to support the theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 16:17:04 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Cai", "T. Tony", ""], ["Zhang", "Anru", ""], ["Zhou", "Yuchen", ""]]}, {"id": "1909.09852", "submitter": "Ashish Mani Dr.", "authors": "Arit Kumar Bishwas, Ashish Mani, and Vasile Palade", "title": "An Investigation of Quantum Deep Clustering Framework with Quantum Deep\n  SVM & Convolutional Neural Network Feature Extractor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have proposed a deep quantum SVM formulation, and further\ndemonstrated a quantum-clustering framework based on the quantum deep SVM\nformulation, deep convolutional neural networks, and quantum K-Means\nclustering. We have investigated the run time computational complexity of the\nproposed quantum deep clustering framework and compared with the possible\nclassical implementation. Our investigation shows that the proposed quantum\nversion of deep clustering formulation demonstrates a significant performance\ngain (exponential speed up gains in many sections) against the possible\nclassical implementation. The proposed theoretical quantum deep clustering\nframework is also interesting & novel research towards the quantum-classical\nmachine learning formulation to articulate the maximum performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 16:19:43 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bishwas", "Arit Kumar", ""], ["Mani", "Ashish", ""], ["Palade", "Vasile", ""]]}, {"id": "1909.09862", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar and Vladimir Cherkassky", "title": "Single Class Universum-SVM", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the idea of Universum learning [1, 2] to single-class\nlearning problems. We propose Single Class Universum-SVM setting that\nincorporates a priori knowledge (in the form of additional data samples) into\nthe single class estimation problem. These additional data samples or Universum\nbelong to the same application domain as (positive) data samples from a single\nclass (of interest), but they follow a different distribution. Proposed\nmethodology for single class U-SVM is based on the known connection between\nbinary classification and single class learning formulations [3]. Several\nempirical comparisons are presented to illustrate the utility of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 18:00:46 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Dhar", "Sauptik", ""], ["Cherkassky", "Vladimir", ""]]}, {"id": "1909.09877", "submitter": "Yifeng Shi", "authors": "Yifeng Shi, Junier Oliva, Marc Niethammer", "title": "Deep Message Passing on Sets", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern methods for learning over graph input data have shown the fruitfulness\nof accounting for relationships among elements in a collection. However, most\nmethods that learn over set input data use only rudimentary approaches to\nexploit intra-collection relationships. In this work we introduce Deep Message\nPassing on Sets (DMPS), a novel method that incorporates relational learning\nfor sets. DMPS not only connects learning on graphs with learning on sets via\ndeep kernel learning, but it also bridges message passing on sets and\ntraditional diffusion dynamics commonly used in denoising models. Based on\nthese connections, we develop two new blocks for relational learning on sets:\nthe set-denoising block and the set-residual block. The former is motivated by\nthe connection between message passing on general graphs and diffusion-based\ndenoising models, whereas the latter is inspired by the well-known residual\nnetwork. In addition to demonstrating the interpretability of our model by\nlearning the true underlying relational structure experimentally, we also show\nthe effectiveness of our approach on both synthetic and real-world datasets by\nachieving results that are competitive with or outperform the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 19:35:35 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Shi", "Yifeng", ""], ["Oliva", "Junier", ""], ["Niethammer", "Marc", ""]]}, {"id": "1909.09884", "submitter": "Rhiannon Michelmore", "authors": "Rhiannon Michelmore, Matthew Wicker, Luca Laurenti, Luca Cardelli,\n  Yarin Gal, Marta Kwiatkowska", "title": "Uncertainty Quantification with Statistical Guarantees in End-to-End\n  Autonomous Driving Control", "comments": "7 pages, 3 figures, submitted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network controllers for autonomous driving have recently\nbenefited from significant performance improvements, and have begun deployment\nin the real world. Prior to their widespread adoption, safety guarantees are\nneeded on the controller behaviour that properly take account of the\nuncertainty within the model as well as sensor noise. Bayesian neural networks,\nwhich assume a prior over the weights, have been shown capable of producing\nsuch uncertainty measures, but properties surrounding their safety have not yet\nbeen quantified for use in autonomous driving scenarios. In this paper, we\ndevelop a framework based on a state-of-the-art simulator for evaluating\nend-to-end Bayesian controllers. In addition to computing pointwise uncertainty\nmeasures that can be computed in real time and with statistical guarantees, we\nalso provide a method for estimating the probability that, given a scenario,\nthe controller keeps the car safe within a finite horizon. We experimentally\nevaluate the quality of uncertainty computation by several Bayesian inference\nmethods in different scenarios and show how the uncertainty measures can be\ncombined and calibrated for use in collision avoidance. Our results suggest\nthat uncertainty estimates can greatly aid decision making in autonomous\ndriving.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 20:05:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Michelmore", "Rhiannon", ""], ["Wicker", "Matthew", ""], ["Laurenti", "Luca", ""], ["Cardelli", "Luca", ""], ["Gal", "Yarin", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1909.09895", "submitter": "Salar Fattahi", "authors": "Salar Fattahi and Nikolai Matni and Somayeh Sojoudi", "title": "Efficient Learning of Distributed Linear-Quadratic Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a robust approach to design distributed controllers\nfor unknown-but-sparse linear and time-invariant systems. By leveraging modern\ntechniques in distributed controller synthesis and structured linear inverse\nproblems as applied to system identification, we show that near-optimal\ndistributed controllers can be learned with sub-linear sample complexity and\ncomputed with near-linear time complexity, both measured with respect to the\ndimension of the system. In particular, we provide sharp end-to-end guarantees\non the stability and the performance of the designed distributed controller and\nprove that for sparse systems, the number of samples needed to guarantee robust\nand near optimal performance of the designed controller can be significantly\nsmaller than the dimension of the system. Finally, we show that the proposed\noptimization problem can be solved to global optimality with near-linear time\ncomplexity by iteratively solving a series of small quadratic programs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 20:58:45 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 03:11:35 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Fattahi", "Salar", ""], ["Matni", "Nikolai", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1909.09902", "submitter": "Pawel Ladosz", "authors": "Pawel Ladosz, Eseoghene Ben-Iwhiwhu, Jeffery Dick, Yang Hu, Nicholas\n  Ketz, Soheil Kolouri, Jeffrey L. Krichmar, Praveen Pilly, and Andrea\n  Soltoggio", "title": "Deep Reinforcement Learning with Modulated Hebbian plus Q Network\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new neural architecture that combines a modulated\nHebbian network (MOHN) with DQN, which we call modulated Hebbian plus Q network\narchitecture (MOHQA). The hypothesis is that such a combination allows MOHQA to\nsolve difficult partially observable Markov decision process (POMDP) problems\nwhich impair temporal difference (TD)-based RL algorithms such as DQN, as the\nTD error cannot be easily derived from observations. The key idea is to use a\nHebbian network with bio-inspired neural traces in order to bridge temporal\ndelays between actions and rewards when confounding observations and sparse\nrewards result in inaccurate TD errors. In MOHQA, DQN learns low level features\nand control, while the MOHN contributes to the high-level decisions by\nassociating rewards with past states and actions. Thus the proposed\narchitecture combines two modules with significantly different learning\nalgorithms, a Hebbian associative network and a classical DQN pipeline,\nexploiting the advantages of both. Simulations on a set of POMDPs and on the\nMALMO environment show that the proposed algorithm improved DQN's results and\neven outperformed control tests with A2C, QRDQN+LSTM and REINFORCE algorithms\non some POMDPs with confounding stimuli and sparse rewards.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 21:32:47 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:05:14 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 14:29:30 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 20:42:17 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ladosz", "Pawel", ""], ["Ben-Iwhiwhu", "Eseoghene", ""], ["Dick", "Jeffery", ""], ["Hu", "Yang", ""], ["Ketz", "Nicholas", ""], ["Kolouri", "Soheil", ""], ["Krichmar", "Jeffrey L.", ""], ["Pilly", "Praveen", ""], ["Soltoggio", "Andrea", ""]]}, {"id": "1909.09929", "submitter": "Prasanna Balaprakash", "authors": "Shashi M. Aithal and Prasanna Balaprakash", "title": "MaLTESE: Large-Scale Simulation-Driven Machine Learning for Transient\n  Driving Cycles", "comments": null, "journal-ref": "In M. Weiland, G. Juckeland, C. Trinitis, and P. Sadayappan,\n  editors, High Performance Computing, pages 186--205, Cham, 2019. Springer\n  International Publishing", "doi": "10.1007/978-3-030-20656-7_10", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal engine operation during a transient driving cycle is the key to\nachieving greater fuel economy, engine efficiency, and reduced emissions. In\norder to achieve continuously optimal engine operation, engine calibration\nmethods use a combination of static correlations obtained from dynamometer\ntests for steady-state operating points and road and/or track performance data.\nAs the parameter space of control variables, design variable constraints, and\nobjective functions increases, the cost and duration for optimal calibration\nbecome prohibitively large. In order to reduce the number of dynamometer tests\nrequired for calibrating modern engines, a large-scale simulation-driven\nmachine learning approach is presented in this work. A parallel, fast, robust,\nphysics-based reduced-order engine simulator is used to obtain performance and\nemission characteristics of engines over a wide range of control parameters\nunder various transient driving conditions (drive cycles). We scale the\nsimulation up to 3,906 nodes of the Theta supercomputer at the Argonne\nLeadership Computing Facility to generate data required to train a machine\nlearning model. The trained model is then used to predict various engine\nparameters of interest. Our results show that a deep-neural-network-based\nsurrogate model achieves high accuracy for various engine parameters such as\nexhaust temperature, exhaust pressure, nitric oxide, and engine torque. Once\ntrained, the deep-neural-network-based surrogate model is fast for inference:\nit requires about 16 micro sec for predicting the engine performance and\nemissions for a single design configuration compared with about 0.5 s per\nconfiguration with the engine simulator. Moreover, we demonstrate that transfer\nlearning and retraining can be leveraged to incrementally retrain the surrogate\nmodel to cope with new configurations that fall outside the training data\nspace.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 01:58:20 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Aithal", "Shashi M.", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1909.09969", "submitter": "Shira Ozeri", "authors": "Lee-Ad Gottlieb, Shira Ozeri", "title": "Classification in asymmetric spaces via sample compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the rigorous study of classification in quasi-metric spaces.\nThese are point sets endowed with a distance function that is non-negative and\nalso satisfies the triangle inequality, but is asymmetric. We develop and\nrefine a learning algorithm for quasi-metrics based on sample compression and\nnearest neighbor, and prove that it has favorable statistical properties.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 09:07:21 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Ozeri", "Shira", ""]]}, {"id": "1909.09978", "submitter": "Joonas H\\\"am\\\"al\\\"ainen", "authors": "Joonas H\\\"am\\\"al\\\"ainen, Alisson S. C. Alencar, Tommi K\\\"arkk\\\"ainen,\n  C\\'esar L. C. Mattos, Amauri H. Souza J\\'unior, Jo\\~ao P. P. Gomes", "title": "Minimal Learning Machine: Theoretical Results and Clustering-Based\n  Reference Point Selection", "comments": "29 pages, Accepted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Minimal Learning Machine (MLM) is a nonlinear supervised approach based\non learning a linear mapping between distance matrices computed in the input\nand output data spaces, where distances are calculated using a subset of points\ncalled reference points. Its simple formulation has attracted several recent\nworks on extensions and applications. In this paper, we aim to address some\nopen questions related to the MLM. First, we detail theoretical aspects that\nassure the interpolation and universal approximation capabilities of the MLM,\nwhich were previously only empirically verified. Second, we identify the task\nof selecting reference points as having major importance for the MLM's\ngeneralization capability. Several clustering-based methods for reference point\nselection in regression scenarios are then proposed and analyzed. Based on an\nextensive empirical evaluation, we conclude that the evaluated methods are both\nscalable and useful. Specifically, for a small number of reference points, the\nclustering-based methods outperformed the standard random selection of the\noriginal MLM formulation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 10:52:30 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 20:59:01 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Joonas", ""], ["Alencar", "Alisson S. C.", ""], ["K\u00e4rkk\u00e4inen", "Tommi", ""], ["Mattos", "C\u00e9sar L. C.", ""], ["J\u00fanior", "Amauri H. Souza", ""], ["Gomes", "Jo\u00e3o P. P.", ""]]}, {"id": "1909.10008", "submitter": "Jo\\~ao Ribeiro", "authors": "Jo\\~ao Ribeiro, Francisco S. Melo and Jo\\~ao Dias", "title": "Multi-task Learning and Catastrophic Forgetting in Continual\n  Reinforcement Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate two hypothesis regarding the use of deep\nreinforcement learning in multiple tasks. The first hypothesis is driven by the\nquestion of whether a deep reinforcement learning algorithm, trained on two\nsimilar tasks, is able to outperform two single-task, individually trained\nalgorithms, by more efficiently learning a new, similar task, that none of the\nthree algorithms has encountered before. The second hypothesis is driven by the\nquestion of whether the same multi-task deep RL algorithm, trained on two\nsimilar tasks and augmented with elastic weight consolidation (EWC), is able to\nretain similar performance on the new task, as a similar algorithm without EWC,\nwhilst being able to overcome catastrophic forgetting in the two previous\ntasks. We show that a multi-task Asynchronous Advantage Actor-Critic (GA3C)\nalgorithm, trained on Space Invaders and Demon Attack, is in fact able to\noutperform two single-tasks GA3C versions, trained individually for each\nsingle-task, when evaluated on a new, third task, namely, Phoenix. We also show\nthat, when training two trained multi-task GA3C algorithms on the third task,\nif one is augmented with EWC, it is not only able to achieve similar\nperformance on the new task, but also capable of overcoming a substantial\namount of catastrophic forgetting on the two previous tasks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 14:00:29 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Ribeiro", "Jo\u00e3o", ""], ["Melo", "Francisco S.", ""], ["Dias", "Jo\u00e3o", ""]]}, {"id": "1909.10023", "submitter": "Guoliang Dong", "authors": "Guoliang Dong, Jingyi Wang, Jun Sun, Yang Zhang, Xinyu Wang, Ting Dai,\n  Jin Song Dong, Xingen Wang", "title": "Towards Interpreting Recurrent Neural Networks through Probabilistic\n  Abstraction", "comments": "Accepted by ASE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are becoming a popular tool for solving many real-world\nproblems such as object recognition and machine translation, thanks to its\nexceptional performance as an end-to-end solution. However, neural networks are\ncomplex black-box models, which hinders humans from interpreting and\nconsequently trusting them in making critical decisions. Towards interpreting\nneural networks, several approaches have been proposed to extract simple\ndeterministic models from neural networks. The results are not encouraging\n(e.g., low accuracy and limited scalability), fundamentally due to the limited\nexpressiveness of such simple models.\n  In this work, we propose an approach to extract probabilistic automata for\ninterpreting an important class of neural networks, i.e., recurrent neural\nnetworks. Our work distinguishes itself from existing approaches in two\nimportant ways. One is that probability is used to compensate for the loss of\nexpressiveness. This is inspired by the observation that human reasoning is\noften `probabilistic'. The other is that we adaptively identify the right level\nof abstraction so that a simple model is extracted in a request-specific way.\nWe conduct experiments on several real-world datasets using state-of-the-art\narchitectures including GRU and LSTM. The result shows that our approach\nsignificantly improves existing approaches in terms of accuracy or scalability.\nLastly, we demonstrate the usefulness of the extracted models through detecting\nadversarial texts.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 15:11:15 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 03:47:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Dong", "Guoliang", ""], ["Wang", "Jingyi", ""], ["Sun", "Jun", ""], ["Zhang", "Yang", ""], ["Wang", "Xinyu", ""], ["Dai", "Ting", ""], ["Dong", "Jin Song", ""], ["Wang", "Xingen", ""]]}, {"id": "1909.10072", "submitter": "Shih-Kang Chao", "authors": "Shih-Kang Chao and Guang Cheng", "title": "A generalization of regularized dual averaging and its dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excessive computational cost for learning large data and streaming data can\nbe alleviated by using stochastic algorithms, such as stochastic gradient\ndescent and its variants. Recent advances improve stochastic algorithms on\nconvergence speed, adaptivity and structural awareness. However, distributional\naspects of these new algorithms are poorly understood, especially for\nstructured parameters. To develop statistical inference in this case, we\npropose a class of generalized regularized dual averaging (gRDA) algorithms\nwith constant step size, which improves RDA (Xiao, 2010; Flammarion and Bach,\n2017). Weak convergence of gRDA trajectories are studied, and as a consequence,\nfor the first time in the literature, the asymptotic distributions for online\nl1 penalized problems become available. These general results apply to both\nconvex and non-convex differentiable loss functions, and in particular, recover\nthe existing regret bound for convex losses (Nemirovski et al., 2009). As\nimportant applications, statistical inferential theory on online sparse linear\nregression and online sparse principal component analysis are developed, and\nare supported by extensive numerical analysis. Interestingly, when gRDA is\nproperly tuned, support recovery and central limiting distribution (with mean\nzero) hold simultaneously in the online setting, which is in contrast with the\nbiased central limiting distribution of batch Lasso (Knight and Fu, 2000).\nTechnical devices, including weak convergence of stochastic mirror descent, are\ndeveloped as by-products with independent interest. Preliminary empirical\nanalysis of modern image data shows that learning very sparse deep neural\nnetworks by gRDA does not necessarily sacrifice testing accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 19:12:26 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Chao", "Shih-Kang", ""], ["Cheng", "Guang", ""]]}, {"id": "1909.10086", "submitter": "Saurabh Verma", "authors": "Saurabh Verma, Zhi-Li Zhang", "title": "Learning Universal Graph Neural Network Embeddings With Aid Of Transfer\n  Learning", "comments": "Previous Paper Title: Deep Universal Graph Embedding Neural Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning powerful data embeddings has become a center piece in machine\nlearning, especially in natural language processing and computer vision\ndomains. The crux of these embeddings is that they are pretrained on huge\ncorpus of data in a unsupervised fashion, sometimes aided with transfer\nlearning. However currently in the graph learning domain, embeddings learned\nthrough existing graph neural networks (GNNs) are task dependent and thus\ncannot be shared across different datasets. In this paper, we present a first\npowerful and theoretically guaranteed graph neural network that is designed to\nlearn task-independent graph embeddings, thereafter referred to as deep\nuniversal graph embedding (DUGNN). Our DUGNN model incorporates a novel graph\nneural network (as a universal graph encoder) and leverages rich Graph Kernels\n(as a multi-task graph decoder) for both unsupervised learning and\n(task-specific) adaptive supervised learning. By learning task-independent\ngraph embeddings across diverse datasets, DUGNN also reaps the benefits of\ntransfer learning. Through extensive experiments and ablation studies, we show\nthat the proposed DUGNN model consistently outperforms both the existing\nstate-of-art GNN models and Graph Kernels by an increased accuracy of 3% - 8%\non graph classification benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 20:21:15 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 02:11:12 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 05:06:26 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Verma", "Saurabh", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "1909.10145", "submitter": "Zhen Li", "authors": "Xuhui Meng, Zhen Li, Dongkun Zhang and George Em Karniadakis", "title": "PPINN: Parareal Physics-Informed Neural Network for time-dependent PDEs", "comments": "17 pages, 7 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.cma.2020.113250", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks (PINNs) encode physical conservation laws\nand prior physical knowledge into the neural networks, ensuring the correct\nphysics is represented accurately while alleviating the need for supervised\nlearning to a great degree. While effective for relatively short-term time\nintegration, when long time integration of the time-dependent PDEs is sought,\nthe time-space domain may become arbitrarily large and hence training of the\nneural network may become prohibitively expensive. To this end, we develop a\nparareal physics-informed neural network (PPINN), hence decomposing a long-time\nproblem into many independent short-time problems supervised by an\ninexpensive/fast coarse-grained (CG) solver. In particular, the serial CG\nsolver is designed to provide approximate predictions of the solution at\ndiscrete times, while initiate many fine PINNs simultaneously to correct the\nsolution iteratively. There is a two-fold benefit from training PINNs with\nsmall-data sets rather than working on a large-data set directly, i.e.,\ntraining of individual PINNs with small-data is much faster, while training the\nfine PINNs can be readily parallelized. Consequently, compared to the original\nPINN approach, the proposed PPINN approach may achieve a significant speedup\nfor long-time integration of PDEs, assuming that the CG solver is fast and can\nprovide reasonable predictions of the solution, hence aiding the PPINN solution\nto converge in just a few iterations. To investigate the PPINN performance on\nsolving time-dependent PDEs, we first apply the PPINN to solve the Burgers\nequation, and subsequently we apply the PPINN to solve a two-dimensional\nnonlinear diffusion-reaction equation. Our results demonstrate that PPINNs\nconverge in a couple of iterations with significant speed-ups proportional to\nthe number of time-subdomains employed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 03:53:53 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Meng", "Xuhui", ""], ["Li", "Zhen", ""], ["Zhang", "Dongkun", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1909.10155", "submitter": "Ananya Kumar", "authors": "Ananya Kumar, Percy Liang, Tengyu Ma", "title": "Verified Uncertainty Calibration", "comments": "Accepted as a spotlight to NeurIPS 2019, updated to include\n  experiments for ECE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications such as weather forecasting and personalized medicine demand\nmodels that output calibrated probability estimates---those representative of\nthe true likelihood of a prediction. Most models are not calibrated out of the\nbox but are recalibrated by post-processing model outputs. We find in this work\nthat popular recalibration methods like Platt scaling and temperature scaling\nare (i) less calibrated than reported, and (ii) current techniques cannot\nestimate how miscalibrated they are. An alternative method, histogram binning,\nhas measurable calibration error but is sample inefficient---it requires\n$O(B/\\epsilon^2)$ samples, compared to $O(1/\\epsilon^2)$ for scaling methods,\nwhere $B$ is the number of distinct probabilities the model can output. To get\nthe best of both worlds, we introduce the scaling-binning calibrator, which\nfirst fits a parametric function to reduce variance and then bins the function\nvalues to actually ensure calibration. This requires only $O(1/\\epsilon^2 + B)$\nsamples. Next, we show that we can estimate a model's calibration error more\naccurately using an estimator from the meteorological community---or\nequivalently measure its calibration error with fewer samples ($O(\\sqrt{B})$\ninstead of $O(B)$). We validate our approach with multiclass calibration\nexperiments on CIFAR-10 and ImageNet, where we obtain a 35% lower calibration\nerror than histogram binning and, unlike scaling methods, guarantees on true\ncalibration. In these experiments, we also estimate the calibration error and\nECE more accurately than the commonly used plugin estimators. We implement all\nthese methods in a Python library:\nhttps://pypi.org/project/uncertainty-calibration\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 04:41:42 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 18:59:12 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Kumar", "Ananya", ""], ["Liang", "Percy", ""], ["Ma", "Tengyu", ""]]}, {"id": "1909.10221", "submitter": "Matthew Thorpe", "authors": "Oliver M. Crook, Tim Hurst, Carola-Bibiane Sch\\\"onlieb, Matthew\n  Thorpe, Konstantinos C. Zygalakis", "title": "PDE-Inspired Algorithms for Semi-Supervised Learning on Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a data set and a subset of labels the problem of semi-supervised\nlearning on point clouds is to extend the labels to the entire data set. In\nthis paper we extend the labels by minimising the constrained discrete\n$p$-Dirichlet energy. Under suitable conditions the discrete problem can be\nconnected, in the large data limit, with the minimiser of a weighted continuum\n$p$-Dirichlet energy with the same constraints. We take advantage of this\nconnection by designing numerical schemes that first estimate the density of\nthe data and then apply PDE methods, such as pseudo-spectral methods, to solve\nthe corresponding Euler-Lagrange equation. We prove that our scheme is\nconsistent in the large data limit for two methods of density estimation:\nkernel density estimation and spline kernel density estimation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 08:44:09 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Crook", "Oliver M.", ""], ["Hurst", "Tim", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""], ["Thorpe", "Matthew", ""], ["Zygalakis", "Konstantinos C.", ""]]}, {"id": "1909.10228", "submitter": "Zhigang Yao", "authors": "Zhigang Yao and Yuqing Xia", "title": "Manifold Fitting under Unbounded Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an emerging trend in non-Euclidean dimension reduction of\naiming to recover a low dimensional structure, namely a manifold, underlying\nthe high dimensional data. Recovering the manifold requires the noise to be of\ncertain concentration. Existing methods address this problem by constructing an\noutput manifold based on the tangent space estimation at each sample point.\nAlthough theoretical convergence for these methods is guaranteed, either the\nsamples are noiseless or the noise is bounded. However, if the noise is\nunbounded, which is a common scenario, the tangent space estimation of the\nnoisy samples will be blurred, thereby breaking the manifold fitting. In this\npaper, we introduce a new manifold-fitting method, by which the output manifold\nis constructed by directly estimating the tangent spaces at the projected\npoints on the underlying manifold, rather than at the sample points, to\ndecrease the error caused by the noise. Our new method provides theoretical\nconvergence, in terms of the upper bound on the Hausdorff distance between the\noutput and underlying manifold and the lower bound on the reach of the output\nmanifold, when the noise is unbounded. Numerical simulations are provided to\nvalidate our theoretical findings and demonstrate the advantages of our method\nover other relevant methods. Finally, our method is applied to real data\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 08:55:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Yao", "Zhigang", ""], ["Xia", "Yuqing", ""]]}, {"id": "1909.10233", "submitter": "Thierry Roncalli", "authors": "Sarah Perrin, Thierry Roncalli", "title": "Machine Learning Optimization Algorithms & Portfolio Allocation", "comments": "66 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio optimization emerged with the seminal paper of Markowitz (1952).\nThe original mean-variance framework is appealing because it is very efficient\nfrom a computational point of view. However, it also has one well-established\nfailing since it can lead to portfolios that are not optimal from a financial\npoint of view. Nevertheless, very few models have succeeded in providing a real\nalternative solution to the Markowitz model. The main reason lies in the fact\nthat most academic portfolio optimization models are intractable in real life\nalthough they present solid theoretical properties. By intractable we mean that\nthey can be implemented for an investment universe with a small number of\nassets using a lot of computational resources and skills, but they are unable\nto manage a universe with dozens or hundreds of assets. However, the emergence\nand the rapid development of robo-advisors means that we need to rethink\nportfolio optimization and go beyond the traditional mean-variance optimization\napproach. Another industry has faced similar issues concerning large-scale\noptimization problems. Machine learning has long been associated with linear\nand logistic regression models. Again, the reason was the inability of\noptimization algorithms to solve high-dimensional industrial problems.\nNevertheless, the end of the 1990s marked an important turning point with the\ndevelopment and the rediscovery of several methods that have since produced\nimpressive results. The goal of this paper is to show how portfolio allocation\ncan benefit from the development of these large-scale optimization algorithms.\nNot all of these algorithms are useful in our case, but four of them are\nessential when solving complex portfolio optimization problems. These four\nalgorithms are the coordinate descent, the alternating direction method of\nmultipliers, the proximal gradient method and the Dykstra's algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:09:12 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Perrin", "Sarah", ""], ["Roncalli", "Thierry", ""]]}, {"id": "1909.10238", "submitter": "Tao Sun", "authors": "Tao Sun, Dongsheng Li", "title": "Decentralized Markov Chain Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized stochastic gradient method emerges as a promising solution for\nsolving large-scale machine learning problems. This paper studies the\ndecentralized Markov chain gradient descent (DMGD) algorithm - a variant of the\ndecentralized stochastic gradient methods where the random samples are taken\nalong the trajectory of a Markov chain. This setting is well-motivated when\nobtaining independent samples is costly or impossible, which excludes the use\nof the traditional stochastic gradient algorithms. Specifically, we consider\nthe first- and zeroth-order versions of decentralized Markov chain gradient\ndescent over a connected network, where each node only communicates with its\nneighbors about intermediate results. The nonergodic convergence and the\nergodic convergence rate of the proposed algorithms have been rigorously\nestablished, and their critical dependences on the network topology and the\nmixing time of Markov chain have been highlighted. The numerical tests further\nvalidate the sample efficiency of our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:20:53 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 13:15:01 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Sun", "Tao", ""], ["Li", "Dongsheng", ""]]}, {"id": "1909.10247", "submitter": "Robert MacKay", "authors": "Robert S. MacKay", "title": "Inference of modes for linear stochastic processes", "comments": "Expanded in several places in response to reading by an electrical\n  engineer", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For dynamical systems that can be modelled as asymptotically stable linear\nsystems forced by Gaussian noise, this paper develops methods to infer or\nestimate their modes from observations in real time. The modes can be real or\ncomplex. For a real mode, we wish to infer its damping rate and mode shape. For\na complex mode, we wish to infer its frequency, damping rate and (complex) mode\nshape. Their amplitudes and correlations are encoded in a mode covariance\nmatrix. The work is motivated and illustrated by the problem of detection of\noscillations in power flow in AC electrical networks. Suggestions of other\napplications are given.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:43:05 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 16:46:47 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["MacKay", "Robert S.", ""]]}, {"id": "1909.10248", "submitter": "Yaping Zheng", "authors": "Yaping Zheng, Shiyi Chen, Xinni Zhang, Xiaofeng Zhang, Xiaofei Yang,\n  Di Wang", "title": "Heterogeneous-Temporal Graph Convolutional Networks: Make the Community\n  Detection Much Better", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection has long been an important yet challenging task to\nanalyze complex networks with a focus on detecting topological structures of\ngraph data. Essentially, real-world graph data contains various features, node\nand edge types which dynamically vary over time, and this invalidates most\nexisting community detection approaches. To cope with these issues, this paper\nproposes the heterogeneous-temporal graph convolutional networks (HTGCN) to\ndetect communities from hetergeneous and temporal graphs. Particularly, we\nfirst design a heterogeneous GCN component to acquire feature representations\nfor each heterogeneous graph at each time step. Then, a residual compressed\naggregation component is proposed to represent \"dynamic\" features for \"varying\"\ncommunities, which are then aggregated with \"static\" features extracted from\ncurrent graph. Extensive experiments are evaluated on two real-world datasets,\ni.e., DBLP and IMDB. The promising results demonstrate that the proposed HTGCN\nis superior to both benchmark and the state-of-the-art approaches, e.g., GCN,\nGAT, GNN, LGNN, HAN and STAR, with respect to a number of evaluation criteria.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:45:08 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 11:12:02 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Zheng", "Yaping", ""], ["Chen", "Shiyi", ""], ["Zhang", "Xinni", ""], ["Zhang", "Xiaofeng", ""], ["Yang", "Xiaofei", ""], ["Wang", "Di", ""]]}, {"id": "1909.10333", "submitter": "Debleena Sengupta", "authors": "Debleena Sengupta", "title": "Deep learning architectures for automated image segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation is widely used in a variety of computer vision tasks, such\nas object localization and recognition, boundary detection, and medical\nimaging. This thesis proposes deep learning architectures to improve automatic\nobject localization and boundary delineation for salient object segmentation in\nnatural images and for 2D medical image segmentation. First, we propose and\nevaluate a novel dilated dense encoder-decoder architecture with a custom\ndilated spatial pyramid pooling block to accurately localize and delineate\nboundaries for salient object segmentation. The dilation offers better spatial\nunderstanding and the dense connectivity preserves features learned at\nshallower levels of the network for better localization. Tested on three\npublicly available datasets, our architecture outperforms the state-of-the-art\nfor one and is very competitive on the other two. Second, we propose and\nevaluate a custom 2D dilated dense UNet architecture for accurate lesion\nlocalization and segmentation in medical images. This architecture can be\nutilized as a stand-alone segmentation framework or used as a rich feature\nextracting backbone to aid other models in medical image segmentation. Our\narchitecture outperforms all baseline models for accurate lesion localization\nand segmentation on a new dataset. We furthermore explore the main\nconsiderations that should be taken into account for 3D medical image\nsegmentation, among them preprocessing techniques and specialized loss\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 19:46:30 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Sengupta", "Debleena", ""]]}, {"id": "1909.10340", "submitter": "Gideon Kowadlo", "authors": "Gideon Kowadlo, Abdelrahman Ahmed, and David Rawlinson", "title": "AHA! an 'Artificial Hippocampal Algorithm' for Episodic Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of ML research concerns slow, statistical learning of i.i.d.\nsamples from large, labelled datasets. Animals do not learn this way. An\nenviable characteristic of animal learning is `episodic' learning - the ability\nto memorise a specific experience as a composition of existing concepts, after\njust one experience, without provided labels. The new knowledge can then be\nused to distinguish between similar experiences, to generalise between classes,\nand to selectively consolidate to long-term memory. The Hippocampus is known to\nbe vital to these abilities. AHA is a biologically-plausible computational\nmodel of the Hippocampus. Unlike most machine learning models, AHA is trained\nwithout external labels and uses only local credit assignment. We demonstrate\nAHA in a superset of the Omniglot one-shot classification benchmark. The\nextended benchmark covers a wider range of known hippocampal functions by\ntesting pattern separation, completion, and recall of original input. These\nfunctions are all performed within a single configuration of the computational\nmodel. Despite these constraints, image classification results are comparable\nto conventional deep convolutional ANNs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 12:49:47 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 15:47:27 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 06:00:38 GMT"}, {"version": "v4", "created": "Fri, 8 Nov 2019 01:56:18 GMT"}, {"version": "v5", "created": "Wed, 25 Mar 2020 04:08:34 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Kowadlo", "Gideon", ""], ["Ahmed", "Abdelrahman", ""], ["Rawlinson", "David", ""]]}, {"id": "1909.10367", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Carolyn Augusta, Graham W. Taylor", "title": "Learning Temporal Attention in Dynamic Graphs with Bilinear Interactions", "comments": "15 pages, source code is available at\n  https://github.com/uoguelph-mlrg/LDG", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about graphs evolving over time is a challenging concept in many\ndomains, such as bioinformatics, physics, and social networks. We consider a\ncommon case in which edges can be short term interactions (e.g., messaging) or\nlong term structural connections (e.g., friendship). In practice, long term\nedges are often specified by humans. Human-specified edges can be both\nexpensive to produce and suboptimal for the downstream task. To alleviate these\nissues, we propose a model based on temporal point processes and variational\nautoencoders that learns to infer temporal attention between nodes by observing\nnode communication. As temporal attention drives between-node feature\npropagation, using the dynamics of node interactions to learn this key\ncomponent provides more flexibility while simultaneously avoiding issues\nassociated with human-specified edges. We also propose a bilinear\ntransformation layer for pairs of node features instead of concatenation,\ntypically used in prior work, and demonstrate its superior performance in all\ncases. In experiments on two datasets in the dynamic link prediction task, our\nmodel often outperforms the baseline model that requires a human-specified\ngraph. Moreover, our learned attention is semantically interpretable and infers\nconnections similar to actual graphs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 13:54:10 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:08:38 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Knyazev", "Boris", ""], ["Augusta", "Carolyn", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1909.10432", "submitter": "Mert Al", "authors": "Mert Al, Zejiang Hou, Sun-Yuan Kung", "title": "Scalable Kernel Learning via the Discriminant Information", "comments": "Published in IEEE 2020 International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel approximation methods create explicit, low-dimensional kernel feature\nmaps to deal with the high computational and memory complexity of standard\ntechniques. This work studies a supervised kernel learning methodology to\noptimize such mappings. We utilize the Discriminant Information criterion, a\nmeasure of class separability with a strong connection to Discriminant\nAnalysis. By generalizing this measure to cover a wider range of kernel maps\nand learning settings, we develop scalable methods to learn kernel features\nwith high discriminant power. Experimental results on several datasets showcase\nthat our techniques can improve optimization and generalization performances\nover state of the art kernel learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 15:43:12 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:41:24 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Al", "Mert", ""], ["Hou", "Zejiang", ""], ["Kung", "Sun-Yuan", ""]]}, {"id": "1909.10447", "submitter": "Pranava Madhyastha", "authors": "Pranava Madhyastha, Rishabh Jain", "title": "On Model Stability as a Function of Random Seed", "comments": "v1; Accepted for publication at CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on quantifying model stability as a function of\nrandom seed by investigating the effects of the induced randomness on model\nperformance and the robustness of the model in general. We specifically perform\na controlled study on the effect of random seeds on the behaviour of attention,\ngradient-based and surrogate model based (LIME) interpretations. Our analysis\nsuggests that random seeds can adversely affect the consistency of models\nresulting in counterfactual interpretations. We propose a technique called\nAggressive Stochastic Weight Averaging (ASWA)and an extension called\nNorm-filtered Aggressive Stochastic Weight Averaging (NASWA) which improves the\nstability of models over random seeds. With our ASWA and NASWA based\noptimization, we are able to improve the robustness of the original model, on\naverage reducing the standard deviation of the model's performance by 72%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:00:06 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Madhyastha", "Pranava", ""], ["Jain", "Rishabh", ""]]}, {"id": "1909.10449", "submitter": "Yuren Zhong", "authors": "Yuren Zhong, Aniket Anand Deshmukh and Clayton Scott", "title": "PAC Reinforcement Learning without Real-World Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies reinforcement learning in the Sim-to-Real setting, in which\nan agent is first trained on a number of simulators before being deployed in\nthe real world, with the aim of decreasing the real-world sample complexity\nrequirement. Using a dynamic model known as a rich observation Markov decision\nprocess (ROMDP), we formulate a theoretical framework for Sim-to-Real in the\nsituation where feedback in the real world is not available. We establish\nreal-world sample complexity guarantees that are smaller than what is currently\nknown for directly (i.e., without access to simulators) learning a ROMDP with\nfeedback.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:07:37 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 14:51:35 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 17:33:50 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zhong", "Yuren", ""], ["Deshmukh", "Aniket Anand", ""], ["Scott", "Clayton", ""]]}, {"id": "1909.10455", "submitter": "Daniel L\\'evy", "authors": "Daniel Levy and John C. Duchi", "title": "Necessary and Sufficient Geometries for Gradient Methods", "comments": "23 pages. To appear at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact of the constraint set and gradient geometry on the\nconvergence of online and stochastic methods for convex optimization, providing\na characterization of the geometries for which stochastic gradient and adaptive\ngradient methods are (minimax) optimal. In particular, we show that when the\nconstraint set is quadratically convex, diagonally pre-conditioned stochastic\ngradient methods are minimax optimal. We further provide a converse that shows\nthat when the constraints are not quadratically convex---for example, any\n$\\ell_p$-ball for $p < 2$---the methods are far from optimal. Based on this, we\ncan provide concrete recommendations for when one should use adaptive, mirror\nor stochastic gradient methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:14:26 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 05:49:48 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Levy", "Daniel", ""], ["Duchi", "John C.", ""]]}, {"id": "1909.10461", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Terrence W.K. Mak, Pascal Van Hentenryck", "title": "Predicting AC Optimal Power Flows: Combining Deep Learning and\n  Lagrangian Dual Methods", "comments": "A version of this paper appears in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Optimal Power Flow (OPF) problem is a fundamental building block for the\noptimization of electrical power systems. It is nonlinear and nonconvex and\ncomputes the generator setpoints for power and voltage, given a set of load\ndemands. It is often needed to be solved repeatedly under various conditions,\neither in real-time or in large-scale studies. This need is further exacerbated\nby the increasing stochasticity of power systems due to renewable energy\nsources in front and behind the meter. To address these challenges, this paper\npresents a deep learning approach to the OPF. The learning model exploits the\ninformation available in the prior states of the system (which is commonly\navailable in practical applications), as well as a dual Lagrangian method to\nsatisfy the physical and engineering constraints present in the OPF. The\nproposed model is evaluated on a large collection of realistic power systems.\nThe experimental results show that its predictions are highly accurate with\naverage errors as low as 0.2%. Additionally, the proposed approach is shown to\nimprove the accuracy of widely adopted OPF linear DC approximation by at least\ntwo orders of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 00:39:17 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 15:25:44 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Mak", "Terrence W. K.", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1909.10467", "submitter": "Hassan Rafique", "authors": "Hassan Rafique, Tong Wang, Qihang Lin", "title": "Model-Agnostic Linear Competitors -- When Interpretable Models Compete\n  and Collaborate with Black-Box Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by an increasing need for model interpretability, interpretable models\nhave become strong competitors for black-box models in many real applications.\nIn this paper, we propose a novel type of model where interpretable models\ncompete and collaborate with black-box models. We present the Model-Agnostic\nLinear Competitors (MALC) for partially interpretable classification. MALC is a\nhybrid model that uses linear models to locally substitute any black-box model,\ncapturing subspaces that are most likely to be in a class while leaving the\nrest of the data to the black-box. MALC brings together the interpretable power\nof linear models and good predictive performance of a black-box model. We\nformulate the training of a MALC model as a convex optimization. The predictive\naccuracy and transparency (defined as the percentage of data captured by the\nlinear models) balance through a carefully designed objective function and the\noptimization problem is solved with the accelerated proximal gradient method.\nExperiments show that MALC can effectively trade prediction accuracy for\ntransparency and provide an efficient frontier that spans the entire spectrum\nof transparency.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:41:57 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Rafique", "Hassan", ""], ["Wang", "Tong", ""], ["Lin", "Qihang", ""]]}, {"id": "1909.10470", "submitter": "Vishvak Murahari", "authors": "Vishvak Murahari, Prithvijit Chattopadhyay, Dhruv Batra, Devi Parikh,\n  Abhishek Das", "title": "Improving Generative Visual Dialog by Answering Diverse Questions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on training generative Visual Dialog models with reinforcement\nlearning(Das et al.) has explored a Qbot-Abot image-guessing game and shown\nthat this 'self-talk' approach can lead to improved performance at the\ndownstream dialog-conditioned image-guessing task. However, this improvement\nsaturates and starts degrading after a few rounds of interaction, and does not\nlead to a better Visual Dialog model. We find that this is due in part to\nrepeated interactions between Qbot and Abot during self-talk, which are not\ninformative with respect to the image. To improve this, we devise a simple\nauxiliary objective that incentivizes Qbot to ask diverse questions, thus\nreducing repetitions and in turn enabling Abot to explore a larger state space\nduring RL ie. be exposed to more visual concepts to talk about, and varied\nquestions to answer. We evaluate our approach via a host of automatic metrics\nand human studies, and demonstrate that it leads to better dialog, ie. dialog\nthat is more diverse (ie. less repetitive), consistent (ie. has fewer\nconflicting exchanges), fluent (ie. more human-like),and detailed, while still\nbeing comparably image-relevant as prior work and ablations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:47:15 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 03:01:48 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Murahari", "Vishvak", ""], ["Chattopadhyay", "Prithvijit", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Das", "Abhishek", ""]]}, {"id": "1909.10549", "submitter": "Gregory Farquhar", "authors": "Gregory Farquhar, Shimon Whiteson, Jakob Foerster", "title": "Loaded DiCE: Trading off Bias and Variance in Any-Order Score Function\n  Estimators for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based methods for optimisation of objectives in stochastic settings\nwith unknown or intractable dynamics require estimators of derivatives. We\nderive an objective that, under automatic differentiation, produces\nlow-variance unbiased estimators of derivatives at any order. Our objective is\ncompatible with arbitrary advantage estimators, which allows the control of the\nbias and variance of any-order derivatives when using function approximation.\nFurthermore, we propose a method to trade off bias and variance of higher order\nderivatives by discounting the impact of more distant causal dependencies. We\ndemonstrate the correctness and utility of our objective in analytically\ntractable MDPs and in meta-reinforcement-learning for continuous control.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:13:50 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Farquhar", "Gregory", ""], ["Whiteson", "Shimon", ""], ["Foerster", "Jakob", ""]]}, {"id": "1909.10582", "submitter": "Vincent Kurtz", "authors": "Vince Kurtz, Hai Lin", "title": "Kalman Filtering with Gaussian Processes Measurement Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world measurement noise in applications like robotics is often\ncorrelated in time, but we typically assume i.i.d. Gaussian noise for\nfiltering. We propose general Gaussian Processes as a non-parametric model for\ncorrelated measurement noise that is flexible enough to accurately reflect\ncorrelation in time, yet simple enough to enable efficient computation. We show\nthat this model accurately reflects the measurement noise resulting from\nvision-based Simultaneous Localization and Mapping (SLAM), and argue that it\nprovides a flexible means of modeling measurement noise for a wide variety of\nsensor systems and perception algorithms. We then extend existing results for\nKalman filtering with autoregressive processes to more general Gaussian\nProcesses, and demonstrate the improved performance of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 19:19:11 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Kurtz", "Vince", ""], ["Lin", "Hai", ""]]}, {"id": "1909.10616", "submitter": "Huaqing Zhang", "authors": "Huaqing Zhang, Xiaolin Cheng, Hui Zang and Dae Hoon Park", "title": "Compiler-Level Matrix Multiplication Optimization for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important linear algebra routine, GEneral Matrix Multiplication (GEMM), is\na fundamental operator in deep learning. Compilers need to translate these\nroutines into low-level code optimized for specific hardware. Compiler-level\noptimization of GEMM has significant performance impact on training and\nexecuting deep learning models. However, most deep learning frameworks rely on\nhardware-specific operator libraries in which GEMM optimization has been mostly\nachieved by manual tuning, which restricts the performance on different target\nhardware. In this paper, we propose two novel algorithms for GEMM optimization\nbased on the TVM framework, a lightweight Greedy Best First Search (G-BFS)\nmethod based on heuristic search, and a Neighborhood Actor Advantage Critic\n(N-A2C) method based on reinforcement learning. Experimental results show\nsignificant performance improvement of the proposed methods, in both the\noptimality of the solution and the cost of search in terms of time and fraction\nof the search space explored. Specifically, the proposed methods achieve 24%\nand 40% savings in GEMM computation time over state-of-the-art XGBoost and RNN\nmethods, respectively, while exploring only 0.1% of the search space. The\nproposed approaches have potential to be applied to other operator-level\noptimizations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 21:03:19 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zhang", "Huaqing", ""], ["Cheng", "Xiaolin", ""], ["Zang", "Hui", ""], ["Park", "Dae Hoon", ""]]}, {"id": "1909.10618", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Haoran Tang, Xingyu Lu, Shixiang Gu, Honglak Lee, Sergey\n  Levine", "title": "Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?", "comments": "Presented as an oral at the NeurIPS 2019 DeepRL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning has demonstrated significant success at\nsolving difficult reinforcement learning (RL) tasks. Previous works have\nmotivated the use of hierarchy by appealing to a number of intuitive benefits,\nincluding learning over temporally extended transitions, exploring over\ntemporally extended periods, and training and exploring in a more semantically\nmeaningful action space, among others. However, in fully observed, Markovian\nsettings, it is not immediately clear why hierarchical RL should provide\nbenefits over standard \"shallow\" RL architectures. In this work, we isolate and\nevaluate the claimed benefits of hierarchical RL on a suite of tasks\nencompassing locomotion, navigation, and manipulation. Surprisingly, we find\nthat most of the observed benefits of hierarchy can be attributed to improved\nexploration, as opposed to easier policy learning or imposed hierarchical\nstructures. Given this insight, we present exploration techniques inspired by\nhierarchy that achieve performance competitive with hierarchical RL while at\nthe same time being much simpler to use and implement.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 21:11:30 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 17:21:22 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Nachum", "Ofir", ""], ["Tang", "Haoran", ""], ["Lu", "Xingyu", ""], ["Gu", "Shixiang", ""], ["Lee", "Honglak", ""], ["Levine", "Sergey", ""]]}, {"id": "1909.10635", "submitter": "Shih-Ting Huang", "authors": "Shih-Ting Huang, Yannick D\\\"uren, Kristoffer H. Hellton and Johannes\n  Lederer", "title": "Tuning parameter calibration for prediction in personalized medicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized medicine has become an important part of medicine, for instance\npredicting individual drug responses based on genomic information. However,\nmany current statistical methods are not tailored to this task, because they\noverlook the individual heterogeneity of patients. In this paper, we look at\npersonalized medicine from a linear regression standpoint. We introduce an\nalternative version of the ridge estimator and target individuals by\nestablishing a tuning parameter calibration scheme that minimizes prediction\nerrors of individual patients. In stark contrast, classical schemes such as\ncross-validation minimize prediction errors only on average. We show that our\npipeline is optimal in terms of oracle inequalities, fast, and highly effective\nboth in simulations and on real data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 22:00:14 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 09:39:10 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 10:57:57 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Huang", "Shih-Ting", ""], ["D\u00fcren", "Yannick", ""], ["Hellton", "Kristoffer H.", ""], ["Lederer", "Johannes", ""]]}, {"id": "1909.10638", "submitter": "Stefan Klus", "authors": "Stefan Klus, Feliks N\\\"uske, Sebastian Peitz, Jan-Hendrik Niemann,\n  Cecilia Clementi, Christof Sch\\\"utte", "title": "Data-driven approximation of the Koopman generator: Model reduction,\n  system identification, and control", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2020.132416", "report-no": null, "categories": "math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a data-driven method for the approximation of the Koopman generator\ncalled gEDMD, which can be regarded as a straightforward extension of EDMD\n(extended dynamic mode decomposition). This approach is applicable to\ndeterministic and stochastic dynamical systems. It can be used for computing\neigenvalues, eigenfunctions, and modes of the generator and for system\nidentification. In addition to learning the governing equations of\ndeterministic systems, which then reduces to SINDy (sparse identification of\nnonlinear dynamics), it is possible to identify the drift and diffusion terms\nof stochastic differential equations from data. Moreover, we apply gEDMD to\nderive coarse-grained models of high-dimensional systems, and also to determine\nefficient model predictive control strategies. We highlight relationships with\nother methods and demonstrate the efficacy of the proposed methods using\nseveral guiding examples and prototypical molecular dynamics problems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 22:10:50 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 11:36:42 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Klus", "Stefan", ""], ["N\u00fcske", "Feliks", ""], ["Peitz", "Sebastian", ""], ["Niemann", "Jan-Hendrik", ""], ["Clementi", "Cecilia", ""], ["Sch\u00fctte", "Christof", ""]]}, {"id": "1909.10651", "submitter": "Zhi Zhang", "authors": "Zhi Zhang, Jiachen Yang, Hongyuan Zha", "title": "Integrating independent and centralized multi-agent reinforcement\n  learning for traffic signal network optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion in metropolitan areas is a world-wide problem that can be\nameliorated by traffic lights that respond dynamically to real-time conditions.\nRecent studies applying deep reinforcement learning (RL) to optimize single\ntraffic lights have shown significant improvement over conventional control.\nHowever, optimization of global traffic condition over a large road network\nfundamentally is a cooperative multi-agent control problem, for which\nsingle-agent RL is not suitable due to environment non-stationarity and\ninfeasibility of optimizing over an exponential joint-action space. Motivated\nby these challenges, we propose QCOMBO, a simple yet effective multi-agent\nreinforcement learning (MARL) algorithm that combines the advantages of\nindependent and centralized learning. We ensure scalability by selecting\nactions from individually optimized utility functions, which are shaped to\nmaximize global performance via a novel consistency regularization loss between\nindividual utility and a global action-value function. Experiments on diverse\nroad topologies and traffic flow conditions in the SUMO traffic simulator show\ncompetitive performance of QCOMBO versus recent state-of-the-art MARL\nalgorithms. We further show that policies trained on small sub-networks can\neffectively generalize to larger networks under different traffic flow\nconditions, providing empirical evidence for the suitability of MARL for\nintelligent traffic control.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 23:39:00 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhang", "Zhi", ""], ["Yang", "Jiachen", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1909.10652", "submitter": "Lingchen Zhu", "authors": "Lingchen Zhu, Tuanfeng Zhang", "title": "Generating Geological Facies Models with Fidelity to Diversity and\n  Statistics of Training Images using Improved Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology and workflow that overcome the limitations\nof the conventional Generative Adversarial Networks (GANs) for geological\nfacies modeling. It attempts to improve the training stability and guarantee\nthe diversity of the generated geology through interpretable latent vectors.\nThe resulting samples are ensured to have the equal probability (or an unbiased\ndistribution) as from the training dataset. This is critical when applying GANs\nto generate unbiased and representative geological models that can be further\nused to facilitate objective uncertainty evaluation and optimal decision-making\nin oil field exploration and development.\n  We proposed and implemented a new variant of GANs called Info-WGAN for the\ngeological facies modeling that combines Information Maximizing Generative\nAdversarial Network (InfoGAN) with Wasserstein distance and Gradient Penalty\n(GP) for learning interpretable latent codes as well as generating stable and\nunbiased distribution from the training data. Different from the original GAN\ndesign, InfoGAN can use the training images with full, partial, or no labels to\nperform disentanglement of the complex sedimentary types exhibited in the\ntraining dataset to achieve the variety and diversity of the generated samples.\nThis is accomplished by adding additional categorical variables that provide\ndisentangled semantic representations besides the mere randomized latent vector\nused in the original GANs. By such means, a regularization term is used to\nmaximize the mutual information between such latent categorical codes and the\ngenerated geological facies in the loss function.\n  Furthermore, the resulting unbiased sampling by Info-WGAN makes the data\nconditioning much easier than the conventional GANs in geological modeling\nbecause of the variety and diversity as well as the equal probability of the\nunconditional sampling by the generator.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 23:40:59 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zhu", "Lingchen", ""], ["Zhang", "Tuanfeng", ""]]}, {"id": "1909.10670", "submitter": "Xin Ding", "authors": "Xin Ding, Z. Jane Wang, William J. Welch", "title": "Subsampling Generative Adversarial Networks: Density Ratio Estimation in\n  Feature Space with Softplus Loss", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2979601", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filtering out unrealistic images from trained generative adversarial networks\n(GANs) has attracted considerable attention recently. Two density ratio based\nsubsampling methods---Discriminator Rejection Sampling (DRS) and\nMetropolis-Hastings GAN (MH-GAN)---were recently proposed, and their\neffectiveness in improving GANs was demonstrated on multiple datasets. However,\nDRS and MH-GAN are based on discriminator based density ratio estimation (DRE)\nmethods, so they may not work well if the discriminator in the trained GAN is\nfar from optimal. Moreover, they do not apply to some GANs (e.g., MMD-GAN). In\nthis paper, we propose a novel Softplus (SP) loss for DRE. Based on it, we\ndevelop a sample-based DRE method in a feature space learned by a specially\ndesigned and pre-trained ResNet-34 (DRE-F-SP). We derive the rate of\nconvergence of a density ratio model trained under the SP loss. Then, we\npropose three different density ratio subsampling methods (DRE-F-SP+RS,\nDRE-F-SP+MH, and DRE-F-SP+SIR) for GANs based on DRE-F-SP. Our subsampling\nmethods do not rely on the optimality of the discriminator and are suitable for\nall types of GANs. We empirically show our subsampling approach can\nsubstantially outperform DRS and MH-GAN on a synthetic dataset and the CIFAR-10\ndataset, using multiple GANs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 01:12:06 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 08:42:25 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2019 08:53:17 GMT"}, {"version": "v4", "created": "Fri, 1 Nov 2019 00:32:26 GMT"}, {"version": "v5", "created": "Thu, 20 Feb 2020 05:28:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Ding", "Xin", ""], ["Wang", "Z. Jane", ""], ["Welch", "William J.", ""]]}, {"id": "1909.10673", "submitter": "Rajat Talak", "authors": "Rajat Talak, Sertac Karaman, and Eytan Modiano", "title": "A Theory of Uncertainty Variables for State Estimation and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new framework of uncertainty variables to model uncertainty. An\nuncertainty variable is characterized by an uncertainty set, in which its\nrealization is bound to lie, while the conditional uncertainty is characterized\nby a set map, from a given realization of a variable to a set of possible\nrealizations of another variable. We prove Bayes' law and the law of total\nprobability equivalents for uncertainty variables. We define a notion of\nindependence, conditional independence, and pairwise independence for a\ncollection of uncertainty variables, and show that this new notion of\nindependence preserves the properties of independence defined over random\nvariables. We then develop a graphical model, namely Bayesian uncertainty\nnetwork, a Bayesian network equivalent defined over a collection of uncertainty\nvariables, and show that all the natural conditional independence properties,\nexpected out of a Bayesian network, hold for the Bayesian uncertainty network.\nWe also define the notion of point estimate, and show its relation with the\nmaximum a posteriori estimate. Probability theory starts with a distribution\nfunction (equivalently a probability measure) as a primitive and builds all\nother useful concepts, such as law of total probability, Bayes' law,\nindependence, graphical models, point estimate, on it. Our work shows that it\nis perfectly possible to start with a set, instead of a distribution function,\nand retain all the useful ideas needed for state estimation and inference.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 01:31:32 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 18:46:08 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Talak", "Rajat", ""], ["Karaman", "Sertac", ""], ["Modiano", "Eytan", ""]]}, {"id": "1909.10700", "submitter": "Aleksandr Aravkin", "authors": "Peng Zheng, Ryan Barber, Reed J.D. Sorensen, Christopher J.L. Murray,\n  and Aleksandr Y. Aravkin", "title": "Trimmed Constrained Mixed Effects Models: Formulations and Algorithms", "comments": "33 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed effects (ME) models inform a vast array of problems in the physical and\nsocial sciences, and are pervasive in meta-analysis. We consider ME models\nwhere the random effects component is linear. We then develop an efficient\napproach for a broad problem class that allows nonlinear measurements, priors,\nand constraints, and finds robust estimates in all of these cases using\ntrimming in the associated marginal likelihood.\n  The software accompanying this paper is disseminated as an open-source Python\npackage called LimeTr. LimeTr is able to recover results more accurately in the\npresence of outliers compared to available packages for both standard\nlongitudinal analysis and meta-analysis, and is also more computationally\nefficient than competing robust alternatives. Supplementary materials that\nreproduce the simulations, as well as run LimeTr and third party code are\navailable online. We also present analyses of global health data, where we use\nadvanced functionality of LimeTr, including constraints to impose monotonicity\nand concavity for dose-response relationships. Nonlinear observation models\nallow new analyses in place of classic approximations, such as log-linear\nmodels. Robust extensions in all analyses ensure that spurious data points do\nnot drive our understanding of either mean relationships or between-study\nheterogeneity.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 03:59:59 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 15:11:34 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zheng", "Peng", ""], ["Barber", "Ryan", ""], ["Sorensen", "Reed J. D.", ""], ["Murray", "Christopher J. L.", ""], ["Aravkin", "Aleksandr Y.", ""]]}, {"id": "1909.10702", "submitter": "Nitish Bahadur", "authors": "Nitish Bahadur and Randy Paffenroth", "title": "Dimension Estimation Using Autoencoders", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dimension Estimation (DE) and Dimension Reduction (DR) are two closely\nrelated topics, but with quite different goals. In DE, one attempts to estimate\nthe intrinsic dimensionality or number of latent variables in a set of\nmeasurements of a random vector. However, in DR, one attempts to project a\nrandom vector, either linearly or non-linearly, to a lower dimensional space\nthat preserves the information contained in the original higher dimensional\nspace. Of course, these two ideas are quite closely linked since, for example,\ndoing DR to a dimension smaller than suggested by DE will likely lead to\ninformation loss. Accordingly, in this paper we will focus on a particular\nclass of deep neural networks called autoencoders which are used extensively\nfor DR but are less well studied for DE. We show that several important\nquestions arise when using autoencoders for DE, above and beyond those that\narise for more classic DR/DE techniques such as Principal Component Analysis.\nWe address autoencoder architectural choices and regularization techniques that\nallow one to transform autoencoder latent layer representations into estimates\nof intrinsic dimension.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 04:09:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Bahadur", "Nitish", ""], ["Paffenroth", "Randy", ""]]}, {"id": "1909.10773", "submitter": "Minhao Cheng", "authors": "Minhao Cheng, Simranjit Singh, Patrick Chen, Pin-Yu Chen, Sijia Liu,\n  Cho-Jui Hsieh", "title": "Sign-OPT: A Query-Efficient Hard-label Adversarial Attack", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the most practical problem setup for evaluating adversarial\nrobustness of a machine learning system with limited access: the hard-label\nblack-box attack setting for generating adversarial examples, where limited\nmodel queries are allowed and only the decision is provided to a queried data\ninput. Several algorithms have been proposed for this problem but they\ntypically require huge amount (>20,000) of queries for attacking one example.\nAmong them, one of the state-of-the-art approaches (Cheng et al., 2019) showed\nthat hard-label attack can be modeled as an optimization problem where the\nobjective function can be evaluated by binary search with additional model\nqueries, thereby a zeroth order optimization algorithm can be applied. In this\npaper, we adopt the same optimization formulation but propose to directly\nestimate the sign of gradient at any direction instead of the gradient itself,\nwhich enjoys the benefit of single query. Using this single query oracle for\nretrieving sign of directional derivative, we develop a novel query-efficient\nSign-OPT approach for hard-label black-box attack. We provide a convergence\nanalysis of the new algorithm and conduct experiments on several models on\nMNIST, CIFAR-10 and ImageNet. We find that Sign-OPT attack consistently\nrequires 5X to 10X fewer queries when compared to the current state-of-the-art\napproaches, and usually converges to an adversarial example with smaller\nperturbation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 09:27:08 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 08:52:24 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 01:44:07 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Cheng", "Minhao", ""], ["Singh", "Simranjit", ""], ["Chen", "Patrick", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1909.10779", "submitter": "Lisa Graziani", "authors": "Lisa Graziani, Stefano Melacci, Marco Gori", "title": "Jointly Learning to Detect Emotions and Predict Facebook Reactions", "comments": "International Conference on Artificial Neural Networks. Springer,\n  Cham, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing ubiquity of Social Media data offers an attractive perspective\nfor improving the quality of machine learning-based models in several fields,\nranging from Computer Vision to Natural Language Processing. In this paper we\nfocus on Facebook posts paired with reactions of multiple users, and we\ninvestigate their relationships with classes of emotions that are typically\nconsidered in the task of emotion detection. We are inspired by the idea of\nintroducing a connection between reactions and emotions by means of First-Order\nLogic formulas, and we propose an end-to-end neural model that is able to\njointly learn to detect emotions and predict Facebook reactions in a multi-task\nenvironment, where the logic formulas are converted into polynomial\nconstraints. Our model is trained using a large collection of unsupervised\ntexts together with data labeled with emotion classes and Facebook posts that\ninclude reactions. An extended experimental analysis that leverages a large\ncollection of Facebook posts shows that the tasks of emotion classification and\nreaction prediction can both benefit from their interaction.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 09:45:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Graziani", "Lisa", ""], ["Melacci", "Stefano", ""], ["Gori", "Marco", ""]]}, {"id": "1909.10790", "submitter": "Arnaud Huaulm\\'e", "authors": "Arnaud Huaulm\\'e, Pierre Jannin, Fabian Reche, Jean-Luc Faucheron,\n  Alexandre Moreau-Gaudry, Sandrine Voros", "title": "Offline identification of surgical deviations in laparoscopic rectopexy", "comments": null, "journal-ref": null, "doi": "10.1016/j.artmed.2020.101837", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A median of 14.4% of patient undergone at least one adverse event\nduring surgery and a third of them are preventable. The occurrence of adverse\nevents forces surgeons to implement corrective strategies and, thus, deviate\nfrom the standard surgical process. Therefore, it is clear that the automatic\nidentification of adverse events is a major challenge for patient safety. In\nthis paper, we have proposed a method enabling us to identify such deviations.\nWe have focused on identifying surgeons' deviations from standard surgical\nprocesses due to surgical events rather than anatomic specificities. This is\nparticularly challenging, given the high variability in typical surgical\nprocedure workflows. Methods: We have introduced a new approach designed to\nautomatically detect and distinguish surgical process deviations based on\nmulti-dimensional non-linear temporal scaling with a hidden semi-Markov model\nusing manual annotation of surgical processes. The approach was then evaluated\nusing cross-validation. Results: The best results have over 90% accuracy.\nRecall and precision were superior at 70%. We have provided a detailed analysis\nof the incorrectly-detected observations. Conclusion: Multi-dimensional\nnon-linear temporal scaling with a hidden semi-Markov model provides promising\nresults for detecting deviations. Our error analysis of the\nincorrectly-detected observations offers different leads in order to further\nimprove our method. Significance: Our method demonstrated the feasibility of\nautomatically detecting surgical deviations that could be implemented for both\nskill analysis and developing situation awareness-based computer-assisted\nsurgical systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 10:17:44 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 10:30:25 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Huaulm\u00e9", "Arnaud", ""], ["Jannin", "Pierre", ""], ["Reche", "Fabian", ""], ["Faucheron", "Jean-Luc", ""], ["Moreau-Gaudry", "Alexandre", ""], ["Voros", "Sandrine", ""]]}, {"id": "1909.10801", "submitter": "Michael Poli", "authors": "Michael Poli, Jinkyoo Park, Ilija Ilievski", "title": "WATTNet: Learning to Trade FX via Hierarchical Spatio-Temporal\n  Representation of Highly Multivariate Time Series", "comments": "Submitted to the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finance is a particularly challenging application area for deep learning\nmodels due to low noise-to-signal ratio, non-stationarity, and partial\nobservability. Non-deliverable-forwards (NDF), a derivatives contract used in\nforeign exchange (FX) trading, presents additional difficulty in the form of\nlong-term planning required for an effective selection of start and end date of\nthe contract. In this work, we focus on tackling the problem of NDF tenor\nselection by leveraging high-dimensional sequential data consisting of spot\nrates, technical indicators and expert tenor patterns. To this end, we\nconstruct a dataset from the Depository Trust & Clearing Corporation (DTCC) NDF\ndata that includes a comprehensive list of NDF volumes and daily spot rates for\n64 FX pairs. We introduce WaveATTentionNet (WATTNet), a novel temporal\nconvolution (TCN) model for spatio-temporal modeling of highly multivariate\ntime series, and validate it across NDF markets with varying degrees of\ndissimilarity between the training and test periods in terms of volatility and\ngeneral market regimes. The proposed method achieves a significant positive\nreturn on investment (ROI) in all NDF markets under analysis, outperforming\nrecurrent and classical baselines by a wide margin. Finally, we propose two\northogonal interpretability approaches to verify noise stability and detect the\ndriving factors of the learned tenor selection strategy.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 10:42:23 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Poli", "Michael", ""], ["Park", "Jinkyoo", ""], ["Ilievski", "Ilija", ""]]}, {"id": "1909.10802", "submitter": "Saar Barkai", "authors": "Saar Barkai, Ido Hakimi and Assaf Schuster", "title": "Gap Aware Mitigation of Gradient Staleness", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is becoming increasingly popular as a platform for\ndistributed training of deep neural networks. Synchronous stochastic gradient\ndescent (SSGD) suffers from substantial slowdowns due to stragglers if the\nenvironment is non-dedicated, as is common in cloud computing. Asynchronous SGD\n(ASGD) methods are immune to these slowdowns but are scarcely used due to\ngradient staleness, which encumbers the convergence process. Recent techniques\nhave had limited success mitigating the gradient staleness when scaling up to\nmany workers (computing nodes). In this paper we define the Gap as a measure of\ngradient staleness and propose Gap-Aware (GA), a novel asynchronous-distributed\nmethod that penalizes stale gradients linearly to the Gap and performs well\neven when scaling to large numbers of workers. Our evaluation on the CIFAR,\nImageNet, and WikiText-103 datasets shows that GA outperforms the currently\nacceptable gradient penalization method, in final test accuracy. We also\nprovide convergence rate proof for GA. Despite prior beliefs, we show that if\nGA is applied, momentum becomes beneficial in asynchronous environments, even\nwhen the number of workers scales up.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 10:46:21 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:10:30 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 17:28:14 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Barkai", "Saar", ""], ["Hakimi", "Ido", ""], ["Schuster", "Assaf", ""]]}, {"id": "1909.10815", "submitter": "Renqian Luo", "authors": "Renqian Luo, Tao Qin, Enhong Chen", "title": "Balanced One-shot Neural Architecture Optimization", "comments": "Code and model checkpoints are publicly available at\n  https://github.com/renqianluo/NAO_pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to rank candidate architectures is the key to the performance of\nneural architecture search~(NAS). One-shot NAS is proposed to reduce the\nexpense but shows inferior performance against conventional NAS and is not\nadequately stable. We investigate into this and find that the ranking\ncorrelation between architectures under one-shot training and the ones under\nstand-alone full training is poor, which misleads the algorithm to discover\nbetter architectures. Further, we show that the training of architectures of\ndifferent sizes under the current one-shot method is imbalanced, which causes\nthe evaluated performances of the architectures to be less predictable of their\nground-truth performances and affects the ranking correlation heavily.\nConsequently, we propose Balanced NAO where we introduce balanced training of\nthe supernet during the search procedure to encourage more updates for large\narchitectures than small architectures by sampling architectures in proportion\nto their model sizes. Comprehensive experiments verify that our proposed method\nis effective and robust which leads to a more stable search. The final\ndiscovered architecture shows significant improvements against baselines with a\ntest error rate of 2.60\\% on CIFAR-10 and top-1 accuracy of 74.4% on ImageNet\nunder the mobile setting. Code and model checkpoints will be publicly\navailable. The code is available at github.com/renqianluo/NAO_pytorch.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:18:52 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 04:20:18 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Luo", "Renqian", ""], ["Qin", "Tao", ""], ["Chen", "Enhong", ""]]}, {"id": "1909.10831", "submitter": "Romuald A. Janik", "authors": "Romuald A. Janik", "title": "Entropy from Machine Learning", "comments": "10 pages, 2 figures; v2: reference added, minor notational\n  improvement; v3: reference added, general comments in section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG hep-lat q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We translate the problem of calculating the entropy of a set of binary\nconfigurations/signals into a sequence of supervised classification tasks.\nSubsequently, one can use virtually any machine learning classification\nalgorithm for computing entropy. This procedure can be used to compute entropy,\nand consequently the free energy directly from a set of Monte Carlo\nconfigurations at a given temperature. As a test of the proposed method, using\nan off-the-shelf machine learning classifier we reproduce the entropy and free\nenergy of the 2D Ising model from Monte Carlo configurations at various\ntemperatures throughout its phase diagram. Other potential applications include\ncomputing the entropy of spiking neurons or any other multidimensional binary\nsignals.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:12:42 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:13:32 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 08:44:48 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Janik", "Romuald A.", ""]]}, {"id": "1909.10856", "submitter": "Qiegen Liu", "authors": "Yiling Liu, Qiegen Liu, Minghui Zhang, Qingxin Yang, Shanshan Wang and\n  Dong Liang", "title": "IFR-Net: Iterative Feature Refinement Network for Compressed Sensing MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the compressive sensing MRI (CS-MRI) approaches in terms of fine\nstructure loss under high acceleration factors, we have proposed an iterative\nfeature refinement model (IFR-CS), equipped with fixed transforms, to restore\nthe meaningful structures and details. Nevertheless, the proposed IFR-CS still\nhas some limitations, such as the selection of hyper-parameters, a lengthy\nreconstruction time, and the fixed sparsifying transform. To alleviate these\nissues, we unroll the iterative feature refinement procedures in IFR-CS to a\nsupervised model-driven network, dubbed IFR-Net. Equipped with training data\npairs, both regularization parameter and the utmost feature refinement operator\nin IFR-CS become trainable. Additionally, inspired by the powerful\nrepresentation capability of convolutional neural network (CNN), CNN-based\ninversion blocks are explored in the sparsity-promoting denoising module to\ngeneralize the sparsity-enforcing operator. Extensive experiments on both\nsimulated and in vivo MR datasets have shown that the proposed network\npossesses a strong capability to capture image details and preserve well the\nstructural information with fast reconstruction speed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:57:18 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 02:18:02 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Liu", "Yiling", ""], ["Liu", "Qiegen", ""], ["Zhang", "Minghui", ""], ["Yang", "Qingxin", ""], ["Wang", "Shanshan", ""], ["Liang", "Dong", ""]]}, {"id": "1909.10881", "submitter": "Amir Karami", "authors": "Amir Karami", "title": "Application of Fuzzy Clustering for Text Data Dimensionality Reduction", "comments": "arXiv admin note: text overlap with arXiv:1712.05997", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large textual corpora are often represented by the document-term frequency\nmatrix whose elements are the frequency of terms; however, this matrix has two\nproblems: sparsity and high dimensionality. Four dimension reduction strategies\nare used to address these problems. Of the four strategies, unsupervised\nfeature transformation (UFT) is a popular and efficient strategy to map the\nterms to a new basis in the document-term frequency matrix. Although several\nUFT-based methods have been developed, fuzzy clustering has not been considered\nfor dimensionality reduction. This research explores fuzzy clustering as a new\nUFT-based approach to create a lower-dimensional representation of documents.\nPerformance of fuzzy clustering with and without using global term weighting\nmethods is shown to exceed principal component analysis and singular value\ndecomposition. This study also explores the effect of applying different\nfuzzifier values on fuzzy clustering for dimensionality reduction purpose.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 03:15:04 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Karami", "Amir", ""]]}, {"id": "1909.10893", "submitter": "Anirudh Goyal", "authors": "Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani, Sergey\n  Levine, Yoshua Bengio, Bernhard Sch\\\"olkopf", "title": "Recurrent Independent Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning modular structures which reflect the dynamics of the environment can\nlead to better generalization and robustness to changes which only affect a few\nof the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a\nnew recurrent architecture in which multiple groups of recurrent cells operate\nwith nearly independent transition dynamics, communicate only sparingly through\nthe bottleneck of attention, and are only updated at time steps where they are\nmost relevant. We show that this leads to specialization amongst the RIMs,\nwhich in turn allows for dramatically improved generalization on tasks where\nsome factors of variation differ systematically between training and\nevaluation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:28:00 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 18:56:25 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 19:32:36 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 16:47:11 GMT"}, {"version": "v5", "created": "Thu, 12 Nov 2020 00:48:33 GMT"}, {"version": "v6", "created": "Tue, 17 Nov 2020 05:23:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Goyal", "Anirudh", ""], ["Lamb", "Alex", ""], ["Hoffmann", "Jordan", ""], ["Sodhani", "Shagun", ""], ["Levine", "Sergey", ""], ["Bengio", "Yoshua", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1909.10904", "submitter": "Joan Bas Serrano", "authors": "Joan Bas-Serrano, Gergely Neu", "title": "Faster saddle-point optimization for solving large-scale Markov decision\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing optimal policies in average-reward\nMarkov decision processes. This classical problem can be formulated as a linear\nprogram directly amenable to saddle-point optimization methods, albeit with a\nnumber of variables that is linear in the number of states. To address this\nissue, recent work has considered a linearly relaxed version of the resulting\nsaddle-point problem. Our work aims at achieving a better understanding of this\nrelaxed optimization problem by characterizing the conditions necessary for\nconvergence to the optimal policy, and designing an optimization algorithm\nenjoying fast convergence rates that are independent of the size of the state\nspace. Notably, our characterization points out some potential issues with\nprevious work.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 21:58:26 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 16:22:14 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Bas-Serrano", "Joan", ""], ["Neu", "Gergely", ""]]}, {"id": "1909.10914", "submitter": "Wei Wang Dr.", "authors": "Xuedou Xiao, Wei Wang, Taobin Chen, Yang Cao, Tao Jiang, Qian Zhang", "title": "Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in unmanned aerial vehicle (UAV) technology have\nrevolutionized a broad class of civil and military applications. However, the\ndesigns of wireless technologies that enable real-time streaming of\nhigh-definition video between UAVs and ground clients present a conundrum. Most\nexisting adaptive bitrate (ABR) algorithms are not optimized for the\nair-to-ground links, which usually fluctuate dramatically due to the dynamic\nflight states of the UAV. In this paper, we present SA-ABR, a new\nsensor-augmented system that generates ABR video streaming algorithms with the\nassistance of various kinds of inherent sensor data that are used to pilot\nUAVs. By incorporating the inherent sensor data with network observations,\nSA-ABR trains a deep reinforcement learning (DRL) model to extract salient\nfeatures from the flight state information and automatically learn an ABR\nalgorithm to adapt to the varying UAV channel capacity through the training\nprocess. SA-ABR does not rely on any assumptions or models about UAV's flight\nstates or the environment, but instead, it makes decisions by exploiting\ntemporal properties of past throughput through the long short-term memory\n(LSTM) to adapt itself to a wide range of highly dynamic environments. We have\nimplemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare\nSA-ABR with a variety of existing state-of-the-art ABR algorithms, and the\nresults show that our system outperforms the best known existing ABR algorithm\nby 21.4% in terms of the average quality of experience (QoE) reward.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:20:44 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Xiao", "Xuedou", ""], ["Wang", "Wei", ""], ["Chen", "Taobin", ""], ["Cao", "Yang", ""], ["Jiang", "Tao", ""], ["Zhang", "Qian", ""]]}, {"id": "1909.10960", "submitter": "Tino Werner", "authors": "Tino Werner, Peter Ruckdeschel", "title": "The column measure and Gradient-Free Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse model selection by structural risk minimization leads to a set of a\nfew predictors, ideally a subset of the true predictors. This selection clearly\ndepends on the underlying loss function $\\tilde L$. For linear regression with\nsquare loss, the particular (functional) Gradient Boosting variant\n$L_2-$Boosting excels for its computational efficiency even for very large\npredictor sets, while still providing suitable estimation consistency. For more\ngeneral loss functions, functional gradients are not always easily accessible\nor, like in the case of continuous ranking, need not even exist. To close this\ngap, starting from column selection frequencies obtained from $L_2-$Boosting,\nwe introduce a loss-dependent ''column measure'' $\\nu^{(\\tilde L)}$ which\nmathematically describes variable selection. The fact that certain variables\nrelevant for a particular loss $\\tilde L$ never get selected by $L_2-$Boosting\nis reflected by a respective singular part of $\\nu^{(\\tilde L)}$ w.r.t.\n$\\nu^{(L_2)}$. With this concept at hand, it amounts to a suitable change of\nmeasure (accounting for singular parts) to make $L_2-$Boosting select variables\naccording to a different loss $\\tilde L$. As a consequence, this opens the\nbridge to applications of simulational techniques such as various resampling\ntechniques, or rejection sampling, to achieve this change of measure in an\nalgorithmic way.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:42:45 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Werner", "Tino", ""], ["Ruckdeschel", "Peter", ""]]}, {"id": "1909.10995", "submitter": "Jo Schlemper", "authors": "Jo Schlemper, Ilkay Oksuz, James R. Clough, Jinming Duan, Andrew P.\n  King, Julia A. Schnabel, Joseph V. Hajnal, Daniel Rueckert", "title": "dAUTOMAP: decomposing AUTOMAP to achieve scalability and enhance\n  performance", "comments": "Presented at ISMRM 27th Annual Meeting & Exhibition (Abstract #658)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AUTOMAP is a promising generalized reconstruction approach, however, it is\nnot scalable and hence the practicality is limited. We present dAUTOMAP, a\nnovel way for decomposing the domain transformation of AUTOMAP, making the\nmodel scale linearly. We show dAUTOMAP outperforms AUTOMAP with significantly\nfewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 15:22:43 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 20:21:44 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Schlemper", "Jo", ""], ["Oksuz", "Ilkay", ""], ["Clough", "James R.", ""], ["Duan", "Jinming", ""], ["King", "Andrew P.", ""], ["Schnabel", "Julia A.", ""], ["Hajnal", "Joseph V.", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1909.11022", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio, Alessio Micheli", "title": "Reservoir Topology in Deep Echo State Networks", "comments": "Preprint of the paper published in the proceedings of ICANN 2019", "journal-ref": null, "doi": "10.1007/978-3-030-30493-5_6", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Echo State Networks (DeepESNs) recently extended the applicability of\nReservoir Computing (RC) methods towards the field of deep learning. In this\npaper we study the impact of constrained reservoir topologies in the\narchitectural design of deep reservoirs, through numerical experiments on\nseveral RC benchmarks. The major outcome of our investigation is to show the\nremarkable effect, in terms of predictive performance gain, achieved by the\nsynergy between a deep reservoir construction and a structured organization of\nthe recurrent units in each layer. Our results also indicate that a\nparticularly advantageous architectural setting is obtained in correspondence\nof DeepESNs where reservoir units are structured according to a permutation\nrecurrent matrix.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 16:15:16 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1909.11029", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, A.S.M. Kayes, Md Hasan Furhad, Mohammad Mainul Islam\n  and Md Shohidul Islam", "title": "E-MIIM: An Ensemble Learning based Context-Aware Mobile Telephony Model\n  for Intelligent Interruption Management", "comments": "10 pages", "journal-ref": "Journal: AI and Society, Springer Nature, 2019", "doi": "10.1007/s00146-019-00898-8", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, mobile telephony interruptions in our daily life activities are\ncommon because of the inappropriate ringing notifications of incoming phone\ncalls in different contexts. Such interruptions may impact on the work\nattention not only for the mobile phone owners but also the surrounding people.\nDecision tree is the most popular machine learning classification technique\nthat is used in existing context-aware mobile intelligent interruption\nmanagement (MIIM) model to overcome such issues. However, a single decision\ntree based context-aware model may cause overfitting problem and thus decrease\nthe prediction accuracy of the inferred model. Therefore, in this paper, we\npropose an ensemble machine learning based context-aware mobile telephony model\nfor the purpose of intelligent interruption management by taking into account\nmulti-dimensional contexts and name it \"E-MIIM\". The experimental results on\nindividuals' real life mobile telephony datasets show that our E-MIIM model is\nmore effective and outperforms existing MIIM model for predicting and managing\nindividual's mobile telephony interruptions based on their relevant contextual\ninformation.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 21:36:33 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Kayes", "A. S. M.", ""], ["Furhad", "Md Hasan", ""], ["Islam", "Mohammad Mainul", ""], ["Islam", "Md Shohidul", ""]]}, {"id": "1909.11082", "submitter": "Sethu Hareesh Kolluru", "authors": "Sethu Hareesh Kolluru", "title": "A Neural Network Based Method to Solve Boundary Value Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Neural Network (NN) based numerical method is formulated and implemented\nfor solving Boundary Value Problems (BVPs) and numerical results are presented\nto validate this method by solving Laplace equation with Dirichlet boundary\ncondition and Poisson's equation with mixed boundary conditions. The principal\nadvantage of NN based numerical method is the discrete data points where the\nfield is computed, can be unstructured and do not suffer from issues of meshing\nlike traditional numerical methods such as Finite Difference Time Domain or\nFinite Element Method. Numerical investigations are carried out for both\nuniform and non-uniform training grid distributions to understand the efficacy\nand limitations of this method and to provide qualitative understanding of\nvarious parameters involved.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:58:39 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Kolluru", "Sethu Hareesh", ""]]}, {"id": "1909.11114", "submitter": "Christian Gary Mena Leco\\~na", "authors": "C. Gary Mena, Arno De Caigny, Kristof Coussement, Koen W. De Bock,\n  Stefan Lessmann", "title": "Churn Prediction with Sequential Data and Deep Neural Networks. A\n  Comparative Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-the-shelf machine learning algorithms for prediction such as regularized\nlogistic regression cannot exploit the information of time-varying features\nwithout previously using an aggregation procedure of such sequential data.\nHowever, recurrent neural networks provide an alternative approach by which\ntime-varying features can be readily used for modeling. This paper assesses the\nperformance of neural networks for churn modeling using recency, frequency, and\nmonetary value data from a financial services provider. Results show that RFM\nvariables in combination with LSTM neural networks have larger top-decile lift\nand expected maximum profit metrics than regularized logistic regression models\nwith commonly-used demographic variables. Moreover, we show that using the\nfitted probabilities from the LSTM as feature in the logistic regression\nincreases the out-of-sample performance of the latter by 25 percent compared to\na model with only static features.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 18:27:14 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Mena", "C. Gary", ""], ["De Caigny", "Arno", ""], ["Coussement", "Kristof", ""], ["De Bock", "Koen W.", ""], ["Lessmann", "Stefan", ""]]}, {"id": "1909.11124", "submitter": "Yifan Xue", "authors": "Yifan Xue, Michael Ding and Xinghua Lu", "title": "Supervised Vector Quantized Variational Autoencoder for Learning\n  Interpretable Global Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning interpretable representations of data remains a central challenge in\ndeep learning. When training a deep generative model, the observed data are\noften associated with certain categorical labels, and, in parallel with\nlearning to regenerate data and simulate new data, learning an interpretable\nrepresentation of each class of data is also a process of acquiring knowledge.\nHere, we present a novel generative model, referred to as the Supervised Vector\nQuantized Variational AutoEncoder (S-VQ-VAE), which combines the power of\nsupervised and unsupervised learning to obtain a unique, interpretable global\nrepresentation for each class of data. Compared with conventional generative\nmodels, our model has three key advantages: first, it is an integrative model\nthat can simultaneously learn a feature representation for individual data\npoint and a global representation for each class of data; second, the learning\nof global representations with embedding codes is guided by supervised\ninformation, which clearly defines the interpretation of each code; and third,\nthe global representations capture crucial characteristics of different\nclasses, which reveal similarity and differences of statistical structures\nunderlying different groups of data. We evaluated the utility of S-VQ-VAE on a\nmachine learning benchmark dataset, the MNIST dataset, and on gene expression\ndata from the Library of Integrated Network-Based Cellular Signatures (LINCS).\nWe proved that S-VQ-VAE was able to learn the global genetic characteristics of\nsamples perturbed by the same class of perturbagen (PCL), and further revealed\nthe mechanism correlations between PCLs. Such knowledge is crucial for\npromoting new drug development for complex diseases like cancer.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 18:51:21 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 19:54:35 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Xue", "Yifan", ""], ["Ding", "Michael", ""], ["Lu", "Xinghua", ""]]}, {"id": "1909.11150", "submitter": "Nouamane Laanait", "authors": "Nouamane Laanait, Joshua Romero, Junqi Yin, M. Todd Young, Sean\n  Treichler, Vitalii Starchenko, Albina Borisevich, Alex Sergeev, Michael\n  Matheson", "title": "Exascale Deep Learning for Scientific Inverse Problems", "comments": "13 pages, 9 figures. Under review by the Systems and Machine Learning\n  (SysML) Conference (SysML '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci cs.DC physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce novel communication strategies in synchronous distributed Deep\nLearning consisting of decentralized gradient reduction orchestration and\ncomputational graph-aware grouping of gradient tensors. These new techniques\nproduce an optimal overlap between computation and communication and result in\nnear-linear scaling (0.93) of distributed training up to 27,600 NVIDIA V100\nGPUs on the Summit Supercomputer. We demonstrate our gradient reduction\ntechniques in the context of training a Fully Convolutional Neural Network to\napproximate the solution of a longstanding scientific inverse problem in\nmaterials imaging. The efficient distributed training on a dataset size of 0.5\nPB, produces a model capable of an atomically-accurate reconstruction of\nmaterials, and in the process reaching a peak performance of 2.15(4)\nEFLOPS$_{16}$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 19:40:59 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Laanait", "Nouamane", ""], ["Romero", "Joshua", ""], ["Yin", "Junqi", ""], ["Young", "M. Todd", ""], ["Treichler", "Sean", ""], ["Starchenko", "Vitalii", ""], ["Borisevich", "Albina", ""], ["Sergeev", "Alex", ""], ["Matheson", "Michael", ""]]}, {"id": "1909.11193", "submitter": "Wei Zhu", "authors": "Wei Zhu, Qiang Qiu, Robert Calderbank, Guillermo Sapiro, Xiuyuan Cheng", "title": "Scaling-Translation-Equivariant Networks with Decomposed Convolutional\n  Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoding the scale information explicitly into the representation learned by\na convolutional neural network (CNN) is beneficial for many computer vision\ntasks especially when dealing with multiscale inputs. We study, in this paper,\na scaling-translation-equivariant (ST-equivariant) CNN with joint convolutions\nacross the space and the scaling group, which is shown to be both sufficient\nand necessary to achieve equivariance for the regular representation of the\nscaling-translation group ST . To reduce the model complexity and computational\nburden, we decompose the convolutional filters under two pre-fixed separable\nbases and truncate the expansion to low-frequency components. A further benefit\nof the truncated filter expansion is the improved deformation robustness of the\nequivariant representation, a property which is theoretically analyzed and\nempirically verified. Numerical experiments demonstrate that the proposed\nscaling-translation-equivariant network with decomposed convolutional filters\n(ScDCFNet) achieves significantly improved performance in multiscale image\nclassification and better interpretability than regular CNNs at a reduced model\nsize.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:23:19 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 18:41:42 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhu", "Wei", ""], ["Qiu", "Qiang", ""], ["Calderbank", "Robert", ""], ["Sapiro", "Guillermo", ""], ["Cheng", "Xiuyuan", ""]]}, {"id": "1909.11197", "submitter": "Tanwi Mallick", "authors": "Tanwi Mallick, Prasanna Balaprakash, Eric Rask, and Jane Macfarlane", "title": "Graph-Partitioning-Based Diffusion Convolutional Recurrent Neural\n  Network for Large-Scale Traffic Forecasting", "comments": null, "journal-ref": "Transportation Research Record (2020)", "doi": "10.1177/0361198120930010", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting approaches are critical to developing adaptive strategies\nfor mobility. Traffic patterns have complex spatial and temporal dependencies\nthat make accurate forecasting on large highway networks a challenging task.\nRecently, diffusion convolutional recurrent neural networks (DCRNNs) have\nachieved state-of-the-art results in traffic forecasting by capturing the\nspatiotemporal dynamics of the traffic. Despite the promising results, however,\napplying DCRNNs for large highway networks still remains elusive because of\ncomputational and memory bottlenecks. We present an approach for implementing a\nDCRNN for a large highway network that overcomes these limitations. Our\napproach uses a graph-partitioning method to decompose a large highway network\ninto smaller networks and trains them independently. We demonstrate the\nefficacy of the graph-partitioning-based DCRNN approach to model the traffic on\na large California highway network with 11,160 sensor locations. We develop an\noverlapping nodes approach for the graph-partitioning-based DCRNN to include\nsensor locations from partitions that are geographically close to a given\npartition. Furthermore, we demonstrate that the DCRNN model can be used to\nforecast the speed and flow simultaneously and that the forecasted values\npreserve fundamental traffic flow dynamics. Our approach to developing DCRNN\nmodels that represent large highway networks can be a potential core capability\nin advanced highway traffic monitoring systems, where a trained DCRNN model\nforecasting traffic at all sensor locations can be used to adjust traffic\nmanagement strategies proactively based on anticipated future conditions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:38:29 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:51:19 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 14:55:15 GMT"}, {"version": "v4", "created": "Mon, 20 Apr 2020 13:15:34 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Mallick", "Tanwi", ""], ["Balaprakash", "Prasanna", ""], ["Rask", "Eric", ""], ["Macfarlane", "Jane", ""]]}, {"id": "1909.11201", "submitter": "Shusen Wang", "authors": "Mengjiao Zhang and Shusen Wang", "title": "Matrix Sketching for Secure Collaborative Machine Learning", "comments": "In International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative learning allows participants to jointly train a model without\ndata sharing. To update the model parameters, the central server broadcasts\nmodel parameters to the clients, and the clients send updating directions such\nas gradients to the server. While data do not leave a client device, the\ncommunicated gradients and parameters will leak a client's privacy. Attacks\nthat infer clients' privacy from gradients and parameters have been developed\nby prior work. Simple defenses such as dropout and differential privacy either\nfail to defend the attacks or seriously hurt test accuracy.\n  We propose a practical defense which we call Double-Blind Collaborative\nLearning (DBCL). The high-level idea is to apply random matrix sketching to the\nparameters (aka weights) and re-generate random sketching after each iteration.\nDBCL prevents clients from conducting gradient-based privacy inferences which\nare the most effective attacks. DBCL works because from the attacker's\nperspective, sketching is effectively random noise that outweighs the signal.\nNotably, DBCL does not much increase computation and communication costs and\ndoes not hurt test accuracy at all.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:55:26 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 21:05:22 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 14:07:12 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 13:27:37 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhang", "Mengjiao", ""], ["Wang", "Shusen", ""]]}, {"id": "1909.11207", "submitter": "Shusen Wang", "authors": "Shusen Wang", "title": "Simple and Almost Assumption-Free Out-of-Sample Bound for Random Feature\n  Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random feature mapping (RFM) is a popular method for speeding up kernel\nmethods at the cost of losing a little accuracy. We study kernel ridge\nregression with random feature mapping (RFM-KRR) and establish novel\nout-of-sample error upper and lower bounds. While out-of-sample bounds for\nRFM-KRR have been established by prior work, this paper's theories are highly\ninteresting for two reasons. On the one hand, our theories are based on weak\nand valid assumptions. In contrast, the existing theories are based on various\nuncheckable assumptions, which makes it unclear whether their bounds are the\nnature of RFM-KRR or simply the consequence of strong assumptions. On the other\nhand, our analysis is completely based on elementary linear algebra and thereby\neasy to read and verify. Finally, our experiments lend empirical supports to\nthe theories.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 22:07:33 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wang", "Shusen", ""]]}, {"id": "1909.11228", "submitter": "David Venuto", "authors": "David Venuto, Leonard Boussioux, Junhao Wang, Rola Dali, Jhelum\n  Chakravorty, Yoshua Bengio, Doina Precup", "title": "Avoidance Learning Using Observational Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imitation learning seeks to learn an expert policy from sampled\ndemonstrations. However, in the real world, it is often difficult to find a\nperfect expert and avoiding dangerous behaviors becomes relevant for safety\nreasons. We present the idea of \\textit{learning to avoid}, an objective\nopposite to imitation learning in some sense, where an agent learns to avoid a\ndemonstrator policy given an environment. We define avoidance learning as the\nprocess of optimizing the agent's reward while avoiding dangerous behaviors\ngiven by a demonstrator. In this work we develop a framework of avoidance\nlearning by defining a suitable objective function for these problems which\ninvolves the \\emph{distance} of state occupancy distributions of the expert and\ndemonstrator policies. We use density estimates for state occupancy measures\nand use the aforementioned distance as the reward bonus for avoiding the\ndemonstrator. We validate our theory with experiments using a wide range of\npartially observable environments. Experimental results show that we are able\nto improve sample efficiency during training compared to state of the art\npolicy optimization and safety methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 23:37:35 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Venuto", "David", ""], ["Boussioux", "Leonard", ""], ["Wang", "Junhao", ""], ["Dali", "Rola", ""], ["Chakravorty", "Jhelum", ""], ["Bengio", "Yoshua", ""], ["Precup", "Doina", ""]]}, {"id": "1909.11232", "submitter": "Al Amin Hosain", "authors": "Al Amin Hosain, Panneer Selvam Santhalingam, Parth Pathak, Jana\n  Kosecka and Huzefa Rangwala", "title": "Sign Language Recognition Analysis using Multimodal Data", "comments": "conference : IEEE DSAA, 2019, Washington DC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-controlled personal and home assistants (such as the Amazon Echo and\nApple Siri) are becoming increasingly popular for a variety of applications.\nHowever, the benefits of these technologies are not readily accessible to Deaf\nor Hard-ofHearing (DHH) users. The objective of this study is to develop and\nevaluate a sign recognition system using multiple modalities that can be used\nby DHH signers to interact with voice-controlled devices. With the advancement\nof depth sensors, skeletal data is used for applications like video analysis\nand activity recognition. Despite having similarity with the well-studied human\nactivity recognition, the use of 3D skeleton data in sign language recognition\nis rare. This is because unlike activity recognition, sign language is mostly\ndependent on hand shape pattern. In this work, we investigate the feasibility\nof using skeletal and RGB video data for sign language recognition using a\ncombination of different deep learning architectures. We validate our results\non a large-scale American Sign Language (ASL) dataset of 12 users and 13107\nsamples across 51 signs. It is named as GMUASL51. We collected the dataset over\n6 months and it will be publicly released in the hope of spurring further\nmachine learning research towards providing improved accessibility for digital\nassistants.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 23:44:49 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Hosain", "Al Amin", ""], ["Santhalingam", "Panneer Selvam", ""], ["Pathak", "Parth", ""], ["Kosecka", "Jana", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1909.11248", "submitter": "John Gideon", "authors": "John Gideon, Katie Matton, Steve Anderau, Melvin G McInnis, Emily\n  Mower Provost", "title": "When to Intervene: Detecting Abnormal Mood using Everyday Smartphone\n  Conversations", "comments": "Submitted to IEEE Transactions on Affective Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipolar disorder (BPD) is a chronic mental illness characterized by extreme\nmood and energy changes from mania to depression. These changes drive behaviors\nthat often lead to devastating personal or social consequences. BPD is managed\nclinically with regular interactions with care providers, who assess mood,\nenergy levels, and the form and content of speech. Recent work has proposed\nsmartphones for monitoring mood using speech. However, these works do not\npredict when to intervene. Predicting when to intervene is challenging because\nthere is not a single measure that is relevant for every person: different\nindividuals may have different levels of symptom severity considered typical.\nAdditionally, this typical mood, or baseline, may change over time, making a\nsingle symptom threshold insufficient. This work presents an innovative\napproach that expands clinical mood monitoring to predict when interventions\nare necessary using an anomaly detection framework, which we call Temporal\nNormalization. We first validate the model using a dataset annotated for\nclinical interventions and then incorporate this method in a deep learning\nframework to predict mood anomalies from natural, unstructured, telephone\nspeech data. The combination of these approaches provides a framework to enable\nreal-world speech-focused mood monitoring.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 01:14:05 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 01:11:49 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Gideon", "John", ""], ["Matton", "Katie", ""], ["Anderau", "Steve", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1909.11251", "submitter": "Chang How Tan Chang H Tan", "authors": "Chang How Tan, Vincent CS Lee, Mahsa Salehi", "title": "Online Semi-Supervised Concept Drift Detection with Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept drift is formally defined as the change in joint distribution of a\nset of input variables X and a target variable y. The two types of drift that\nare extensively studied are real drift and virtual drift where the former is\nthe change in posterior probabilities p(y|X) while the latter is the change in\ndistribution of X without affecting the posterior probabilities. Many\napproaches on concept drift detection either assume full availability of data\nlabels, y or handle only the virtual drift. In a streaming environment, the\nassumption of full availability of data labels, y is questioned. On the other\nhand, approaches that deal with virtual drift failed to address real drift.\nRather than improving the state-of-the-art methods, this paper presents a\nsemi-supervised framework to deal with the challenges above. The objective of\nthe proposed framework is to learn from streaming environment with limited data\nlabels, y and detect real drift concurrently. This paper proposes a novel\nconcept drift detection method utilizing the densities of posterior\nprobabilities in partially labeled streaming environments. Experimental results\non both synthetic and realworld datasets show that our proposed semi-supervised\nframework enables the detection of concept drift in such environment while\nachieving comparable prediction performance to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 01:47:28 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 02:10:38 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Tan", "Chang How", ""], ["Lee", "Vincent CS", ""], ["Salehi", "Mahsa", ""]]}, {"id": "1909.11274", "submitter": "Taiji Suzuki", "authors": "Taiji Suzuki, Hiroshi Abe, Tomoaki Nishimura", "title": "Compression based bound for non-compressed network: unified\n  generalization error analysis of large compressible deep neural network", "comments": "published in ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest issues in deep learning theory is the generalization\nability of networks with huge model size. The classical learning theory\nsuggests that overparameterized models cause overfitting. However, practically\nused large deep models avoid overfitting, which is not well explained by the\nclassical approaches. To resolve this issue, several attempts have been made.\nAmong them, the compression based bound is one of the promising approaches.\nHowever, the compression based bound can be applied only to a compressed\nnetwork, and it is not applicable to the non-compressed original network. In\nthis paper, we give a unified frame-work that can convert compression based\nbounds to those for non-compressed original networks. The bound gives even\nbetter rate than the one for the compressed network by improving the bias term.\nBy establishing the unified frame-work, we can obtain a data dependent\ngeneralization error bound which gives a tighter evaluation than the data\nindependent ones.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:43:14 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 05:40:09 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 16:39:16 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Suzuki", "Taiji", ""], ["Abe", "Hiroshi", ""], ["Nishimura", "Tomoaki", ""]]}, {"id": "1909.11275", "submitter": "Lech Szymanski", "authors": "Lech Szymanski, Brendan McCane, Craig Atkinson", "title": "Switched linear projections for neural network interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce switched linear projections for expressing the activity of a\nneuron in a deep neural network in terms of a single linear projection in the\ninput space. The method works by isolating the active subnetwork, a series of\nlinear transformations, that determine the entire computation of the network\nfor a given input instance. With these projections we can decompose activity in\nany hidden layer into patterns detected in a given input instance. We also\npropose that in ReLU networks it is instructive and meaningful to examine\npatterns that deactivate the neurons in a hidden layer, something that is\nimplicitly ignored by the existing interpretability methods tracking solely the\nactive aspect of the network's computation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:43:37 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 22:19:43 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 22:05:51 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Szymanski", "Lech", ""], ["McCane", "Brendan", ""], ["Atkinson", "Craig", ""]]}, {"id": "1909.11285", "submitter": "Ze Wang", "authors": "Ze Wang, Xiuyuan Cheng, Guillermo Sapiro, and Qiang Qiu", "title": "A Dictionary Approach to Domain-Invariant Learning in Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider domain-invariant deep learning by explicitly\nmodeling domain shifts with only a small amount of domain-specific parameters\nin a Convolutional Neural Network (CNN). By exploiting the observation that a\nconvolutional filter can be well approximated as a linear combination of a\nsmall set of dictionary atoms, we show for the first time, both empirically and\ntheoretically, that domain shifts can be effectively handled by decomposing a\nconvolutional layer into a domain-specific atom layer and a domain-shared\ncoefficient layer, while both remain convolutional. An input channel will now\nfirst convolve spatially only with each respective domain-specific dictionary\natom to \"absorb\" domain variations, and then output channels are linearly\ncombined using common decomposition coefficients trained to promote shared\nsemantics across domains. We use toy examples, rigorous analysis, and\nreal-world examples with diverse datasets and architectures, to show the\nproposed plug-in framework's effectiveness in cross and joint domain\nperformance and domain adaptation. With the proposed architecture, we need only\na small set of dictionary atoms to model each additional domain, which brings a\nnegligible amount of additional parameters, typically a few hundred.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 04:35:04 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 23:31:44 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Ze", ""], ["Cheng", "Xiuyuan", ""], ["Sapiro", "Guillermo", ""], ["Qiu", "Qiang", ""]]}, {"id": "1909.11294", "submitter": "Simon Luo", "authors": "Simon Luo, Lamiae Azizi and Mahito Sugiyama", "title": "Hierarchical Probabilistic Model for Blind Source Separation via\n  Legendre Transformation", "comments": "13 pages, 7 figures, UAI2021", "journal-ref": "37th Confeence on Uncertainty in Artificial Intelligence, July\n  27-30, 2021, Online", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel blind source separation (BSS) method, called information\ngeometric blind source separation (IGBSS). Our formulation is based on the\nlog-linear model equipped with a hierarchically structured sample space, which\nhas theoretical guarantees to uniquely recover a set of source signals by\nminimizing the KL divergence from a set of mixed signals. Source signals,\nreceived signals, and mixing matrices are realized as different layers in our\nhierarchical sample space. Our empirical results have demonstrated on images\nand time series data that our approach is superior to well established\ntechniques and is able to separate signals with complex interactions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 05:22:45 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 07:28:51 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 01:46:56 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Luo", "Simon", ""], ["Azizi", "Lamiae", ""], ["Sugiyama", "Mahito", ""]]}, {"id": "1909.11298", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Alexander Cloninger", "title": "Classification Logit Two-sample Testing by Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of generative adversarial networks and variational\nlearning suggests training a classifier network may work well in addressing the\nclassical two-sample problem. Network-based tests have the computational\nadvantage that the algorithm scales to large samples. This paper proposes a\ntwo-sample statistic which is the difference of the logit function, provided by\na trained classification neural network, evaluated on the testing set split of\nthe two datasets. Theoretically, we prove the testing power to differentiate\ntwo sub-exponential densities given that the network is sufficiently\nparametrized. When the two densities lie on or near to low-dimensional\nmanifolds embedded in possibly high-dimensional space, the needed network\ncomplexity is reduced to only scale with the intrinsic dimensionality. Both the\napproximation and estimation error analysis are based on a new result of\nnear-manifold integral approximation. In experiments, the proposed method\ndemonstrates better performance than previous network-based tests using\nclassification accuracy as the two-sample statistic, and compares favorably to\ncertain kernel maximum mean discrepancy tests on synthetic datasets and\nhand-written digit datasets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 05:55:28 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 20:16:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Cloninger", "Alexander", ""]]}, {"id": "1909.11299", "submitter": "Cheolhyoung Lee", "authors": "Cheolhyoung Lee, Kyunghyun Cho, Wanmo Kang", "title": "Mixout: Effective Regularization to Finetune Large-scale Pretrained\n  Language Models", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing, it has been observed recently that\ngeneralization could be greatly improved by finetuning a large-scale language\nmodel pretrained on a large unlabeled corpus. Despite its recent success and\nwide adoption, finetuning a large pretrained language model on a downstream\ntask is prone to degenerate performance when there are only a small number of\ntraining instances available. In this paper, we introduce a new regularization\ntechnique, to which we refer as \"mixout\", motivated by dropout. Mixout\nstochastically mixes the parameters of two models. We show that our mixout\ntechnique regularizes learning to minimize the deviation from one of the two\nmodels and that the strength of regularization adapts along the optimization\ntrajectory. We empirically evaluate the proposed mixout and its variants on\nfinetuning a pretrained language model on downstream tasks. More specifically,\nwe demonstrate that the stability of finetuning and the average accuracy\ngreatly increase when we use the proposed approach to regularize finetuning of\nBERT on downstream tasks in GLUE.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 06:04:37 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 02:18:43 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Lee", "Cheolhyoung", ""], ["Cho", "Kyunghyun", ""], ["Kang", "Wanmo", ""]]}, {"id": "1909.11304", "submitter": "Ethan Dyer", "authors": "Ethan Dyer, Guy Gur-Ari", "title": "Asymptotics of Wide Networks from Feynman Diagrams", "comments": "10 pages, 3 figures, 1 Table + Appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the asymptotic behavior of wide networks is of considerable\ninterest. In this work, we present a general method for analyzing this large\nwidth behavior. The method is an adaptation of Feynman diagrams, a standard\ntool for computing multivariate Gaussian integrals. We apply our method to\nstudy training dynamics, improving existing bounds and deriving new results on\nwide network evolution during stochastic gradient descent. Going beyond the\nstrict large width limit, we present closed-form expressions for higher-order\nterms governing wide network training, and test these predictions empirically.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 06:29:20 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Dyer", "Ethan", ""], ["Gur-Ari", "Guy", ""]]}, {"id": "1909.11313", "submitter": "Bo Tranberg", "authors": "Bo Tranberg, Kasper Koops Kratmann, Jason Stege", "title": "Determining offshore wind installation times using machine learning and\n  open data", "comments": "Offshore WindEurope conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The installation process of offshore wind turbines requires the use of\nexpensive jack-up vessels. These vessels regularly report their position via\nthe Automatic Identification System (AIS). This paper introduces a novel\napproach of applying machine learning to AIS data from jack-up vessels. We\napply the new method to 13 offshore wind farms in Danish, German and British\nwaters. For each of the wind farms we identify individual turbine locations,\nindividual installation times, time in transit and time in harbor for the\nrespective vessel. This is done in an automated way exclusively using AIS data\nwith no prior knowledge of turbine locations, thus enabling a detailed\ndescription of the entire installation process.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 07:18:29 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 11:02:01 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Tranberg", "Bo", ""], ["Kratmann", "Kasper Koops", ""], ["Stege", "Jason", ""]]}, {"id": "1909.11373", "submitter": "Jiachen Li", "authors": "Jiachen Li, Quan Vuong, Shuang Liu, Minghua Liu, Kamil Ciosek, Keith\n  Ross, Henrik Iskov Christensen, Hao Su", "title": "Multi-task Batch Reinforcement Learning with Metric Learning", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the Multi-task Batch Reinforcement Learning problem. Given multiple\ndatasets collected from different tasks, we train a multi-task policy to\nperform well in unseen tasks sampled from the same distribution. The task\nidentities of the unseen tasks are not provided. To perform well, the policy\nmust infer the task identity from collected transitions by modelling its\ndependency on states, actions and rewards. Because the different datasets may\nhave state-action distributions with large divergence, the task inference\nmodule can learn to ignore the rewards and spuriously correlate $\\textit{only}$\nstate-action pairs to the task identity, leading to poor test time performance.\nTo robustify task inference, we propose a novel application of the triplet\nloss. To mine hard negative examples, we relabel the transitions from the\ntraining tasks by approximating their reward functions. When we allow further\ntraining on the unseen tasks, using the trained policy as an initialization\nleads to significantly faster convergence compared to randomly initialized\npolicies (up to $80\\%$ improvement and across 5 different Mujoco task\ndistributions). We name our method $\\textbf{MBML}$\n($\\textbf{M}\\text{ulti-task}$ $\\textbf{B}\\text{atch}$ RL with\n$\\textbf{M}\\text{etric}$ $\\textbf{L}\\text{earning}$).\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:49:01 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 20:57:44 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 08:31:42 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 03:58:33 GMT"}, {"version": "v5", "created": "Thu, 1 Oct 2020 20:12:10 GMT"}, {"version": "v6", "created": "Fri, 23 Oct 2020 20:01:46 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Li", "Jiachen", ""], ["Vuong", "Quan", ""], ["Liu", "Shuang", ""], ["Liu", "Minghua", ""], ["Ciosek", "Kamil", ""], ["Ross", "Keith", ""], ["Christensen", "Henrik Iskov", ""], ["Su", "Hao", ""]]}, {"id": "1909.11396", "submitter": "Kristoffer Wickstr{\\o}m", "authors": "Kristoffer Wickstr{\\o}m, Sigurd L{\\o}kse, Michael Kampffmeyer, Shujian\n  Yu, Jose Principe, Robert Jenssen", "title": "Information Plane Analysis of Deep Neural Networks via Matrix-Based\n  Renyi's Entropy and Tensor Kernels", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing deep neural networks (DNNs) via information plane (IP) theory has\ngained tremendous attention recently as a tool to gain insight into, among\nothers, their generalization ability. However, it is by no means obvious how to\nestimate mutual information (MI) between each hidden layer and the\ninput/desired output, to construct the IP. For instance, hidden layers with\nmany neurons require MI estimators with robustness towards the high\ndimensionality associated with such layers. MI estimators should also be able\nto naturally handle convolutional layers, while at the same time being\ncomputationally tractable to scale to large networks. None of the existing IP\nmethods to date have been able to study truly deep Convolutional Neural\nNetworks (CNNs), such as the e.g.\\ VGG-16. In this paper, we propose an IP\nanalysis using the new matrix--based R\\'enyi's entropy coupled with tensor\nkernels over convolutional layers, leveraging the power of kernel methods to\nrepresent properties of the probability distribution independently of the\ndimensionality of the data. The obtained results shed new light on the previous\nliterature concerning small-scale DNNs, however using a completely new\napproach. Importantly, the new framework enables us to provide the first\ncomprehensive IP analysis of contemporary large-scale DNNs and CNNs,\ninvestigating the different training phases and providing new insights into the\ntraining dynamics of large-scale neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 10:42:39 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wickstr\u00f8m", "Kristoffer", ""], ["L\u00f8kse", "Sigurd", ""], ["Kampffmeyer", "Michael", ""], ["Yu", "Shujian", ""], ["Principe", "Jose", ""], ["Jenssen", "Robert", ""]]}, {"id": "1909.11406", "submitter": "Thiago Andrade", "authors": "Thiago Andrade, Brais Cancela and Jo\\~ao Gama", "title": "Mining Human Mobility Data to Discover Locations and Habits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many aspects of life are associated with places of human mobility patterns\nand nowadays we are facing an increase in the pervasiveness of mobile devices\nthese individuals carry. Positioning technologies that serve these devices such\nas the cellular antenna (GSM networks), global navigation satellite systems\n(GPS), and more recently the WiFi positioning system (WPS) provide large\namounts of spatio-temporal data in a continuous way. Therefore, detecting\nsignificant places and the frequency of movements between them is fundamental\nto understand human behavior. In this paper, we propose a method for\ndiscovering user habits without any a priori or external knowledge by\nintroducing a density-based clustering for spatio-temporal data to identify\nmeaningful places and by applying a Gaussian Mixture Model (GMM) over the set\nof meaningful places to identify the representations of individual habits. To\nevaluate the proposed method we use two real-world datasets. One dataset\ncontains high-density GPS data and the other one contains GSM mobile phone data\nin a coarse representation. The results show that the proposed method is\nsuitable for this task as many unique habits were identified. This can be used\nfor understanding users' behavior and to draw their characterizing profiles\nhaving a panorama of the mobility patterns from the data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 11:03:32 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Andrade", "Thiago", ""], ["Cancela", "Brais", ""], ["Gama", "Jo\u00e3o", ""]]}, {"id": "1909.11426", "submitter": "Abhinav Srivastav", "authors": "Nguyen Kim Thang and Abhinav Srivastav", "title": "Online Non-Monotone DR-submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study fundamental problems of maximizing DR-submodular\ncontinuous functions that have real-world applications in the domain of machine\nlearning, economics, operations research and communication systems. It captures\na subclass of non-convex optimization that provides both theoretical and\npractical guarantees. Here, we focus on minimizing regret for online arriving\nnon-monotone DR-submodular functions over different types of convex sets:\nhypercube, down-closed and general convex sets.\n  First, we present an online algorithm that achieves a $1/e$-approximation\nratio with the regret of $O(T^{2/3})$ for maximizing DR-submodular functions\nover any down-closed convex set. Note that, the approximation ratio of $1/e$\nmatches the best-known guarantee for the offline version of the problem.\nMoreover, when the convex set is the hypercube, we propose a tight\n1/2-approximation algorithm with regret bound of $O(\\sqrt{T})$. Next, we give\nan online algorithm that achieves an approximation guarantee (depending on the\nsearch space) for the problem of maximizing non-monotone continuous\nDR-submodular functions over a \\emph{general} convex set (not necessarily\ndown-closed). To best of our knowledge, no prior algorithm with approximation\nguarantee was known for non-monotone DR-submodular maximization in the online\nsetting. Finally we run experiments to verify the performance of our algorithms\non problems arising in machine learning domain with the real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:06:39 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 18:22:16 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Thang", "Nguyen Kim", ""], ["Srivastav", "Abhinav", ""]]}, {"id": "1909.11446", "submitter": "Jialin Liu", "authors": "Jialin Liu and Fei Chao and Longzhi Yang and Chih-Min Lin and Qiang\n  Shen", "title": "Decoder Choice Network for Meta-Learning", "comments": "13papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning has been widely used for implementing few-shot learning and\nfast model adaptation. One kind of meta-learning methods attempt to learn how\nto control the gradient descent process in order to make the gradient-based\nlearning have high speed and generalization. This work proposes a method that\ncontrols the gradient descent process of the model parameters of a neural\nnetwork by limiting the model parameters in a low-dimensional latent space. The\nmain challenge of this idea is that a decoder with too many parameters is\nrequired. This work designs a decoder with typical structure and shares a part\nof weights in the decoder to reduce the number of the required parameters.\nBesides, this work has introduced ensemble learning to work with the proposed\napproach for improving performance. The results show that the proposed approach\nis witnessed by the superior performance over the Omniglot classification and\nthe miniImageNet classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:43:53 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:55:35 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Jialin", ""], ["Chao", "Fei", ""], ["Yang", "Longzhi", ""], ["Lin", "Chih-Min", ""], ["Shen", "Qiang", ""]]}, {"id": "1909.11448", "submitter": "Mireille El Gheche", "authors": "Guillermo Ortiz-Jimenez, Mireille El Gheche, Effrosyni Simou, Hermina\n  Petric Maretic, Pascal Frossard", "title": "Forward-Backward Splitting for Optimal Transport based Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport aims to estimate a transportation plan that minimizes a\ndisplacement cost. This is realized by optimizing the scalar product between\nthe sought plan and the given cost, over the space of doubly stochastic\nmatrices. When the entropy regularization is added to the problem, the\ntransportation plan can be efficiently computed with the Sinkhorn algorithm.\nThanks to this breakthrough, optimal transport has been progressively extended\nto machine learning and statistical inference by introducing additional\napplication-specific terms in the problem formulation. It is however\nchallenging to design efficient optimization algorithms for optimal transport\nbased extensions. To overcome this limitation, we devise a general\nforward-backward splitting algorithm based on Bregman distances for solving a\nwide range of optimization problems involving a differentiable function with\nLipschitz-continuous gradient and a doubly stochastic constraint. We illustrate\nthe efficiency of our approach in the context of continuous domain adaptation.\nExperiments show that the proposed method leads to a significant improvement in\nterms of speed and performance with respect to the state of the art for domain\nadaptation on a continually rotating distribution coming from the standard two\nmoon dataset.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 03:43:35 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 13:07:09 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 16:39:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ortiz-Jimenez", "Guillermo", ""], ["Gheche", "Mireille El", ""], ["Simou", "Effrosyni", ""], ["Maretic", "Hermina Petric", ""], ["Frossard", "Pascal", ""]]}, {"id": "1909.11459", "submitter": "Gregor Simm", "authors": "Gregor N. C. Simm and Jos\\'e Miguel Hern\\'andez-Lobato", "title": "A Generative Model for Molecular Distance Geometry", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Great computational effort is invested in generating equilibrium states for\nmolecular systems using, for example, Markov chain Monte Carlo. We present a\nprobabilistic model that generates statistically independent samples for\nmolecules from their graph representations. Our model learns a low-dimensional\nmanifold that preserves the geometry of local atomic neighborhoods through a\nprincipled learning representation that is based on Euclidean distance\ngeometry. In a new benchmark for molecular conformation generation, we show\nexperimentally that our generative model achieves state-of-the-art accuracy.\nFinally, we show how to use our model as a proposal distribution in an\nimportance sampling scheme to compute molecular properties.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:56:50 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 09:49:40 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 18:07:06 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 17:06:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Simm", "Gregor N. C.", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1909.11472", "submitter": "Guillaume Godin", "authors": "Ruud van Deursen and Guillaume Godin", "title": "Deep Generative Model for Sparse Graphs using Text-Based Learning with\n  Augmentation in Generative Examination Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graphs and networks are a key research tool for a variety of science fields,\nmost notably chemistry, biology, engineering and social sciences. Modeling and\ngeneration of graphs with efficient sampling is a key challenge for graphs. In\nparticular, the non-uniqueness, high dimensionality of the vertices and local\ndependencies of the edges may render the task challenging. We apply our\nrecently introduced method, Generative Examination Networks (GENs) to create\nthe first text-based generative graph models using one-line text formats as\ngraph representation. In our GEN, a RNN-generative model for a one-line text\nformat learns autonomously to predict the next available character. The\ntraining is stopped by an examination mechanism checking validating the\npercentage of valid graphs generated. We achieved moderate to high validity\nusing dense g6 strings (random 67.8 +/- 0.6, canonical 99.1 +/- 0.2). Based on\nthese results we have adapted the widely used SMILES representation for\nmolecules to a new input format, which we call linear graph input (LGI). Apart\nfrom the benefits of a short compressible text-format, a major advantage\ninclude the possibility to randomize and augment the format. The generative\nmodels are evaluated for overall performance and for reconstruction of the\nproperty space. The results show that LGI strings are very well suited for\nmachine-learning and that augmentation is essential for the performance of the\nmodel in terms of validity, uniqueness and novelty. Lastly, the format can\naddress smaller and larger dataset of graphs and the format can be easily\nadapted to define another meaning of the characters used in the LGI-string and\ncan address sparse graph problems in used in other fields of science.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:50:37 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["van Deursen", "Ruud", ""], ["Godin", "Guillaume", ""]]}, {"id": "1909.11480", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, David \\'Alvarez, Vicen\\c{c} G\\'omez, Olga Slizovskaia,\n  Jos\\'e F. N\\'u\\~nez, Jordi Luque", "title": "Input complexity and out-of-distribution detection with likelihood-based\n  generative models", "comments": "Accepted for ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-based generative models are a promising resource to detect\nout-of-distribution (OOD) inputs which could compromise the robustness or\nreliability of a machine learning system. However, likelihoods derived from\nsuch models have been shown to be problematic for detecting certain types of\ninputs that significantly differ from training data. In this paper, we pose\nthat this problem is due to the excessive influence that input complexity has\nin generative models' likelihoods. We report a set of experiments supporting\nthis hypothesis, and use an estimate of input complexity to derive an efficient\nand parameter-free OOD score, which can be seen as a likelihood-ratio, akin to\nBayesian model comparison. We find such score to perform comparably to, or even\nbetter than, existing OOD detection approaches under a wide range of data sets,\nmodels, model sizes, and complexity estimates.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:27:53 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 10:46:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 10:38:05 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["\u00c1lvarez", "David", ""], ["G\u00f3mez", "Vicen\u00e7", ""], ["Slizovskaia", "Olga", ""], ["N\u00fa\u00f1ez", "Jos\u00e9 F.", ""], ["Luque", "Jordi", ""]]}, {"id": "1909.11500", "submitter": "Sebastian Goldt", "authors": "Sebastian Goldt, Marc M\\'ezard, Florent Krzakala, Lenka Zdeborov\\'a", "title": "Modelling the influence of data structure on learning in neural\n  networks: the hidden manifold model", "comments": null, "journal-ref": "Physical Review X, Vol. 10, No. 4 (2020)", "doi": "10.1103/PhysRevX.10.041044", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the reasons for the success of deep neural networks trained\nusing stochastic gradient-based methods is a key open problem for the nascent\ntheory of deep learning. The types of data where these networks are most\nsuccessful, such as images or sequences of speech, are characterised by\nintricate correlations. Yet, most theoretical work on neural networks does not\nexplicitly model training data, or assumes that elements of each data sample\nare drawn independently from some factorised probability distribution. These\napproaches are thus by construction blind to the correlation structure of\nreal-world data sets and their impact on learning in neural networks. Here, we\nintroduce a generative model for structured data sets that we call the hidden\nmanifold model (HMM). The idea is to construct high-dimensional inputs that lie\non a lower-dimensional manifold, with labels that depend only on their position\nwithin this manifold, akin to a single layer decoder or generator in a\ngenerative adversarial network. We demonstrate that learning of the hidden\nmanifold model is amenable to an analytical treatment by proving a \"Gaussian\nEquivalence Property\" (GEP), and we use the GEP to show how the dynamics of\ntwo-layer neural networks trained using one-pass stochastic gradient descent is\ncaptured by a set of integro-differential equations that track the performance\nof the network at all times. This permits us to analyse in detail how a neural\nnetwork learns functions of increasing complexity during training, how its\nperformance depends on its size and how it is impacted by parameters such as\nthe learning rate or the dimension of the hidden manifold.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:56:56 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 15:57:34 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 14:15:45 GMT"}, {"version": "v4", "created": "Thu, 3 Dec 2020 16:48:43 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Goldt", "Sebastian", ""], ["M\u00e9zard", "Marc", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1909.11501", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Stephen Roberts, Chris Holmes", "title": "Disentangling to Cluster: Gaussian Mixture Variational Ladder\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clustering we normally output one cluster variable for each datapoint.\nHowever it is not necessarily the case that there is only one way to partition\na given dataset into cluster components. For example, one could cluster objects\nby their colour, or by their type. Different attributes form a hierarchy, and\nwe could wish to cluster in any of them. By disentangling the learnt latent\nrepresentations of some dataset into different layers for different attributes\nwe can then cluster in those latent spaces. We call this \"disentangled\nclustering\". Extending Variational Ladder Autoencoders (Zhao et al., 2017), we\npropose a clustering algorithm, VLAC, that outperforms a Gaussian Mixture DGM\nin cluster accuracy over digit identity on the test set of SVHN. We also\ndemonstrate learning clusters jointly over numerous layers of the hierarchy of\nlatent variables for the data, and show component-wise generation from this\nhierarchical model.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:05:02 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 17:37:25 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Willetts", "Matthew", ""], ["Roberts", "Stephen", ""], ["Holmes", "Chris", ""]]}, {"id": "1909.11507", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Alexander Camuto, Stephen Roberts, Chris Holmes", "title": "Regularising Deep Networks with Deep Generative Models", "comments": "8 pages plus appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new method for regularising neural networks. We learn a\nprobability distribution over the activations of all layers of the model and\nthen insert imputed values into the network during training. We obtain a\nposterior for an arbitrary subset of activations conditioned on the remainder.\nThis is a generalisation of data augmentation to the hidden layers of a\nnetwork, and a form of data-aware dropout. We demonstrate that our training\nmethod leads to higher test accuracy and lower test-set cross-entropy for\nneural networks trained on CIFAR-10 and SVHN compared to standard\nregularisation baselines: our approach leads to networks with better calibrated\nuncertainty over the class posteriors all the while delivering greater test-set\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:14:04 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 17:05:10 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Willetts", "Matthew", ""], ["Camuto", "Alexander", ""], ["Roberts", "Stephen", ""], ["Holmes", "Chris", ""]]}, {"id": "1909.11515", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Kun Xu, Jun Zhu", "title": "Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been widely recognized that adversarial examples can be easily crafted\nto fool deep networks, which mainly root from the locally non-linear behavior\nnearby input examples. Applying mixup in training provides an effective\nmechanism to improve generalization performance and model robustness against\nadversarial perturbations, which introduces the globally linear behavior\nin-between training examples. However, in previous work, the mixup-trained\nmodels only passively defend adversarial attacks in inference by directly\nclassifying the inputs, where the induced global linearity is not well\nexploited. Namely, since the locality of the adversarial perturbations, it\nwould be more efficient to actively break the locality via the globality of the\nmodel predictions. Inspired by simple geometric intuition, we develop an\ninference principle, named mixup inference (MI), for mixup-trained models. MI\nmixups the input with other random clean samples, which can shrink and transfer\nthe equivalent perturbation if the input is adversarial. Our experiments on\nCIFAR-10 and CIFAR-100 demonstrate that MI can further improve the adversarial\nrobustness for the models trained by mixup and its variants.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:21:55 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 08:54:57 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Pang", "Tianyu", ""], ["Xu", "Kun", ""], ["Zhu", "Jun", ""]]}, {"id": "1909.11522", "submitter": "Guillermo Valle-P\\'erez", "authors": "Chris Mingard, Joar Skalse, Guillermo Valle-P\\'erez, David\n  Mart\\'inez-Rubio, Vladimir Mikulik, Ard A. Louis", "title": "Neural networks are a priori biased towards Boolean functions with low\n  entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the inductive bias of neural networks is critical to explaining\ntheir ability to generalise. Here, for one of the simplest neural networks -- a\nsingle-layer perceptron with n input neurons, one output neuron, and no\nthreshold bias term -- we prove that upon random initialisation of weights, the\na priori probability P(t) that it represents a Boolean function that classifies\nt points in {0,1}^n as 1 has a remarkably simple form: P(t) = 2^{-n} for 0\\leq\nt < 2^n.\n  Since a perceptron can express far fewer Boolean functions with small or\nlarge values of t (low entropy) than with intermediate values of t (high\nentropy) there is, on average, a strong intrinsic a-priori bias towards\nindividual functions with low entropy. Furthermore, within a class of functions\nwith fixed t, we often observe a further intrinsic bias towards functions of\nlower complexity. Finally, we prove that, regardless of the distribution of\ninputs, the bias towards low entropy becomes monotonically stronger upon adding\nReLU layers, and empirically show that increasing the variance of the bias term\nhas a similar effect.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:29:45 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 15:57:00 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 21:47:42 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mingard", "Chris", ""], ["Skalse", "Joar", ""], ["Valle-P\u00e9rez", "Guillermo", ""], ["Mart\u00ednez-Rubio", "David", ""], ["Mikulik", "Vladimir", ""], ["Louis", "Ard A.", ""]]}, {"id": "1909.11527", "submitter": "Li Wang", "authors": "Leihong Zhang, Li Wang, Zhaojun Bai and Ren-cang Li", "title": "A Self-consistent-field Iteration for Orthogonal Canonical Correlation\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient algorithm for solving orthogonal canonical\ncorrelation analysis (OCCA) in the form of trace-fractional structure and\northogonal linear projections. Even though orthogonality has been widely used\nand proved to be a useful criterion for pattern recognition and feature\nextraction, existing methods for solving OCCA problem are either numerical\nunstable by relying on a deflation scheme, or less efficient by directly using\ngeneric optimization methods. In this paper, we propose an alternating\nnumerical scheme whose core is the sub-maximization problem in the\ntrace-fractional form with an orthogonal constraint. A customized\nself-consistent-field (SCF) iteration for this sub-maximization problem is\ndevised. It is proved that the SCF iteration is globally convergent to a KKT\npoint and that the alternating numerical scheme always converges. We further\nformulate a new trace-fractional maximization problem for orthogonal multiset\nCCA (OMCCA) and then propose an efficient algorithm with an either Jacobi-style\nor Gauss-Seidel-style updating scheme based on the same SCF iteration.\nExtensive experiments are conducted to evaluate the proposed algorithms against\nexisting methods including two real world applications: multi-label\nclassification and multi-view feature extraction. Experimental results show\nthat our methods not only perform competitively to or better than baselines but\nalso are more efficient.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:34:31 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Zhang", "Leihong", ""], ["Wang", "Li", ""], ["Bai", "Zhaojun", ""], ["Li", "Ren-cang", ""]]}, {"id": "1909.11532", "submitter": "Yangang Chen", "authors": "Yangang Chen, Justin W. L. Wan", "title": "Deep Neural Network Framework Based on Backward Stochastic Differential\n  Equations for Pricing and Hedging American Options in High Dimensions", "comments": "35 pages, 11 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep neural network framework for computing prices and deltas of\nAmerican options in high dimensions. The architecture of the framework is a\nsequence of neural networks, where each network learns the difference of the\nprice functions between adjacent timesteps. We introduce the least squares\nresidual of the associated backward stochastic differential equation as the\nloss function. Our proposed framework yields prices and deltas on the entire\nspacetime, not only at a given point. The computational cost of the proposed\napproach is quadratic in dimension, which addresses the curse of dimensionality\nissue that state-of-the-art approaches suffer. Our numerical simulations\ndemonstrate these contributions, and show that the proposed neural network\nframework outperforms state-of-the-art approaches in high dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:50:24 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Chen", "Yangang", ""], ["Wan", "Justin W. L.", ""]]}, {"id": "1909.11538", "submitter": "Majid Moghadam", "authors": "Ali Alizadeh, Majid Moghadam, Yunus Bicer, Nazim Kemal Ure, Ugur\n  Yavas, Can Kurtulus", "title": "Automated Lane Change Decision Making using Deep Reinforcement Learning\n  in Dynamic and Uncertain Highway Environment", "comments": "Accepted to IEEE Intelligent Transportation Systems Conference - ITSC\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous lane changing is a critical feature for advanced autonomous\ndriving systems, that involves several challenges such as uncertainty in other\ndriver's behaviors and the trade-off between safety and agility. In this work,\nwe develop a novel simulation environment that emulates these challenges and\ntrain a deep reinforcement learning agent that yields consistent performance in\na variety of dynamic and uncertain traffic scenarios. Results show that the\nproposed data-driven approach performs significantly better in noisy\nenvironments compared to methods that rely solely on heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:27:07 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Alizadeh", "Ali", ""], ["Moghadam", "Majid", ""], ["Bicer", "Yunus", ""], ["Ure", "Nazim Kemal", ""], ["Yavas", "Ugur", ""], ["Kurtulus", "Can", ""]]}, {"id": "1909.11542", "submitter": "Gabriel Ryan", "authors": "Gabriel Ryan, Justin Wong, Jianan Yao, Ronghui Gu, Suman Jana", "title": "CLN2INV: Learning Loop Invariants with Continuous Logic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program verification offers a framework for ensuring program correctness and\ntherefore systematically eliminating different classes of bugs. Inferring loop\ninvariants is one of the main challenges behind automated verification of\nreal-world programs which often contain many loops. In this paper, we present\nContinuous Logic Network (CLN), a novel neural architecture for automatically\nlearning loop invariants directly from program execution traces. Unlike\nexisting neural networks, CLNs can learn precise and explicit representations\nof formulas in Satisfiability Modulo Theories (SMT) for loop invariants from\nprogram execution traces. We develop a new sound and complete semantic mapping\nfor assigning SMT formulas to continuous truth values that allows CLNs to be\ntrained efficiently. We use CLNs to implement a new inference system for loop\ninvariants, CLN2INV, that significantly outperforms existing approaches on the\npopular Code2Inv dataset. CLN2INV is the first tool to solve all 124\ntheoretically solvable problems in the Code2Inv dataset. Moreover, CLN2INV\ntakes only 1.1 seconds on average for each problem, which is 40 times faster\nthan existing approaches. We further demonstrate that CLN2INV can even learn 12\nsignificantly more complex loop invariants than the ones required for the\nCode2Inv dataset.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:05:02 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:54:09 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 16:07:49 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Ryan", "Gabriel", ""], ["Wong", "Justin", ""], ["Yao", "Jianan", ""], ["Gu", "Ronghui", ""], ["Jana", "Suman", ""]]}, {"id": "1909.11544", "submitter": "Aleksandr Koriagin", "authors": "Alexander Koryagin, Roman Khudorozkov, Sergey Tsimfer", "title": "PyDEns: a Python Framework for Solving Differential Equations with\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a lot of papers proposed to use neural networks to approximately\nsolve partial differential equations (PDEs). Yet, there has been a lack of\nflexible framework for convenient experimentation. In an attempt to fill the\ngap, we introduce a PyDEns-module open-sourced on GitHub. Coupled with\ncapabilities of BatchFlow, open-source framework for convenient and\nreproducible deep learning, PyDEns-module allows to 1) solve partial\ndifferential equations from a large family, including heat equation and wave\nequation 2) easily search for the best neural-network architecture among the\nzoo, that includes ResNet and DenseNet 3) fully control the process of\nmodel-training by testing different point-sampling schemes. With that in mind,\nour main contribution goes as follows: implementation of a ready-to-use and\nopen-source numerical solver of PDEs of a novel format, based on neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:06:26 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Koryagin", "Alexander", ""], ["Khudorozkov", "Roman", ""], ["Tsimfer", "Sergey", ""]]}, {"id": "1909.11553", "submitter": "Alix Lh\\'eritier", "authors": "Alix Lh\\'eritier", "title": "PCMC-Net: Feature-based Pairwise Choice Markov Chains", "comments": "Final version to be published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise Choice Markov Chains (PCMC) have been recently introduced to\novercome limitations of choice models based on traditional axioms unable to\nexpress empirical observations from modern behavior economics like context\neffects occurring when a choice between two options is altered by adding a\nthird alternative. The inference approach that estimates the transition rates\nbetween each possible pair of alternatives via maximum likelihood suffers when\nthe examples of each alternative are scarce and is inappropriate when new\nalternatives can be observed at test time. In this work, we propose an\namortized inference approach for PCMC by embedding its definition into a neural\nnetwork that represents transition rates as a function of the alternatives' and\nindividual's features. We apply our construction to the complex case of airline\nitinerary booking where singletons are common (due to varying prices and\nindividual-specific itineraries), and context effects and behaviors strongly\ndependent on market segments are observed. Experiments show our network\nsignificantly outperforming, in terms of prediction accuracy and logarithmic\nloss, feature engineered standard and latent class Multinomial Logit models as\nwell as recent machine learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:30:38 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 14:48:18 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lh\u00e9ritier", "Alix", ""]]}, {"id": "1909.11556", "submitter": "Angela Fan", "authors": "Angela Fan, Edouard Grave, Armand Joulin", "title": "Reducing Transformer Depth on Demand with Structured Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized transformer networks have obtained state of the art results\nin various natural language processing tasks, such as machine translation,\nlanguage modeling, and question answering. These models contain hundreds of\nmillions of parameters, necessitating a large amount of computation and making\nthem prone to overfitting. In this work, we explore LayerDrop, a form of\nstructured dropout, which has a regularization effect during training and\nallows for efficient pruning at inference time. In particular, we show that it\nis possible to select sub-networks of any depth from one large network without\nhaving to finetune them and with limited impact on performance. We demonstrate\nthe effectiveness of our approach by improving the state of the art on machine\ntranslation, language modeling, summarization, question answering, and language\nunderstanding benchmarks. Moreover, we show that our approach leads to small\nBERT-like models of higher quality compared to training from scratch or using\ndistillation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:35:03 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Fan", "Angela", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""]]}, {"id": "1909.11564", "submitter": "Giacomo Aletti", "authors": "Giacomo Aletti", "title": "Analytical confidence intervals for the number of different objects in\n  data streams", "comments": "accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.CO stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper develops a new mathematical-statistical approach to analyze a\nclass of Flajolet-Martin algorithms (FMa), and provides analytical confidence\nintervals for the number F0 of distinct elements in a stream, based on Chernoff\nbounds. The class of FMa has reached a significant popularity in bigdata stream\nlearning, and the attention of the literature has mainly been based on\nalgorithmic aspects, basically complexity optimality, while the statistical\nanalysis of these class of algorithms has been often faced heuristically. The\nanalysis provided here shows deep connections with mathematical special\nfunctions and with extreme value theory. The latter connection may help in\nexplaining heuristic considerations, while the first opens many numerical\nissues, faced at the end of the present paper. Finally, the algorithms are\ntested on an anonymized real data stream and MonteCarlo simulations are\nprovided to support our analytical choice in this context.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:46:11 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 10:37:18 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 16:50:17 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Aletti", "Giacomo", ""]]}, {"id": "1909.11572", "submitter": "Dar Gilboa", "authors": "Dar Gilboa and Guy Gur-Ari", "title": "Wider Networks Learn Better Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferability of learned features between tasks can massively reduce the\ncost of training a neural network on a novel task. We investigate the effect of\nnetwork width on learned features using activation atlases --- a visualization\ntechnique that captures features the entire hidden state responds to, as\nopposed to individual neurons alone. We find that, while individual neurons do\nnot learn interpretable features in wide networks, groups of neurons do. In\naddition, the hidden state of a wide network contains more information about\nthe inputs than that of a narrow network trained to the same test accuracy.\nInspired by this observation, we show that when fine-tuning the last layer of a\nnetwork on a new task, performance improves significantly as the width of the\nnetwork is increased, even though test accuracy on the original task is\nindependent of width.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:00:27 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Gilboa", "Dar", ""], ["Gur-Ari", "Guy", ""]]}, {"id": "1909.11580", "submitter": "Yuguang Wang", "authors": "Yu Guang Wang, Ming Li, Zheng Ma, Guido Montufar, Xiaosheng Zhuang,\n  Yanan Fan", "title": "Haar Graph Pooling", "comments": "14 pages, 4 figures, 7 tables; Published in ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Graph Neural Networks (GNNs) are useful models for graph classification\nand graph-based regression tasks. In these tasks, graph pooling is a critical\ningredient by which GNNs adapt to input graphs of varying size and structure.\nWe propose a new graph pooling operation based on compressive Haar transforms\n-- HaarPooling. HaarPooling implements a cascade of pooling operations; it is\ncomputed by following a sequence of clusterings of the input graph. A\nHaarPooling layer transforms a given input graph to an output graph with a\nsmaller node number and the same feature dimension; the compressive Haar\ntransform filters out fine detail information in the Haar wavelet domain. In\nthis way, all the HaarPooling layers together synthesize the features of any\ngiven input graph into a feature vector of uniform size. Such transforms\nprovide a sparse characterization of the data and preserve the structure\ninformation of the input graph. GNNs implemented with standard graph\nconvolution layers and HaarPooling layers achieve state of the art performance\non diverse graph classification and regression problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:13:54 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 10:49:45 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 15:10:45 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Wang", "Yu Guang", ""], ["Li", "Ming", ""], ["Ma", "Zheng", ""], ["Montufar", "Guido", ""], ["Zhuang", "Xiaosheng", ""], ["Fan", "Yanan", ""]]}, {"id": "1909.11583", "submitter": "Simon Schmitt", "authors": "Simon Schmitt, Matteo Hessel, Karen Simonyan", "title": "Off-Policy Actor-Critic with Shared Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the combination of actor-critic reinforcement learning\nalgorithms with uniform large-scale experience replay and propose solutions for\ntwo challenges: (a) efficient actor-critic learning with experience replay (b)\nstability of off-policy learning where agents learn from other agents\nbehaviour. We employ those insights to accelerate hyper-parameter sweeps in\nwhich all participating agents run concurrently and share their experience via\na common replay module. To this end we analyze the bias-variance tradeoffs in\nV-trace, a form of importance sampling for actor-critic methods. Based on our\nanalysis, we then argue for mixing experience sampled from replay with\non-policy experience, and propose a new trust region scheme that scales\neffectively to data distributions where V-trace becomes unstable. We provide\nextensive empirical validation of the proposed solution. We further show the\nbenefits of this setup by demonstrating state-of-the-art data efficiency on\nAtari among agents trained up until 200M environment frames.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:20:46 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 12:51:59 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Schmitt", "Simon", ""], ["Hessel", "Matteo", ""], ["Simonyan", "Karen", ""]]}, {"id": "1909.11588", "submitter": "Zhanfu Yang", "authors": "Ziliang Chen, Zhanfu Yang", "title": "Graph Neural Reasoning May Fail in Certifying Boolean Unsatisfiability", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is feasible and practically-valuable to bridge the characteristics between\ngraph neural networks (GNNs) and logical reasoning. Despite considerable\nefforts and successes witnessed to solve Boolean satisfiability (SAT), it\nremains a mystery of GNN-based solvers for more complex predicate logic\nformulae. In this work, we conjectures with some evidences, that\ngenerally-defined GNNs present several limitations to certify the\nunsatisfiability (UNSAT) in Boolean formulae. It implies that GNNs may probably\nfail in learning the logical reasoning tasks if they contain proving UNSAT as\nthe sub-problem included by most predicate logic formulae.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:24:50 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 16:57:26 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Chen", "Ziliang", ""], ["Yang", "Zhanfu", ""]]}, {"id": "1909.11591", "submitter": "Mohammadhosein Hasanbeig", "authors": "Lim Zun Yuan, Mohammadhosein Hasanbeig, Alessandro Abate, Daniel\n  Kroening", "title": "Modular Deep Reinforcement Learning with Temporal Logic Specifications", "comments": "arXiv admin note: text overlap with arXiv:1902.00778", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an actor-critic, model-free, and online Reinforcement Learning\n(RL) framework for continuous-state continuous-action Markov Decision Processes\n(MDPs) when the reward is highly sparse but encompasses a high-level temporal\nstructure. We represent this temporal structure by a finite-state machine and\nconstruct an on-the-fly synchronised product with the MDP and the finite\nmachine. The temporal structure acts as a guide for the RL agent within the\nproduct, where a modular Deep Deterministic Policy Gradient (DDPG) architecture\nis proposed to generate a low-level control policy. We evaluate our framework\nin a Mars rover experiment and we present the success rate of the synthesised\npolicy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:10:00 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 12:57:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yuan", "Lim Zun", ""], ["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "1909.11594", "submitter": "Sandeep Kumar", "authors": "Sandeep Kumar, Jiaxi Ying, Jos'e Vin'icius de M. Cardoso, and Daniel\n  P.Palomar", "title": "Structured Graph Learning Via Laplacian Spectral Constraints", "comments": "12 Pages, Accepted for NIPS 2019. arXiv admin note: substantial text\n  overlap with arXiv:1904.09792", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a graph with a specific structure is essential for interpretability\nand identification of the relationships among data. It is well known that\nstructured graph learning from observed samples is an NP-hard combinatorial\nproblem. In this paper, we first show that for a set of important graph\nfamilies it is possible to convert the structural constraints of structure into\neigenvalue constraints of the graph Laplacian matrix. Then we introduce a\nunified graph learning framework, lying at the integration of the spectral\nproperties of the Laplacian matrix with Gaussian graphical modeling that is\ncapable of learning structures of a large class of graph families. The proposed\nalgorithms are provably convergent and practically amenable for large-scale\nsemi-supervised and unsupervised graph-based learning tasks. Extensive\nnumerical experiments with both synthetic and real data sets demonstrate the\neffectiveness of the proposed methods. An R package containing code for all the\nexperimental results is available at\nhttps://cran.r-project.org/package=spectralGraphTopology.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:25:10 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Kumar", "Sandeep", ""], ["Ying", "Jiaxi", ""], ["Cardoso", "Jos'e Vin'icius de M.", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "1909.11611", "submitter": "Ivana Bala\\v{z}evi\\'c", "authors": "Carl Allen, Ivana Bala\\v{z}evi\\'c, Timothy Hospedales", "title": "Interpreting Knowledge Graph Relation Representation from Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many models learn representations of knowledge graph data by exploiting its\nlow-rank latent structure, encoding known relations between entities and\nenabling unknown facts to be inferred. To predict whether a relation holds\nbetween entities, embeddings are typically compared in the latent space\nfollowing a relation-specific mapping. Whilst their predictive performance has\nsteadily improved, how such models capture the underlying latent structure of\nsemantic information remains unexplained. Building on recent theoretical\nunderstanding of word embeddings, we categorise knowledge graph relations into\nthree types and for each derive explicit requirements of their representations.\nWe show that empirical properties of relation representations and the relative\nperformance of leading knowledge graph representation methods are justified by\nour analysis.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:49:44 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:02:19 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Allen", "Carl", ""], ["Bala\u017eevi\u0107", "Ivana", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1909.11616", "submitter": "Ching-Yuan Bai", "authors": "Ching-Yuan Bai, Buo-Fu Chen, and Hsuan-Tien Lin", "title": "Benchmarking Tropical Cyclone Rapid Intensification with Satellite\n  Images and Attention-based Deep Models", "comments": "In Proceedings of the The European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD),\n  September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid intensification (RI) of tropical cyclones often causes major\ndestruction to human civilization due to short response time. It is an\nimportant yet challenging task to accurately predict this kind of extreme\nweather event in advance. Traditionally, meteorologists tackle the task with\nhuman-driven feature extraction and predictor correction procedures.\nNevertheless, these procedures do not leverage the power of modern machine\nlearning models and abundant sensor data, such as satellite images. In\naddition, the human-driven nature of such an approach makes it difficult to\nreproduce and benchmark prediction models. In this study, we build a benchmark\nfor RI prediction using only satellite images, which are underutilized in\ntraditional techniques. The benchmark follows conventional data science\npractices, making it easier for data scientists to contribute to RI prediction.\nWe demonstrate the usefulness of the benchmark by designing a domain-inspired\nspatiotemporal deep learning model. The results showcase the promising\nperformance of deep learning in solving complex meteorological problems such as\nRI prediction.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:59:41 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 17:18:25 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Bai", "Ching-Yuan", ""], ["Chen", "Buo-Fu", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1909.11630", "submitter": "Thanh Le", "authors": "Thanh Le, Vasant Honavar", "title": "The Dynamical Gaussian Process Latent Variable Model in the Longitudinal\n  Scenario", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dynamical Gaussian Process Latent Variable Models provide an elegant\nnon-parametric framework for learning the low dimensional representations of\nthe high-dimensional time-series. Real world observational studies, however,\nare often ill-conditioned: the observations can be noisy, not assuming the\nluxury of relatively complete and equally spaced like those in time series.\nSuch conditions make it difficult to learn reasonable representations in the\nhigh dimensional longitudinal data set by way of Gaussian Process Latent\nVariable Model as well as other dimensionality reduction procedures. In this\nstudy, we approach the inference of Gaussian Process Dynamical Systems in\nLongitudinal scenario by augmenting the bound in the variational approximation\nto include systematic samples of the unseen observations. We demonstrate the\nusefulness of this approach on synthetic as well as the human motion capture\ndata set.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:24:51 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Le", "Thanh", ""], ["Honavar", "Vasant", ""]]}, {"id": "1909.11639", "submitter": "Vikash Kumar", "authors": "Michael Ahn, Henry Zhu, Kristian Hartikainen, Hugo Ponte, Abhishek\n  Gupta, Sergey Levine, Vikash Kumar", "title": "ROBEL: Robotics Benchmarks for Learning with Low-Cost Robots", "comments": "Published @ CoRL2019. For details visit -\n  http://www.roboticsbenchmarks.org", "journal-ref": "Conference on Robot Learning, 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ROBEL is an open-source platform of cost-effective robots designed for\nreinforcement learning in the real world. ROBEL introduces two robots, each\naimed to accelerate reinforcement learning research in different task domains:\nD'Claw is a three-fingered hand robot that facilitates learning dexterous\nmanipulation tasks, and D'Kitty is a four-legged robot that facilitates\nlearning agile legged locomotion tasks. These low-cost, modular robots are easy\nto maintain and are robust enough to sustain on-hardware reinforcement learning\nfrom scratch with over 14000 training hours registered on them to date. To\nleverage this platform, we propose an extensible set of continuous control\nbenchmark tasks for each robot. These tasks feature dense and sparse task\nobjectives, and additionally introduce score metrics as hardware-safety. We\nprovide benchmark scores on an initial set of tasks using a variety of\nlearning-based methods. Furthermore, we show that these results can be\nreplicated across copies of the robots located in different institutions. Code,\ndocumentation, design files, detailed assembly instructions, final policies,\nbaseline details, task videos, and all supplementary materials required to\nreproduce the results are available at www.roboticsbenchmarks.org.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:38:52 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 07:16:23 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 01:47:52 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Ahn", "Michael", ""], ["Zhu", "Henry", ""], ["Hartikainen", "Kristian", ""], ["Ponte", "Hugo", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Kumar", "Vikash", ""]]}, {"id": "1909.11640", "submitter": "Lucy Gao", "authors": "Lucy L. Gao, Daniela Witten, Jacob Bien", "title": "Testing for Association in Multi-View Network Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider data consisting of multiple networks, each\ncomprised of a different edge set on a common set of nodes. Many models have\nbeen proposed for the analysis of such multi-view network data under the\nassumption that the data views are closely related. In this paper, we provide\ntools for evaluating this assumption. In particular, we ask: given two networks\nthat each follow a stochastic block model, is there an association between the\nlatent community memberships of the nodes in the two networks? To answer this\nquestion, we extend the stochastic block model for a single network view to the\ntwo-view setting, and develop a new hypothesis test for the null hypothesis\nthat the latent community memberships in the two data views are independent. We\napply our test to protein-protein interaction data from the HINT database (Das\nand Hint, 2012). We find evidence of a weak association between the latent\ncommunity memberships of proteins defined with respect to binary interaction\ndata and the latent community memberships of proteins defined with respect to\nco-complex association data. We also extend this proposal to the setting of a\nnetwork with node covariates.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:41:51 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 19:32:51 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 20:13:00 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Gao", "Lucy L.", ""], ["Witten", "Daniela", ""], ["Bien", "Jacob", ""]]}, {"id": "1909.11651", "submitter": "Manuel P\\'erez-Carrasco", "authors": "Manuel P\\'erez-Carrasco, Guillermo Cabrera-Vives, Pavlos Protopapas,\n  Nicol\\'as Astorga, Marouan Belhaj", "title": "Matching Embeddings for Domain Adaptation", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work we address the problem of transferring knowledge obtained from a\nvast annotated source domain to a low labeled target domain. We propose\nAdversarial Variational Domain Adaptation (AVDA), a semi-supervised domain\nadaptation method based on deep variational embedded representations. We use\napproximate inference and domain adversarial methods to map samples from source\nand target domains into an aligned class-dependent embedding defined as a\nGaussian Mixture Model. AVDA works as a classifier and considers a generative\nmodel that helps this classification. We used digits dataset for\nexperimentation. Our results show that on a semi-supervised few-shot scenario\nour model outperforms previous methods in most of the adaptation tasks, even\nusing a fewer number of labeled samples per class on target domain.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:54:47 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 02:00:18 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 13:39:14 GMT"}, {"version": "v4", "created": "Sun, 24 Jan 2021 06:36:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["P\u00e9rez-Carrasco", "Manuel", ""], ["Cabrera-Vives", "Guillermo", ""], ["Protopapas", "Pavlos", ""], ["Astorga", "Nicol\u00e1s", ""], ["Belhaj", "Marouan", ""]]}, {"id": "1909.11671", "submitter": "Jinsung Yoon", "authors": "Jinsung Yoon, Sercan O. Arik, Tomas Pfister", "title": "Data Valuation using Reinforcement Learning", "comments": "17 pages, 12 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the value of data is a fundamental problem in machine learning.\nData valuation has multiple important use cases: (1) building insights about\nthe learning task, (2) domain adaptation, (3) corrupted sample discovery, and\n(4) robust learning. To adaptively learn data values jointly with the target\ntask predictor model, we propose a meta learning framework which we name Data\nValuation using Reinforcement Learning (DVRL). We employ a data value estimator\n(modeled by a deep neural network) to learn how likely each datum is used in\ntraining of the predictor model. We train the data value estimator using a\nreinforcement signal of the reward obtained on a small validation set that\nreflects performance on the target task. We demonstrate that DVRL yields\nsuperior data value estimates compared to alternative methods across different\ntypes of datasets and in a diverse set of application scenarios. The corrupted\nsample discovery performance of DVRL is close to optimal in many regimes (i.e.\nas if the noisy samples were known apriori), and for domain adaptation and\nrobust learning DVRL significantly outperforms state-of-the-art by 14.6% and\n10.8%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:00:02 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Yoon", "Jinsung", ""], ["Arik", "Sercan O.", ""], ["Pfister", "Tomas", ""]]}, {"id": "1909.11702", "submitter": "Tyler Scott", "authors": "Tyler R. Scott, Karl Ridgeway, Michael C. Mozer", "title": "Stochastic Prototype Embeddings", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised deep-embedding methods project inputs of a domain to a\nrepresentational space in which same-class instances lie near one another and\ndifferent-class instances lie far apart. We propose a probabilistic method that\ntreats embeddings as random variables. Extending a state-of-the-art\ndeterministic method, Prototypical Networks (Snell et al., 2017), our approach\nsupposes the existence of a class prototype around which class instances are\nGaussian distributed. The prototype posterior is a product distribution over\nlabeled instances, and query instances are classified by marginalizing relative\nprototype proximity over embedding uncertainty. We describe an efficient\nsampler for approximate inference that allows us to train the model at roughly\nthe same space and time cost as its deterministic sibling. Incorporating\nuncertainty improves performance on few-shot learning and gracefully handles\nlabel noise and out-of-distribution inputs. Compared to the state-of-the-art\nstochastic method, Hedged Instance Embeddings (Oh et al., 2019), we achieve\nsuperior large- and open-set classification accuracy. Our method also aligns\nclass-discriminating features with the axes of the embedding space, yielding an\ninterpretable, disentangled representation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:38:36 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Scott", "Tyler R.", ""], ["Ridgeway", "Karl", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1909.11715", "submitter": "Alex Lamb", "authors": "Vikas Verma, Meng Qu, Kenji Kawaguchi, Alex Lamb, Yoshua Bengio, Juho\n  Kannala, Jian Tang", "title": "GraphMix: Improved Training of GNNs for Semi-Supervised Learning", "comments": "https://github.com/vikasverma1077/GraphMix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GraphMix, a regularization method for Graph Neural Network based\nsemi-supervised object classification, whereby we propose to train a\nfully-connected network jointly with the graph neural network via parameter\nsharing and interpolation-based regularization. Further, we provide a\ntheoretical analysis of how GraphMix improves the generalization bounds of the\nunderlying graph neural network, without making any assumptions about the\n\"aggregation\" layer or the depth of the graph neural networks. We\nexperimentally validate this analysis by applying GraphMix to various\narchitectures such as Graph Convolutional Networks, Graph Attention Networks\nand Graph-U-Net. Despite its simplicity, we demonstrate that GraphMix can\nconsistently improve or closely match state-of-the-art performance using even\nsimpler architectures such as Graph Convolutional Networks, across three\nestablished graph benchmarks: Cora, Citeseer and Pubmed citation network\ndatasets, as well as three newly proposed datasets: Cora-Full, Co-author-CS and\nCo-author-Physics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:57:39 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 20:49:23 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 22:08:36 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Verma", "Vikas", ""], ["Qu", "Meng", ""], ["Kawaguchi", "Kenji", ""], ["Lamb", "Alex", ""], ["Bengio", "Yoshua", ""], ["Kannala", "Juho", ""], ["Tang", "Jian", ""]]}, {"id": "1909.11720", "submitter": "Guang Cheng", "authors": "Yue Xing, Qifan Song, and Guang Cheng", "title": "Benefit of Interpolation in Nearest Neighbor Algorithms", "comments": "Under review as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The over-parameterized models attract much attention in the era of data\nscience and deep learning. It is empirically observed that although these\nmodels, e.g. deep neural networks, over-fit the training data, they can still\nachieve small testing error, and sometimes even {\\em outperform} traditional\nalgorithms which are designed to avoid over-fitting. The major goal of this\nwork is to sharply quantify the benefit of data interpolation in the context of\nnearest neighbors (NN) algorithm. Specifically, we consider a class of\ninterpolated weighting schemes and then carefully characterize their asymptotic\nperformances. Our analysis reveals a U-shaped performance curve with respect to\nthe level of data interpolation, and proves that a mild degree of data\ninterpolation {\\em strictly} improves the prediction accuracy and statistical\nstability over those of the (un-interpolated) optimal $k$NN algorithm. This\ntheoretically justifies (predicts) the existence of the second U-shaped curve\nin the recently discovered double descent phenomenon. Note that our goal in\nthis study is not to promote the use of interpolated-NN method, but to obtain\ntheoretical insights on data interpolation inspired by the aforementioned\nphenomenon.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:24:24 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Xing", "Yue", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "1909.11722", "submitter": "Tianshi Cao", "authors": "Tianshi Cao, Marc Law, Sanja Fidler", "title": "A Theoretical Analysis of the Number of Shots in Few-Shot Learning", "comments": "15 pages incl. appendix, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification is the task of predicting the category of an example\nfrom a set of few labeled examples. The number of labeled examples per category\nis called the number of shots (or shot number). Recent works tackle this task\nthrough meta-learning, where a meta-learner extracts information from observed\ntasks during meta-training to quickly adapt to new tasks during meta-testing.\nIn this formulation, the number of shots exploited during meta-training has an\nimpact on the recognition performance at meta-test time. Generally, the shot\nnumber used in meta-training should match the one used in meta-testing to\nobtain the best performance. We introduce a theoretical analysis of the impact\nof the shot number on Prototypical Networks, a state-of-the-art few-shot\nclassification method. From our analysis, we propose a simple method that is\nrobust to the choice of shot number used during meta-training, which is a\ncrucial hyperparameter. The performance of our model trained for an arbitrary\nmeta-training shot number shows great performance for different values of\nmeta-testing shot numbers. We experimentally demonstrate our approach on\ndifferent few-shot classification benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:33:05 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 23:24:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Cao", "Tianshi", ""], ["Law", "Marc", ""], ["Fidler", "Sanja", ""]]}, {"id": "1909.11727", "submitter": "Nishant Gurunath", "authors": "Nishant Gurunath, Sai Krishna Rallabandi, Alan Black", "title": "Disentangling Speech and Non-Speech Components for Building Robust\n  Acoustic Models from Found Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to build language technologies for majority of the languages, it is\nimportant to leverage the resources available in public domain on the internet\n- commonly referred to as `Found Data'. However, such data is characterized by\nthe presence of non-standard, non-trivial variations. For instance, speech\nresources found on the internet have non-speech content, such as music.\nTherefore, speech recognition and speech synthesis models need to be robust to\nsuch variations. In this work, we present an analysis to show that it is\nimportant to disentangle the latent causal factors of variation in the original\ndata to accomplish these tasks. Based on this, we present approaches to\ndisentangle such variations from the data using Latent Stochastic Models.\nSpecifically, we present a method to split the latent prior space into\ncontinuous representations of dominant speech modes present in the magnitude\nspectra of audio signals. We propose a completely unsupervised approach using\nmultinode latent space variational autoencoders (VAE). We show that the\nconstraints on the latent space of a VAE can be in-fact used to separate speech\nand music, independent of the language of the speech. This paper also\nanalytically presents the requirement on the number of latent variables for the\ntask based on distribution of the speech data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:37:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Gurunath", "Nishant", ""], ["Rallabandi", "Sai Krishna", ""], ["Black", "Alan", ""]]}, {"id": "1909.11760", "submitter": "Chang Liu", "authors": "Chang Liu, Yanan Xu, Yanmin Zhu", "title": "ALCNN: Attention-based Model for Fine-grained Demand Inference of\n  Dock-less Shared Bike in New Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, dock-less shared bikes have been widely spread across many\ncities in China and facilitate people's lives. However, at the same time, it\nalso raises many problems about dock-less shared bike management due to the\nmismatching between demands and real distribution of bikes. Before deploying\ndock-less shared bikes in a city, companies need to make a plan for dispatching\nbikes from places having excessive bikes to locations with high demands for\nproviding better services. In this paper, we study the problem of inferring\nfine-grained bike demands anywhere in a new city before the deployment of\nbikes. This problem is challenging because new city lacks training data and\nbike demands vary by both places and time. To solve the problem, we provide\nvarious methods to extract discriminative features from multi-source geographic\ndata, such as POI, road networks and nighttime light, for each place. We\nutilize correlation Principle Component Analysis (coPCA) to deal with extracted\nfeatures of both old city and new city to realize distribution adaption. Then,\nwe adopt a discrete wavelet transform (DWT) based model to mine daily patterns\nfor each place from fine-grained bike demand. We propose an attention based\nlocal CNN model, \\textbf{ALCNN}, to infer the daily patterns with latent\nfeatures from coPCA with multiple CNNs for modeling the influence of neighbor\nplaces. In addition, ALCNN merges latent features from multiple CNNs and can\nselect a suitable size of influenced regions. The extensive experiments on\nreal-life datasets show that the proposed approach outperforms competitive\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 21:05:13 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liu", "Chang", ""], ["Xu", "Yanan", ""], ["Zhu", "Yanmin", ""]]}, {"id": "1909.11763", "submitter": "Yunhui Guo", "authors": "Yunhui Guo, Mingrui Liu, Tianbao Yang, Tajana Rosing", "title": "Improved Schemes for Episodic Memory-based Lifelong Learning", "comments": "NeurIPS 2020, Spotlight. 17 pages. Code:\n  https://github.com/yunhuiguo/MEGA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep neural networks can achieve remarkable performance on a single\ntask. However, when the deep neural network is continually trained on a\nsequence of tasks, it seems to gradually forget the previous learned knowledge.\nThis phenomenon is referred to as \\textit{catastrophic forgetting} and\nmotivates the field called lifelong learning. Recently, episodic memory based\napproaches such as GEM \\cite{lopez2017gradient} and A-GEM\n\\cite{chaudhry2018efficient} have shown remarkable performance. In this paper,\nwe provide the first unified view of episodic memory based approaches from an\noptimization's perspective. This view leads to two improved schemes for\nepisodic memory based lifelong learning, called MEGA-I and MEGA-II. MEGA-I and\nMEGA-II modulate the balance between old tasks and the new task by integrating\nthe current gradient with the gradient computed on the episodic memory.\nNotably, we show that GEM and A-GEM are degenerate cases of MEGA-I and MEGA-II\nwhich consistently put the same emphasis on the current task, regardless of how\nthe loss changes over time. Our proposed schemes address this issue by using\nnovel loss-balancing updating rules, which drastically improve the performance\nover GEM and A-GEM. Extensive experimental results show that the proposed\nschemes significantly advance the state-of-the-art on four commonly used\nlifelong learning benchmarks, reducing the error by up to 18\\%.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 20:49:15 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 00:34:42 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 20:08:09 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 19:46:43 GMT"}, {"version": "v5", "created": "Fri, 22 Nov 2019 06:08:31 GMT"}, {"version": "v6", "created": "Tue, 13 Oct 2020 22:09:32 GMT"}, {"version": "v7", "created": "Tue, 15 Dec 2020 04:06:12 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Guo", "Yunhui", ""], ["Liu", "Mingrui", ""], ["Yang", "Tianbao", ""], ["Rosing", "Tajana", ""]]}, {"id": "1909.11784", "submitter": "Achim Zeileis", "authors": "Nikolaus Umlauf, Nadja Klein, Thorsten Simon, Achim Zeileis", "title": "bamlss: A Lego Toolbox for Flexible Bayesian Regression (and Beyond)", "comments": "48 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last decades, the challenges in applied regression and in predictive\nmodeling have been changing considerably: (1) More flexible model\nspecifications are needed as big(ger) data become available, facilitated by\nmore powerful computing infrastructure. (2) Full probabilistic modeling rather\nthan predicting just means or expectations is crucial in many applications. (3)\nInterest in Bayesian inference has been increasing both as an appealing\nframework for regularizing or penalizing model estimation as well as a natural\nalternative to classical frequentist inference. However, while there has been a\nlot of research in all three areas, also leading to associated software\npackages, a modular software implementation that allows to easily combine all\nthree aspects has not yet been available. For filling this gap, the R package\nbamlss is introduced for Bayesian additive models for location, scale, and\nshape (and beyond). At the core of the package are algorithms for\nhighly-efficient Bayesian estimation and inference that can be applied to\ngeneralized additive models (GAMs) or generalized additive models for location,\nscale, and shape (GAMLSS), also known as distributional regression. However,\nits building blocks are designed as \"Lego bricks\" encompassing various\ndistributions (exponential family, Cox, joint models, ...), regression terms\n(linear, splines, random effects, tensor products, spatial fields, ...), and\nestimators (MCMC, backfitting, gradient boosting, lasso, ...). It is\ndemonstrated how these can be easily recombined to make classical models more\nflexible or create new custom models for specific modeling challenges.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 21:31:02 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Umlauf", "Nikolaus", ""], ["Klein", "Nadja", ""], ["Simon", "Thorsten", ""], ["Zeileis", "Achim", ""]]}, {"id": "1909.11786", "submitter": "Nilesh Ahuja", "authors": "Nilesh A. Ahuja, Ibrahima Ndiour, Trushant Kalyanpur, Omesh Tickoo", "title": "Probabilistic Modeling of Deep Features for Out-of-Distribution and\n  Adversarial Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a principled approach for detecting out-of-distribution (OOD) and\nadversarial samples in deep neural networks. Our approach consists in modeling\nthe outputs of the various layers (deep features) with parametric probability\ndistributions once training is completed. At inference, the likelihoods of the\ndeep features w.r.t the previously learnt distributions are calculated and used\nto derive uncertainty estimates that can discriminate in-distribution samples\nfrom OOD samples. We explore the use of two classes of multivariate\ndistributions for modeling the deep features - Gaussian and Gaussian mixture -\nand study the trade-off between accuracy and computational complexity. We\ndemonstrate benefits of our approach on image features by detecting OOD images\nand adversarially-generated images, using popular DNN architectures on MNIST\nand CIFAR10 datasets. We show that more precise modeling of the feature\ndistributions result in significantly improved detection of OOD and adversarial\nsamples; up to 12 percentage points in AUPR and AUROC metrics. We further show\nthat our approach remains extremely effective when applied to video data and\nassociated spatio-temporal features by detecting adversarial samples on\nactivity classification tasks using UCF101 dataset, and the C3D network. To our\nknowledge, our methodology is the first one reported for reliably detecting\nwhite-box adversarial framing, a state-of-the-art adversarial attack for video\nclassifiers.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 21:41:56 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ahuja", "Nilesh A.", ""], ["Ndiour", "Ibrahima", ""], ["Kalyanpur", "Trushant", ""], ["Tickoo", "Omesh", ""]]}, {"id": "1909.11790", "submitter": "Chapman Siu", "authors": "Chapman Siu", "title": "Residual Networks Behave Like Boosting Algorithms", "comments": "This work was supported by and completed whilst author was at Suncorp\n  Group Limited. to appear 2019 IEEE International Conference on Data Science\n  and Advance Analytics (DSAA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Residual Networks (ResNet) is equivalent to boosting feature\nrepresentation, without any modification to the underlying ResNet training\nalgorithm. A regret bound based on Online Gradient Boosting theory is proved\nand suggests that ResNet could achieve Online Gradient Boosting regret bounds\nthrough neural network architectural changes with the addition of a shrinkage\nparameter in the identity skip-connections and using residual modules with\nmax-norm bounds. Through this relation between ResNet and Online Boosting,\nnovel feature representation boosting algorithms can be constructed based on\naltering residual modules. We demonstrate this through proposing decision tree\nresidual modules to construct a new boosted decision tree algorithm and\ndemonstrating generalization error bounds for both approaches; relaxing\nconstraints within BoostResNet algorithm to allow it to be trained in an\nout-of-core manner. We evaluate convolution ResNet with and without shrinkage\nmodifications to demonstrate its efficacy, and demonstrate that our online\nboosted decision tree algorithm is comparable to state-of-the-art offline\nboosted decision tree algorithms without the drawback of offline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:00:08 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Siu", "Chapman", ""]]}, {"id": "1909.11793", "submitter": "John Palowitch", "authors": "John Palowitch, Bryan Perozzi", "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training\n  Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are Graph Neural Networks (GNNs) fair? In many real world graphs, the\nformation of edges is related to certain node attributes (e.g. gender,\ncommunity, reputation). In this case, standard GNNs using these edges will be\nbiased by this information, as it is encoded in the structure of the adjacency\nmatrix itself. In this paper, we show that when metadata is correlated with the\nformation of node neighborhoods, unsupervised node embedding dimensions learn\nthis metadata. This bias implies an inability to control for important\ncovariates in real-world applications, such as recommendation systems. To solve\nthese issues, we introduce the Metadata-Orthogonal Node Embedding Training\n(MONET) unit, a general model for debiasing embeddings of nodes in a graph.\nMONET achieves this by ensuring that the node embeddings are trained on a\nhyperplane orthogonal to that of the node metadata. This effectively organizes\nunstructured embedding dimensions into an interpretable topology-only,\nmetadata-only division with no linear interactions. We illustrate the\neffectiveness of MONET though our experiments on a variety of real world\ngraphs, which shows that our method can learn and remove the effect of\narbitrary covariates in tasks such as preventing the leakage of political party\naffiliation in a blog network, and thwarting the gaming of embedding-based\nrecommendation systems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:12:08 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 07:25:32 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Palowitch", "John", ""], ["Perozzi", "Bryan", ""]]}, {"id": "1909.11795", "submitter": "Jo Schlemper", "authors": "Jo Schlemper, Jinming Duan, Cheng Ouyang, Chen Qin, Jose Caballero,\n  Joseph V. Hajnal, Daniel Rueckert", "title": "Data consistency networks for (calibration-less) accelerated parallel MR\n  image reconstruction", "comments": "Presented at ISMRM 27th Annual Meeting & Exhibition (Abstract #4663)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present simple reconstruction networks for multi-coil data by extending\ndeep cascade of CNN's and exploiting the data consistency layer. In particular,\nwe propose two variants, where one is inspired by POCSENSE and the other is\ncalibration-less. We show that the proposed approaches are competitive relative\nto the state of the art both quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:15:56 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Schlemper", "Jo", ""], ["Duan", "Jinming", ""], ["Ouyang", "Cheng", ""], ["Qin", "Chen", ""], ["Caballero", "Jose", ""], ["Hajnal", "Joseph V.", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1909.11799", "submitter": "Ronan Perry", "authors": "Ronan Perry, Tyler M. Tomita, Ronak Mehta, Jesus Arroyo, Jesse\n  Patsolic, Benjamin Falk, Joshua T. Vogelstein", "title": "Manifold Forests: Closing the Gap on Neural Networks", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decision forests (DFs), in particular random forests and gradient boosting\ntrees, have demonstrated state-of-the-art accuracy compared to other methods in\nmany supervised learning scenarios. In particular, DFs dominate other methods\nin tabular data, that is, when the feature space is unstructured, so that the\nsignal is invariant to permuting feature indices. However, in structured data\nlying on a manifold---such as images, text, and speech---deep networks (DNs),\nspecifically convolutional deep networks (ConvNets), tend to outperform DFs. We\nconjecture that at least part of the reason for this is that the input to DNs\nis not simply the feature magnitudes, but also their indices (for example, the\nconvolution operation uses feature locality). In contrast, naive DF\nimplementations fail to explicitly consider feature indices. A recently\nproposed DF approach demonstrates that DFs, for each node, implicitly sample a\nrandom matrix from some specific distribution. These DFs, like some classes of\nDNs, learn by partitioning the feature space into convex polytopes\ncorresponding to linear functions. We build on that approach and show that one\ncan choose distributions in a manifold-aware fashion to incorporate feature\nlocality. We demonstrate the empirical performance on data whose features live\non three different manifolds: a torus, images, and time-series. In all\nsimulations, our Manifold Oblique Random Forest (MORF) algorithm empirically\ndominates other state-of-the-art approaches that ignore feature space structure\nand challenges the performance of ConvNets. Moreover, MORF runs significantly\nfaster than ConvNets and maintains interpretability and theoretical\njustification. This approach, therefore, has promise to enable DFs and other\nmachine learning methods to close the gap to deep networks on manifold-valued\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:28:47 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 19:24:32 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 21:05:16 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Perry", "Ronan", ""], ["Tomita", "Tyler M.", ""], ["Mehta", "Ronak", ""], ["Arroyo", "Jesus", ""], ["Patsolic", "Jesse", ""], ["Falk", "Benjamin", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1909.11804", "submitter": "Shusen Liu", "authors": "Shusen Liu, Rushil Anirudh, Jayaraman J. Thiagarajan and Peer-Timo\n  Bremer", "title": "Function Preserving Projection for Scalable Exploration of\n  High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present function preserving projections (FPP), a scalable linear\nprojection technique for discovering interpretable relationships in\nhigh-dimensional data. Conventional dimension reduction methods aim to\nmaximally preserve the global and/or local geometric structure of a dataset.\nHowever, in practice one is often more interested in determining how one or\nmultiple user-selected response function(s) can be explained by the data. To\nintuitively connect the responses to the data, FPP constructs 2D linear\nembeddings optimized to reveal interpretable yet potentially non-linear\npatterns of the response functions. More specifically, FPP is designed to (i)\nproduce human-interpretable embeddings; (ii) capture non-linear relationships;\n(iii) allow the simultaneous use of multiple response functions; and (iv) scale\nto millions of samples. Using FPP on real-world datasets, one can obtain\nfundamentally new insights about high-dimensional relationships in large-scale\ndata that could not be achieved using existing dimension reduction methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:40:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liu", "Shusen", ""], ["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1909.11810", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Maxim Naumov, Dheevatsa Mudigere, Jiyan Yang, James\n  Zou", "title": "Mixed Dimension Embeddings with Application to Memory-Efficient\n  Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Embedding representations power machine intelligence in many applications,\nincluding recommendation systems, but they are space intensive -- potentially\noccupying hundreds of gigabytes in large-scale settings. To help manage this\noutsized memory consumption, we explore mixed dimension embeddings, an\nembedding layer architecture in which a particular embedding vector's dimension\nscales with its query frequency. Through theoretical analysis and systematic\nexperiments, we demonstrate that using mixed dimensions can drastically reduce\nthe memory usage, while maintaining and even improving the ML performance.\nEmpirically, we show that the proposed mixed dimension layers improve accuracy\nby 0.1% using half as many parameters or maintain it using 16X fewer parameters\nfor click-through rate prediction task on the Criteo Kaggle dataset.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:19:55 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 20:04:29 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 09:37:45 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ginart", "Antonio", ""], ["Naumov", "Maxim", ""], ["Mudigere", "Dheevatsa", ""], ["Yang", "Jiyan", ""], ["Zou", "James", ""]]}, {"id": "1909.11813", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Ole Winther", "title": "LAVAE: Disentangling Location and Appearance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic generative model for unsupervised learning of\nstructured, interpretable, object-based representations of visual scenes. We\nuse amortized variational inference to train the generative model end-to-end.\nThe learned representations of object location and appearance are fully\ndisentangled, and objects are represented independently of each other in the\nlatent space. Unlike previous approaches that disentangle location and\nappearance, ours generalizes seamlessly to scenes with many more objects than\nencountered in the training regime. We evaluate the proposed model on\nmulti-MNIST and multi-dSprites data sets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:33:14 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 00:10:09 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Dittadi", "Andrea", ""], ["Winther", "Ole", ""]]}, {"id": "1909.11820", "submitter": "Masoud Badiei Khuzani", "authors": "Masoud Badiei Khuzani, Liyue Shen, Shahin Shahrampour, Lei Xing", "title": "A Mean-Field Theory for Kernel Alignment with Random Features in\n  Generative and Discriminative Models", "comments": "51 pages, 4 figures. In this edition, new simulations for the kernel\n  SVMs are included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel supervised learning method to optimize the kernel in the\nmaximum mean discrepancy generative adversarial networks (MMD GANs), and the\nkernel support vector machines (SVMs). Specifically, we characterize a\ndistributionally robust optimization problem to compute a good distribution for\nthe random feature model of Rahimi and Recht. Due to the fact that the\ndistributional optimization is infinite dimensional, we consider a Monte-Carlo\nsample average approximation (SAA) to obtain a more tractable finite\ndimensional optimization problem. We subsequently leverage a particle\nstochastic gradient descent (SGD) method to solve the derived finite\ndimensional optimization problem. Based on a mean-field analysis, we then prove\nthat the empirical distribution of the interactive particles system at each\niteration of the SGD follows the path of the gradient descent flow on the\nWasserstein manifold. We also establish the non-asymptotic consistency of the\nfinite sample estimator. We evaluate our kernel learning method for the\nhypothesis testing problem by evaluating the kernel MMD statistics, and show\nthat our learning method indeed attains better power of the test for larger\nthreshold values compared to an untrained kernel. Moreover, our empirical\nevaluation on benchmark data-sets shows the advantage of our kernel learning\napproach compared to alternative kernel learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:45:55 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 02:40:56 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 02:53:48 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Khuzani", "Masoud Badiei", ""], ["Shen", "Liyue", ""], ["Shahrampour", "Shahin", ""], ["Xing", "Lei", ""]]}, {"id": "1909.11821", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, Ting-Han Fan, Peter J. Ramadge, and Hao Su", "title": "Model Imitation for Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) aims to learn a dynamic model to\nreduce the number of interactions with real-world environments. However, due to\nestimation error, rollouts in the learned model, especially those of long\nhorizons, fail to match the ones in real-world environments. This mismatching\nhas seriously impacted the sample complexity of MBRL. The phenomenon can be\nattributed to the fact that previous works employ supervised learning to learn\nthe one-step transition models, which has inherent difficulty ensuring the\nmatching of distributions from multi-step rollouts. Based on the claim, we\npropose to learn the transition model by matching the distributions of\nmulti-step rollouts sampled from the transition model and the real ones via\nWGAN. We theoretically show that matching the two can minimize the difference\nof cumulative rewards between the real transition and the learned one. Our\nexperiments also show that the proposed Model Imitation method can compete or\noutperform the state-of-the-art in terms of sample complexity and average\nreturn.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:52:30 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 06:19:21 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 05:47:10 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Fan", "Ting-Han", ""], ["Ramadge", "Peter J.", ""], ["Su", "Hao", ""]]}, {"id": "1909.11825", "submitter": "Yu Sun", "authors": "Yu Sun, Eric Tzeng, Trevor Darrell, Alexei A. Efros", "title": "Unsupervised Domain Adaptation through Self-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper addresses unsupervised domain adaptation, the setting where\nlabeled training data is available on a source domain, but the goal is to have\ngood performance on a target domain with only unlabeled data. Like much of\nprevious work, we seek to align the learned representations of the source and\ntarget domains while preserving discriminability. The way we accomplish\nalignment is by learning to perform auxiliary self-supervised task(s) on both\ndomains simultaneously. Each self-supervised task brings the two domains closer\ntogether along the direction relevant to that task. Training this jointly with\nthe main task classifier on the source domain is shown to successfully\ngeneralize to the unlabeled target domain. The presented objective is\nstraightforward to implement and easy to optimize. We achieve state-of-the-art\nresults on four out of seven standard benchmarks, and competitive results on\nsegmentation adaptation. We also demonstrate that our method composes well with\nanother popular pixel-level adaptation method.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 00:21:16 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 08:09:29 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sun", "Yu", ""], ["Tzeng", "Eric", ""], ["Darrell", "Trevor", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1909.11832", "submitter": "Nairouz Mrabah", "authors": "Nairouz Mrabah, Mohamed Bouguessa, Riadh Ksantini", "title": "Adversarial Deep Embedded Clustering: on a better trade-off between\n  Feature Randomness and Feature Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering using deep autoencoders has been thoroughly investigated in recent\nyears. Current approaches rely on simultaneously learning embedded features and\nclustering the data points in the latent space. Although numerous deep\nclustering approaches outperform the shallow models in achieving favorable\nresults on several high-semantic datasets, a critical weakness of such models\nhas been overlooked. In the absence of concrete supervisory signals, the\nembedded clustering objective function may distort the latent space by learning\nfrom unreliable pseudo-labels. Thus, the network can learn non-representative\nfeatures, which in turn undermines the discriminative ability, yielding worse\npseudo-labels. In order to alleviate the effect of random discriminative\nfeatures, modern autoencoder-based clustering papers propose to use the\nreconstruction loss for pretraining and as a regularizer during the clustering\nphase. Nevertheless, a clustering-reconstruction trade-off can cause the\n\\textit{Feature Drift} phenomena. In this paper, we propose ADEC (Adversarial\nDeep Embedded Clustering) a novel autoencoder-based clustering model, which\naddresses a dual problem, namely, \\textit{Feature Randomness} and\n\\textit{Feature Drift}, using adversarial training. We empirically demonstrate\nthe suitability of our model on handling these problems using benchmark real\ndatasets. Experimental results validate that our model outperforms\nstate-of-the-art autoencoder-based clustering methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 00:51:09 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Mrabah", "Nairouz", ""], ["Bouguessa", "Mohamed", ""], ["Ksantini", "Riadh", ""]]}, {"id": "1909.11835", "submitter": "Ulrich A\\\"ivodji", "authors": "Ulrich A\\\"ivodji, S\\'ebastien Gambs, Timon Ther", "title": "GAMIN: An Adversarial Approach to Black-Box Model Inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have demonstrated that machine learning models are vulnerable to\nmodel inversion attacks, which lead to the exposure of sensitive information\ncontained in their training dataset. While some model inversion attacks have\nbeen developed in the past in the black-box attack setting, in which the\nadversary does not have direct access to the structure of the model, few of\nthese have been conducted so far against complex models such as deep neural\nnetworks. In this paper, we introduce GAMIN (for Generative Adversarial Model\nINversion), a new black-box model inversion attack framework achieving\nsignificant results even against deep models such as convolutional neural\nnetworks at a reasonable computing cost. GAMIN is based on the continuous\ntraining of a surrogate model for the target model under attack and a generator\nwhose objective is to generate inputs resembling those used to train the target\nmodel. The attack was validated against various neural networks used as image\nclassifiers. In particular, when attacking models trained on the MNIST dataset,\nGAMIN is able to extract recognizable digits for up to 60% of labels produced\nby the target. Attacks against skin classification models trained on the pilot\nparliament dataset also demonstrated the capacity to extract recognizable\nfeatures from the targets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 01:01:32 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Gambs", "S\u00e9bastien", ""], ["Ther", "Timon", ""]]}, {"id": "1909.11837", "submitter": "Haoyu Zhao", "authors": "Rong Ge, Runzhe Wang, Haoyu Zhao", "title": "Mildly Overparametrized Neural Nets can Memorize Training Data\n  Efficiently", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed \\citep{zhang2016understanding} that deep neural networks\ncan memorize: they achieve 100\\% accuracy on training data. Recent theoretical\nresults explained such behavior in highly overparametrized regimes, where the\nnumber of neurons in each layer is larger than the number of training samples.\nIn this paper, we show that neural networks can be trained to memorize training\ndata perfectly in a mildly overparametrized regime, where the number of\nparameters is just a constant factor more than the number of training samples,\nand the number of neurons is much smaller.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 01:19:21 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ge", "Rong", ""], ["Wang", "Runzhe", ""], ["Zhao", "Haoyu", ""]]}, {"id": "1909.11851", "submitter": "Christian Szegedy", "authors": "Dennis Lee, Christian Szegedy, Markus N. Rabe, Sarah M. Loos and\n  Kshitij Bansal", "title": "Mathematical Reasoning in Latent Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and conduct a simple experiment to study whether neural networks\ncan perform several steps of approximate reasoning in a fixed dimensional\nlatent space. The set of rewrites (i.e. transformations) that can be\nsuccessfully performed on a statement represents essential semantic features of\nthe statement. We can compress this information by embedding the formula in a\nvector space, such that the vector associated with a statement can be used to\npredict whether a statement can be rewritten by other theorems. Predicting the\nembedding of a formula generated by some rewrite rule is naturally viewed as\napproximate reasoning in the latent space. In order to measure the\neffectiveness of this reasoning, we perform approximate deduction sequences in\nthe latent space and use the resulting embedding to inform the semantic\nfeatures of the corresponding formal statement (which is obtained by performing\nthe corresponding rewrite sequence using real formulas). Our experiments show\nthat graph neural networks can make non-trivial predictions about the\nrewrite-success of statements, even when they propagate predicted latent\nrepresentations for several steps. Since our corpus of mathematical formulas\nincludes a wide variety of mathematical disciplines, this experiment is a\nstrong indicator for the feasibility of deduction in latent space in general.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 02:33:07 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Lee", "Dennis", ""], ["Szegedy", "Christian", ""], ["Rabe", "Markus N.", ""], ["Loos", "Sarah M.", ""], ["Bansal", "Kshitij", ""]]}, {"id": "1909.11854", "submitter": "Irem Cetin", "authors": "Irem Cetin, Gerard Sanroma, Steffen E. Petersen, Sandy Napel, Oscar\n  Camara, Miguel-Angel Gonzalez Ballester, Karim Lekadir", "title": "A Radiomics Approach to Computer-Aided Diagnosis with Cardiac Cine-MRI", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-75541-0_9", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Use expert visualization or conventional clinical indices can lack accuracy\nfor borderline classications. Advanced statistical approaches based on\neigen-decomposition have been mostly concerned with shape and motion indices.\nIn this paper, we present a new approach to identify CVDs from cine-MRI by\nestimating large pools of radiomic features (statistical, shape and textural\nfeatures) encoding relevant changes in anatomical and image characteristics due\nto CVDs. The calculated cine-MRI radiomic features are assessed using\nsequential forward feature selection to identify the most relevant ones for\ngiven CVD classes (e.g. myocardial infarction, cardiomyopathy, abnormal right\nventricle). Finally, advanced machine learning is applied to suitably integrate\nthe selected radiomics for final multi-feature classification based on Support\nVector Machines (SVMs). The proposed technique was trained and cross-validated\nusing 100 cine-MRI cases corresponding to five different cardiac classes from\nthe ACDC MICCAI 2017 challenge\n\\footnote{https://www.creatis.insa-lyon.fr/Challenge/acdc/index.html}. All\ncases were correctly classified in this preliminary study, indicating potential\nof using large-scale radiomics for MRI-based diagnosis of CVDs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 10:43:51 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Cetin", "Irem", ""], ["Sanroma", "Gerard", ""], ["Petersen", "Steffen E.", ""], ["Napel", "Sandy", ""], ["Camara", "Oscar", ""], ["Ballester", "Miguel-Angel Gonzalez", ""], ["Lekadir", "Karim", ""]]}, {"id": "1909.11855", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Tu Dinh Nguyen and Dinh Phung", "title": "Universal Graph Transformer Self-Attention Networks", "comments": "We have updated the Pytorch and Tensorflow implementation at:\n  https://github.com/daiquocnguyen/Graph-Transformer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transformer self-attention network has been extensively used in research\ndomains such as computer vision, image processing, and natural language\nprocessing. But it has not been actively used in graph neural networks (GNNs)\nwhere constructing an advanced aggregation function is essential. To this end,\nwe present U2GNN, an effective GNN model leveraging a transformer\nself-attention mechanism followed by a recurrent transition, to induce a\npowerful aggregation function to learn graph representations. Experimental\nresults show that the proposed U2GNN achieves state-of-the-art accuracies on\nwell-known benchmark datasets for graph classification. Our code is available\nat: https://github.com/daiquocnguyen/Graph-Transformer\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 02:39:59 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 13:27:35 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 16:47:35 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 02:05:59 GMT"}, {"version": "v5", "created": "Wed, 8 Apr 2020 15:15:35 GMT"}, {"version": "v6", "created": "Thu, 16 Apr 2020 14:46:21 GMT"}, {"version": "v7", "created": "Mon, 29 Jun 2020 10:15:50 GMT"}, {"version": "v8", "created": "Mon, 3 Aug 2020 15:13:44 GMT"}, {"version": "v9", "created": "Fri, 23 Oct 2020 17:39:40 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "1909.11865", "submitter": "Alessandro Fanfarillo", "authors": "Alessandro Fanfarillo, Behrooz Roozitalab, Weiming Hu, Guido Cervone", "title": "Probabilistic Forecasting using Deep Generative Models", "comments": "23 pages, 9 figures, submitted to Computers and Geosciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Analog Ensemble (AnEn) method tries to estimate the probability\ndistribution of the future state of the atmosphere with a set of past\nobservations that correspond to the best analogs of a deterministic Numerical\nWeather Prediction (NWP). This model post-processing method has been\nsuccessfully used to improve the forecast accuracy for several weather-related\napplications including air quality, and short-term wind and solar power\nforecasting, to name a few. In order to provide a meaningful probabilistic\nforecast, the AnEn method requires storing a historical set of past predictions\nand observations in memory for a period of at least several months and spanning\nthe seasons relevant for the prediction of interest. Although the memory and\ncomputing costs of the AnEn method are less expensive than using a brute-force\ndynamical ensemble approach, for a large number of stations and large datasets,\nthe amount of memory required for AnEn can easily become prohibitive.\nFurthermore, in order to find the best analogs associated with a certain\nprediction produced by a NWP model, the current approach requires searching\nover the entire dataset by applying a certain metric. This approach requires\napplying the metric over the entire historical dataset, which may take a\nsubstantial amount of time. In this work, we investigate an alternative way to\nimplement the AnEn method using deep generative models. By doing so, a\ngenerative model can entirely or partially replace the dataset of pairs of\npredictions and observations, reducing the amount of memory required to produce\nthe probabilistic forecast by several orders of magnitude. Furthermore, the\ngenerative model can generate a meaningful set of analogs associated with a\ncertain forecast in constant time without performing any search, saving a\nconsiderable amount of time even in the presence of huge historical datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 03:12:48 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Fanfarillo", "Alessandro", ""], ["Roozitalab", "Behrooz", ""], ["Hu", "Weiming", ""], ["Cervone", "Guido", ""]]}, {"id": "1909.11877", "submitter": "Yaniv Ben-Itzhak", "authors": "Shay Vargaftik, Isaac Keslassy, Ariel Orda, Yaniv Ben-Itzhak", "title": "RADE: Resource-Efficient Supervised Anomaly Detection Using Decision\n  Tree-Based Ensemble Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-tree-based ensemble classification methods (DTEMs) are a prevalent\ntool for supervised anomaly detection. However, due to the continued growth of\ndatasets, DTEMs result in increasing drawbacks such as growing memory\nfootprints, longer training times, and slower classification latencies at lower\nthroughput. In this paper, we present, design, and evaluate RADE - a DTEM-based\nanomaly detection framework that augments standard DTEM classifiers and\nalleviates these drawbacks by relying on two observations: (1) we find that a\nsmall (coarse-grained) DTEM model is sufficient to classify the majority of the\nclassification queries correctly, such that a classification is valid only if\nits corresponding confidence level is greater than or equal to a predetermined\nclassification confidence threshold; (2) we find that in these fewer harder\ncases where our coarse-grained DTEM model results in insufficient confidence in\nits classification, we can improve it by forwarding the classification query to\none of expert DTEM (fine-grained) models, which is explicitly trained for that\nparticular case. We implement RADE in Python based on scikit-learn and evaluate\nit over different DTEM methods: RF, XGBoost, AdaBoost, GBDT and LightGBM, and\nover three publicly available datasets. Our evaluation over both a strong AWS\nEC2 instance and a Raspberry Pi 3 device indicates that RADE offers competitive\nand often superior anomaly detection capabilities as compared to standard DTEM\nmethods, while significantly improving memory footprint (by up to 5.46x),\ntraining-time (by up to 17.2x), and classification latency (by up to 31.2x).\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 04:07:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 12:40:58 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Vargaftik", "Shay", ""], ["Keslassy", "Isaac", ""], ["Orda", "Ariel", ""], ["Ben-Itzhak", "Yaniv", ""]]}, {"id": "1909.11886", "submitter": "Youngmoon Jung", "authors": "Youngmoon Jung, Yeunju Choi, Hoirin Kim", "title": "Self-Adaptive Soft Voice Activity Detection using Deep Neural Networks\n  for Robust Speaker Verification", "comments": "Accepted at 2019 IEEE Automatic Speech Recognition and Understanding\n  Workshop (ASRU 2019)", "journal-ref": "Proc. of ASRU 2019, pp. 365-372", "doi": "10.1109/ASRU46091.2019.9003935", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice activity detection (VAD), which classifies frames as speech or\nnon-speech, is an important module in many speech applications including\nspeaker verification. In this paper, we propose a novel method, called\nself-adaptive soft VAD, to incorporate a deep neural network (DNN)-based VAD\ninto a deep speaker embedding system. The proposed method is a combination of\nthe following two approaches. The first approach is soft VAD, which performs a\nsoft selection of frame-level features extracted from a speaker feature\nextractor. The frame-level features are weighted by their corresponding speech\nposteriors estimated from the DNN-based VAD, and then aggregated to generate a\nspeaker embedding. The second approach is self-adaptive VAD, which fine-tunes\nthe pre-trained VAD on the speaker verification data to reduce the domain\nmismatch. Here, we introduce two unsupervised domain adaptation (DA) schemes,\nnamely speech posterior-based DA (SP-DA) and joint learning-based DA (JL-DA).\nExperiments on a Korean speech database demonstrate that the verification\nperformance is improved significantly in real-world environments by using\nself-adaptive soft VAD.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 04:38:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jung", "Youngmoon", ""], ["Choi", "Yeunju", ""], ["Kim", "Hoirin", ""]]}, {"id": "1909.11907", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Shaofeng Zou, Yingbin Liang", "title": "Two Time-scale Off-Policy TD Learning: Non-asymptotic Analysis over\n  Markovian Samples", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based temporal difference (GTD) algorithms are widely used in\noff-policy learning scenarios. Among them, the two time-scale TD with gradient\ncorrection (TDC) algorithm has been shown to have superior performance. In\ncontrast to previous studies that characterized the non-asymptotic convergence\nrate of TDC only under identical and independently distributed (i.i.d.) data\nsamples, we provide the first non-asymptotic convergence analysis for two\ntime-scale TDC under a non-i.i.d.\\ Markovian sample path and linear function\napproximation. We show that the two time-scale TDC can converge as fast as\nO(log t/(t^(2/3))) under diminishing stepsize, and can converge exponentially\nfast under constant stepsize, but at the cost of a non-vanishing error. We\nfurther propose a TDC algorithm with blockwisely diminishing stepsize, and show\nthat it asymptotically converges with an arbitrarily small error at a\nblockwisely linear convergence rate. Our experiments demonstrate that such an\nalgorithm converges as fast as TDC under constant stepsize, and still enjoys\ncomparable accuracy as TDC under diminishing stepsize.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 05:48:16 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Xu", "Tengyu", ""], ["Zou", "Shaofeng", ""], ["Liang", "Yingbin", ""]]}, {"id": "1909.11926", "submitter": "Guilin Li", "authors": "Guilin Li, Xing Zhang, Zitong Wang, Matthias Tan, Jiashi Feng, Zhenguo\n  Li, Tong Zhang", "title": "Hierarchical Neural Architecture Search via Operator Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, the efficiency of automatic neural architecture design has been\nsignificantly improved by gradient-based search methods such as DARTS. However,\nrecent literature has brought doubt to the generalization ability of DARTS,\narguing that DARTS performs poorly when the search space is changed, i.e, when\ndifferent set of candidate operators are used. Regularization techniques such\nas early stopping have been proposed to partially solve this problem. In this\npaper, we tackle this problem from a different perspective by identifying two\ncontributing factors to the collapse of DARTS when the search space changes:\n(1) the correlation of similar operators incurs unfavorable competition among\nthem and makes their relative importance score unreliable and (2) the\noptimization complexity gap between the proxy search stage and the final\ntraining. Based on these findings, we propose a new hierarchical search\nalgorithm. With its operator clustering and optimization complexity match, the\nalgorithm can consistently find high-performance architecture across various\nsearch spaces. For all the five variants of the popular cell-based search\nspaces, the proposed algorithm always obtains state-of-the-art architecture\nwith best accuracy on the CIFAR-10, CIFAR-100 and ImageNet over other\nwell-established DARTS-alike algorithms. Code is available at\nhttps://github.com/susan0199/StacNAS.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 06:26:58 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 15:29:40 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 03:20:17 GMT"}, {"version": "v4", "created": "Wed, 11 Dec 2019 03:53:31 GMT"}, {"version": "v5", "created": "Mon, 25 Jan 2021 10:03:07 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Li", "Guilin", ""], ["Zhang", "Xing", ""], ["Wang", "Zitong", ""], ["Tan", "Matthias", ""], ["Feng", "Jiashi", ""], ["Li", "Zhenguo", ""], ["Zhang", "Tong", ""]]}, {"id": "1909.11932", "submitter": "Md Sazzad Hossain", "authors": "Md Sazzad Hossain, Andrew P Paplinski, John M Betts", "title": "Adaptive Class Weight based Dual Focal Loss for Improved Semantic\n  Segmentation", "comments": "We, the authors, are withdrawing this preprint due to a number of\n  errors pointed out by the reviewers. Based on the reviewers' feedback, the\n  paper has gone through an extensive revision, which significantly differs\n  from this preprint version by methodologically as well as experimentally. We\n  acknowledge the reviewers for their scrutinized review which guided our study\n  in the right direction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Dual Focal Loss (DFL) function, as a replacement\nfor the standard cross entropy (CE) function to achieve a better treatment of\nthe unbalanced classes in a dataset. Our DFL method is an improvement on the\nrecently reported Focal Loss (FL) cross-entropy function, which proposes a\nscaling method that puts more weight on the examples that are difficult to\nclassify over those that are easy. However, the scaling parameter of FL is\nempirically set, which is problem-dependent. In addition, like other CE\nvariants, FL only focuses on the loss of true classes. Therefore, no loss\nfeedback is gained from the false classes. Although focusing only on true\nexamples increases probability on true classes and correspondingly reduces\nprobability on false classes due to the nature of the softmax function, it does\nnot achieve the best convergence due to avoidance of the loss on false classes.\nOur DFL method improves on the simple FL in two ways. Firstly, it takes the\nidea of FL to focus more on difficult examples than the easy ones, but\nevaluates loss on both true and negative classes with equal importance.\nSecondly, the scaling parameter of DFL has been made learnable so that it can\ntune itself by backpropagation rather than being dependent on manual tuning. In\nthis way, our proposed DFL method offers an auto-tunable loss function that can\nreduce the class imbalance effect as well as put more focus on both true\ndifficult examples and negative easy examples.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 06:36:21 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 13:54:05 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 05:20:15 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hossain", "Md Sazzad", ""], ["Paplinski", "Andrew P", ""], ["Betts", "John M", ""]]}, {"id": "1909.11939", "submitter": "Yannis Flet-Berliac", "authors": "Yannis Flet-Berliac, Philippe Preux", "title": "MERL: Multi-Head Reinforcement Learning", "comments": "Deep Reinforcement Learning Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common challenge in reinforcement learning is how to convert the agent's\ninteractions with an environment into fast and robust learning. For instance,\nearlier work makes use of domain knowledge to improve existing reinforcement\nlearning algorithms in complex tasks. While promising, previously acquired\nknowledge is often costly and challenging to scale up. Instead, we decide to\nconsider problem knowledge with signals from quantities relevant to solve any\ntask, e.g., self-performance assessment and accurate expectations.\n$\\mathcal{V}^{ex}$ is such a quantity. It is the fraction of variance explained\nby the value function $V$ and measures the discrepancy between $V$ and the\nreturns. Taking advantage of $\\mathcal{V}^{ex}$, we propose MERL, a general\nframework for structuring reinforcement learning by injecting problem knowledge\ninto policy gradient updates. As a result, the agent is not only optimized for\na reward but learns using problem-focused quantities provided by MERL,\napplicable out-of-the-box to any task. In this paper: (a) We introduce and\ndefine MERL, the multi-head reinforcement learning framework we use throughout\nthis work. (b) We conduct experiments across a variety of standard benchmark\nenvironments, including 9 continuous control tasks, where results show improved\nperformance. (c) We demonstrate that MERL also improves transfer learning on a\nset of challenging pixel-based tasks. (d) We ponder how MERL tackles the\nproblem of reward sparsity and better conditions the feature space of\nreinforcement learning agents.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 06:57:51 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 15:31:28 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 12:17:17 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 09:15:11 GMT"}, {"version": "v5", "created": "Fri, 29 Nov 2019 14:24:35 GMT"}, {"version": "v6", "created": "Tue, 31 Mar 2020 07:57:20 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Flet-Berliac", "Yannis", ""], ["Preux", "Philippe", ""]]}, {"id": "1909.11953", "submitter": "Sheng Wan", "authors": "Sheng Wan and Chen Gong and Ping Zhong and Shirui Pan and Guangyu Li\n  and Jian Yang", "title": "Hyperspectral Image Classification With Context-Aware Dynamic Graph\n  Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hyperspectral image (HSI) classification, spatial context has demonstrated\nits significance in achieving promising performance. However, conventional\nspatial context-based methods simply assume that spatially neighboring pixels\nshould correspond to the same land-cover class, so they often fail to correctly\ndiscover the contextual relations among pixels in complex situations, and thus\nleading to imperfect classification results on some irregular or inhomogeneous\nregions such as class boundaries. To address this deficiency, we develop a new\nHSI classification method based on the recently proposed Graph Convolutional\nNetwork (GCN), as it can flexibly encode the relations among arbitrarily\nstructured non-Euclidean data. Different from traditional GCN, there are two\nnovel strategies adopted by our method to further exploit the contextual\nrelations for accurate HSI classification. First, since the receptive field of\ntraditional GCN is often limited to fairly small neighborhood, we proposed to\ncapture long range contextual relations in HSI by performing successive graph\nconvolutions on a learned region-induced graph which is transformed from the\noriginal 2D image grids. Second, we refine the graph edge weight and the\nconnective relationships among image regions by learning the improved adjacency\nmatrix and the 'edge filter', so that the graph can be gradually refined to\nadapt to the representations generated by each graph convolutional layer. Such\nupdated graph will in turn result in accurate region representations, and vice\nversa. The experiments carried out on three real-world benchmark datasets\ndemonstrate that the proposed method yields significant improvement in the\nclassification performance when compared with some state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 07:37:37 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Wan", "Sheng", ""], ["Gong", "Chen", ""], ["Zhong", "Ping", ""], ["Pan", "Shirui", ""], ["Li", "Guangyu", ""], ["Yang", "Jian", ""]]}, {"id": "1909.11957", "submitter": "Haoran You", "authors": "Haoran You, Chaojian Li, Pengfei Xu, Yonggan Fu, Yue Wang, Xiaohan\n  Chen, Richard G. Baraniuk, Zhangyang Wang, and Yingyan Lin", "title": "Drawing early-bird tickets: Towards more efficient training of deep\n  networks", "comments": "Accepted as ICLR2020 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Frankle & Carbin, 2019) shows that there exist winning tickets (small but\ncritical subnetworks) for dense, randomly initialized networks, that can be\ntrained alone to achieve comparable accuracies to the latter in a similar\nnumber of iterations. However, the identification of these winning tickets\nstill requires the costly train-prune-retrain process, limiting their practical\nbenefits. In this paper, we discover for the first time that the winning\ntickets can be identified at the very early training stage, which we term as\nearly-bird (EB) tickets, via low-cost training schemes (e.g., early stopping\nand low-precision training) at large learning rates. Our finding of EB tickets\nis consistent with recently reported observations that the key connectivity\npatterns of neural networks emerge early. Furthermore, we propose a mask\ndistance metric that can be used to identify EB tickets with low computational\noverhead, without needing to know the true winning tickets that emerge after\nthe full training. Finally, we leverage the existence of EB tickets and the\nproposed mask distance to develop efficient training methods, which are\nachieved by first identifying EB tickets via low-cost schemes, and then\ncontinuing to train merely the EB tickets towards the target accuracy.\nExperiments based on various deep networks and datasets validate: 1) the\nexistence of EB tickets, and the effectiveness of mask distance in efficiently\nidentifying them; and 2) that the proposed efficient training via EB tickets\ncan achieve up to 4.7x energy savings while maintaining comparable or even\nbetter accuracy, demonstrating a promising and easily adopted method for\ntackling cost-prohibitive deep network training. Code available at\nhttps://github.com/RICE-EIC/Early-Bird-Tickets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 07:43:56 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 05:44:12 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 21:21:44 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 06:12:58 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["You", "Haoran", ""], ["Li", "Chaojian", ""], ["Xu", "Pengfei", ""], ["Fu", "Yonggan", ""], ["Wang", "Yue", ""], ["Chen", "Xiaohan", ""], ["Baraniuk", "Richard G.", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "1909.12031", "submitter": "Hong Liu", "authors": "Hong Liu and Mingsheng Long and Jianmin Wang and Michael I. Jordan", "title": "Towards Understanding the Transferability of Deep Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks trained on a wide range of datasets demonstrate\nimpressive transferability. Deep features appear general in that they are\napplicable to many datasets and tasks. Such property is in prevalent use in\nreal-world applications. A neural network pretrained on large datasets, such as\nImageNet, can significantly boost generalization and accelerate training if\nfine-tuned to a smaller target dataset. Despite its pervasiveness, few effort\nhas been devoted to uncovering the reason of transferability in deep feature\nrepresentations. This paper tries to understand transferability from the\nperspectives of improved generalization, optimization and the feasibility of\ntransferability. We demonstrate that 1) Transferred models tend to find flatter\nminima, since their weight matrices stay close to the original flat region of\npretrained parameters when transferred to a similar target dataset; 2)\nTransferred representations make the loss landscape more favorable with\nimproved Lipschitzness, which accelerates and stabilizes training\nsubstantially. The improvement largely attributes to the fact that the\nprincipal component of gradient is suppressed in the pretrained parameters,\nthus stabilizing the magnitude of gradient in back-propagation. 3) The\nfeasibility of transferability is related to the similarity of both input and\nlabel. And a surprising discovery is that the feasibility is also impacted by\nthe training stages in that the transferability first increases during\ntraining, and then declines. We further provide a theoretical analysis to\nverify our observations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 11:23:34 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liu", "Hong", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1909.12035", "submitter": "Moustafa Ebada", "authors": "Moustafa Ebada, Sebastian Cammerer, Ahmed Elkelesh and Stephan ten\n  Brink", "title": "Deep Learning-based Polar Code Design", "comments": "Allerton2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a deep learning-based polar code construction\nalgorithm. The core idea is to represent the information/frozen bit indices of\na polar code as a binary vector which can be interpreted as trainable weights\nof a neural network (NN). For this, we demonstrate how this binary vector can\nbe relaxed to a soft-valued vector, facilitating the learning process through\ngradient descent and enabling an efficient code construction. We further show\nhow different polar code design constraints (e.g., code rate) can be taken into\naccount by means of careful binary-to-soft and soft-to-binary conversions,\nalong with rate-adjustment after each learning iteration. Besides its\nconceptual simplicity, this approach benefits from having the\n\"decoder-in-the-loop\", i.e., the nature of the decoder is inherently taken into\nconsideration while learning (designing) the polar code. We show results for\nbelief propagation (BP) decoding over both AWGN and Rayleigh fading channels\nwith considerable performance gains over state-of-the-art construction schemes.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 11:36:51 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 16:17:37 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ebada", "Moustafa", ""], ["Cammerer", "Sebastian", ""], ["Elkelesh", "Ahmed", ""], ["Brink", "Stephan ten", ""]]}, {"id": "1909.12038", "submitter": "Qimai Li", "authors": "Qimai Li, Xiaotong Zhang, Han Liu, Quanyu Dai, Xiao-Ming Wu", "title": "Dimensionwise Separable 2-D Graph Convolution for Unsupervised and\n  Semi-Supervised Learning on Graphs", "comments": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD '21)", "journal-ref": null, "doi": "10.1145/3447548.3467413", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCN) have been the model of choice for\ngraph representation learning, which is mainly due to the effective design of\ngraph convolution that computes the representation of a node by aggregating\nthose of its neighbors. However, existing GCN variants commonly use 1-D graph\nconvolution that solely operates on the object link graph without exploring\ninformative relational information among object attributes. This significantly\nlimits their modeling capability and may lead to inferior performance on noisy\nand sparse real-world networks. In this paper, we explore 2-D graph convolution\nto jointly model object links and attribute relations for graph representation\nlearning. Specifically, we propose a computationally efficient dimensionwise\nseparable 2-D graph convolution (DSGC) for filtering node features.\nTheoretically, we show that DSGC can reduce intra-class variance of node\nfeatures on both the object dimension and the attribute dimension to learn more\neffective representations. Empirically, we demonstrate that by modeling\nattribute relations, DSGC achieves significant performance gain over\nstate-of-the-art methods for node classification and clustering on a variety of\nreal-world networks. The source code for reproducing the experimental results\nis available at https://github.com/liqimai/DSGC.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 11:47:54 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 18:19:39 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 16:22:25 GMT"}, {"version": "v4", "created": "Sun, 21 Jun 2020 17:44:03 GMT"}, {"version": "v5", "created": "Wed, 9 Jun 2021 10:33:41 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Li", "Qimai", ""], ["Zhang", "Xiaotong", ""], ["Liu", "Han", ""], ["Dai", "Quanyu", ""], ["Wu", "Xiao-Ming", ""]]}, {"id": "1909.12051", "submitter": "Daniel Gissin", "authors": "Daniel Gissin, Shai Shalev-Shwartz, Amit Daniely", "title": "The Implicit Bias of Depth: How Incremental Learning Drives\n  Generalization", "comments": "25 pages, 7 figures, published at the International Conference on\n  Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A leading hypothesis for the surprising generalization of neural networks is\nthat the dynamics of gradient descent bias the model towards simple solutions,\nby searching through the solution space in an incremental order of complexity.\nWe formally define the notion of incremental learning dynamics and derive the\nconditions on depth and initialization for which this phenomenon arises in deep\nlinear models. Our main theoretical contribution is a dynamical depth\nseparation result, proving that while shallow models can exhibit incremental\nlearning dynamics, they require the initialization to be exponentially small\nfor these dynamics to present themselves. However, once the model becomes\ndeeper, the dependence becomes polynomial and incremental learning can arise in\nmore natural settings. We complement our theoretical findings by experimenting\nwith deep matrix sensing, quadratic neural networks and with binary\nclassification using diagonal and convolutional linear networks, showing all of\nthese models exhibit incremental learning.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:38:41 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 10:44:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gissin", "Daniel", ""], ["Shalev-Shwartz", "Shai", ""], ["Daniely", "Amit", ""]]}, {"id": "1909.12057", "submitter": "Erik J Bekkers", "authors": "Erik J Bekkers", "title": "B-Spline CNNs on Lie Groups", "comments": "Accepted for publication at ICLR 2020, code available at\n  https://github.com/ebekkers/gsplinets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group convolutional neural networks (G-CNNs) can be used to improve classical\nCNNs by equipping them with the geometric structure of groups. Central in the\nsuccess of G-CNNs is the lifting of feature maps to higher dimensional\ndisentangled representations, in which data characteristics are effectively\nlearned, geometric data-augmentations are made obsolete, and predictable\nbehavior under geometric transformations (equivariance) is guaranteed via group\ntheory. Currently, however, the practical implementations of G-CNNs are limited\nto either discrete groups (that leave the grid intact) or continuous compact\ngroups such as rotations (that enable the use of Fourier theory). In this paper\nwe lift these limitations and propose a modular framework for the design and\nimplementation of G-CNNs for arbitrary Lie groups. In our approach the\ndifferential structure of Lie groups is used to expand convolution kernels in a\ngeneric basis of B-splines that is defined on the Lie algebra. This leads to a\nflexible framework that enables localized, atrous, and deformable convolutions\nin G-CNNs by means of respectively localized, sparse and non-uniform B-spline\nexpansions. The impact and potential of our approach is studied on two\nbenchmark datasets: cancer detection in histopathology slides in which rotation\nequivariance plays a key role and facial landmark localization in which scale\nequivariance is important. In both cases, G-CNN architectures outperform their\nclassical 2D counterparts and the added value of atrous and localized group\nconvolutions is studied in detail.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:42:42 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:33:36 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 12:53:19 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 08:46:23 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Bekkers", "Erik J", ""]]}, {"id": "1909.12063", "submitter": "Qi Deng", "authors": "Qi Deng", "title": "Artificial Intelligence BlockCloud (AIBC) Technical Whitepaper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AIBC is an Artificial Intelligence and blockchain technology based\nlarge-scale decentralized ecosystem that allows system-wide low-cost sharing of\ncomputing and storage resources. The AIBC consists of four layers: a\nfundamental layer, a resource layer, an application layer, and an ecosystem\nlayer. The AIBC implements a two-consensus scheme to enforce upper-layer\neconomic policies and achieve fundamental layer performance and robustness: the\nDPoEV incentive consensus on the application and resource layers, and the DABFT\ndistributed consensus on the fundamental layer. The DABFT uses deep learning\ntechniques to predict and select the most suitable BFT algorithm in order to\nachieve the best balance of performance, robustness, and security. The DPoEV\nuses the knowledge map algorithm to accurately assess the economic value of\ndigital assets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:49:50 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Deng", "Qi", ""]]}, {"id": "1909.12064", "submitter": "Max Horn", "authors": "Max Horn, Michael Moor, Christian Bock, Bastian Rieck, Karsten\n  Borgwardt", "title": "Set Functions for Time Series", "comments": "Accepted at the International Conference on Machine Learning (ICML)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the eminent successes of deep neural networks, many architectures are\noften hard to transfer to irregularly-sampled and asynchronous time series that\ncommonly occur in real-world datasets, especially in healthcare applications.\nThis paper proposes a novel approach for classifying irregularly-sampled time\nseries with unaligned measurements, focusing on high scalability and data\nefficiency. Our method SeFT (Set Functions for Time Series) is based on recent\nadvances in differentiable set function learning, extremely parallelizable with\na beneficial memory footprint, thus scaling well to large datasets of long time\nseries and online monitoring scenarios. Furthermore, our approach permits\nquantifying per-observation contributions to the classification outcome. We\nextensively compare our method with existing algorithms on multiple healthcare\ntime series datasets and demonstrate that it performs competitively whilst\nsignificantly reducing runtime.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:52:43 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 15:37:23 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 19:59:49 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Horn", "Max", ""], ["Moor", "Michael", ""], ["Bock", "Christian", ""], ["Rieck", "Bastian", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "1909.12077", "submitter": "Biswadip Dey", "authors": "Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty", "title": "Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control", "comments": "Published as a Conference Paper at ICLR 2020", "journal-ref": "International Conference on Learning Representations (ICLR 2020);\n  https://openreview.net/forum?id=ryxmb1rKDS", "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning\nframework which can infer the dynamics of a physical system, given by an\nordinary differential equation (ODE), from observed state trajectories. To\nachieve better generalization with fewer training samples, SymODEN incorporates\nappropriate inductive bias by designing the associated computation graph in a\nphysics-informed manner. In particular, we enforce Hamiltonian dynamics with\ncontrol to learn the underlying dynamics in a transparent way, which can then\nbe leveraged to draw insight about relevant physical aspects of the system,\nsuch as mass and potential energy. In addition, we propose a parametrization\nwhich can enforce this Hamiltonian formalism even when the generalized\ncoordinate data is embedded in a high-dimensional space or we can only access\nvelocity data instead of generalized momentum. This framework, by offering\ninterpretable, physically-consistent models for physical systems, opens up new\npossibilities for synthesizing model-based control strategies.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:13:16 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:22:51 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 04:10:53 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 03:02:07 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhong", "Yaofeng Desmond", ""], ["Dey", "Biswadip", ""], ["Chakraborty", "Amit", ""]]}, {"id": "1909.12078", "submitter": "Kolyan Ray", "authors": "Kolyan Ray and Botond Szabo", "title": "Debiased Bayesian inference for average treatment effects", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian approaches have become increasingly popular in causal inference\nproblems due to their conceptual simplicity, excellent performance and in-built\nuncertainty quantification ('posterior credible sets'). We investigate Bayesian\ninference for average treatment effects from observational data, which is a\nchallenging problem due to the missing counterfactuals and selection bias.\nWorking in the standard potential outcomes framework, we propose a data-driven\nmodification to an arbitrary (nonparametric) prior based on the propensity\nscore that corrects for the first-order posterior bias, thereby improving\nperformance. We illustrate our method for Gaussian process (GP) priors using\n(semi-)synthetic data. Our experiments demonstrate significant improvement in\nboth estimation accuracy and uncertainty quantification compared to the\nunmodified GP, rendering our approach highly competitive with the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:19:51 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ray", "Kolyan", ""], ["Szabo", "Botond", ""]]}, {"id": "1909.12083", "submitter": "Marco Cristoforetti", "authors": "L. Coviello, M. Cristoforetti, G. Jurman and C. Furlanello", "title": "In-field grape berries counting for yield estimation using dilated CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital technologies ignited a revolution in the agrifood domain known as\nprecision agriculture: a main question for enabling precision agriculture at\nscale is if accurate product quality control can be made available at minimal\ncost, leveraging existing technologies and agronomists' skills. As a\ncontribution along this direction we demonstrate a tool for accurate fruit\nyield estimation from smartphone cameras, by adapting Deep Learning algorithms\noriginally developed for crowd counting.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:28:53 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Coviello", "L.", ""], ["Cristoforetti", "M.", ""], ["Jurman", "G.", ""], ["Furlanello", "C.", ""]]}, {"id": "1909.12098", "submitter": "Gonzalo Mart\\'inez-Mu\\~noz", "authors": "Seyedsaman Emami, Gonzalo Mart\\'inez-Mu\\~noz", "title": "Sequential Training of Neural Networks with Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel technique based on gradient boosting to train a\nshallow neural network (NN). Gradient boosting is an additive expansion\nalgorithm in which a series of models are trained sequentially to approximate a\ngiven function. A neural network can also be seen as an additive model where\nthe scalar product of the responses of the last hidden layer and its weights\nprovide the final output of the network. Instead of training the network as a\nwhole, the proposed algorithm trains the network sequentially in $T$ steps.\nFirst, the bias term of the network is initialized with a constant\napproximation that minimizes the average loss of the data. Then, at each step,\na portion of the network, composed of $J$ neurons, is trained to approximate\nthe pseudo-residuals on the training data computed from the previous\niterations. Finally, the $T$ partial models and bias are integrated as a single\nNN with $T \\times J$ neurons in the hidden layer. Extensive experiments in\nclassification and regression tasks are carried out showing a competitive\ngeneralization performance with respect to neural networks trained with\ndifferent standard solvers, such as Adam, L-BFGS and SGD. Furthermore, we show\nthat the proposed method design permits to switch off a number of hidden units\nduring test (the units that were last trained) without a significant reduction\nof its generalization ability. This permits the adaptation of the model to\ndifferent classification speed requirements on the fly.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:45:39 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 14:42:37 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Emami", "Seyedsaman", ""], ["Mart\u00ednez-Mu\u00f1oz", "Gonzalo", ""]]}, {"id": "1909.12108", "submitter": "Avraam Chatzimichailidis", "authors": "Avraam Chatzimichailidis, Franz-Josef Pfreundt, Nicolas R. Gauger,\n  Janis Keuper", "title": "GradVis: Visualization and Second Order Analysis of Optimization\n  Surfaces during the Training of Deep Neural Networks", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current training methods for deep neural networks boil down to very high\ndimensional and non-convex optimization problems which are usually solved by a\nwide range of stochastic gradient descent methods. While these approaches tend\nto work in practice, there are still many gaps in the theoretical understanding\nof key aspects like convergence and generalization guarantees, which are\ninduced by the properties of the optimization surface (loss landscape). In\norder to gain deeper insights, a number of recent publications proposed methods\nto visualize and analyze the optimization surfaces. However, the computational\ncost of these methods are very high, making it hardly possible to use them on\nlarger networks.\n  In this paper, we present the GradVis Toolbox, an open source library for\nefficient and scalable visualization and analysis of deep neural network loss\nlandscapes in Tensorflow and PyTorch. Introducing more efficient mathematical\nformulations and a novel parallelization scheme, GradVis allows to plot 2d and\n3d projections of optimization surfaces and trajectories, as well as high\nresolution second order gradient information for large networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:55:12 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 09:45:59 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Chatzimichailidis", "Avraam", ""], ["Pfreundt", "Franz-Josef", ""], ["Gauger", "Nicolas R.", ""], ["Keuper", "Janis", ""]]}, {"id": "1909.12114", "submitter": "Leila Arras", "authors": "Leila Arras, Jose A. Arjona-Medina, Michael Widrich, Gr\\'egoire\n  Montavon, Michael Gillhofer, Klaus-Robert M\\\"uller, Sepp Hochreiter and\n  Wojciech Samek", "title": "Explaining and Interpreting LSTMs", "comments": "28 pages, 7 figures, book chapter, In: Explainable AI: Interpreting,\n  Explaining and Visualizing Deep Learning, LNCS volume 11700, Springer 2019.\n  arXiv admin note: text overlap with arXiv:1806.07857", "journal-ref": null, "doi": "10.1007/978-3-030-28954-6_11", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have acted as a strong unifying force in the design of\nmodern AI systems, the neural network architectures themselves remain highly\nheterogeneous due to the variety of tasks to be solved. In this chapter, we\nexplore how to adapt the Layer-wise Relevance Propagation (LRP) technique used\nfor explaining the predictions of feed-forward networks to the LSTM\narchitecture used for sequential data modeling and forecasting. The special\naccumulators and gated interactions present in the LSTM require both a new\npropagation scheme and an extension of the underlying theoretical framework to\ndeliver faithful explanations.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 11:45:43 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Arras", "Leila", ""], ["Arjona-Medina", "Jose A.", ""], ["Widrich", "Michael", ""], ["Montavon", "Gr\u00e9goire", ""], ["Gillhofer", "Michael", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Hochreiter", "Sepp", ""], ["Samek", "Wojciech", ""]]}, {"id": "1909.12116", "submitter": "Jong Chul Ye", "authors": "Byeongsu Sim, Gyutaek Oh, Jeongsol Kim, Chanyong Jung, Jong Chul Ye", "title": "Optimal Transport driven CycleGAN for Unsupervised Learning in Inverse\n  Problems", "comments": "accepted for publication in the SIAM Journal on Imaging Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the performance of classical generative adversarial network (GAN),\nWasserstein generative adversarial networks (W-GAN) was developed as a\nKantorovich dual formulation of the optimal transport (OT) problem using\nWasserstein-1 distance. However, it was not clear how cycleGAN-type generative\nmodels can be derived from the optimal transport theory. Here we show that a\nnovel cycleGAN architecture can be derived as a Kantorovich dual OT formulation\nif a penalized least square (PLS) cost with deep learning-based inverse path\npenalty is used as a transportation cost. One of the most important advantages\nof this formulation is that depending on the knowledge of the forward problem,\ndistinct variations of cycleGAN architecture can be derived: for example, one\nwith two pairs of generators and discriminators, and the other with only a\nsingle pair of generator and discriminator. Even for the two generator cases,\nwe show that the structural knowledge of the forward operator can lead to a\nsimpler generator architecture which significantly simplifies the neural\nnetwork training. The new cycleGAN formulation, what we call the OT-cycleGAN,\nhave been applied for various biomedical imaging problems, such as accelerated\nmagnetic resonance imaging (MRI), super-resolution microscopy, and low-dose\nx-ray computed tomography (CT). Experimental results confirm the efficacy and\nflexibility of the theory.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 11:28:49 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 13:59:39 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 16:28:14 GMT"}, {"version": "v4", "created": "Sun, 30 Aug 2020 12:14:48 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Sim", "Byeongsu", ""], ["Oh", "Gyutaek", ""], ["Kim", "Jeongsol", ""], ["Jung", "Chanyong", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1909.12120", "submitter": "Eren Balevi", "authors": "Eren Balevi and Jeffrey G. Andrews", "title": "Autoencoder-Based Error Correction Coding for One-Bit Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel deep learning-based error correction coding\nscheme for AWGN channels under the constraint of one-bit quantization in the\nreceivers. Specifically, it is first shown that the optimum error correction\ncode that minimizes the probability of bit error can be obtained by perfectly\ntraining a special autoencoder, in which \"perfectly\" refers to converging the\nglobal minima. However, perfect training is not possible in most cases. To\napproach the performance of a perfectly trained autoencoder with a suboptimum\ntraining, we propose utilizing turbo codes as an implicit regularization, i.e.,\nusing a concatenation of a turbo code and an autoencoder. It is empirically\nshown that this design gives nearly the same performance as to the\nhypothetically perfectly trained autoencoder, and we also provide a theoretical\nproof of why that is so. The proposed coding method is as bandwidth efficient\nas the integrated (outer) turbo code, since the autoencoder exploits the excess\nbandwidth from pulse shaping and packs signals more intelligently thanks to\nsparsity in neural networks. Our results show that the proposed coding scheme\nat finite block lengths outperforms conventional turbo codes even for QPSK\nmodulation. Furthermore, the proposed coding method can make one-bit\nquantization operational even for 16-QAM.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:57:13 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Balevi", "Eren", ""], ["Andrews", "Jeffrey G.", ""]]}, {"id": "1909.12127", "submitter": "Oleksandr Shchur", "authors": "Oleksandr Shchur, Marin Bilo\\v{s}, Stephan G\\\"unnemann", "title": "Intensity-Free Learning of Temporal Point Processes", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal point processes are the dominant paradigm for modeling sequences of\nevents happening at irregular intervals. The standard way of learning in such\nmodels is by estimating the conditional intensity function. However,\nparameterizing the intensity function usually incurs several trade-offs. We\nshow how to overcome the limitations of intensity-based approaches by directly\nmodeling the conditional distribution of inter-event times. We draw on the\nliterature on normalizing flows to design models that are flexible and\nefficient. We additionally propose a simple mixture model that matches the\nflexibility of flow-based models, but also permits sampling and computing\nmoments in closed form. The proposed models achieve state-of-the-art\nperformance in standard prediction tasks and are suitable for novel\napplications, such as learning sequence embeddings and imputing missing data.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:11:55 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 10:06:02 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Shchur", "Oleksandr", ""], ["Bilo\u0161", "Marin", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1909.12160", "submitter": "Mohamad Dia", "authors": "Mohamad Dia, Elodie Savary, Martin Melchior, Frederic Courbin", "title": "Galaxy Image Simulation Using Progressive GANs", "comments": "Submitted to the Astronomical Data Analysis Software & Systems\n  Conference (ADASS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.GA eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide an efficient and realistic data-driven approach to\nsimulate astronomical images using deep generative models from machine\nlearning. Our solution is based on a variant of the generative adversarial\nnetwork (GAN) with progressive training methodology and Wasserstein cost\nfunction. The proposed solution generates naturalistic images of galaxies that\nshow complex structures and high diversity, which suggests that data-driven\nsimulations using machine learning can replace many of the expensive\nmodel-driven methods used in astronomical data processing.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:44:27 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Dia", "Mohamad", ""], ["Savary", "Elodie", ""], ["Melchior", "Martin", ""], ["Courbin", "Frederic", ""]]}, {"id": "1909.12180", "submitter": "Alexander Meinke", "authors": "Alexander Meinke, Matthias Hein", "title": "Towards neural networks that provably know when they don't know", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that ReLU networks produce arbitrarily\nover-confident predictions far away from the training data. Thus, ReLU networks\ndo not know when they don't know. However, this is a highly important property\nin safety critical applications. In the context of out-of-distribution\ndetection (OOD) there have been a number of proposals to mitigate this problem\nbut none of them are able to make any mathematical guarantees. In this paper we\npropose a new approach to OOD which overcomes both problems. Our approach can\nbe used with ReLU networks and provides provably low confidence predictions far\naway from the training data as well as the first certificates for low\nconfidence predictions in a neighborhood of an out-distribution point. In the\nexperiments we show that state-of-the-art methods fail in this worst-case\nsetting whereas our model can guarantee its performance while retaining\nstate-of-the-art OOD performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:20:08 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 09:27:11 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Meinke", "Alexander", ""], ["Hein", "Matthias", ""]]}, {"id": "1909.12185", "submitter": "Regis Albuquerque", "authors": "Regis Antonio Saraiva Albuquerque, Albert Franca Josua Costa, Eulanda\n  Miranda dos Santos, Robert Sabourin and Rafael Giusti", "title": "A Decision-Based Dynamic Ensemble Selection Method for Concept Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online method for concept driftdetection based on dynamic\nclassifier ensemble selection. Theproposed method generates a pool of ensembles\nby promotingdiversity among classifier members and chooses expert\nensemblesaccording to global prequential accuracy values. Unlike currentdynamic\nensemble selection approaches that use only local knowl-edge to select the most\ncompetent ensemble for each instance,our method focuses on selection taking\ninto account the decisionspace. Consequently, it is well adapted to the context\nof driftdetection in data stream problems. The results of the experimentsshow\nthat the proposed method attained the highest detection pre-cision and the\nlowest number of false alarms, besides competitiveclassification accuracy\nrates, in artificial datasets representingdifferent types of drifts. Moreover,\nit outperformed baselines indifferent real-problem datasets in terms of\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:22:18 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Albuquerque", "Regis Antonio Saraiva", ""], ["Costa", "Albert Franca Josua", ""], ["Santos", "Eulanda Miranda dos", ""], ["Sabourin", "Robert", ""], ["Giusti", "Rafael", ""]]}, {"id": "1909.12201", "submitter": "Oleksandr Shchur", "authors": "Oleksandr Shchur, Stephan G\\\"unnemann", "title": "Overlapping Community Detection with Graph Neural Networks", "comments": "The First International Workshop on Deep Learning on Graphs (In\n  Conjunction with the 25th ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining) https://dlg2019.bitbucket.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is a fundamental problem in machine learning. While deep\nlearning has shown great promise in many graphrelated tasks, developing neural\nmodels for community detection has received surprisingly little attention. The\nfew existing approaches focus on detecting disjoint communities, even though\ncommunities in real graphs are well known to be overlapping. We address this\nshortcoming and propose a graph neural network (GNN) based model for\noverlapping community detection. Despite its simplicity, our model outperforms\nthe existing baselines by a large margin in the task of community recovery. We\nestablish through an extensive experimental evaluation that the proposed model\nis effective, scalable and robust to hyperparameter settings. We also perform\nan ablation study that confirms that GNN is the key ingredient to the power of\nthe proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:45:39 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Shchur", "Oleksandr", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1909.12205", "submitter": "Vahid Partovi Nia", "authors": "Gr\\'egoire Morin, Ryan Razani, Vahid Partovi Nia, and Eyy\\\"ub Sari", "title": "Smart Ternary Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models are resource hungry. Low bit quantization such as\nbinary and ternary quantization is a common approach to alleviate this resource\nrequirements. Ternary quantization provides a more flexible model and often\nbeats binary quantization in terms of accuracy, but doubles memory and\nincreases computation cost. Mixed quantization depth models, on another hand,\nallows a trade-off between accuracy and memory footprint. In such models,\nquantization depth is often chosen manually (which is a tiring task), or is\ntuned using a separate optimization routine (which requires training a\nquantized network multiple times). Here, we propose Smart Ternary Quantization\n(STQ) in which we modify the quantization depth directly through an adaptive\nregularization function, so that we train a model only once. This method jumps\nbetween binary and ternary quantization while training. We show its application\non image classification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:49:08 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Morin", "Gr\u00e9goire", ""], ["Razani", "Ryan", ""], ["Nia", "Vahid Partovi", ""], ["Sari", "Eyy\u00fcb", ""]]}, {"id": "1909.12218", "submitter": "Timo Klock", "authors": "Zeljko Kereta, Timo Klock", "title": "Estimating covariance and precision matrices along subspaces", "comments": "25 pages, 9 figures", "journal-ref": null, "doi": "10.1214/20-EJS1782", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the accuracy of estimating the covariance and the precision matrix\nof a $D$-variate sub-Gaussian distribution along a prescribed subspace or\ndirection using the finite sample covariance. Our results show that the\nestimation accuracy depends almost exclusively on the components of the\ndistribution that correspond to desired subspaces or directions. This is\nrelevant and important for problems where the behavior of data along a\nlower-dimensional space is of specific interest, such as dimension reduction or\nstructured regression problems. We also show that estimation of precision\nmatrices is almost independent of the condition number of the covariance\nmatrix. The presented applications include direction-sensitive eigenspace\nperturbation bounds, relative bounds for the smallest eigenvalue, and the\nestimation of the single-index model. For the latter, a new estimator, derived\nfrom the analysis, with strong theoretical guarantees and superior numerical\nperformance is proposed.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:15:49 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 11:55:04 GMT"}, {"version": "v3", "created": "Sun, 6 Dec 2020 15:34:09 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Kereta", "Zeljko", ""], ["Klock", "Timo", ""]]}, {"id": "1909.12220", "submitter": "Yulin Wang", "authors": "Yulin Wang, Xuran Pan, Shiji Song, Hong Zhang, Cheng Wu, Gao Huang", "title": "Implicit Semantic Data Augmentation for Deep Networks", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel implicit semantic data augmentation (ISDA)\napproach to complement traditional augmentation techniques like flipping,\ntranslation or rotation. Our work is motivated by the intriguing property that\ndeep networks are surprisingly good at linearizing features, such that certain\ndirections in the deep feature space correspond to meaningful semantic\ntransformations, e.g., adding sunglasses or changing backgrounds. As a\nconsequence, translating training samples along many semantic directions in the\nfeature space can effectively augment the dataset to improve generalization. To\nimplement this idea effectively and efficiently, we first perform an online\nestimate of the covariance matrix of deep features for each class, which\ncaptures the intra-class semantic variations. Then random vectors are drawn\nfrom a zero-mean normal distribution with the estimated covariance to augment\nthe training data in that class. Importantly, instead of augmenting the samples\nexplicitly, we can directly minimize an upper bound of the expected\ncross-entropy (CE) loss on the augmented training set, leading to a highly\nefficient algorithm. In fact, we show that the proposed ISDA amounts to\nminimizing a novel robust CE loss, which adds negligible extra computational\ncost to a normal training procedure. Although being simple, ISDA consistently\nimproves the generalization performance of popular deep models (ResNets and\nDenseNets) on a variety of datasets, e.g., CIFAR-10, CIFAR-100 and ImageNet.\nCode for reproducing our results is available at\nhttps://github.com/blackfeather-wang/ISDA-for-Deep-Networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:17:45 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 04:57:35 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2019 13:56:17 GMT"}, {"version": "v4", "created": "Fri, 20 Dec 2019 10:11:01 GMT"}, {"version": "v5", "created": "Sat, 25 Apr 2020 03:13:03 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Yulin", ""], ["Pan", "Xuran", ""], ["Song", "Shiji", ""], ["Zhang", "Hong", ""], ["Wu", "Cheng", ""], ["Huang", "Gao", ""]]}, {"id": "1909.12223", "submitter": "Lingxiao Zhao", "authors": "Lingxiao Zhao, Leman Akoglu", "title": "PairNorm: Tackling Oversmoothing in GNNs", "comments": "ICLR 2020 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of graph neural nets (GNNs) is known to gradually decrease\nwith increasing number of layers. This decay is partly attributed to\noversmoothing, where repeated graph convolutions eventually make node\nembeddings indistinguishable. We take a closer look at two different\ninterpretations, aiming to quantify oversmoothing. Our main contribution is\nPairNorm, a novel normalization layer that is based on a careful analysis of\nthe graph convolution operator, which prevents all node embeddings from\nbecoming too similar. What is more, PairNorm is fast, easy to implement without\nany change to network architecture nor any additional parameters, and is\nbroadly applicable to any GNN. Experiments on real-world graphs demonstrate\nthat PairNorm makes deeper GCN, GAT, and SGC models more robust against\noversmoothing, and significantly boosts performance for a new problem setting\nthat benefits from deeper GNNs. Code is available at\nhttps://github.com/LingxiaoShawn/PairNorm.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:20:37 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 02:27:25 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Zhao", "Lingxiao", ""], ["Akoglu", "Leman", ""]]}, {"id": "1909.12228", "submitter": "Ameya Jagtap Dr", "authors": "Ameya D. Jagtap, Kenji Kawaguchi and George Em Karniadakis", "title": "Locally adaptive activation functions with slope recovery term for deep\n  and physics-informed neural networks", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": "10.1098/rspa.2020.0334", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two approaches of locally adaptive activation functions namely,\nlayer-wise and neuron-wise locally adaptive activation functions, which improve\nthe performance of deep and physics-informed neural networks. The local\nadaptation of activation function is achieved by introducing a scalable\nparameter in each layer (layer-wise) and for every neuron (neuron-wise)\nseparately, and then optimizing it using a variant of stochastic gradient\ndescent algorithm. In order to further increase the training speed, an\nactivation slope based slope recovery term is added in the loss function, which\nfurther accelerates convergence, thereby reducing the training cost. On the\ntheoretical side, we prove that in the proposed method, the gradient descent\nalgorithms are not attracted to sub-optimal critical points or local minima\nunder practical conditions on the initialization and learning rate, and that\nthe gradient dynamics of the proposed method is not achievable by base methods\nwith any (adaptive) learning rates. We further show that the adaptive\nactivation methods accelerate the convergence by implicitly multiplying\nconditioning matrices to the gradient of the base method without any explicit\ncomputation of the conditioning matrix and the matrix-vector product. The\ndifferent adaptive activation functions are shown to induce different implicit\nconditioning matrices. Furthermore, the proposed methods with the slope\nrecovery are shown to accelerate the training process.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:36:21 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 23:00:15 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 01:21:22 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 04:39:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Jagtap", "Ameya D.", ""], ["Kawaguchi", "Kenji", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1909.12231", "submitter": "Diego Antognini", "authors": "Diego Antognini and Boi Faltings", "title": "Learning to Create Sentence Semantic Relation Graphs for Multi-Document\n  Summarization", "comments": "10 pages, 4 tables, 1 figure, Accepted at 2019 Empirical Methods in\n  Natural Language Processing - Workshop on New Frontiers in Summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking facts across documents is a challenging task, as the language used to\nexpress the same information in a sentence can vary significantly, which\ncomplicates the task of multi-document summarization. Consequently, existing\napproaches heavily rely on hand-crafted features, which are domain-dependent\nand hard to craft, or additional annotated data, which is costly to gather. To\novercome these limitations, we present a novel method, which makes use of two\ntypes of sentence embeddings: universal embeddings, which are trained on a\nlarge unrelated corpus, and domain-specific embeddings, which are learned\nduring training.\n  To this end, we develop SemSentSum, a fully data-driven model able to\nleverage both types of sentence embeddings by building a sentence semantic\nrelation graph. SemSentSum achieves competitive results on two types of\nsummary, consisting of 665 bytes and 100 words. Unlike other state-of-the-art\nmodels, neither hand-crafted features nor additional annotated data are\nnecessary, and the method is easily adaptable for other tasks. To our\nknowledge, we are the first to use multiple sentence embeddings for the task of\nmulti-document summarization.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 10:21:55 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Antognini", "Diego", ""], ["Faltings", "Boi", ""]]}, {"id": "1909.12232", "submitter": "Sebastian Bayerl", "authors": "Sebastian P. Bayerl and Korbinian Riedhammer", "title": "A Comparison of Hybrid and End-to-End Models for Syllable Recognition", "comments": "22th International Conference of Text, Speech and Dialogue TSD2019", "journal-ref": null, "doi": "10.1007/978-3-030-27947-9_30", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comparison of a traditional hybrid speech recognition\nsystem (kaldi using WFST and TDNN with lattice-free MMI) and a lexicon-free\nend-to-end (TensorFlow implementation of multi-layer LSTM with CTC training)\nmodels for German syllable recognition on the Verbmobil corpus. The results\nshow that explicitly modeling prior knowledge is still valuable in building\nrecognition systems. With a strong language model (LM) based on syllables, the\nstructured approach significantly outperforms the end-to-end model. The best\nword error rate (WER) regarding syllables was achieved using kaldi with a\n4-gram LM, modeling all syllables observed in the training set. It achieved\n10.0% WER w.r.t. the syllables, compared to the end-to-end approach where the\nbest WER was 27.53%. The work presented here has implications for building\nfuture recognition systems that operate independent of a large vocabulary, as\ntypically used in a tasks such as recognition of syllabic or agglutinative\nlanguages, out-of-vocabulary techniques, keyword search indexing and medical\nspeech processing.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:51:35 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bayerl", "Sebastian P.", ""], ["Riedhammer", "Korbinian", ""]]}, {"id": "1909.12235", "submitter": "Matteo Tiezzi", "authors": "Matteo Tiezzi, Stefano Melacci, Marco Maggini, Angelo Frosini", "title": "Video Surveillance of Highway Traffic Events by Deep Learning\n  Architectures", "comments": null, "journal-ref": "Lecture Notes in Computer Science, vol 11141, (2018) pp 584-593", "doi": "10.1007/978-3-030-01424-7_57", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a video surveillance system able to detect traffic\nevents in videos acquired by fixed videocameras on highways. The events of\ninterest consist in a specific sequence of situations that occur in the video,\nas for instance a vehicle stopping on the emergency lane. Hence, the detection\nof these events requires to analyze a temporal sequence in the video stream. We\ncompare different approaches that exploit architectures based on Recurrent\nNeural Networks (RNNs) and Convolutional Neural Networks (CNNs). A first\napproach extracts vectors of features, mostly related to motion, from each\nvideo frame and exploits a RNN fed with the resulting sequence of vectors. The\nother approaches are based directly on the sequence of frames, that are\neventually enriched with pixel-wise motion information. The obtained stream is\nprocessed by an architecture that stacks a CNN and a RNN, and we also\ninvestigate a transfer-learning-based model. The results are very promising and\nthe best architecture will be tested online in real operative conditions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:36:02 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Tiezzi", "Matteo", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""], ["Frosini", "Angelo", ""]]}, {"id": "1909.12243", "submitter": "Yi Huang", "authors": "Yi Huang and Ishanu Chattopadhyay", "title": "Data Smashing 2.0: Sequence Likelihood (SL) Divergence For Fast Time\n  Series Comparison", "comments": "typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing subtle historical patterns is central to modeling and forecasting\nproblems in time series analysis. Here we introduce and develop a new approach\nto quantify deviations in the underlying hidden generators of observed data\nstreams, resulting in a new efficiently computable universal metric for time\nseries. The proposed metric is in the sense that we can compare and contrast\ndata streams regardless of where and how they are generated and without any\nfeature engineering step. The approach proposed in this paper is conceptually\ndistinct from our previous work on data smashing, and vastly improves\ndiscrimination performance and computing speed. The core idea here is the\ngeneralization of the notion of KL divergence often used to compare probability\ndistributions to a notion of divergence in time series. We call this the\nsequence likelihood (SL) divergence, which may be used to measure deviations\nwithin a well-defined class of discrete-valued stochastic processes. We devise\nefficient estimators of SL divergence from finite sample paths and subsequently\nformulate a universal metric useful for computing distance between time series\nproduced by hidden stochastic generators.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:42:13 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 02:08:53 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Huang", "Yi", ""], ["Chattopadhyay", "Ishanu", ""]]}, {"id": "1909.12255", "submitter": "Yuzhe Yang", "authors": "Yuzhe Yang, Guo Zhang, Zhi Xu, Dina Katabi", "title": "Harnessing Structures for Value-Based Planning and Reinforcement\n  Learning", "comments": "ICLR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based methods constitute a fundamental methodology in planning and deep\nreinforcement learning (RL). In this paper, we propose to exploit the\nunderlying structures of the state-action value function, i.e., Q function, for\nboth planning and deep RL. In particular, if the underlying system dynamics\nlead to some global structures of the Q function, one should be capable of\ninferring the function better by leveraging such structures. Specifically, we\ninvestigate the low-rank structure, which widely exists for big data matrices.\nWe verify empirically the existence of low-rank Q functions in the context of\ncontrol and deep RL tasks. As our key contribution, by leveraging Matrix\nEstimation (ME) techniques, we propose a general framework to exploit the\nunderlying low-rank structure in Q functions. This leads to a more efficient\nplanning procedure for classical control, and additionally, a simple scheme\nthat can be applied to any value-based RL techniques to consistently achieve\nbetter performance on \"low-rank\" tasks. Extensive experiments on control tasks\nand Atari games confirm the efficacy of our approach. Code is available at\nhttps://github.com/YyzHarry/SV-RL.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:01:23 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 21:39:26 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 15:53:48 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Yang", "Yuzhe", ""], ["Zhang", "Guo", ""], ["Xu", "Zhi", ""], ["Katabi", "Dina", ""]]}, {"id": "1909.12272", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Daniel Cullina, Prateek Mittal", "title": "Lower Bounds on Adversarial Robustness from Optimal Transport", "comments": "Accepted for the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019); 18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While progress has been made in understanding the robustness of machine\nlearning classifiers to test-time adversaries (evasion attacks), fundamental\nquestions remain unresolved. In this paper, we use optimal transport to\ncharacterize the minimum possible loss in an adversarial classification\nscenario. In this setting, an adversary receives a random labeled example from\none of two classes, perturbs the example subject to a neighborhood constraint,\nand presents the modified example to the classifier. We define an appropriate\ncost function such that the minimum transportation cost between the\ndistributions of the two classes determines the minimum $0-1$ loss for any\nclassifier. When the classifier comes from a restricted hypothesis class, the\noptimal transportation cost provides a lower bound. We apply our framework to\nthe case of Gaussian data with norm-bounded adversaries and explicitly show\nmatching bounds for the classification and transport problems as well as the\noptimality of linear classifiers. We also characterize the sample complexity of\nlearning in this setting, deriving and extending previously known results as a\nspecial case. Finally, we use our framework to study the gap between the\noptimal classification performance possible and that currently achieved by\nstate-of-the-art robustly trained neural networks for datasets of interest,\nnamely, MNIST, Fashion MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:30:16 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 22:09:50 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["Cullina", "Daniel", ""], ["Mittal", "Prateek", ""]]}, {"id": "1909.12289", "submitter": "Qingyun Dou", "authors": "Qingyun Dou, Yiting Lu, Joshua Efiong and Mark J. F. Gales", "title": "Attention Forcing for Sequence-to-sequence Model Training", "comments": "11 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-regressive sequence-to-sequence models with attention mechanism have\nachieved state-of-the-art performance in many tasks such as machine translation\nand speech synthesis. These models can be difficult to train. The standard\napproach, teacher forcing, guides a model with reference output history during\ntraining. The problem is that the model is unlikely to recover from its\nmistakes during inference, where the reference output is replaced by generated\noutput. Several approaches deal with this problem, largely by guiding the model\nwith generated output history. To make training stable, these approaches often\nrequire a heuristic schedule or an auxiliary classifier. This paper introduces\nattention forcing, which guides the model with generated output history and\nreference attention. This approach can train the model to recover from its\nmistakes, in a stable fashion, without the need for a schedule or a classifier.\nIn addition, it allows the model to generate output sequences aligned with the\nreferences, which can be important for cascaded systems like many speech\nsynthesis systems. Experiments on speech synthesis show that attention forcing\nyields significant performance gain. Experiments on machine translation show\nthat for tasks where various re-orderings of the output are valid, guiding the\nmodel with generated output history is challenging, while guiding the model\nwith reference attention is beneficial.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:52:15 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 19:17:11 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Dou", "Qingyun", ""], ["Lu", "Yiting", ""], ["Efiong", "Joshua", ""], ["Gales", "Mark J. F.", ""]]}, {"id": "1909.12291", "submitter": "Steven Young", "authors": "Robert M. Patton, J. Travis Johnston, Steven R. Young, Catherine D.\n  Schuman, Thomas E. Potok, Derek C. Rose, Seung-Hwan Lim, Junghoon Chae, Le\n  Hou, Shahira Abousamra, Dimitris Samaras, Joel Saltz", "title": "Exascale Deep Learning to Accelerate Cancer Research", "comments": "Submitted to IEEE Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, through the use of neural networks, has demonstrated\nremarkable ability to automate many routine tasks when presented with\nsufficient data for training. The neural network architecture (e.g. number of\nlayers, types of layers, connections between layers, etc.) plays a critical\nrole in determining what, if anything, the neural network is able to learn from\nthe training data. The trend for neural network architectures, especially those\ntrained on ImageNet, has been to grow ever deeper and more complex. The result\nhas been ever increasing accuracy on benchmark datasets with the cost of\nincreased computational demands. In this paper we demonstrate that neural\nnetwork architectures can be automatically generated, tailored for a specific\napplication, with dual objectives: accuracy of prediction and speed of\nprediction. Using MENNDL--an HPC-enabled software stack for neural architecture\nsearch--we generate a neural network with comparable accuracy to\nstate-of-the-art networks on a cancer pathology dataset that is also $16\\times$\nfaster at inference. The speedup in inference is necessary because of the\nvolume and velocity of cancer pathology data; specifically, the previous\nstate-of-the-art networks are too slow for individual researchers without\naccess to HPC systems to keep pace with the rate of data generation. Our new\nmodel enables researchers with modest computational resources to analyze newly\ngenerated data faster than it is collected.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:53:26 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Patton", "Robert M.", ""], ["Johnston", "J. Travis", ""], ["Young", "Steven R.", ""], ["Schuman", "Catherine D.", ""], ["Potok", "Thomas E.", ""], ["Rose", "Derek C.", ""], ["Lim", "Seung-Hwan", ""], ["Chae", "Junghoon", ""], ["Hou", "Le", ""], ["Abousamra", "Shahira", ""], ["Samaras", "Dimitris", ""], ["Saltz", "Joel", ""]]}, {"id": "1909.12292", "submitter": "Ziwei Ji", "authors": "Ziwei Ji, Matus Telgarsky", "title": "Polylogarithmic width suffices for gradient descent to achieve\n  arbitrarily small test error with shallow ReLU networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical work has guaranteed that overparameterized networks\ntrained by gradient descent achieve arbitrarily low training error, and\nsometimes even low test error. The required width, however, is always\npolynomial in at least one of the sample size $n$, the (inverse) target error\n$1/\\epsilon$, and the (inverse) failure probability $1/\\delta$. This work shows\nthat $\\widetilde{\\Theta}(1/\\epsilon)$ iterations of gradient descent with\n$\\widetilde{\\Omega}(1/\\epsilon^2)$ training examples on two-layer ReLU networks\nof any width exceeding $\\mathrm{polylog}(n,1/\\epsilon,1/\\delta)$ suffice to\nachieve a test misclassification error of $\\epsilon$. We also prove that\nstochastic gradient descent can achieve $\\epsilon$ test error with\npolylogarithmic width and $\\widetilde{\\Theta}(1/\\epsilon)$ samples. The\nanalysis relies upon the separation margin of the limiting kernel, which is\nguaranteed positive, can distinguish between true labels and random labels, and\ncan give a tight sample-complexity analysis in the infinite-width setting\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:56:28 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 02:21:50 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 05:48:27 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 03:53:09 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1909.12297", "submitter": "Fredrik K. Gustafsson", "authors": "Fredrik K. Gustafsson, Martin Danelljan, Goutam Bhat, Thomas B.\n  Sch\\\"on", "title": "Energy-Based Models for Deep Probabilistic Regression", "comments": "ECCV 2020. Code is available at\n  https://github.com/fregu856/ebms_regression", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning-based classification is generally tackled using\nstandardized approaches, a wide variety of techniques are employed for\nregression. In computer vision, one particularly popular such technique is that\nof confidence-based regression, which entails predicting a confidence value for\neach input-target pair (x,y). While this approach has demonstrated impressive\nresults, it requires important task-dependent design choices, and the predicted\nconfidences lack a natural probabilistic meaning. We address these issues by\nproposing a general and conceptually simple regression method with a clear\nprobabilistic interpretation. In our proposed approach, we create an\nenergy-based model of the conditional target density p(y|x), using a deep\nneural network to predict the un-normalized density from (x,y). This model of\np(y|x) is trained by directly minimizing the associated negative\nlog-likelihood, approximated using Monte Carlo sampling. We perform\ncomprehensive experiments on four computer vision regression tasks. Our\napproach outperforms direct regression, as well as other probabilistic and\nconfidence-based methods. Notably, our model achieves a 2.2% AP improvement\nover Faster-RCNN for object detection on the COCO dataset, and sets a new\nstate-of-the-art on visual tracking when applied for bounding box estimation.\nIn contrast to confidence-based methods, our approach is also shown to be\ndirectly applicable to more general tasks such as age and head-pose estimation.\nCode is available at https://github.com/fregu856/ebms_regression.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:58:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 15:35:36 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 11:19:02 GMT"}, {"version": "v4", "created": "Sun, 19 Jul 2020 12:47:37 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Gustafsson", "Fredrik K.", ""], ["Danelljan", "Martin", ""], ["Bhat", "Goutam", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1909.12299", "submitter": "Subba Reddy Oota", "authors": "Subba Reddy Oota and Naresh Manwani and Raju S. Bapi", "title": "Expert2Coder: Capturing Divergent Brain Regions Using Mixture of\n  Regression Experts", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  fMRI semantic category understanding using linguistic encoding models\nattempts to learn a forward mapping that relates stimuli to the corresponding\nbrain activation. State-of-the-art encoding models use a single global model\n(linear or non-linear) to predict brain activation given the stimulus. However,\nthe critical assumption in these methods is that a priori different brain\nregions respond the same way to all the stimuli, that is, there is no\nmodularity or specialization assumed for any region. This goes against the\nmodularity theory, supported by many cognitive neuroscience investigations\nsuggesting that there are functionally specialized regions in the brain. In\nthis paper, we achieve this by clustering similar regions together and for\nevery cluster we learn a different linear regression model using a mixture of\nlinear experts model. The key idea here is that each linear expert captures the\nbehaviour of similar brain regions. Given a new stimulus, the utility of the\nproposed model is twofold (i) predicts the brain activation as a weighted\nlinear combination of the activations of multiple linear experts and (ii) to\nlearn multiple experts corresponding to different brain regions. We argue that\neach expert captures activity patterns related to a particular region of\ninterest (ROI) in the human brain. This study helps in understanding the brain\nregions that are activated together given different kinds of stimuli.\nImportantly, we suggest that the mixture of regression experts (MoRE) framework\nsuccessfully combines the two principles of organization of function in the\nbrain, namely that of specialization and integration. Experiments on fMRI data\nfrom paradigm 1 [1]where participants view linguistic stimuli show that the\nproposed MoRE model has better prediction accuracy compared to that of\nconventional models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:59:33 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 19:45:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Oota", "Subba Reddy", ""], ["Manwani", "Naresh", ""], ["Bapi", "Raju S.", ""]]}, {"id": "1909.12301", "submitter": "Jingwei Ma", "authors": "Jingwei Ma, Jiahui Wen, Mingyang Zhong, Liangchen Liu, Chaojie Li,\n  Weitong Chen, Yin Yang, Honghui Tu, Xue Li", "title": "DBRec: Dual-Bridging Recommendation via Discovering Latent Groups", "comments": "10 pages, 16 figures, The 28th ACM International Conference on\n  Information and Knowledge Management (CIKM '19)", "journal-ref": null, "doi": "10.1145/3357384.3357892", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recommender systems, the user-item interaction data is usually sparse and\nnot sufficient for learning comprehensive user/item representations for\nrecommendation. To address this problem, we propose a novel dual-bridging\nrecommendation model (DBRec). DBRec performs latent user/item group discovery\nsimultaneously with collaborative filtering, and interacts group information\nwith users/items for bridging similar users/items. Therefore, a user's\npreference over an unobserved item, in DBRec, can be bridged by the users\nwithin the same group who have rated the item, or the user-rated items that\nshare the same group with the unobserved item. In addition, we propose to\njointly learn user-user group (item-item group) hierarchies, so that we can\neffectively discover latent groups and learn compact user/item representations.\nWe jointly integrate collaborative filtering, latent group discovering and\nhierarchical modelling into a unified framework, so that all the model\nparameters can be learned toward the optimization of the objective function. We\nvalidate the effectiveness of the proposed model with two real datasets, and\ndemonstrate its advantage over the state-of-the-art recommendation models with\nextensive experiments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 03:58:03 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 14:19:23 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Ma", "Jingwei", ""], ["Wen", "Jiahui", ""], ["Zhong", "Mingyang", ""], ["Liu", "Liangchen", ""], ["Li", "Chaojie", ""], ["Chen", "Weitong", ""], ["Yang", "Yin", ""], ["Tu", "Honghui", ""], ["Li", "Xue", ""]]}, {"id": "1909.12325", "submitter": "Shahana Ibrahim", "authors": "Shahana Ibrahim, Xiao Fu, Nikos Kargas, Kejun Huang", "title": "Crowdsourcing via Pairwise Co-occurrences: Identifiability and\n  Algorithms", "comments": "28 pages, 5 figures, to appear in 33rd NeurIPS conference, Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data deluge comes with high demands for data labeling. Crowdsourcing (or,\nmore generally, ensemble learning) techniques aim to produce accurate labels\nvia integrating noisy, non-expert labeling from annotators. The classic\nDawid-Skene estimator and its accompanying expectation maximization (EM)\nalgorithm have been widely used, but the theoretical properties are not fully\nunderstood. Tensor methods were proposed to guarantee identification of the\nDawid-Skene model, but the sample complexity is a hurdle for applying such\napproaches---since the tensor methods hinge on the availability of third-order\nstatistics that are hard to reliably estimate given limited data. In this\npaper, we propose a framework using pairwise co-occurrences of the annotator\nresponses, which naturally admits lower sample complexity. We show that the\napproach can identify the Dawid-Skene model under realistic conditions. We\npropose an algebraic algorithm reminiscent of convex geometry-based structured\nmatrix factorization to solve the model identification problem efficiently, and\nan identifiability-enhanced algorithm for handling more challenging and\ncritical scenarios. Experiments show that the proposed algorithms outperform\nthe state-of-art algorithms under a variety of scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 18:28:23 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ibrahim", "Shahana", ""], ["Fu", "Xiao", ""], ["Kargas", "Nikos", ""], ["Huang", "Kejun", ""]]}, {"id": "1909.12326", "submitter": "Yuang Jiang", "authors": "Yuang Jiang, Shiqiang Wang, Victor Valls, Bong Jun Ko, Wei-Han Lee,\n  Kin K. Leung, Leandros Tassiulas", "title": "Model Pruning Enables Efficient Federated Learning on Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) allows model training from local data collected by\nedge/mobile devices, while preserving data privacy. A challenge is that client\ndevices in FL usually have much more limited computation and communication\nresources compared to servers in a datacenter. To overcome this challenge, we\npropose PruneFL -- a novel FL approach with adaptive and distributed parameter\npruning, which adapts the model size during FL to reduce both communication and\ncomputation overhead and minimize the overall training time, while maintaining\na similar accuracy as the original model. PruneFL includes initial pruning at a\nselected client and further pruning as part of the FL process. The model size\nis adapted during this process, which includes maximizing the approximate\nempirical risk reduction divided by the time of one FL round. Our experiments\nwith various datasets on edge devices (e.g., Raspberry Pi) show that: (i) we\nsignificantly reduce the training time compared to conventional FL and various\nother pruning-based methods; (ii) the pruned model converges to an accuracy\nthat is very similar to the original model but has a much smaller size, and it\nis also a lottery ticket of the original model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 18:32:33 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 21:16:43 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 03:01:22 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 03:35:42 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Jiang", "Yuang", ""], ["Wang", "Shiqiang", ""], ["Valls", "Victor", ""], ["Ko", "Bong Jun", ""], ["Lee", "Wei-Han", ""], ["Leung", "Kin K.", ""], ["Tassiulas", "Leandros", ""]]}, {"id": "1909.12340", "submitter": "Mor Shpigel Nacson", "authors": "Niv Giladi, Mor Shpigel Nacson, Elad Hoffer, Daniel Soudry", "title": "At Stability's Edge: How to Adjust Hyperparameters to Preserve Minima\n  Selection in Asynchronous Training of Neural Networks?", "comments": "ICLR 2020 Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Recent developments have made it possible to accelerate neural\nnetworks training significantly using large batch sizes and data parallelism.\nTraining in an asynchronous fashion, where delay occurs, can make training even\nmore scalable. However, asynchronous training has its pitfalls, mainly a\ndegradation in generalization, even after convergence of the algorithm. This\ngap remains not well understood, as theoretical analysis so far mainly focused\non the convergence rate of asynchronous methods. Contributions: We examine\nasynchronous training from the perspective of dynamical stability. We find that\nthe degree of delay interacts with the learning rate, to change the set of\nminima accessible by an asynchronous stochastic gradient descent algorithm. We\nderive closed-form rules on how the learning rate could be changed, while\nkeeping the accessible set the same. Specifically, for high delay values, we\nfind that the learning rate should be kept inversely proportional to the delay.\nWe then extend this analysis to include momentum. We find momentum should be\neither turned off, or modified to improve training stability. We provide\nempirical experiments to validate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:05:58 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 13:06:02 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Giladi", "Niv", ""], ["Nacson", "Mor Shpigel", ""], ["Hoffer", "Elad", ""], ["Soudry", "Daniel", ""]]}, {"id": "1909.12362", "submitter": "Adityanarayanan Radhakrishnan", "authors": "Adityanarayanan Radhakrishnan, Mikhail Belkin, Caroline Uhler", "title": "Overparameterized Neural Networks Implement Associative Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying computational mechanisms for memorization and retrieval of data\nis a long-standing problem at the intersection of machine learning and\nneuroscience. Our main finding is that standard overparameterized deep neural\nnetworks trained using standard optimization methods implement such a mechanism\nfor real-valued data. Empirically, we show that: (1) overparameterized\nautoencoders store training samples as attractors, and thus, iterating the\nlearned map leads to sample recovery; (2) the same mechanism allows for\nencoding sequences of examples, and serves as an even more efficient mechanism\nfor memory than autoencoding. Theoretically, we prove that when trained on a\nsingle example, autoencoders store the example as an attractor. Lastly, by\ntreating a sequence encoder as a composition of maps, we prove that sequence\nencoding provides a more efficient mechanism for memory than autoencoding.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:53:55 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 16:16:21 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Radhakrishnan", "Adityanarayanan", ""], ["Belkin", "Mikhail", ""], ["Uhler", "Caroline", ""]]}, {"id": "1909.12367", "submitter": "Jinsung Yoon", "authors": "Jinsung Yoon, Sercan O. Arik, Tomas Pfister", "title": "RL-LIM: Reinforcement Learning-based Locally Interpretable Modeling", "comments": "18 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding black-box machine learning models is important towards their\nwidespread adoption. However, developing globally interpretable models that\nexplain the behavior of the entire model is challenging. An alternative\napproach is to explain black-box models through explaining individual\nprediction using a locally interpretable model. In this paper, we propose a\nnovel method for locally interpretable modeling - Reinforcement Learning-based\nLocally Interpretable Modeling (RL-LIM). RL-LIM employs reinforcement learning\nto select a small number of samples and distill the black-box model prediction\ninto a low-capacity locally interpretable model. Training is guided with a\nreward that is obtained directly by measuring agreement of the predictions from\nthe locally interpretable model with the black-box model. RL-LIM near-matches\nthe overall prediction performance of black-box models while yielding\nhuman-like interpretability, and significantly outperforms state of the art\nlocally interpretable models in terms of overall prediction performance and\nfidelity.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:06:45 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Yoon", "Jinsung", ""], ["Arik", "Sercan O.", ""], ["Pfister", "Tomas", ""]]}, {"id": "1909.12383", "submitter": "Ziming Zhang", "authors": "Yecheng Lyu and Xinming Huang and Ziming Zhang", "title": "Graph-Preserving Grid Layout: A Simple Graph Drawing Method for Graph\n  Classification using CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) suffer from the irregularity of graphs,\nwhile more widely-used convolutional neural networks (CNNs) benefit from\nregular grids. To bridge the gap between GCN and CNN, in contrast to previous\nworks on generalizing the basic operations in CNNs to graph data, in this paper\nwe address the problem of how to project undirected graphs onto the grid in a\n{\\em principled} way where CNNs can be used as backbone for geometric deep\nlearning. To this end, inspired by the literature of graph drawing we propose a\nnovel graph-preserving grid layout (GPGL), an integer programming that\nminimizes the topological loss on the grid. Technically we propose solving GPGL\napproximately using a {\\em regularized} Kamada-Kawai algorithm, a well-known\nnonconvex optimization technique in graph drawing, with a vertex separation\npenalty that improves the rounding performance on top of the solutions from\nrelaxation. Using GPGL we can easily conduct data augmentation as every local\nminimum will lead to a grid layout for the same graph. Together with the help\nof multi-scale maxout CNNs, we demonstrate the empirical success of our method\nfor graph classification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:53:12 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Lyu", "Yecheng", ""], ["Huang", "Xinming", ""], ["Zhang", "Ziming", ""]]}, {"id": "1909.12384", "submitter": "Xiangrui Zeng", "authors": "Xiangrui Zeng, Hongyu Zheng", "title": "CS Sparse K-means: An Algorithm for Cluster-Specific Feature Selection\n  in High-Dimensional Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature selection is an important and challenging task in high dimensional\nclustering. For example, in genomics, there may only be a small number of genes\nthat are differentially expressed, which are informative to the overall\nclustering structure. Existing feature selection methods, such as Sparse\nK-means, rarely tackle the problem of accounting features that can only\nseparate a subset of clusters. In genomics, it is highly likely that a gene can\nonly define one subtype against all the other subtypes or distinguish a pair of\nsubtypes but not others. In this paper, we propose a K-means based clustering\nalgorithm that discovers informative features as well as which cluster pairs\nare separable by each selected features. The method is essentially an EM\nalgorithm, in which we introduce lasso-type constraints on each cluster pair in\nthe M step, and make the E step possible by maximizing the raw cross-cluster\ndistance instead of minimizing the intra-cluster distance. The results were\ndemonstrated on simulated data and a leukemia gene expression dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:57:17 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 19:23:13 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zeng", "Xiangrui", ""], ["Zheng", "Hongyu", ""]]}, {"id": "1909.12385", "submitter": "Lingxiao Zhao", "authors": "Xuan Wu, Lingxiao Zhao, Leman Akoglu", "title": "A Quest for Structure: Jointly Learning the Graph Structure and\n  Semi-Supervised Classification", "comments": "11 pages, CIKM-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) is effectively used for numerous\nclassification problems, thanks to its ability to make use of abundant\nunlabeled data. The main assumption of various SSL algorithms is that the\nnearby points on the data manifold are likely to share a label. Graph-based SSL\nconstructs a graph from point-cloud data as an approximation to the underlying\nmanifold, followed by label inference. It is no surprise that the quality of\nthe constructed graph in capturing the essential structure of the data is\ncritical to the accuracy of the subsequent inference step [6]. How should one\nconstruct a graph from the input point-cloud data for graph-based SSL? In this\nwork we introduce a new, parallel graph learning framework (called PG-learn)\nfor the graph construction step of SSL. Our solution has two main ingredients:\n(1) a gradient-based optimization of the edge weights (more specifically,\ndifferent kernel bandwidths in each dimension) based on a validation loss\nfunction, and (2) a parallel hyperparameter search algorithm with an adaptive\nresource allocation scheme. In essence, (1) allows us to search around a\n(random) initial hyperparameter configuration for a better one with lower\nvalidation loss. Since the search space of hyperparameters is huge for\nhigh-dimensional problems, (2) empowers our gradient-based search to go through\nas many different initial configurations as possible, where runs for relatively\nunpromising starting configurations are terminated early to allocate the time\nfor others. As such, PG-learn is a carefully-designed hybrid of random and\nadaptive search. Through experiments on multi-class classification problems, we\nshow that PG-learn significantly outperforms a variety of existing graph\nconstruction schemes in accuracy (per fixed time budget for hyperparameter\ntuning), and scales more effectively to high dimensional problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:59:29 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Wu", "Xuan", ""], ["Zhao", "Lingxiao", ""], ["Akoglu", "Leman", ""]]}, {"id": "1909.12397", "submitter": "Moonkyung Ryu", "authors": "Moonkyung Ryu, Yinlam Chow, Ross Anderson, Christian Tjandraatmadja,\n  Craig Boutilier", "title": "CAQL: Continuous Action Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based reinforcement learning (RL) methods like Q-learning have shown\nsuccess in a variety of domains. One challenge in applying Q-learning to\ncontinuous-action RL problems, however, is the continuous action maximization\n(max-Q) required for optimal Bellman backup. In this work, we develop CAQL, a\n(class of) algorithm(s) for continuous-action Q-learning that can use several\nplug-and-play optimizers for the max-Q problem. Leveraging recent optimization\nresults for deep neural networks, we show that max-Q can be solved optimally\nusing mixed-integer programming (MIP). When the Q-function representation has\nsufficient power, MIP-based optimization gives rise to better policies and is\nmore robust than approximate methods (e.g., gradient ascent, cross-entropy\nsearch). We further develop several techniques to accelerate inference in CAQL,\nwhich despite their approximate nature, perform well. We compare CAQL with\nstate-of-the-art RL algorithms on benchmark continuous-control problems that\nhave different degrees of action constraints and show that CAQL outperforms\npolicy-based methods in heavily constrained environments, often dramatically.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:16:17 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 18:15:34 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 19:29:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ryu", "Moonkyung", ""], ["Chow", "Yinlam", ""], ["Anderson", "Ross", ""], ["Tjandraatmadja", "Christian", ""], ["Boutilier", "Craig", ""]]}, {"id": "1909.12401", "submitter": "Brent Harrison", "authors": "Md Sultan Al Nahian, Tasmia Tasrin, Sagar Gandhi, Ryan Gaines, and\n  Brent Harrison", "title": "A Hierarchical Approach for Visual Storytelling Using Image Description", "comments": "Accepted at the 2019 International Conference on Interactive Digital\n  Storytelling (ICIDS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary challenges of visual storytelling is developing techniques\nthat can maintain the context of the story over long event sequences to\ngenerate human-like stories. In this paper, we propose a hierarchical deep\nlearning architecture based on encoder-decoder networks to address this\nproblem. To better help our network maintain this context while also generating\nlong and diverse sentences, we incorporate natural language image descriptions\nalong with the images themselves to generate each story sentence. We evaluate\nour system on the Visual Storytelling (VIST) dataset and show that our method\noutperforms state-of-the-art techniques on a suite of different automatic\nevaluation metrics. The empirical results from this evaluation demonstrate the\nnecessities of different components of our proposed architecture and shows the\neffectiveness of the architecture for visual storytelling.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:25:41 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Nahian", "Md Sultan Al", ""], ["Tasrin", "Tasmia", ""], ["Gandhi", "Sagar", ""], ["Gaines", "Ryan", ""], ["Harrison", "Brent", ""]]}, {"id": "1909.12432", "submitter": "Hamidreza Mahyar", "authors": "Soroush Aalibagi, Hamidreza Mahyar, Ali Movaghar, and H. Eugene\n  Stanley", "title": "A Matrix Factorization Model for Hellinger-based Trust Management in\n  Social Internet of Things", "comments": null, "journal-ref": null, "doi": "10.1109/TDSC.2021.3052953", "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Social Internet of Things (SIoT), integration of the Internet of Things\nand Social Networks paradigms, has been introduced to build a network of smart\nnodes that are capable of establishing social links. In order to deal with\nmisbehaving service provider nodes, service requestor nodes must evaluate their\ntrustworthiness levels. In this paper, we propose a novel trust management\nmechanism in the SIoT to predict the most reliable service providers for each\nservice requestor, which leads to reduce the risk of being exposed to malicious\nnodes. We model the SIoT with a flexible bipartite graph (containing two sets\nof nodes: service providers and service requestors), then build a social\nnetwork among the service requestor nodes, using the Hellinger distance.\nAfterward, we develop a social trust model using nodes' centrality and\nsimilarity measures to extract trust behaviors among the social network nodes.\nFinally, a matrix factorization technique is designed to extract latent\nfeatures of SIoT nodes, find trustworthy nodes, and mitigate the data sparsity\nand cold start problems. We analyze the effect of parameters in the proposed\ntrust prediction mechanism on prediction accuracy. The results indicate that\nfeedbacks from the neighboring nodes of a specific service requestor with high\nHellinger similarity in our mechanism outperforms the best existing methods. We\nalso show that utilizing the social trust model, which only considers a\nsimilarity measure, significantly improves the accuracy of the prediction\nmechanism. Furthermore, we evaluate the effectiveness of the proposed trust\nmanagement system through a real-world SIoT use case. Our results demonstrate\nthat the proposed mechanism is resilient to different types of network attacks,\nand it can accurately find the most proper and trustworthy service provider.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 23:18:40 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 21:06:52 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 20:59:08 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Aalibagi", "Soroush", ""], ["Mahyar", "Hamidreza", ""], ["Movaghar", "Ali", ""], ["Stanley", "H. Eugene", ""]]}, {"id": "1909.12434", "submitter": "Divyansh Kaushik", "authors": "Divyansh Kaushik, Eduard Hovy, Zachary C. Lipton", "title": "Learning the Difference that Makes a Difference with\n  Counterfactually-Augmented Data", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite alarm over the reliance of machine learning systems on so-called\nspurious patterns, the term lacks coherent meaning in standard statistical\nframeworks. However, the language of causality offers clarity: spurious\nassociations are due to confounding (e.g., a common cause), but not direct or\nindirect causal effects. In this paper, we focus on natural language\nprocessing, introducing methods and resources for training models less\nsensitive to spurious patterns. Given documents and their initial labels, we\ntask humans with revising each document so that it (i) accords with a\ncounterfactual target label; (ii) retains internal coherence; and (iii) avoids\nunnecessary changes. Interestingly, on sentiment analysis and natural language\ninference tasks, classifiers trained on original data fail on their\ncounterfactually-revised counterparts and vice versa. Classifiers trained on\ncombined datasets perform remarkably well, just shy of those specialized to\neither domain. While classifiers trained on either original or manipulated data\nalone are sensitive to spurious features (e.g., mentions of genre), models\ntrained on the combined data are less sensitive to this signal. Both datasets\nare publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 23:25:25 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:32:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kaushik", "Divyansh", ""], ["Hovy", "Eduard", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1909.12441", "submitter": "Xin Yang", "authors": "Huaian Diao, Zhao Song, David P. Woodruff, Xin Yang", "title": "Total Least Squares Regression in Input Sparsity Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the total least squares problem, one is given an $m \\times n$ matrix $A$,\nand an $m \\times d$ matrix $B$, and one seeks to \"correct\" both $A$ and $B$,\nobtaining matrices $\\hat{A}$ and $\\hat{B}$, so that there exists an $X$\nsatisfying the equation $\\hat{A}X = \\hat{B}$. Typically the problem is\noverconstrained, meaning that $m \\gg \\max(n,d)$. The cost of the solution\n$\\hat{A}, \\hat{B}$ is given by $\\|A-\\hat{A}\\|_F^2 + \\|B - \\hat{B}\\|_F^2$. We\ngive an algorithm for finding a solution $X$ to the linear system\n$\\hat{A}X=\\hat{B}$ for which the cost $\\|A-\\hat{A}\\|_F^2 + \\|B-\\hat{B}\\|_F^2$\nis at most a multiplicative $(1+\\epsilon)$ factor times the optimal cost, up to\nan additive error $\\eta$ that may be an arbitrarily small function of $n$.\nImportantly, our running time is $\\tilde{O}( \\mathrm{nnz}(A) + \\mathrm{nnz}(B)\n) + \\mathrm{poly}(n/\\epsilon) \\cdot d$, where for a matrix $C$,\n$\\mathrm{nnz}(C)$ denotes its number of non-zero entries. Importantly, our\nrunning time does not directly depend on the large parameter $m$. As total\nleast squares regression is known to be solvable via low rank approximation, a\nnatural approach is to invoke fast algorithms for approximate low rank\napproximation, obtaining matrices $\\hat{A}$ and $\\hat{B}$ from this low rank\napproximation, and then solving for $X$ so that $\\hat{A}X = \\hat{B}$. However,\nexisting algorithms do not apply since in total least squares the rank of the\nlow rank approximation needs to be $n$, and so the running time of known\nmethods would be at least $mn^2$. In contrast, we are able to achieve a much\nfaster running time for finding $X$ by never explicitly forming the equation\n$\\hat{A} X = \\hat{B}$, but instead solving for an $X$ which is a solution to an\nimplicit such equation. Finally, we generalize our algorithm to the total least\nsquares problem with regularization.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 00:02:57 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Diao", "Huaian", ""], ["Song", "Zhao", ""], ["Woodruff", "David P.", ""], ["Yang", "Xin", ""]]}, {"id": "1909.12473", "submitter": "Gaurav Gupta", "authors": "Gaurav Gupta, Anit Kumar Sahu, Wan-Yi Lin", "title": "Noisy Batch Active Learning with Deterministic Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of training machine learning models incrementally with\nbatches of samples annotated with noisy oracles. We select each batch of\nsamples that are important and also diverse via clustering and importance\nsampling. More importantly, we incorporate model uncertainty into the sampling\nprobability to compensate for poor estimation of the importance scores when the\ntraining data is too small to build a meaningful model. Experiments on\nbenchmark image classification datasets (MNIST, SVHN, CIFAR10, and EMNIST) show\nimprovement over existing active learning strategies. We introduce an extra\ndenoising layer to deep networks to make active learning robust to label noises\nand show significant improvements.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:33:30 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 21:00:27 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Gupta", "Gaurav", ""], ["Sahu", "Anit Kumar", ""], ["Lin", "Wan-Yi", ""]]}, {"id": "1909.12475", "submitter": "Jared Dunnmon", "authors": "Luke Oakden-Rayner, Jared Dunnmon, Gustavo Carneiro, Christopher R\\'e", "title": "Hidden Stratification Causes Clinically Meaningful Failures in Machine\n  Learning for Medical Imaging", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models for medical image analysis often suffer from poor\nperformance on important subsets of a population that are not identified during\ntraining or testing. For example, overall performance of a cancer detection\nmodel may be high, but the model still consistently misses a rare but\naggressive cancer subtype. We refer to this problem as hidden stratification,\nand observe that it results from incompletely describing the meaningful\nvariation in a dataset. While hidden stratification can substantially reduce\nthe clinical efficacy of machine learning models, its effects remain difficult\nto measure. In this work, we assess the utility of several possible techniques\nfor measuring and describing hidden stratification effects, and characterize\nthese effects on multiple medical imaging datasets. We find evidence that\nhidden stratification can occur in unidentified imaging subsets with low\nprevalence, low label quality, subtle distinguishing features, or spurious\ncorrelates, and that it can result in relative performance differences of over\n20% on clinically important subsets. Finally, we explore the clinical\nimplications of our findings, and suggest that evaluation of hidden\nstratification should be a critical component of any machine learning\ndeployment in medical imaging.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:42:58 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 09:44:33 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Oakden-Rayner", "Luke", ""], ["Dunnmon", "Jared", ""], ["Carneiro", "Gustavo", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1909.12486", "submitter": "Fu-Ming Guo", "authors": "Fu-Ming Guo, Sijia Liu, Finlay S. Mungall, Xue Lin and Yanzhi Wang", "title": "Reweighted Proximal Pruning for Large-Scale Language Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pre-trained language representation flourishes as the mainstay of\nthe natural language understanding community, e.g., BERT. These pre-trained\nlanguage representations can create state-of-the-art results on a wide range of\ndownstream tasks. Along with continuous significant performance improvement,\nthe size and complexity of these pre-trained neural models continue to increase\nrapidly. Is it possible to compress these large-scale language representation\nmodels? How will the pruned language representation affect the downstream\nmulti-task transfer learning objectives? In this paper, we propose Reweighted\nProximal Pruning (RPP), a new pruning method specifically designed for a\nlarge-scale language representation model. Through experiments on SQuAD and the\nGLUE benchmark suite, we show that proximal pruned BERT keeps high accuracy for\nboth the pre-training task and the downstream multiple fine-tuning tasks at\nhigh prune ratio. RPP provides a new perspective to help us analyze what\nlarge-scale language representation might learn. Additionally, RPP makes it\npossible to deploy a large state-of-the-art language representation model such\nas BERT on a series of distinct devices (e.g., online servers, mobile phones,\nand edge devices).\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 04:10:10 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 01:23:53 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Guo", "Fu-Ming", ""], ["Liu", "Sijia", ""], ["Mungall", "Finlay S.", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1909.12488", "submitter": "Jakub Kone\\v{c}n\\'y", "authors": "Yihan Jiang, Jakub Kone\\v{c}n\\'y, Keith Rush, Sreeram Kannan", "title": "Improving Federated Learning Personalization via Model Agnostic Meta\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) refers to learning a high quality global model based\non decentralized data storage, without ever copying the raw data. A natural\nscenario arises with data created on mobile phones by the activity of their\nusers. Given the typical data heterogeneity in such situations, it is natural\nto ask how can the global model be personalized for every such device,\nindividually. In this work, we point out that the setting of Model Agnostic\nMeta Learning (MAML), where one optimizes for a fast, gradient-based, few-shot\nadaptation to a heterogeneous distribution of tasks, has a number of\nsimilarities with the objective of personalization for FL. We present FL as a\nnatural source of practical applications for MAML algorithms, and make the\nfollowing observations. 1) The popular FL algorithm, Federated Averaging, can\nbe interpreted as a meta learning algorithm. 2) Careful fine-tuning can yield a\nglobal model with higher accuracy, which is at the same time easier to\npersonalize. However, solely optimizing for the global model accuracy yields a\nweaker personalization result. 3) A model trained using a standard datacenter\noptimization method is much harder to personalize, compared to one trained\nusing Federated Averaging, supporting the first claim. These results raise new\nquestions for FL, MAML, and broader ML research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 04:26:37 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Jiang", "Yihan", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Rush", "Keith", ""], ["Kannan", "Sreeram", ""]]}, {"id": "1909.12518", "submitter": "Lior Kamma", "authors": "Allan Gr{\\o}nlund, Lior Kamma, Kasper Green Larsen, Alexander\n  Mathiasen, Jelani Nelson", "title": "Margin-Based Generalization Lower Bounds for Boosted Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is one of the most successful ideas in machine learning. The most\nwell-accepted explanations for the low generalization error of boosting\nalgorithms such as AdaBoost stem from margin theory. The study of margins in\nthe context of boosting algorithms was initiated by Schapire, Freund, Bartlett\nand Lee (1998) and has inspired numerous boosting algorithms and generalization\nbounds. To date, the strongest known generalization (upper bound) is the $k$th\nmargin bound of Gao and Zhou (2013). Despite the numerous generalization upper\nbounds that have been proved over the last two decades, nothing is known about\nthe tightness of these bounds. In this paper, we give the first margin-based\nlower bounds on the generalization error of boosted classifiers. Our lower\nbounds nearly match the $k$th margin bound and thus almost settle the\ngeneralization performance of boosted classifiers in terms of margins.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 06:56:47 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:39:11 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 08:07:50 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 05:56:19 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Gr\u00f8nlund", "Allan", ""], ["Kamma", "Lior", ""], ["Larsen", "Kasper Green", ""], ["Mathiasen", "Alexander", ""], ["Nelson", "Jelani", ""]]}, {"id": "1909.12535", "submitter": "Duc Bui", "authors": "Duc Bui, Kshitiz Malik, Jack Goetz, Honglei Liu, Seungwhan Moon, Anuj\n  Kumar, Kang G. Shin", "title": "Federated User Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative personalization, such as through learned user representations\n(embeddings), can improve the prediction accuracy of neural-network-based\nmodels significantly. We propose Federated User Representation Learning (FURL),\na simple, scalable, privacy-preserving and resource-efficient way to utilize\nexisting neural personalization techniques in the Federated Learning (FL)\nsetting. FURL divides model parameters into federated and private parameters.\nPrivate parameters, such as private user embeddings, are trained locally, but\nunlike federated parameters, they are not transferred to or averaged on the\nserver. We show theoretically that this parameter split does not affect\ntraining for most model personalization approaches. Storing user embeddings\nlocally not only preserves user privacy, but also improves memory locality of\npersonalization compared to on-server training. We evaluate FURL on two\ndatasets, demonstrating a significant improvement in model quality with 8% and\n51% performance increases, and approximately the same level of performance as\ncentralized training with only 0% and 4% reductions. Furthermore, we show that\nuser embeddings learned in FL and the centralized setting have a very similar\nstructure, indicating that FURL can learn collaboratively through the shared\nparameters while preserving user privacy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 07:40:08 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Bui", "Duc", ""], ["Malik", "Kshitiz", ""], ["Goetz", "Jack", ""], ["Liu", "Honglei", ""], ["Moon", "Seungwhan", ""], ["Kumar", "Anuj", ""], ["Shin", "Kang G.", ""]]}, {"id": "1909.12552", "submitter": "Valerio Perrone", "authors": "Valerio Perrone, Huibin Shen, Matthias Seeger, Cedric Archambeau,\n  Rodolphe Jenatton", "title": "Learning search spaces for Bayesian optimization: Another view of\n  hyperparameter transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a successful methodology to optimize black-box\nfunctions that are expensive to evaluate. While traditional methods optimize\neach black-box function in isolation, there has been recent interest in\nspeeding up BO by transferring knowledge across multiple related black-box\nfunctions. In this work, we introduce a method to automatically design the BO\nsearch space by relying on evaluations of previous black-box functions. We\ndepart from the common practice of defining a set of arbitrary search ranges a\npriori by considering search space geometries that are learned from historical\ndata. This simple, yet effective strategy can be used to endow many existing BO\nmethods with transfer learning properties. Despite its simplicity, we show that\nour approach considerably boosts BO by reducing the size of the search space,\nthus accelerating the optimization of a variety of black-box optimization\nproblems. In particular, the proposed approach combined with random search\nresults in a parameter-free, easy-to-implement, robust hyperparameter\noptimization strategy. We hope it will constitute a natural baseline for\nfurther research attempting to warm-start BO.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:22:48 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Perrone", "Valerio", ""], ["Shen", "Huibin", ""], ["Seeger", "Matthias", ""], ["Archambeau", "Cedric", ""], ["Jenatton", "Rodolphe", ""]]}, {"id": "1909.12555", "submitter": "Shen Li", "authors": "Shen Li, Bryan Hooi, Gim Hee Lee", "title": "Identifying through Flows for Recovering Latent Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifiability, or recovery of the true latent representations from which\nthe observed data originates, is de facto a fundamental goal of representation\nlearning. Yet, most deep generative models do not address the question of\nidentifiability, and thus fail to deliver on the promise of the recovery of the\ntrue latent sources that generate the observations. Recent work proposed\nidentifiable generative modelling using variational autoencoders (iVAE) with a\ntheory of identifiability. Due to the intractablity of KL divergence between\nvariational approximate posterior and the true posterior, however, iVAE has to\nmaximize the evidence lower bound (ELBO) of the marginal likelihood, leading to\nsuboptimal solutions in both theory and practice. In contrast, we propose an\nidentifiable framework for estimating latent representations using a flow-based\nmodel (iFlow). Our approach directly maximizes the marginal likelihood,\nallowing for theoretical guarantees on identifiability, thereby dispensing with\nvariational approximations. We derive its optimization objective in analytical\nform, making it possible to train iFlow in an end-to-end manner. Simulations on\nsynthetic data validate the correctness and effectiveness of our proposed\nmethod and demonstrate its practical advantages over other existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:37:13 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 00:48:12 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 01:07:37 GMT"}, {"version": "v4", "created": "Sun, 26 Apr 2020 07:21:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Li", "Shen", ""], ["Hooi", "Bryan", ""], ["Lee", "Gim Hee", ""]]}, {"id": "1909.12557", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "Multi-Agent Actor-Critic with Hierarchical Graph Attention Network", "comments": "Accepted as a conference paper at the Thirty-Fourth AAAI Conference\n  on Artificial Intelligence (AAAI-20), New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most previous studies on multi-agent reinforcement learning focus on deriving\ndecentralized and cooperative policies to maximize a common reward and rarely\nconsider the transferability of trained policies to new tasks. This prevents\nsuch policies from being applied to more complex multi-agent tasks. To resolve\nthese limitations, we propose a model that conducts both representation\nlearning for multiple agents using hierarchical graph attention network and\npolicy learning using multi-agent actor-critic. The hierarchical graph\nattention network is specially designed to model the hierarchical relationships\namong multiple agents that either cooperate or compete with each other to\nderive more advanced strategic policies. Two attention networks, the\ninter-agent and inter-group attention layers, are used to effectively model\nindividual and group level interactions, respectively. The two attention\nnetworks have been proven to facilitate the transfer of learned policies to new\ntasks with different agent compositions and allow one to interpret the learned\nstrategies. Empirically, we demonstrate that the proposed model outperforms\nexisting methods in several mixed cooperative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:40:01 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 02:38:58 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1909.12566", "submitter": "Hamid Zafar", "authors": "Hamid Zafar, Maryam Tavakol, Jens Lehmann", "title": "Distantly Supervised Question Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of structured databases for Question Answering (QA) systems has\nled to developing methods, in which the problem of learning the correct answer\nefficiently is based on a linking task between the constituents of the question\nand the corresponding entries in the database. As a result, parsing the\nquestions in order to determine their main elements, which are required for\nanswer retrieval, becomes crucial. However, most datasets for QA systems lack\ngold annotations for parsing, i.e., labels are only available in the form of\n(question, formal-query, answer). In this paper, we propose a distantly\nsupervised learning framework based on reinforcement learning to learn the\nmentions of entities and relations in questions. We leverage the provided\nformal queries to characterize delayed rewards for optimizing a policy gradient\nobjective for the parsing model. An empirical evaluation of our approach shows\na significant improvement in the performance of entity and relation linking\ncompared to the state of the art. We also demonstrate that a more accurate\nparsing component enhances the overall performance of QA systems.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:58:20 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 13:31:12 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zafar", "Hamid", ""], ["Tavakol", "Maryam", ""], ["Lehmann", "Jens", ""]]}, {"id": "1909.12580", "submitter": "Malik Magdon-Ismail", "authors": "Malik Magdon-Ismail, Alex Gittens", "title": "Fast Fixed Dimension L2-Subspace Embeddings of Arbitrary Accuracy, With\n  Application to L1 and L2 Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a fast oblivious L2-embedding of $A\\in \\mathbb{R}^{n x d}$ to $B\\in\n\\mathbb{R}^{r x d}$ satisfying $(1-\\varepsilon)\\|A x\\|_2^2 \\le \\|B x\\|_2^2 <=\n(1+\\varepsilon) \\|Ax\\|_2^2.$ Our embedding dimension $r$ equals $d$, a constant\nindependent of the distortion $\\varepsilon$. We use as a black-box any\nL2-embedding $\\Pi^T A$ and inherit its runtime and accuracy, effectively\ndecoupling the dimension $r$ from runtime and accuracy, allowing downstream\nmachine learning applications to benefit from both a low dimension and high\naccuracy (in prior embeddings higher accuracy means higher dimension). We give\napplications of our L2-embedding to regression, PCA and statistical leverage\nscores. We also give applications to L1: 1.) An oblivious L1-embedding with\ndimension $d+O(d\\ln^{1+\\eta} d)$ and distortion $O((d\\ln d)/\\ln\\ln d)$, with\napplication to constructing well-conditioned bases; 2.) Fast approximation of\nL1-Lewis weights using our L2 embedding to quickly approximate L2-leverage\nscores.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 09:41:47 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Magdon-Ismail", "Malik", ""], ["Gittens", "Alex", ""]]}, {"id": "1909.12598", "submitter": "Apratim Bhattacharyya", "authors": "Apratim Bhattacharyya, Mario Fritz, Bernt Schiele", "title": "\"Best-of-Many-Samples\" Distribution Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) can achieve state-of-the-art sample\nquality in generative modelling tasks but suffer from the mode collapse\nproblem. Variational Autoencoders (VAE) on the other hand explicitly maximize a\nreconstruction-based data log-likelihood forcing it to cover all modes, but\nsuffer from poorer sample quality. Recent works have proposed hybrid VAE-GAN\nframeworks which integrate a GAN-based synthetic likelihood to the VAE\nobjective to address both the mode collapse and sample quality issues, with\nlimited success. This is because the VAE objective forces a trade-off between\nthe data log-likelihood and divergence to the latent prior. The synthetic\nlikelihood ratio term also shows instability during training. We propose a\nnovel objective with a \"Best-of-Many-Samples\" reconstruction cost and a stable\ndirect estimate of the synthetic likelihood. This enables our hybrid VAE-GAN\nframework to achieve high data log-likelihood and low divergence to the latent\nprior at the same time and shows significant improvement over both hybrid\nVAE-GANS and plain GANs in mode coverage and quality.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 10:23:42 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Bhattacharyya", "Apratim", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "1909.12637", "submitter": "Vincent Fortuin", "authors": "Margherita Rosnati, Vincent Fortuin", "title": "MGP-AttTCN: An Interpretable Machine Learning Model for the Prediction\n  of Sepsis", "comments": "Published at PLOS ONE", "journal-ref": null, "doi": "10.1371/journal.pone.0251248", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a mortality rate of 5.4 million lives worldwide every year and a\nhealthcare cost of more than 16 billion dollars in the USA alone, sepsis is one\nof the leading causes of hospital mortality and an increasing concern in the\nageing western world. Recently, medical and technological advances have helped\nre-define the illness criteria of this disease, which is otherwise poorly\nunderstood by the medical society. Together with the rise of widely accessible\nElectronic Health Records, the advances in data mining and complex nonlinear\nalgorithms are a promising avenue for the early detection of sepsis. This work\ncontributes to the research effort in the field of automated sepsis detection\nwith an open-access labelling of the medical MIMIC-III data set. Moreover, we\npropose MGP-AttTCN: a joint multitask Gaussian Process and attention-based deep\nlearning model to early predict the occurrence of sepsis in an interpretable\nmanner. We show that our model outperforms the current state-of-the-art and\npresent evidence that different labelling heuristics lead to discrepancies in\ntask difficulty. For instance, when predicting sepsis five hours prior to onset\non our new realistic labels, our proposed model achieves an area under the ROC\ncurve of 0.660 and an area under the PR curve of 0.483, whereas the (less\ninterpretable) previous state-of-the-art model (MGP-TCN) achieves 0.635 AUROC\nand 0.460 AUPR and the popular commercial InSight model achieves 0.490 AUROC\nand 0.359 AUPR.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 11:55:24 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 16:36:40 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Rosnati", "Margherita", ""], ["Fortuin", "Vincent", ""]]}, {"id": "1909.12641", "submitter": "Jack Goetz", "authors": "Jack Goetz, Kshitiz Malik, Duc Bui, Seungwhan Moon, Honglei Liu and\n  Anuj Kumar", "title": "Active Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning allows for population level models to be trained without\ncentralizing client data by transmitting the global model to clients,\ncalculating gradients locally, then averaging the gradients. Downloading models\nand uploading gradients uses the client's bandwidth, so minimizing these\ntransmission costs is important. The data on each client is highly variable, so\nthe benefit of training on different clients may differ dramatically. To\nexploit this we propose Active Federated Learning, where in each round clients\nare selected not uniformly at random, but with a probability conditioned on the\ncurrent model and the data on the client to maximize efficiency. We propose a\ncheap, simple and intuitive sampling scheme which reduces the number of\nrequired training iterations by 20-70% while maintaining the same model\naccuracy, and which mimics well known resampling techniques under certain\nconditions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:15:42 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Goetz", "Jack", ""], ["Malik", "Kshitiz", ""], ["Bui", "Duc", ""], ["Moon", "Seungwhan", ""], ["Liu", "Honglei", ""], ["Kumar", "Anuj", ""]]}, {"id": "1909.12644", "submitter": "Shotaro Akaho", "authors": "Shotaro Akaho, Hideitsu Hino, Noboru Murata", "title": "On a convergence property of a geometrical algorithm for statistical\n  manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine a geometrical projection algorithm for statistical\ninference. The algorithm is based on Pythagorean relation and it is\nderivative-free as well as representation-free that is useful in nonparametric\ncases. We derive a bound of learning rate to guarantee local convergence. In\nspecial cases of m-mixture and e-mixture estimation problems, we calculate\nspecific forms of the bound that can be used easily in practice.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:23:52 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Akaho", "Shotaro", ""], ["Hino", "Hideitsu", ""], ["Murata", "Noboru", ""]]}, {"id": "1909.12655", "submitter": "Kosuke Arase", "authors": "Kosuke Arase, Yusuke Mukuta, and Tatsuya Harada", "title": "Rethinking Task and Metrics of Instance Segmentation on 3D Point Clouds", "comments": "The 4th Workshop on Geometry Meets Deep Learning (ICCV Workshop 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance segmentation on 3D point clouds is one of the most extensively\nresearched areas toward the realization of autonomous cars and robots. Certain\nexisting studies have split input point clouds into small regions such as 1m x\n1m; one reason for this is that models in the studies cannot consume a large\nnumber of points because of the large space complexity. However, because such\nsmall regions occasionally include a very small number of instances belonging\nto the same class, an evaluation using existing metrics such as mAP is largely\naffected by the category recognition performance. To address these problems, we\npropose a new method with space complexity O(Np) such that large regions can be\nconsumed, as well as novel metrics for tasks that are independent of the\ncategories or size of the inputs. Our method learns a mapping from input point\nclouds to an embedding space, where the embeddings form clusters for each\ninstance and distinguish instances using these clusters during testing. Our\nmethod achieves state-of-the-art performance using both existing and the\nproposed metrics. Moreover, we show that our new metric can evaluate the\nperformance of a task without being affected by any other condition.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:45:12 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Arase", "Kosuke", ""], ["Mukuta", "Yusuke", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1909.12673", "submitter": "Jonathan Rosenfeld", "authors": "Jonathan S. Rosenfeld, Amir Rosenfeld, Yonatan Belinkov, Nir Shavit", "title": "A Constructive Prediction of the Generalization Error Across Scales", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dependency of the generalization error of neural networks on model and\ndataset size is of critical importance both in practice and for understanding\nthe theory of neural networks. Nevertheless, the functional form of this\ndependency remains elusive. In this work, we present a functional form which\napproximates well the generalization error in practice. Capitalizing on the\nsuccessful concept of model scaling (e.g., width, depth), we are able to\nsimultaneously construct such a form and specify the exact models which can\nattain it across model/data scales. Our construction follows insights obtained\nfrom observations conducted over a range of model/data scales, in various model\ntypes and datasets, in vision and language tasks. We show that the form both\nfits the observations well across scales, and provides accurate predictions\nfrom small- to large-scale models and data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 13:27:53 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:20:34 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Rosenfeld", "Jonathan S.", ""], ["Rosenfeld", "Amir", ""], ["Belinkov", "Yonatan", ""], ["Shavit", "Nir", ""]]}, {"id": "1909.12702", "submitter": "Sunil Aryal", "authors": "Sunil Aryal, Arbind Agrahari Baniya and KC Santosh", "title": "Improved histogram-based anomaly detector with the extended principal\n  component features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of big data, databases are growing rapidly in terms of the number\nof records. Fast automatic detection of anomalous records in these massive\ndatabases is a challenging task. Traditional distance based anomaly detectors\nare not applicable in these massive datasets. Recently, a simple but extremely\nfast anomaly detector using one-dimensional histograms has been introduced. The\nanomaly score of a data instance is computed as the product of the probability\nmass of histograms in each dimensions where it falls into. It is shown to\nproduce competitive results compared to many state-of-the-art methods in many\ndatasets. Because it assumes data features are independent of each other, it\nresults in poor detection accuracy when there is correlation between features.\nTo address this issue, we propose to increase the feature size by adding more\nfeatures based on principal components. Our results show that using the\noriginal input features together with principal components improves the\ndetection accuracy of histogram-based anomaly detector significantly without\ncompromising much in terms of run-time.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 14:18:10 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Aryal", "Sunil", ""], ["Baniya", "Arbind Agrahari", ""], ["Santosh", "KC", ""]]}, {"id": "1909.12732", "submitter": "Shruti Tople", "authors": "Shruti Tople and Amit Sharma and Aditya Nori", "title": "Alleviating Privacy Attacks via Causal Learning", "comments": "Accepted at International Conference on Machine Learning, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models, especially deep neural networks have been shown to\nbe susceptible to privacy attacks such as membership inference where an\nadversary can detect whether a data point was used for training a black-box\nmodel. Such privacy risks are exacerbated when a model's predictions are used\non an unseen data distribution. To alleviate privacy attacks, we demonstrate\nthe benefit of predictive models that are based on the causal relationships\nbetween input features and the outcome. We first show that models learnt using\ncausal structure generalize better to unseen data, especially on data from\ndifferent distributions than the train distribution. Based on this\ngeneralization property, we establish a theoretical link between causality and\nprivacy: compared to associational models, causal models provide stronger\ndifferential privacy guarantees and are more robust to membership inference\nattacks. Experiments on simulated Bayesian networks and the colored-MNIST\ndataset show that associational models exhibit upto 80% attack accuracy under\ndifferent test distributions and sample sizes whereas causal models exhibit\nattack accuracy close to a random guess.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:06:42 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 18:15:45 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 16:20:02 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 14:02:13 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Tople", "Shruti", ""], ["Sharma", "Amit", ""], ["Nori", "Aditya", ""]]}, {"id": "1909.12734", "submitter": "Praneeth Vepakomma", "authors": "Indu Ilanchezian, Praneeth Vepakomma, Abhishek Singh, Otkrist Gupta,\n  G. N. Srinivasa Prasanna, Ramesh Raskar", "title": "Maximal adversarial perturbations for obfuscation: Hiding certain\n  attributes while preserving rest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the usage of adversarial perturbations for the\npurpose of privacy from human perception and model (machine) based detection.\nWe employ adversarial perturbations for obfuscating certain variables in raw\ndata while preserving the rest. Current adversarial perturbation methods are\nused for data poisoning with minimal perturbations of the raw data such that\nthe machine learning model's performance is adversely impacted while the human\nvision cannot perceive the difference in the poisoned dataset due to minimal\nnature of perturbations. We instead apply relatively maximal perturbations of\nraw data to conditionally damage model's classification of one attribute while\npreserving the model performance over another attribute. In addition, the\nmaximal nature of perturbation helps adversely impact human perception in\nclassifying hidden attribute apart from impacting model performance. We\nvalidate our result qualitatively by showing the obfuscated dataset and\nquantitatively by showing the inability of models trained on clean data to\npredict the hidden attribute from the perturbed dataset while being able to\npredict the rest of attributes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:08:46 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ilanchezian", "Indu", ""], ["Vepakomma", "Praneeth", ""], ["Singh", "Abhishek", ""], ["Gupta", "Otkrist", ""], ["Prasanna", "G. N. Srinivasa", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1909.12737", "submitter": "Gon\\c{c}alo Faria", "authors": "Gon\\c{c}alo Faria", "title": "Learning to compute inner consensus: A novel approach to modeling\n  agreement between Capsules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This project considers Capsule Networks, a recently introduced machine\nlearning model that has shown promising results regarding generalization and\npreservation of spatial information with few parameters. The Capsule Network's\ninner routing procedures thus far proposed, a priori, establish how the routing\nrelations are modeled, which limits the expressiveness of the underlying model.\nIn this project, we propose two distinct ways in which the routing procedure\ncan be learned like any other network parameter.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:13:13 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 23:33:53 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 15:46:01 GMT"}, {"version": "v4", "created": "Wed, 11 Dec 2019 16:33:03 GMT"}, {"version": "v5", "created": "Thu, 9 Jan 2020 18:22:45 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Faria", "Gon\u00e7alo", ""]]}, {"id": "1909.12741", "submitter": "R\\'emi Bernhard", "authors": "R\\'emi Bernhard, Pierre-Alain Moellic and Jean-Max Dutertre", "title": "Impact of Low-bitwidth Quantization on the Adversarial Robustness for\n  Embedded Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the will to deploy neural networks models on embedded systems grows, and\nconsidering the related memory footprint and energy consumption issues, finding\nlighter solutions to store neural networks such as weight quantization and more\nefficient inference methods become major research topics. Parallel to that,\nadversarial machine learning has risen recently with an impressive and\nsignificant attention, unveiling some critical flaws of machine learning\nmodels, especially neural networks. In particular, perturbed inputs called\nadversarial examples have been shown to fool a model into making incorrect\npredictions. In this article, we investigate the adversarial robustness of\nquantized neural networks under different threat models for a classical\nsupervised image classification task. We show that quantization does not offer\nany robust protection, results in severe form of gradient masking and advance\nsome hypotheses to explain it. However, we experimentally observe poor\ntransferability capacities which we explain by quantization value shift\nphenomenon and gradient misalignment and explore how these results can be\nexploited with an ensemble-based defense.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:18:37 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:34:24 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Bernhard", "R\u00e9mi", ""], ["Moellic", "Pierre-Alain", ""], ["Dutertre", "Jean-Max", ""]]}, {"id": "1909.12743", "submitter": "Reza Bahmanyar", "authors": "Reza Bahmanyar, Elenora Vig, and Peter Reinartz", "title": "MRCNet: Crowd Counting and Density Map Estimation in Aerial and Ground\n  Imagery", "comments": null, "journal-ref": "BMVC Workshop on Object Detection and Recognition for Security\n  Screenin (BMVC-ODRSS) 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the many advantages of aerial imagery for crowd monitoring and\nmanagement at mass events, datasets of aerial images of crowds are still\nlacking in the field. As a remedy, in this work we introduce a novel crowd\ndataset, the DLR Aerial Crowd Dataset (DLR-ACD), which is composed of 33 large\naerial images acquired from 16 flight campaigns over mass events with 226,291\npersons annotated. To the best of our knowledge, DLR-ACD is the first aerial\ncrowd dataset and will be released publicly. To tackle the problem of accurate\ncrowd counting and density map estimation in aerial images of crowds, this work\nalso proposes a new encoder-decoder convolutional neural network, the so-called\nMulti-Resolution Crowd Network MRCNet. The encoder is based on the VGG-16\nnetwork and the decoder is composed of a set of bilinear upsampling and\nconvolutional layers. Using two losses, one at an earlier level and another at\nthe last level of the decoder, MRCNet estimates crowd counts and\nhigh-resolution crowd density maps as two different but interrelated tasks. In\naddition, MRCNet utilizes contextual and detailed local information by\ncombining high- and low-level features through a number of lateral connections\ninspired by the Feature Pyramid Network (FPN) technique. We evaluated MRCNet on\nthe proposed DLR-ACD dataset as well as on the ShanghaiTech dataset, a\nCCTV-based crowd counting benchmark. The results demonstrate that MRCNet\noutperforms the state-of-the-art crowd counting methods in estimating the crowd\ncounts and density maps for both aerial and CCTV-based images.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:22:23 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bahmanyar", "Reza", ""], ["Vig", "Elenora", ""], ["Reinartz", "Peter", ""]]}, {"id": "1909.12778", "submitter": "Xiaohan Ding", "authors": "Xiaohan Ding, Guiguang Ding, Xiangxin Zhou, Yuchen Guo, Jungong Han,\n  Ji Liu", "title": "Global Sparse Momentum SGD for Pruning Very Deep Neural Networks", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) is powerful but computationally expensive and\nmemory intensive, thus impeding its practical usage on resource-constrained\nfront-end devices. DNN pruning is an approach for deep model compression, which\naims at eliminating some parameters with tolerable performance degradation. In\nthis paper, we propose a novel momentum-SGD-based optimization method to reduce\nthe network complexity by on-the-fly pruning. Concretely, given a global\ncompression ratio, we categorize all the parameters into two parts at each\ntraining iteration which are updated using different rules. In this way, we\ngradually zero out the redundant parameters, as we update them using only the\nordinary weight decay but no gradients derived from the objective function. As\na departure from prior methods that require heavy human works to tune the\nlayer-wise sparsity ratios, prune by solving complicated non-differentiable\nproblems or finetune the model after pruning, our method is characterized by 1)\nglobal compression that automatically finds the appropriate per-layer sparsity\nratios; 2) end-to-end training; 3) no need for a time-consuming re-training\nprocess after pruning; and 4) superior capability to find better winning\ntickets which have won the initialization lottery.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:24:19 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:21:53 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 15:39:02 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Ding", "Xiaohan", ""], ["Ding", "Guiguang", ""], ["Zhou", "Xiangxin", ""], ["Guo", "Yuchen", ""], ["Han", "Jungong", ""], ["Liu", "Ji", ""]]}, {"id": "1909.12789", "submitter": "Hongxun Jiang", "authors": "Yancong Xie, Hongxun Jiang", "title": "Stock Market Forecasting Based on Text Mining Technology: A Support\n  Vector Machine Method", "comments": "11 pages, 10 figures, 5 tables", "journal-ref": "J. Comp. 12 (2017) 500-510", "doi": "10.17706/jcp.12.6.500-510", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  News items have a significant impact on stock markets but the ways are\nobscure. Many previous works have aimed at finding accurate stock market\nforecasting models. In this paper, we use text mining and sentiment analysis on\nChinese online financial news, to predict Chinese stock tendency and stock\nprices based on support vector machine (SVM). Firstly, we collect 2,302,692\nnews items, which date from 1/1/2008 to 1/1/2015. Secondly, based on this\ndataset, a specific domain stop-word dictionary and a precise sentiment\ndictionary are formed. Thirdly, we propose a forecasting model using SVM. On\nthe algorithm of SVM implementation, we also propose two-parameter optimization\nalgorithms to search for the best initial parameter setting. The result shows\nthat parameter G has the main effect, while parameter C's effect is not\nobvious. Furthermore, support vector regression (SVR) models for different\nChinese stocks are similar whereas in support vector classification (SVC)\nmodels best parameters are quite differential. Series of contrast experiments\nshow that: a) News has significant influence on stock market; b) Expansion\ninput vector for additional situations when that day has no news data is better\nthan normal input in SVR, yet is worse in SVC; c) SVR shows a fantastic degree\nof fitting in predicting stock fluctuation while such result has some time lag;\nd) News effect time lag for stock market is less than two days; e) In SVC,\nhistoric stock data has a most efficient time lag which is about 10 days,\nwhereas in SVR this effect is not obvious. Besides, based on the special\nstructure of the input vector, we also design a method to calculate the\nfinancial source impact factor. Result suggests that the news quality and\naudience number both have a significant effect on the source impact factor.\nBesides, for Chinese investors, traditional media has more influence than\ndigital media.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:52:27 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Xie", "Yancong", ""], ["Jiang", "Hongxun", ""]]}, {"id": "1909.12830", "submitter": "Brandon Amos", "authors": "Brandon Amos, Denis Yarats", "title": "The Differentiable Cross-Entropy Method", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the cross-entropy method (CEM) for the non-convex optimization of a\ncontinuous and parameterized objective function and introduce a differentiable\nvariant that enables us to differentiate the output of CEM with respect to the\nobjective function's parameters. In the machine learning setting this brings\nCEM inside of the end-to-end learning pipeline where this has otherwise been\nimpossible. We show applications in a synthetic energy-based structured\nprediction task and in non-convex continuous control. In the control setting we\nshow how to embed optimal action sequences into a lower-dimensional space. DCEM\nenables us to fine-tune CEM-based controllers with policy optimization.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 17:59:08 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 16:28:10 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 17:24:05 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 23:10:39 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Amos", "Brandon", ""], ["Yarats", "Denis", ""]]}, {"id": "1909.12892", "submitter": "Andrew Lampinen", "authors": "Sebastien Racaniere, Andrew K. Lampinen, Adam Santoro, David P.\n  Reichert, Vlad Firoiu, Timothy P. Lillicrap", "title": "Automated curricula through setter-solver interactions", "comments": null, "journal-ref": "International Conference on Learning Representations, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms use correlations between policies and\nrewards to improve agent performance. But in dynamic or sparsely rewarding\nenvironments these correlations are often too small, or rewarding events are\ntoo infrequent to make learning feasible. Human education instead relies on\ncurricula--the breakdown of tasks into simpler, static challenges with dense\nrewards--to build up to complex behaviors. While curricula are also useful for\nartificial agents, hand-crafting them is time consuming. This has lead\nresearchers to explore automatic curriculum generation. Here we explore\nautomatic curriculum generation in rich, dynamic environments. Using a\nsetter-solver paradigm we show the importance of considering goal validity,\ngoal feasibility, and goal coverage to construct useful curricula. We\ndemonstrate the success of our approach in rich but sparsely rewarding 2D and\n3D environments, where an agent is tasked to achieve a single goal selected\nfrom a set of possible goals that varies between episodes, and identify\nchallenges for future work. Finally, we demonstrate the value of a novel\ntechnique that guides agents towards a desired goal distribution. Altogether,\nthese results represent a substantial step towards applying automatic task\ncurricula to learn complex, otherwise unlearnable goals, and to our knowledge\nare the first to demonstrate automated curriculum generation for\ngoal-conditioned agents in environments where the possible goals vary between\nepisodes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 20:11:12 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 00:01:48 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Racaniere", "Sebastien", ""], ["Lampinen", "Andrew K.", ""], ["Santoro", "Adam", ""], ["Reichert", "David P.", ""], ["Firoiu", "Vlad", ""], ["Lillicrap", "Timothy P.", ""]]}, {"id": "1909.12898", "submitter": "Mahsa Ghasemi", "authors": "Mahsa Ghasemi, Abolfazl Hashemi, Haris Vikalo, Ufuk Topcu", "title": "Identifying Sparse Low-Dimensional Structures in Markov Chains: A\n  Nonnegative Matrix Factorization Approach", "comments": "Accepted for publication in American Control Conference (ACC)\n  Proceedings, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning low-dimensional representations for\nlarge-scale Markov chains. We formulate the task of representation learning as\nthat of mapping the state space of the model to a low-dimensional state space,\ncalled the kernel space. The kernel space contains a set of meta states which\nare desired to be representative of only a small subset of original states. To\npromote this structural property, we constrain the number of nonzero entries of\nthe mappings between the state space and the kernel space. By imposing the\ndesired characteristics of the representation, we cast the problem as a\nconstrained nonnegative matrix factorization. To compute the solution, we\npropose an efficient block coordinate gradient descent and theoretically\nanalyze its convergence properties.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 20:28:44 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 19:23:56 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ghasemi", "Mahsa", ""], ["Hashemi", "Abolfazl", ""], ["Vikalo", "Haris", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1909.12903", "submitter": "Shupeng Gui", "authors": "Shupeng Gui, Xiangliang Zhang, Pan Zhong, Shuang Qiu, Mingrui Wu,\n  Jieping Ye, Zhengdao Wang, and Ji Liu", "title": "PINE: Universal Deep Embedding for Graph Nodes via Partial Permutation\n  Invariant Set Functions", "comments": "24 pages, 4 figures, 3 tables. arXiv admin note: text overlap with\n  arXiv:1805.11182", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph node embedding aims at learning a vector representation for all nodes\ngiven a graph. It is a central problem in many machine learning tasks (e.g.,\nnode classification, recommendation, community detection). The key problem in\ngraph node embedding lies in how to define the dependence to neighbors.\nExisting approaches specify (either explicitly or implicitly) certain\ndependencies on neighbors, which may lead to loss of subtle but important\nstructural information within the graph and other dependencies among neighbors.\nThis intrigues us to ask the question: can we design a model to give the\nmaximal flexibility of dependencies to each node's neighborhood. In this paper,\nwe propose a novel graph node embedding (named PINE) via a novel notion of\npartial permutation invariant set function, to capture any possible dependence.\nOur method 1) can learn an arbitrary form of the representation function from\nthe neighborhood, withour losing any potential dependence structures, and 2) is\napplicable to both homogeneous and heterogeneous graph embedding, the latter of\nwhich is challenged by the diversity of node types. Furthermore, we provide\ntheoretical guarantee for the representation capability of our method for\ngeneral homogeneous and heterogeneous graphs. Empirical evaluation results on\nbenchmark data sets show that our proposed PINE method outperforms the\nstate-of-the-art approaches on producing node vectors for various learning\ntasks of both homogeneous and heterogeneous graphs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:35:03 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gui", "Shupeng", ""], ["Zhang", "Xiangliang", ""], ["Zhong", "Pan", ""], ["Qiu", "Shuang", ""], ["Wu", "Mingrui", ""], ["Ye", "Jieping", ""], ["Wang", "Zhengdao", ""], ["Liu", "Ji", ""]]}, {"id": "1909.12912", "submitter": "Andre Pacheco", "authors": "Andre G. C. Pacheco and Renato A. Krohling", "title": "The impact of patient clinical information on automated skin cancer\n  detection", "comments": null, "journal-ref": null, "doi": "10.1016/j.compbiomed.2019.103545", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer is one of the most common types of cancer around the world. For\nthis reason, over the past years, different approaches have been proposed to\nassist detect it. Nonetheless, most of them are based only on dermoscopy images\nand do not take into account the patient clinical information. In this work,\nfirst, we present a new dataset that contains clinical images, acquired from\nsmartphones, and patient clinical information of the skin lesions. Next, we\nintroduce a straightforward approach to combine the clinical data and the\nimages using different well-known deep learning models. These models are\napplied to the presented dataset using only the images and combining them with\nthe patient clinical information. We present a comprehensive study to show the\nimpact of the clinical data on the final predictions. The results obtained by\ncombining both sets of information show a general improvement of around 7% in\nthe balanced accuracy for all models. In addition, the statistical test\nindicates significant differences between the models with and without\nconsidering both data. The improvement achieved shows the potential of using\npatient clinical information in skin cancer detection and indicates that this\npiece of information is important to leverage skin cancer detection systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:27:12 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Pacheco", "Andre G. C.", ""], ["Krohling", "Renato A.", ""]]}, {"id": "1909.12937", "submitter": "Manel Mart\\'inez-Ram\\'on", "authors": "Meenu Ajith and Manel Mart\\'inez-Ram\\'on", "title": "Unsupervised Segmentation of Fire and Smoke from Infra-Red Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a vision-based fire and smoke segmentation system which\nuse spatial, temporal and motion information to extract the desired regions\nfrom the video frames. The fusion of information is done using multiple\nfeatures such as optical flow, divergence and intensity values. These features\nextracted from the images are used to segment the pixels into different classes\nin an unsupervised way. A comparative analysis is done by using multiple\nclustering algorithms for segmentation. Here the Markov Random Field performs\nmore accurately than other segmentation algorithms since it characterizes the\nspatial interactions of pixels using a finite number of parameters. It builds a\nprobabilistic image model that selects the most likely labeling using the\nmaximum a posteriori (MAP) estimation. This unsupervised approach is tested on\nvarious images and achieves a frame-wise fire detection rate of 95.39%. Hence\nthis method can be used for early detection of fire in real-time and it can be\nincorporated into an indoor or outdoor surveillance system.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:19:17 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Ajith", "Meenu", ""], ["Mart\u00ednez-Ram\u00f3n", "Manel", ""]]}, {"id": "1909.12943", "submitter": "Mesay Samuel", "authors": "Mesay Samuel Gondere, Lars Schmidt-Thieme, Abiot Sinamo Boltena, Hadi\n  Samer Jomaa", "title": "Handwritten Amharic Character Recognition Using a Convolutional Neural\n  Network", "comments": "ECDA2019 Conference Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amharic is the official language of the Federal Democratic Republic of\nEthiopia. There are lots of historic Amharic and Ethiopic handwritten documents\naddressing various relevant issues including governance, science, religious,\nsocial rules, cultures and art works which are very reach indigenous knowledge.\nThe Amharic language has its own alphabet derived from Ge'ez which is currently\nthe liturgical language in Ethiopia. Handwritten character recognition for non\nLatin scripts like Amharic is not addressed especially using the advantages of\nthe state of the art techniques. This research work designs for the first time\na model for Amharic handwritten character recognition using a convolutional\nneural network. The dataset was organized from collected sample handwritten\ndocuments and data augmentation was applied for machine learning. The model was\nfurther enhanced using multi-task learning from the relationships of the\ncharacters. Promising results are observed from the later model which can\nfurther be applied to word prediction.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 21:12:22 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gondere", "Mesay Samuel", ""], ["Schmidt-Thieme", "Lars", ""], ["Boltena", "Abiot Sinamo", ""], ["Jomaa", "Hadi Samer", ""]]}, {"id": "1909.12949", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker and Khaled Salah", "title": "AppsPred: Predicting Context-Aware Smartphone Apps using Random Forest\n  Learning", "comments": "28 pages", "journal-ref": "Journal: Internet of Things (IoT): Engineering Cyber-Physical\n  Human Systems, Elsevier, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the popularity of context-awareness in the Internet of Things (IoT)\nand the recent advanced features in the most popular IoT device, i.e.,\nsmartphone, modeling and predicting personalized usage behavior based on\nrelevant contexts can be highly useful in assisting them to carry out daily\nroutines and activities. Usage patterns of different categories smartphone apps\nsuch as social networking, communication, entertainment, or daily life services\nrelated apps usually vary greatly between individuals. People use these apps\ndifferently in different contexts, such as temporal context, spatial context,\nindividual mood and preference, work status, Internet connectivity like Wifi?\nstatus, or device related status like phone profile, battery level etc. Thus,\nwe consider individuals' apps usage as a multi-class context-aware problem for\npersonalized modeling and prediction. Random Forest learning is one of the most\npopular machine learning techniques to build a multi-class prediction model.\nTherefore, in this paper, we present an effective context-aware smartphone apps\nprediction model, and name it \"AppsPred\" using random forest machine learning\ntechnique that takes into account optimal number of trees based on such\nmulti-dimensional contexts to build the resultant forest. The effectiveness of\nthis model is examined by conducting experiments on smartphone apps usage\ndatasets collected from individual users. The experimental results show that\nour AppsPred significantly outperforms other popular machine learning\nclassification approaches like ZeroR, Naive Bayes, Decision Tree, Support\nVector Machines, Logistic Regression while predicting smartphone apps in\nvarious context-aware test cases.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:43:37 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Salah", "Khaled", ""]]}, {"id": "1909.12950", "submitter": "Rico Jonschkowski", "authors": "Rico Jonschkowski and Austin Stone", "title": "Towards Object Detection from Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel approach to weakly supervised object detection. Instead of\nannotated images, our method only requires two short videos to learn to detect\na new object: 1) a video of a moving object and 2) one or more \"negative\"\nvideos of the scene without the object. The key idea of our algorithm is to\ntrain the object detector to produce physically plausible object motion when\napplied to the first video and to not detect anything in the second video. With\nthis approach, our method learns to locate objects without any object location\nannotations. Once the model is trained, it performs object detection on single\nimages. We evaluate our method in three robotics settings that afford learning\nobjects from motion: observing moving objects, watching demonstrations of\nobject manipulation, and physically interacting with objects (see a video\nsummary at https://youtu.be/BH0Hv3zZG_4).\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:00:14 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Jonschkowski", "Rico", ""], ["Stone", "Austin", ""]]}, {"id": "1909.12969", "submitter": "Matthew Olson", "authors": "Matthew L. Olson, Lawrence Neal, Fuxin Li, Weng-Keen Wong", "title": "Counterfactual States for Atari Agents via Generative Deep Learning", "comments": "IJCAI XAI Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep reinforcement learning agents have produced impressive results\nin many domains, their decision making is difficult to explain to humans. To\naddress this problem, past work has mainly focused on explaining why an action\nwas chosen in a given state. A different type of explanation that is useful is\na counterfactual, which deals with \"what if?\" scenarios. In this work, we\nintroduce the concept of a counterfactual state to help humans gain a better\nunderstanding of what would need to change (minimally) in an Atari game image\nfor the agent to choose a different action. We introduce a novel method to\ncreate counterfactual states from a generative deep learning architecture. In\naddition, we evaluate the effectiveness of counterfactual states on human\nparticipants who are not machine learning experts. Our user study results\nsuggest that our generated counterfactual states are useful in helping\nnon-expert participants gain a better understanding of an agent's decision\nmaking process.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 21:55:01 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Olson", "Matthew L.", ""], ["Neal", "Lawrence", ""], ["Li", "Fuxin", ""], ["Wong", "Weng-Keen", ""]]}, {"id": "1909.12982", "submitter": "Congzheng Song", "authors": "Congzheng Song, Reza Shokri", "title": "Robust Membership Encoding: Inference Attacks and Copyright Protection\n  for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning as a service (MLaaS), and algorithm marketplaces are on a\nrise. Data holders can easily train complex models on their data using third\nparty provided learning codes. Training accurate ML models requires massive\nlabeled data and advanced learning algorithms. The resulting models are\nconsidered as intellectual property of the model owners and their copyright\nshould be protected. Also, MLaaS needs to be trusted not to embed secret\ninformation about the training data into the model, such that it could be later\nretrieved when the model is deployed.\n  In this paper, we present \\emph{membership encoding} for training deep neural\nnetworks and encoding the membership information, i.e. whether a data point is\nused for training, for a subset of training data. Membership encoding has\nseveral applications in different scenarios, including robust watermarking for\nmodel copyright protection, and also the risk analysis of stealthy data\nembedding privacy attacks. Our encoding algorithm can determine the membership\nof significantly redacted data points, and is also robust to model compression\nand fine-tuning. It also enables encoding a significant fraction of the\ntraining set, with negligible drop in the model's prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 23:17:13 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 01:28:12 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Song", "Congzheng", ""], ["Shokri", "Reza", ""]]}, {"id": "1909.13003", "submitter": "Yunbo Wang", "authors": "Yunbo Wang, Bo Liu, Jiajun Wu, Yuke Zhu, Simon S. Du, Li Fei-Fei,\n  Joshua B. Tenenbaum", "title": "DualSMC: Tunneling Differentiable Filtering and Planning under\n  Continuous POMDPs", "comments": "IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major difficulty of solving continuous POMDPs is to infer the multi-modal\ndistribution of the unobserved true states and to make the planning algorithm\ndependent on the perceived uncertainty. We cast POMDP filtering and planning\nproblems as two closely related Sequential Monte Carlo (SMC) processes, one\nover the real states and the other over the future optimal trajectories, and\ncombine the merits of these two parts in a new model named the DualSMC network.\nIn particular, we first introduce an adversarial particle filter that leverages\nthe adversarial relationship between its internal components. Based on the\nfiltering results, we then propose a planning algorithm that extends the\nprevious SMC planning approach [Piche et al., 2018] to continuous POMDPs with\nan uncertainty-dependent policy. Crucially, not only can DualSMC handle complex\nobservations such as image input but also it remains highly interpretable. It\nis shown to be effective in three continuous POMDP domains: the floor\npositioning domain, the 3D light-dark navigation domain, and a modified Reacher\ndomain.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 01:52:27 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 07:35:53 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 04:23:39 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 06:27:36 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Wang", "Yunbo", ""], ["Liu", "Bo", ""], ["Wu", "Jiajun", ""], ["Zhu", "Yuke", ""], ["Du", "Simon S.", ""], ["Fei-Fei", "Li", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1909.13004", "submitter": "Tianyi Luo", "authors": "Tianyi Luo and Yang Liu", "title": "Machine Truth Serum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wisdom of the crowd revealed a striking fact that the majority answer from a\ncrowd is often more accurate than any individual expert. We observed the same\nstory in machine learning--ensemble methods leverage this idea to combine\nmultiple learning algorithms to obtain better classification performance. Among\nmany popular examples is the celebrated Random Forest, which applies the\nmajority voting rule in aggregating different decision trees to make the final\nprediction. Nonetheless, these aggregation rules would fail when the majority\nis more likely to be wrong. In this paper, we extend the idea proposed in\nBayesian Truth Serum that \"a surprisingly more popular answer is more likely\nthe true answer\" to classification problems. The challenge for us is to define\nor detect when an answer should be considered as being \"surprising\". We present\ntwo machine learning aided methods which aim to reveal the truth when it is\nminority instead of majority who has the true answer. Our experiments over\nreal-world datasets show that better classification performance can be obtained\ncompared to always trusting the majority voting. Our proposed methods also\noutperform popular ensemble algorithms. Our approach can be generically applied\nas a subroutine in ensemble methods to replace majority voting rule.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 01:59:14 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Luo", "Tianyi", ""], ["Liu", "Yang", ""]]}, {"id": "1909.13014", "submitter": "Amirhossein Reisizadeh", "authors": "Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie,\n  Ramtin Pedarsani", "title": "FedPAQ: A Communication-Efficient Federated Learning Method with\n  Periodic Averaging and Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed framework according to which a model is\ntrained over a set of devices, while keeping data localized. This framework\nfaces several systems-oriented challenges which include (i) communication\nbottleneck since a large number of devices upload their local updates to a\nparameter server, and (ii) scalability as the federated network consists of\nmillions of devices. Due to these systems challenges as well as issues related\nto statistical heterogeneity of data and privacy concerns, designing a provably\nefficient federated learning method is of significant importance yet it remains\nchallenging. In this paper, we present FedPAQ, a communication-efficient\nFederated Learning method with Periodic Averaging and Quantization. FedPAQ\nrelies on three key features: (1) periodic averaging where models are updated\nlocally at devices and only periodically averaged at the server; (2) partial\ndevice participation where only a fraction of devices participate in each round\nof the training; and (3) quantized message-passing where the edge nodes\nquantize their updates before uploading to the parameter server. These features\naddress the communications and scalability challenges in federated learning. We\nalso show that FedPAQ achieves near-optimal theoretical guarantees for strongly\nconvex and non-convex loss functions and empirically demonstrate the\ncommunication-computation tradeoff provided by our method.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 03:10:53 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 02:38:39 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 21:37:38 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 19:09:29 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Reisizadeh", "Amirhossein", ""], ["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Jadbabaie", "Ali", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1909.13017", "submitter": "Kabir Olorede Opeyemi", "authors": "Kabir Opeyemi Olorede and Waheed Babatunde Yahya", "title": "A New Covariance Estimator for Sufficient Dimension Reduction in\n  High-Dimensional and Undersized Sample Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "JCGS-19-251", "categories": "stat.ME cs.CC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of standard sufficient dimension reduction methods for\nreducing the dimension space of predictors without losing regression\ninformation requires inverting the covariance matrix of the predictors. This\nhas posed a number of challenges especially when analyzing high-dimensional\ndata sets in which the number of predictors $\\mathit{p}$ is much larger than\nnumber of samples $n,~(n\\ll p)$. A new covariance estimator, called the\n\\textit{Maximum Entropy Covariance} (MEC) that addresses loss of covariance\ninformation when similar covariance matrices are linearly combined using\n\\textit{Maximum Entropy} (ME) principle is proposed in this work. By\nbenefitting naturally from slicing or discretizing range of the response\nvariable, y into \\textit{H} non-overlapping categories, $\\mathit{h_{1},\\ldots\n,h_{H}}$, MEC first combines covariance matrices arising from samples in each y\nslice $\\mathit{h\\in H}$ and then select the one that maximizes entropy under\nthe principle of maximum uncertainty. The MEC estimator is then formed from\nconvex mixture of such entropy-maximizing sample covariance $S_{\\mbox{mec}}$\nestimate and pooled sample covariance $\\mathbf{S}_{\\mathit{p}}$ estimate across\nthe $\\mathit{H}$ slices without requiring time-consuming covariance\noptimization procedures. MEC deals directly with singularity and instability of\nsample group covariance estimate in both regression and classification\nproblems. The efficiency of the MEC estimator is studied with the existing\nsufficient dimension reduction methods such as \\textit{Sliced Inverse\nRegression} (SIR) and \\textit{Sliced Average Variance Estimator} (SAVE) as\ndemonstrated on both classification and regression problems using real life\nLeukemia cancer data and customers' electricity load profiles from smart meter\ndata sets respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 03:34:42 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Olorede", "Kabir Opeyemi", ""], ["Yahya", "Waheed Babatunde", ""]]}, {"id": "1909.13021", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki, Carl Allen, Rik Sarkar", "title": "Multi-scale Attributed Node Embedding", "comments": "Published in the Journal of Complex Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present network embedding algorithms that capture information about a node\nfrom the local distribution over node attributes around it, as observed over\nrandom walks following an approach similar to Skip-gram. Observations from\nneighborhoods of different sizes are either pooled (AE) or encoded distinctly\nin a multi-scale approach (MUSAE). Capturing attribute-neighborhood\nrelationships over multiple scales is useful for a diverse range of\napplications, including latent feature identification across disconnected\nnetworks with similar attributes. We prove theoretically that matrices of\nnode-feature pointwise mutual information are implicitly factorized by the\nembeddings. Experiments show that our algorithms are robust, computationally\nefficient and outperform comparable models on social networks and web graphs.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 04:13:33 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:57:34 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 22:05:08 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Allen", "Carl", ""], ["Sarkar", "Rik", ""]]}, {"id": "1909.13031", "submitter": "Sarath Yasodharan", "authors": "Sarath Yasodharan, Patrick Loiseau", "title": "Nonzero-sum Adversarial Hypothesis Testing Games", "comments": "23 pages, 14 figures. Accepted for publication in the 33rd Conference\n  on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonzero-sum hypothesis testing games that arise in the context of\nadversarial classification, in both the Bayesian as well as the Neyman-Pearson\nframeworks. We first show that these games admit mixed strategy Nash\nequilibria, and then we examine some interesting concentration phenomena of\nthese equilibria. Our main results are on the exponential rates of convergence\nof classification errors at equilibrium, which are analogous to the well-known\nChernoff-Stein lemma and Chernoff information that describe the error exponents\nin the classical binary hypothesis testing problem, but with parameters derived\nfrom the adversarial model. The results are validated through numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 05:46:48 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Yasodharan", "Sarath", ""], ["Loiseau", "Patrick", ""]]}, {"id": "1909.13035", "submitter": "Qitian Wu", "authors": "Qitian Wu, Rui Gao, Hongyuan Zha", "title": "Stein Bridging: Enabling Mutual Reinforcement between Explicit and\n  Implicit Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are generally categorized into explicit models and\nimplicit models. The former defines an explicit density form, whose normalizing\nconstant is often unknown; while the latter, including generative adversarial\nnetworks (GANs), generates samples without explicitly defining a density\nfunction. In spite of substantial recent advances demonstrating the power of\nthe two classes of generative models in many applications, both of them, when\nused alone, suffer from respective limitations and drawbacks. To mitigate these\nissues, we propose Stein Bridging, a novel joint training framework that\nconnects an explicit density estimator and an implicit sample generator with\nStein discrepancy. We show that the Stein Bridge induces new regularization\nschemes for both explicit and implicit models. Convergence analysis and\nextensive experiments demonstrate that the Stein Bridging i) improves the\nstability and sample quality of the GAN training, and ii) facilitates the\ndensity estimator to seek more modes in data and alleviate the mode-collapse\nissue. Additionally, we discuss several applications of Stein Bridging and\nuseful tricks in practical implementation used in our experiments.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 06:39:33 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 10:33:42 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wu", "Qitian", ""], ["Gao", "Rui", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1909.13049", "submitter": "Alberto Bemporad Prof.", "authors": "Alberto Bemporad and Dario Piga", "title": "Active preference learning based on radial basis functions", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for solving optimization problems in which the\ndecision-maker cannot evaluate the objective function, but rather can only\nexpress a preference such as \"this is better than that\" between two candidate\ndecision vectors. The algorithm described in this paper aims at reaching the\nglobal optimizer by iteratively proposing the decision maker a new comparison\nto make, based on actively learning a surrogate of the latent (unknown and\nperhaps unquantifiable) objective function from past sampled decision vectors\nand pairwise preferences. The surrogate is fit by means of radial basis\nfunctions, under the constraint of satisfying, if possible, the preferences\nexpressed by the decision maker on existing samples. The surrogate is used to\npropose a new sample of the decision vector for comparison with the current\nbest candidate based on two possible criteria: minimize a combination of the\nsurrogate and an inverse weighting distance function to balance between\nexploitation of the surrogate and exploration of the decision space, or\nmaximize a function related to the probability that the new candidate will be\npreferred. Compared to active preference learning based on Bayesian\noptimization, we show that our approach is superior in that, within the same\nnumber of comparisons, it approaches the global optimum more closely and is\ncomputationally lighter. MATLAB and a Python implementations of the algorithms\ndescribed in the paper are available at\nhttp://cse.lab.imtlucca.it/~bemporad/idwgopt.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 08:37:51 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Bemporad", "Alberto", ""], ["Piga", "Dario", ""]]}, {"id": "1909.13062", "submitter": "Prateek Munjal", "authors": "Prateek Munjal, Akanksha Paul, Narayanan C. Krishnan", "title": "Implicit Discriminator in Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently generative models have focused on combining the advantages of\nvariational autoencoders (VAE) and generative adversarial networks (GAN) for\ngood reconstruction and generative abilities. In this work we introduce a novel\nhybrid architecture, Implicit Discriminator in Variational Autoencoder (IDVAE),\nthat combines a VAE and a GAN, which does not need an explicit discriminator\nnetwork. The fundamental premise of the IDVAE architecture is that the encoder\nof a VAE and the discriminator of a GAN utilize common features and therefore\ncan be trained as a shared network, while the decoder of the VAE and the\ngenerator of the GAN can be combined to learn a single network. This results in\na simple two-tier architecture that has the properties of both a VAE and a GAN.\nThe qualitative and quantitative experiments on real-world benchmark datasets\ndemonstrates that IDVAE perform better than the state of the art hybrid\napproaches. We experimentally validate that IDVAE can be easily extended to\nwork in a conditional setting and demonstrate its performance on complex\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 10:12:28 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Munjal", "Prateek", ""], ["Paul", "Akanksha", ""], ["Krishnan", "Narayanan C.", ""]]}, {"id": "1909.13077", "submitter": "Dan Wang", "authors": "Dan Wang and Jibing Gong and Yaxi Song", "title": "W-RNN: News text classification based on a Weighted RNN", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the information is stored as text, so text mining is regarded as\nhaving high commercial potential. Aiming at the semantic constraint problem of\nclassification methods based on sparse representation, we propose a weighted\nrecurrent neural network (W-RNN), which can fully extract text serialization\nsemantic information. For the problem that the feature high dimensionality and\nunclear semantic relationship in text data representation, we first utilize the\nword vector to represent the vocabulary in the text and use Recurrent Neural\nNetwork (RNN) to extract features of the serialized text data. The word vector\nis then automatically weighted and summed using the intermediate output of the\nword vector to form the text representation vector. Finally, the neural network\nis used for classification. W-RNN is verified on the news dataset and proves\nthat W-RNN is superior to other four baseline methods in Precision, Recall, F1\nand loss values, which is suitable for text classification.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 11:54:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Dan", ""], ["Gong", "Jibing", ""], ["Song", "Yaxi", ""]]}, {"id": "1909.13079", "submitter": "Alexandre Proutiere", "authors": "Alexandre Proutiere and Po-An Wang", "title": "An Optimal Algorithm for Multiplayer Multi-Armed Bandits", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses the Multiplayer Multi-Armed Bandit (MMAB) problem, where\n$M$ decision makers or players collaborate to maximize their cumulative reward.\nWhen several players select the same arm, a collision occurs and no reward is\ncollected on this arm. Players involved in a collision are informed about this\ncollision. We present DPE (Decentralized Parsimonious Exploration), a\ndecentralized algorithm that achieves the same regret as that obtained by an\noptimal centralized algorithm. Our algorithm has better regret guarantees than\nthe state-of-the-art algorithm SIC-MMAB \\cite{boursier2019}. As in SIC-MMAB,\nplayers communicate through collisions only. An additional important advantage\nof DPE is that it requires very little communication. Specifically, the\nexpected number of rounds where players use collisions to communicate is\nfinite.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 12:35:12 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 07:57:57 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Proutiere", "Alexandre", ""], ["Wang", "Po-An", ""]]}, {"id": "1909.13082", "submitter": "Alexander Korotin", "authors": "Alexander Korotin and Vage Egiazarian and Arip Asadulaev and Alexander\n  Safin and Evgeny Burnaev", "title": "Wasserstein-2 Generative Networks", "comments": "30 pages, 21 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel end-to-end non-minimax algorithm for training optimal\ntransport mappings for the quadratic cost (Wasserstein-2 distance). The\nalgorithm uses input convex neural networks and a cycle-consistency\nregularization to approximate Wasserstein-2 distance. In contrast to popular\nentropic and quadratic regularizers, cycle-consistency does not introduce bias\nand scales well to high dimensions. From the theoretical side, we estimate the\nproperties of the generative mapping fitted by our algorithm. From the\npractical side, we evaluate our algorithm on a wide range of tasks:\nimage-to-image color transfer, latent space optimal transport, image-to-image\nstyle transfer, and domain adaptation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 12:42:12 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 09:42:03 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 18:04:14 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 10:53:46 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Korotin", "Alexander", ""], ["Egiazarian", "Vage", ""], ["Asadulaev", "Arip", ""], ["Safin", "Alexander", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1909.13104", "submitter": "Christos Karatsalos", "authors": "Christos Karatsalos, Yannis Panagiotakis", "title": "Attention-based method for categorizing different types of online\n  harassment language", "comments": "Accepted in \"SIMAH (SocIaL Media And Harassment): First workshop on\n  categorizing different types of online harassment languages in social media\"\n  @ ECML-PKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-43887-6_26", "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of social media and networking platforms, Twitter has been doomed\nfor abuse and harassment toward users specifically women. Monitoring the\ncontents including sexism and sexual harassment in traditional media is easier\nthan monitoring on the online social media platforms like Twitter, because of\nthe large amount of user generated content in these media. So, the research\nabout the automated detection of content containing sexual or racist harassment\nis an important issue and could be the basis for removing that content or\nflagging it for human evaluation. Previous studies have been focused on\ncollecting data about sexism and racism in very broad terms. However, there is\nno much study focusing on different types of online harassment attracting\nnatural language processing techniques. In this work, we present an\nmulti-attention based approach for the detection of different types of\nharassment in tweets. Our approach is based on the Recurrent Neural Networks\nand particularly we are using a deep, classification specific multi-attention\nmechanism. Moreover, we tackle the problem of imbalanced data, using a\nback-translation method. Finally, we present a comparison between different\napproaches based on the Recurrent Neural Networks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 14:32:46 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 00:36:10 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Karatsalos", "Christos", ""], ["Panagiotakis", "Yannis", ""]]}, {"id": "1909.13111", "submitter": "Ryo Yonetani", "authors": "Mohammadamin Barekatain, Ryo Yonetani, Masashi Hamaya", "title": "MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement\n  Learning between Diverse Environmental Dynamics", "comments": "This work was presented at IJCAI 2020. Copyright (c) 2020\n  International Joint Conferences on Artificial Intelligence, All rights\n  reserved", "journal-ref": "Proceedings of the Twenty-Ninth International Joint Conference on\n  Artificial Intelligence 2020. Pages 3108-3116", "doi": "10.24963/ijcai.2020/430", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer reinforcement learning (RL) aims at improving the learning\nefficiency of an agent by exploiting knowledge from other source agents trained\non relevant tasks. However, it remains challenging to transfer knowledge\nbetween different environmental dynamics without having access to the source\nenvironments. In this work, we explore a new challenge in transfer RL, where\nonly a set of source policies collected under diverse unknown dynamics is\navailable for learning a target task efficiently. To address this problem, the\nproposed approach, MULTI-source POLicy AggRegation (MULTIPOLAR), comprises two\nkey techniques. We learn to aggregate the actions provided by the source\npolicies adaptively to maximize the target task performance. Meanwhile, we\nlearn an auxiliary network that predicts residuals around the aggregated\nactions, which ensures the target policy's expressiveness even when some of the\nsource policies perform poorly. We demonstrated the effectiveness of MULTIPOLAR\nthrough an extensive experimental evaluation across six simulated environments\nranging from classic control problems to challenging robotics simulations,\nunder both continuous and discrete action spaces. The demo videos and code are\navailable on the project webpage: https://omron-sinicx.github.io/multipolar/.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 15:13:46 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 00:21:32 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Barekatain", "Mohammadamin", ""], ["Yonetani", "Ryo", ""], ["Hamaya", "Masashi", ""]]}, {"id": "1909.13123", "submitter": "Zhengming Ding", "authors": "Zhengming Ding and Ming Shao and Handong Zhao and Sheng Li", "title": "Learning Robust Data Representation: A Knowledge Flow Perspective", "comments": "7 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  It is always demanding to learn robust visual representation for various\nlearning problems; however, this learning and maintenance process usually\nsuffers from noise, incompleteness or knowledge domain mismatch. Thus, robust\nrepresentation learning by removing noisy features or samples, complementing\nincomplete data, and mitigating the distribution difference becomes the key.\nAlong this line of research, low-rank modeling has been widely-applied to\nsolving representation learning challenges. This survey covers the topic from a\nknowledge flow perspective in terms of: (1) robust knowledge recovery, (2)\nrobust knowledge transfer, and (3) robust knowledge fusion, centered around\nseveral major applications. First of all, we deliver a unified formulation for\nrobust knowledge discovery given single dataset. Second, we discuss robust\nknowledge transfer and fusion given multiple datasets with different knowledge\nflows, followed by practical challenges, model variations, and remarks.\nFinally, we highlight future research of robust knowledge discovery for\nincomplete, unbalance, large-scale data analysis. This would benefit AI\ncommunity from literature review to future direction.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 17:15:38 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 18:35:43 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Ding", "Zhengming", ""], ["Shao", "Ming", ""], ["Zhao", "Handong", ""], ["Li", "Sheng", ""]]}, {"id": "1909.13144", "submitter": "Xin Dong", "authors": "Yuhang Li, Xin Dong, Wei Wang", "title": "Additive Powers-of-Two Quantization: An Efficient Non-uniform\n  Discretization for Neural Networks", "comments": "quantization, efficient neural network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Additive Powers-of-Two~(APoT) quantization, an efficient\nnon-uniform quantization scheme for the bell-shaped and long-tailed\ndistribution of weights and activations in neural networks. By constraining all\nquantization levels as the sum of Powers-of-Two terms, APoT quantization enjoys\nhigh computational efficiency and a good match with the distribution of\nweights. A simple reparameterization of the clipping function is applied to\ngenerate a better-defined gradient for learning the clipping threshold.\nMoreover, weight normalization is presented to refine the distribution of\nweights to make the training more stable and consistent. Experimental results\nshow that our proposed method outperforms state-of-the-art methods, and is even\ncompetitive with the full-precision models, demonstrating the effectiveness of\nour proposed APoT quantization. For example, our 4-bit quantized ResNet-50 on\nImageNet achieves 76.6% top-1 accuracy without bells and whistles; meanwhile,\nour model reduces 22% computational cost compared with the uniformly quantized\ncounterpart. The code is available at\nhttps://github.com/yhhhli/APoT_Quantization.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 20:14:11 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 14:15:07 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Yuhang", ""], ["Dong", "Xin", ""], ["Wang", "Wei", ""]]}, {"id": "1909.13146", "submitter": "Andreas Georgiou", "authors": "Andreas Georgiou, Vincent Fortuin, Harun Mustafa, Gunnar R\\\"atsch", "title": "META$^\\mathbf{2}$: Memory-efficient taxonomic classification and\n  abundance estimation for metagenomics with deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metagenomic studies have increasingly utilized sequencing technologies in\norder to analyze DNA fragments found in environmental samples.One important\nstep in this analysis is the taxonomic classification of the DNA fragments.\nConventional read classification methods require large databases and vast\namounts of memory to run, with recent deep learning methods suffering from very\nlarge model sizes. We therefore aim to develop a more memory-efficient\ntechnique for taxonomic classification. A task of particular interest is\nabundance estimation in metagenomic samples. Current attempts rely on\nclassifying single DNA reads independently from each other and are therefore\nagnostic to co-occurence patterns between taxa. In this work, we also attempt\nto take these patterns into account. We develop a novel memory-efficient read\nclassification technique, combining deep learning and locality-sensitive\nhashing. We show that this approach outperforms conventional mapping-based and\nother deep learning methods for single-read taxonomic classification when\nrestricting all methods to a fixed memory footprint. Moreover, we formulate the\ntask of abundance estimation as a Multiple Instance Learning (MIL) problem and\nwe extend current deep learning architectures with two different types of\npermutation-invariant MIL pooling layers: a) deepsets and b) attention-based\npooling. We illustrate that our architectures can exploit the co-occurrence of\nspecies in metagenomic read sets and outperform the single-read architectures\nin predicting the distribution over taxa at higher taxonomic ranks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 20:30:40 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:05:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Georgiou", "Andreas", ""], ["Fortuin", "Vincent", ""], ["Mustafa", "Harun", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1909.13158", "submitter": "Daniel Pirutinsky", "authors": "Wesley Cowan, Michael N. Katehakis, and Daniel Pirutinsky", "title": "Accelerating the Computation of UCB and Related Indices for\n  Reinforcement Learning", "comments": "A version of some of the algorithms and comparisons has appeared in a\n  previous technical note by Cowan, Katehakis, and Pirutinsky (2019)\n  arXiv:1909.06019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we derive an efficient method for computing the indices\nassociated with an asymptotically optimal upper confidence bound algorithm\n(MDP-UCB) of Burnetas and Katehakis (1997) that only requires solving a system\nof two non-linear equations with two unknowns, irrespective of the cardinality\nof the state space of the Markovian decision process (MDP). In addition, we\ndevelop a similar acceleration for computing the indices for the\nMDP-Deterministic Minimum Empirical Divergence (MDP-DMED) algorithm developed\nin Cowan et al. (2019), based on ideas from Honda and Takemura (2011), that\ninvolves solving a single equation of one variable. We provide experimental\nresults demonstrating the computational time savings and regret performance of\nthese algorithms. In these comparison we also consider the Optimistic Linear\nProgramming (OLP) algorithm (Tewari and Bartlett, 2008) and a method based on\nPosterior sampling (MDP-PS).\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 21:56:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Cowan", "Wesley", ""], ["Katehakis", "Michael N.", ""], ["Pirutinsky", "Daniel", ""]]}, {"id": "1909.13164", "submitter": "Meyer Scetbon", "authors": "Meyer Scetbon, Michael Elad, Peyman Milanfar", "title": "Deep K-SVD Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers noise removal from images, focusing on the well known\nK-SVD denoising algorithm. This sparsity-based method was proposed in 2006, and\nfor a short while it was considered as state-of-the-art. However, over the\nyears it has been surpassed by other methods, including the recent\ndeep-learning-based newcomers. The question we address in this paper is whether\nK-SVD was brought to its peak in its original conception, or whether it can be\nmade competitive again. The approach we take in answering this question is to\nredesign the algorithm to operate in a supervised manner. More specifically, we\npropose an end-to-end deep architecture with the exact K-SVD computational\npath, and train it for optimized denoising. Our work shows how to overcome\ndifficulties arising in turning the K-SVD scheme into a differentiable, and\nthus learnable, machine. With a small number of parameters to learn and while\npreserving the original K-SVD essence, the proposed architecture is shown to\noutperform the classical K-SVD algorithm substantially, and getting closer to\nrecent state-of-the-art learning-based denoising methods. Adopting a broader\ncontext, this work touches on themes around the design of deep-learning\nsolutions for image processing tasks, while paving a bridge between classic\nmethods and novel deep-learning-based ones.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 22:30:21 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 17:54:48 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Scetbon", "Meyer", ""], ["Elad", "Michael", ""], ["Milanfar", "Peyman", ""]]}, {"id": "1909.13168", "submitter": "Sandeep Srinivasan", "authors": "William Hughes, Sandeep Srinivasan, Rohit Suvarna, Maithilee Kulkarni", "title": "Optimizing Design Verification using Machine Learning: Doing better than\n  Random", "comments": "9 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As integrated circuits have become progressively more complex, constrained\nrandom stimulus has become ubiquitous as a means of stimulating a designs\nfunctionality and ensuring it fully meets expectations. In theory, random\nstimulus allows all possible combinations to be exercised given enough time,\nbut in practice with highly complex designs a purely random approach will have\ndifficulty in exercising all possible combinations in a timely fashion. As a\nresult it is often necessary to steer the Design Verification (DV) environment\nto generate hard to hit combinations. The resulting constrained-random approach\nis powerful but often relies on extensive human expertise to guide the DV\nenvironment in order to fully exercise the design. As designs become more\ncomplex, the guidance aspect becomes progressively more challenging and time\nconsuming often resulting in design schedules in which the verification time to\nhit all possible design coverage points is the dominant schedule limitation.\nThis paper describes an approach which leverages existing constrained-random DV\nenvironment tools but which further enhances them using supervised learning and\nreinforcement learning techniques. This approach provides better than random\nresults in a highly automated fashion thereby ensuring DV objectives of full\ndesign coverage can be achieved on an accelerated timescale and with fewer\nresources.\n  Two hardware verification examples are presented, one of a Cache Controller\ndesign and one using the open-source RISCV-Ariane design and Google's RISCV\nRandom Instruction Generator. We demonstrate that a machine-learning based\napproach can perform significantly better on functional coverage and reaching\ncomplex hard-to-hit states than a random or constrained-random approach.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 23:23:57 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Hughes", "William", ""], ["Srinivasan", "Sandeep", ""], ["Suvarna", "Rohit", ""], ["Kulkarni", "Maithilee", ""]]}, {"id": "1909.13188", "submitter": "Kun Xu", "authors": "Kun Xu, Chongxuan Li, Jun Zhu, Bo Zhang", "title": "Understanding and Stabilizing GANs' Training Dynamics with Control\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are effective in generating realistic\nimages but the training is often unstable. There are existing efforts that\nmodel the training dynamics of GANs in the parameter space but the analysis\ncannot directly motivate practically effective stabilizing methods. To this\nend, we present a conceptually novel perspective from control theory to\ndirectly model the dynamics of GANs in the function space and provide simple\nyet effective methods to stabilize GANs' training. We first analyze the\ntraining dynamic of a prototypical Dirac GAN and adopt the widely-used\nclosed-loop control (CLC) to improve its stability. We then extend CLC to\nstabilize the training dynamic of normal GANs, where CLC is implemented as a\nsquared $L2$ regularizer on the output of the discriminator. Empirical results\nshow that our method can effectively stabilize the training and obtain\nstate-of-the-art performance on data generation tasks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 02:19:40 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 03:42:34 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 08:41:51 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 03:25:00 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Xu", "Kun", ""], ["Li", "Chongxuan", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1909.13189", "submitter": "Bryon Aragam", "authors": "Xun Zheng, Chen Dan, Bryon Aragam, Pradeep Ravikumar, and Eric P. Xing", "title": "Learning Sparse Nonparametric DAGs", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for learning sparse nonparametric directed acyclic\ngraphs (DAGs) from data. Our approach is based on a recent algebraic\ncharacterization of DAGs that led to a fully continuous program for score-based\nlearning of DAG models parametrized by a linear structural equation model\n(SEM). We extend this algebraic characterization to nonparametric SEM by\nleveraging nonparametric sparsity based on partial derivatives, resulting in a\ncontinuous optimization problem that can be applied to a variety of\nnonparametric and semiparametric models including GLMs, additive noise models,\nand index models as special cases. Unlike existing approaches that require\nspecific modeling choices, loss functions, or algorithms, we present a\ncompletely general framework that can be applied to general nonlinear models\n(e.g. without additive noise), general differentiable loss functions, and\ngeneric black-box optimization routines. The code is available at\nhttps://github.com/xunzheng/notears.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 02:20:56 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 23:21:15 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Zheng", "Xun", ""], ["Dan", "Chen", ""], ["Aragam", "Bryon", ""], ["Ravikumar", "Pradeep", ""], ["Xing", "Eric P.", ""]]}, {"id": "1909.13193", "submitter": "Isaac Ampomah", "authors": "Isaac K. E. Ampomah, Sally McClean, Zhiwei Lin and Glenn Hawe", "title": "Gated Task Interaction Framework for Multi-task Sequence Tagging", "comments": "8 pages", "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent studies have shown that neural models can achieve high performance on\nseveral sequence labelling/tagging problems without the explicit use of\nlinguistic features such as part-of-speech (POS) tags. These models are trained\nonly using the character-level and the word embedding vectors as inputs. Others\nhave shown that linguistic features can improve the performance of neural\nmodels on tasks such as chunking and named entity recognition (NER). However,\nthe change in performance depends on the degree of semantic relatedness between\nthe linguistic features and the target task; in some instances, linguistic\nfeatures can have a negative impact on performance. This paper presents an\napproach to jointly learn these linguistic features along with the target\nsequence labelling tasks with a new multi-task learning (MTL) framework called\nGated Tasks Interaction (GTI) network for solving multiple sequence tagging\ntasks. The GTI network exploits the relations between the multiple tasks via\nneural gate modules. These gate modules control the flow of information between\nthe different tasks. Experiments on benchmark datasets for chunking and NER\nshow that our framework outperforms other competitive baselines trained with\nand without external training resources.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 02:56:24 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Ampomah", "Isaac K. E.", ""], ["McClean", "Sally", ""], ["Lin", "Zhiwei", ""], ["Hawe", "Glenn", ""]]}, {"id": "1909.13196", "submitter": "Zhiwei Deng", "authors": "Zhiwei Deng, Greg Mori", "title": "Policy Message Passing: A New Algorithm for Probabilistic Graph\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general graph-structured neural network architecture operates on graphs\nthrough two core components: (1) complex enough message functions; (2) a fixed\ninformation aggregation process. In this paper, we present the Policy Message\nPassing algorithm, which takes a probabilistic perspective and reformulates the\nwhole information aggregation as stochastic sequential processes. The algorithm\nworks on a much larger search space, utilizes reasoning history to perform\ninference, and is robust to noisy edges. We apply our algorithm to multiple\ncomplex graph reasoning and prediction tasks and show that our algorithm\nconsistently outperforms state-of-the-art graph-structured models by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 03:23:17 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Deng", "Zhiwei", ""], ["Mori", "Greg", ""]]}, {"id": "1909.13203", "submitter": "Ruishan Liu", "authors": "Ruishan Liu, Akshay Balsubramani, James Zou", "title": "Learning transport cost from subset correspondence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to align multiple datasets is an important problem with many\napplications, and it is especially useful when we need to integrate multiple\nexperiments or correct for confounding. Optimal transport (OT) is a principled\napproach to align datasets, but a key challenge in applying OT is that we need\nto specify a transport cost function that accurately captures how the two\ndatasets are related. Reliable cost functions are typically not available and\npractitioners often resort to using hand-crafted or Euclidean cost even if it\nmay not be appropriate. In this work, we investigate how to learn the cost\nfunction using a small amount of side information which is often available. The\nside information we consider captures subset correspondence---i.e. certain\nsubsets of points in the two data sets are known to be related. For example, we\nmay have some images labeled as cars in both datasets; or we may have a common\nannotated cell type in single-cell data from two batches. We develop an\nend-to-end optimizer (OT-SI) that differentiates through the Sinkhorn algorithm\nand effectively learns the suitable cost function from side information. On\nsystematic experiments in images, marriage-matching and single-cell RNA-seq,\nour method substantially outperform state-of-the-art benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 05:28:28 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Liu", "Ruishan", ""], ["Balsubramani", "Akshay", ""], ["Zou", "James", ""]]}, {"id": "1909.13221", "submitter": "Chao Wei", "authors": "Chao Wei, Weiru Zhang, Shengjie Sun, Fei Li, Xiaonan Meng, Yi Hu and\n  Hao Wang", "title": "Optimal Delivery with Budget Constraint in E-Commerce Advertising", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online advertising in E-commerce platforms provides sellers an opportunity to\nachieve potential audiences with different target goals. Ad serving systems\n(like display and search advertising systems) that assign ads to pages should\nsatisfy objectives such as plenty of audience for branding advertisers, clicks\nor conversions for performance-based advertisers, at the same time try to\nmaximize overall revenue of the platform. In this paper, we propose an approach\nbased on linear programming subjects to constraints in order to optimize the\nrevenue and improve different performance goals simultaneously. We have\nvalidated our algorithm by implementing an offline simulation system in Alibaba\nE-commerce platform and running the auctions from online requests which takes\nsystem performance, ranking and pricing schemas into account. We have also\ncompared our algorithm with related work, and the results show that our\nalgorithm can effectively improve campaign performance and revenue of the\nplatform.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 07:11:10 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 12:52:24 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Wei", "Chao", ""], ["Zhang", "Weiru", ""], ["Sun", "Shengjie", ""], ["Li", "Fei", ""], ["Meng", "Xiaonan", ""], ["Hu", "Yi", ""], ["Wang", "Hao", ""]]}, {"id": "1909.13231", "submitter": "Yu Sun", "authors": "Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros,\n  Moritz Hardt", "title": "Test-Time Training with Self-Supervision for Generalization under\n  Distribution Shifts", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose Test-Time Training, a general approach for\nimproving the performance of predictive models when training and test data come\nfrom different distributions. We turn a single unlabeled test sample into a\nself-supervised learning problem, on which we update the model parameters\nbefore making a prediction. This also extends naturally to data in an online\nstream. Our simple approach leads to improvements on diverse image\nclassification benchmarks aimed at evaluating robustness to distribution\nshifts.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 08:09:15 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 06:34:47 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 18:09:39 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Sun", "Yu", ""], ["Wang", "Xiaolong", ""], ["Liu", "Zhuang", ""], ["Miller", "John", ""], ["Efros", "Alexei A.", ""], ["Hardt", "Moritz", ""]]}, {"id": "1909.13241", "submitter": "Evangelos Psomakelis Mr", "authors": "Evangelos Psomakelis, Konstantinos Tserpes, Dimitris Zissisc,\n  Dimosthenis Anagnostopoulos and Theodora Varvarigou", "title": "Context agnostic trajectory prediction based on $\\lambda$-architecture", "comments": null, "journal-ref": "Future Generation Computer Systems 2019,ISSN 0167-739X", "doi": "10.1016/j.future.2019.09.046", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the next position of movable objects has been a problem for at\nleast the last three decades, referred to as trajectory prediction. In our\ndays, the vast amounts of data being continuously produced add the big data\ndimension to the trajectory prediction problem, which we are trying to tackle\nby creating a {\\lambda}-Architecture based analytics platform. This platform\nperforms both batch and stream analytics tasks and then combines them to\nperform analytical tasks that cannot be performed by analyzing any of these\nlayers by itself. The biggest benefit of this platform is its context agnostic\ntrait, which allows us to use it for any use case, as long as a time-stamped\ngeolocation stream is provided. The experimental results presented prove that\neach part of the {\\lambda}-Architecture performs well at certain targets,\nmaking a combination of these parts a necessity in order to improve the overall\naccuracy and performance of the platform.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 09:22:21 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Psomakelis", "Evangelos", ""], ["Tserpes", "Konstantinos", ""], ["Zissisc", "Dimitris", ""], ["Anagnostopoulos", "Dimosthenis", ""], ["Varvarigou", "Theodora", ""]]}, {"id": "1909.13260", "submitter": "Emille E. O. Ishida", "authors": "Emille E. O. Ishida, Matwey V. Kornilov, Konstantin L. Malanchev,\n  Maria V. Pruzhinskaya, Alina A. Volnova, Vladimir S. Korolev, Florian Mondon,\n  Sreevarsha Sreejith, Anastasia Malancheva and Shubhomoy Das", "title": "Active Anomaly Detection for time-domain discoveries", "comments": "10 pages, 5 figures, updated to include PLAsTiCC results", "journal-ref": "A&A 650, A195 (2021)", "doi": "10.1051/0004-6361/202037709", "report-no": null, "categories": "astro-ph.IM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first evidence that adaptive learning techniques can boost the\ndiscovery of unusual objects within astronomical light curve data sets. Our\nmethod follows an active learning strategy where the learning algorithm chooses\nobjects which can potentially improve the learner if additional information\nabout them is provided. This new information is subsequently used to update the\nmachine learning model, allowing its accuracy to evolve with each new\ninformation. For the case of anomaly detection, the algorithm aims to maximize\nthe number of scientifically interesting anomalies presented to the expert by\nslightly modifying the weights of a traditional Isolation Forest (IF) at each\niteration. In order to demonstrate the potential of such techniques, we apply\nthe Active Anomaly Discovery (AAD) algorithm to 2 data sets: simulated light\ncurves from the PLAsTiCC challenge and real light curves from the Open\nSupernova Catalog. We compare the AAD results to those of a static IF. For both\nmethods, we performed a detailed analysis for all objects with the ~2% highest\nanomaly scores. We show that, in the real data scenario, AAD was able to\nidentify ~80\\% more true anomalies than the IF. This result is the first\nevidence that AAD algorithms can play a central role in the search for new\nphysics in the era of large scale sky surveys.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 11:25:15 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 15:52:21 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ishida", "Emille E. O.", ""], ["Kornilov", "Matwey V.", ""], ["Malanchev", "Konstantin L.", ""], ["Pruzhinskaya", "Maria V.", ""], ["Volnova", "Alina A.", ""], ["Korolev", "Vladimir S.", ""], ["Mondon", "Florian", ""], ["Sreejith", "Sreevarsha", ""], ["Malancheva", "Anastasia", ""], ["Das", "Shubhomoy", ""]]}, {"id": "1909.13271", "submitter": "Thierry Tambe", "authors": "Thierry Tambe, En-Yu Yang, Zishen Wan, Yuntian Deng, Vijay Janapa\n  Reddi, Alexander Rush, David Brooks, Gu-Yeon Wei", "title": "AdaptivFloat: A Floating-point based Data Type for Resilient Deep\n  Learning Inference", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional hardware-friendly quantization methods, such as fixed-point or\ninteger, tend to perform poorly at very low word sizes as their shrinking\ndynamic ranges cannot adequately capture the wide data distributions commonly\nseen in sequence transduction models. We present AdaptivFloat, a floating-point\ninspired number representation format for deep learning that dynamically\nmaximizes and optimally clips its available dynamic range, at a layer\ngranularity, in order to create faithful encoding of neural network parameters.\nAdaptivFloat consistently produces higher inference accuracies compared to\nblock floating-point, uniform, IEEE-like float or posit encodings at very low\nprecision ($\\leq$ 8-bit) across a diverse set of state-of-the-art neural\nnetwork topologies. And notably, AdaptivFloat is seen surpassing baseline FP32\nperformance by up to +0.3 in BLEU score and -0.75 in word error rate at weight\nbit widths that are $\\leq$ 8-bit. Experimental results on a deep neural network\n(DNN) hardware accelerator, exploiting AdaptivFloat logic in its computational\ndatapath, demonstrate per-operation energy and area that is 0.9$\\times$ and\n1.14$\\times$, respectively, that of equivalent bit width integer-based\naccelerator variants.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 12:41:46 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 16:00:21 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 09:30:21 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Tambe", "Thierry", ""], ["Yang", "En-Yu", ""], ["Wan", "Zishen", ""], ["Deng", "Yuntian", ""], ["Reddi", "Vijay Janapa", ""], ["Rush", "Alexander", ""], ["Brooks", "David", ""], ["Wei", "Gu-Yeon", ""]]}, {"id": "1909.13316", "submitter": "Vitor Cerqueira", "authors": "Vitor Cerqueira, Luis Torgo, Carlos Soares", "title": "Machine Learning vs Statistical Methods for Time Series Forecasting:\n  Size Matters", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series forecasting is one of the most active research topics. Machine\nlearning methods have been increasingly adopted to solve these predictive\ntasks. However, in a recent work, these were shown to systematically present a\nlower predictive performance relative to simple statistical methods. In this\nwork, we counter these results. We show that these are only valid under an\nextremely low sample size. Using a learning curve method, our results suggest\nthat machine learning methods improve their relative predictive performance as\nthe sample size grows. The code to reproduce the experiments is available at\nhttps://github.com/vcerqueira/MLforForecasting.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 16:44:12 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Cerqueira", "Vitor", ""], ["Torgo", "Luis", ""], ["Soares", "Carlos", ""]]}, {"id": "1909.13322", "submitter": "Rongrong Wang", "authors": "Rongrong Wang, Xiaopeng Zhang", "title": "Capacity Preserving Mapping for High-dimensional Data Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a rigorous mathematical treatment to the crowding issue in data\nvisualization when high dimensional data sets are projected down to low\ndimensions for visualization. By properly adjusting the capacity of high\ndimensional balls, our method makes right enough room to prepare for the\nembedding. A key component of the proposed method is an estimation of the\ncorrelation dimension at various scales which reflects the data density\nvariation. The proposed adjustment to the capacity applies to any distance\n(Euclidean, geodesic, diffusion) and can potentially be used in many existing\nmethods to mitigate the crowding during the dimension reduction. We demonstrate\nthe effectiveness of the new method using synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 17:06:13 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 13:59:39 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wang", "Rongrong", ""], ["Zhang", "Xiaopeng", ""]]}, {"id": "1909.13327", "submitter": "Christoph Feinauer", "authors": "Matteo Negri, Davide Bergamini, Carlo Baldassi, Riccardo Zecchina,\n  Christoph Feinauer", "title": "Natural representation of composite data with replicated autoencoders", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative processes in biology and other fields often produce data that can\nbe regarded as resulting from a composition of basic features. Here we present\nan unsupervised method based on autoencoders for inferring these basic features\nof data. The main novelty in our approach is that the training is based on the\noptimization of the `local entropy' rather than the standard loss, resulting in\na more robust inference, and enhancing the performance on this type of data\nconsiderably. Algorithmically, this is realized by training an interacting\nsystem of replicated autoencoders. We apply this method to synthetic and\nprotein sequence data, and show that it is able to infer a hidden\nrepresentation that correlates well with the underlying generative process,\nwithout requiring any prior knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 17:41:44 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Negri", "Matteo", ""], ["Bergamini", "Davide", ""], ["Baldassi", "Carlo", ""], ["Zecchina", "Riccardo", ""], ["Feinauer", "Christoph", ""]]}, {"id": "1909.13334", "submitter": "Zhengdao Chen", "authors": "Zhengdao Chen, Jianyu Zhang, Martin Arjovsky and L\\'eon Bottou", "title": "Symplectic Recurrent Neural Networks", "comments": "Added link to GitHub repository", "journal-ref": "8th International Conference on Learning Representations (ICLR\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Symplectic Recurrent Neural Networks (SRNNs) as learning\nalgorithms that capture the dynamics of physical systems from observed\ntrajectories. An SRNN models the Hamiltonian function of the system by a neural\nnetwork and furthermore leverages symplectic integration, multiple-step\ntraining and initial state optimization to address the challenging numerical\nissues associated with Hamiltonian systems. We show that SRNNs succeed reliably\non complex and noisy Hamiltonian systems. We also show how to augment the SRNN\nintegration scheme in order to handle stiff dynamical systems such as bouncing\nbilliards.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 18:04:07 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 16:32:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Chen", "Zhengdao", ""], ["Zhang", "Jianyu", ""], ["Arjovsky", "Martin", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1909.13339", "submitter": "Badr-Eddine Ch\\'erief-Abdellatif", "authors": "Badr-Eddine Ch\\'erief-Abdellatif, Pierre Alquier", "title": "MMD-Bayes: Robust Bayesian Estimation via Maximum Mean Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some misspecified settings, the posterior distribution in Bayesian\nstatistics may lead to inconsistent estimates. To fix this issue, it has been\nsuggested to replace the likelihood by a pseudo-likelihood, that is the\nexponential of a loss function enjoying suitable robustness properties. In this\npaper, we build a pseudo-likelihood based on the Maximum Mean Discrepancy,\ndefined via an embedding of probability distributions into a reproducing kernel\nHilbert space. We show that this MMD-Bayes posterior is consistent and robust\nto model misspecification. As the posterior obtained in this way might be\nintractable, we also prove that reasonable variational approximations of this\nposterior enjoy the same properties. We provide details on a stochastic\ngradient algorithm to compute these variational approximations. Numerical\nsimulations indeed suggest that our estimator is more robust to\nmisspecification than the ones based on the likelihood.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 18:49:05 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 17:51:01 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Ch\u00e9rief-Abdellatif", "Badr-Eddine", ""], ["Alquier", "Pierre", ""]]}, {"id": "1909.13340", "submitter": "Geoffrey Fox", "authors": "Geoffrey Fox, Shantenu Jha", "title": "Learning Everywhere: A Taxonomy for the Integration of Machine Learning\n  and Simulations", "comments": "15th International Conference eScience 2019, September 24-27, 2019,\n  San Diego, California,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a taxonomy of research on Machine Learning (ML) applied to enhance\nsimulations together with a catalog of some activities. We cover eight patterns\nfor the link of ML to the simulations or systems plus three algorithmic areas:\nparticle dynamics, agent-based models and partial differential equations. The\npatterns are further divided into three action areas: Improving simulation with\nConfigurations and Integration of Data, Learn Structure, Theory and Model for\nSimulation, and Learn to make Surrogates.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 18:52:30 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 11:20:36 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fox", "Geoffrey", ""], ["Jha", "Shantenu", ""]]}, {"id": "1909.13343", "submitter": "Xiao Wang", "authors": "Akshay Arora, Arun Nethi, Priyanka Kharat, Vency Verghese, Grant\n  Jenkins, Steve Miff, Vikas Chowdhry, Xiao Wang", "title": "ISTHMUS: Secure, Scalable, Real-time and Robust Machine Learning\n  Platform for Healthcare", "comments": "11 pages, 7 figures. Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, machine learning (ML) and artificial intelligence (AI) based\nsystems have evolved and scaled across different industries such as finance,\nretail, insurance, energy utilities, etc. Among other things, they have been\nused to predict patterns of customer behavior, to generate pricing models, and\nto predict the return on investments. But the successes in deploying machine\nlearning models at scale in those industries have not translated into the\nhealthcare setting. There are multiple reasons why integrating ML models into\nhealthcare has not been widely successful, but from a technical perspective,\ngeneral-purpose commercial machine learning platforms are not a good fit for\nhealthcare due to complexities in handling data quality issues, mandates to\ndemonstrate clinical relevance, and a lack of ability to monitor performance in\na highly regulated environment with stringent security and privacy needs. In\nthis paper, we describe Isthmus, a turnkey, cloud-based platform which\naddresses the challenges above and reduces time to market for operationalizing\nML/AI in healthcare. Towards the end, we describe three case studies which shed\nlight on Isthmus capabilities. These include (1) supporting an end-to-end\nlifecycle of a model which predicts trauma survivability at hospital trauma\ncenters, (2) bringing in and harmonizing data from disparate sources to create\na community data platform for inferring population as well as patient level\ninsights for Social Determinants of Health (SDoH), and (3) ingesting\nlive-streaming data from various IoT sensors to build models, which can\nleverage real-time and longitudinal information to make advanced time-sensitive\npredictions.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 19:15:08 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:06:39 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Arora", "Akshay", ""], ["Nethi", "Arun", ""], ["Kharat", "Priyanka", ""], ["Verghese", "Vency", ""], ["Jenkins", "Grant", ""], ["Miff", "Steve", ""], ["Chowdhry", "Vikas", ""], ["Wang", "Xiao", ""]]}, {"id": "1909.13355", "submitter": "Christoph Studer", "authors": "Eric Lei, Oscar Casta\\~neda, Olav Tirkkonen, Tom Goldstein, Christoph\n  Studer", "title": "Siamese Neural Networks for Wireless Positioning and Channel Charting", "comments": "Presented at Allerton 2019; 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been proposed recently for positioning and channel\ncharting of user equipments (UEs) in wireless systems. Both of these approaches\nprocess channel state information (CSI) that is acquired at a multi-antenna\nbase-station in order to learn a function that maps CSI to location\ninformation. CSI-based positioning using deep neural networks requires a\ndataset that contains both CSI and associated location information. Channel\ncharting (CC) only requires CSI information to extract relative position\ninformation. Since CC builds on dimensionality reduction, it can be implemented\nusing autoencoders. In this paper, we propose a unified architecture based on\nSiamese networks that can be used for supervised UE positioning and\nunsupervised channel charting. In addition, our framework enables\nsemisupervised positioning, where only a small set of location information is\navailable during training. We use simulations to demonstrate that Siamese\nnetworks achieve similar or better performance than existing positioning and CC\napproaches with a single, unified neural network architecture.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 20:04:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lei", "Eric", ""], ["Casta\u00f1eda", "Oscar", ""], ["Tirkkonen", "Olav", ""], ["Goldstein", "Tom", ""], ["Studer", "Christoph", ""]]}, {"id": "1909.13360", "submitter": "Jung Lee", "authors": "Jung Hoon Lee", "title": "Library network, a possible path to explainable neural networks", "comments": "15 page, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) may outperform human brains in complex tasks, but\nthe lack of transparency in their decision-making processes makes us question\nwhether we could fully trust DNNs with high stakes problems. As DNNs'\noperations rely on a massive number of both parallel and sequential\nlinear/nonlinear computations, predicting their mistakes is nearly impossible.\nAlso, a line of studies suggests that DNNs can be easily deceived by\nadversarial attacks, indicating that their decisions can easily be corrupted by\nunexpected factors. Such vulnerability must be overcome if we intend to take\nadvantage of DNNs' efficiency in high stakes problems. Here, we propose an\nalgorithm that can help us better understand DNNs' decision-making processes.\nOur empirical evaluations suggest that this algorithm can effectively trace\nDNNs' decision processes from one layer to another and detect adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 20:25:08 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 16:12:46 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 23:59:46 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Lee", "Jung Hoon", ""]]}, {"id": "1909.13371", "submitter": "Erik Meijer", "authors": "Kartik Chandra, Erik Meijer, Samantha Andow, Emilio Arroyo-Fang, Irene\n  Dea, Johann George, Melissa Grueter, Basil Hosmer, Steffi Stumpos, Alanna\n  Tempest, Shannon Yang", "title": "Gradient Descent: The Ultimate Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working with any gradient-based machine learning algorithm involves the\ntedious task of tuning the optimizer's hyperparameters, such as the learning\nrate. There exist many techniques for automated hyperparameter optimization,\nbut they typically introduce even more hyperparameters to control the\nhyperparameter optimization process. We propose to instead learn the\nhyperparameters themselves by gradient descent, and furthermore to learn the\nhyper-hyperparameters by gradient descent as well, and so on ad infinitum. As\nthese towers of gradient-based optimizers grow, they become significantly less\nsensitive to the choice of top-level hyperparameters, hence decreasing the\nburden on the user to search for optimal values.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:41:49 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Chandra", "Kartik", ""], ["Meijer", "Erik", ""], ["Andow", "Samantha", ""], ["Arroyo-Fang", "Emilio", ""], ["Dea", "Irene", ""], ["George", "Johann", ""], ["Grueter", "Melissa", ""], ["Hosmer", "Basil", ""], ["Stumpos", "Steffi", ""], ["Tempest", "Alanna", ""], ["Yang", "Shannon", ""]]}, {"id": "1909.13377", "submitter": "Jiacheng Pan", "authors": "Jiacheng Pan, Hongyi Sun, Kecheng Xu, Yifei Jiang, Xiangquan Xiao,\n  Jiangtao Hu, Jinghao Miao", "title": "Lane Attention: Predicting Vehicles' Moving Trajectories by Learning\n  Their Attention over Lanes", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately forecasting the future movements of surrounding vehicles is\nessential for safe and efficient operations of autonomous driving cars. This\ntask is difficult because a vehicle's moving trajectory is greatly determined\nby its driver's intention, which is often hard to estimate. By leveraging\nattention mechanisms along with long short-term memory (LSTM) networks, this\nwork learns the relation between a driver's intention and the vehicle's\nchanging positions relative to road infrastructures, and uses it to guide the\nprediction. Different from other state-of-the-art solutions, our work treats\nthe on-road lanes as non-Euclidean structures, unfolds the vehicle's moving\nhistory to form a spatio-temporal graph, and uses methods from Graph Neural\nNetworks to solve the problem. Not only is our approach a pioneering attempt in\nusing non-Euclidean methods to process static environmental features around a\npredicted object, our model also outperforms other state-of-the-art models in\nseveral metrics. The practicability and interpretability analysis of the model\nshows great potential for large-scale deployment in various autonomous driving\nsystems in addition to our own.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:50:39 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 05:44:24 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Pan", "Jiacheng", ""], ["Sun", "Hongyi", ""], ["Xu", "Kecheng", ""], ["Jiang", "Yifei", ""], ["Xiao", "Xiangquan", ""], ["Hu", "Jiangtao", ""], ["Miao", "Jinghao", ""]]}, {"id": "1909.13384", "submitter": "Rajesh Jayaram", "authors": "Huaian Diao, Rajesh Jayaram, Zhao Song, Wen Sun, David P. Woodruff", "title": "Optimal Sketching for Kronecker Product Regression and Low Rank\n  Approximation", "comments": "A preliminary version of this paper appeared in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Kronecker product regression problem, in which the design matrix\nis a Kronecker product of two or more matrices. Given $A_i \\in \\mathbb{R}^{n_i\n\\times d_i}$ for $i=1,2,\\dots,q$ where $n_i \\gg d_i$ for each $i$, and $b \\in\n\\mathbb{R}^{n_1 n_2 \\cdots n_q}$, let $\\mathcal{A} = A_1 \\otimes A_2 \\otimes\n\\cdots \\otimes A_q$. Then for $p \\in [1,2]$, the goal is to find $x \\in\n\\mathbb{R}^{d_1 \\cdots d_q}$ that approximately minimizes $\\|\\mathcal{A}x -\nb\\|_p$. Recently, Diao, Song, Sun, and Woodruff (AISTATS, 2018) gave an\nalgorithm which is faster than forming the Kronecker product $\\mathcal{A}$\nSpecifically, for $p=2$ their running time is $O(\\sum_{i=1}^q \\text{nnz}(A_i) +\n\\text{nnz}(b))$, where nnz$(A_i)$ is the number of non-zero entries in $A_i$.\nNote that nnz$(b)$ can be as large as $n_1 \\cdots n_q$. For $p=1,$ $q=2$ and\n$n_1 = n_2$, they achieve a worse bound of $O(n_1^{3/2} \\text{poly}(d_1d_2) +\n\\text{nnz}(b))$. In this work, we provide significantly faster algorithms. For\n$p=2$, our running time is $O(\\sum_{i=1}^q \\text{nnz}(A_i) )$, which has no\ndependence on nnz$(b)$. For $p<2$, our running time is $O(\\sum_{i=1}^q\n\\text{nnz}(A_i) + \\text{nnz}(b))$, which matches the prior best running time\nfor $p=2$. We also consider the related all-pairs regression problem, where\ngiven $A \\in \\mathbb{R}^{n \\times d}, b \\in \\mathbb{R}^n$, we want to solve\n$\\min_{x} \\|\\bar{A}x - \\bar{b}\\|_p$, where $\\bar{A} \\in \\mathbb{R}^{n^2 \\times\nd}, \\bar{b} \\in \\mathbb{R}^{n^2}$ consist of all pairwise differences of the\nrows of $A,b$. We give an $O(\\text{nnz}(A))$ time algorithm for $p \\in[1,2]$,\nimproving the $\\Omega(n^2)$ time needed to form $\\bar{A}$. Finally, we initiate\nthe study of Kronecker product low rank and low $t$-rank approximation. For\ninput $\\mathcal{A}$ as above, we give $O(\\sum_{i=1}^q \\text{nnz}(A_i))$ time\nalgorithms, which is much faster than computing $\\mathcal{A}$.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 22:24:28 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Diao", "Huaian", ""], ["Jayaram", "Rajesh", ""], ["Song", "Zhao", ""], ["Sun", "Wen", ""], ["Woodruff", "David P.", ""]]}, {"id": "1909.13391", "submitter": "Jayanth Regatti", "authors": "Jayanth Regatti, Gaurav Tendolkar, Yi Zhou, Abhishek Gupta, Yingbin\n  Liang", "title": "Distributed SGD Generalizes Well Under Asynchrony", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of fully synchronized distributed systems has faced a\nbottleneck due to the big data trend, under which asynchronous distributed\nsystems are becoming a major popularity due to their powerful scalability. In\nthis paper, we study the generalization performance of stochastic gradient\ndescent (SGD) on a distributed asynchronous system. The system consists of\nmultiple worker machines that compute stochastic gradients which are further\nsent to and aggregated on a common parameter server to update the variables,\nand the communication in the system suffers from possible delays. Under the\nalgorithm stability framework, we prove that distributed asynchronous SGD\ngeneralizes well given enough data samples in the training optimization. In\nparticular, our results suggest to reduce the learning rate as we allow more\nasynchrony in the distributed system. Such adaptive learning rate strategy\nimproves the stability of the distributed algorithm and reduces the\ncorresponding generalization error. Then, we confirm our theoretical findings\nvia numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 22:35:42 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Regatti", "Jayanth", ""], ["Tendolkar", "Gaurav", ""], ["Zhou", "Yi", ""], ["Gupta", "Abhishek", ""], ["Liang", "Yingbin", ""]]}, {"id": "1909.13392", "submitter": "Sunil Gandhi", "authors": "Sunil Gandhi, Tim Oates, Tinoosh Mohsenin, Nicholas Waytowich", "title": "Learning from Observations Using a Single Video Demonstration and Human\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for learning from video demonstrations by\nusing human feedback to construct a mapping between the standard representation\nof the agent and the visual representation of the demonstration. In this way,\nwe leverage the advantages of both these representations, i.e., we learn the\npolicy using standard state representations, but are able to specify the\nexpected behavior using video demonstration. We train an autonomous agent using\na single video demonstration and use human feedback (using numerical similarity\nrating) to map the standard representation to the visual representation with a\nneural network. We show the effectiveness of our method by teaching a hopper\nagent in the MuJoCo to perform a backflip using a single video demonstration\ngenerated in MuJoCo as well as from a real-world YouTube video of a person\nperforming a backflip. Additionally, we show that our method can transfer to\nnew tasks, such as hopping, with very little human feedback.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 22:44:59 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gandhi", "Sunil", ""], ["Oates", "Tim", ""], ["Mohsenin", "Tinoosh", ""], ["Waytowich", "Nicholas", ""]]}, {"id": "1909.13403", "submitter": "Zinan Lin", "authors": "Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, Vyas Sekar", "title": "Using GANs for Sharing Networked Time Series Data: Challenges, Initial\n  Promise, and Open Questions", "comments": "Published in IMC 2020. 20 pages, 26 figures", "journal-ref": null, "doi": "10.1145/3419394.3423643", "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited data access is a longstanding barrier to data-driven research and\ndevelopment in the networked systems community. In this work, we explore if and\nhow generative adversarial networks (GANs) can be used to incentivize data\nsharing by enabling a generic framework for sharing synthetic datasets with\nminimal expert knowledge. As a specific target, our focus in this paper is on\ntime series datasets with metadata (e.g., packet loss rate measurements with\ncorresponding ISPs). We identify key challenges of existing GAN approaches for\nsuch workloads with respect to fidelity (e.g., long-term dependencies, complex\nmultidimensional relationships, mode collapse) and privacy (i.e., existing\nguarantees are poorly understood and can sacrifice fidelity). To improve\nfidelity, we design a custom workflow called DoppelGANger (DG) and demonstrate\nthat across diverse real-world datasets (e.g., bandwidth measurements, cluster\nrequests, web sessions) and use cases (e.g., structural characterization,\npredictive modeling, algorithm comparison), DG achieves up to 43% better\nfidelity than baseline models. Although we do not resolve the privacy problem\nin this work, we identify fundamental challenges with both classical notions of\nprivacy and recent advances to improve the privacy properties of GANs, and\nsuggest a potential roadmap for addressing these challenges. By shedding light\non the promise and challenges, we hope our work can rekindle the conversation\non workflows for data sharing.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 00:13:19 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 06:39:40 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 15:45:27 GMT"}, {"version": "v4", "created": "Sun, 15 Nov 2020 01:20:02 GMT"}, {"version": "v5", "created": "Sun, 17 Jan 2021 04:54:51 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Lin", "Zinan", ""], ["Jain", "Alankar", ""], ["Wang", "Chen", ""], ["Fanti", "Giulia", ""], ["Sekar", "Vyas", ""]]}, {"id": "1909.13404", "submitter": "Renato Negrinho", "authors": "Renato Negrinho, Darshan Patil, Nghia Le, Daniel Ferreira, Matthew\n  Gormley, Geoffrey Gordon", "title": "Towards modular and programmable architecture search", "comments": "Published at NeurIPS 2019. Code and documentation for the language\n  implementation can be found at https://github.com/negrinho/deep_architect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search methods are able to find high performance deep\nlearning architectures with minimal effort from an expert. However, current\nsystems focus on specific use-cases (e.g. convolutional image classifiers and\nrecurrent language models), making them unsuitable for general use-cases that\nan expert might wish to write. Hyperparameter optimization systems are\ngeneral-purpose but lack the constructs needed for easy application to\narchitecture search. In this work, we propose a formal language for encoding\nsearch spaces over general computational graphs. The language constructs allow\nus to write modular, composable, and reusable search space encodings and to\nreason about search space design. We use our language to encode search spaces\nfrom the architecture search literature. The language allows us to decouple the\nimplementations of the search space and the search algorithm, allowing us to\nexpose search spaces to search algorithms through a consistent interface. Our\nexperiments show the ease with which we can experiment with different\ncombinations of search spaces and search algorithms without having to implement\neach combination from scratch. We release an implementation of our language\nwith this paper.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 00:18:56 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Negrinho", "Renato", ""], ["Patil", "Darshan", ""], ["Le", "Nghia", ""], ["Ferreira", "Daniel", ""], ["Gormley", "Matthew", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1909.13408", "submitter": "Pawe{\\l} Widera", "authors": "Pawe{\\l} Widera, Paco M.J. Welsing, Christoph Ladel, John Loughlin,\n  Floris P.J.G. Lafeber, Florence Petit Dop, Jonathan Larkin, Harrie Weinans,\n  Ali Mobasheri and Jaume Bacardit", "title": "Multi-classifier prediction of knee osteoarthritis progression from\n  incomplete imbalanced longitudinal data", "comments": "22 pages, 12 figures, 10 tables", "journal-ref": "Scientific Reports, 10(1), 2020", "doi": "10.1038/s41598-020-64643-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conventional inclusion criteria used in osteoarthritis clinical trials are\nnot very effective in selecting patients who would benefit from a therapy being\ntested. Typically majority of selected patients show no or limited disease\nprogression during a trial period. As a consequence, the effect of the tested\ntreatment cannot be observed, and the efforts and resources invested in running\nthe trial are not rewarded. This could be avoided, if selection criteria were\nmore predictive of the future disease progression.\n  In this article, we formulated the patient selection problem as a multi-class\nclassification task, with classes based on clinically relevant measures of\nprogression (over a time scale typical for clinical trials). Using data from\ntwo long-term knee osteoarthritis studies OAI and CHECK, we tested multiple\nalgorithms and learning process configurations (including multi-classifier\napproaches, cost-sensitive learning, and feature selection), to identify the\nbest performing machine learning models. We examined the behaviour of the best\nmodels, with respect to prediction errors and the impact of used features, to\nconfirm their clinical relevance. We found that the model-based selection\noutperforms the conventional inclusion criteria, reducing by 20-25% the number\nof patients who show no progression. This result might lead to more efficient\nclinical trials.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 00:42:14 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 17:58:00 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Widera", "Pawe\u0142", ""], ["Welsing", "Paco M. J.", ""], ["Ladel", "Christoph", ""], ["Loughlin", "John", ""], ["Lafeber", "Floris P. J. G.", ""], ["Dop", "Florence Petit", ""], ["Larkin", "Jonathan", ""], ["Weinans", "Harrie", ""], ["Mobasheri", "Ali", ""], ["Bacardit", "Jaume", ""]]}, {"id": "1909.13428", "submitter": "Qinghua Tao", "authors": "Yusen Huo, Qinghua Tao, and Jianming Hu", "title": "Tensor-based Cooperative Control for Large Scale Multi-intersection\n  Traffic Signal Using Deep Reinforcement Learning and Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signal control has long been considered as a critical topic in\nintelligent transportation systems. Most existing learning methods mainly focus\non isolated intersections and suffer from inefficient training. This paper aims\nat the cooperative control for large scale multi-intersection traffic signal,\nin which a novel end-to-end learning based model is established and the\nefficient training method is proposed correspondingly. In the proposed model,\nthe input traffic status in multi-intersections is represented by a tensor,\nwhich not only significantly reduces dimensionality than using a single matrix\nbut also avoids information loss. For the output, a multidimensional boolean\nvector is employed for the control policy to indicate whether the signal state\nchanges or not, which simplifies the representation and abides the practical\nphase changing rules. In the proposed model, a multi-task learning structure is\nused to get the cooperative policy by learning. Instead of only using the\nreinforcement learning to train the model, we employ imitation learning to\nintegrate a rule based model with neural networks to do the pre-training, which\nprovides a reliable and satisfactory stage solution and greatly accelerates the\nconvergence. Afterwards, the reinforcement learning method is adopted to\ncontinue the fine training, where proximal policy optimization algorithm is\nincorporated to solve the policy collapse problem in multi-dimensional output\nsituation. In numerical experiments, the advantages of the proposed model are\ndemonstrated with comparison to the related state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:20:47 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Huo", "Yusen", ""], ["Tao", "Qinghua", ""], ["Hu", "Jianming", ""]]}, {"id": "1909.13433", "submitter": "Juho Lee", "authors": "Juho Lee, Yoonho Lee, Yee Whye Teh", "title": "Deep Amortized Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep amortized clustering (DAC), a neural architecture which\nlearns to cluster datasets efficiently using a few forward passes. DAC\nimplicitly learns what makes a cluster, how to group data points into clusters,\nand how to count the number of clusters in datasets. DAC is meta-learned using\nlabelled datasets for training, a process distinct from traditional clustering\nalgorithms which usually require hand-specified prior knowledge about cluster\nshapes/structures. We empirically show, on both synthetic and image data, that\nDAC can efficiently and accurately cluster new datasets coming from the same\ndistribution used to generate training datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:35:49 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lee", "Juho", ""], ["Lee", "Yoonho", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1909.13456", "submitter": "Zhe Gan", "authors": "Wenlin Wang, Chenyang Tao, Zhe Gan, Guoyin Wang, Liqun Chen, Xinyuan\n  Zhang, Ruiyi Zhang, Qian Yang, Ricardo Henao, Lawrence Carin", "title": "Improving Textual Network Learning with Variational Homophilic\n  Embeddings", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many network learning applications crucially hinges on the\nsuccess of network embedding algorithms, which aim to encode rich network\ninformation into low-dimensional vertex-based vector representations. This\npaper considers a novel variational formulation of network embeddings, with\nspecial focus on textual networks. Different from most existing methods that\noptimize a discriminative objective, we introduce Variational Homophilic\nEmbedding (VHE), a fully generative model that learns network embeddings by\nmodeling the semantic (textual) information with a variational autoencoder,\nwhile accounting for the structural (topology) information through a novel\nhomophilic prior design. Homophilic vertex embeddings encourage similar\nembedding vectors for related (connected) vertices. The proposed VHE promises\nbetter generalization for downstream tasks, robustness to incomplete\nobservations, and the ability to generalize to unseen vertices. Extensive\nexperiments on real-world networks, for multiple tasks, demonstrate that the\nproposed method consistently achieves superior performance relative to\ncompeting state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 05:03:25 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Wenlin", ""], ["Tao", "Chenyang", ""], ["Gan", "Zhe", ""], ["Wang", "Guoyin", ""], ["Chen", "Liqun", ""], ["Zhang", "Xinyuan", ""], ["Zhang", "Ruiyi", ""], ["Yang", "Qian", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1909.13458", "submitter": "Yuandong Tian", "authors": "Yuandong Tian", "title": "Student Specialization in Deep ReLU Networks With Finite Width and Input\n  Dimension", "comments": "Accepted in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a deep ReLU / Leaky ReLU student network trained from the output\nof a fixed teacher network of the same depth, with Stochastic Gradient Descent\n(SGD). The student network is \\emph{over-realized}: at each layer $l$, the\nnumber $n_l$ of student nodes is more than that ($m_l$) of teacher. Under mild\nconditions on dataset and teacher network, we prove that when the gradient is\nsmall at every data sample, each teacher node is \\emph{specialized} by at least\none student node \\emph{at the lowest layer}. For two-layer network, such\nspecialization can be achieved by training on any dataset of \\emph{polynomial}\nsize $\\mathcal{O}( K^{5/2} d^3 \\epsilon^{-1})$. until the gradient magnitude\ndrops to $\\mathcal{O}(\\epsilon/K^{3/2}\\sqrt{d})$. Here $d$ is the input\ndimension, $K = m_1 + n_1$ is the total number of neurons in the lowest layer\nof teacher and student. Note that we require a specific form of data\naugmentation and the sample complexity includes the additional data generated\nfrom augmentation. To our best knowledge, we are the first to give polynomial\nsample complexity for student specialization of training two-layer (Leaky) ReLU\nnetworks with finite depth and width in teacher-student setting, and finite\ncomplexity for the lowest layer specialization in multi-layer case, without\nparametric assumption of the input (like Gaussian). Our theory suggests that\nteacher nodes with large fan-out weights get specialized first when the\ngradient is still large, while others are specialized with small gradient,\nwhich suggests inductive bias in training. This shapes the stage of training as\nempirically observed in multiple previous works. Experiments on synthetic and\nCIFAR10 verify our findings. The code is released in\nhttps://github.com/facebookresearch/luckmatters.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 05:06:58 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:22:39 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 19:23:16 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 04:12:10 GMT"}, {"version": "v5", "created": "Mon, 8 Jun 2020 16:41:18 GMT"}, {"version": "v6", "created": "Sun, 28 Jun 2020 18:12:14 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tian", "Yuandong", ""]]}, {"id": "1909.13469", "submitter": "Shubhadeep Chakraborty", "authors": "Shubhadeep Chakraborty and Xianyang Zhang", "title": "A New Framework for Distance and Kernel-based Metrics in High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents new metrics to quantify and test for (i) the equality of\ndistributions and (ii) the independence between two high-dimensional random\nvectors. We show that the energy distance based on the usual Euclidean distance\ncannot completely characterize the homogeneity of two high-dimensional\ndistributions in the sense that it only detects the equality of means and the\ntraces of covariance matrices in the high-dimensional setup. We propose a new\nclass of metrics which inherits the desirable properties of the energy distance\nand maximum mean discrepancy/(generalized) distance covariance and the\nHilbert-Schmidt Independence Criterion in the low-dimensional setting and is\ncapable of detecting the homogeneity of/completely characterizing independence\nbetween the low-dimensional marginal distributions in the high dimensional\nsetup. We further propose t-tests based on the new metrics to perform\nhigh-dimensional two-sample testing/independence testing and study their\nasymptotic behavior under both high dimension low sample size (HDLSS) and high\ndimension medium sample size (HDMSS) setups. The computational complexity of\nthe t-tests only grows linearly with the dimension and thus is scalable to very\nhigh dimensional data. We demonstrate the superior power behavior of the\nproposed tests for homogeneity of distributions and independence via both\nsimulated and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 06:19:42 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Chakraborty", "Shubhadeep", ""], ["Zhang", "Xianyang", ""]]}, {"id": "1909.13472", "submitter": "Martin Royer", "authors": "Martin Royer (DATASHAPE), Fr\\'ed\\'eric Chazal (DATASHAPE), Cl\\'ement\n  Levrard (LPSM (UMR\\_8001)), Umeda Yuhei, Ike Yuichi", "title": "ATOL: Measure Vectorization for Automatic Topologically-Oriented\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust topological information commonly comes in the form of a set of\npersistence diagrams, finite measures that are in nature uneasy to affix to\ngeneric machine learning frameworks. We introduce a fast, learnt, unsupervised\nvectorization method for measures in Euclidean spaces and use it for reflecting\nunderlying changes in topological behaviour in machine learning contexts. The\nalgorithm is simple and efficiently discriminates important space regions where\nmeaningful differences to the mean measure arise. It is proven to be able to\nseparate clusters of persistence diagrams. We showcase the strength and\nrobustness of our approach on a number of applications, from emulous and modern\ngraph collections where the method reaches state-of-the-art performance to a\ngeometric synthetic dynamical orbits problem. The proposed methodology comes\nwith a single high level tuning parameter: the total measure encoding budget.\nWe provide a completely open access software.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 06:30:33 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:21:18 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 08:13:12 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Royer", "Martin", "", "DATASHAPE"], ["Chazal", "Fr\u00e9d\u00e9ric", "", "DATASHAPE"], ["Levrard", "Cl\u00e9ment", "", "LPSM"], ["Yuhei", "Umeda", ""], ["Yuichi", "Ike", ""]]}, {"id": "1909.13488", "submitter": "Guang-He Lee", "authors": "Guang-He Lee and Tommi S. Jaakkola", "title": "Oblique Decision Trees from Derivatives of ReLU Networks", "comments": "Published in International Conference on Learning Representations\n  (ICLR), 2020. Code available: https://github.com/guanghelee/iclr20-lcn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how neural models can be used to realize piece-wise constant\nfunctions such as decision trees. The proposed architecture, which we call\nlocally constant networks, builds on ReLU networks that are piece-wise linear\nand hence their associated gradients with respect to the inputs are locally\nconstant. We formally establish the equivalence between the classes of locally\nconstant networks and decision trees. Moreover, we highlight several\nadvantageous properties of locally constant networks, including how they\nrealize decision trees with parameter sharing across branching / leaves.\nIndeed, only $M$ neurons suffice to implicitly model an oblique decision tree\nwith $2^M$ leaf nodes. The neural representation also enables us to adopt many\ntools developed for deep networks (e.g., DropConnect (Wan et al., 2013)) while\nimplicitly training decision trees. We demonstrate that our method outperforms\nalternative techniques for training oblique decision trees in the context of\nmolecular property classification and regression tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 07:23:16 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 18:55:49 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lee", "Guang-He", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1909.13492", "submitter": "Zhigang Yao", "authors": "Zhigang Yao and Wee Chin Tan", "title": "Manifold Fitting in Ambient Space", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data sets in many applications no longer comprise samples of real\nvectors in a real vector space but samples of much more complex structures\nwhich may be represented as points in a space with certain underlying geometric\nstructure, namely a manifold. Manifold learning is an emerging field for\nlearning the underlying structure. The study of manifold learning can be split\ninto two main branches, namely dimension reduction and manifold fitting. With\nthe aim of interacting statistics and geometry, we tackle the problem of\nmanifold fitting in the ambient space. Inspired by the relation between the\neigenvalues of the Laplace-Beltrami operator and the geometry of a manifold, we\naim to find a small set of points that preserve the geometry of the underlying\nmanifold. Based on this relationship, we extend the idea of subsampling to\nnoisy datasets in high dimensional space and utilize the Moving Least Squares\n(MLS) approach to approximate the underlying manifold. We analyze the two core\nsteps in our proposed method theoretically and also provide the bounds for the\nMLS approach. Our simulation results and real data analysis demonstrate the\nsuperiority of our method in estimating the underlying manifold from noisy\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 07:36:41 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Yao", "Zhigang", ""], ["Tan", "Wee Chin", ""]]}, {"id": "1909.13499", "submitter": "Sylvain Arlot", "authors": "Sylvain Arlot (LMO, CELESTE)", "title": "Rejoinder on: Minimal penalties and the slope heuristics: a survey", "comments": null, "journal-ref": "Journal de la Societe Fran{\\c c}aise de Statistique, Societe\n  Fran{\\c c}aise de Statistique et Societe Mathematique de France, Vol 106,\n  No.3, 158-168. 2019", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This text is the rejoinder following the discussion of a survey paper about\nminimal penalties and the slope heuristics (Arlot, 2019. Minimal penalties and\nthe slope heuristics: a survey. Journal de la SFDS). While commenting on the\nremarks made by the discussants, it provides two new results about the slope\nheuristics for model selection among a collection of projection estimators in\nleast-squares fixed-design regression. First, we prove that the slope\nheuristics works even when all models are significantly biased. Second, when\nthe noise is Gaussian with a general dependence structure, we compute\nexpectations of key quantities, showing that the slope heuristics certainly is\nvalid in this setting also.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 08:04:46 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Arlot", "Sylvain", "", "LMO, CELESTE"]]}, {"id": "1909.13501", "submitter": "Guang-Yuan Hao", "authors": "Guang-Yuan Hao, Hong-Xing Yu, Wei-Shi Zheng", "title": "DSRGAN: Explicitly Learning Disentangled Representation of Underlying\n  Structure and Rendering for Image Generation without Tuple Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on explicitly learning disentangled representation for natural image\ngeneration, where the underlying spatial structure and the rendering on the\nstructure can be independently controlled respectively, yet using no tuple\nsupervision. The setting is significant since tuple supervision is costly and\nsometimes even unavailable. However, the task is highly unconstrained and thus\nill-posed. To address this problem, we propose to introduce an auxiliary domain\nwhich shares a common underlying-structure space with the target domain, and we\nmake a partially shared latent space assumption. The key idea is to encourage\nthe partially shared latent variable to represent the similar underlying\nspatial structures in both domains, while the two domain-specific latent\nvariables will be unavoidably arranged to present renderings of two domains\nrespectively. This is achieved by designing two parallel generative networks\nwith a common Progressive Rendering Architecture (PRA), which constrains both\ngenerative networks' behaviors to model shared underlying structure and to\nmodel spatially dependent relation between rendering and underlying structure.\nThus, we propose DSRGAN (GANs for Disentangling Underlying Structure and\nRendering) to instantiate our method. We also propose a quantitative criterion\n(the Normalized Disentanglability) to quantify disentanglability. Comparison to\nthe state-of-the-art methods shows that DSRGAN can significantly outperform\nthem in disentanglability.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 08:07:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Hao", "Guang-Yuan", ""], ["Yu", "Hong-Xing", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "1909.13518", "submitter": "Gabriel Kalweit", "authors": "Gabriel Kalweit, Maria Huegle, Joschka Boedecker", "title": "Composite Q-learning: Multi-scale Q-function Decomposition and Separable\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, off-policy reinforcement learning methods have shown\npromising results in their application for robot control. Deep Q-learning,\nhowever, still suffers from poor data-efficiency and is susceptible to\nstochasticity in the environment or reward functions which is limiting with\nregard to real-world applications. We alleviate these problems by proposing two\nnovel off-policy Temporal-Difference formulations: (1) Truncated Q-functions\nwhich represent the return for the first n steps of a target-policy rollout\nw.r.t. the full action-value and (2) Shifted Q-functions, acting as the\nfarsighted return after this truncated rollout. This decomposition allows us to\noptimize both parts with their individual learning rates, achieving significant\nlearning speedup. We prove that the combination of these short- and long-term\npredictions is a representation of the full return, leading to the Composite\nQ-learning algorithm. We show the efficacy of Composite Q-learning in the\ntabular case and compare Deep Composite Q-learning with TD3 and TD3(Delta),\nwhich we introduce as an off-policy variant of TD(Delta). Moreover, we show\nthat Composite TD3 outperforms TD3 as well as state-of-the-art compositional\nQ-learning approaches significantly in terms of data-efficiency in multiple\nsimulated robot tasks and that Composite Q-learning is robust to stochastic\nenvironments and reward functions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 08:40:09 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 08:32:55 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kalweit", "Gabriel", ""], ["Huegle", "Maria", ""], ["Boedecker", "Joschka", ""]]}, {"id": "1909.13521", "submitter": "Katsuhiko Ishiguro", "authors": "Shion Honda, Hirotaka Akita, Katsuhiko Ishiguro, Toshiki Nakanishi,\n  Kenta Oono", "title": "Graph Residual Flow for Molecular Graph Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical generative models for molecular graphs attract attention from\nmany researchers from the fields of bio- and chemo-informatics. Among these\nmodels, invertible flow-based approaches are not fully explored yet. In this\npaper, we propose a powerful invertible flow for molecular graphs, called graph\nresidual flow (GRF). The GRF is based on residual flows, which are known for\nmore flexible and complex non-linear mappings than traditional coupling flows.\nWe theoretically derive non-trivial conditions such that GRF is invertible, and\npresent a way of keeping the entire flows invertible throughout the training\nand sampling. Experimental results show that a generative model based on the\nproposed GRF achieves comparable generation performance, with much smaller\nnumber of trainable parameters compared to the existing flow-based model.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 08:43:10 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Honda", "Shion", ""], ["Akita", "Hirotaka", ""], ["Ishiguro", "Katsuhiko", ""], ["Nakanishi", "Toshiki", ""], ["Oono", "Kenta", ""]]}, {"id": "1909.13550", "submitter": "Max-Heinrich Laves M. Sc.", "authors": "Max-Heinrich Laves, Sontje Ihler, Karl-Philipp Kortmann, Tobias\n  Ortmaier", "title": "Well-calibrated Model Uncertainty with Temperature Scaling for Dropout\n  Variational Inference", "comments": "Accepted at 4th workshop on Bayesian Deep Learning (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model uncertainty obtained by variational Bayesian inference with Monte Carlo\ndropout is prone to miscalibration. The uncertainty does not represent the\nmodel error well. In this paper, temperature scaling is extended to dropout\nvariational inference to calibrate model uncertainty. Expected uncertainty\ncalibration error (UCE) is presented as a metric to measure miscalibration of\nuncertainty. The effectiveness of this approach is evaluated on CIFAR-10/100\nfor recent CNN architectures. Experimental results show, that temperature\nscaling considerably reduces miscalibration by means of UCE and enables robust\nrejection of uncertain predictions. The proposed approach can easily be derived\nfrom frequentist temperature scaling and yields well-calibrated model\nuncertainty. It is simple to implement and does not affect the model accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 09:29:44 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:46:21 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 16:49:58 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Laves", "Max-Heinrich", ""], ["Ihler", "Sontje", ""], ["Kortmann", "Karl-Philipp", ""], ["Ortmaier", "Tobias", ""]]}, {"id": "1909.13561", "submitter": "Yizhe Wu", "authors": "Yizhe Wu, Sudhanshu Kasewa, Oliver Groth, Sasha Salter, Li Sun, Oiwi\n  Parker Jones, Ingmar Posner", "title": "Imagine That! Leveraging Emergent Affordances for 3D Tool Synthesis", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the richness of information captured by the latent\nspace of a vision-based generative model. The model combines unsupervised\ngenerative learning with a task-based performance predictor to learn and to\nexploit task-relevant object affordances given visual observations from a\nreaching task, involving a scenario and a stick-like tool. While the learned\nembedding of the generative model captures factors of variation in 3D tool\ngeometry (e.g. length, width, and shape), the performance predictor identifies\nsub-manifolds of the embedding that correlate with task success. Within a\nvariety of scenarios, we demonstrate that traversing the latent space via\nbackpropagation from the performance predictor allows us to imagine tools\nappropriate for the task at hand. Our results indicate that affordances-like\nthe utility for reaching-are encoded along smooth trajectories in latent space.\nAccessing these emergent affordances by considering only high-level performance\ncriteria (such as task success) enables an agent to manipulate tool geometries\nin a targeted and deliberate way.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 09:55:33 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 11:37:36 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 06:51:23 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 04:05:19 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Wu", "Yizhe", ""], ["Kasewa", "Sudhanshu", ""], ["Groth", "Oliver", ""], ["Salter", "Sasha", ""], ["Sun", "Li", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "1909.13563", "submitter": "Nikolaos Bakas", "authors": "Nikolaos P. Bakas, Andreas Langousis, Mihalis Nicolaou, Savvas A.\n  Chatzichristofis", "title": "A Gradient Free Neural Network Framework Based on Universal\n  Approximation Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a numerical scheme for computation of Artificial Neural Networks\n(ANN) weights, which stems from the Universal Approximation Theorem, avoiding\nlaborious iterations. The proposed algorithm adheres to the underlying theory,\nis highly fast, and results in remarkably low errors when applied for\nregression and classification of complex data-sets, such as the Griewank\nfunction of multiple variables $\\mathbf{x} \\in \\mathbb{R}^{100}$ with random\nnoise addition, and MNIST database for handwritten digits recognition, with\n$7\\times10^4$ images. The same mathematical formulation is found capable of\napproximating highly nonlinear functions in multiple dimensions, with low\nerrors (e.g. $10^{-10}$) for the test-set of the unknown functions, their\nhigher-order partial derivatives, as well as numerically solving Partial\nDifferential Equations. The method is based on the calculation of the weights\nof each neuron in small neighborhoods of the data, such that the corresponding\nlocal approximation matrix is invertible. Accordingly, optimization of\nhyperparameters is not necessary, as the number of neurons stems directly from\nthe dimensionality of the data, further improving the algorithmic speed. Under\nthis setting, overfitting is inherently avoided, and the results are\ninterpretable and reproducible. The complexity of the proposed algorithm is of\nclass P with\n$\\mathcal{O}(mn^2)+\\mathcal{O}(\\frac{m^3}{n^2})-\\mathcal{O}(\\log(n+1))$\ncomputing time, with respect to the observations $m$ and features $n$, in\ncontrast with the NP-Complete class of standard algorithms for ANN training.\nThe performance of the method is high, irrespective of the size of the dataset,\nand the test-set errors are similar or smaller than the training errors,\nindicating the generalization efficiency of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:04:15 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 09:54:05 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 11:29:07 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Bakas", "Nikolaos P.", ""], ["Langousis", "Andreas", ""], ["Nicolaou", "Mihalis", ""], ["Chatzichristofis", "Savvas A.", ""]]}, {"id": "1909.13576", "submitter": "Lukas Brinkmeyer", "authors": "Lukas Brinkmeyer, Rafael Rego Drumond, Randolf Scholz, Josif Grabocka,\n  Lars Schmidt-Thieme", "title": "Chameleon: Learning Model Initializations Across Tasks With Different\n  Schemas", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric models, and particularly neural networks, require weight\ninitialization as a starting point for gradient-based optimization. Recent work\nshows that a specific initial parameter set can be learned from a population of\nsupervised learning tasks. Using this initial parameter set enables a fast\nconvergence for unseen classes even when only a handful of instances is\navailable (model-agnostic meta-learning). Currently, methods for learning model\ninitializations are limited to a population of tasks sharing the same schema,\ni.e., the same number, order, type, and semantics of predictor and target\nvariables. In this paper, we address the problem of meta-learning parameter\ninitialization across tasks with different schemas, i.e., if the number of\npredictors varies across tasks, while they still share some variables. We\npropose Chameleon, a model that learns to align different predictor schemas to\na common representation. In experiments on 23 datasets of the OpenML-CC18\nbenchmark, we show that Chameleon can successfully learn parameter\ninitializations across tasks with different schemas, presenting, to the best of\nour knowledge, the first cross-dataset few-shot classification approach for\nunstructured data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:42:44 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 12:36:22 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 17:13:37 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 16:34:37 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Brinkmeyer", "Lukas", ""], ["Drumond", "Rafael Rego", ""], ["Scholz", "Randolf", ""], ["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1909.13581", "submitter": "Jie Bai", "authors": "Jie Bai, Linjing Li, Daniel Zeng", "title": "Spread-gram: A spreading-activation schema of network structural\n  learning", "comments": "21 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning has exploded recently. However, existing\nstudies usually reconstruct networks as sequences or matrices, which may cause\ninformation bias or sparsity problem during model training. Inspired by a\ncognitive model of human memory, we propose a network representation learning\nscheme. In this scheme, we learn node embeddings by adjusting the proximity of\nnodes traversing the spreading structure of the network. Our proposed method\nshows a significant improvement in multiple analysis tasks based on various\nreal-world networks, ranging from semantic networks to protein interaction\nnetworks, international trade networks, human behavior networks, etc. In\nparticular, our model can effectively discover the hierarchical structures in\nnetworks. The well-organized model training speeds up the convergence to only a\nsmall number of iterations, and the training time is linear with respect to the\nedge numbers.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:55:00 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Bai", "Jie", ""], ["Li", "Linjing", ""], ["Zeng", "Daniel", ""]]}, {"id": "1909.13582", "submitter": "Maria H\\\"ugle", "authors": "Maria Huegle, Gabriel Kalweit, Moritz Werling, Joschka Boedecker", "title": "Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning\n  in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The common pipeline in autonomous driving systems is highly modular and\nincludes a perception component which extracts lists of surrounding objects and\npasses these lists to a high-level decision component. In this case, leveraging\nthe benefits of deep reinforcement learning for high-level decision making\nrequires special architectures to deal with multiple variable-length sequences\nof different object types, such as vehicles, lanes or traffic signs. At the\nsame time, the architecture has to be able to cover interactions between\ntraffic participants in order to find the optimal action to be taken. In this\nwork, we propose the novel Deep Scenes architecture, that can learn complex\ninteraction-aware scene representations based on extensions of either 1) Deep\nSets or 2) Graph Convolutional Networks. We present the Graph-Q and DeepScene-Q\noff-policy reinforcement learning algorithms, both outperforming\nstate-of-the-art methods in evaluations with the publicly available traffic\nsimulator SUMO.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:59:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Huegle", "Maria", ""], ["Kalweit", "Gabriel", ""], ["Werling", "Moritz", ""], ["Boedecker", "Joschka", ""]]}, {"id": "1909.13584", "submitter": "Laura Rieger", "authors": "Laura Rieger, Chandan Singh, W. James Murdoch, Bin Yu", "title": "Interpretations are useful: penalizing explanations to align neural\n  networks with prior knowledge", "comments": "18 pages; published in ICML2020; Erratum: numbers in table 1 were too\n  high (now corrected) with the trend remaining the same", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an explanation of a deep learning model to be effective, it must provide\nboth insight into a model and suggest a corresponding action in order to\nachieve some objective. Too often, the litany of proposed explainable deep\nlearning methods stop at the first step, providing practitioners with insight\ninto a model, but no way to act on it. In this paper, we propose contextual\ndecomposition explanation penalization (CDEP), a method which enables\npractitioners to leverage existing explanation methods in order to increase the\npredictive accuracy of deep learning models. In particular, when shown that a\nmodel has incorrectly assigned importance to some features, CDEP enables\npractitioners to correct these errors by directly regularizing the provided\nexplanations. Using explanations provided by contextual decomposition (CD)\n(Murdoch et al., 2018), we demonstrate the ability of our method to increase\nperformance on an array of toy and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 11:02:01 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 12:05:59 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 19:24:50 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 12:43:21 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Rieger", "Laura", ""], ["Singh", "Chandan", ""], ["Murdoch", "W. James", ""], ["Yu", "Bin", ""]]}, {"id": "1909.13595", "submitter": "David Salinas", "authors": "David Salinas, Huibin Shen, Valerio Perrone", "title": "A Quantile-based Approach for Hyperparameter Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular methodology to tune the\nhyperparameters of expensive black-box functions. Traditionally, BO focuses on\na single task at a time and is not designed to leverage information from\nrelated functions, such as tuning performance objectives of the same algorithm\nacross multiple datasets. In this work, we introduce a novel approach to\nachieve transfer learning across different \\emph{datasets} as well as different\n\\emph{objectives}. The main idea is to regress the mapping from hyperparameter\nto objective quantiles with a semi-parametric Gaussian Copula distribution,\nwhich provides robustness against different scales or outliers that can occur\nin different tasks. We introduce two methods to leverage this mapping: a\nThompson sampling strategy as well as a Gaussian Copula process using such\nquantile estimate as a prior. We show that these strategies can combine the\nestimation of multiple objectives such as latency and accuracy, steering the\nhyperparameters optimization toward faster predictions for the same level of\naccuracy. Extensive experiments demonstrate significant improvements over\nstate-of-the-art methods for both hyperparameter optimization and neural\narchitecture search.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 11:28:09 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 11:43:02 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Salinas", "David", ""], ["Shen", "Huibin", ""], ["Perrone", "Valerio", ""]]}, {"id": "1909.13600", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng", "title": "Towards Robust Direct Perception Networks for Automated Driving", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of engineering robust direct perception neural\nnetworks with output being regression. Such networks take high dimensional\ninput image data, and they produce affordances such as the curvature of the\nupcoming road segment or the distance to the front vehicle. Our proposal starts\nby allowing a neural network prediction to deviate from the label with\ntolerance $\\Delta$. The source of tolerance can be either contractual or from\nlimiting factors where two entities may label the same data with slightly\ndifferent numerical values. The tolerance motivates the use of a non-standard\nloss function where the loss is set to $0$ so long as the prediction-to-label\ndistance is less than $\\Delta$. We further extend the loss function and define\na new provably robust criterion that is parametric to the allowed output\ntolerance $\\Delta$, the layer index $\\tilde{l}$ where perturbation is\nconsidered, and the maximum perturbation amount $\\kappa$. During training, the\nrobust loss is computed by first propagating symbolic errors from the\n$\\tilde{l}$-th layer (with quantity bounded by $\\kappa$) to the output layer,\nfollowed by computing the overflow between the error bounds and the allowed\ntolerance. The overall concept is experimented in engineering a direct\nperception neural network for understanding the central position of the\nego-lane in pixel coordinates.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 11:32:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Cheng", "Chih-Hong", ""]]}, {"id": "1909.13607", "submitter": "Haotian Fu", "authors": "Haotian Fu, Hongyao Tang, Jianye Hao, Wulong Liu, Chen Chen", "title": "MGHRL: Meta Goal-generation for Hierarchical Reinforcement Learning", "comments": "Accepted to the ICLR 2020 workshop: Beyond tabula rasa in RL\n  (BeTR-RL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most meta reinforcement learning (meta-RL) methods learn to adapt to new\ntasks by directly optimizing the parameters of policies over primitive action\nspace. Such algorithms work well in tasks with relatively slight difference.\nHowever, when the task distribution becomes wider, it would be quite\ninefficient to directly learn such a meta-policy. In this paper, we propose a\nnew meta-RL algorithm called Meta Goal-generation for Hierarchical RL (MGHRL).\nInstead of directly generating policies over primitive action space for new\ntasks, MGHRL learns to generate high-level meta strategies over subgoals given\npast experience and leaves the rest of how to achieve subgoals as independent\nRL subtasks. Our empirical results on several challenging simulated robotics\nenvironments show that our method enables more efficient and generalized\nmeta-learning from past experience.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 11:55:17 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 03:39:47 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 05:26:55 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 08:36:01 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Fu", "Haotian", ""], ["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Liu", "Wulong", ""], ["Chen", "Chen", ""]]}, {"id": "1909.13611", "submitter": "An-Phi Nguyen", "authors": "An-phi Nguyen, Mar\\'ia Rodr\\'iguez Mart\\'inez", "title": "MonoNet: Towards Interpretable Models by Learning Monotonic Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to interpret, or explain, the predictions made by a machine\nlearning model is of fundamental importance. This is especially true when there\nis interest in deploying data-driven models to make high-stakes decisions, e.g.\nin healthcare. While recent years have seen an increasing interest in\ninterpretable machine learning research, this field is currently lacking an\nagreed-upon definition of interpretability, and some researchers have called\nfor a more active conversation towards a rigorous approach to interpretability.\nJoining this conversation, we claim in this paper that the difficulty of\ninterpreting a complex model stems from the existing interactions among\nfeatures. We argue that by enforcing monotonicity between features and outputs,\nwe are able to reason about the effect of a single feature on an output\nindependently from other features, and consequently better understand the\nmodel. We show how to structurally introduce this constraint in deep learning\nmodels by adding new simple layers. We validate our model on benchmark\ndatasets, and compare our results with previously proposed interpretable\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 12:02:16 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Nguyen", "An-phi", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""]]}, {"id": "1909.13671", "submitter": "Lei Li", "authors": "Lei Li", "title": "On the convergence of gradient descent for two layer neural networks", "comments": "There was some issue in the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that gradient descent can yield the zero training loss in\nthe over-parametrized regime (the width of the neural networks is much larger\nthan the number of data points). In this work, combining the ideas of some\nexisting works, we investigate the gradient descent method for training\ntwo-layer neural networks for approximating some target continuous functions.\nBy making use the generic chaining technique from probability theory, we show\nthat gradient descent can yield an exponential convergence rate, while the\nwidth of the neural networks needed is independent of the size of the training\ndata. The result also implies some strong approximation ability of the\ntwo-layer neural networks without curse of dimensionality.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:14:44 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 01:53:57 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 09:09:25 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Lei", ""]]}, {"id": "1909.13676", "submitter": "Alexander Robey", "authors": "Alexander Robey, Arman Adibi, Brent Schlotfeldt, George J. Pappas,\n  Hamed Hassani", "title": "Optimal Algorithms for Submodular Maximization with Distributed\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of discrete optimization problems that aim to maximize a\nsubmodular objective function subject to a distributed partition matroid\nconstraint. More precisely, we consider a networked scenario in which multiple\nagents choose actions from local strategy sets with the goal of maximizing a\nsubmodular objective function defined over the set of all possible actions.\nGiven this distributed setting, we develop Constraint-Distributed Continuous\nGreedy (CDCG), a message passing algorithm that converges to the tight\n$(1-1/e)$ approximation factor of the optimum global solution using only local\ncomputation and communication. It is known that a sequential greedy algorithm\ncan only achieve a $1/2$ multiplicative approximation of the optimal solution\nfor this class of problems in the distributed setting. Our framework relies on\nlifting the discrete problem to a continuous domain and developing a consensus\nalgorithm that achieves the tight $(1-1/e)$ approximation guarantee of the\nglobal discrete solution once a proper rounding scheme is applied. We also\noffer empirical results from a multi-agent area coverage problem to show that\nthe proposed method significantly outperforms the state-of-the-art sequential\ngreedy method.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:26:05 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 00:21:21 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 01:40:48 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Robey", "Alexander", ""], ["Adibi", "Arman", ""], ["Schlotfeldt", "Brent", ""], ["Pappas", "George J.", ""], ["Hassani", "Hamed", ""]]}, {"id": "1909.13690", "submitter": "Suryabhan Singh Hada", "authors": "Suryabhan Singh Hada and Miguel \\'A. Carreira-Perpi\\~n\\'an", "title": "Style Transfer by Rigid Alignment in Neural Net Feature Space", "comments": "Accepted to WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arbitrary style transfer is an important problem in computer vision that aims\nto transfer style patterns from an arbitrary style image to a given content\nimage. However, current methods either rely on slow iterative optimization or\nfast pre-determined feature transformation, but at the cost of compromised\nvisual quality of the styled image; especially, distorted content structure. In\nthis work, we present an effective and efficient approach for arbitrary style\ntransfer that seamlessly transfers style patterns as well as keep content\nstructure intact in the styled image. We achieve this by aligning style\nfeatures to content features using rigid alignment; thus modifying style\nfeatures, unlike the existing methods that do the opposite. We demonstrate the\neffectiveness of the proposed approach by generating high-quality stylized\nimages and compare the results with the current state-of-the-art techniques for\narbitrary style transfer.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:54:00 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 08:03:17 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Hada", "Suryabhan Singh", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""]]}, {"id": "1909.13692", "submitter": "Berkin Bilgic", "authors": "Daniel Polak, Itthi Chatnuntawech, Jaeyeon Yoon, Siddharth Srinivasan\n  Iyer, Jongho Lee, Peter Bachert, Elfar Adalsteinsson, Kawin Setsompop, Berkin\n  Bilgic", "title": "Nonlinear Dipole Inversion (NDI) enables Quantitative Susceptibility\n  Mapping (QSM) without parameter tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Nonlinear Dipole Inversion (NDI) for high-quality Quantitative\nSusceptibility Mapping (QSM) without regularization tuning, while matching the\nimage quality of state-of-the-art reconstruction techniques. In addition to\navoiding over-smoothing that these techniques often suffer from, we also\nobviate the need for parameter selection. NDI is flexible enough to allow for\nreconstruction from an arbitrary number of head orientations, and outperforms\nCOSMOS even when using as few as 1-direction data. This is made possible by a\nnonlinear forward-model that uses the magnitude as an effective prior, for\nwhich we derived a simple gradient descent update rule. We synergistically\ncombine this physics-model with a Variational Network (VN) to leverage the\npower of deep learning in the VaNDI algorithm. This technique adopts the simple\ngradient descent rule from NDI and learns the network parameters during\ntraining, hence requires no additional parameter tuning. Further, we evaluate\nNDI at 7T using highly accelerated Wave-CAIPI acquisitions at 0.5 mm isotropic\nresolution and demonstrate high-quality QSM from as few as 2-direction data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:37:24 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Polak", "Daniel", ""], ["Chatnuntawech", "Itthi", ""], ["Yoon", "Jaeyeon", ""], ["Iyer", "Siddharth Srinivasan", ""], ["Lee", "Jongho", ""], ["Bachert", "Peter", ""], ["Adalsteinsson", "Elfar", ""], ["Setsompop", "Kawin", ""], ["Bilgic", "Berkin", ""]]}, {"id": "1909.13698", "submitter": "Yuyang Gao", "authors": "Yuyang Gao, Giorgio A. Ascoli, Liang Zhao", "title": "BEAN: Interpretable Representation Learning with Biologically-Enhanced\n  Artificial Neuronal Assembly Regularization", "comments": "Accepted as an original research paper at Frontiers in Neurorobotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known for extracting useful information from\nlarge amounts of data. However, the representations learned in DNNs are\ntypically hard to interpret, especially in dense layers. One crucial issue of\nthe classical DNN model such as multilayer perceptron (MLP) is that neurons in\nthe same layer of DNNs are conditionally independent of each other, which makes\nco-training and emergence of higher modularity difficult. In contrast to DNNs,\nbiological neurons in mammalian brains display substantial dependency patterns.\nSpecifically, biological neural networks encode representations by so-called\nneuronal assemblies: groups of neurons interconnected by strong synaptic\ninteractions and sharing joint semantic content. The resulting population\ncoding is essential for human cognitive and mnemonic processes. Here, we\npropose a novel Biologically Enhanced Artificial Neuronal assembly (BEAN)\nregularization to model neuronal correlations and dependencies, inspired by\ncell assembly theory from neuroscience. Experimental results show that BEAN\nenables the formation of interpretable neuronal functional clusters and\nconsequently promotes a sparse, memory/computation-efficient network without\nloss of model performance. Moreover, our few-shot learning experiments\ndemonstrate that BEAN could also enhance the generalizability of the model when\ntraining samples are extremely limited.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 14:54:30 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 14:18:45 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Gao", "Yuyang", ""], ["Ascoli", "Giorgio A.", ""], ["Zhao", "Liang", ""]]}, {"id": "1909.13718", "submitter": "Navid Zobeiry", "authors": "Navid Zobeiry, Keith D. Humfeld", "title": "An Iterative Scientific Machine Learning Approach for Discovery of\n  Theories Underlying Physical Phenomena", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Form a pure mathematical point of view, common functional forms representing\ndifferent physical phenomena can be defined. For example, rates of chemical\nreactions, diffusion and heat transfer are all governed by exponential-type\nexpressions. If machine learning is used for physical problems, inferred from\ndomain knowledge, original features can be transformed in such a way that the\nend expressions are highly aligned and correlated with the underlying physics.\nThis should significantly reduce the training effort in terms of iterations,\narchitecture and the number of required data points. We extend this by\napproaching a problem from an agnostic position and propose a systematic and\niterative methodology to discover theories underlying physical phenomena. At\nfirst, commonly observed functional forms of theoretical expressions are used\nto transform original features before conducting correlation analysis to\noutput. Using random combinations of highly correlated expressions, training of\nNeural Networks (NN) are performed. By comparing the rates of convergence or\nmean error in training, expressions describing the underlying physical problems\ncan be discovered, leading to extracting explicit analytic equations. This\napproach was used in three blind demonstrations for different physical\nphenomena.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 05:06:34 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zobeiry", "Navid", ""], ["Humfeld", "Keith D.", ""]]}, {"id": "1909.13721", "submitter": "Andrey Sapegin", "authors": "Andrey Sapegin and Christoph Meinel", "title": "K-Metamodes: frequency- and ensemble-based distributed k-modes\n  clustering for security analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays processing of Big Security Data, such as log messages, is commonly\nused for intrusion detection purposed. Its heterogeneous nature, as well as\ncombination of numerical and categorical attributes does not allow to apply the\nexisting data mining methods directly on the data without feature\npreprocessing. Therefore, a rather computationally expensive conversion of\ncategorical attributes into vector space should be utilised for analysis of\nsuch data. However, a well-known k-modes algorithm allows to cluster the\ncategorical data directly and avoid conversion into the vector space. The\nexisting implementations of k-modes for Big Data processing are ensemble-based\nand utilise two-step clustering, where data subsets are first clustered\nindependently, whereas the resulting cluster modes are clustered again in order\nto calculate metamodes valid for all data subsets. In this paper, the novel\nfrequency-based distance function is proposed for the second step of\nensemble-based k-modes clustering. Besides this, the existing feature\ndiscretisation method from the previous work is utilised in order to adapt\nk-modes for processing of mixed data sets. The resulting k-metamodes algorithm\nwas tested on two public security data sets and reached higher effectiveness in\ncomparison with the previous work.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:05:50 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sapegin", "Andrey", ""], ["Meinel", "Christoph", ""]]}, {"id": "1909.13739", "submitter": "Danilo Jimenez Rezende", "authors": "Danilo Jimenez Rezende and S\\'ebastien Racani\\`ere and Irina Higgins\n  and Peter Toth", "title": "Equivariant Hamiltonian Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces equivariant hamiltonian flows, a method for learning\nexpressive densities that are invariant with respect to a known Lie-algebra of\nlocal symmetry transformations while providing an equivariant representation of\nthe data. We provide proof of principle demonstrations of how such flows can be\nlearnt, as well as how the addition of symmetry invariance constraints can\nimprove data efficiency and generalisation. Finally, we make connections to\ndisentangled representation learning and show how this work relates to a\nrecently proposed definition.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:30:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Rezende", "Danilo Jimenez", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Higgins", "Irina", ""], ["Toth", "Peter", ""]]}, {"id": "1909.13743", "submitter": "Roman F\\\"oll", "authors": "Roman F\\\"oll, Bernard Haasdonk, Markus Hanselmann, Holger Ulmer", "title": "Deep recurrent Gaussian process with variational Sparse Spectrum\n  approximation", "comments": "22 pages, 4 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:1711.00799", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling sequential data has become more and more important in practice. Some\napplications are autonomous driving, virtual sensors and weather forecasting.\nTo model such systems, so called recurrent models are frequently used. In this\npaper we introduce several new Deep recurrent Gaussian process (DRGP) models\nbased on the Sparse Spectrum Gaussian process (SSGP) and the improved version,\ncalled variational Sparse Spectrum Gaussian process (VSSGP). We follow the\nrecurrent structure given by an existing DRGP based on a specific variational\nsparse Nystr\\\"om approximation, the recurrent Gaussian process (RGP). Similar\nto previous work, we also variationally integrate out the input-space and hence\ncan propagate uncertainty through the Gaussian process (GP) layers. Our\napproach can deal with a larger class of covariance functions than the RGP,\nbecause its spectral nature allows variational integration in all stationary\ncases. Furthermore, we combine the (variational) Sparse Spectrum ((V)SS)\napproximations with a well known inducing-input regularization framework. We\nimprove over current state of the art methods in prediction accuracy for\nexperimental data-sets used for their evaluation and introduce a new data-set\nfor engine control, named Emission.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 09:44:10 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["F\u00f6ll", "Roman", ""], ["Haasdonk", "Bernard", ""], ["Hanselmann", "Markus", ""], ["Ulmer", "Holger", ""]]}, {"id": "1909.13788", "submitter": "Junxian He", "authors": "Junxian He, Jiatao Gu, Jiajun Shen, Marc'Aurelio Ranzato", "title": "Revisiting Self-Training for Neural Sequence Generation", "comments": "ICLR 2020. The first two authors contributed equally. Updated to fix\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-training is one of the earliest and simplest semi-supervised methods.\nThe key idea is to augment the original labeled dataset with unlabeled data\npaired with the model's prediction (i.e. the pseudo-parallel data). While\nself-training has been extensively studied on classification problems, in\ncomplex sequence generation tasks (e.g. machine translation) it is still\nunclear how self-training works due to the compositionality of the target\nspace. In this work, we first empirically show that self-training is able to\ndecently improve the supervised baseline on neural sequence generation tasks.\nThrough careful examination of the performance gains, we find that the\nperturbation on the hidden states (i.e. dropout) is critical for self-training\nto benefit from the pseudo-parallel data, which acts as a regularizer and\nforces the model to yield close predictions for similar unlabeled inputs. Such\neffect helps the model correct some incorrect predictions on unlabeled data. To\nfurther encourage this mechanism, we propose to inject noise to the input\nspace, resulting in a \"noisy\" version of self-training. Empirical study on\nstandard machine translation and text summarization benchmarks shows that noisy\nself-training is able to effectively utilize unlabeled data and improve the\nperformance of the supervised baseline by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 15:30:00 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 08:35:41 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 22:49:31 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["He", "Junxian", ""], ["Gu", "Jiatao", ""], ["Shen", "Jiajun", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1909.13789", "submitter": "Irina Higgins", "authors": "Peter Toth and Danilo Jimenez Rezende and Andrew Jaegle and\n  S\\'ebastien Racani\\`ere and Aleksandar Botev and Irina Higgins", "title": "Hamiltonian Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hamiltonian formalism plays a central role in classical and quantum\nphysics. Hamiltonians are the main tool for modelling the continuous time\nevolution of systems with conserved quantities, and they come equipped with\nmany useful properties, like time reversibility and smooth interpolation in\ntime. These properties are important for many machine learning problems - from\nsequence prediction to reinforcement learning and density modelling - but are\nnot typically provided out of the box by standard tools such as recurrent\nneural networks. In this paper, we introduce the Hamiltonian Generative Network\n(HGN), the first approach capable of consistently learning Hamiltonian dynamics\nfrom high-dimensional observations (such as images) without restrictive domain\nassumptions. Once trained, we can use HGN to sample new trajectories, perform\nrollouts both forward and backward in time and even speed up or slow down the\nlearned dynamics. We demonstrate how a simple modification of the network\narchitecture turns HGN into a powerful normalising flow model, called Neural\nHamiltonian Flow (NHF), that uses Hamiltonian dynamics to model expressive\ndensities. We hope that our work serves as a first practical demonstration of\nthe value that the Hamiltonian formalism can bring to deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 15:32:52 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 12:00:47 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Toth", "Peter", ""], ["Rezende", "Danilo Jimenez", ""], ["Jaegle", "Andrew", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Botev", "Aleksandar", ""], ["Higgins", "Irina", ""]]}, {"id": "1909.13806", "submitter": "Sijia Liu", "authors": "Sijia Liu, Songtao Lu, Xiangyi Chen, Yao Feng, Kaidi Xu, Abdullah\n  Al-Dujaili, Minyi Hong, Una-May O'Reilly", "title": "Min-Max Optimization without Gradients: Convergence and Applications to\n  Adversarial ML", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of constrained robust (min-max)\noptimization ina black-box setting, where the desired optimizer cannot access\nthe gradients of the objective function but may query its values. We present a\nprincipled optimization framework, integrating a zeroth-order (ZO) gradient\nestimator with an alternating projected stochastic gradient descent-ascent\nmethod, where the former only requires a small number of function queries and\nthe later needs just one-step descent/ascent update. We show that the proposed\nframework, referred to as ZO-Min-Max, has a sub-linear convergence rate under\nmild conditions and scales gracefully with problem size. From an application\nside, we explore a promising connection between black-box min-max optimization\nand black-box evasion and poisoning attacks in adversarial machine learning\n(ML). Our empirical evaluations on these use cases demonstrate the\neffectiveness of our approach and its scalability to dimensions that prohibit\nusing recent black-box solvers.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 16:02:49 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 01:49:54 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 01:41:35 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Liu", "Sijia", ""], ["Lu", "Songtao", ""], ["Chen", "Xiangyi", ""], ["Feng", "Yao", ""], ["Xu", "Kaidi", ""], ["Al-Dujaili", "Abdullah", ""], ["Hong", "Minyi", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1909.13833", "submitter": "Rob Cornish", "authors": "Rob Cornish, Anthony L. Caterini, George Deligiannidis, Arnaud Doucet", "title": "Relaxing Bijectivity Constraints with Continuously Indexed Normalising\n  Flows", "comments": "Minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that normalising flows become pathological when used to model targets\nwhose supports have complicated topologies. In this scenario, we prove that a\nflow must become arbitrarily numerically noninvertible in order to approximate\nthe target closely. This result has implications for all flow-based models, and\nespecially Residual Flows (ResFlows), which explicitly control the Lipschitz\nconstant of the bijection used. To address this, we propose Continuously\nIndexed Flows (CIFs), which replace the single bijection used by normalising\nflows with a continuously indexed family of bijections, and which can\nintuitively \"clean up\" mass that would otherwise be misplaced by a single\nbijection. We show theoretically that CIFs are not subject to the same\ntopological limitations as normalising flows, and obtain better empirical\nperformance on a variety of models and benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 16:51:48 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 18:25:10 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 15:20:23 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 16:54:30 GMT"}, {"version": "v5", "created": "Fri, 23 Apr 2021 17:48:10 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Cornish", "Rob", ""], ["Caterini", "Anthony L.", ""], ["Deligiannidis", "George", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1909.13839", "submitter": "Sami Alabed", "authors": "Sami Alabed", "title": "RLCache: Automated Cache Management Using Reinforcement Learning", "comments": "MPhil Thesis, 76 pages, Reinforcement Learning, Multi-agent,\n  multi-task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the use of reinforcement learning to guide a general\npurpose cache manager decisions. Cache managers directly impact the overall\nperformance of computer systems. They govern decisions about which objects\nshould be cached, the duration they should be cached for, and decides on which\nobjects to evict from the cache if it is full. These three decisions impact\nboth the cache hit rate and size of the storage that is needed to achieve that\ncache hit rate. An optimal cache manager will avoid unnecessary operations,\nmaximise the cache hit rate which results in fewer round trips to a slower\nbackend storage system, and minimise the size of storage needed to achieve a\nhigh hit-rate.\n  This project investigates using reinforcement learning in cache management by\ndesigning three separate agents for each of the cache manager tasks.\nFurthermore, the project investigates two advanced reinforcement learning\narchitectures for multi-decision problems: a single multi-task agent and a\nmulti-agent. We also introduce a framework to simplify the modelling of\ncomputer systems problems as a reinforcement learning task. The framework\nabstracts delayed experiences observations and reward assignment in computer\nsystems while providing a flexible way to scale to multiple agents.\n  Simulation results based on an established database benchmark system show\nthat reinforcement learning agents can achieve a higher cache hit rate over\nheuristic driven algorithms while minimising the needed space. They are also\nable to adapt to a changing workload and dynamically adjust their caching\nstrategy accordingly. The proposed cache manager model is generic and\napplicable to other types of caches, such as file system caches. This project\nis the first, to our knowledge, to model cache manager decisions as a\nmulti-task control problem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:03:51 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Alabed", "Sami", ""]]}, {"id": "1909.13844", "submitter": "Thomas Elsken", "authors": "Christoph Schorn, Thomas Elsken, Sebastian Vogel, Armin Runge, Andre\n  Guntoro, Gerd Ascheid", "title": "Automated design of error-resilient and hardware-efficient deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying deep neural networks (DNNs) in mobile and safety-critical systems,\nsuch as autonomous vehicles, demands a reliable and efficient execution on\nhardware. Optimized dedicated hardware accelerators are being developed to\nachieve this. However, the design of efficient and reliable hardware has become\nincreasingly difficult, due to the increased complexity of modern integrated\ncircuit technology and its sensitivity against hardware faults, such as random\nbit-flips. It is thus desirable to exploit optimization potential for error\nresilience and efficiency also at the algorithmic side, e.g., by optimizing the\narchitecture of the DNN. Since there are numerous design choices for the\narchitecture of DNNs, with partially opposing effects on the preferred\ncharacteristics (such as small error rates at low latency), multi-objective\noptimization strategies are necessary. In this paper, we develop an\nevolutionary optimization technique for the automated design of\nhardware-optimized DNN architectures. For this purpose, we derive a set of\neasily computable objective functions, which enable the fast evaluation of DNN\narchitectures with respect to their hardware efficiency and error resilience\nsolely based on the network topology. We observe a strong correlation between\npredicted error resilience and actual measurements obtained from fault\ninjection simulations. Furthermore, we analyze two different quantization\nschemes for efficient DNN computation and find significant differences\nregarding their effect on error resilience.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:08:22 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Schorn", "Christoph", ""], ["Elsken", "Thomas", ""], ["Vogel", "Sebastian", ""], ["Runge", "Armin", ""], ["Guntoro", "Andre", ""], ["Ascheid", "Gerd", ""]]}, {"id": "1909.13846", "submitter": "Maximilian Baader", "authors": "Maximilian Baader, Matthew Mirman, Martin Vechev", "title": "Universal Approximation with Certified Networks", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks to be certifiably robust is critical to ensure their\nsafety against adversarial attacks. However, it is currently very difficult to\ntrain a neural network that is both accurate and certifiably robust. In this\nwork we take a step towards addressing this challenge. We prove that for every\ncontinuous function $f$, there exists a network $n$ such that: (i) $n$\napproximates $f$ arbitrarily close, and (ii) simple interval bound propagation\nof a region $B$ through $n$ yields a result that is arbitrarily close to the\noptimal output of $f$ on $B$. Our result can be seen as a Universal\nApproximation Theorem for interval-certified ReLU networks. To the best of our\nknowledge, this is the first work to prove the existence of accurate,\ninterval-certified networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:11:23 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 19:14:37 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Baader", "Maximilian", ""], ["Mirman", "Matthew", ""], ["Vechev", "Martin", ""]]}, {"id": "1909.13857", "submitter": "Anit Kumar Sahu", "authors": "Satya Narayan Shukla, Anit Kumar Sahu, Devin Willmott, J. Zico Kolter", "title": "Black-box Adversarial Attacks with Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of black-box adversarial attacks, where the aim is to\ngenerate adversarial examples using information limited to loss function\nevaluations of input-output pairs. We use Bayesian optimization~(BO) to\nspecifically cater to scenarios involving low query budgets to develop query\nefficient adversarial attacks. We alleviate the issues surrounding BO in\nregards to optimizing high dimensional deep learning models by effective\ndimension upsampling techniques. Our proposed approach achieves performance\ncomparable to the state of the art black-box adversarial attacks albeit with a\nmuch lower average query count. In particular, in low query budget regimes, our\nproposed method reduces the query count up to $80\\%$ with respect to the state\nof the art methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:35:02 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Sahu", "Anit Kumar", ""], ["Willmott", "Devin", ""], ["Kolter", "J. Zico", ""]]}]