[{"id": "2102.00050", "submitter": "Yury Polyanskiy", "authors": "Meir Feder and Yury Polyanskiy", "title": "Sequential prediction under log-loss and misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the question of sequential prediction under the log-loss in terms\nof cumulative regret. Namely, given a hypothesis class of distributions,\nlearner sequentially predicts the (distribution of the) next letter in sequence\nand its performance is compared to the baseline of the best constant predictor\nfrom the hypothesis class. The well-specified case corresponds to an additional\nassumption that the data-generating distribution belongs to the hypothesis\nclass as well. Here we present results in the more general misspecified case.\nDue to special properties of the log-loss, the same problem arises in the\ncontext of competitive-optimality in density estimation, and model selection.\nFor the $d$-dimensional Gaussian location hypothesis class, we show that\ncumulative regrets in the well-specified and misspecified cases asymptotically\ncoincide. In other words, we provide an $o(1)$ characterization of the\ndistribution-free (or PAC) regret in this case -- the first such result as far\nas we know. We recall that the worst-case (or individual-sequence) regret in\nthis case is larger by an additive constant ${d\\over 2} + o(1)$. Surprisingly,\nneither the traditional Bayesian estimators, nor the Shtarkov's normalized\nmaximum likelihood achieve the PAC regret and our estimator requires special\n\"robustification\" against heavy-tailed data. In addition, we show two general\nresults for misspecified regret: the existence and uniqueness of the optimal\nestimator, and the bound sandwiching the misspecified regret between\nwell-specified regrets with (asymptotically) close hypotheses classes.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 20:28:23 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 14:34:52 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Feder", "Meir", ""], ["Polyanskiy", "Yury", ""]]}, {"id": "2102.00058", "submitter": "Jae-Kwang Kim", "authors": "Hengfang Wang, Jae-Kwang Kim", "title": "Statistical Inference after Kernel Ridge Regression Imputation under\n  item nonresponse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Imputation is a popular technique for handling missing data. We consider a\nnonparametric approach to imputation using the kernel ridge regression\ntechnique and propose consistent variance estimation. The proposed variance\nestimator is based on a linearization approach which employs the entropy method\nto estimate the density ratio. The root-n consistency of the imputation\nestimator is established when a Sobolev space is utilized in the kernel ridge\nregression imputation, which enables us to develop the proposed variance\nestimator. Synthetic data experiments are presented to confirm our theory.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 20:46:33 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Wang", "Hengfang", ""], ["Kim", "Jae-Kwang", ""]]}, {"id": "2102.00082", "submitter": "Sophie H. Yu", "authors": "Yihong Wu and Jiaming Xu and Sophie H. Yu", "title": "Settling the Sharp Reconstruction Thresholds of Random Graph Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies the problem of recovering the hidden vertex correspondence\nbetween two edge-correlated random graphs. We focus on the Gaussian model where\nthe two graphs are complete graphs with correlated Gaussian weights and the\nErd\\H{o}s-R\\'enyi model where the two graphs are subsampled from a common\nparent Erd\\H{o}s-R\\'enyi graph $\\mathcal{G}(n,p)$. For dense graphs with\n$p=n^{-o(1)}$, we prove that there exists a sharp threshold, above which one\ncan correctly match all but a vanishing fraction of vertices and below which\ncorrectly matching any positive fraction is impossible, a phenomenon known as\nthe \"all-or-nothing\" phase transition. Even more strikingly, in the Gaussian\nsetting, above the threshold all vertices can be exactly matched with high\nprobability. In contrast, for sparse Erd\\H{o}s-R\\'enyi graphs with\n$p=n^{-\\Theta(1)}$, we show that the all-or-nothing phenomenon no longer holds\nand we determine the thresholds up to a constant factor. Along the way, we also\nderive the sharp threshold for exact recovery, sharpening the existing results\nin Erd\\H{o}s-R\\'enyi graphs.\n  The proof of the negative results builds upon a tight characterization of the\nmutual information based on the truncated second-moment computation and an\n\"area theorem\" that relates the mutual information to the integral of the\nreconstruction error. The positive results follows from a tight analysis of the\nmaximum likelihood estimator that takes into account the cycle structure of the\ninduced permutation on the edges.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 21:49:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Wu", "Yihong", ""], ["Xu", "Jiaming", ""], ["Yu", "Sophie H.", ""]]}, {"id": "2102.00102", "submitter": "Ivana Malenica", "authors": "Ivana Malenica, Aurelien Bibaut and Mark J. van der Laan", "title": "Adaptive Sequential Design for a Single Time-Series", "comments": "arXiv admin note: text overlap with arXiv:1809.00734", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The current work is motivated by the need for robust statistical methods for\nprecision medicine; as such, we address the need for statistical methods that\nprovide actionable inference for a single unit at any point in time. We aim to\nlearn an optimal, unknown choice of the controlled components of the design in\norder to optimize the expected outcome; with that, we adapt the randomization\nmechanism for future time-point experiments based on the data collected on the\nindividual over time. Our results demonstrate that one can learn the optimal\nrule based on a single sample, and thereby adjust the design at any point t\nwith valid inference for the mean target parameter. This work provides several\ncontributions to the field of statistical precision medicine. First, we define\na general class of averages of conditional causal parameters defined by the\ncurrent context for the single unit time-series data. We define a nonparametric\nmodel for the probability distribution of the time-series under few\nassumptions, and aim to fully utilize the sequential randomization in the\nestimation procedure via the double robust structure of the efficient influence\ncurve of the proposed target parameter. We present multiple\nexploration-exploitation strategies for assigning treatment, and methods for\nestimating the optimal rule. Lastly, we present the study of the data-adaptive\ninference on the mean under the optimal treatment rule, where the target\nparameter adapts over time in response to the observed context of the\nindividual. Our target parameter is pathwise differentiable with an efficient\ninfluence function that is doubly robust - which makes it easier to estimate\nthan previously proposed variations. We characterize the limit distribution of\nour estimator under a Donsker condition expressed in terms of a notion of\nbracketing entropy adapted to martingale settings.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 22:51:45 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 15:16:45 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Malenica", "Ivana", ""], ["Bibaut", "Aurelien", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "2102.00127", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat, Liam Li, Eric Xing, Ameet Talwalkar", "title": "On Data Efficiency of Meta-learning", "comments": "Preliminary version. An updated version is to appear in AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning has enabled learning statistical models that can be quickly\nadapted to new prediction tasks. Motivated by use-cases in personalized\nfederated learning, we study the often overlooked aspect of the modern\nmeta-learning algorithms -- their data efficiency. To shed more light on which\nmethods are more efficient, we use techniques from algorithmic stability to\nderive bounds on the transfer risk that have important practical implications,\nindicating how much supervision is needed and how it must be allocated for each\nmethod to attain the desired level of generalization. Further, we introduce a\nnew simple framework for evaluating meta-learning methods under a limit on the\navailable supervision, conduct an empirical study of MAML, Reptile, and\nProtonets, and demonstrate the differences in the behavior of these methods on\nfew-shot and federated learning benchmarks. Finally, we propose active\nmeta-learning, which incorporates active data selection into learning-to-learn,\nleading to better performance of all methods in the limited supervision regime.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 01:44:12 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Li", "Liam", ""], ["Xing", "Eric", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2102.00128", "submitter": "Nil-Jana Akpinar", "authors": "Nil-Jana Akpinar, Maria De-Arteaga, Alexandra Chouldechova", "title": "The effect of differential victim crime reporting on predictive policing\n  systems", "comments": "Conference on Fairness, Accountability, and Transparency (FAccT 2021)", "journal-ref": null, "doi": "10.1145/3442188.3445877", "report-no": null, "categories": "cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Police departments around the world have been experimenting with forms of\nplace-based data-driven proactive policing for over two decades. Modern\nincarnations of such systems are commonly known as hot spot predictive\npolicing. These systems predict where future crime is likely to concentrate\nsuch that police can allocate patrols to these areas and deter crime before it\noccurs. Previous research on fairness in predictive policing has concentrated\non the feedback loops which occur when models are trained on discovered crime\ndata, but has limited implications for models trained on victim crime reporting\ndata. We demonstrate how differential victim crime reporting rates across\ngeographical areas can lead to outcome disparities in common crime hot spot\nprediction models. Our analysis is based on a simulation patterned after\ndistrict-level victimization and crime reporting survey data for Bogot\\'a,\nColombia. Our results suggest that differential crime reporting rates can lead\nto a displacement of predicted hotspots from high crime but low reporting areas\nto high or medium crime and high reporting areas. This may lead to\nmisallocations both in the form of over-policing and under-policing.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 01:57:22 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 22:52:55 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Akpinar", "Nil-Jana", ""], ["De-Arteaga", "Maria", ""], ["Chouldechova", "Alexandra", ""]]}, {"id": "2102.00185", "submitter": "Alexey Naumov", "authors": "Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov, Hoi-To\n  Wai", "title": "On the Stability of Random Matrix Product with Markovian Noise:\n  Application to Linear Stochastic Approximation and TD Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the exponential stability of random matrix products driven\nby a general (possibly unbounded) state space Markov chain. It is a cornerstone\nin the analysis of stochastic algorithms in machine learning (e.g. for\nparameter tracking in online learning or reinforcement learning). The existing\nresults impose strong conditions such as uniform boundedness of the\nmatrix-valued functions and uniform ergodicity of the Markov chains. Our main\ncontribution is an exponential stability result for the $p$-th moment of random\nmatrix product, provided that (i) the underlying Markov chain satisfies a\nsuper-Lyapunov drift condition, (ii) the growth of the matrix-valued functions\nis controlled by an appropriately defined function (related to the drift\ncondition). Using this result, we give finite-time $p$-th moment bounds for\nconstant and decreasing stepsize linear stochastic approximation schemes with\nMarkovian noise on general state space. We illustrate these findings for linear\nvalue-function estimation in reinforcement learning. We provide finite-time\n$p$-th moment bound for various members of temporal difference (TD) family of\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 08:39:38 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Durmus", "Alain", ""], ["Moulines", "Eric", ""], ["Naumov", "Alexey", ""], ["Samsonov", "Sergey", ""], ["Wai", "Hoi-To", ""]]}, {"id": "2102.00199", "submitter": "Nikita Puchkin", "authors": "Denis Belomestny, Eric Moulines, Alexey Naumov, Nikita Puchkin, and\n  Sergey Samsonov", "title": "Rates of convergence for density estimation with GANs", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We undertake a precise study of the non-asymptotic properties of vanilla\ngenerative adversarial networks (GANs) and derive theoretical guarantees in the\nproblem of estimating an unknown $d$-dimensional density $p^*$ under a proper\nchoice of the class of generators and discriminators. We prove that the\nresulting density estimate converges to $p^*$ in terms of Jensen-Shannon (JS)\ndivergence at the rate $(\\log n/n)^{2\\beta/(2\\beta+d)}$ where $n$ is the sample\nsize and $\\beta$ determines the smoothness of $p^*.$ This is the first result\nin the literature on density estimation using vanilla GANs with JS rates faster\nthan $n^{-1/2}$ in the regime $\\beta>d/2.$\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 09:59:14 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Belomestny", "Denis", ""], ["Moulines", "Eric", ""], ["Naumov", "Alexey", ""], ["Puchkin", "Nikita", ""], ["Samsonov", "Sergey", ""]]}, {"id": "2102.00208", "submitter": "Christian M. Dahl", "authors": "Christian M. Dahl, Emil N. S{\\o}rensen", "title": "Time Series (re)sampling using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel bootstrap procedure for dependent data based on Generative\nAdversarial networks (GANs). We show that the dynamics of common stationary\ntime series processes can be learned by GANs and demonstrate that GANs trained\non a single sample path can be used to generate additional samples from the\nprocess. We find that temporal convolutional neural networks provide a suitable\ndesign for the generator and discriminator, and that convincing samples can be\ngenerated on the basis of a vector of iid normal noise. We demonstrate the\nfinite sample properties of GAN sampling and the suggested bootstrap using\nsimulations where we compare the performance to circular block bootstrapping in\nthe case of resampling an AR(1) time series processes. We find that resampling\nusing the GAN can outperform circular block bootstrapping in terms of empirical\ncoverage.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 10:58:15 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Dahl", "Christian M.", ""], ["S\u00f8rensen", "Emil N.", ""]]}, {"id": "2102.00236", "submitter": "Francesco Orabona", "authors": "Francesco Orabona and D\\'avid P\\'al", "title": "Parameter-free Stochastic Optimization of Variationally Coherent\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and analyze an algorithm for first-order stochastic optimization of\na large class of functions on $\\mathbb{R}^d$. In particular, we consider the\n\\emph{variationally coherent} functions which can be convex or non-convex. The\niterates of our algorithm on variationally coherent functions converge almost\nsurely to the global minimizer $\\boldsymbol{x}^*$. Additionally, the very same\nalgorithm with the same hyperparameters, after $T$ iterations guarantees on\nconvex functions that the expected suboptimality gap is bounded by\n$\\widetilde{O}(\\|\\boldsymbol{x}^* - \\boldsymbol{x}_0\\| T^{-1/2+\\epsilon})$ for\nany $\\epsilon>0$. It is the first algorithm to achieve both these properties at\nthe same time. Also, the rate for convex functions essentially matches the\nperformance of parameter-free algorithms. Our algorithm is an instance of the\nFollow The Regularized Leader algorithm with the added twist of using\n\\emph{rescaled gradients} and time-varying linearithmic regularizers.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 15:05:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Orabona", "Francesco", ""], ["P\u00e1l", "D\u00e1vid", ""]]}, {"id": "2102.00252", "submitter": "Emiliano Valdez", "authors": "Banghee So, Jean-Philippe Boucher, Emiliano A. Valdez", "title": "Synthetic Dataset Generation of Driver Telematics", "comments": "24 pages, 11 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes techniques employed in the production of a synthetic\ndataset of driver telematics emulated from a similar real insurance dataset.\nThe synthetic dataset generated has 100,000 policies that included observations\nabout driver's claims experience together with associated classical risk\nvariables and telematics-related variables. This work is aimed to produce a\nresource that can be used to advance models to assess risks for usage-based\ninsurance. It follows a three-stage process using machine learning algorithms.\nThe first stage is simulating values for the number of claims as multiple\nbinary classifications applying feedforward neural networks. The second stage\nis simulating values for aggregated amount of claims as regression using\nfeedforward neural networks, with number of claims included in the set of\nfeature variables. In the final stage, a synthetic portfolio of the space of\nfeature variables is generated applying an extended $\\texttt{SMOTE}$ algorithm.\nThe resulting dataset is evaluated by comparing the synthetic and real datasets\nwhen Poisson and gamma regression models are fitted to the respective data.\nOther visualization and data summarization produce remarkable similar\nstatistics between the two datasets. We hope that researchers interested in\nobtaining telematics datasets to calibrate models or learning algorithms will\nfind our work valuable.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 15:52:56 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["So", "Banghee", ""], ["Boucher", "Jean-Philippe", ""], ["Valdez", "Emiliano A.", ""]]}, {"id": "2102.00305", "submitter": "Bo Ning", "authors": "Bo Ning", "title": "Spike and slab Bayesian sparse principal component analysis", "comments": "27 pages, 5 tables, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sparse principal component analysis (PCA) is a popular tool for dimensional\nreduction of high-dimensional data. Despite its massive popularity, there is\nstill a lack of theoretically justifiable Bayesian sparse PCA that is\ncomputationally scalable. A major challenge is choosing a suitable prior for\nthe loadings matrix, as principal components are mutually orthogonal. We\npropose a spike and slab prior that meets this orthogonality constraint and\nshow that the posterior enjoys both theoretical and computational advantages.\nTwo computational algorithms, the PX-CAVI and the PX-EM algorithms, are\ndeveloped. Both algorithms use parameter expansion to deal with the\northogonality constraint and to accelerate their convergence speeds. We found\nthat the PX-CAVI algorithm has superior empirical performance than the PX-EM\nalgorithm and two other penalty methods for sparse PCA. The PX-CAVI algorithm\nis then applied to study a lung cancer gene expression dataset. $\\mathsf{R}$\npackage $\\mathsf{VBsparsePCA}$ with an implementation of the algorithm is\navailable on The Comprehensive R Archive Network.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 20:28:30 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ning", "Bo", ""]]}, {"id": "2102.00314", "submitter": "Gal Vardi", "authors": "Gal Vardi, Daniel Reichman, Toniann Pitassi, Ohad Shamir", "title": "Size and Depth Separation in Approximating Benign Functions with Neural\n  Networks", "comments": "Edits after review + changing the terminology from \"natural\n  functions\" to \"benign functions\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When studying the expressive power of neural networks, a main challenge is to\nunderstand how the size and depth of the network affect its ability to\napproximate real functions. However, not all functions are interesting from a\npractical viewpoint: functions of interest usually have a polynomially-bounded\nLipschitz constant, and can be computed efficiently. We call functions that\nsatisfy these conditions \"benign\", and explore the benefits of size and depth\nfor approximation of benign functions with ReLU networks. As we show, this\nproblem is more challenging than the corresponding problem for non-benign\nfunctions. We give barriers to showing depth-lower-bounds: Proving existence of\na benign function that cannot be approximated by polynomial-size networks of\ndepth $4$ would settle longstanding open problems in computational complexity.\nIt implies that beyond depth $4$ there is a barrier to showing depth-separation\nfor benign functions, even between networks of constant depth and networks of\nnonconstant depth. We also study size-separation, namely, whether there are\nbenign functions that can be approximated with networks of size $O(s(d))$, but\nnot with networks of size $O(s'(d))$. We show a complexity-theoretic barrier to\nproving such results beyond size $O(d\\log^2(d))$, but also show an explicit\nbenign function, that can be approximated with networks of size $O(d)$ and not\nwith networks of size $o(d/\\log d)$. For approximation in $L_\\infty$ we achieve\nsuch separation already between size $O(d)$ and size $o(d)$. Moreover, we show\nsuperpolynomial size lower bounds and barriers to such lower bounds, depending\non the assumptions on the function. Our size-separation results rely on an\nanalysis of size lower bounds for Boolean functions, which is of independent\ninterest: We show linear size lower bounds for computing explicit Boolean\nfunctions with neural networks and threshold circuits.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 21:30:11 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 01:51:12 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 20:34:40 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Vardi", "Gal", ""], ["Reichman", "Daniel", ""], ["Pitassi", "Toniann", ""], ["Shamir", "Ohad", ""]]}, {"id": "2102.00315", "submitter": "Peyman Setoodeh", "authors": "Pedram Fekri, Ali Akbar Safavi, Mehrdad Hosseini Zadeh, and Peyman\n  Setoodeh", "title": "Metalearning: Sparse Variable-Structure Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimension of the encoder output (i.e., the code layer) in an autoencoder is a\nkey hyper-parameter for representing the input data in a proper space. This\ndimension must be carefully selected in order to guarantee the desired\nreconstruction accuracy. Although overcomplete representation can address this\ndimension issue, the computational complexity will increase with dimension.\nInspired by non-parametric methods, here, we propose a metalearning approach to\nincrease the number of basis vectors used in dynamic sparse coding on the fly.\nAn actor-critic algorithm is deployed to automatically choose an appropriate\ndimension for feature vectors regarding the required level of accuracy. The\nproposed method benefits from online dictionary learning and fast iterative\nshrinkage-thresholding algorithm (FISTA) as the optimizer in the inference\nphase. It aims at choosing the minimum number of bases for the overcomplete\nrepresentation regarding the reconstruction error threshold. This method allows\nfor online controlling of both the representation dimension and the\nreconstruction error in a dynamic framework.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 21:32:23 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Fekri", "Pedram", ""], ["Safavi", "Ali Akbar", ""], ["Zadeh", "Mehrdad Hosseini", ""], ["Setoodeh", "Peyman", ""]]}, {"id": "2102.00380", "submitter": "Stephanie Ger", "authors": "Stephanie Ger, Diego Klabjan and Jean Utke", "title": "Classification Models for Partially Ordered Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many models such as Long Short Term Memory (LSTMs), Gated Recurrent Units\n(GRUs) and transformers have been developed to classify time series data with\nthe assumption that events in a sequence are ordered. On the other hand, fewer\nmodels have been developed for set based inputs, where order does not matter.\nThere are several use cases where data is given as partially-ordered sequences\nbecause of the granularity or uncertainty of time stamps. We introduce a novel\ntransformer based model for such prediction tasks, and benchmark against\nextensions of existing order invariant models. We also discuss how transition\nprobabilities between events in a sequence can be used to improve model\nperformance. We show that the transformer-based equal-time model outperforms\nextensions of existing set models on three data sets.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 05:08:21 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ger", "Stephanie", ""], ["Klabjan", "Diego", ""], ["Utke", "Jean", ""]]}, {"id": "2102.00384", "submitter": "Chanwoo Lee", "authors": "Chanwoo Lee, Miaoyan Wang", "title": "Beyond the Signs: Nonparametric Tensor Completion via Sign Series", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of tensor estimation from noisy observations with\npossibly missing entries. A nonparametric approach to tensor completion is\ndeveloped based on a new model which we coin as sign representable tensors. The\nmodel represents the signal tensor of interest using a series of structured\nsign tensors. Unlike earlier methods, the sign series representation\neffectively addresses both low- and high-rank signals, while encompassing many\nexisting tensor models -- including CP models, Tucker models, single index\nmodels, several hypergraphon models -- as special cases. We show that the sign\ntensor series is theoretically characterized, and computationally estimable,\nvia classification tasks with carefully-specified weights. Excess risk bounds,\nestimation error rates, and sample complexities are established. We demonstrate\nthe outperformance of our approach over previous methods on two datasets, one\non human brain connectivity networks and the other on topic data mining.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 05:27:01 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lee", "Chanwoo", ""], ["Wang", "Miaoyan", ""]]}, {"id": "2102.00397", "submitter": "Longyuan Li", "authors": "Longyuan Li, Junchi Yan, Xiaokang Yang, and Yaohui Jin", "title": "Learning Interpretable Deep State Space Model for Probabilistic Time\n  Series Forecasting", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probabilistic time series forecasting involves estimating the distribution of\nfuture based on its history, which is essential for risk management in\ndownstream decision-making. We propose a deep state space model for\nprobabilistic time series forecasting whereby the non-linear emission model and\ntransition model are parameterized by networks and the dependency is modeled by\nrecurrent neural nets. We take the automatic relevance determination (ARD) view\nand devise a network to exploit the exogenous variables in addition to time\nseries. In particular, our ARD network can incorporate the uncertainty of the\nexogenous variables and eventually helps identify useful exogenous variables\nand suppress those irrelevant for forecasting. The distribution of multi-step\nahead forecasts are approximated by Monte Carlo simulation. We show in\nexperiments that our model produces accurate and sharp probabilistic forecasts.\nThe estimated uncertainty of our forecasting also realistically increases over\ntime, in a spontaneous manner.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 06:49:33 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Longyuan", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""], ["Jin", "Yaohui", ""]]}, {"id": "2102.00431", "submitter": "Longyuan Li", "authors": "Longyuan Li, Jihai Zhang, Junchi Yan, Yaohui Jin, Yunhao Zhang, Yanjie\n  Duan, and Guangjian Tian", "title": "Synergetic Learning of Heterogeneous Temporal Sequences for\n  Multi-Horizon Probabilistic Forecasting", "comments": "Accepted by AAAI 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-series is ubiquitous across applications, such as transportation,\nfinance and healthcare. Time-series is often influenced by external factors,\nespecially in the form of asynchronous events, making forecasting difficult.\nHowever, existing models are mainly designated for either synchronous\ntime-series or asynchronous event sequence, and can hardly provide a synthetic\nway to capture the relation between them. We propose Variational Synergetic\nMulti-Horizon Network (VSMHN), a novel deep conditional generative model. To\nlearn complex correlations across heterogeneous sequences, a tailored encoder\nis devised to combine the advances in deep point processes models and\nvariational recurrent neural networks. In addition, an aligned time coding and\nan auxiliary transition scheme are carefully devised for batched training on\nunaligned sequences. Our model can be trained effectively using stochastic\nvariational inference and generates probabilistic predictions with Monte-Carlo\nsimulation. Furthermore, our model produces accurate, sharp and more realistic\nprobabilistic forecasts. We also show that modeling asynchronous event\nsequences is crucial for multi-horizon time-series forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 11:00:55 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Longyuan", ""], ["Zhang", "Jihai", ""], ["Yan", "Junchi", ""], ["Jin", "Yaohui", ""], ["Zhang", "Yunhao", ""], ["Duan", "Yanjie", ""], ["Tian", "Guangjian", ""]]}, {"id": "2102.00434", "submitter": "Gilad Yehudai", "authors": "Eran Malach, Gilad Yehudai, Shai Shalev-Shwartz, Ohad Shamir", "title": "The Connection Between Approximation, Depth Separation and Learnability\n  in Neural Networks", "comments": "COLT 2021 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have shown separation results between deep neural\nnetworks, and hypothesis classes with inferior approximation capacity such as\nshallow networks or kernel classes. On the other hand, the fact that deep\nnetworks can efficiently express a target function does not mean that this\ntarget function can be learned efficiently by deep neural networks. In this\nwork we study the intricate connection between learnability and approximation\ncapacity. We show that learnability with deep networks of a target function\ndepends on the ability of simpler classes to approximate the target.\nSpecifically, we show that a necessary condition for a function to be learnable\nby gradient descent on deep neural networks is to be able to approximate the\nfunction, at least in a weak sense, with shallow neural networks. We also show\nthat a class of functions can be learned by an efficient statistical query\nalgorithm if and only if it can be approximated in a weak sense by some kernel\nclass. We give several examples of functions which demonstrate depth\nseparation, and conclude that they cannot be efficiently learned, even by a\nhypothesis class that can efficiently approximate them.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 11:32:30 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 12:32:55 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Malach", "Eran", ""], ["Yehudai", "Gilad", ""], ["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""]]}, {"id": "2102.00457", "submitter": "Chang Wei Tan", "authors": "Chang Wei Tan and Angus Dempster and Christoph Bergmeir and Geoffrey\n  I. Webb", "title": "MultiRocket: Effective summary statistics for convolutional outputs in\n  time series classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rocket and MiniRocket, while two of the fastest methods for time series\nclassification, are both somewhat less accurate than the current most accurate\nmethods (namely, HIVE-COTE and its variants). We show that it is possible to\nsignificantly improve the accuracy of MiniRocket (and Rocket), with some\nadditional computational expense, by expanding the set of features produced by\nthe transform, making MultiRocket (for MiniRocket with Multiple Features)\noverall the single most accurate method on the datasets in the UCR archive,\nwhile still being orders of magnitude faster than any algorithm of comparable\naccuracy other than its precursors\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 14:04:10 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Tan", "Chang Wei", ""], ["Dempster", "Angus", ""], ["Bergmeir", "Christoph", ""], ["Webb", "Geoffrey I.", ""]]}, {"id": "2102.00461", "submitter": "Mariana Almeida", "authors": "Bruno Jardim and Ricardo Rei and Mariana S. C. Almeida", "title": "Multilingual Email Zoning", "comments": "Accepted at EACL 2021 SRW\n  (https://sites.google.com/view/eaclsrw2021/home); 6 pages with 2 Figures and\n  8 Tables, plus references; Cleverly Multilingual Zoning Corpus available at\n  https://github.com/cleverly-ai/multilingual-email-zoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.AP stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The segmentation of emails into functional zones (also dubbed email zoning)\nis a relevant preprocessing step for most NLP tasks that deal with emails.\nHowever, despite the multilingual character of emails and their applications,\nprevious literature regarding email zoning corpora and systems was developed\nessentially for English.\n  In this paper, we analyse the existing email zoning corpora and propose a new\nmultilingual benchmark composed of 625 emails in Portuguese, Spanish and\nFrench. Moreover, we introduce OKAPI, the first multilingual email segmentation\nmodel based on a language agnostic sentence encoder. Besides generalizing well\nfor unseen languages, our model is competitive with current English benchmarks,\nand reached new state-of-the-art performances for domain adaptation tasks in\nEnglish.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 14:32:20 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 19:37:39 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Jardim", "Bruno", ""], ["Rei", "Ricardo", ""], ["Almeida", "Mariana S. C.", ""]]}, {"id": "2102.00479", "submitter": "Nathan Kallus", "authors": "Yichun Hu, Nathan Kallus, Masatoshi Uehara", "title": "Fast Rates for the Regret of Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the regret of reinforcement learning from offline data generated by\na fixed behavior policy in an infinite-horizon discounted Markov decision\nprocess (MDP). While existing analyses of common approaches, such as fitted\n$Q$-iteration (FQI), suggest a $O(1/\\sqrt{n})$ convergence for regret,\nempirical behavior exhibits much faster convergence. In this paper, we present\na finer regret analysis that exactly characterizes this phenomenon by providing\nfast rates for the regret convergence. First, we show that given any estimate\nfor the optimal quality function $Q^*$, the regret of the policy it defines\nconverges at a rate given by the exponentiation of the $Q^*$-estimate's\npointwise convergence rate, thus speeding it up. The level of exponentiation\ndepends on the level of noise in the decision-making problem, rather than the\nestimation problem. We establish such noise levels for linear and tabular MDPs\nas examples. Second, we provide new analyses of FQI and Bellman residual\nminimization to establish the correct pointwise convergence guarantees. As\nspecific cases, our results imply $O(1/n)$ regret rates in linear cases and\n$\\exp(-\\Omega(n))$ regret rates in tabular cases.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 16:17:56 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hu", "Yichun", ""], ["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "2102.00485", "submitter": "Stefan Horoi", "authors": "Stefan Horoi, Jessie Huang, Guy Wolf, Smita Krishnaswamy", "title": "Visualizing High-Dimensional Trajectories on the Loss-Landscape of ANNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training artificial neural networks requires the optimization of highly\nnon-convex loss functions. Throughout the years, the scientific community has\ndeveloped an extensive set of tools and architectures that render this\noptimization task tractable and a general intuition has been developed for\nchoosing hyper parameters that help the models reach minima that generalize\nwell to unseen data. However, for the most part, the difference in trainability\nin between architectures, tasks and even the gap in network generalization\nabilities still remain unexplained. Visualization tools have played a key role\nin uncovering key geometric characteristics of the loss-landscape of ANNs and\nhow they impact trainability and generalization capabilities. However, most\nvisualizations methods proposed so far have been relatively limited in their\ncapabilities since they are of linear nature and only capture features in a\nlimited number of dimensions. We propose the use of the modern dimensionality\nreduction method PHATE which represents the SOTA in terms of capturing both\nglobal and local structures of high-dimensional data. We apply this method to\nvisualize the loss landscape during and after training. Our visualizations\nreveal differences in training trajectories and generalization capabilities\nwhen used to make comparisons between optimization methods, initializations,\narchitectures, and datasets. Given this success we anticipate this method to be\nused in making informed choices about these aspects of neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 16:30:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Horoi", "Stefan", ""], ["Huang", "Jessie", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "2102.00490", "submitter": "Alon Cohen", "authors": "Alon Cohen, Haim Kaplan, Tomer Koren, Yishay Mansour", "title": "Online Markov Decision Processes with Aggregate Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a novel variant of online finite-horizon Markov Decision Processes\nwith adversarially changing loss functions and initially unknown dynamics. In\neach episode, the learner suffers the loss accumulated along the trajectory\nrealized by the policy chosen for the episode, and observes aggregate bandit\nfeedback: the trajectory is revealed along with the cumulative loss suffered,\nrather than the individual losses encountered along the trajectory. Our main\nresult is a computationally efficient algorithm with $O(\\sqrt{K})$ regret for\nthis setting, where $K$ is the number of episodes.\n  We establish this result via an efficient reduction to a novel bandit\nlearning setting we call Distorted Linear Bandits (DLB), which is a variant of\nbandit linear optimization where actions chosen by the learner are\nadversarially distorted before they are committed. We then develop a\ncomputationally-efficient online algorithm for DLB for which we prove an\n$O(\\sqrt{T})$ regret bound, where $T$ is the number of time steps. Our\nalgorithm is based on online mirror descent with a self-concordant barrier\nregularization that employs a novel increasing learning rate schedule.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 16:49:07 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Cohen", "Alon", ""], ["Kaplan", "Haim", ""], ["Koren", "Tomer", ""], ["Mansour", "Yishay", ""]]}, {"id": "2102.00500", "submitter": "Sam Polk", "authors": "James M. Murphy and Sam L. Polk", "title": "A Multiscale Environment for Learning by Diffusion", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering algorithms partition a dataset into groups of similar points. The\nclustering problem is very general, and different partitions of the same\ndataset could be considered correct and useful. To fully understand such data,\nit must be considered at a variety of scales, ranging from coarse to fine. We\nintroduce the Multiscale Environment for Learning by Diffusion (MELD) data\nmodel, which is a family of clusterings parameterized by nonlinear diffusion on\nthe dataset. We show that the MELD data model precisely captures latent\nmultiscale structure in data and facilitates its analysis. To efficiently learn\nthe multiscale structure observed in many real datasets, we introduce the\nMultiscale Learning by Unsupervised Nonlinear Diffusion (M-LUND) clustering\nalgorithm, which is derived from a diffusion process at a range of temporal\nscales. We provide theoretical guarantees for the algorithm's performance and\nestablish its computational efficiency. Finally, we show that the M-LUND\nclustering algorithm detects the latent structure in a range of synthetic and\nreal datasets.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 17:46:19 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Murphy", "James M.", ""], ["Polk", "Sam L.", ""]]}, {"id": "2102.00504", "submitter": "Marco Bressan", "authors": "Marco Bressan, Nicol\\`o Cesa-Bianchi, Silvio Lattanzi, Andrea Paudice", "title": "Exact Recovery of Clusters in Finite Metric Spaces Using Oracle Queries", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of exact cluster recovery using oracle queries.\nPrevious results show that clusters in Euclidean spaces that are convex and\nseparated with a margin can be reconstructed exactly using only $O(\\log n)$\nsame-cluster queries, where $n$ is the number of input points. In this work, we\nstudy this problem in the more challenging non-convex setting. We introduce a\nstructural characterization of clusters, called $(\\beta,\\gamma)$-convexity,\nthat can be applied to any finite set of points equipped with a metric (or even\na semimetric, as the triangle inequality is not needed). Using\n$(\\beta,\\gamma)$-convexity, we can translate natural density properties of\nclusters (which include, for instance, clusters that are strongly non-convex in\n$\\mathbb{R}^d$) into a graph-theoretic notion of convexity. By exploiting this\nconvexity notion, we design a deterministic algorithm that recovers\n$(\\beta,\\gamma)$-convex clusters using $O(k^2 \\log n + k^2\n(6/\\beta\\gamma)^{dens(X)})$ same-cluster queries, where $k$ is the number of\nclusters and $dens(X)$ is the density dimension of the semimetric. We show that\nan exponential dependence on the density dimension is necessary, and we also\nshow that, if we are allowed to make $O(k^2 + k\\log n)$ additional queries to a\n\"cluster separation\" oracle, then we can recover clusters that have different\nand arbitrary scales, even when the scale of each cluster is unknown.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 18:00:29 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 14:00:14 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bressan", "Marco", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""], ["Lattanzi", "Silvio", ""], ["Paudice", "Andrea", ""]]}, {"id": "2102.00667", "submitter": "Fengzhen Tang Sonna", "authors": "Fengzhen Tang, Haifeng Feng, Peter Tino, Bailu Si, Daxiong Ji", "title": "Probabilistic Learning Vector Quantization on Manifold of Symmetric\n  Positive Definite Matrices", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we develop a new classification method for manifold-valued\ndata in the framework of probabilistic learning vector quantization. In many\nclassification scenarios, the data can be naturally represented by symmetric\npositive definite matrices, which are inherently points that live on a curved\nRiemannian manifold. Due to the non-Euclidean geometry of Riemannian manifolds,\ntraditional Euclidean machine learning algorithms yield poor results on such\ndata. In this paper, we generalize the probabilistic learning vector\nquantization algorithm for data points living on the manifold of symmetric\npositive definite matrices equipped with Riemannian natural metric\n(affine-invariant metric). By exploiting the induced Riemannian distance, we\nderive the probabilistic learning Riemannian space quantization algorithm,\nobtaining the learning rule through Riemannian gradient descent. Empirical\ninvestigations on synthetic data, image data , and motor imagery EEG data\ndemonstrate the superior performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 06:58:39 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Tang", "Fengzhen", ""], ["Feng", "Haifeng", ""], ["Tino", "Peter", ""], ["Si", "Bailu", ""], ["Ji", "Daxiong", ""]]}, {"id": "2102.00678", "submitter": "Nan Lu", "authors": "Nan Lu, Shida Lei, Gang Niu, Issei Sato, Masashi Sugiyama", "title": "Binary Classification from Multiple Unlabeled Datasets via Surrogate Set\n  Classification", "comments": "ICML2021 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with high annotation costs, training a classifier only from weakly\nsupervised data has attracted a great deal of attention these days. Among\nvarious approaches, strengthening supervision from completely unsupervised\nclassification is a promising direction, which typically employs class priors\nas the only supervision and trains a binary classifier from unlabeled (U)\ndatasets. While existing risk-consistent methods are theoretically grounded\nwith high flexibility, they can learn only from two U sets. In this paper, we\npropose a new approach for binary classification from $m$ U-sets for $m\\ge2$.\nOur key idea is to consider an auxiliary classification task called surrogate\nset classification (SSC), which is aimed at predicting from which U set each\nobserved data is drawn. SSC can be solved by a standard (multi-class)\nclassification method, and we use the SSC solution to obtain the final binary\nclassifier through a certain linear-fractional transformation. We built our\nmethod in a flexible and efficient end-to-end deep learning framework and prove\nit to be classifier-consistent. Through experiments, we demonstrate the\nsuperiority of our proposed method over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 07:36:38 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 10:55:31 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Lu", "Nan", ""], ["Lei", "Shida", ""], ["Niu", "Gang", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2102.00725", "submitter": "Yi Yu", "authors": "Anne Gael Manegueu, Alexandra Carpentier and Yi Yu", "title": "Generalized non-stationary bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a non-stationary stochastic bandit problem, which\ngeneralizes the switching bandit problem. On top of the switching bandit\nproblem (\\textbf{Case a}), we are interested in three concrete examples:\n(\\textbf{b}) the means of the arms are local polynomials, (\\textbf{c}) the\nmeans of the arms are locally smooth, and (\\textbf{d}) the gaps of the arms\nhave a bounded number of inflexion points and where the highest arm mean cannot\nvary too much in a short range. These three settings are very different, but\nhave in common the following: (i) the number of similarly-sized level sets of\nthe logarithm of the gaps can be controlled, and (ii) the highest mean has a\nlimited number of abrupt changes, and otherwise has limited variations. We\npropose a single algorithm in this general setting, that in particular solves\nin an efficient and unified way the four problems (a)-(d) mentioned.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 09:34:44 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 08:13:53 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Manegueu", "Anne Gael", ""], ["Carpentier", "Alexandra", ""], ["Yu", "Yi", ""]]}, {"id": "2102.00751", "submitter": "Jason Lin", "authors": "Jason Z. Lin and Jelena Bradic", "title": "Learning to Combat Noisy Labels via Classification Margins", "comments": "21 pages, 8 sets of figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A deep neural network trained on noisy labels is known to quickly lose its\npower to discriminate clean instances from noisy ones. After the early learning\nphase has ended, the network memorizes the noisy instances, which leads to a\ndegradation in generalization performance. To resolve this issue, we propose\nMARVEL (MARgins Via Early Learning), where we track the goodness of \"fit\" for\nevery instance by maintaining an epoch-history of its classification margins.\nBased on consecutive negative margins, we discard suspected noisy instances by\nzeroing out their weights. In addition, MARVEL+ upweights arduous instances\nenabling the network to learn a more nuanced representation of the\nclassification boundary. Experimental results on benchmark datasets with\nsynthetic label noise show that MARVEL outperforms other baselines consistently\nacross different noise levels, with a significantly larger margin under\nasymmetric noise.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 10:35:25 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Lin", "Jason Z.", ""], ["Bradic", "Jelena", ""]]}, {"id": "2102.00760", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes and Alessandro Rudi and Francis Bach", "title": "Fast rates in structured prediction", "comments": "14 main pages, 3 main figures, 43 pages, 4 figures (with appendix)", "journal-ref": "Conference on Learning Theory, PMLR 134, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discrete supervised learning problems such as classification are often\ntackled by introducing a continuous surrogate problem akin to regression.\nBounding the original error, between estimate and solution, by the surrogate\nerror endows discrete problems with convergence rates already shown for\ncontinuous instances. Yet, current approaches do not leverage the fact that\ndiscrete problems are essentially predicting a discrete output when continuous\nproblems are predicting a continuous value. In this paper, we tackle this issue\nfor general structured prediction problems, opening the way to \"super fast\"\nrates, that is, convergence rates for the excess risk faster than $n^{-1}$,\nwhere $n$ is the number of observations, with even exponential rates with the\nstrongest assumptions. We first illustrate it for predictors based on nearest\nneighbors, generalizing rates known for binary classification to any discrete\nproblem within the framework of structured prediction. We then consider kernel\nridge regression where we improve known rates in $n^{-1/4}$ to arbitrarily fast\nrates, depending on a parameter characterizing the hardness of the problem,\nthus allowing, under smoothness assumptions, to bypass the curse of\ndimensionality.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 10:50:04 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 13:02:31 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 15:04:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Cabannes", "Vivien", ""], ["Rudi", "Alessandro", ""], ["Bach", "Francis", ""]]}, {"id": "2102.00815", "submitter": "Qinghua Liu", "authors": "Chi Jin, Qinghua Liu, Sobhan Miryoosefi", "title": "Bellman Eluder Dimension: New Rich Classes of RL Problems, and\n  Sample-Efficient Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the minimal structural assumptions that empower sample-efficient\nlearning is one of the most important research directions in Reinforcement\nLearning (RL). This paper advances our understanding of this fundamental\nquestion by introducing a new complexity measure -- Bellman Eluder (BE)\ndimension. We show that the family of RL problems of low BE dimension is\nremarkably rich, which subsumes a vast majority of existing tractable RL\nproblems including but not limited to tabular MDPs, linear MDPs, reactive\nPOMDPs, low Bellman rank problems as well as low Eluder dimension problems.\nThis paper further designs a new optimization-based algorithm -- GOLF, and\nreanalyzes a hypothesis elimination-based algorithm -- OLIVE (proposed in Jiang\net al., 2017). We prove that both algorithms learn the near-optimal policies of\nlow BE dimension problems in a number of samples that is polynomial in all\nrelevant parameters, but independent of the size of state-action space. Our\nregret and sample complexity results match or improve the best existing results\nfor several well-known subclasses of low BE dimension problems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 13:13:58 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 04:48:14 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 01:57:55 GMT"}, {"version": "v4", "created": "Fri, 16 Jul 2021 02:45:23 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Jin", "Chi", ""], ["Liu", "Qinghua", ""], ["Miryoosefi", "Sobhan", ""]]}, {"id": "2102.00892", "submitter": "Sina Hajimiri", "authors": "Sina Hajimiri, Aryo Lotfi, Mahdieh Soleymani Baghshah", "title": "Semi-Supervised Disentanglement of Class-Related and Class-Independent\n  Factors in VAE", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, extending variational autoencoder's framework to learn\ndisentangled representations has received much attention. We address this\nproblem by proposing a framework capable of disentangling class-related and\nclass-independent factors of variation in data. Our framework employs an\nattention mechanism in its latent space in order to improve the process of\nextracting class-related factors from data. We also deal with the multimodality\nof data distribution by utilizing mixture models as learnable prior\ndistributions, as well as incorporating the Bhattacharyya coefficient in the\nobjective function to prevent highly overlapping mixtures. Our model's encoder\nis further trained in a semi-supervised manner, with a small fraction of\nlabeled data, to improve representations' interpretability. Experiments show\nthat our framework disentangles class-related and class-independent factors of\nvariation and learns interpretable features. Moreover, we demonstrate our\nmodel's performance with quantitative and qualitative results on various\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:05:24 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hajimiri", "Sina", ""], ["Lotfi", "Aryo", ""], ["Baghshah", "Mahdieh Soleymani", ""]]}, {"id": "2102.00927", "submitter": "Sidharth Gupta", "authors": "Sidharth Gupta and Ivan Dokmani\\'c", "title": "Total Least Squares Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the phase retrieval problem with errors in the sensing vectors. A\nnumber of recent methods for phase retrieval are based on least squares (LS)\nformulations which assume errors in the quadratic measurements. We extend this\napproach to handle errors in the sensing vectors by adopting the total least\nsquares (TLS) framework that is used in linear inverse problems with operator\nerrors. We show how gradient descent and the specific geometry of the phase\nretrieval problem can be used to obtain a simple and efficient TLS solution.\nAdditionally, we derive the gradients of the TLS and LS solutions with respect\nto the sensing vectors and measurements which enables us to calculate the\nsolution errors. By analyzing these error expressions we determine conditions\nunder which each method should outperform the other. We run simulations to\ndemonstrate that our method can lead to more accurate solutions. We further\ndemonstrate the effectiveness of our approach by performing phase retrieval\nexperiments on real optical hardware which naturally contains both sensing\nvector and measurement errors.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:52:14 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 20:46:53 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Gupta", "Sidharth", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "2102.00931", "submitter": "Gergely Neu", "authors": "Gergely Neu", "title": "Information-Theoretic Generalization Bounds for Stochastic Gradient\n  Descent", "comments": "to appear at COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the generalization properties of the popular stochastic optimization\nmethod known as stochastic gradient descent (SGD) for optimizing general\nnon-convex loss functions. Our main contribution is providing upper bounds on\nthe generalization error that depend on local statistics of the stochastic\ngradients evaluated along the path of iterates calculated by SGD. The key\nfactors our bounds depend on are the variance of the gradients (with respect to\nthe data distribution) and the local smoothness of the objective function along\nthe SGD path, and the sensitivity of the loss function to perturbations to the\nfinal output. Our key technical tool is combining the information-theoretic\ngeneralization bounds previously used for analyzing randomized variants of SGD\nwith a perturbation analysis of the iterates.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:00:34 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 19:08:50 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Neu", "Gergely", ""]]}, {"id": "2102.00937", "submitter": "Kwangjun Ahn", "authors": "Kwangjun Ahn, Felipe Suarez", "title": "Riemannian Perspective on Matrix Factorization", "comments": "23 pages, 6 figures. Comments would be appreciated!", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.DG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the non-convex matrix factorization approach to matrix completion\nvia Riemannian geometry. Based on an optimization formulation over a\nGrassmannian manifold, we characterize the landscape based on the notion of\nprincipal angles between subspaces. For the fully observed case, our results\nshow that there is a region in which the cost is geodesically convex, and\noutside of which all critical points are strictly saddle. We empirically study\nthe partially observed case based on our findings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:12:07 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ahn", "Kwangjun", ""], ["Suarez", "Felipe", ""]]}, {"id": "2102.00968", "submitter": "Jonathan Berrisch", "authors": "Jonathan Berrisch, Florian Ziel", "title": "CRPS Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combination and aggregation techniques can improve forecast accuracy\nsubstantially. This also holds for probabilistic forecasting methods where full\npredictive distributions are combined. There are several time-varying and\nadaptive weighting schemes like Bayesian model averaging (BMA). However, the\nperformance of different forecasters may vary not only over time but also in\nparts of the distribution. So one may be more accurate in the center of the\ndistributions, and other ones perform better in predicting the distribution's\ntails. Consequently, we introduce a new weighting procedure that considers both\nvarying performance across time and the distribution. We discuss pointwise\nonline aggregation algorithms that optimize with respect to the continuous\nranked probability score (CRPS). After analyzing the theoretical properties of\na fully adaptive Bernstein online aggregation (BOA) method, we introduce\nsmoothing procedures for pointwise CRPS learning. The properties are confirmed\nand discussed using simulation studies. Additionally, we illustrate the\nperformance in a forecasting study for carbon markets. In detail, we predict\nthe distribution of European emission allowance prices.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:54:05 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Berrisch", "Jonathan", ""], ["Ziel", "Florian", ""]]}, {"id": "2102.01117", "submitter": "Idan Amir", "authors": "Idan Amir, Tomer Koren, Roi Livni", "title": "SGD Generalizes Better Than GD (And Regularization Doesn't Help)", "comments": null, "journal-ref": "Conference on Learning Theory 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new separation result between the generalization performance of\nstochastic gradient descent (SGD) and of full-batch gradient descent (GD) in\nthe fundamental stochastic convex optimization model. While for SGD it is\nwell-known that $O(1/\\epsilon^2)$ iterations suffice for obtaining a solution\nwith $\\epsilon$ excess expected risk, we show that with the same number of\nsteps GD may overfit and emit a solution with $\\Omega(1)$ generalization error.\nMoreover, we show that in fact $\\Omega(1/\\epsilon^4)$ iterations are necessary\nfor GD to match the generalization performance of SGD, which is also tight due\nto recent work by Bassily et al. (2020). We further discuss how regularizing\nthe empirical risk minimized by GD essentially does not change the above\nresult, and revisit the concepts of stability, implicit bias and the role of\nthe learning algorithm in generalization.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 19:18:40 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 23:13:14 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Amir", "Idan", ""], ["Koren", "Tomer", ""], ["Livni", "Roi", ""]]}, {"id": "2102.01194", "submitter": "Hailin Sang", "authors": "G. Jogesh Babu, David Banks, Hyunsoon Cho, David Han, Hailin Sang and\n  Shouyi Wang", "title": "A Statistician Teaches Deep Learning", "comments": "19 pages, accepted by Journal of Statistical Theory and Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning (DL) has gained much attention and become increasingly popular\nin modern data science. Computer scientists led the way in developing deep\nlearning techniques, so the ideas and perspectives can seem alien to\nstatisticians. Nonetheless, it is important that statisticians become involved\n-- many of our students need this expertise for their careers. In this paper,\ndeveloped as part of a program on DL held at the Statistical and Applied\nMathematical Sciences Institute, we address this culture gap and provide tips\non how to teach deep learning to statistics graduate students. After some\nbackground, we list ways in which DL and statistical perspectives differ,\nprovide a recommended syllabus that evolved from teaching two iterations of a\nDL graduate course, offer examples of suggested homework assignments, give an\nannotated list of teaching resources, and discuss DL in the context of two\nresearch areas.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 04:59:43 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 23:09:23 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Babu", "G. Jogesh", ""], ["Banks", "David", ""], ["Cho", "Hyunsoon", ""], ["Han", "David", ""], ["Sang", "Hailin", ""], ["Wang", "Shouyi", ""]]}, {"id": "2102.01199", "submitter": "Rodney Sparapani", "authors": "Robert E. McCulloch, Rodney A. Sparapani, Brent R. Logan and\n  Purushottam W. Laud", "title": "Causal Inference with the Instrumental Variable Approach and Bayesian\n  Nonparametric Machine Learning", "comments": "33 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We provide a new flexible framework for inference with the instrumental\nvariable model. Rather than using linear specifications, functions\ncharacterizing the effects of instruments and other explanatory variables are\nestimated using machine learning via Bayesian Additive Regression Trees (BART).\nError terms and their distribution are inferred using Dirichlet Process\nmixtures. Simulated and real examples show that when the true functions are\nlinear, little is lost. But when nonlinearities are present, dramatic\nimprovements are obtained with virtually no manual tuning.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 21:55:19 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["McCulloch", "Robert E.", ""], ["Sparapani", "Rodney A.", ""], ["Logan", "Brent R.", ""], ["Laud", "Purushottam W.", ""]]}, {"id": "2102.01208", "submitter": "Akhilan Boopathy", "authors": "Akhilan Boopathy, Tsui-Wei Weng, Sijia Liu, Pin-Yu Chen, Gaoyuan\n  Zhang, Luca Daniel", "title": "Fast Training of Provably Robust Neural Networks by SingleProp", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have developed several methods of defending neural networks\nagainst adversarial attacks with certified guarantees. However, these\ntechniques can be computationally costly due to the use of certification during\ntraining. We develop a new regularizer that is both more efficient than\nexisting certified defenses, requiring only one additional forward propagation\nthrough a network, and can be used to train networks with similar certified\naccuracy. Through experiments on MNIST and CIFAR-10 we demonstrate improvements\nin training speed and comparable certified accuracy compared to\nstate-of-the-art certified defenses.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 22:12:51 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Boopathy", "Akhilan", ""], ["Weng", "Tsui-Wei", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Zhang", "Gaoyuan", ""], ["Daniel", "Luca", ""]]}, {"id": "2102.01229", "submitter": "Wonyoung Kim", "authors": "Wonyoung Kim, Gi-soo Kim, Myunghee Cho Paik", "title": "Doubly Robust Thompson Sampling for linear payoffs", "comments": "18pages including Supplementary Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenging aspect of the bandit problem is that a stochastic reward is\nobserved only for the chosen arm and the rewards of other arms remain missing.\nSince the arm choice depends on the past context and reward pairs, the contexts\nof chosen arms suffer from correlation and render the analysis difficult. We\npropose a novel multi-armed contextual bandit algorithm called Doubly Robust\n(DR) Thompson Sampling (TS) that applies the DR technique used in missing data\nliterature to TS. The proposed algorithm improves the bound of TS by a factor\nof $\\sqrt{d}$, where $d$ is the dimension of the context. A benefit of the\nproposed method is that it uses all the context data, chosen or not chosen,\nthus allowing to circumvent the technical definition of unsaturated arms used\nin theoretical analysis of TS. Empirical studies show the advantage of the\nproposed algorithm over TS.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 23:31:10 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Kim", "Wonyoung", ""], ["Kim", "Gi-soo", ""], ["Paik", "Myunghee Cho", ""]]}, {"id": "2102.01238", "submitter": "Veronica Tozzo", "authors": "Federico Ciech, Veronica Tozzo", "title": "Time Adaptive Gaussian Model", "comments": "15 pages, 1 figures, supplementary material for conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multivariate time series analysis is becoming an integral part of data\nanalysis pipelines. Understanding the individual time point connections between\ncovariates as well as how these connections change in time is non-trivial. To\nthis aim, we propose a novel method that leverages on Hidden Markov Models and\nGaussian Graphical Models -- Time Adaptive Gaussian Model (TAGM). Our model is\na generalization of state-of-the-art methods for the inference of temporal\ngraphical models, its formulation leverages on both aspects of these models\nproviding better results than current methods. In particular,it performs\npattern recognition by clustering data points in time; and, it finds\nprobabilistic (and possibly causal) relationships among the observed variables.\nCompared to current methods for temporal network inference, it reduces the\nbasic assumptions while still showing good inference performances.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 00:28:14 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 15:56:36 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ciech", "Federico", ""], ["Tozzo", "Veronica", ""]]}, {"id": "2102.01258", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Maryam Aliakbarpour, and Flavio P. Calmon", "title": "Local Differential Privacy Is Equivalent to Contraction of\n  $E_\\gamma$-Divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the local differential privacy (LDP) guarantees of a\nrandomized privacy mechanism via its contraction properties. We first show that\nLDP constraints can be equivalently cast in terms of the contraction\ncoefficient of the $E_\\gamma$-divergence. We then use this equivalent formula\nto express LDP guarantees of privacy mechanisms in terms of contraction\ncoefficients of arbitrary $f$-divergences. When combined with standard\nestimation-theoretic tools (such as Le Cam's and Fano's converse methods), this\nresult allows us to study the trade-off between privacy and utility in several\ntesting and minimax and Bayesian estimation problems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 02:18:12 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Aliakbarpour", "Maryam", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "2102.01302", "submitter": "Tao Sun", "authors": "Tao Sun, Dongsheng Li, Bao Wang", "title": "Stability and Generalization of the Decentralized Stochastic Gradient\n  Descent", "comments": null, "journal-ref": "AAAI-2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The stability and generalization of stochastic gradient-based methods provide\nvaluable insights into understanding the algorithmic performance of machine\nlearning models. As the main workhorse for deep learning, stochastic gradient\ndescent has received a considerable amount of studies. Nevertheless, the\ncommunity paid little attention to its decentralized variants. In this paper,\nwe provide a novel formulation of the decentralized stochastic gradient\ndescent. Leveraging this formulation together with (non)convex optimization\ntheory, we establish the first stability and generalization guarantees for the\ndecentralized stochastic gradient descent. Our theoretical results are built on\ntop of a few common and mild assumptions and reveal that the decentralization\ndeteriorates the stability of SGD for the first time. We verify our theoretical\nfindings by using a variety of decentralized settings and benchmark machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 04:23:23 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 12:40:12 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 01:24:35 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Sun", "Tao", ""], ["Li", "Dongsheng", ""], ["Wang", "Bao", ""]]}, {"id": "2102.01391", "submitter": "Bjarne Grimstad", "authors": "Bjarne Grimstad, Mathilde Hotvedt, Anders T. Sandnes, Odd\n  Kolbj{\\o}rnsen, Lars S. Imsland", "title": "Bayesian Neural Networks for Virtual Flow Metering: An Empirical Study", "comments": "34 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have presented promising results from the application of machine\nlearning (ML) to the modeling of flow rates in oil and gas wells. Encouraging\nresults and advantageous properties of ML models, such as computationally cheap\nevaluation and ease of calibration to new data, have sparked optimism for the\ndevelopment of data-driven virtual flow meters (VFMs). Data-driven VFMs are\ndeveloped in the small data regime, where it is important to question the\nuncertainty and robustness of models. The modeling of uncertainty may help to\nbuild trust in models, which is a prerequisite for industrial applications. The\ncontribution of this paper is the introduction of a probabilistic VFM based on\nBayesian neural networks. Uncertainty in the model and measurements is\ndescribed, and the paper shows how to perform approximate Bayesian inference\nusing variational inference. The method is studied by modeling on a large and\nheterogeneous dataset, consisting of 60 wells across five different oil and gas\nassets. The predictive performance is analyzed on historical and future test\ndata, where an average error of 4-6% and 8-13% is achieved for the 50% best\nperforming models, respectively. Variational inference appears to provide more\nrobust predictions than the reference approach on future data. Prediction\nperformance and uncertainty calibration is explored in detail and discussed in\nlight of four data challenges. The findings motivate the development of\nalternative strategies to improve the robustness of data-driven VFMs.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 09:05:19 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 07:02:25 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 09:20:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Grimstad", "Bjarne", ""], ["Hotvedt", "Mathilde", ""], ["Sandnes", "Anders T.", ""], ["Kolbj\u00f8rnsen", "Odd", ""], ["Imsland", "Lars S.", ""]]}, {"id": "2102.01419", "submitter": "Pedro Abdalla Teixeira", "authors": "Pedro Abdalla and Afonso S. Bandeira", "title": "Community Detection with a Subsampled Semidefinite Program", "comments": "7 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semidefinite programming is an important tool to tackle several problems in\ndata science and signal processing, including clustering and community\ndetection. However, semidefinite programs are often slow in practice, so speed\nup techniques such as sketching are often considered. In the context of\ncommunity detection in the stochastic block model, Mixon and Xie [9] have\nrecently proposed a sketching framework in which a semidefinite program is\nsolved only on a subsampled subgraph of the network, giving rise to significant\ncomputational savings. In this short paper, we provide a positive answer to a\nconjecture of Mixon and Xie about the statistical limits of this technique for\nthe stochastic block model with two balanced communities.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 10:31:57 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 16:53:16 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Abdalla", "Pedro", ""], ["Bandeira", "Afonso S.", ""]]}, {"id": "2102.01424", "submitter": "Vladim\\'ir Hol\\'y", "authors": "Ond\\v{r}ej Sokol and Vladim\\'ir Hol\\'y", "title": "Clustering with Penalty for Joint Occurrence of Objects: Computational\n  Aspects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of Hol\\'y, Sokol and \\v{C}ern\\'y (Applied Soft Computing, 2017,\nVol. 60, p. 752-762) clusters objects based on their incidence in a large\nnumber of given sets. The idea is to minimize the occurrence of multiple\nobjects from the same cluster in the same set. In the current paper, we study\ncomputational aspects of the method. First, we prove that the problem of\nfinding the optimal clustering is NP-hard. Second, to numerically find a\nsuitable clustering, we propose to use the genetic algorithm augmented by a\nrenumbering procedure, a fast task-specific local search heuristic and an\ninitial solution based on a simplified model. Third, in a simulation study, we\ndemonstrate that our improvements of the standard genetic algorithm\nsignificantly enhance its computational performance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 10:39:27 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Sokol", "Ond\u0159ej", ""], ["Hol\u00fd", "Vladim\u00edr", ""]]}, {"id": "2102.01432", "submitter": "Aoxue Chen", "authors": "Aoxue Chen, Guang Lin", "title": "Robust data-driven discovery of partial differential equations with\n  time-dependent coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a robust Bayesian sparse learning algorithm based on\nBayesian group Lasso with spike and slab priors for the discovery of partial\ndifferential equations with variable coefficients. Using the samples draw from\nthe posterior distribution with a Gibbs sampler, we are able to estimate the\nvalues of coefficients, together with their standard errors and confidence\nintervals. Apart from constructing the error bars, uncertainty quantification\ncan also be employed for designing new criteria of model selection and\nthreshold setting. This enables our method more adjustable and robust in\nlearning equations with time-dependent coefficients. Three criteria are\nintroduced for model selection and threshold setting to identify the correct\nterms: the root mean square, total error bar, and group error bar. Moreover,\nthree noise filters are integrated with the robust Bayesian sparse learning\nalgorithm for better results with larger noise. Numerical results demonstrate\nthat our method is more robust than sequential grouped threshold ridge\nregression and group Lasso in noisy situations through three examples.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 11:05:34 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Aoxue", ""], ["Lin", "Guang", ""]]}, {"id": "2102.01466", "submitter": "Anthony Devaux", "authors": "Anthony Devaux (BPH), Robin Genuer (BPH, SISTM), Karine P\\'er\\`es\n  (BPH), C\\'ecile Proust-Lima (BPH)", "title": "Individual dynamic prediction of clinical endpoint from large\n  dimensional longitudinal biomarker history: a landmark approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The individual data collected throughout patient follow-up constitute crucial\ninformation for assessing the risk of a clinical event, and eventually for\nadapting a therapeutic strategy. Joint models and landmark models have been\nproposed to compute individual dynamic predictions from repeated measures to\none or two markers. However, they hardly extend to the case where the complete\npatient history includes much more repeated markers possibly. Our objective was\nthus to propose a solution for the dynamic prediction of a health event that\nmay exploit repeated measures of a possibly large number of markers. We\ncombined a landmark approach extended to endogenous markers history with\nmachine learning methods adapted to survival data. Each marker trajectory is\nmodeled using the information collected up to landmark time, and summary\nvariables that best capture the individual trajectories are derived. These\nsummaries and additional covariates are then included in different prediction\nmethods. To handle a possibly large dimensional history, we rely on machine\nlearning methods adapted to survival data, namely regularized regressions and\nrandom survival forests, to predict the event from the landmark time, and we\nshow how they can be combined into a superlearner. Then, the performances are\nevaluated by cross-validation using estimators of Brier Score and the area\nunder the Receiver Operating Characteristic curve adapted to censored data. We\ndemonstrate in a simulation study the benefits of machine learning survival\nmethods over standard survival models, especially in the case of numerous\nand/or nonlinear relationships between the predictors and the event. We then\napplied the methodology in two prediction contexts: a clinical context with the\nprediction of death for patients with primary biliary cholangitis, and a public\nhealth context with the prediction of death in the general elderly population\nat different ages. Our methodology, implemented in R, enables the prediction of\nan event using the entire longitudinal patient history, even when the number of\nrepeated markers is large. Although introduced with mixed models for the\nrepeated markers and methods for a single right censored time-to-event, our\nmethod can be used with any other appropriate modeling technique for the\nmarkers and can be easily extended to competing risks setting.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 12:36:18 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Devaux", "Anthony", "", "BPH"], ["Genuer", "Robin", "", "BPH, SISTM"], ["P\u00e9r\u00e8s", "Karine", "", "BPH"], ["Proust-Lima", "C\u00e9cile", "", "BPH"]]}, {"id": "2102.01496", "submitter": "Hamed Jalali", "authors": "Hamed Jalali, Martin Pawelczyk, Gjergji Kasneci", "title": "Gaussian Experts Selection using Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Local approximations are popular methods to scale Gaussian processes (GPs) to\nbig data. Local approximations reduce time complexity by dividing the original\ndataset into subsets and training a local expert on each subset. Aggregating\nthe experts' prediction is done assuming either conditional dependence or\nindependence between the experts. Imposing the \\emph{conditional independence\nassumption} (CI) between the experts renders the aggregation of different\nexpert predictions time efficient at the cost of poor uncertainty\nquantification. On the other hand, modeling dependent experts can provide\nprecise predictions and uncertainty quantification at the expense of\nimpractically high computational costs. By eliminating weak experts via a\ntheory-guided expert selection step, we substantially reduce the computational\ncost of aggregating dependent experts while ensuring calibrated uncertainty\nquantification. We leverage techniques from the literature on undirected\ngraphical models, using sparse precision matrices that encode conditional\ndependencies between experts to select the most important experts. Moreov\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 14:12:11 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 11:55:06 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Jalali", "Hamed", ""], ["Pawelczyk", "Martin", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "2102.01514", "submitter": "Charline Le Lan", "authors": "Charline Le Lan, Marc G. Bellemare, Pablo Samuel Castro", "title": "Metrics and continuity in reinforcement learning", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most practical applications of reinforcement learning, it is untenable to\nmaintain direct estimates for individual states; in continuous-state systems,\nit is impossible. Instead, researchers often leverage state similarity (whether\nexplicitly or implicitly) to build models that can generalize well from a\nlimited set of samples. The notion of state similarity used, and the\nneighbourhoods and topologies they induce, is thus of crucial importance, as it\nwill directly affect the performance of the algorithms. Indeed, a number of\nrecent works introduce algorithms assuming the existence of \"well-behaved\"\nneighbourhoods, but leave the full specification of such topologies for future\nwork. In this paper we introduce a unified formalism for defining these\ntopologies through the lens of metrics. We establish a hierarchy amongst these\nmetrics and demonstrate their theoretical implications on the Markov Decision\nProcess specifying the reinforcement learning problem. We complement our\ntheoretical results with empirical evaluations showcasing the differences\nbetween the metrics considered.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 14:30:41 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lan", "Charline Le", ""], ["Bellemare", "Marc G.", ""], ["Castro", "Pablo Samuel", ""]]}, {"id": "2102.01567", "submitter": "Zaiwei Chen", "authors": "Zaiwei Chen, Siva Theja Maguluri, Sanjay Shakkottai, and Karthikeyan\n  Shanmugam", "title": "A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous\n  Q-Learning and TD-Learning Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops an unified framework to study finite-sample convergence\nguarantees of a large class of value-based asynchronous reinforcement learning\n(RL) algorithms. We do this by first reformulating the RL algorithms as\n\\textit{Markovian Stochastic Approximation} (SA) algorithms to solve\nfixed-point equations. We then develop a Lyapunov analysis and derive\nmean-square error bounds on the convergence of the Markovian SA. Based on this\nresult, we establish finite-sample mean-square convergence bounds for\nasynchronous RL algorithms such as $Q$-learning, $n$-step TD, TD$(\\lambda)$,\nand off-policy TD algorithms including V-trace. As a by-product, by analyzing\nthe convergence bounds of $n$-step TD and TD$(\\lambda)$, we provide theoretical\ninsights into the bias-variance trade-off, i.e., efficiency of bootstrapping in\nRL. This was first posed as an open problem in (Sutton, 1999).\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 15:48:19 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:59:52 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 20:20:47 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Chen", "Zaiwei", ""], ["Maguluri", "Siva Theja", ""], ["Shakkottai", "Sanjay", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "2102.01570", "submitter": "Sitan Chen", "authors": "Sitan Chen, Zhao Song, Runzhou Tao, Ruizhe Zhang", "title": "Symmetric Boolean Factor Analysis with Applications to InstaHide", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we examine the security of InstaHide, a recently proposed scheme\nfor distributed learning (Huang et al.). A number of recent works have given\nreconstruction attacks for InstaHide in various regimes by leveraging an\nintriguing connection to the following matrix factorization problem: given the\nGram matrix of a collection of m random k-sparse Boolean vectors in {0,1}^r,\nrecover the vectors (up to the trivial symmetries). Equivalently, this can be\nthought of as a sparse, symmetric variant of the well-studied problem of\nBoolean factor analysis, or as an average-case version of the classic problem\nof recovering a k-uniform hypergraph from its line graph.\n  As previous algorithms either required m to be exponentially large in k or\nonly applied to k = 2, they left open the question of whether InstaHide\npossesses some form of \"fine-grained security\" against reconstruction attacks\nfor moderately large k. In this work, we answer this in the negative by giving\na simple O(m^{\\omega + 1}) time algorithm for the above matrix factorization\nproblem. Our algorithm, based on tensor decomposition, only requires m to be at\nleast quasi-linear in r. We complement this result with a quasipolynomial-time\nalgorithm for a worst-case setting of the problem where the collection of\nk-sparse vectors is chosen arbitrarily.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 15:52:52 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Sitan", ""], ["Song", "Zhao", ""], ["Tao", "Runzhou", ""], ["Zhang", "Ruizhe", ""]]}, {"id": "2102.01577", "submitter": "Alexis Bellot", "authors": "Alexis Bellot, Mihaela van der Schaar", "title": "Policy Analysis using Synthetic Controls in Continuous-Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual estimation using synthetic controls is one of the most\nsuccessful recent methodological developments in causal inference. Despite its\npopularity, the current description only considers time series aligned across\nunits and synthetic controls expressed as linear combinations of observed\ncontrol units. We propose a continuous-time alternative that models the latent\ncounterfactual path explicitly using the formalism of controlled differential\nequations. This model is directly applicable to the general setting of\nirregularly-aligned multivariate time series and may be optimized in rich\nfunction spaces -- thereby improving on some limitations of existing\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 16:07:39 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Bellot", "Alexis", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2102.01621", "submitter": "Luca Venturi", "authors": "Luca Venturi, Samy Jelassi, Tristan Ozuch, Joan Bruna", "title": "Depth separation beyond radial functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional depth separation results for neural networks show that\ncertain functions can be efficiently approximated by two-hidden-layer networks\nbut not by one-hidden-layer ones in high-dimensions $d$. Existing results of\nthis type mainly focus on functions with an underlying radial or\none-dimensional structure, which are usually not encountered in practice. The\nfirst contribution of this paper is to extend such results to a more general\nclass of functions, namely functions with piece-wise oscillatory structure, by\nbuilding on the proof strategy of (Eldan and Shamir, 2016). We complement these\nresults by showing that, if the domain radius and the rate of oscillation of\nthe objective function are constant, then approximation by one-hidden-layer\nnetworks holds at a $\\mathrm{poly}(d)$ rate for any fixed error threshold.\n  A common theme in the proof of such results is the fact that one-hidden-layer\nnetworks fail to approximate high-energy functions whose Fourier representation\nis spread in the domain. On the other hand, existing approximation results of a\nfunction by one-hidden-layer neural networks rely on the function having a\nsparse Fourier representation. The choice of the domain also represents a\nsource of gaps between upper and lower approximation bounds. Focusing on a\nfixed approximation domain, namely the sphere $\\mathbb{S}^{d-1}$ in dimension\n$d$, we provide a characterization of both functions which are efficiently\napproximable by one-hidden-layer networks and of functions which are provably\nnot, in terms of their Fourier expansion.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 17:25:02 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 17:49:56 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Venturi", "Luca", ""], ["Jelassi", "Samy", ""], ["Ozuch", "Tristan", ""], ["Bruna", "Joan", ""]]}, {"id": "2102.01646", "submitter": "Steve Hanneke", "authors": "Steve Hanneke, Roi Livni, and Shay Moran", "title": "Online Learning with Simple Predictors and a Combinatorial\n  Characterization of Minimax in 0/1 Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Which classes can be learned properly in the online model? -- that is, by an\nalgorithm that at each round uses a predictor from the concept class. While\nthere are simple and natural cases where improper learning is necessary, it is\nnatural to ask how complex must the improper predictors be in such cases. Can\none always achieve nearly optimal mistake/regret bounds using \"simple\"\npredictors?\n  In this work, we give a complete characterization of when this is possible,\nthus settling an open problem which has been studied since the pioneering works\nof Angluin (1987) and Littlestone (1988). More precisely, given any concept\nclass C and any hypothesis class H, we provide nearly tight bounds (up to a log\nfactor) on the optimal mistake bounds for online learning C using predictors\nfrom H. Our bound yields an exponential improvement over the previously best\nknown bound by Chase and Freitag (2020).\n  As applications, we give constructive proofs showing that (i) in the\nrealizable setting, a near-optimal mistake bound (up to a constant factor) can\nbe attained by a sparse majority-vote of proper predictors, and (ii) in the\nagnostic setting, a near-optimal regret bound (up to a log factor) can be\nattained by a randomized proper algorithm.\n  A technical ingredient of our proof which may be of independent interest is a\ngeneralization of the celebrated Minimax Theorem (von Neumann, 1928) for binary\nzero-sum games. A simple game which fails to satisfy Minimax is \"Guess the\nLarger Number\", where each player picks a number and the larger number wins.\nThe payoff matrix is infinite triangular. We show this is the only obstruction:\nif a game does not contain triangular submatrices of unbounded sizes then the\nMinimax Theorem holds. This generalizes von Neumann's Minimax Theorem by\nremoving requirements of finiteness (or compactness), and captures precisely\nthe games of interest in online learning.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:02:01 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hanneke", "Steve", ""], ["Livni", "Roi", ""], ["Moran", "Shay", ""]]}, {"id": "2102.01659", "submitter": "Tobias Haug", "authors": "Tobias Haug, Kishor Bharti, M. S. Kim", "title": "Capacity and quantum geometry of parametrized quantum circuits", "comments": "10 pages, 9 figures. Code available at\n  https://github.com/txhaug/quantum-geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To harness the potential of noisy intermediate-scale quantum devices, it is\nparamount to find the best type of circuits to run hybrid quantum-classical\nalgorithms. Key candidates are parametrized quantum circuits that can be\neffectively implemented on current devices. Here, we evaluate the capacity and\ntrainability of these circuits using the geometric structure of the parameter\nspace via the effective quantum dimension, which reveals the expressive power\nof circuits in general as well as of particular initialization strategies. We\nassess the representation power of various popular circuit types and find\nstriking differences depending on the type of entangling gates used. Particular\ncircuits are characterized by scaling laws in their expressiveness. We identify\na transition in the quantum geometry of the parameter space, which leads to a\ndecay of the quantum natural gradient for deep circuits. For shallow circuits,\nthe quantum natural gradient can be orders of magnitude larger in value\ncompared to the regular gradient; however, both of them can suffer from\nvanishing gradients. By tuning a fixed set of circuit parameters to randomized\nones, we find a region where the circuit is expressive, but does not suffer\nfrom barren plateaus, hinting at a good way to initialize circuits. Our results\nenhance the understanding of parametrized quantum circuits for improving\nvariational quantum algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:16:57 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Haug", "Tobias", ""], ["Bharti", "Kishor", ""], ["Kim", "M. S.", ""]]}, {"id": "2102.01691", "submitter": "Adri\\`a Garriga-Alonso", "authors": "Adri\\`a Garriga-Alonso and Vincent Fortuin", "title": "Exact Langevin Dynamics with Stochastic Gradients", "comments": "13 pages, 2 figures. Accepted to the 3rd Symposium on Advances in\n  Approximate Bayesian Inference (AABI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Stochastic gradient Markov Chain Monte Carlo algorithms are popular samplers\nfor approximate inference, but they are generally biased. We show that many\nrecent versions of these methods (e.g. Chen et al. (2014)) cannot be corrected\nusing Metropolis-Hastings rejection sampling, because their acceptance\nprobability is always zero. We can fix this by employing a sampler with\nrealizable backwards trajectories, such as Gradient-Guided Monte Carlo\n(Horowitz, 1991), which generalizes stochastic gradient Langevin dynamics\n(Welling and Teh, 2011) and Hamiltonian Monte Carlo. We show that this sampler\ncan be used with stochastic gradients, yielding nonzero acceptance\nprobabilities, which can be computed even across multiple steps.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:59:31 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Garriga-Alonso", "Adri\u00e0", ""], ["Fortuin", "Vincent", ""]]}, {"id": "2102.01729", "submitter": "Adam B. Block", "authors": "Adam Block, Yuval Dagan, and Sasha Rakhlin", "title": "Majorizing Measures, Sequential Complexities, and Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the technique of generic chaining and majorizing measures for\ncontrolling sequential Rademacher complexity. We relate majorizing measures to\nthe notion of fractional covering numbers, which we show to be dominated in\nterms of sequential scale-sensitive dimensions in a horizon-independent way,\nand, under additional complexity assumptions establish a tight control on\nworst-case sequential Rademacher complexity in terms of the integral of\nsequential scale-sensitive dimension. Finally, we establish a tight contraction\ninequality for worst-case sequential Rademacher complexity. The above\nconstitutes the resolution of a number of outstanding open problems in\nextending the classical theory of empirical processes to the sequential case,\nand, in turn, establishes sharp results for online learning.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 19:52:58 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Block", "Adam", ""], ["Dagan", "Yuval", ""], ["Rakhlin", "Sasha", ""]]}, {"id": "2102.01748", "submitter": "Ming Yin", "authors": "Ming Yin, Yu Bai, Yu-Xiang Wang", "title": "Near-Optimal Offline Reinforcement Learning via Double Variance\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of offline reinforcement learning (RL) -- a\nwell-motivated setting of RL that aims at policy optimization using only\nhistorical data. Despite its wide applicability, theoretical understandings of\noffline RL, such as its optimal sample complexity, remain largely open even in\nbasic settings such as \\emph{tabular} Markov Decision Processes (MDPs).\n  In this paper, we propose Off-Policy Double Variance Reduction (OPDVR), a new\nvariance reduction based algorithm for offline RL. Our main result shows that\nOPDVR provably identifies an $\\epsilon$-optimal policy with\n$\\widetilde{O}(H^2/d_m\\epsilon^2)$ episodes of offline data in the\nfinite-horizon stationary transition setting, where $H$ is the horizon length\nand $d_m$ is the minimal marginal state-action distribution induced by the\nbehavior policy. This improves over the best known upper bound by a factor of\n$H$. Moreover, we establish an information-theoretic lower bound of\n$\\Omega(H^2/d_m\\epsilon^2)$ which certifies that OPDVR is optimal up to\nlogarithmic factors. Lastly, we show that OPDVR also achieves rate-optimal\nsample complexity under alternative settings such as the finite-horizon MDPs\nwith non-stationary transitions and the infinite horizon MDPs with discounted\nrewards.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 20:47:35 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Yin", "Ming", ""], ["Bai", "Yu", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2102.01759", "submitter": "Hideyuki Miyahara", "authors": "Hideyuki Miyahara and Vwani Roychowdhury", "title": "Ansatz-Independent Variational Quantum Classifier", "comments": "95 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paradigm of variational quantum classifiers (VQCs) encodes\n\\textit{classical information} as quantum states, followed by quantum\nprocessing and then measurements to generate classical predictions. VQCs are\npromising candidates for efficient utilization of a near-term quantum device:\nclassifiers involving $M$-dimensional datasets can be implemented with only\n$\\lceil \\log_2 M \\rceil$ qubits by using an amplitude encoding. A general\nframework for designing and training VQCs, however, has not been proposed, and\na fundamental understanding of its power and analytical relationships with\nclassical classifiers are not well understood. An encouraging specific\nembodiment of VQCs, quantum circuit learning (QCL), utilizes an ansatz: it\nexpresses the quantum evolution operator as a circuit with a predetermined\ntopology and parametrized gates; training involves learning the gate parameters\nthrough optimization. In this letter, we first address the open questions about\nVQCs and then show that they, including QCL, fit inside the well-known kernel\nmethod. Based on such correspondence, we devise a design framework of efficient\nansatz-independent VQCs, which we call the unitary kernel method (UKM): it\ndirectly optimizes the unitary evolution operator in a VQC. Thus, we show that\nthe performance of QCL is bounded from above by the UKM. Next, we propose a\nvariational circuit realization (VCR) for designing efficient quantum circuits\nfor a given unitary operator. By combining the UKM with the VCR, we establish\nan efficient framework for constructing high-performing circuits. We finally\nbenchmark the relatively superior performance of the UKM and the VCR via\nextensive numerical simulations on multiple datasets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 21:25:39 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Miyahara", "Hideyuki", ""], ["Roychowdhury", "Vwani", ""]]}, {"id": "2102.01934", "submitter": "Loc Hoang Tran", "authors": "Nguyen Trinh Vu Dang, Loc Tran, Linh Tran", "title": "Noise-robust classification with hypergraph neural network", "comments": "9 page, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents a novel version of the hypergraph neural network method.\nThis method is utilized to solve the noisy label learning problem. First, we\napply the PCA dimensional reduction technique to the feature matrices of the\nimage datasets in order to reduce the \"noise\" and the redundant features in the\nfeature matrices of the image datasets and to reduce the runtime constructing\nthe hypergraph of the hypergraph neural network method. Then, the classic\ngraph-based semi-supervised learning method, the classic hypergraph based\nsemi-supervised learning method, the graph neural network, the hypergraph\nneural network, and our proposed hypergraph neural network are employed to\nsolve the noisy label learning problem. The accuracies of these five methods\nare evaluated and compared. Experimental results show that the hypergraph\nneural network methods achieve the best performance when the noise level\nincreases. Moreover, the hypergraph neural network methods are at least as good\nas the graph neural network.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 08:34:53 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Dang", "Nguyen Trinh Vu", ""], ["Tran", "Loc", ""], ["Tran", "Linh", ""]]}, {"id": "2102.01938", "submitter": "Prafulla Chandra Mr", "authors": "Prafulla Chandra, Andrew Thangaraj and Nived Rajaraman", "title": "Missing Mass of Rank-2 Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Estimation of missing mass with the popular Good-Turing (GT) estimator is\nwell-understood in the case where samples are independent and identically\ndistributed (iid). In this article, we consider the same problem when the\nsamples come from a stationary Markov chain with a rank-2 transition matrix,\nwhich is one of the simplest extensions of the iid case. We develop an upper\nbound on the absolute bias of the GT estimator in terms of the spectral gap of\nthe chain and a tail bound on the occupancy of states. Borrowing tail bounds\nfrom known concentration results for Markov chains, we evaluate the bound using\nother parameters of the chain. The analysis, supported by simulations, suggests\nthat, for rank-2 irreducible chains, the GT estimator has bias and mean-squared\nerror falling with number of samples at a rate that depends loosely on the\nconnectivity of the states in the chain.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 08:38:21 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 09:22:02 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Chandra", "Prafulla", ""], ["Thangaraj", "Andrew", ""], ["Rajaraman", "Nived", ""]]}, {"id": "2102.01956", "submitter": "Alperen Karan", "authors": "Alperen Karan, Atabey Kaygun", "title": "Time Series Classification via Topological Data Analysis", "comments": "31 pages, 20 figures", "journal-ref": null, "doi": "10.1016/j.eswa.2021.115326", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop topological data analysis methods for\nclassification tasks on univariate time series. As an application, we perform\nbinary and ternary classification tasks on two public datasets that consist of\nphysiological signals collected under stress and non-stress conditions. We\naccomplish our goal by using persistent homology to engineer stable topological\nfeatures after we use a time delay embedding of the signals and perform a\nsubwindowing instead of using windows of fixed length. The combination of\nmethods we use can be applied to any univariate time series and in this\napplication allows us to reduce noise and use long window sizes without\nincurring an extra computational cost. We then use machine learning models on\nthe features we algorithmically engineered to obtain higher accuracies with\nfewer features.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:09:05 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 21:15:35 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Karan", "Alperen", ""], ["Kaygun", "Atabey", ""]]}, {"id": "2102.01982", "submitter": "Michael Fop", "authors": "Michael Fop, Pierre-Alexandre Mattei, Charles Bouveyron, Thomas\n  Brendan Murphy", "title": "Unobserved classes and extra variables in high-dimensional discriminant\n  analysis", "comments": "29 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In supervised classification problems, the test set may contain data points\nbelonging to classes not observed in the learning phase. Moreover, the same\nunits in the test data may be measured on a set of additional variables\nrecorded at a subsequent stage with respect to when the learning sample was\ncollected. In this situation, the classifier built in the learning phase needs\nto adapt to handle potential unknown classes and the extra dimensions. We\nintroduce a model-based discriminant approach, Dimension-Adaptive Mixture\nDiscriminant Analysis (D-AMDA), which can detect unobserved classes and adapt\nto the increasing dimensionality. Model estimation is carried out via a full\ninductive approach based on an EM algorithm. The method is then embedded in a\nmore general framework for adaptive variable selection and classification\nsuitable for data of large dimensions. A simulation study and an artificial\nexperiment related to classification of adulterated honey samples are used to\nvalidate the ability of the proposed framework to deal with complex situations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 10:01:52 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Fop", "Michael", ""], ["Mattei", "Pierre-Alexandre", ""], ["Bouveyron", "Charles", ""], ["Murphy", "Thomas Brendan", ""]]}, {"id": "2102.02016", "submitter": "Gholamali Aminian", "authors": "Gholamali Aminian, Laura Toni, Miguel R. D. Rodrigues", "title": "Information-Theoretic Bounds on the Moments of the Generalization Error\n  of Learning Algorithms", "comments": "7 pages, 3 figures, to be published in ISIT 2021. Some typos are\n  fixed in the new version. The Re'yni divergence results are added in the new\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Generalization error bounds are critical to understanding the performance of\nmachine learning models. In this work, building upon a new bound of the\nexpected value of an arbitrary function of the population and empirical risk of\na learning algorithm, we offer a more refined analysis of the generalization\nbehaviour of a machine learning models based on a characterization of (bounds)\nto their generalization error moments. We discuss how the proposed bounds --\nwhich also encompass new bounds to the expected generalization error -- relate\nto existing bounds in the literature. We also discuss how the proposed\ngeneralization error moment bounds can be used to construct new generalization\nerror high-probability bounds.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 11:38:00 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 23:39:01 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Aminian", "Gholamali", ""], ["Toni", "Laura", ""], ["Rodrigues", "Miguel R. D.", ""]]}, {"id": "2102.02029", "submitter": "Dan Garber", "authors": "Dan Garber, Noam Wolf", "title": "Frank-Wolfe with a Nearest Extreme Point Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider variants of the classical Frank-Wolfe algorithm for constrained\nsmooth convex minimization, that instead of access to the standard oracle for\nminimizing a linear function over the feasible set, have access to an oracle\nthat can find an extreme point of the feasible set that is closest in Euclidean\ndistance to a given vector. We first show that for many feasible sets of\ninterest, such an oracle can be implemented with the same complexity as the\nstandard linear optimization oracle. We then show that with such an oracle we\ncan design new Frank-Wolfe variants which enjoy significantly improved\ncomplexity bounds in case the set of optimal solutions lies in the convex hull\nof a subset of extreme points with small diameter (e.g., a low-dimensional face\nof a polytope). In particular, for many $0\\text{--}1$ polytopes, under\nquadratic growth and strict complementarity conditions, we obtain the first\nlinearly convergent variant with rate that depends only on the dimension of the\noptimal face and not on the ambient dimension.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 12:20:24 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Garber", "Dan", ""], ["Wolf", "Noam", ""]]}, {"id": "2102.02049", "submitter": "Gellert Weisz", "authors": "Gell\\'ert Weisz, Philip Amortila, Barnab\\'as Janzer, Yasin\n  Abbasi-Yadkori, Nan Jiang, Csaba Szepesv\\'ari", "title": "On Query-efficient Planning in MDPs under Linear Realizability of the\n  Optimal State-value Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider local planning in fixed-horizon MDPs with a generative model\nunder the assumption that the optimal value function lies close to the span of\na feature map. The generative model provides a local access to the MDP: The\nplanner can ask for random transitions from previously returned states and\narbitrary actions, and features are only accessible for states that are\nencountered in this process. As opposed to previous work (e.g. Lattimore et al.\n(2020)) where linear realizability of all policies was assumed, we consider the\nsignificantly relaxed assumption of a single linearly realizable\n(deterministic) policy. A recent lower bound by Weisz et al. (2020) established\nthat the related problem when the action-value function of the optimal policy\nis linearly realizable requires an exponential number of queries, either in $H$\n(the horizon of the MDP) or $d$ (the dimension of the feature mapping). Their\nconstruction crucially relies on having an exponentially large action set. In\ncontrast, in this work, we establish that poly$(H,d)$ planning is possible with\nstate value function realizability whenever the action set has a constant size.\nIn particular, we present the TensorPlan algorithm which uses\npoly$((dH/\\delta)^A)$ simulator queries to find a $\\delta$-optimal policy\nrelative to any deterministic policy for which the value function is linearly\nrealizable with some bounded parameter. This is the first algorithm to give a\npolynomial query complexity guarantee using only linear-realizability of a\nsingle competing value function. Whether the computation cost is similarly\nbounded remains an open question. We extend the upper bound to the\nnear-realizable case and to the infinite-horizon discounted setup. We also\npresent a lower bound in the infinite-horizon episodic setting: Planners that\nachieve constant suboptimality need exponentially many queries, either in $d$\nor the number of actions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 13:23:15 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 13:53:07 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 11:37:09 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Amortila", "Philip", ""], ["Janzer", "Barnab\u00e1s", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Jiang", "Nan", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2102.02087", "submitter": "Marie Roald", "authors": "Marie Roald, Carla Schenker, Jeremy E. Cohen, Evrim Acar", "title": "PARAFAC2 AO-ADMM: Constraints in all modes", "comments": "5 pages, 4 figures, submitted to EUSIPCO21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PARAFAC2 model provides a flexible alternative to the popular\nCANDECOMP/PARAFAC (CP) model for tensor decompositions. Unlike CP, PARAFAC2\nallows factor matrices in one mode (i.e., evolving mode) to change across\ntensor slices, which has proven useful for applications in different domains\nsuch as chemometrics, and neuroscience. However, the evolving mode of the\nPARAFAC2 model is traditionally modelled implicitly, which makes it challenging\nto regularise it. Currently, the only way to apply regularisation on that mode\nis with a flexible coupling approach, which finds the solution through\nregularised least-squares subproblems. In this work, we instead propose an\nalternating direction method of multipliers (ADMM)-based algorithm for fitting\nPARAFAC2 and widen the possible regularisation penalties to any proximable\nfunction. Our numerical experiments demonstrate that the proposed ADMM-based\napproach for PARAFAC2 can accurately recover the underlying components from\nsimulated data while being both computationally efficient and flexible in terms\nof imposing constraints.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 14:42:18 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Roald", "Marie", ""], ["Schenker", "Carla", ""], ["Cohen", "Jeremy E.", ""], ["Acar", "Evrim", ""]]}, {"id": "2102.02090", "submitter": "Michael Franklin Mbouopda", "authors": "Michael Franklin Mbouopda and Engelbert Mephu Nguifo", "title": "Uncertain Time Series Classification With Shapelet Transform", "comments": "2020 International Conference on Data Mining Workshops, Sorrento,\n  Italy, November 17-20, 2020", "journal-ref": "2020 IEEE International Conference on Data Mining Workshops\n  (ICDMW)", "doi": "10.1109/ICDMW51313.2020.00044", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series classification is a task that aims at classifying chronological\ndata. It is used in a diverse range of domains such as meteorology, medicine\nand physics. In the last decade, many algorithms have been built to perform\nthis task with very appreciable accuracy. However, applications where time\nseries have uncertainty has been under-explored. Using uncertainty propagation\ntechniques, we propose a new uncertain dissimilarity measure based on Euclidean\ndistance. We then propose the uncertain shapelet transform algorithm for the\nclassification of uncertain time series. The large experiments we conducted on\nstate of the art datasets show the effectiveness of our contribution. The\nsource code of our contribution and the datasets we used are all available on a\npublic repository.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 14:46:01 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mbouopda", "Michael Franklin", ""], ["Nguifo", "Engelbert Mephu", ""]]}, {"id": "2102.02145", "submitter": "Omar Montasser", "authors": "Omar Montasser, Steve Hanneke, Nathan Srebro", "title": "Adversarially Robust Learning with Unknown Perturbation Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of learning predictors that are robust to adversarial\nexamples with respect to an unknown perturbation set, relying instead on\ninteraction with an adversarial attacker or access to attack oracles, examining\ndifferent models for such interactions. We obtain upper bounds on the sample\ncomplexity and upper and lower bounds on the number of required interactions,\nor number of successful attacks, in different interaction models, in terms of\nthe VC and Littlestone dimensions of the hypothesis class of predictors, and\nwithout any assumptions on the perturbation set.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 17:01:39 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Montasser", "Omar", ""], ["Hanneke", "Steve", ""], ["Srebro", "Nathan", ""]]}, {"id": "2102.02167", "submitter": "Amit Attia", "authors": "Amit Attia and Tomer Koren", "title": "Algorithmic Instabilities of Accelerated Gradient Descent", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the algorithmic stability of Nesterov's accelerated gradient method.\nFor convex quadratic objectives, Chen et al. (2018) proved that the uniform\nstability of the method grows quadratically with the number of optimization\nsteps, and conjectured that the same is true for the general convex and smooth\ncase. We disprove this conjecture and show, for two notions of algorithmic\nstability (including uniform stability), that the stability of Nesterov's\naccelerated method in fact deteriorates exponentially fast with the number of\ngradient steps. This stands in sharp contrast to the bounds in the quadratic\ncase, but also to known results for non-accelerated gradient methods where\nstability typically grows linearly with the number of steps.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 17:50:42 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 18:49:09 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Attia", "Amit", ""], ["Koren", "Tomer", ""]]}, {"id": "2102.02171", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and Alistair Stewart and Yuxin\n  Sun", "title": "Outlier-Robust Learning of Ising Models Under Dobrushin's Condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning Ising models satisfying Dobrushin's\ncondition in the outlier-robust setting where a constant fraction of the\nsamples are adversarially corrupted. Our main result is to provide the first\ncomputationally efficient robust learning algorithm for this problem with\nnear-optimal error guarantees. Our algorithm can be seen as a special case of\nan algorithm for robustly learning a distribution from a general exponential\nfamily. To prove its correctness for Ising models, we establish new\nanti-concentration results for degree-$2$ polynomials of Ising models that may\nbe of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 18:00:57 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""], ["Sun", "Yuxin", ""]]}, {"id": "2102.02193", "submitter": "Jakub Tetek", "authors": "Kasper Green Larsen, Rasmus Pagh, Jakub T\\v{e}tek", "title": "CountSketches, Feature Hashing and the Median of Three", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the classic CountSketch method, which is a sparse,\nrandom projection that transforms a (high-dimensional) Euclidean vector $v$ to\na vector of dimension $(2t-1) s$, where $t, s > 0$ are integer parameters. It\nis known that even for $t=1$, a CountSketch allows estimating coordinates of\n$v$ with variance bounded by $\\|v\\|_2^2/s$. For $t > 1$, the estimator takes\nthe median of $2t-1$ independent estimates, and the probability that the\nestimate is off by more than $2 \\|v\\|_2/\\sqrt{s}$ is exponentially small in\n$t$. This suggests choosing $t$ to be logarithmic in a desired inverse failure\nprobability. However, implementations of CountSketch often use a small,\nconstant $t$. Previous work only predicts a constant factor improvement in this\nsetting.\n  Our main contribution is a new analysis of Count-Sketch, showing an\nimprovement in variance to $O(\\min\\{\\|v\\|_1^2/s^2,\\|v\\|_2^2/s\\})$ when $t > 1$.\nThat is, the variance decreases proportionally to $s^{-2}$, asymptotically for\nlarge enough $s$. We also study the variance in the setting where an inner\nproduct is to be estimated from two CountSketches. This finding suggests that\nthe Feature Hashing method, which is essentially identical to CountSketch but\ndoes not make use of the median estimator, can be made more reliable at a small\ncost in settings where using a median estimator is possible.\n  We confirm our theoretical findings in experiments and thereby help justify\nwhy a small constant number of estimates often suffice in practice. Our\nimproved variance bounds are based on new general theorems about the variance\nand higher moments of the median of i.i.d. random variables that may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 18:45:21 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Larsen", "Kasper Green", ""], ["Pagh", "Rasmus", ""], ["T\u011btek", "Jakub", ""]]}, {"id": "2102.02291", "submitter": "Marco Loog", "authors": "Marco Loog", "title": "Nearest Neighbor-based Importance Weighting", "comments": "Submitted to arXiv due to popular demand", "journal-ref": "MLSP 2021, Santander, Spain", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Importance weighting is widely applicable in machine learning in general and\nin techniques dealing with data covariate shift problems in particular. A\nnovel, direct approach to determine such importance weighting is presented. It\nrelies on a nearest neighbor classification scheme and is relatively\nstraightforward to implement. Comparative experiments on various classification\ntasks demonstrate the effectiveness of our so-called nearest neighbor weighting\n(NNeW) scheme. Considering its performance, our procedure can act as a simple\nand effective baseline method for importance weighting.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 21:05:17 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Loog", "Marco", ""]]}, {"id": "2102.02336", "submitter": "Emmanouil Vasileios Vlatakis Gkaragkounis", "authors": "Daniel Hsu, Clayton Sanford, Rocco A. Servedio, Emmanouil-Vasileios\n  Vlatakis-Gkaragkounis", "title": "On the Approximation Power of Two-Layer Networks of Random ReLUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the following question: how well can depth-two ReLU\nnetworks with randomly initialized bottom-level weights represent smooth\nfunctions? We give near-matching upper- and lower-bounds for\n$L_2$-approximation in terms of the Lipschitz constant, the desired accuracy,\nand the dimension of the problem, as well as similar results in terms of\nSobolev norms. Our positive results employ tools from harmonic analysis and\nridgelet representation theory, while our lower-bounds are based on (robust\nversions of) dimensionality arguments.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 23:41:34 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Hsu", "Daniel", ""], ["Sanford", "Clayton", ""], ["Servedio", "Rocco A.", ""], ["Vlatakis-Gkaragkounis", "Emmanouil-Vasileios", ""]]}, {"id": "2102.02339", "submitter": "Wenpin Tang", "authors": "Wenpin Tang and Xun Yu Zhou", "title": "Simulated annealing from continuum to discretization: a convergence\n  analysis via the Eyring--Kramers law", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the convergence rate of continuous-time simulated annealing $(X_t;\n\\, t \\ge 0)$ and its discretization $(x_k; \\, k =0,1, \\ldots)$ for\napproximating the global optimum of a given function $f$. We prove that the\ntail probability $\\mathbb{P}(f(X_t) > \\min f +\\delta)$ (resp.\n$\\mathbb{P}(f(x_k) > \\min f +\\delta)$) decays polynomial in time (resp. in\ncumulative step size), and provide an explicit rate as a function of the model\nparameters. Our argument applies the recent development on functional\ninequalities for the Gibbs measure at low temperatures -- the Eyring-Kramers\nlaw. In the discrete setting, we obtain a condition on the step size to ensure\nthe convergence.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 23:45:39 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 06:12:10 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Tang", "Wenpin", ""], ["Zhou", "Xun Yu", ""]]}, {"id": "2102.02365", "submitter": "Eld Emanuel Str\\\"om", "authors": "Jonas Kiessling, Emanuel Str\\\"om and Ra\\'ul Tempone", "title": "Wind Field Reconstruction with Adaptive Random Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the use of spatial interpolation methods for reconstructing\nthe horizontal near-surface wind field given a sparse set of measurements. In\nparticular, random Fourier features is compared to a set of benchmark methods\nincluding Kriging and Inverse distance weighting. Random Fourier features is a\nlinear model $\\beta(\\pmb x) = \\sum_{k=1}^K \\beta_k e^{i\\omega_k \\pmb x}$\napproximating the velocity field, with frequencies $\\omega_k$ randomly sampled\nand amplitudes $\\beta_k$ trained to minimize a loss function. We include a\nphysically motivated divergence penalty term $|\\nabla \\cdot \\beta(\\pmb x)|^2$,\nas well as a penalty on the Sobolev norm. We derive a bound on the\ngeneralization error and derive a sampling density that minimizes the bound.\nFollowing (arXiv:2007.10683 [math.NA]), we devise an adaptive\nMetropolis-Hastings algorithm for sampling the frequencies of the optimal\ndistribution. In our experiments, our random Fourier features model outperforms\nthe benchmark models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 01:42:08 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Kiessling", "Jonas", ""], ["Str\u00f6m", "Emanuel", ""], ["Tempone", "Ra\u00fal", ""]]}, {"id": "2102.02396", "submitter": "Trung Vu", "authors": "Trung Vu and Raviv Raich", "title": "Exact Linear Convergence Rate Analysis for Low-Rank Symmetric Matrix\n  Completion via Gradient Descent", "comments": "Full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization-based gradient descent is a scalable and efficient algorithm\nfor solving low-rank matrix completion. Recent progress in structured\nnon-convex optimization has offered global convergence guarantees for gradient\ndescent under certain statistical assumptions on the low-rank matrix and the\nsampling set. However, while the theory suggests gradient descent enjoys fast\nlinear convergence to a global solution of the problem, the universal nature of\nthe bounding technique prevents it from obtaining an accurate estimate of the\nrate of convergence. In this paper, we perform a local analysis of the exact\nlinear convergence rate of gradient descent for factorization-based matrix\ncompletion for symmetric matrices. Without any additional assumptions on the\nunderlying model, we identify the deterministic condition for local convergence\nof gradient descent, which only depends on the solution matrix and the sampling\nset. More crucially, our analysis provides a closed-form expression of the\nasymptotic rate of convergence that matches exactly with the linear convergence\nobserved in practice. To the best of our knowledge, our result is the first one\nthat offers the exact rate of convergence of gradient descent for matrix\nfactorization in Euclidean space for matrix completion.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 03:41:54 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 03:55:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Vu", "Trung", ""], ["Raich", "Raviv", ""]]}, {"id": "2102.02410", "submitter": "Mo Zhou", "authors": "Mo Zhou, Rong Ge, Chi Jin", "title": "A Local Convergence Theory for Mildly Over-Parameterized Two-Layer\n  Neural Network", "comments": "Added references and fixed typos. Accepted to COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While over-parameterization is widely believed to be crucial for the success\nof optimization for the neural networks, most existing theories on\nover-parameterization do not fully explain the reason -- they either work in\nthe Neural Tangent Kernel regime where neurons don't move much, or require an\nenormous number of neurons. In practice, when the data is generated using a\nteacher neural network, even mildly over-parameterized neural networks can\nachieve 0 loss and recover the directions of teacher neurons. In this paper we\ndevelop a local convergence theory for mildly over-parameterized two-layer\nneural net. We show that as long as the loss is already lower than a threshold\n(polynomial in relevant parameters), all student neurons in an\nover-parameterized two-layer neural network will converge to one of teacher\nneurons, and the loss will go to 0. Our result holds for any number of student\nneurons as long as it is at least as large as the number of teacher neurons,\nand our convergence rate is independent of the number of student neurons. A key\ncomponent of our analysis is the new characterization of local optimization\nlandscape -- we show the gradient satisfies a special case of Lojasiewicz\nproperty which is different from local strong convexity or PL conditions used\nin previous work.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 04:41:04 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 18:13:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhou", "Mo", ""], ["Ge", "Rong", ""], ["Jin", "Chi", ""]]}, {"id": "2102.02414", "submitter": "Yivan Zhang", "authors": "Yivan Zhang, Gang Niu, Masashi Sugiyama", "title": "Learning Noise Transition Matrix from Only Noisy Labels via Total\n  Variation Regularization", "comments": "ICML 2021 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many weakly supervised classification methods employ a noise transition\nmatrix to capture the class-conditional label corruption. To estimate the\ntransition matrix from noisy data, existing methods often need to estimate the\nnoisy class-posterior, which could be unreliable due to the overconfidence of\nneural networks. In this work, we propose a theoretically grounded method that\ncan estimate the noise transition matrix and learn a classifier simultaneously,\nwithout relying on the error-prone noisy class-posterior estimation.\nConcretely, inspired by the characteristics of the stochastic label corruption\nprocess, we propose total variation regularization, which encourages the\npredicted probabilities to be more distinguishable from each other. Under mild\nassumptions, the proposed method yields a consistent estimator of the\ntransition matrix. We show the effectiveness of the proposed method through\nexperiments on benchmark and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 05:09:18 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 07:59:54 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Yivan", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2102.02450", "submitter": "Haoyu Wei", "authors": "Huiming Zhang, Haoyu Wei", "title": "Sharper Sub-Weibull Concentrations: Non-asymptotic Bai-Yin Theorem", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Arising in high-dimensional probability, non-asymptotic concentration\ninequalities play an essential role in the finite-sample theory of machine\nlearning and high-dimensional statistics. In this article, we obtain a sharper\nand constants-specified concentration inequality for the summation of\nindependent sub-Weibull random variables, which leads to a mixture of two\ntails: sub-Gaussian for small deviations and sub-Weibull for large deviations\n(from mean). These bounds improve existing bounds with sharper constants. In\nthe application of random matrices, we derive non-asymptotic versions of\nBai-Yin's theorem for sub-Weibull entries and it extends the previous result in\nterms of sub-Gaussian entries. In the application of negative binomial\nregressions, we gives the $\\ell_2$-error of the estimated coefficients when\ncovariate vector $X$ is sub-Weibull distributed with sparse structures, which\nis a new result for negative binomial regressions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 07:16:27 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 16:10:12 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Zhang", "Huiming", ""], ["Wei", "Haoyu", ""]]}, {"id": "2102.02472", "submitter": "Hyejin Park", "authors": "Hyejin Park and Seiyun Shin and Kwang-Sung Jun and Jungseul Ok", "title": "Transfer Learning in Bandits with Latent Continuity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Structured stochastic multi-armed bandits provide accelerated regret rates\nover the standard unstructured bandit problems. Most structured bandits,\nhowever, assume the knowledge of the structural parameter such as Lipschitz\ncontinuity, which is often not available. To cope with the latent structural\nparameter, we consider a transfer learning setting in which an agent must learn\nto transfer the structural information from the prior tasks to the next task,\nwhich is inspired by practical problems such as rate adaptation in wireless\nlink. We propose a novel framework to provably and accurately estimate the\nLipschitz constant based on previous tasks and fully exploit it for the new\ntask at hand. We analyze the efficiency of the proposed framework in two folds:\n(i) the sample complexity of our estimator matches with the\ninformation-theoretic fundamental limit; and (ii) our regret bound on the new\ntask is close to that of the oracle algorithm with the full knowledge of the\nLipschitz constant under mild assumptions. Our analysis reveals a set of useful\ninsights on transfer learning for latent Lipschitzconstants such as the\nfundamental challenge a learner faces. Our numerical evaluations confirm our\ntheoretical findings and show the superiority of the proposed framework\ncompared to baselines.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 08:19:12 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 17:28:47 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Park", "Hyejin", ""], ["Shin", "Seiyun", ""], ["Jun", "Kwang-Sung", ""], ["Ok", "Jungseul", ""]]}, {"id": "2102.02488", "submitter": "Christina Petschnigg", "authors": "Christina Petschnigg, Markus Spitzner, Lucas Weitzendorf and J\\\"urgen\n  Pilz", "title": "From a Point Cloud to a Simulation Model: Bayesian Segmentation and\n  Entropy based Uncertainty Estimation for 3D Modelling", "comments": "Submitted to MDPI Entropy for Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 3D modelling of indoor environments and the generation of process\nsimulations play an important role in factory and assembly planning. In\nbrownfield planning cases existing data are often outdated and incomplete\nespecially for older plants, which were mostly planned in 2D. Thus, current\nenvironment models cannot be generated directly on the basis of existing data\nand a holistic approach on how to build such a factory model in a highly\nautomated fashion is mostly non-existent. Major steps in generating an\nenvironment model in a production plant include data collection and\npre-processing, object identification as well as pose estimation. In this work,\nwe elaborate a methodical workflow, which starts with the digitalization of\nlarge-scale indoor environments and ends with the generation of a static\nenvironment or simulation model. The object identification step is realized\nusing a Bayesian neural network capable of point cloud segmentation. We\nelaborate how the information on network uncertainty generated by a Bayesian\nsegmentation framework can be used in order to build up a more accurate\nenvironment model. The steps of data collection and point cloud segmentation as\nwell as the resulting model accuracy are evaluated on a real-world data set\ncollected at the assembly line of a large-scale automotive production plant.\nThe segmentation network is further evaluated on the publicly available\nStanford Large-Scale 3D Indoor Spaces data set. The Bayesian segmentation\nnetwork clearly surpasses the performance of the frequentist baseline and\nallows us to increase the accuracy of the model placement in a simulation scene\nconsiderably.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 08:59:49 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Petschnigg", "Christina", ""], ["Spitzner", "Markus", ""], ["Weitzendorf", "Lucas", ""], ["Pilz", "J\u00fcrgen", ""]]}, {"id": "2102.02504", "submitter": "Pierre Alquier", "authors": "Dimitri Meunier and Pierre Alquier", "title": "Meta-strategy for Learning Tuning Parameters with Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online gradient methods, like the online gradient algorithm (OGA), often\ndepend on tuning parameters that are difficult to set in practice. We consider\nan online meta-learning scenario, and we propose a meta-strategy to learn these\nparameters from past tasks. Our strategy is based on the minimization of a\nregret bound. It allows to learn the initialization and the step size in OGA\nwith guarantees. We provide a regret analysis of the strategy in the case of\nconvex losses. It suggests that, when there are parameters\n$\\theta_1,\\dots,\\theta_T$ solving well tasks $1,\\dots,T$ respectively and that\nare close enough one to each other, our strategy indeed improves on learning\neach task in isolation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 09:32:22 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 09:03:58 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Meunier", "Dimitri", ""], ["Alquier", "Pierre", ""]]}, {"id": "2102.02514", "submitter": "Felix Sattler", "authors": "Felix Sattler and Tim Korjakow and Roman Rischke and Wojciech Samek", "title": "FedAUX: Leveraging Unlabeled Auxiliary Data in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Distillation (FD) is a popular novel algorithmic paradigm for\nFederated Learning, which achieves training performance competitive to prior\nparameter averaging based methods, while additionally allowing the clients to\ntrain different model architectures, by distilling the client predictions on an\nunlabeled auxiliary set of data into a student model. In this work we propose\nFedAUX, an extension to FD, which, under the same set of assumptions,\ndrastically improves performance by deriving maximum utility from the unlabeled\nauxiliary data. FedAUX modifies the FD training procedure in two ways: First,\nunsupervised pre-training on the auxiliary data is performed to find a model\ninitialization for the distributed training. Second, $(\\varepsilon,\n\\delta)$-differentially private certainty scoring is used to weight the\nensemble predictions on the auxiliary data according to the certainty of each\nclient model. Experiments on large-scale convolutional neural networks and\ntransformer models demonstrate, that the training performance of FedAUX exceeds\nSOTA FL baseline methods by a substantial margin in both the iid and non-iid\nregime, further closing the gap to centralized training performance. Code is\navailable at github.com/fedl-repo/fedaux.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 09:53:53 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Sattler", "Felix", ""], ["Korjakow", "Tim", ""], ["Rischke", "Roman", ""], ["Samek", "Wojciech", ""]]}, {"id": "2102.02551", "submitter": "Yang Zhang", "authors": "Yugeng Liu and Rui Wen and Xinlei He and Ahmed Salem and Zhikun Zhang\n  and Michael Backes and Emiliano De Cristofaro and Mario Fritz and Yang Zhang", "title": "ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inference attacks against Machine Learning (ML) models allow adversaries to\nlearn information about training data, model parameters, etc. While researchers\nhave studied these attacks thoroughly, they have done so in isolation. We lack\na comprehensive picture of the risks caused by the attacks, such as the\ndifferent scenarios they can be applied to, the common factors that influence\ntheir performance, the relationship among them, or the effectiveness of defense\ntechniques. In this paper, we fill this gap by presenting a first-of-its-kind\nholistic risk assessment of different inference attacks against machine\nlearning models. We concentrate on four attacks - namely, membership inference,\nmodel inversion, attribute inference, and model stealing - and establish a\nthreat model taxonomy. Our extensive experimental evaluation conducted over\nfive model architectures and four datasets shows that the complexity of the\ntraining dataset plays an important role with respect to the attack's\nperformance, while the effectiveness of model stealing and membership inference\nattacks are negatively correlated. We also show that defenses like DP-SGD and\nKnowledge Distillation can only hope to mitigate some of the inference attacks.\nOur analysis relies on a modular re-usable software, ML-Doctor, which enables\nML model owners to assess the risks of deploying their models, and equally\nserves as a benchmark tool for researchers and practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 11:35:13 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Liu", "Yugeng", ""], ["Wen", "Rui", ""], ["He", "Xinlei", ""], ["Salem", "Ahmed", ""], ["Zhang", "Zhikun", ""], ["Backes", "Michael", ""], ["De Cristofaro", "Emiliano", ""], ["Fritz", "Mario", ""], ["Zhang", "Yang", ""]]}, {"id": "2102.02618", "submitter": "Oliver Urs Lenz", "authors": "Oliver Urs Lenz, Daniel Peralta, Chris Cornelis", "title": "Optimised one-class classification performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We provide a thorough treatment of hyperparameter optimisation for three data\ndescriptors with a good track-record in the literature: Support Vector Machine\n(SVM), Nearest Neighbour Distance (NND) and Average Localised Proximity (ALP).\nThe hyperparameters of SVM have to be optimised through cross-validation, while\nNND and ALP allow the reuse of a single nearest-neighbour query and an\nefficient form of leave-one-out validation. We experimentally evaluate the\neffect of hyperparameter optimisation with 246 classification problems drawn\nfrom 50 datasets. From a selection of optimisation algorithms, the recent\nMalherbe-Powell proposal optimises the hyperparameters of all three data\ndescriptors most efficiently. We calculate the increase in test AUROC and the\namount of overfitting as a function of the number of hyperparameter\nevaluations. After 50 evaluations, ALP and SVM both significantly outperform\nNND. The performance of ALP and SVM is comparable, but ALP can be optimised\nmore efficiently, while a choice between ALP and SVM based on validation AUROC\ngives the best overall result. This distils the many variables of one-class\nclassification with hyperparameter optimisation down to a clear choice with a\nknown trade-off, allowing practitioners to make informed decisions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 14:08:20 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Lenz", "Oliver Urs", ""], ["Peralta", "Daniel", ""], ["Cornelis", "Chris", ""]]}, {"id": "2102.02642", "submitter": "Benjamin Christoffersen", "authors": "Benjamin Christoffersen, Mark Clements, Keith Humphreys, Hedvig\n  Kjellstr\\\"om", "title": "Asymptotically Exact and Fast Gaussian Copula Models for Imputation of\n  Mixed Data Types", "comments": "20 pages, 1 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing values with mixed data types is a common problem in a large number of\nmachine learning applications such as processing of surveys and in different\nmedical applications. Recently, Gaussian copula models have been suggested as a\nmeans of performing imputation of missing values using a probabilistic\nframework. While the present Gaussian copula models have shown to yield state\nof the art performance, they have two limitations: they are based on an\napproximation that is fast but may be imprecise and they do not support\nunordered multinomial variables. We address the first limitation using direct\nand arbitrarily precise approximations both for model estimation and imputation\nby using randomized quasi-Monte Carlo procedures. The method we provide has\nlower errors for the estimated model parameters and the imputed values,\ncompared to previously proposed methods. We also extend the previous Gaussian\ncopula models to include unordered multinomial variables in addition to the\npresent support of ordinal, binary, and continuous variables.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 14:42:29 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 10:15:31 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Christoffersen", "Benjamin", ""], ["Clements", "Mark", ""], ["Humphreys", "Keith", ""], ["Kjellstr\u00f6m", "Hedvig", ""]]}, {"id": "2102.02685", "submitter": "Luca Ganassali", "authors": "Luca Ganassali, Laurent Massouli\\'e, Marc Lelarge", "title": "Impossibility of Partial Recovery in the Graph Alignment Problem", "comments": "23 pages, 8 figures. Accepted for publication at COLT21", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random graph alignment refers to recovering the underlying vertex\ncorrespondence between two random graphs with correlated edges. This can be\nviewed as an average-case and noisy version of the well-known graph isomorphism\nproblem. For the correlated Erd\\\"os-R\\'enyi model, we prove an impossibility\nresult for partial recovery in the sparse regime, with constant average degree\nand correlation, as well as a general bound on the maximal reachable overlap.\nOur bound is tight in the noiseless case (the graph isomorphism problem) and we\nconjecture that it is still tight with noise. Our proof technique relies on a\ncareful application of the probabilistic method to build automorphisms between\ntree components of a subcritical Erd\\\"os-R\\'enyi graph.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 15:26:48 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 14:23:47 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ganassali", "Luca", ""], ["Massouli\u00e9", "Laurent", ""], ["Lelarge", "Marc", ""]]}, {"id": "2102.02694", "submitter": "Yura Perugachi-Diaz", "authors": "Yura Perugachi-Diaz, Jakub M. Tomczak, Sandjai Bhulai", "title": "Invertible DenseNets with Concatenated LipSwish", "comments": "This is an extension of Invertible DenseNets (arXiv:2010.02125)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Invertible Dense Networks (i-DenseNets), a more parameter\nefficient extension of Residual Flows. The method relies on an analysis of the\nLipschitz continuity of the concatenation in DenseNets, where we enforce\ninvertibility of the network by satisfying the Lipschitz constant. Furthermore,\nwe propose a learnable weighted concatenation, which not only improves the\nmodel performance but also indicates the importance of the concatenated\nweighted representation. Additionally, we introduce the Concatenated LipSwish\nas activation function, for which we show how to enforce the Lipschitz\ncondition and which boosts performance. The new architecture, i-DenseNet,\nout-performs Residual Flow and other flow-based models on density estimation\nevaluated in bits per dimension, where we utilize an equal parameter budget.\nMoreover, we show that the proposed model out-performs Residual Flows when\ntrained as a hybrid model where the model is both a generative and a\ndiscriminative model.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 15:45:33 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 21:15:21 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Perugachi-Diaz", "Yura", ""], ["Tomczak", "Jakub M.", ""], ["Bhulai", "Sandjai", ""]]}, {"id": "2102.02697", "submitter": "Roland Jucknewitz", "authors": "Roland Jucknewitz, Oliver Weidinger, Anja Schramm", "title": "Covid-19 risk factors: Statistical learning from German healthcare\n  claims data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyse prior risk factors for severe, critical or fatal courses of\nCovid-19 based on a retrospective cohort using claims data of the AOK Bayern.\nAs our main methodological contribution, we avoid prior grouping and\npre-selection of candidate risk factors. Instead, fine-grained hierarchical\ninformation from medical classification systems for diagnoses, pharmaceuticals\nand procedures are used, resulting in more than 33,000 covariates. Our approach\nhas better predictive ability than well-specified morbidity groups but does not\nneed prior subject-matter knowledge. The methodology and estimated coefficients\nare made available to decision makers to prioritize protective measures towards\nvulnerable subpopulations and to researchers who like to adjust for a large set\nof confounders in studies of individual risk factors.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 15:48:21 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 07:46:49 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Jucknewitz", "Roland", ""], ["Weidinger", "Oliver", ""], ["Schramm", "Anja", ""]]}, {"id": "2102.02741", "submitter": "Hongteng Xu", "authors": "Hongteng Xu and Dixin Luo and Hongyuan Zha", "title": "Hawkes Processes on Graphons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel framework for modeling multiple multivariate point\nprocesses, each with heterogeneous event types that share an underlying space\nand obey the same generative mechanism. Focusing on Hawkes processes and their\nvariants that are associated with Granger causality graphs, our model leverages\nan uncountable event type space and samples the graphs with different sizes\nfrom a nonparametric model called {\\it graphon}. Given those graphs, we can\ngenerate the corresponding Hawkes processes and simulate event sequences.\nLearning this graphon-based Hawkes process model helps to 1) infer the\nunderlying relations shared by different Hawkes processes; and 2) simulate\nevent sequences with different event types but similar dynamics. We learn the\nproposed model by minimizing the hierarchical optimal transport distance\nbetween the generated event sequences and the observed ones, leading to a novel\nreward-augmented maximum likelihood estimation method. We analyze the\nproperties of our model in-depth and demonstrate its rationality and\neffectiveness in both theory and experiments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 17:09:50 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Xu", "Hongteng", ""], ["Luo", "Dixin", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2102.02756", "submitter": "Jiacheng Zhuo", "authors": "Jiacheng Zhuo, Jeongyeol Kwon, Nhat Ho, Constantine Caramanis", "title": "On the computational and statistical complexity of over-parameterized\n  matrix sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider solving the low rank matrix sensing problem with Factorized\nGradient Descend (FGD) method when the true rank is unknown and over-specified,\nwhich we refer to as over-parameterized matrix sensing. If the ground truth\nsignal $\\mathbf{X}^* \\in \\mathbb{R}^{d*d}$ is of rank $r$, but we try to\nrecover it using $\\mathbf{F} \\mathbf{F}^\\top$ where $\\mathbf{F} \\in\n\\mathbb{R}^{d*k}$ and $k>r$, the existing statistical analysis falls short, due\nto a flat local curvature of the loss function around the global maxima. By\ndecomposing the factorized matrix $\\mathbf{F}$ into separate column spaces to\ncapture the effect of extra ranks, we show that $\\|\\mathbf{F}_t \\mathbf{F}_t -\n\\mathbf{X}^*\\|_{F}^2$ converges to a statistical error of $\\tilde{\\mathcal{O}}\n({k d \\sigma^2/n})$ after\n$\\tilde{\\mathcal{O}}(\\frac{\\sigma_{r}}{\\sigma}\\sqrt{\\frac{n}{d}})$ number of\niterations where $\\mathbf{F}_t$ is the output of FGD after $t$ iterations,\n$\\sigma^2$ is the variance of the observation noise, $\\sigma_{r}$ is the $r$-th\nlargest eigenvalue of $\\mathbf{X}^*$, and $n$ is the number of sample. Our\nresults, therefore, offer a comprehensive picture of the statistical and\ncomputational complexity of FGD for the over-parameterized matrix sensing\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 04:23:49 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhuo", "Jiacheng", ""], ["Kwon", "Jeongyeol", ""], ["Ho", "Nhat", ""], ["Caramanis", "Constantine", ""]]}, {"id": "2102.02770", "submitter": "Matthew Feickert", "authors": "Matthew Feickert and Benjamin Nachman", "title": "A Living Review of Machine Learning for Particle Physics", "comments": "3 pages, 3 figures, GitHub repository of Living Review\n  https://github.com/iml-wg/HEPML-LivingReview", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph cs.LG hep-ex physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern machine learning techniques, including deep learning, are rapidly\nbeing applied, adapted, and developed for high energy physics. Given the fast\npace of this research, we have created a living review with the goal of\nproviding a nearly comprehensive list of citations for those developing and\napplying these approaches to experimental, phenomenological, or theoretical\nanalyses. As a living document, it will be updated as often as possible to\nincorporate the latest developments. A list of proper (unchanging) reviews can\nbe found within. Papers are grouped into a small set of topics to be as useful\nas possible. Suggestions and contributions are most welcome, and we provide\ninstructions for participating.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 04:39:40 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Feickert", "Matthew", ""], ["Nachman", "Benjamin", ""]]}, {"id": "2102.02789", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes, Francis Bach, Alessandro Rudi", "title": "Disambiguation of weak supervision with exponential convergence rates", "comments": "22 pages; 6 figures", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning approached through supervised learning requires expensive\nannotation of data. This motivates weakly supervised learning, where data are\nannotated with incomplete yet discriminative information. In this paper, we\nfocus on partial labelling, an instance of weak supervision where, from a given\ninput, we are given a set of potential targets. We review a disambiguation\nprinciple to recover full supervision from weak supervision, and propose an\nempirical disambiguation algorithm. We prove exponential convergence rates of\nour algorithm under classical learnability assumptions, and we illustrate the\nusefulness of our method on practical examples.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:14:32 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 16:14:29 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 14:29:24 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Cabannes", "Vivien", ""], ["Bach", "Francis", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2102.02791", "submitter": "Joern Hees", "authors": "J\\\"orn Hees, Dayananda Herurkar, Mario Meier", "title": "RECol: Reconstruction Error Columns for Outlier Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting outliers or anomalies is a common data analysis task. As a\nsub-field of unsupervised machine learning, a large variety of approaches\nexist, but the vast majority treats the input features as independent and often\nfails to recognize even simple (linear) relationships in the input feature\nspace. Hence, we introduce RECol, a generic data pre-processing approach to\ngenerate additional columns in a leave-one-out-fashion: For each column, we try\nto predict its values based on the other columns, generating reconstruction\nerror columns. We run experiments across a large variety of common baseline\napproaches and benchmark datasets with and without our RECol pre-processing\nmethod and show that the generated reconstruction error feature space generally\nseems to support common outlier detection methods and often considerably\nimproves their ROC-AUC and PR-AUC values.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:24:59 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Hees", "J\u00f6rn", ""], ["Herurkar", "Dayananda", ""], ["Meier", "Mario", ""]]}, {"id": "2102.02802", "submitter": "Mahdi Boloursaz Mashhadi", "authors": "Mahdi Boloursaz Mashhadi, Mikolaj Jankowski, Tze-Yang Tung, Szymon\n  Kobus, and Deniz Gunduz", "title": "Federated mmWave Beam Selection Utilizing LIDAR Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Efficient link configuration in millimeter wave (mmWave) communication\nsystems is a crucial yet challenging task due to the overhead imposed by beam\nselection. For vehicle-to-infrastructure (V2I) networks, side information from\nLIDAR sensors mounted on the vehicles has been leveraged to reduce the beam\nsearch overhead. In this letter, we propose a federated LIDAR aided beam\nselection method for V2I mmWave communication systems. In the proposed scheme,\nconnected vehicles collaborate to train a shared neural network (NN) on their\nlocally available LIDAR data during normal operation of the system. We also\npropose a reduced-complexity convolutional NN (CNN) classifier architecture and\nLIDAR preprocessing, which significantly outperforms previous works in terms of\nboth the performance and the complexity.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:49:20 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 15:10:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mashhadi", "Mahdi Boloursaz", ""], ["Jankowski", "Mikolaj", ""], ["Tung", "Tze-Yang", ""], ["Kobus", "Szymon", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2102.02872", "submitter": "Sanjiban Choudhury", "authors": "Jonathan Spencer, Sanjiban Choudhury, Arun Venkatraman, Brian Ziebart,\n  J. Andrew Bagnell", "title": "Feedback in Imitation Learning: The Three Regimes of Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning practitioners have often noted that conditioning policies\non previous actions leads to a dramatic divergence between \"held out\" error and\nperformance of the learner in situ. Interactive approaches can provably address\nthis divergence but require repeated querying of a demonstrator. Recent work\nidentifies this divergence as stemming from a \"causal confound\" in predicting\nthe current action, and seek to ablate causal aspects of current state using\ntools from causal inference. In this work, we argue instead that this\ndivergence is simply another manifestation of covariate shift, exacerbated\nparticularly by settings of feedback between decisions and input features. The\nlearner often comes to rely on features that are strongly predictive of\ndecisions, but are subject to strong covariate shift.\n  Our work demonstrates a broad class of problems where this shift can be\nmitigated, both theoretically and practically, by taking advantage of a\nsimulator but without any further querying of expert demonstration. We analyze\nexisting benchmarks used to test imitation learning approaches and find that\nthese benchmarks are realizable and simple and thus insufficient for capturing\nthe harder regimes of error compounding seen in real-world decision making\nproblems. We find, in a surprising contrast with previous literature, but\nconsistent with our theory, that naive behavioral cloning provides excellent\nresults. We detail the need for new standardized benchmarks that capture the\nphenomena seen in robotics problems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:18:56 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:55:12 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Spencer", "Jonathan", ""], ["Choudhury", "Sanjiban", ""], ["Venkatraman", "Arun", ""], ["Ziebart", "Brian", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "2102.02876", "submitter": "Alexander Schell", "authors": "Alexander Schell and Harald Oberhauser", "title": "Nonlinear Independent Component Analysis for Continuous-Time Signals", "comments": "68 pages, 8 figures. Added consistency results (Section 8), corrected\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the classical problem of recovering a multidimensional source\nprocess from observations of nonlinear mixtures of this process. Assuming\nstatistical independence of the coordinate processes of the source, we show\nthat this recovery is possible for many popular models of stochastic processes\n(up to order and monotone scaling of their coordinates) if the mixture is given\nby a sufficiently differentiable, invertible function. Key to our approach is\nthe combination of tools from stochastic analysis and recent contrastive\nlearning approaches to nonlinear ICA. This yields a scalable method with widely\napplicable theoretical guarantees for which our experiments indicate good\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:28:44 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 12:47:34 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Schell", "Alexander", ""], ["Oberhauser", "Harald", ""]]}, {"id": "2102.02950", "submitter": "Masanori Yamada", "authors": "Masanori Yamada, Sekitoshi Kanai, Tomoharu Iwata, Tomokatsu Takahashi,\n  Yuki Yamanaka, Hiroshi Takahashi, Atsutoshi Kumagai", "title": "Adversarial Training Makes Weight Loss Landscape Sharper in Logistic\n  Regression", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is actively studied for learning robust models against\nadversarial examples. A recent study finds that adversarially trained models\ndegenerate generalization performance on adversarial examples when their weight\nloss landscape, which is loss changes with respect to weights, is sharp.\nUnfortunately, it has been experimentally shown that adversarial training\nsharpens the weight loss landscape, but this phenomenon has not been\ntheoretically clarified. Therefore, we theoretically analyze this phenomenon in\nthis paper. As a first step, this paper proves that adversarial training with\nthe L2 norm constraints sharpens the weight loss landscape in the linear\nlogistic regression model. Our analysis reveals that the sharpness of the\nweight loss landscape is caused by the noise aligned in the direction of\nincreasing the loss, which is used in adversarial training. We theoretically\nand experimentally confirm that the weight loss landscape becomes sharper as\nthe magnitude of the noise of adversarial training increases in the linear\nlogistic regression model. Moreover, we experimentally confirm the same\nphenomena in ResNet18 with softmax as a more general case.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 01:31:01 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Yamada", "Masanori", ""], ["Kanai", "Sekitoshi", ""], ["Iwata", "Tomoharu", ""], ["Takahashi", "Tomokatsu", ""], ["Yamanaka", "Yuki", ""], ["Takahashi", "Hiroshi", ""], ["Kumagai", "Atsutoshi", ""]]}, {"id": "2102.02969", "submitter": "Jianhao Ma", "authors": "Jianhao Ma and Salar Fattahi", "title": "Implicit Regularization of Sub-Gradient Method in Robust Matrix\n  Recovery: Don't be Afraid of Outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that simple short-sighted algorithms, such as gradient\ndescent, generalize well in the over-parameterized learning tasks, due to their\nimplicit regularization. However, it is unknown whether the implicit\nregularization of these algorithms can be extended to robust learning tasks,\nwhere a subset of samples may be grossly corrupted with noise. In this work, we\nprovide a positive answer to this question in the context of robust matrix\nrecovery problem. In particular, we consider the problem of recovering a\nlow-rank matrix from a number of linear measurements, where a subset of\nmeasurements are corrupted with large noise. We show that a simple sub-gradient\nmethod converges to the true low-rank solution efficiently, when it is applied\nto the over-parameterized l1-loss function without any explicit regularization\nor rank constraint. Moreover, by building upon a new notion of restricted\nisometry property, called sign-RIP, we prove the robustness of the sub-gradient\nmethod against outliers in the over-parameterized regime. In particular, we\nshow that, with Gaussian measurements, the sub-gradient method is guaranteed to\nconverge to the true low-rank solution, even if an arbitrary fraction of the\nmeasurements are grossly corrupted with noise.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 02:52:00 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 15:37:21 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Ma", "Jianhao", ""], ["Fattahi", "Salar", ""]]}, {"id": "2102.02976", "submitter": "Hao Wang", "authors": "Hao Wang, Yizhe Huang, Rui Gao, Flavio P. Calmon", "title": "Learning While Dissipating Information: Understanding the Generalization\n  Capability of SGLD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the generalization capability of learning algorithms is at the\nheart of statistical learning theory. In this paper, we investigate the\ngeneralization gap of stochastic gradient Langevin dynamics (SGLD), a widely\nused optimizer for training deep neural networks (DNNs). We derive an\nalgorithm-dependent generalization bound by analyzing SGLD through an\ninformation-theoretic lens. Our analysis reveals an intricate trade-off between\nlearning and information dissipation: SGLD learns from data by updating\nparameters at each iteration while dissipating information from early training\nstages. Our bound also involves the variance of gradients which captures a\nparticular kind of \"sharpness\" of the loss landscape. The main proof techniques\nin this paper rely on strong data processing inequalities -- a fundamental\nconcept in information theory -- and Otto-Villani's HWI inequality. Finally, we\ndemonstrate our bound through numerical experiments, showing that it can\npredict the behavior of the true generalization gap.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 03:18:52 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Wang", "Hao", ""], ["Huang", "Yizhe", ""], ["Gao", "Rui", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "2102.02979", "submitter": "Stefano Gualandi", "authors": "Auricchio Gennaro, Codegoni Andrea, Gualandi Stefano, Zambon Lorenzo", "title": "The Fourier Loss Function", "comments": "15 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces a new loss function induced by the Fourier-based\nMetric. This metric is equivalent to the Wasserstein distance but is computed\nvery efficiently using the Fast Fourier Transform algorithm. We prove that the\nFourier loss function is twice differentiable, and we provide the explicit\nformula for both its gradient and its Hessian matrix. More importantly, we show\nthat minimising the Fourier loss function is equivalent to maximising the\nlikelihood of the data under a Gaussian noise in the space of frequencies. We\napply our loss function to a multi-class classification task using MNIST,\nFashion-MNIST, and CIFAR10 datasets. The computational results show that, while\nits accuracy is competitive with other state-of-the-art loss functions, the\nFourier loss function is significantly more robust to noisy data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 03:19:44 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Gennaro", "Auricchio", ""], ["Andrea", "Codegoni", ""], ["Stefano", "Gualandi", ""], ["Lorenzo", "Zambon", ""]]}, {"id": "2102.02981", "submitter": "Masatoshi Uehara", "authors": "Masatoshi Uehara, Masaaki Imaizumi, Nan Jiang, Nathan Kallus, Wen Sun,\n  Tengyang Xie", "title": "Finite Sample Analysis of Minimax Offline Reinforcement Learning:\n  Completeness, Fast Rates and First-Order Efficiency", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We offer a theoretical characterization of off-policy evaluation (OPE) in\nreinforcement learning using function approximation for marginal importance\nweights and $q$-functions when these are estimated using recent minimax\nmethods. Under various combinations of realizability and completeness\nassumptions, we show that the minimax approach enables us to achieve a fast\nrate of convergence for weights and quality functions, characterized by the\ncritical inequality \\citep{bartlett2005}. Based on this result, we analyze\nconvergence rates for OPE. In particular, we introduce novel alternative\ncompleteness conditions under which OPE is feasible and we present the first\nfinite-sample result with first-order efficiency in non-tabular environments,\ni.e., having the minimal coefficient in the leading term.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 03:20:39 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Uehara", "Masatoshi", ""], ["Imaizumi", "Masaaki", ""], ["Jiang", "Nan", ""], ["Kallus", "Nathan", ""], ["Sun", "Wen", ""], ["Xie", "Tengyang", ""]]}, {"id": "2102.03060", "submitter": "Chen Amiraz", "authors": "Chen Amiraz, Robert Krauthgamer, Boaz Nadler", "title": "Sparse Normal Means Estimation with Sublinear Communication", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sparse normal means estimation in a distributed\nsetting with communication constraints. We assume there are $M$ machines, each\nholding a $d$-dimensional observation of a $K$-sparse vector $\\mu$ corrupted by\nadditive Gaussian noise. A central fusion machine is connected to the $M$\nmachines in a star topology, and its goal is to estimate the vector $\\mu$ with\na low communication budget. Previous works have shown that to achieve the\ncentralized minimax rate for the $\\ell_2$ risk, the total communication must be\nhigh - at least linear in the dimension $d$. This phenomenon occurs, however,\nat very weak signals. We show that once the signal-to-noise ratio (SNR) is\nslightly higher, the support of $\\mu$ can be correctly recovered with much less\ncommunication. Specifically, we present two algorithms for the distributed\nsparse normal means problem, and prove that above a certain SNR threshold, with\nhigh probability, they recover the correct support with total communication\nthat is sublinear in the dimension $d$. Furthermore, the communication\ndecreases exponentially as a function of signal strength. If in addition $KM\\ll\nd$, then with an additional round of sublinear communication, our algorithms\nachieve the centralized rate for the $\\ell_2$ risk. Finally, we present\nsimulations that illustrate the performance of our algorithms in different\nparameter regimes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:52:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Amiraz", "Chen", ""], ["Krauthgamer", "Robert", ""], ["Nadler", "Boaz", ""]]}, {"id": "2102.03065", "submitter": "Jang-Hyun Kim", "authors": "Jang-Hyun Kim, Wonho Choo, Hosan Jeong, Hyun Oh Song", "title": "Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity", "comments": "Published at ICLR 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks show great performance on fitting to the training\ndistribution, improving the networks' generalization performance to the test\ndistribution and robustness to the sensitivity to input perturbations still\nremain as a challenge. Although a number of mixup based augmentation strategies\nhave been proposed to partially address them, it remains unclear as to how to\nbest utilize the supervisory signal within each input data for mixup from the\noptimization perspective. We propose a new perspective on batch mixup and\nformulate the optimal construction of a batch of mixup data maximizing the data\nsaliency measure of each individual mixup data and encouraging the supermodular\ndiversity among the constructed mixup data. This leads to a novel discrete\noptimization problem minimizing the difference between submodular functions. We\nalso propose an efficient modular approximation based iterative submodular\nminimization algorithm for efficient mixup computation per each minibatch\nsuitable for minibatch based neural network training. Our experiments show the\nproposed method achieves the state of the art generalization, calibration, and\nweakly supervised localization results compared to other mixup methods. The\nsource code is available at https://github.com/snu-mllab/Co-Mixup.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 09:12:02 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Kim", "Jang-Hyun", ""], ["Choo", "Wonho", ""], ["Jeong", "Hosan", ""], ["Song", "Hyun Oh", ""]]}, {"id": "2102.03156", "submitter": "Quentin Bouniot", "authors": "Quentin Bouniot, Romaric Audigier, Ang\\'elique Loesch", "title": "Optimal Transport as a Defense Against Adversarial Attacks", "comments": "Accepted at ICPR2020. Code is available at\n  https://github.com/CEA-LIST/adv-sat", "journal-ref": null, "doi": "10.1109/ICPR48806.2021.9413327", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning classifiers are now known to have flaws in the representations\nof their class. Adversarial attacks can find a human-imperceptible perturbation\nfor a given image that will mislead a trained model. The most effective methods\nto defend against such attacks trains on generated adversarial examples to\nlearn their distribution. Previous work aimed to align original and adversarial\nimage representations in the same way as domain adaptation to improve\nrobustness. Yet, they partially align the representations using approaches that\ndo not reflect the geometry of space and distribution. In addition, it is\ndifficult to accurately compare robustness between defended models. Until now,\nthey have been evaluated using a fixed perturbation size. However, defended\nmodels may react differently to variations of this perturbation size. In this\npaper, the analogy of domain adaptation is taken a step further by exploiting\noptimal transport theory. We propose to use a loss between distributions that\nfaithfully reflect the ground distance. This leads to SAT (Sinkhorn Adversarial\nTraining), a more robust defense against adversarial attacks. Then, we propose\nto quantify more precisely the robustness of a model to adversarial attacks\nover a wide range of perturbation sizes using a different metric, the Area\nUnder the Accuracy Curve (AUAC). We perform extensive experiments on both\nCIFAR-10 and CIFAR-100 datasets and show that our defense is globally more\nrobust than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 13:24:36 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 08:06:59 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Bouniot", "Quentin", ""], ["Audigier", "Romaric", ""], ["Loesch", "Ang\u00e9lique", ""]]}, {"id": "2102.03159", "submitter": "Wenbo Gong", "authors": "Wenbo Gong, Kaibo Zhang, Yingzhen Li, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Active Slices for Sliced Stein Discrepancy", "comments": "22 pages, 7 figures, International Conference on Machine Learning\n  (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sliced Stein discrepancy (SSD) and its kernelized variants have demonstrated\npromising successes in goodness-of-fit tests and model learning in high\ndimensions. Despite their theoretical elegance, their empirical performance\ndepends crucially on the search of optimal slicing directions to discriminate\nbetween two distributions. Unfortunately, previous gradient-based optimisation\napproaches for this task return sub-optimal results: they are computationally\nexpensive, sensitive to initialization, and they lack theoretical guarantees\nfor convergence. We address these issues in two steps. First, we provide\ntheoretical results stating that the requirement of using optimal slicing\ndirections in the kernelized version of SSD can be relaxed, validating the\nresulting discrepancy with finite random slicing directions. Second, given that\ngood slicing directions are crucial for practical performance, we propose a\nfast algorithm for finding such slicing directions based on ideas of active\nsub-space construction and spectral decomposition. Experiments on\ngoodness-of-fit tests and model learning show that our approach achieves both\nimproved performance and faster convergence. Especially, we demonstrate a\n14-80x speed-up in goodness-of-fit tests when comparing with gradient-based\nalternatives.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 13:33:17 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 12:34:41 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 13:14:19 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Gong", "Wenbo", ""], ["Zhang", "Kaibo", ""], ["Li", "Yingzhen", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2102.03169", "submitter": "Yingzhi Xia", "authors": "Yingzhi Xia, Nicholas Zabaras", "title": "Bayesian multiscale deep generative model for the solution of\n  high-dimensional inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of spatially-varying parameters for computationally expensive\nforward models governed by partial differential equations is addressed. A novel\nmultiscale Bayesian inference approach is introduced based on deep\nprobabilistic generative models. Such generative models provide a flexible\nrepresentation by inferring on each scale a low-dimensional latent encoding\nwhile allowing hierarchical parameter generation from coarse- to fine-scales.\nCombining the multiscale generative model with Markov Chain Monte Carlo (MCMC),\ninference across scales is achieved enabling us to efficiently obtain posterior\nparameter samples at various scales. The estimation of coarse-scale parameters\nusing a low-dimensional latent embedding captures global and notable parameter\nfeatures using an inexpensive but inaccurate solver. MCMC sampling of the\nfine-scale parameters is enabled by utilizing the posterior information in the\nimmediate coarser-scale. In this way, the global features are identified in the\ncoarse-scale with inference of low-dimensional variables and inexpensive\nforward computation, and the local features are refined and corrected in the\nfine-scale. The developed method is demonstrated with two types of permeability\nestimation for flow in heterogeneous media. One is a Gaussian random field\n(GRF) with uncertain length scales, and the other is channelized permeability\nwith the two regions defined by different GRFs. The obtained results indicate\nthat the method allows high-dimensional parameter estimation while exhibiting\nstability, efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 11:47:21 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 04:05:45 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Xia", "Yingzhi", ""], ["Zabaras", "Nicholas", ""]]}, {"id": "2102.03183", "submitter": "Loucas Pillaud-Vivien", "authors": "Aditya Varre, Loucas Pillaud-Vivien, Nicolas Flammarion", "title": "Last iterate convergence of SGD for Least-Squares in the Interpolation\n  regime", "comments": "23 pages, 1 figure, 1 Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent successes of neural networks that have the ability to\nfit the data perfectly and generalize well, we study the noiseless model in the\nfundamental least-squares setup. We assume that an optimum predictor fits\nperfectly inputs and outputs $\\langle \\theta_* , \\phi(X) \\rangle = Y$, where\n$\\phi(X)$ stands for a possibly infinite dimensional non-linear feature map. To\nsolve this problem, we consider the estimator given by the last iterate of\nstochastic gradient descent (SGD) with constant step-size. In this context, our\ncontribution is two fold: (i) from a (stochastic) optimization perspective, we\nexhibit an archetypal problem where we can show explicitly the convergence of\nSGD final iterate for a non-strongly convex problem with constant step-size\nwhereas usual results use some form of average and (ii) from a statistical\nperspective, we give explicit non-asymptotic convergence rates in the\nover-parameterized setting and leverage a fine-grained parameterization of the\nproblem to exhibit polynomial rates that can be faster than $O(1/T)$. The link\nwith reproducing kernel Hilbert spaces is established.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 14:02:20 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 18:02:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Varre", "Aditya", ""], ["Pillaud-Vivien", "Loucas", ""], ["Flammarion", "Nicolas", ""]]}, {"id": "2102.03202", "submitter": "Stefano Zamuner", "authors": "Stefano Zamuner, Paolo De Los Rios", "title": "Interpretable Neural Networks based classifiers for categorical inputs", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of the pervasive usage of Neural Networks in human sensitive\napplications, their interpretability is becoming an increasingly important\ntopic in machine learning. In this work we introduce a simple way to interpret\nthe output function of a neural network classifier that take as input\ncategorical variables. By exploiting a mapping between a neural network\nclassifier and a physical energy model, we show that in these cases each layer\nof the network, and the logits layer in particular, can be expanded as a sum of\nterms that account for the contribution to the classification of each input\npattern. For instance, at the first order, the expansion considers just the\nlinear relation between input features and output while at the second order\npairwise dependencies between input features are also accounted for. The\nanalysis of the contributions of each pattern, after an appropriate gauge\ntransformation, is presented in two cases where the effectiveness of the method\ncan be appreciated.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 14:38:50 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zamuner", "Stefano", ""], ["Rios", "Paolo De Los", ""]]}, {"id": "2102.03239", "submitter": "Christian M. Dahl", "authors": "Christian M. Dahl, Torben S. D. Johansen, Emil N. S{\\o}rensen,\n  Christian E. Westermann and Simon F. Wittrock", "title": "Applications of Machine Learning in Document Digitisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data acquisition forms the primary step in all empirical research. The\navailability of data directly impacts the quality and extent of conclusions and\ninsights. In particular, larger and more detailed datasets provide convincing\nanswers even to complex research questions. The main problem is that 'large and\ndetailed' usually implies 'costly and difficult', especially when the data\nmedium is paper and books. Human operators and manual transcription have been\nthe traditional approach for collecting historical data. We instead advocate\nthe use of modern machine learning techniques to automate the digitisation\nprocess. We give an overview of the potential for applying machine digitisation\nfor data collection through two illustrative applications. The first\ndemonstrates that unsupervised layout classification applied to raw scans of\nnurse journals can be used to construct a treatment indicator. Moreover, it\nallows an assessment of assignment compliance. The second application uses\nattention-based neural networks for handwritten text recognition in order to\ntranscribe age and birth and death dates from a large collection of Danish\ndeath certificates. We describe each step in the digitisation pipeline and\nprovide implementation insights.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 15:35:28 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Dahl", "Christian M.", ""], ["Johansen", "Torben S. D.", ""], ["S\u00f8rensen", "Emil N.", ""], ["Westermann", "Christian E.", ""], ["Wittrock", "Simon F.", ""]]}, {"id": "2102.03257", "submitter": "\\\"Ozge Sahin", "authors": "\\\"Ozge Sahin, Claudia Czado", "title": "Vine copula mixture models and clustering for non-Gaussian data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of finite mixture models suffer from not allowing asymmetric\ntail dependencies within components and not capturing non-elliptical clusters\nin clustering applications. Since vine copulas are very flexible in capturing\nthese types of dependencies, we propose a novel vine copula mixture model for\ncontinuous data. We discuss the model selection and parameter estimation\nproblems and further formulate a new model-based clustering algorithm. The use\nof vine copulas in clustering allows for a range of shapes and dependency\nstructures for the clusters. Our simulation experiments illustrate a\nsignificant gain in clustering accuracy when notably asymmetric tail\ndependencies or/and non-Gaussian margins within the components exist. The\nanalysis of real data sets accompanies the proposed method. We show that the\nmodel-based clustering algorithm with vine copula mixture models outperforms\nthe other model-based clustering techniques, especially for the non-Gaussian\nmultivariate data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 16:04:26 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Sahin", "\u00d6zge", ""], ["Czado", "Claudia", ""]]}, {"id": "2102.03280", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang and Osvaldo Simeone", "title": "Multi-Sample Online Learning for Spiking Neural Networks based on\n  Generalized Expectation Maximization", "comments": "To be presented at ICASSP 2021. Author's Accepted Manuscript. (A\n  longer version can be found at arXiv:2007.11894), Author's Accepted\n  Manuscript. arXiv admin note: text overlap with arXiv:2007.11894", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) offer a novel computational paradigm that\ncaptures some of the efficiency of biological brains by processing through\nbinary neural dynamic activations. Probabilistic SNN models are typically\ntrained to maximize the likelihood of the desired outputs by using unbiased\nestimates of the log-likelihood gradients. While prior work used single-sample\nestimators obtained from a single run of the network, this paper proposes to\nleverage multiple compartments that sample independent spiking signals while\nsharing synaptic weights. The key idea is to use these signals to obtain more\naccurate statistical estimates of the log-likelihood training criterion, as\nwell as of its gradient. The approach is based on generalized\nexpectation-maximization (GEM), which optimizes a tighter approximation of the\nlog-likelihood using importance sampling. The derived online learning algorithm\nimplements a three-factor rule with global per-compartment learning signals.\nExperimental results on a classification task on the neuromorphic MNIST-DVS\ndata set demonstrate significant improvements in terms of log-likelihood,\naccuracy, and calibration when increasing the number of compartments used for\ntraining and inference.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 16:39:42 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2102.03282", "submitter": "Kaifeng Bu", "authors": "Kaifeng Bu, Dax Enshan Koh, Lu Li, Qingxian Luo, Yaobo Zhang", "title": "Effects of quantum resources on the statistical complexity of quantum\n  circuits", "comments": "6+6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how the addition of quantum resources changes the statistical\ncomplexity of quantum circuits by utilizing the framework of quantum resource\ntheories. Measures of statistical complexity that we consider include the\nRademacher complexity and the Gaussian complexity, which are well-known\nmeasures in computational learning theory that quantify the richness of classes\nof real-valued functions. We derive bounds for the statistical complexities of\nquantum circuits that have limited access to certain resources and apply our\nresults to two special cases: (1) stabilizer circuits that are supplemented\nwith a limited number of T gates and (2) instantaneous quantum polynomial-time\nClifford circuits that are supplemented with a limited number of CCZ gates. We\nshow that the increase in the statistical complexity of a quantum circuit when\nan additional quantum channel is added to it is upper bounded by the free\nrobustness of the added channel. Finally, we derive bounds for the\ngeneralization error associated with learning from training data arising from\nquantum circuits.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 16:42:35 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bu", "Kaifeng", ""], ["Koh", "Dax Enshan", ""], ["Li", "Lu", ""], ["Luo", "Qingxian", ""], ["Zhang", "Yaobo", ""]]}, {"id": "2102.03324", "submitter": "Henry Moss", "authors": "Henry B. Moss, David S. Leslie, Javier Gonzalez, Paul Rayson", "title": "GIBBON: General-purpose Information-Based Bayesian OptimisatioN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a general-purpose extension of max-value entropy search,\na popular approach for Bayesian Optimisation (BO). A novel approximation is\nproposed for the information gain -- an information-theoretic quantity central\nto solving a range of BO problems, including noisy, multi-fidelity and batch\noptimisations across both continuous and highly-structured discrete spaces.\nPreviously, these problems have been tackled separately within\ninformation-theoretic BO, each requiring a different sophisticated\napproximation scheme, except for batch BO, for which no\ncomputationally-lightweight information-theoretic approach has previously been\nproposed. GIBBON (General-purpose Information-Based Bayesian OptimisatioN)\nprovides a single principled framework suitable for all the above,\nout-performing existing approaches whilst incurring substantially lower\ncomputational overheads. In addition, GIBBON does not require the problem's\nsearch space to be Euclidean and so is the first high-performance yet\ncomputationally light-weight acquisition function that supports batch BO over\ngeneral highly structured input spaces like molecular search and gene design.\nMoreover, our principled derivation of GIBBON yields a natural interpretation\nof a popular batch BO heuristic based on determinantal point processes.\nFinally, we analyse GIBBON across a suite of synthetic benchmark tasks, a\nmolecular search loop, and as part of a challenging batch multi-fidelity\nframework for problems with controllable experimental noise.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 18:04:37 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Moss", "Henry B.", ""], ["Leslie", "David S.", ""], ["Gonzalez", "Javier", ""], ["Rayson", "Paul", ""]]}, {"id": "2102.03334", "submitter": "Wonjae Kim", "authors": "Wonjae Kim, Bokyung Son, Ildoo Kim", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region\n  Supervision", "comments": "ICML 2021 Long Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-Language Pre-training (VLP) has improved performance on various\njoint vision-and-language downstream tasks. Current approaches to VLP heavily\nrely on image feature extraction processes, most of which involve region\nsupervision (e.g., object detection) and the convolutional architecture (e.g.,\nResNet). Although disregarded in the literature, we find it problematic in\nterms of both (1) efficiency/speed, that simply extracting input features\nrequires much more computation than the multimodal interaction steps; and (2)\nexpressive power, as it is upper bounded to the expressive power of the visual\nembedder and its predefined visual vocabulary. In this paper, we present a\nminimal VLP model, Vision-and-Language Transformer (ViLT), monolithic in the\nsense that the processing of visual inputs is drastically simplified to just\nthe same convolution-free manner that we process textual inputs. We show that\nViLT is up to tens of times faster than previous VLP models, yet with\ncompetitive or better downstream task performance. Our code and pre-trained\nweights are available at https://github.com/dandelin/vilt.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 18:36:11 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 17:15:46 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kim", "Wonjae", ""], ["Son", "Bokyung", ""], ["Kim", "Ildoo", ""]]}, {"id": "2102.03381", "submitter": "Leffey Xie", "authors": "Lehui Xie, Yaopeng Wang, Jia-Li Yin, and Ximeng Liu", "title": "Robust Single-step Adversarial Training with Regularizer", "comments": "7 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High cost of training time caused by multi-step adversarial example\ngeneration is a major challenge in adversarial training. Previous methods try\nto reduce the computational burden of adversarial training using single-step\nadversarial example generation schemes, which can effectively improve the\nefficiency but also introduce the problem of catastrophic overfitting, where\nthe robust accuracy against Fast Gradient Sign Method (FGSM) can achieve nearby\n100\\% whereas the robust accuracy against Projected Gradient Descent (PGD)\nsuddenly drops to 0\\% over a single epoch. To address this problem, we propose\na novel Fast Gradient Sign Method with PGD Regularization (FGSMPR) to boost the\nefficiency of adversarial training without catastrophic overfitting. Our core\nidea is that single-step adversarial training can not learn robust internal\nrepresentations of FGSM and PGD adversarial examples. Therefore, we design a\nPGD regularization term to encourage similar embeddings of FGSM and PGD\nadversarial examples. The experiments demonstrate that our proposed method can\ntrain a robust deep network for L$_\\infty$-perturbations with FGSM adversarial\ntraining and reduce the gap to multi-step adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:07:10 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Xie", "Lehui", ""], ["Wang", "Yaopeng", ""], ["Yin", "Jia-Li", ""], ["Liu", "Ximeng", ""]]}, {"id": "2102.03389", "submitter": "He Li", "authors": "Xi Chen, Zehua Lai, He Li, Yichen Zhang", "title": "Online Statistical Inference for Gradient-free Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As gradient-free stochastic optimization gains emerging attention for a wide\nrange of applications recently, the demand for uncertainty quantification of\nparameters obtained from such approaches arises. In this paper, we investigate\nthe problem of statistical inference for model parameters based on\ngradient-free stochastic optimization methods that use only function values\nrather than gradients. We first present central limit theorem results for\nPolyak-Ruppert-averaging type gradient-free estimators. The asymptotic\ndistribution reflects the trade-off between the rate of convergence and\nfunction query complexity. We next construct valid confidence intervals for\nmodel parameters through the estimation of the covariance matrix in a fully\nonline fashion. We further give a general gradient-free framework for\ncovariance estimation and analyze the role of function query complexity in the\nconvergence rate of the covariance estimator. This provides a one-pass\ncomputationally efficient procedure for simultaneously obtaining an estimator\nof model parameters and conducting statistical inference. Finally, we provide\nnumerical experiments to verify our theoretical results and illustrate some\nextensions of our method for various machine learning and deep learning\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:22:41 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Chen", "Xi", ""], ["Lai", "Zehua", ""], ["Li", "He", ""], ["Zhang", "Yichen", ""]]}, {"id": "2102.03390", "submitter": "Minhui Huang", "authors": "Minhui Huang, Shiqian Ma, Lifeng Lai", "title": "Projection Robust Wasserstein Barycenters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting and aggregating information from several probability measures or\nhistograms is a fundamental task in machine learning. One of the popular\nsolution methods for this task is to compute the barycenter of the probability\nmeasures under the Wasserstein metric. However, approximating the Wasserstein\nbarycenter is numerically challenging because of the curse of dimensionality.\nThis paper proposes the projection robust Wasserstein barycenter (PRWB) that\nhas the potential to mitigate the curse of dimensionality. Since PRWB is\nnumerically very challenging to solve, we further propose a relaxed PRWB\n(RPRWB) model, which is more tractable. The RPRWB projects the probability\nmeasures onto a lower-dimensional subspace that maximizes the Wasserstein\nbarycenter objective. The resulting problem is a max-min problem over the\nStiefel manifold. By combining the iterative Bregman projection algorithm and\nRiemannian optimization, we propose two new algorithms for computing the RPRWB.\nThe complexity of arithmetic operations of the proposed algorithms for\nobtaining an $\\epsilon$-stationary solution is analyzed. We incorporate the\nRPRWB into a discrete distribution clustering algorithm, and the numerical\nresults on real text datasets confirm that our RPRWB model helps improve the\nclustering performance significantly.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:23:35 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 02:26:09 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 01:03:39 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Huang", "Minhui", ""], ["Ma", "Shiqian", ""], ["Lai", "Lifeng", ""]]}, {"id": "2102.03400", "submitter": "Nadav Merlis", "authors": "Yonathan Efroni, Nadav Merlis, Aadirupa Saha, Shie Mannor", "title": "Confidence-Budget Matching for Sequential Budgeted Learning", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core element in decision-making under uncertainty is the feedback on the\nquality of the performed actions. However, in many applications, such feedback\nis restricted. For example, in recommendation systems, repeatedly asking the\nuser to provide feedback on the quality of recommendations will annoy them. In\nthis work, we formalize decision-making problems with querying budget, where\nthere is a (possibly time-dependent) hard limit on the number of reward queries\nallowed. Specifically, we consider multi-armed bandits, linear bandits, and\nreinforcement learning problems. We start by analyzing the performance of\n`greedy' algorithms that query a reward whenever they can. We show that in\nfully stochastic settings, doing so performs surprisingly well, but in the\npresence of any adversity, this might lead to linear regret. To overcome this\nissue, we propose the Confidence-Budget Matching (CBM) principle that queries\nrewards when the confidence intervals are wider than the inverse square root of\nthe available budget. We analyze the performance of CBM based algorithms in\ndifferent settings and show that they perform well in the presence of adversity\nin the contexts, initial states, and budgets.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:56:31 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 08:10:37 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Efroni", "Yonathan", ""], ["Merlis", "Nadav", ""], ["Saha", "Aadirupa", ""], ["Mannor", "Shie", ""]]}, {"id": "2102.03403", "submitter": "Saptarshi Chakraborty", "authors": "Debolina Paul, Saptarshi Chakraborty and Swagatam Das", "title": "Robust Principal Component Analysis: A Median of Means Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) is a fundamental tool for data\nvisualization, denoising, and dimensionality reduction. It is widely popular in\nStatistics, Machine Learning, Computer Vision, and related fields. However, PCA\nis well known to fall prey to the presence of outliers and often fails to\ndetect the true underlying low-dimensional structure within the dataset. Recent\nsupervised learning methods, following the Median of Means (MoM) philosophy,\nhave shown great success in dealing with outlying observations without much\ncompromise to their large sample theoretical properties. In this paper, we\npropose a PCA procedure based on the MoM principle. Called the Median of Means\nPrincipal Component Analysis (MoMPCA), the proposed method is not only\ncomputationally appealing but also achieves optimal convergence rates under\nminimal assumptions. In particular, we explore the non-asymptotic error bounds\nof the obtained solution via the aid of Vapnik-Chervonenkis theory and\nRademacher complexity, while granting absolutely no assumption on the outlying\nobservations. The efficacy of the proposal is also thoroughly showcased through\nsimulations and real data applications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:59:05 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Paul", "Debolina", ""], ["Chakraborty", "Saptarshi", ""], ["Das", "Swagatam", ""]]}, {"id": "2102.03432", "submitter": "Marcus Noack", "authors": "Marcus M. Noack and James A. Sethian", "title": "Advanced Stationary and Non-Stationary Kernel Designs for Domain-Aware\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process regression is a widely-applied method for function\napproximation and uncertainty quantification. The technique has gained\npopularity recently in the machine learning community due to its robustness and\ninterpretability. The mathematical methods we discuss in this paper are an\nextension of the Gaussian-process framework. We are proposing advanced kernel\ndesigns that only allow for functions with certain desirable characteristics to\nbe elements of the reproducing kernel Hilbert space (RKHS) that underlies all\nkernel methods and serves as the sample space for Gaussian process regression.\nThese desirable characteristics reflect the underlying physics; two obvious\nexamples are symmetry and periodicity constraints. In addition, non-stationary\nkernel designs can be defined in the same framework to yield flexible\nmulti-task Gaussian processes. We will show the impact of advanced kernel\ndesigns on Gaussian processes using several synthetic and two scientific data\nsets. The results show that including domain knowledge, communicated through\nadvanced kernel designs, has a significant impact on the accuracy and relevance\nof the function approximation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 22:07:56 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 18:32:25 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Noack", "Marcus M.", ""], ["Sethian", "James A.", ""]]}, {"id": "2102.03450", "submitter": "Zhixian Chen", "authors": "Zhixian Chen, Tengfei Ma, Yangqiu Song, Yang Wang", "title": "Wasserstein diffusion on graphs with missing attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing node attributes is a common problem in real-world graphs. Graph\nneural networks have been demonstrated powerful in graph representation\nlearning, however, they rely heavily on the completeness of graph information.\nFew of them consider the incomplete node attributes, which can bring great\ndamage to the performance in practice. In this paper, we propose an innovative\nnode representation learning framework, Wasserstein graph diffusion (WGD), to\nmitigate the problem. Instead of feature imputation, our method directly learns\nnode representations from the missing-attribute graphs. Specifically, we extend\nthe message passing schema in general graph neural networks to a Wasserstein\nspace derived from the decomposition of attribute matrices. We test WGD in node\nclassification tasks under two settings: missing whole attributes on some nodes\nand missing only partial attributes on all nodes. In addition, we find WGD is\nsuitable to recover missing values and adapt it to tackle matrix completion\nproblems with graphs of users and items. Experimental results on both tasks\ndemonstrate the superiority of our method.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 00:06:51 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Chen", "Zhixian", ""], ["Ma", "Tengfei", ""], ["Song", "Yangqiu", ""], ["Wang", "Yang", ""]]}, {"id": "2102.03497", "submitter": "Ziquan Liu", "authors": "Ziquan Liu, Yufei Cui, Jia Wan, Yu Mao, Antoni B. Chan", "title": "The Implicit Biases of Stochastic Gradient Descent on Deep Neural\n  Networks with Batch Normalization", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with batch normalization (BN-DNNs) are invariant to\nweight rescaling due to their normalization operations. However, using weight\ndecay (WD) benefits these weight-scale-invariant networks, which is often\nattributed to an increase of the effective learning rate when the weight norms\nare decreased. In this paper, we demonstrate the insufficiency of the previous\nexplanation and investigate the implicit biases of stochastic gradient descent\n(SGD) on BN-DNNs to provide a theoretical explanation for the efficacy of\nweight decay. We identity two implicit biases of SGD on BN-DNNs: 1) the weight\nnorms in SGD training remain constant in the continuous-time domain and keep\nincreasing in the discrete-time domain; 2) SGD optimizes weight vectors in\nfully-connected networks or convolution kernels in convolution neural networks\nby updating components lying in the input feature span, while leaving those\ncomponents orthogonal to the input feature span unchanged. Thus, SGD without WD\naccumulates weight noise orthogonal to the input feature span, and cannot\neliminate such noise. Our empirical studies corroborate the hypothesis that\nweight decay suppresses weight noise that is left untouched by SGD.\nFurthermore, we propose to use weight rescaling (WRS) instead of weight decay\nto achieve the same regularization effect, while avoiding performance\ndegradation of WD on some momentum-based optimizers. Our empirical results on\nimage recognition show that regardless of optimization methods and network\narchitectures, training BN-DNNs using WRS achieves similar or better\nperformance compared with using WD. We also show that training with WRS\ngeneralizes better compared to WD, on other computer vision tasks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 03:40:20 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Liu", "Ziquan", ""], ["Cui", "Yufei", ""], ["Wan", "Jia", ""], ["Mao", "Yu", ""], ["Chan", "Antoni B.", ""]]}, {"id": "2102.03509", "submitter": "Sameera Ramasinghe Mr.", "authors": "Sameera Ramasinghe, Kasun Fernando, Salman Khan, Nick Barnes", "title": "Robust normalizing flows using Bernstein-type polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling real-world distributions can often be challenging due to sample data\nthat are subjected to perturbations, e.g., instrumentation errors, or added\nrandom noise. Since flow models are typically nonlinear algorithms, they\namplify these initial errors, leading to poor generalizations. This paper\nproposes a framework to construct Normalizing Flows (NF), which demonstrates\nhigher robustness against such initial errors. To this end, we utilize\nBernstein-type polynomials inspired by the optimal stability of the Bernstein\nbasis. Further, compared to the existing NF frameworks, our method provides\ncompelling advantages like theoretical upper bounds for the approximation\nerror, higher interpretability, suitability for compactly supported densities,\nand the ability to employ higher degree polynomials without training\ninstability. We conduct a thorough theoretical analysis and empirically\ndemonstrate the efficacy of the proposed technique using experiments on both\nreal-world and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 04:32:05 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 11:20:58 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ramasinghe", "Sameera", ""], ["Fernando", "Kasun", ""], ["Khan", "Salman", ""], ["Barnes", "Nick", ""]]}, {"id": "2102.03525", "submitter": "Hao Lei", "authors": "Hao Lei and Ying Chen", "title": "Exclusive Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose an Exclusive Topic Modeling (ETM) for unsupervised text\nclassification, which is able to 1) identify the field-specific keywords though\nless frequently appeared and 2) deliver well-structured topics with exclusive\nwords. In particular, a weighted Lasso penalty is imposed to reduce the\ndominance of the frequently appearing yet less relevant words automatically,\nand a pairwise Kullback-Leibler divergence penalty is used to implement topics\nseparation. Simulation studies demonstrate that the ETM detects the\nfield-specific keywords, while LDA fails. When applying to the benchmark NIPS\ndataset, the topic coherence score on average improves by 22% and 10% for the\nmodel with weighted Lasso penalty and pairwise Kullback-Leibler divergence\npenalty, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 07:03:15 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lei", "Hao", ""], ["Chen", "Ying", ""]]}, {"id": "2102.03585", "submitter": "Salar Fattahi", "authors": "Salar Fattahi and Andres Gomez", "title": "Scalable Inference of Sparsely-changing Markov Random Fields with Strong\n  Statistical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of inferring time-varying Markov random\nfields (MRF), where the underlying graphical model is both sparse and changes\nsparsely over time. Most of the existing methods for the inference of\ntime-varying MRFs rely on the regularized maximum likelihood estimation (MLE),\nthat typically suffer from weak statistical guarantees and high computational\ntime. Instead, we introduce a new class of constrained optimization problems\nfor the inference of sparsely-changing MRFs. The proposed optimization problem\nis formulated based on the exact $\\ell_0$ regularization, and can be solved in\nnear-linear time and memory. Moreover, we show that the proposed estimator\nenjoys a provably small estimation error. As a special case, we derive sharp\nstatistical guarantees for the inference of sparsely-changing Gaussian MRFs\n(GMRF) in the high-dimensional regime, showing that such problems can be\nlearned with as few as one sample per time. Our proposed method is extremely\nefficient in practice: it can accurately estimate sparsely-changing graphical\nmodels with more than 500 million variables in less than one hour.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 13:53:00 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Fattahi", "Salar", ""], ["Gomez", "Andres", ""]]}, {"id": "2102.03594", "submitter": "Oleksandr Zadorozhnyi", "authors": "Oleksandr Zadorozhnyi, Pierre Gaillard, Sebastien Gerschinovitz,\n  Alessandro Rudi", "title": "Online nonparametric regression with Sobolev kernels", "comments": "40 pages, 5 figures, 3 tables (version 2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work we investigate the variation of the online kernelized ridge\nregression algorithm in the setting of $d-$dimensional adversarial\nnonparametric regression. We derive the regret upper bounds on the classes of\nSobolev spaces $W_{p}^{\\beta}(\\mathcal{X})$, $p\\geq 2, \\beta>\\frac{d}{p}$. The\nupper bounds are supported by the minimax regret analysis, which reveals that\nin the cases $\\beta> \\frac{d}{2}$ or $p=\\infty$ these rates are (essentially)\noptimal. Finally, we compare the performance of the kernelized ridge regression\nforecaster to the known non-parametric forecasters in terms of the regret rates\nand their computational complexity as well as to the excess risk rates in the\nsetting of statistical (i.i.d.) nonparametric regression.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 15:05:14 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 09:20:16 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zadorozhnyi", "Oleksandr", ""], ["Gaillard", "Pierre", ""], ["Gerschinovitz", "Sebastien", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2102.03607", "submitter": "Botao Hao", "authors": "Botao Hao, Xiang Ji, Yaqi Duan, Hao Lu, Csaba Szepesv\\'ari, Mengdi\n  Wang", "title": "Bootstrapping Statistical Inference for Off-Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrapping provides a flexible and effective approach for assessing the\nquality of batch reinforcement learning, yet its theoretical property is less\nunderstood. In this paper, we study the use of bootstrapping in off-policy\nevaluation (OPE), and in particular, we focus on the fitted Q-evaluation (FQE)\nthat is known to be minimax-optimal in the tabular and linear-model cases. We\npropose a bootstrapping FQE method for inferring the distribution of the policy\nevaluation error and show that this method is asymptotically efficient and\ndistributionally consistent for off-policy statistical inference. To overcome\nthe computation limit of bootstrapping, we further adapt a subsampling\nprocedure that improves the runtime by an order of magnitude. We numerically\nevaluate the bootrapping method in classical RL environments for confidence\ninterval estimation, estimating the variance of off-policy evaluator, and\nestimating the correlation between multiple off-policy evaluators.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 16:45:33 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 11:19:15 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hao", "Botao", ""], ["Ji", "Xiang", ""], ["Duan", "Yaqi", ""], ["Lu", "Hao", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Wang", "Mengdi", ""]]}, {"id": "2102.03609", "submitter": "Manohar Kaul", "authors": "Manohar Kaul and Masaaki Imaizumi", "title": "Understanding Higher-order Structures in Evolving Graphs: A Simplicial\n  Complex based Kernel Estimation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic graphs are rife with higher-order interactions, such as co-authorship\nrelationships and protein-protein interactions in biological networks, that\nnaturally arise between more than two nodes at once. In spite of the ubiquitous\npresence of such higher-order interactions, limited attention has been paid to\nthe higher-order counterpart of the popular pairwise link prediction problem.\nExisting higher-order structure prediction methods are mostly based on\nheuristic feature extraction procedures, which work well in practice but lack\ntheoretical guarantees. Such heuristics are primarily focused on predicting\nlinks in a static snapshot of the graph. Moreover, these heuristic-based\nmethods fail to effectively utilize and benefit from the knowledge of latent\nsubstructures already present within the higher-order structures. In this\npaper, we overcome these obstacles by capturing higher-order interactions\nsuccinctly as \\textit{simplices}, model their neighborhood by face-vectors, and\ndevelop a nonparametric kernel estimator for simplices that views the evolving\ngraph from the perspective of a time process (i.e., a sequence of graph\nsnapshots). Our method substantially outperforms several baseline higher-order\nprediction methods. As a theoretical achievement, we prove the consistency and\nasymptotic normality in terms of the Wasserstein distance of our estimator\nusing Stein's method.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 16:49:02 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kaul", "Manohar", ""], ["Imaizumi", "Masaaki", ""]]}, {"id": "2102.03639", "submitter": "Ranjan Maitra", "authors": "Wei-Chen Chen and Ranjan Maitra", "title": "A Practical Model-based Segmentation Approach for Accurate Activation\n  Detection in Single-Subject functional Magnetic Resonance Imaging Studies", "comments": "20 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional Magnetic Resonance Imaging (fMRI) maps cerebral activation in\nresponse to stimuli but this activation is often difficult to detect,\nespecially in low-signal contexts and single-subject studies. Accurate\nactivation detection can be guided by the fact that very few voxels are, in\nreality, truly activated and that activated voxels are spatially localized, but\nit is challenging to incorporate both these facts. We provide a computationally\nfeasible and methodologically sound model-based approach, implemented in the R\npackage MixfMRI, that bounds the a priori expected proportion of activated\nvoxels while also incorporating spatial context. Results on simulation\nexperiments for different levels of activation detection difficulty are\nuniformly encouraging. The value of the methodology in low-signal and\nsingle-subject fMRI studies is illustrated on a sports imagination experiment.\nConcurrently, we also extend the potential use of fMRI as a clinical tool to,\nfor example, detect awareness and improve treatment in individual patients in\npersistent vegetative state, such as traumatic brain injury survivors.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 18:46:33 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Chen", "Wei-Chen", ""], ["Maitra", "Ranjan", ""]]}, {"id": "2102.03734", "submitter": "Shubhada Agrawal", "authors": "Shubhada Agrawal, Sandeep Juneja, Wouter M. Koolen", "title": "Regret Minimization in Heavy-Tailed Bandits", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classic regret-minimization problem in the stochastic\nmulti-armed bandit setting when the arm-distributions are allowed to be\nheavy-tailed. Regret minimization has been well studied in simpler settings of\neither bounded support reward distributions or distributions that belong to a\nsingle parameter exponential family. We work under the much weaker assumption\nthat the moments of order $(1+\\epsilon)$ are uniformly bounded by a known\nconstant B, for some given $\\epsilon > 0$. We propose an optimal algorithm that\nmatches the lower bound exactly in the first-order term. We also give a\nfinite-time bound on its regret. We show that our index concentrates faster\nthan the well known truncated or trimmed empirical mean estimators for the mean\nof heavy-tailed distributions. Computing our index can be computationally\ndemanding. To address this, we develop a batch-based algorithm that is optimal\nup to a multiplicative constant depending on the batch size. We hence provide a\ncontrolled trade-off between statistical optimality and computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 07:46:24 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Agrawal", "Shubhada", ""], ["Juneja", "Sandeep", ""], ["Koolen", "Wouter M.", ""]]}, {"id": "2102.03739", "submitter": "Stefano Peluchetti", "authors": "Daniele Bracale, Stefano Favaro, Sandra Fortini, Stefano Peluchetti", "title": "Infinite-channel deep stable convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interplay between infinite-width neural networks (NNs) and classes of\nGaussian processes (GPs) is well known since the seminal work of Neal (1996).\nWhile numerous theoretical refinements have been proposed in the recent years,\nthe interplay between NNs and GPs relies on two critical distributional\nassumptions on the NN's parameters: A1) finite variance; A2) independent and\nidentical distribution (iid). In this paper, we consider the problem of\nremoving A1 in the general context of deep feed-forward convolutional NNs. In\nparticular, we assume iid parameters distributed according to a stable\ndistribution and we show that the infinite-channel limit of a deep feed-forward\nconvolutional NNs, under suitable scaling, is a stochastic process with\nmultivariate stable finite-dimensional distributions. Such a limiting\ndistribution is then characterized through an explicit backward recursion for\nits parameters over the layers. Our contribution extends results of Favaro et\nal. (2020) to convolutional architectures, and it paves the way to expand\nexciting recent lines of research that rely on classes of GP limits.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 08:12:46 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bracale", "Daniele", ""], ["Favaro", "Stefano", ""], ["Fortini", "Sandra", ""], ["Peluchetti", "Stefano", ""]]}, {"id": "2102.03743", "submitter": "Stefano Peluchetti", "authors": "Emanuele Dolera, Stefano Favaro, Stefano Peluchetti", "title": "A Bayesian nonparametric approach to count-min sketch under power-law\n  data streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The count-min sketch (CMS) is a randomized data structure that provides\nestimates of tokens' frequencies in a large data stream using a compressed\nrepresentation of the data by random hashing. In this paper, we rely on a\nrecent Bayesian nonparametric (BNP) view on the CMS to develop a novel\nlearning-augmented CMS under power-law data streams. We assume that tokens in\nthe stream are drawn from an unknown discrete distribution, which is endowed\nwith a normalized inverse Gaussian process (NIGP) prior. Then, using\ndistributional properties of the NIGP, we compute the posterior distribution of\na token's frequency in the stream, given the hashed data, and in turn\ncorresponding BNP estimates. Applications to synthetic and real data show that\nour approach achieves a remarkable performance in the estimation of\nlow-frequency tokens. This is known to be a desirable feature in the context of\nnatural language processing, where it is indeed common in the context of the\npower-law behaviour of the data.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 08:36:00 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 07:27:25 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Dolera", "Emanuele", ""], ["Favaro", "Stefano", ""], ["Peluchetti", "Stefano", ""]]}, {"id": "2102.03748", "submitter": "Tianyu Liu", "authors": "Tianyu Liu, Jie Lu, Zheng Yan, Guangquan Zhang", "title": "PAC-Bayes Bounds for Meta-learning with Data-Dependent Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  By leveraging experience from previous tasks, meta-learning algorithms can\nachieve effective fast adaptation ability when encountering new tasks. However\nit is unclear how the generalization property applies to new tasks. Probably\napproximately correct (PAC) Bayes bound theory provides a theoretical framework\nto analyze the generalization performance for meta-learning. We derive three\nnovel generalisation error bounds for meta-learning based on PAC-Bayes relative\nentropy bound. Furthermore, using the empirical risk minimization (ERM) method,\na PAC-Bayes bound for meta-learning with data-dependent prior is developed.\nExperiments illustrate that the proposed three PAC-Bayes bounds for\nmeta-learning guarantee a competitive generalization performance guarantee, and\nthe extended PAC-Bayes bound with data-dependent prior can achieve rapid\nconvergence ability.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 09:03:43 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Liu", "Tianyu", ""], ["Lu", "Jie", ""], ["Yan", "Zheng", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2102.03758", "submitter": "Peng Zhao", "authors": "Peng Zhao and Yu-Xiang Wang and Zhi-Hua Zhou", "title": "Non-stationary Online Learning with Memory and Non-stochastic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of Online Convex Optimization (OCO) with memory, which\nallows loss functions to depend on past decisions and thus captures temporal\neffects of learning problems. In this paper, we introduce dynamic policy regret\nas the performance measure to design algorithms robust to non-stationary\nenvironments, which competes algorithms' decisions with a sequence of changing\ncomparators. We propose a novel algorithm for OCO with memory that provably\nenjoys an optimal dynamic policy regret. The key technical challenge is how to\ncontrol the switching cost, the cumulative movements of player's decisions,\nwhich is neatly addressed by a novel decomposition of dynamic policy regret and\nan appropriate meta-expert structure. Furthermore, we apply the results to the\nproblem of online non-stochastic control, i.e., controlling a linear dynamical\nsystem with adversarial disturbance and convex loss functions. We derive a\nnovel gradient-based controller with dynamic policy regret guarantees, which is\nthe first controller competitive to a sequence of changing policies.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 09:45:15 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 09:47:15 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zhao", "Peng", ""], ["Wang", "Yu-Xiang", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2102.03773", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Andrea Bragagnolo, Francesco Odierna, Attilio\n  Fiandrotti, Marco Grangetto", "title": "SeReNe: Sensitivity based Regularization of Neurons for Structured\n  Sparsity in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks include millions of learnable parameters, making their\ndeployment over resource-constrained devices problematic. SeReNe\n(Sensitivity-based Regularization of Neurons) is a method for learning sparse\ntopologies with a structure, exploiting neural sensitivity as a regularizer. We\ndefine the sensitivity of a neuron as the variation of the network output with\nrespect to the variation of the activity of the neuron. The lower the\nsensitivity of a neuron, the less the network output is perturbed if the neuron\noutput changes. By including the neuron sensitivity in the cost function as a\nregularization term, we areable to prune neurons with low sensitivity. As\nentire neurons are pruned rather then single parameters, practical network\nfootprint reduction becomes possible. Our experimental results on multiple\nnetwork architectures and datasets yield competitive compression ratios with\nrespect to state-of-the-art references.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 10:53:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Bragagnolo", "Andrea", ""], ["Odierna", "Francesco", ""], ["Fiandrotti", "Attilio", ""], ["Grangetto", "Marco", ""]]}, {"id": "2102.03793", "submitter": "Miguel Ruiz-Garcia", "authors": "Miguel Ruiz-Garcia, Ge Zhang, Samuel S. Schoenholz, Andrea J. Liu", "title": "Tilting the playing field: Dynamical loss functions for machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.soft stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that learning can be improved by using loss functions that evolve\ncyclically during training to emphasize one class at a time. In\nunderparameterized networks, such dynamical loss functions can lead to\nsuccessful training for networks that fail to find a deep minima of the\nstandard cross-entropy loss. In overparameterized networks, dynamical loss\nfunctions can lead to better generalization. Improvement arises from the\ninterplay of the changing loss landscape with the dynamics of the system as it\nevolves to minimize the loss. In particular, as the loss function oscillates,\ninstabilities develop in the form of bifurcation cascades, which we study using\nthe Hessian and Neural Tangent Kernel. Valleys in the landscape widen and\ndeepen, and then narrow and rise as the loss landscape changes during a cycle.\nAs the landscape narrows, the learning rate becomes too large and the network\nbecomes unstable and bounces around the valley. This process ultimately pushes\nthe system into deeper and wider regions of the loss landscape and is\ncharacterized by decreasing eigenvalues of the Hessian. This results in better\nregularized models with improved generalization performance.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 13:15:08 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 19:38:02 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 17:57:22 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Ruiz-Garcia", "Miguel", ""], ["Zhang", "Ge", ""], ["Schoenholz", "Samuel S.", ""], ["Liu", "Andrea J.", ""]]}, {"id": "2102.03794", "submitter": "Shizhan Lu", "authors": "Yu Han, Shizhan Lu, Haiyan Xu", "title": "A self-adaptive and robust fission clustering algorithm via heat\n  diffusion and maximal turning angle", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cluster analysis, which focuses on the grouping and categorization of similar\nelements, is widely used in various fields of research. A novel and fast\nclustering algorithm, fission clustering algorithm, is proposed in recent year.\nIn this article, we propose a robust fission clustering (RFC) algorithm and a\nself-adaptive noise identification method. The RFC and the self-adaptive noise\nidentification method are combine to propose a self-adaptive robust fission\nclustering (SARFC) algorithm. Several frequently-used datasets were applied to\ntest the performance of the proposed clustering approach and to compare the\nresults with those of other algorithms. The comprehensive comparisons indicate\nthat the proposed method has advantages over other common methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 13:16:47 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Han", "Yu", ""], ["Lu", "Shizhan", ""], ["Xu", "Haiyan", ""]]}, {"id": "2102.03802", "submitter": "Mark Kozdoba", "authors": "Mark Kozdoba and Shie Mannor", "title": "Dimension Free Generalization Bounds for Non Linear Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we study generalization guarantees for the metric learning\nproblem, where the metric is induced by a neural network type embedding of the\ndata. Specifically, we provide uniform generalization bounds for two regimes --\nthe sparse regime, and a non-sparse regime which we term \\emph{bounded\namplification}. The sparse regime bounds correspond to situations where\n$\\ell_1$-type norms of the parameters are small. Similarly to the situation in\nclassification, solutions satisfying such bounds can be obtained by an\nappropriate regularization of the problem. On the other hand, unregularized SGD\noptimization of a metric learning loss typically does not produce sparse\nsolutions. We show that despite this lack of sparsity, by relying on a\ndifferent, new property of the solutions, it is still possible to provide\ndimension free generalization guarantees. Consequently, these bounds can\nexplain generalization in non sparse real experimental situations. We\nillustrate the studied phenomena on the MNIST and 20newsgroups datasets.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 14:47:00 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kozdoba", "Mark", ""], ["Mannor", "Shie", ""]]}, {"id": "2102.03803", "submitter": "Uri Sherman", "authors": "Uri Sherman, Tomer Koren", "title": "Lazy OCO: Online Convex Optimization on a Switching Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of online convex optimization where the player is\npermitted to switch decisions at most $S$ times in expectation throughout $T$\nrounds. Similar problems have been addressed in prior work for the discrete\ndecision set setting, and more recently in the continuous setting but only with\nan adaptive adversary. In this work, we aim to fill the gap and present\ncomputationally efficient algorithms in the more prevalent oblivious setting,\nestablishing a regret bound of $O(T/S)$ for general convex losses and\n$\\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic\ni.i.d.~losses, we present a simple algorithm that performs $\\log T$ switches\nwith only a multiplicative $\\log T$ factor overhead in its regret in both the\ngeneral and strongly convex settings. Finally, we complement our algorithms\nwith lower bounds that match our upper bounds in some of the cases we consider.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 14:47:19 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:32:23 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Sherman", "Uri", ""], ["Koren", "Tomer", ""]]}, {"id": "2102.03815", "submitter": "Stefano Teso", "authors": "Freya Behrens, Stefano Teso, Davide Mottin", "title": "Bandits for Learning to Explain from Explanations", "comments": "Accepted at the Explainable Agency in Artificial Intelligence\n  Workshop, hosted at the 35th AAAI Conference on Artificial Intelligence,\n  February 2-9, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Explearn, an online algorithm that learns to jointly output\npredictions and explanations for those predictions. Explearn leverages Gaussian\nProcesses (GP)-based contextual bandits. This brings two key benefits. First,\nGPs naturally capture different kinds of explanations and enable the system\ndesigner to control how explanations generalize across the space by virtue of\nchoosing a suitable kernel. Second, Explearn builds on recent results in\ncontextual bandits which guarantee convergence with high probability. Our\ninitial experiments hint at the promise of the approach.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 15:20:53 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Behrens", "Freya", ""], ["Teso", "Stefano", ""], ["Mottin", "Davide", ""]]}, {"id": "2102.03832", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar", "title": "Generalization of Model-Agnostic Meta-Learning Algorithms: Recurring and\n  Unseen Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the generalization properties of Model-Agnostic\nMeta-Learning (MAML) algorithms for supervised learning problems. We focus on\nthe setting in which we train the MAML model over $m$ tasks, each with $n$ data\npoints, and characterize its generalization error from two points of view:\nFirst, we assume the new task at test time is one of the training tasks, and we\nshow that, for strongly convex objective functions, the expected excess\npopulation loss is bounded by $\\mathcal{O}(1/mn)$. Second, we consider the MAML\nalgorithm's generalization to an unseen task and show that the resulting\ngeneralization error depends on the total variation distance between the\nunderlying distributions of the new task and the tasks observed during the\ntraining process. Our proof techniques rely on the connections between\nalgorithmic stability and generalization bounds of algorithms. In particular,\nwe propose a new definition of stability for meta-learning algorithms, which\nallows us to capture the role of both the number of tasks $m$ and number of\nsamples per task $n$ on the generalization error of MAML.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 16:16:23 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Fallah", "Alireza", ""], ["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2102.03865", "submitter": "Pablo Morala", "authors": "Pablo Morala (1), Jenny Alexandra Cifuentes (1), Rosa E. Lillo (1 and\n  2), I\\~naki Ucar (1) ((1) uc3m-Santander Big Data Institute, Universidad\n  Carlos III de Madrid., (2) Department of Statistics, Universidad Carlos III\n  de Madrid.)", "title": "Towards a mathematical framework to inform Neural Network modelling via\n  Polynomial Regression", "comments": "39 pages, 15 figures", "journal-ref": "Neural Networks 142 (2021), 57-72", "doi": "10.1016/j.neunet.2021.04.036", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even when neural networks are widely used in a large number of applications,\nthey are still considered as black boxes and present some difficulties for\ndimensioning or evaluating their prediction error. This has led to an\nincreasing interest in the overlapping area between neural networks and more\ntraditional statistical methods, which can help overcome those problems. In\nthis article, a mathematical framework relating neural networks and polynomial\nregression is explored by building an explicit expression for the coefficients\nof a polynomial regression from the weights of a given neural network, using a\nTaylor expansion approach. This is achieved for single hidden layer neural\nnetworks in regression problems. The validity of the proposed method depends on\ndifferent factors like the distribution of the synaptic potentials or the\nchosen activation function. The performance of this method is empirically\ntested via simulation of synthetic data generated from polynomials to train\nneural networks with different structures and hyperparameters, showing that\nalmost identical predictions can be obtained when certain conditions are met.\nLastly, when learning from polynomial generated data, the proposed method\nproduces polynomials that approximate correctly the data locally.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 17:56:16 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Morala", "Pablo", "", "1 and\n  2"], ["Cifuentes", "Jenny Alexandra", "", "1 and\n  2"], ["Lillo", "Rosa E.", "", "1 and\n  2"], ["Ucar", "I\u00f1aki", ""]]}, {"id": "2102.03892", "submitter": "Ye Tian", "authors": "Ye Tian, Yang Feng", "title": "RaSE: A Variable Screening Framework via Random Subspace Ensembles", "comments": "58 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable screening methods have been shown to be effective in dimension\nreduction under the ultra-high dimensional setting. Most existing screening\nmethods are designed to rank the predictors according to their individual\ncontributions to the response. As a result, variables that are marginally\nindependent but jointly dependent with the response could be missed. In this\nwork, we propose a new framework for variable screening, Random Subspace\nEnsemble (RaSE), which works by evaluating the quality of random subspaces that\nmay cover multiple predictors. This new screening framework can be naturally\ncombined with any subspace evaluation criterion, which leads to an array of\nscreening methods. The framework is capable to identify signals with no\nmarginal effect or with high-order interaction effects. It is shown to enjoy\nthe sure screening property and rank consistency. We also develop an iterative\nversion of RaSE screening with theoretical support. Extensive simulation\nstudies and real-data analysis show the effectiveness of the new screening\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 19:24:52 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 21:14:13 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 16:04:34 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Tian", "Ye", ""], ["Feng", "Yang", ""]]}, {"id": "2102.03895", "submitter": "Jiacheng Zhu", "authors": "Jiacheng Zhu, Aritra Guha, Dat Do, Mengdi Xu, XuanLong Nguyen, Ding\n  Zhao", "title": "Functional optimal transport: map estimation and domain adaptation for\n  functional data", "comments": "23 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a formulation of optimal transport problem for distributions on\nfunction spaces, where the stochastic map between functional domains can be\npartially represented in terms of an (infinite-dimensional) Hilbert-Schmidt\noperator mapping a Hilbert space of functions to another. For numerous machine\nlearning tasks, data can be naturally viewed as samples drawn from spaces of\nfunctions, such as curves and surfaces, in high dimensions. Optimal transport\nfor functional data analysis provides a useful framework of treatment for such\ndomains. In this work, we develop an efficient algorithm for finding the\nstochastic transport map between functional domains and provide theoretical\nguarantees on the existence, uniqueness, and consistency of our estimate for\nthe Hilbert-Schmidt operator. We validate our method on synthetic datasets and\nstudy the geometric properties of the transport map. Experiments on real-world\ndatasets of robot arm trajectories further demonstrate the effectiveness of our\nmethod on applications in domain adaptation.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 19:29:28 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 17:40:37 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 18:58:42 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhu", "Jiacheng", ""], ["Guha", "Aritra", ""], ["Do", "Dat", ""], ["Xu", "Mengdi", ""], ["Nguyen", "XuanLong", ""], ["Zhao", "Ding", ""]]}, {"id": "2102.03906", "submitter": "Dominik Janzing", "authors": "Dominik Janzing", "title": "Causal version of Principle of Insufficient Reason and MaxEnt", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Principle of insufficient Reason (PIR) assigns equal probabilities to\neach alternative of a random experiment whenever there is no reason to prefer\none over the other. Maximum Entropy (MaxEnt) generalizes PIR to the case where\nstatistical information like expectations are given. It is known that both\nprinciples result in paradox probability updates for joint distributions of\ncause and effect. This is because constraints on the conditional P(effect |\ncause) result in changes of P(cause) that assign higher probability to those\nvalues of the cause that offer more options for the effect, suggesting\n'intentional behaviour'. Earlier work therefore suggested sequentially\nmaximizing (conditional) entropy according to the causal order, but without\nfurther justification apart from plausibility for toy examples. We justify\ncausal modifications of PIR and MaxEnt by separating constraints into\nrestrictions for the cause and restrictions for the mechanism that generates\nthe effect from the cause. We further sketch why Causal PIR also entails\n'Information Geometric Causal Inference'.\n  We briefly discuss problems of generalizing the causal version of MaxEnt to\narbitrary causal DAGs.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 20:36:43 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Janzing", "Dominik", ""]]}, {"id": "2102.03926", "submitter": "Kaiyi Ji", "authors": "Kaiyi Ji and Yingbin Liang", "title": "Lower Bounds and Accelerated Algorithms for Bilevel Optimization", "comments": "33 pages, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization has recently attracted growing interests due to its wide\napplications in modern machine learning problems. Although recent studies have\ncharacterized the convergence rate for several such popular algorithms, it is\nstill unclear how much further these convergence rates can be improved. In this\npaper, we address this fundamental question from two perspectives. First, we\nprovide the first-known lower complexity bounds of\n$\\widetilde{\\Omega}(\\frac{1}{\\sqrt{\\mu_x}\\mu_y})$ and $\\widetilde\n\\Omega\\big(\\frac{1}{\\sqrt{\\epsilon}}\\min\\{\\frac{1}{\\mu_y},\\frac{1}{\\sqrt{\\epsilon^{3}}}\\}\\big)$\nrespectively for strongly-convex-strongly-convex and convex-strongly-convex\nbilevel optimizations. Second, we propose an accelerated bilevel optimizer\nnamed AccBiO, whose complexity improves the existing upper bounds orderwisely\nunder strongly-convex-strongly-convex, convex-strongly-convex and\nnonconvex-strongly-convex geometries. We further show that AccBiO achieves the\noptimal results (i.e., the upper and lower bounds match) under certain\nconditions up to logarithmic factors. Interestingly, our lower bounds under\nboth geometries are larger than the corresponding optimal complexities of\nminimax optimization, establishing that bilevel optimization is provably more\nchallenging than minimax optimization. We finally discuss the extensions and\napplications of our results to other problems such as minimax optimization.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 21:46:29 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 16:07:14 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ji", "Kaiyi", ""], ["Liang", "Yingbin", ""]]}, {"id": "2102.03935", "submitter": "Ramin Bostanabad", "authors": "Nicholas Oune, Ramin Bostanabad", "title": "Latent Map Gaussian Processes for Mixed Variable Metamodeling", "comments": "35 Pages, 7 Figures, 14 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian processes (GPs) are ubiquitously used in sciences and engineering as\nmetamodels. Standard GPs, however, can only handle numerical or quantitative\nvariables. In this paper, we introduce latent map Gaussian processes (LMGPs)\nthat inherit the attractive properties of GPs and are also applicable to mixed\ndata which have both quantitative and qualitative inputs. The core idea behind\nLMGPs is to learn a continuous, low-dimensional latent space or manifold which\nencodes all qualitative inputs. To learn this manifold, we first assign a\nunique prior vector representation to each combination of qualitative inputs.\nWe then use a low-rank linear map to project these priors on a manifold that\ncharacterizes the posterior representations. As the posteriors are\nquantitative, they can be directly used in any standard correlation function\nsuch as the Gaussian or Matern. Hence, the optimal map and the corresponding\nmanifold, along with other hyperparameters of the correlation function, can be\nsystematically learned via maximum likelihood estimation. Through a wide range\nof analytic and real-world examples, we demonstrate the advantages of LMGPs\nover state-of-the-art methods in terms of accuracy and versatility. In\nparticular, we show that LMGPs can handle variable-length inputs, have an\nexplainable neural network interpretation, and provide insights into how\nqualitative inputs affect the response or interact with each other. We also\nemploy LMGPs in Bayesian optimization and illustrate that they can discover\noptimal compound compositions more efficiently than conventional methods that\nconvert compositions to qualitative variables via manual featurization.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 22:21:53 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 19:20:37 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Oune", "Nicholas", ""], ["Bostanabad", "Ramin", ""]]}, {"id": "2102.03948", "submitter": "Serge Vicente Vicente", "authors": "Serge Vicente, Alejandro Murua", "title": "Determinantal consensus clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random restart of a given algorithm produces many partitions to yield a\nconsensus clustering. Ensemble methods such as consensus clustering have been\nrecognized as more robust approaches for data clustering than single clustering\nalgorithms. We propose the use of determinantal point processes or DPP for the\nrandom restart of clustering algorithms based on initial sets of center points,\nsuch as k-medoids or k-means. The relation between DPP and kernel-based methods\nmakes DPPs suitable to describe and quantify similarity between objects. DPPs\nfavor diversity of the center points within subsets. So, subsets with more\nsimilar points have less chances of being generated than subsets with very\ndistinct points. The current and most popular sampling technique is sampling\ncenter points uniformly at random. We show through extensive simulations that,\ncontrary to DPP, this technique fails both to ensure diversity, and to obtain a\ngood coverage of all data facets. These two properties of DPP are key to make\nDPPs achieve good performance with small ensembles. Simulations with artificial\ndatasets and applications to real datasets show that determinantal consensus\nclustering outperform classical algorithms such as k-medoids and k-means\nconsensus clusterings which are based on uniform random sampling of center\npoints.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 23:48:24 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Vicente", "Serge", ""], ["Murua", "Alejandro", ""]]}, {"id": "2102.03977", "submitter": "Sainyam Galhotra", "authors": "Sainyam Galhotra, Sandhya Saisubramanian and Shlomo Zilberstein", "title": "Learning to Generate Fair Clusters from Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fair clustering is the process of grouping similar entities together, while\nsatisfying a mathematically well-defined fairness metric as a constraint. Due\nto the practical challenges in precise model specification, the prescribed\nfairness constraints are often incomplete and act as proxies to the intended\nfairness requirement, leading to biased outcomes when the system is deployed.\nWe examine how to identify the intended fairness constraint for a problem based\non limited demonstrations from an expert. Each demonstration is a clustering\nover a subset of the data.\n  We present an algorithm to identify the fairness metric from demonstrations\nand generate clusters using existing off-the-shelf clustering techniques, and\nanalyze its theoretical properties. To extend our approach to novel fairness\nmetrics for which clustering algorithms do not currently exist, we present a\ngreedy method for clustering. Additionally, we investigate how to generate\ninterpretable solutions using our approach. Empirical evaluation on three\nreal-world datasets demonstrates the effectiveness of our approach in quickly\nidentifying the underlying fairness and interpretability constraints, which are\nthen used to generate fair and interpretable clusters.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 03:09:33 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "2102.04000", "submitter": "Yu Inatsu", "authors": "Yu Inatsu, Shogo Iwazaki, Ichiro Takeuchi", "title": "Active learning for distributionally robust level-set estimation", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cases exist in which a black-box function $f$ with high evaluation cost\ndepends on two types of variables $\\bm x$ and $\\bm w$, where $\\bm x$ is a\ncontrollable \\emph{design} variable and $\\bm w$ are uncontrollable\n\\emph{environmental} variables that have random variation following a certain\ndistribution $P$. In such cases, an important task is to find the range of\ndesign variables $\\bm x$ such that the function $f(\\bm x, \\bm w)$ has the\ndesired properties by incorporating the random variation of the environmental\nvariables $\\bm w$. A natural measure of robustness is the probability that\n$f(\\bm x, \\bm w)$ exceeds a given threshold $h$, which is known as the\n\\emph{probability threshold robustness} (PTR) measure in the literature on\nrobust optimization. However, this robustness measure cannot be correctly\nevaluated when the distribution $P$ is unknown. In this study, we addressed\nthis problem by considering the \\textit{distributionally robust PTR} (DRPTR)\nmeasure, which considers the worst-case PTR within given candidate\ndistributions. Specifically, we studied the problem of efficiently identifying\na reliable set $H$, which is defined as a region in which the DRPTR measure\nexceeds a certain desired probability $\\alpha$, which can be interpreted as a\nlevel set estimation (LSE) problem for DRPTR. We propose a theoretically\ngrounded and computationally efficient active learning method for this problem.\nWe show that the proposed method has theoretical guarantees on convergence and\naccuracy, and confirmed through numerical experiments that the proposed method\noutperforms existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 04:43:31 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Inatsu", "Yu", ""], ["Iwazaki", "Shogo", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2102.04008", "submitter": "Seungwoong Ha", "authors": "Seungwoong Ha and Hawoong Jeong", "title": "Discovering conservation laws from trajectories via machine learning", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.class-ph physics.comp-ph physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Invariants and conservation laws convey critical information about the\nunderlying dynamics of a system, yet it is generally infeasible to find them\nfrom large-scale data without any prior knowledge or human insight. We propose\nConservNet to achieve this goal, a neural network that spontaneously discovers\na conserved quantity from grouped data where the members of each group share\ninvariants, similar to a general experimental setting where trajectories from\ndifferent trials are observed. As a neural network trained with a novel and\nintuitive loss function called noise-variance loss, ConservNet learns the\nhidden invariants in each group of multi-dimensional observables in a\ndata-driven, end-to-end manner. Our model successfully discovers underlying\ninvariants from the simulated systems having invariants as well as a real-world\ndouble pendulum trajectory. Since the model is robust to various noises and\ndata conditions compared to baseline, our approach is directly applicable to\nexperimental data for discovering hidden conservation laws and further, general\nrelationships between variables.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 05:51:21 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 17:01:16 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ha", "Seungwoong", ""], ["Jeong", "Hawoong", ""]]}, {"id": "2102.04050", "submitter": "Tom Hess", "authors": "Tom Hess, Michal Moshkovitz and Sivan Sabato", "title": "A Constant Approximation Algorithm for Sequential Random-Order\n  No-Substitution k-Median Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study k-median clustering under the sequential no-substitution setting. In\nthis setting, a data stream is sequentially observed, and some of the points\nare selected by the algorithm as cluster centers. However, a point can be\nselected as a center only immediately after it is observed, before observing\nthe next point. In addition, a selected center cannot be substituted later. We\ngive the first algorithm for this setting that obtains a constant approximation\nfactor on the optimal risk under a random arrival order, an exponential\nimprovement over previous work. This is also the first constant approximation\nguarantee that holds without any structural assumptions on the input data.\nMoreover, the number of selected centers is only quasi-linear in k. Our\nalgorithm and analysis are based on a careful risk estimation that avoids\noutliers, a new concept of a linear bin division, and a multiscale approach to\ncenter selection.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 08:25:29 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 13:49:37 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hess", "Tom", ""], ["Moshkovitz", "Michal", ""], ["Sabato", "Sivan", ""]]}, {"id": "2102.04074", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Learning Curve Theory", "comments": "26 pages, 6 Figures", "journal-ref": "Latest 2021 version at http://www.hutter1.net/publ/scaling.pdf", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently a number of empirical \"universal\" scaling law papers have been\npublished, most notably by OpenAI. `Scaling laws' refers to power-law decreases\nof training or test error w.r.t. more data, larger neural networks, and/or more\ncompute. In this work we focus on scaling w.r.t. data size $n$. Theoretical\nunderstanding of this phenomenon is largely lacking, except in\nfinite-dimensional models for which error typically decreases with $n^{-1/2}$\nor $n^{-1}$, where $n$ is the sample size. We develop and theoretically analyse\nthe simplest possible (toy) model that can exhibit $n^{-\\beta}$ learning curves\nfor arbitrary power $\\beta>0$, and determine whether power laws are universal\nor depend on the data distribution.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 09:25:31 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "2102.04108", "submitter": "Hiroaki Yamada", "authors": "Hiroaki Yamada, Makoto Yamada", "title": "Dynamic Sasvi: Strong Safe Screening for Norm-Regularized Least Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recently introduced technique for a sparse optimization problem called\n\"safe screening\" allows us to identify irrelevant variables in the early stage\nof optimization. In this paper, we first propose a flexible framework for safe\nscreening based on the Fenchel-Rockafellar duality and then derive a strong\nsafe screening rule for norm-regularized least squares by the framework. We\ncall the proposed screening rule for norm-regularized least squares \"dynamic\nSasvi\" because it can be interpreted as a generalization of Sasvi. Unlike the\noriginal Sasvi, it does not require the exact solution of a more strongly\nregularized problem; hence, it works safely in practice. We show that our\nscreening rule can eliminate more features and increase the speed of the solver\nin comparison with other screening rules both theoretically and experimentally.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:25:40 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Yamada", "Hiroaki", ""], ["Yamada", "Makoto", ""]]}, {"id": "2102.04145", "submitter": "Zheng Wang", "authors": "Bruno Abrahao, Zheng Wang, Haider Ahmed, Yuchen Zhu", "title": "Model Rectification via Unknown Unknowns Extraction from Deployment\n  Samples", "comments": "18 pages (7 pages for supplementary materials)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model deficiency that results from incomplete training data is a form of\nstructural blindness that leads to costly errors, oftentimes with high\nconfidence. During the training of classification tasks, underrepresented\nclass-conditional distributions that a given hypothesis space can recognize\nresults in a mismatch between the model and the target space. To mitigate the\nconsequences of this discrepancy, we propose Random Test Sampling and\nCross-Validation (RTSCV) as a general algorithmic framework that aims to\nperform a post-training model rectification at deployment time in a supervised\nway. RTSCV extracts unknown unknowns (u.u.s), i.e., examples from the\nclass-conditional distributions that a classifier is oblivious to, and works in\ncombination with a diverse family of modern prediction models. RTSCV augments\nthe training set with a sample of the test set (or deployment data) and uses\nthis redefined class layout to discover u.u.s via cross-validation, without\nrelying on active learning or budgeted queries to an oracle. We contribute a\ntheoretical analysis that establishes performance guarantees based on the\ndesign bases of modern classifiers. Our experimental evaluation demonstrates\nRTSCV's effectiveness, using 7 benchmark tabular and computer vision datasets,\nby reducing a performance gap as large as 41% from the respective\npre-rectification models. Last we show that RTSCV consistently outperforms\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 11:46:19 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Abrahao", "Bruno", ""], ["Wang", "Zheng", ""], ["Ahmed", "Haider", ""], ["Zhu", "Yuchen", ""]]}, {"id": "2102.04152", "submitter": "Brian McWilliams", "authors": "Ian Gemp and Brian McWilliams and Claire Vernade and Thore Graepel", "title": "EigenGame Unloaded: When playing games is better than optimizing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build on the recently proposed EigenGame that views eigendecomposition as\na competitive game. EigenGame's updates are biased if computed using\nminibatches of data, which hinders convergence and more sophisticated\nparallelism in the stochastic setting. In this work, we propose an unbiased\nstochastic update that is asymptotically equivalent to EigenGame, enjoys\ngreater parallelism allowing computation on datasets of larger sample sizes,\nand outperforms EigenGame in experiments. We present applications to finding\nthe principal components of massive datasets and performing spectral clustering\nof graphs. We analyze and discuss our proposed update in the context of\nEigenGame and the shift in perspective from optimization to games.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 12:04:59 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Gemp", "Ian", ""], ["McWilliams", "Brian", ""], ["Vernade", "Claire", ""], ["Graepel", "Thore", ""]]}, {"id": "2102.04154", "submitter": "Jan Metzen", "authors": "Jan Hendrik Metzen, Maksym Yatsura", "title": "Efficient Certified Defenses Against Patch Attacks on Image Classifiers", "comments": "accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial patches pose a realistic threat model for physical world attacks\non autonomous systems via their perception component. Autonomous systems in\nsafety-critical domains such as automated driving should thus contain a\nfail-safe fallback component that combines certifiable robustness against\npatches with efficient inference while maintaining high performance on clean\ninputs. We propose BagCert, a novel combination of model architecture and\ncertification procedure that allows efficient certification. We derive a loss\nthat enables end-to-end optimization of certified robustness against patches of\ndifferent sizes and locations. On CIFAR10, BagCert certifies 10.000 examples in\n43 seconds on a single GPU and obtains 86% clean and 60% certified accuracy\nagainst 5x5 patches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 12:11:41 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Metzen", "Jan Hendrik", ""], ["Yatsura", "Maksym", ""]]}, {"id": "2102.04208", "submitter": "Daniel Hesslow", "authors": "Daniel Hesslow and Iacopo Poli", "title": "Contrastive Embeddings for Neural Architectures", "comments": "Add \"This project has received funding from the European Union's\n  Horizon 2020 research and innovation programme under the Marie\n  Sklodowska-Curie grant agreement No 860830\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of algorithms for neural architecture search strongly depends\non the parametrization of the search space. We use contrastive learning to\nidentify networks across different initializations based on their data\nJacobians, and automatically produce the first architecture embeddings\nindependent from the parametrization of the search space. Using our contrastive\nembeddings, we show that traditional black-box optimization algorithms, without\nmodification, can reach state-of-the-art performance in Neural Architecture\nSearch. As our method provides a unified embedding space, we perform for the\nfirst time transfer learning between search spaces. Finally, we show the\nevolution of embeddings during training, motivating future studies into using\nembeddings at different training stages to gain a deeper understanding of the\nnetworks in a search space.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 14:06:35 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 13:24:07 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Hesslow", "Daniel", ""], ["Poli", "Iacopo", ""]]}, {"id": "2102.04259", "submitter": "Mathieu Even", "authors": "Mathieu Even and Laurent Massouli\\'e", "title": "Concentration of Non-Isotropic Random Tensors with Applications to\n  Learning and Empirical Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dimension is an inherent bottleneck to some modern learning tasks, where\noptimization methods suffer from the size of the data. In this paper, we study\nnon-isotropic distributions of data and develop tools that aim at reducing\nthese dimensional costs by a dependency on an effective dimension rather than\nthe ambient one. Based on non-asymptotic estimates of the metric entropy of\nellipsoids -- that prove to generalize to infinite dimensions -- and on a\nchaining argument, our uniform concentration bounds involve an effective\ndimension instead of the global dimension, improving over existing results. We\nshow the importance of taking advantage of non-isotropic properties in learning\nproblems with the following applications: i) we improve state-of-the-art\nresults in statistical preconditioning for communication-efficient distributed\noptimization, ii) we introduce a non-isotropic randomized smoothing for\nnon-smooth optimization. Both applications cover a class of functions that\nencompasses empirical risk minization (ERM) for linear models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 17:13:03 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 08:47:50 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Even", "Mathieu", ""], ["Massouli\u00e9", "Laurent", ""]]}, {"id": "2102.04263", "submitter": "Tanut Treetanthiploet", "authors": "Samuel Cohen and Tanut Treetanthiploet", "title": "Correlated Bandits for Dynamic Pricing via the ARC algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE cs.LG econ.GN q-fin.EC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Asymptotic Randomised Control (ARC) algorithm provides a rigorous\napproximation to the optimal strategy for a wide class of Bayesian bandits,\nwhile retaining reasonable computational complexity. In particular, it allows a\ndecision maker to observe signals in addition to their rewards, to incorporate\ncorrelations between the outcomes of different choices, and to have nontrivial\ndynamics for their estimates. The algorithm is guaranteed to asymptotically\noptimise the expected discounted payoff, with error depending on the initial\nuncertainty of the bandit. In this paper, we consider a batched bandit problem\nwhere observations arrive from a generalised linear model; we extend the ARC\nalgorithm to this setting. We apply this to a classic dynamic pricing problem\nbased on a Bayesian hierarchical model and demonstrate that the ARC algorithm\noutperforms alternative approaches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 14:54:26 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Cohen", "Samuel", ""], ["Treetanthiploet", "Tanut", ""]]}, {"id": "2102.04269", "submitter": "Sebastian Kaltenbach", "authors": "Sebastian Kaltenbach, Phaedon-Stelios Koutsourelakis", "title": "Physics-aware, deep probabilistic modeling of multiscale dynamics in the\n  Small Data regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data-based discovery of effective, coarse-grained (CG) models of\nhigh-dimensional dynamical systems presents a unique challenge in computational\nphysics and particularly in the context of multiscale problems. The present\npaper offers a probabilistic perspective that simultaneously identifies\npredictive, lower-dimensional coarse-grained (CG) variables as well as their\ndynamics. We make use of the expressive ability of deep neural networks in\norder to represent the right-hand side of the CG evolution law. Furthermore, we\ndemonstrate how domain knowledge that is very often available in the form of\nphysical constraints (e.g. conservation laws) can be incorporated with the\nnovel concept of virtual observables. Such constraints, apart from leading to\nphysically realistic predictions, can significantly reduce the requisite amount\nof training data which enables reducing the amount of required, computationally\nexpensive multiscale simulations (Small Data regime). The proposed state-space\nmodel is trained using probabilistic inference tools and, in contrast to\nseveral other techniques, does not require the prescription of a fine-to-coarse\n(restriction) projection nor time-derivatives of the state variables. The\nformulation adopted is capable of quantifying the predictive uncertainty as\nwell as of reconstructing the evolution of the full, fine-scale system which\nallows to select the quantities of interest a posteriori. We demonstrate the\nefficacy of the proposed framework in a high-dimensional system of moving\nparticles.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 15:04:05 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 18:50:32 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kaltenbach", "Sebastian", ""], ["Koutsourelakis", "Phaedon-Stelios", ""]]}, {"id": "2102.04279", "submitter": "Zhiyan Ding", "authors": "Zhiyan Ding and Qin Li", "title": "Constrained Ensemble Langevin Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The classical Langevin Monte Carlo method looks for i.i.d. samples from a\ntarget distribution by descending along the gradient of the target\ndistribution. It is popular partially due to its fast convergence rate.\nHowever, the numerical cost is sometimes high because the gradient can be hard\nto obtain. One approach to eliminate the gradient computation is to employ the\nconcept of \"ensemble\", where a large number of particles are evolved together\nso that the neighboring particles provide gradient information to each other.\nIn this article, we discuss two algorithms that integrate the ensemble feature\ninto LMC, and the associated properties. There are two sides of our discovery:\n  1. By directly surrogating the gradient using the ensemble approximation, we\ndevelop Ensemble Langevin Monte Carlo. We show that this method is unstable due\nto a potentially small denominator that induces high variance. We provide a\ncounterexample to explicitly show this instability.\n  2. We then change the strategy and enact the ensemble approximation to the\ngradient only in a constrained manner, to eliminate the unstable points. The\nalgorithm is termed Constrained Ensemble Langevin Monte Carlo. We show that,\nwith a proper tuning, the surrogation takes place often enough to bring the\nreasonable numerical saving, while the induced error is still low enough for us\nto maintain the fast convergence rate, up to a controllable discretization and\nensemble error.\n  Such combination of ensemble method and LMC shed light on inventing\ngradient-free algorithms that produce i.i.d. samples almost exponentially fast.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 15:30:37 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 16:00:42 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ding", "Zhiyan", ""], ["Li", "Qin", ""]]}, {"id": "2102.04297", "submitter": "Xingyu Wang", "authors": "Xingyu Wang, Sewoong Oh, Chang-Han Rhee", "title": "Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise", "comments": "94 pages (24 pages for the main paper and 70 pages for the\n  supplementary materials), 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The empirical success of deep learning is often attributed to SGD's\nmysterious ability to avoid sharp local minima in the loss landscape, as sharp\nminima are known to lead to poor generalization. Recently, empirical evidence\nof heavy-tailed gradient noise was reported in many deep learning tasks, and it\nwas shown in \\c{S}im\\c{s}ekli (2019a,b) that SGD can escape sharp local minima\nunder the presence of such heavy-tailed gradient noise, providing a partial\nsolution to the mystery. In this work, we analyze a popular variant of SGD\nwhere gradients are truncated above a fixed threshold. We show that it achieves\na stronger notion of avoiding sharp minima: it can effectively eliminate sharp\nlocal minima entirely from its training trajectory. We characterize the\ndynamics of truncated SGD driven by heavy-tailed noises. First, we show that\nthe truncation threshold and width of the attraction field dictate the order of\nthe first exit time from the associated local minimum. Moreover, when the\nobjective function satisfies appropriate structural conditions, we prove that\nas the learning rate decreases, the dynamics of heavy-tailed truncated SGD\nclosely resemble those of a continuous-time Markov chain that never visits any\nsharp minima. Real data experiments on deep learning confirm our theoretical\nprediction that heavy-tailed SGD with gradient clipping finds a \"flatter\" local\nminima and achieves better generalization.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:03:49 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 21:19:13 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 06:05:05 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Wang", "Xingyu", ""], ["Oh", "Sewoong", ""], ["Rhee", "Chang-Han", ""]]}, {"id": "2102.04313", "submitter": "Zoe Holmes", "authors": "Joe Gibbs, Kaitlin Gili, Zo\\\"e Holmes, Benjamin Commeau, Andrew\n  Arrasmith, Lukasz Cincio, Patrick J. Coles and Andrew Sornborger", "title": "Long-time simulations with high fidelity on quantum hardware", "comments": "Main text: 14 pages, 11 Figures. Appendices: 10 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": "LA-UR-21-21053", "categories": "quant-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Moderate-size quantum computers are now publicly accessible over the cloud,\nopening the exciting possibility of performing dynamical simulations of quantum\nsystems. However, while rapidly improving, these devices have short coherence\ntimes, limiting the depth of algorithms that may be successfully implemented.\nHere we demonstrate that, despite these limitations, it is possible to\nimplement long-time, high fidelity simulations on current hardware.\nSpecifically, we simulate an XY-model spin chain on the Rigetti and IBM quantum\ncomputers, maintaining a fidelity of at least 0.9 for over 600 time steps. This\nis a factor of 150 longer than is possible using the iterated Trotter method.\nOur simulations are performed using a new algorithm that we call the fixed\nstate Variational Fast Forwarding (fsVFF) algorithm. This algorithm decreases\nthe circuit depth and width required for a quantum simulation by finding an\napproximate diagonalization of a short time evolution unitary. Crucially, fsVFF\nonly requires finding a diagonalization on the subspace spanned by the initial\nstate, rather than on the total Hilbert space as with previous methods,\nsubstantially reducing the required resources. We further demonstrate the\nviability of fsVFF through large numerical implementations of the algorithm, as\nwell as an analysis of its noise resilience and the scaling of simulation\nerrors.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:18:50 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 11:49:55 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Gibbs", "Joe", ""], ["Gili", "Kaitlin", ""], ["Holmes", "Zo\u00eb", ""], ["Commeau", "Benjamin", ""], ["Arrasmith", "Andrew", ""], ["Cincio", "Lukasz", ""], ["Coles", "Patrick J.", ""], ["Sornborger", "Andrew", ""]]}, {"id": "2102.04342", "submitter": "Jesse Russell", "authors": "Jesse Russell", "title": "The Limits of Computation in Solving Equity Trade-Offs in Machine\n  Learning and Justice System Risk Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper explores how different ideas of racial equity in machine learning,\nin justice settings in particular, can present trade-offs that are difficult to\nsolve computationally. Machine learning is often used in justice settings to\ncreate risk assessments, which are used to determine interventions, resources,\nand punitive actions. Overall aspects and performance of these machine\nlearning-based tools, such as distributions of scores, outcome rates by levels,\nand the frequency of false positives and true positives, can be problematic\nwhen examined by racial group. Models that produce different distributions of\nscores or produce a different relationship between level and outcome are\nproblematic when those scores and levels are directly linked to the restriction\nof individual liberty and to the broader context of racial inequity. While\ncomputation can help highlight these aspects, data and computation are unlikely\nto solve them. This paper explores where values and mission might have to fill\nthe spaces computation leaves.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:46:29 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Russell", "Jesse", ""]]}, {"id": "2102.04373", "submitter": "Calvin Tsay", "authors": "Calvin Tsay and Jan Kronqvist and Alexander Thebelt and Ruth Misener", "title": "Partition-based formulations for mixed-integer optimization of trained\n  ReLU neural networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a class of mixed-integer formulations for trained ReLU\nneural networks. The approach balances model size and tightness by partitioning\nnode inputs into a number of groups and forming the convex hull over the\npartitions via disjunctive programming. At one extreme, one partition per input\nrecovers the convex hull of a node, i.e., the tightest possible formulation for\neach node. For fewer partitions, we develop smaller relaxations that\napproximate the convex hull, and show that they outperform existing\nformulations. Specifically, we propose strategies for partitioning variables\nbased on theoretical motivations and validate these strategies using extensive\ncomputational experiments. Furthermore, the proposed scheme complements known\nalgorithmic approaches, e.g., optimization-based bound tightening captures\ndependencies within a partition.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:27:34 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tsay", "Calvin", ""], ["Kronqvist", "Jan", ""], ["Thebelt", "Alexander", ""], ["Misener", "Ruth", ""]]}, {"id": "2102.04376", "submitter": "Yannis Flet-Berliac", "authors": "Yannis Flet-Berliac and Johan Ferret and Olivier Pietquin and Philippe\n  Preux and Matthieu Geist", "title": "Adversarially Guided Actor-Critic", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite definite success in deep reinforcement learning problems,\nactor-critic algorithms are still confronted with sample inefficiency in\ncomplex environments, particularly in tasks where efficient exploration is a\nbottleneck. These methods consider a policy (the actor) and a value function\n(the critic) whose respective losses are built using different motivations and\napproaches. This paper introduces a third protagonist: the adversary. While the\nadversary mimics the actor by minimizing the KL-divergence between their\nrespective action distributions, the actor, in addition to learning to solve\nthe task, tries to differentiate itself from the adversary predictions. This\nnovel objective stimulates the actor to follow strategies that could not have\nbeen correctly predicted from previous trajectories, making its behavior\ninnovative in tasks where the reward is extremely rare. Our experimental\nanalysis shows that the resulting Adversarially Guided Actor-Critic (AGAC)\nalgorithm leads to more exhaustive exploration. Notably, AGAC outperforms\ncurrent state-of-the-art methods on a set of various hard-exploration and\nprocedurally-generated tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:31:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Flet-Berliac", "Yannis", ""], ["Ferret", "Johan", ""], ["Pietquin", "Olivier", ""], ["Preux", "Philippe", ""], ["Geist", "Matthieu", ""]]}, {"id": "2102.04396", "submitter": "Kiwon Lee", "authors": "Courtney Paquette, Kiwon Lee, Fabian Pedregosa and Elliot Paquette", "title": "SGD in the Large: Average-case Analysis, Asymptotics, and Stepsize\n  Criticality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework, inspired by random matrix theory, for analyzing\nthe dynamics of stochastic gradient descent (SGD) when both number of samples\nand dimensions are large. This framework applies to any fixed stepsize and the\nfinite sum setting. Using this new framework, we show that the dynamics of SGD\non a least squares problem with random data become deterministic in the large\nsample and dimensional limit. Furthermore, the limiting dynamics are governed\nby a Volterra integral equation. This model predicts that SGD undergoes a phase\ntransition at an explicitly given critical stepsize that ultimately affects its\nconvergence rate, which we also verify experimentally. Finally, when input data\nis isotropic, we provide explicit expressions for the dynamics and average-case\nconvergence rates (i.e., the complexity of an algorithm averaged over all\npossible inputs). These rates show significant improvement over the worst-case\ncomplexities.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:00:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Paquette", "Courtney", ""], ["Lee", "Kiwon", ""], ["Pedregosa", "Fabian", ""], ["Paquette", "Elliot", ""]]}, {"id": "2102.04401", "submitter": "Nikos Zarifis", "authors": "Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis", "title": "The Optimality of Polynomial Regression for Agnostic Learning under\n  Gaussian Marginals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of agnostic learning under the Gaussian distribution. We\ndevelop a method for finding hard families of examples for a wide class of\nproblems by using LP duality. For Boolean-valued concept classes, we show that\nthe $L^1$-regression algorithm is essentially best possible, and therefore that\nthe computational difficulty of agnostically learning a concept class is\nclosely related to the polynomial degree required to approximate any function\nfrom the class in $L^1$-norm. Using this characterization along with additional\nanalytic tools, we obtain optimal SQ lower bounds for agnostically learning\nlinear threshold functions and the first non-trivial SQ lower bounds for\npolynomial threshold functions and intersections of halfspaces. We also develop\nan analogous theory for agnostically learning real-valued functions, and as an\napplication prove near-optimal SQ lower bounds for agnostically learning ReLUs\nand sigmoids.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:06:32 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Pittas", "Thanasis", ""], ["Zarifis", "Nikos", ""]]}, {"id": "2102.04419", "submitter": "Ali Lafzi", "authors": "Ali Lafzi, Miad Boodaghi, Siavash Zamani, and Niyousha Mohammadshafie", "title": "Analysis of the Effectiveness of Face-Coverings on the Death Rate of\n  COVID-19 Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent outbreak of the COVID-19 shocked humanity leading to the death of\nmillions of people worldwide. To stave off the spread of the virus, the\nauthorities in the US, employed different strategies including the mask mandate\n(MM) order issued by the states' governors. Although most of the previous\nstudies pointed in the direction that MM can be effective in hindering the\nspread of viral infections, the effectiveness of MM in reducing the degree of\nexposure to the virus and, consequently, death rates remains indeterminate.\nIndeed, the extent to which the degree of exposure to COVID-19 takes part in\nthe lethality of the virus remains unclear. In the current work, we defined a\nparameter called the average death ratio as the monthly average of the ratio of\nthe number of daily deaths to the total number of daily cases. We utilized\nsurvey data provided by New York Times to quantify people's abidance to the MM\norder. Additionally, we implicitly addressed the extent to which people abide\nby the MM order that may depend on some parameters like population, income, and\npolitical inclination. Using different machine learning classification\nalgorithms we investigated how the decrease or increase in death ratio for the\ncounties in the US West Coast correlates with the input parameters. Our results\nshowed a promising score as high as 0.94 with algorithms like XGBoost, Random\nForest, and Naive Bayes. To verify the model, the best performing algorithms\nwere then utilized to analyze other states (Arizona, New Jersey, New York and\nTexas) as test cases. The findings show an acceptable trend, further confirming\nusability of the chosen features for prediction of similar cases.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:26:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lafzi", "Ali", ""], ["Boodaghi", "Miad", ""], ["Zamani", "Siavash", ""], ["Mohammadshafie", "Niyousha", ""]]}, {"id": "2102.04439", "submitter": "Mohammad Esmaeili", "authors": "Mohammad Esmaeili and Aria Nosratinia", "title": "Community Detection: Exact Recovery in Weighted Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In community detection, the exact recovery of communities (clusters) has been\nmainly investigated under the general stochastic block model with edges drawn\nfrom Bernoulli distributions. This paper considers the exact recovery of\ncommunities in a complete graph in which the graph edges are drawn from either\na set of Gaussian distributions with community-dependent means and variances,\nor a set of exponential distributions with community-dependent means. For each\ncase, we introduce a new semi-metric that describes sufficient and necessary\nconditions of exact recovery. The necessary and sufficient conditions are\nasymptotically tight. The analysis is also extended to incomplete, fully\nconnected weighted graphs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:54:29 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Esmaeili", "Mohammad", ""], ["Nosratinia", "Aria", ""]]}, {"id": "2102.04449", "submitter": "Hao Lei", "authors": "Hao Lei and Ying Chen", "title": "Concentrated Document Topic Model", "comments": "arXiv admin note: text overlap with arXiv:2102.03525", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a Concentrated Document Topic Model(CDTM) for unsupervised text\nclassification, which is able to produce a concentrated and sparse document\ntopic distribution. In particular, an exponential entropy penalty is imposed on\nthe document topic distribution. Documents that have diverse topic\ndistributions are penalized more, while those having concentrated topics are\npenalized less. We apply the model to the benchmark NIPS dataset and observe\nmore coherent topics and more concentrated and sparse document-topic\ndistributions than Latent Dirichlet Allocation(LDA).\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 07:12:05 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Lei", "Hao", ""], ["Chen", "Ying", ""]]}, {"id": "2102.04462", "submitter": "Stefano Favaro", "authors": "Emanuele Dolera, Stefano Favaro, Stefano Peluchetti", "title": "Learning-augmented count-min sketches via Bayesian nonparametrics", "comments": "40 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:2102.03743", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The count-min sketch (CMS) is a time and memory efficient randomized data\nstructure that provides estimates of tokens' frequencies in a data stream, i.e.\npoint queries, based on random hashed data. Learning-augmented CMSs improve the\nCMS by learning models that allow to better exploit data properties. In this\npaper, we focus on the learning-augmented CMS of Cai, Mitzenmacher and Adams\n(\\textit{NeurIPS} 2018), which relies on Bayesian nonparametric (BNP) modeling\nof a data stream via Dirichlet process (DP) priors. This is referred to as the\nCMS-DP, and it leads to BNP estimates of a point query as posterior means of\nthe point query given the hashed data. While BNPs is proved to be a powerful\ntool for developing robust learning-augmented CMSs, ideas and methods behind\nthe CMS-DP are tailored to point queries under DP priors, and they can not be\nused for other priors or more general queries. In this paper, we present an\nalternative, and more flexible, derivation of the CMS-DP such that: i) it\nallows to make use of the Pitman-Yor process (PYP) prior, which is arguably the\nmost popular generalization of the DP prior; ii) it can be readily applied to\nthe more general problem of estimating range queries. This leads to develop a\nnovel learning-augmented CMS under power-law data streams, referred to as the\nCMS-PYP, which relies on BNP modeling of the stream via PYP priors.\nApplications to synthetic and real data show that the CMS-PYP outperforms the\nCMS and the CMS-DP in the estimation of low-frequency tokens; this known to be\na critical feature in natural language processing, where it is indeed common to\nencounter power-law data streams.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:02:30 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Dolera", "Emanuele", ""], ["Favaro", "Stefano", ""], ["Peluchetti", "Stefano", ""]]}, {"id": "2102.04487", "submitter": "Divyansh Jhunjhunwala", "authors": "Divyansh Jhunjhunwala, Advait Gadhikar, Gauri Joshi, Yonina C. Eldar", "title": "Adaptive Quantization of Model Updates for Communication-Efficient\n  Federated Learning", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication of model updates between client nodes and the central\naggregating server is a major bottleneck in federated learning, especially in\nbandwidth-limited settings and high-dimensional models. Gradient quantization\nis an effective way of reducing the number of bits required to communicate each\nmodel update, albeit at the cost of having a higher error floor due to the\nhigher variance of the stochastic gradients. In this work, we propose an\nadaptive quantization strategy called AdaQuantFL that aims to achieve\ncommunication efficiency as well as a low error floor by changing the number of\nquantization levels during the course of training. Experiments on training deep\nneural networks show that our method can converge in much fewer communicated\nbits as compared to fixed quantization level setups, with little or no impact\non training and test accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 19:14:21 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Jhunjhunwala", "Divyansh", ""], ["Gadhikar", "Advait", ""], ["Joshi", "Gauri", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2102.04540", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, Haipeng Luo", "title": "Last-iterate Convergence of Decentralized Optimistic Gradient\n  Descent/Ascent in Infinite-horizon Competitive Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study infinite-horizon discounted two-player zero-sum Markov games, and\ndevelop a decentralized algorithm that provably converges to the set of Nash\nequilibria under self-play. Our algorithm is based on running an Optimistic\nGradient Descent Ascent algorithm on each state to learn the policies, with a\ncritic that slowly learns the value of each state. To the best of our\nknowledge, this is the first algorithm in this setting that is simultaneously\nrational (converging to the opponent's best response when it uses a stationary\npolicy), convergent (converging to the set of Nash equilibria under self-play),\nagnostic (no need to know the actions played by the opponent), symmetric\n(players taking symmetric roles in the algorithm), and enjoying a finite-time\nlast-iterate convergence guarantee, all of which are desirable properties of\ndecentralized algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 21:45:56 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 17:16:37 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Lee", "Chung-Wei", ""], ["Zhang", "Mengxiao", ""], ["Luo", "Haipeng", ""]]}, {"id": "2102.04613", "submitter": "Zhengmian Hu", "authors": "Zhengmian Hu, Feihu Huang, Heng Huang", "title": "A New Framework for Variance-Reduced Hamiltonian Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework of variance-reduced Hamiltonian Monte Carlo (HMC)\nmethods for sampling from an $L$-smooth and $m$-strongly log-concave\ndistribution, based on a unified formulation of biased and unbiased variance\nreduction methods. We study the convergence properties for HMC with gradient\nestimators which satisfy the Mean-Squared-Error-Bias (MSEB) property. We show\nthat the unbiased gradient estimators, including SAGA and SVRG, based HMC\nmethods achieve highest gradient efficiency with small batch size under high\nprecision regime, and require $\\tilde{O}(N + \\kappa^2 d^{\\frac{1}{2}}\n\\varepsilon^{-1} + N^{\\frac{2}{3}} \\kappa^{\\frac{4}{3}} d^{\\frac{1}{3}}\n\\varepsilon^{-\\frac{2}{3}} )$ gradient complexity to achieve\n$\\epsilon$-accuracy in 2-Wasserstein distance. Moreover, our HMC methods with\nbiased gradient estimators, such as SARAH and SARGE, require\n$\\tilde{O}(N+\\sqrt{N} \\kappa^2 d^{\\frac{1}{2}} \\varepsilon^{-1})$ gradient\ncomplexity, which has the same dependency on condition number $\\kappa$ and\ndimension $d$ as full gradient method, but improves the dependency of sample\nsize $N$ for a factor of $N^\\frac{1}{2}$. Experimental results on both\nsynthetic and real-world benchmark data show that our new framework\nsignificantly outperforms the full gradient and stochastic gradient HMC\napproaches. The earliest version of this paper was submitted to ICML 2020 with\nthree weak accept but was not finally accepted.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 02:44:24 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hu", "Zhengmian", ""], ["Huang", "Feihu", ""], ["Huang", "Heng", ""]]}, {"id": "2102.04635", "submitter": "Zhishuai Guo", "authors": "Zhuoning Yuan, Zhishuai Guo, Yi Xu, Yiming Ying, Tianbao Yang", "title": "Federated Deep AUC Maximization for Heterogeneous Data with a Constant\n  Communication Complexity", "comments": "Zhuoning and Zhishuai contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\underline{D}eep \\underline{A}UC (area under the ROC curve)\n\\underline{M}aximization (DAM) has attracted much attention recently due to its\ngreat potential for imbalanced data classification. However, the research on\n\\underline{F}ederated \\underline{D}eep \\underline{A}UC \\underline{M}aximization\n(FDAM) is still limited. Compared with standard federated learning (FL)\napproaches that focus on decomposable minimization objectives, FDAM is more\ncomplicated due to its minimization objective is non-decomposable over\nindividual examples. In this paper, we propose improved FDAM algorithms for\nheterogeneous data by solving the popular non-convex strongly-concave min-max\nformulation of DAM in a distributed fashion. A striking result of this paper is\nthat the communication complexity of the proposed algorithm is a constant\nindependent of the number of machines and also independent of the accuracy\nlevel, which improves an existing result by orders of magnitude. Of independent\ninterest, the proposed algorithm can also be applied to a class of\nnon-convex-strongly-concave min-max problems. The experiments have demonstrated\nthe effectiveness of our FDAM algorithm on benchmark datasets, and on medical\nchest X-ray images from different organizations. Our experiment shows that the\nperformance of FDAM using data from multiple hospitals can improve the AUC\nscore on testing data from a single hospital for detecting life-threatening\ndiseases based on chest radiographs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 04:05:19 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Yuan", "Zhuoning", ""], ["Guo", "Zhishuai", ""], ["Xu", "Yi", ""], ["Ying", "Yiming", ""], ["Yang", "Tianbao", ""]]}, {"id": "2102.04671", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Yuejiao Sun, Wotao Yin", "title": "A Single-Timescale Stochastic Bilevel Optimization Method", "comments": "Minor edits in Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic bilevel optimization generalizes the classic stochastic\noptimization from the minimization of a single objective to the minimization of\nan objective function that depends the solution of another optimization\nproblem. Recently, stochastic bilevel optimization is regaining popularity in\nemerging machine learning applications such as hyper-parameter optimization and\nmodel-agnostic meta learning. To solve this class of stochastic optimization\nproblems, existing methods require either double-loop or two-timescale updates,\nwhich are sometimes less efficient. This paper develops a new optimization\nmethod for a class of stochastic bilevel problems that we term Single-Timescale\nstochAstic BiLevEl optimization (STABLE) method. STABLE runs in a single loop\nfashion, and uses a single-timescale update with a fixed batch size. To achieve\nan $\\epsilon$-stationary point of the bilevel problem, STABLE requires ${\\cal\nO}(\\epsilon^{-2})$ samples in total; and to achieve an $\\epsilon$-optimal\nsolution in the strongly convex case, STABLE requires ${\\cal O}(\\epsilon^{-1})$\nsamples. To the best of our knowledge, this is the first bilevel optimization\nalgorithm achieving the same order of sample complexity as the stochastic\ngradient descent method for the single-level stochastic optimization.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 06:35:30 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 06:27:44 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Chen", "Tianyi", ""], ["Sun", "Yuejiao", ""], ["Yin", "Wotao", ""]]}, {"id": "2102.04683", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata and Yoshinobu Kawahara", "title": "Meta-Learning for Koopman Spectral Analysis with Short Time-series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Koopman spectral analysis has attracted attention for nonlinear dynamical\nsystems since we can analyze nonlinear dynamics with a linear regime by\nembedding data into a Koopman space by a nonlinear function. For the analysis,\nwe need to find appropriate embedding functions. Although several neural\nnetwork-based methods have been proposed for learning embedding functions,\nexisting methods require long time-series for training neural networks. This\nlimitation prohibits performing Koopman spectral analysis in applications where\nonly short time-series are available. In this paper, we propose a meta-learning\nmethod for estimating embedding functions from unseen short time-series by\nexploiting knowledge learned from related but different time-series. With the\nproposed method, a representation of a given short time-series is obtained by a\nbidirectional LSTM for extracting its properties. The embedding function of the\nshort time-series is modeled by a neural network that depends on the\ntime-series representation. By sharing the LSTM and neural networks across\nmultiple time-series, we can learn common knowledge from different time-series\nwhile modeling time-series-specific embedding functions with the time-series\nrepresentation. Our model is trained such that the expected test prediction\nerror is minimized with the episodic training framework. We experimentally\ndemonstrate that the proposed method achieves better performance in terms of\neigenvalue estimation and future prediction than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 07:19:19 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "2102.04704", "submitter": "Andrew Lowy", "authors": "Andrew Lowy and Meisam Razaviyayn", "title": "Output Perturbation for Differentially Private Convex Optimization with\n  Improved Population Loss Bounds, Runtimes and Applications to Private\n  Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding efficient, easily implementable differentially private (DP)\nalgorithms that offer strong excess risk bounds is an important problem in\nmodern machine learning. To date, most work has focused on private empirical\nrisk minimization (ERM) or private population loss minimization. However, there\nare often other objectives--such as fairness, adversarial robustness, or\nsensitivity to outliers--besides average performance that are not captured in\nthe classical ERM setup. To this end, we study a completely general family of\nconvex, Lipschitz loss functions and establish the first known DP excess risk\nand runtime bounds for optimizing this broad class. We provide similar bounds\nunder additional assumptions of smoothness and/or strong convexity. We also\naddress private stochastic convex optimization (SCO). While $(\\epsilon,\n\\delta)$-DP ($\\delta > 0$) has been the focus of much recent work in private\nSCO, proving tight population loss bounds and runtime bounds for $(\\epsilon,\n0)$-DP remains a challenging open problem. We provide the tightest known\n$(\\epsilon, 0)$-DP population loss bounds and fastest runtimes under the\npresence of (or lack of) smoothness and strong convexity. Our methods extend to\nthe $\\delta > 0$ setting, where we offer the unique benefit of ensuring\ndifferential privacy for arbitrary $\\epsilon > 0$ by incorporating a new form\nof Gaussian noise. Finally, we apply our theory to two learning frameworks:\ntilted ERM and adversarial learning. In particular, our theory quantifies\ntradeoffs between adversarial robustness, privacy, and runtime. Our results are\nachieved using perhaps the simplest DP algorithm: output perturbation. Although\nthis method is not novel conceptually, our novel implementation scheme and\nanalysis show that the power of this method to achieve strong privacy, utility,\nand runtime guarantees has not been fully appreciated in prior works.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 08:47:06 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Lowy", "Andrew", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "2102.04721", "submitter": "Xiaofan Liu", "authors": "Xiaofan Liua, Zuoquan Zhanga, Di Wanga", "title": "Classification of Imbalanced Credit scoring data sets Based on Ensemble\n  Method with the Weighted-Hybrid-Sampling", "comments": "Credit scoring, Imbalanced data, Data sampling, Boosting algorithm", "journal-ref": null, "doi": null, "report-no": "A20210209", "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the era of big data, the utilization of credit-scoring models to determine\nthe credit risk of applicants accurately becomes a trend in the future. The\nconventional machine learning on credit scoring data sets tends to have poor\nclassification for the minority class, which may bring huge commercial harm to\nbanks. In order to classify imbalanced data sets, we propose a new ensemble\nalgorithm, namely, Weighted-Hybrid-Sampling-Boost (WHSBoost). In data sampling,\nwe process the imbalanced data sets with weights by the Weighted-SMOTE method\nand the Weighted-Under-Sampling method, and thus obtain a balanced training\nsample data set with equal weight. In ensemble algorithm, each time we train\nthe base classifier, the balanced data set is given by the method above. In\norder to verify the applicability and robustness of the WHSBoost algorithm, we\nperformed experiments on the simulation data sets, real benchmark data sets and\nreal credit scoring data sets, comparing WHSBoost with SMOTE, SMOTEBoost and\nHSBoost based on SVM, BPNN, DT and KNN.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 09:32:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Liua", "Xiaofan", ""], ["Zhanga", "Zuoquan", ""], ["Wanga", "Di", ""]]}, {"id": "2102.04764", "submitter": "Cagatay Yildiz", "authors": "\\c{C}a\\u{g}atay Y{\\i}ld{\\i}z, Markus Heinonen, and Harri\n  L\\\"ahdesm\\\"aki", "title": "Continuous-Time Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) approaches rely on discrete-time\nstate transition models whereas physical systems and the vast majority of\ncontrol tasks operate in continuous-time. To avoid time-discretization\napproximation of the underlying process, we propose a continuous-time MBRL\nframework based on a novel actor-critic method. Our approach also infers the\nunknown state evolution differentials with Bayesian neural ordinary\ndifferential equations (ODE) to account for epistemic uncertainty. We implement\nand test our method on a new ODE-RL suite that explicitly solves\ncontinuous-time control systems. Our experiments illustrate that the model is\nrobust against irregular and noisy data, is sample-efficient, and can solve\ncontrol problems which pose challenges to discrete-time MBRL methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:30:19 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 08:46:17 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 07:21:29 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Y\u0131ld\u0131z", "\u00c7a\u011fatay", ""], ["Heinonen", "Markus", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "2102.04776", "submitter": "Emilien Dupont", "authors": "Emilien Dupont, Yee Whye Teh, Arnaud Doucet", "title": "Generative Models as Distributions of Functions", "comments": "Added point clouds experiments, quantitative evaluations and link to\n  github repo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models are typically trained on grid-like data such as images. As\na result, the size of these models usually scales directly with the underlying\ngrid resolution. In this paper, we abandon discretized grids and instead\nparameterize individual data points by continuous functions. We then build\ngenerative models by learning distributions over such functions. By treating\ndata points as functions, we can abstract away from the specific type of data\nwe train on and construct models that scale independently of signal resolution.\nTo train our model, we use an adversarial approach with a discriminator that\nacts on continuous signals. Through experiments on both images and 3D shapes,\nwe demonstrate that our model can learn rich distributions of functions\nindependently of data type and resolution.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:47:55 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 18:04:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Dupont", "Emilien", ""], ["Teh", "Yee Whye", ""], ["Doucet", "Arnaud", ""]]}, {"id": "2102.04801", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Gianluigi Silvestri and Marcel van Gerven", "title": "Automatic variational inference with cascading flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automation of probabilistic reasoning is one of the primary aims of\nmachine learning. Recently, the confluence of variational inference and deep\nlearning has led to powerful and flexible automatic inference methods that can\nbe trained by stochastic gradient descent. In particular, normalizing flows are\nhighly parameterized deep models that can fit arbitrarily complex posterior\ndensities. However, normalizing flows struggle in highly structured\nprobabilistic programs as they need to relearn the forward-pass of the program.\nAutomatic structured variational inference (ASVI) remedies this problem by\nconstructing variational programs that embed the forward-pass. Here, we combine\nthe flexibility of normalizing flows and the prior-embedding property of ASVI\nin a new family of variational programs, which we named cascading flows. A\ncascading flows program interposes a newly designed highway flow architecture\nin between the conditional distributions of the prior program such as to steer\nit toward the observed data. These programs can be constructed automatically\nfrom an input probabilistic program and can also be amortized automatically. We\nevaluate the performance of the new variational programs in a series of\nstructured inference problems. We find that cascading flows have much higher\nperformance than both normalizing flows and ASVI in a large set of structured\ninference problems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 12:44:39 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Ambrogioni", "Luca", ""], ["Silvestri", "Gianluigi", ""], ["van Gerven", "Marcel", ""]]}, {"id": "2102.04877", "submitter": "Soon Hoe Lim", "authors": "Soon Hoe Lim, N. Benjamin Erichson, Liam Hodgkinson, Michael W.\n  Mahoney", "title": "Noisy Recurrent Neural Networks", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a general framework for studying recurrent neural networks (RNNs)\ntrained by injecting noise into hidden states. Specifically, we consider RNNs\nthat can be viewed as discretizations of stochastic differential equations\ndriven by input data. This framework allows us to study the implicit\nregularization effect of general noise injection schemes by deriving an\napproximate explicit regularizer in the small noise regime. We find that, under\nreasonable assumptions, this implicit regularization promotes flatter minima;\nit biases towards models with more stable dynamics; and, in classification\ntasks, it favors models with larger classification margin. Sufficient\nconditions for global stability are obtained, highlighting the phenomenon of\nstochastic stabilization, where noise injection can improve stability during\ntraining. Our theory is supported by empirical results which demonstrate\nimproved robustness with respect to various input perturbations, while\nmaintaining state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 15:20:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Lim", "Soon Hoe", ""], ["Erichson", "N. Benjamin", ""], ["Hodgkinson", "Liam", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2102.04896", "submitter": "Dalton Sakthivadivel", "authors": "Dalton A R Sakthivadivel", "title": "Formalising the Use of the Activation Function in Neural Inference", "comments": "Six pages and one of references, two figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate how the activation function can be used to describe neural\nfiring in an abstract way, and in turn, why it works well in artificial neural\nnetworks. We discuss how a spike in a biological neurone belongs to a\nparticular universality class of phase transitions in statistical physics. We\nthen show that the artificial neurone is, mathematically, a mean field model of\nbiological neural membrane dynamics, which arises from modelling spiking as a\nphase transition. This allows us to treat selective neural firing in an\nabstract way, and formalise the role of the activation function in perceptron\nlearning. The resultant statistical physical model allows us to recover the\nexpressions for some known activation functions as various special cases. Along\nwith deriving this model and specifying the analogous neural case, we analyse\nthe phase transition to understand the physics of neural network learning.\nTogether, it is shown that there is not only a biological meaning, but a\nphysical justification, for the emergence and performance of typical activation\nfunctions; implications for neural learning and inference are also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 19:42:21 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 16:55:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Sakthivadivel", "Dalton A R", ""]]}, {"id": "2102.04951", "submitter": "Antonio Candelieri", "authors": "Antonio Candelieri, Francesco Archetti", "title": "MISO-wiLDCosts: Multi Information Source Optimization with Location\n  Dependent Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses black-box optimization over multiple information sources\nwhose both fidelity and query cost change over the search space, that is they\nare location dependent. The approach uses: (i) an Augmented Gaussian Process,\nrecently proposed in multi-information source optimization as a single model of\nthe objective function over search space and sources, and (ii) a Gaussian\nProcess to model the location-dependent cost of each source. The former is used\ninto a Confidence Bound based acquisition function to select the next source\nand location to query, while the latter is used to penalize the value of the\nacquisition depending on the expected query cost for any source-location pair.\nThe proposed approach is evaluated on a set of Hyperparameters Optimization\ntasks, consisting of two Machine Learning classifiers and three datasets of\ndifferent sizes.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 17:04:17 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Candelieri", "Antonio", ""], ["Archetti", "Francesco", ""]]}, {"id": "2102.04998", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Philip M. Long, Peter L. Bartlett", "title": "When does gradient descent with logistic loss interpolate using deep\n  networks with smoothed ReLU activations?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish conditions under which gradient descent applied to fixed-width\ndeep networks drives the logistic loss to zero, and prove bounds on the rate of\nconvergence. Our analysis applies for smoothed approximations to the ReLU, such\nas Swish and the Huberized ReLU, proposed in previous applied work. We provide\ntwo sufficient conditions for convergence. The first is simply a bound on the\nloss at initialization. The second is a data separation condition used in prior\nanalyses.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 18:04:37 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 04:14:30 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Long", "Philip M.", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "2102.05047", "submitter": "Max Hopkins", "authors": "Max Hopkins, Daniel Kane, Shachar Lovett, Michal Moshkovitz", "title": "Bounded Memory Active Learning through Enriched Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The explosive growth of easily-accessible unlabeled data has lead to growing\ninterest in active learning, a paradigm in which data-hungry learning\nalgorithms adaptively select informative examples in order to lower\nprohibitively expensive labeling costs. Unfortunately, in standard worst-case\nmodels of learning, the active setting often provides no improvement over\nnon-adaptive algorithms. To combat this, a series of recent works have\nconsidered a model in which the learner may ask enriched queries beyond labels.\nWhile such models have seen success in drastically lowering label costs, they\ntend to come at the expense of requiring large amounts of memory. In this work,\nwe study what families of classifiers can be learned in bounded memory. To this\nend, we introduce a novel streaming-variant of enriched-query active learning\nalong with a natural combinatorial parameter called lossless sample compression\nthat is sufficient for learning not only with bounded memory, but in a\nquery-optimal and computationally efficient manner as well. Finally, we give\nthree fundamental examples of classifier families with small, easy to compute\nlossless compression schemes when given access to basic enriched queries:\naxis-aligned rectangles, decision trees, and halfspaces in two dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 19:00:00 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Hopkins", "Max", ""], ["Kane", "Daniel", ""], ["Lovett", "Shachar", ""], ["Moshkovitz", "Michal", ""]]}, {"id": "2102.05075", "submitter": "Alex Lambert", "authors": "Alex Lambert, Sanjeel Parekh, Zolt\\'an Szab\\'o, Florence d'Alch\\'e-Buc", "title": "Emotion Transfer Using Vector-Valued Infinite Task Learning", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Style transfer is a significant problem of machine learning with numerous\nsuccessful applications. In this work, we present a novel style transfer\nframework building upon infinite task learning and vector-valued reproducing\nkernel Hilbert spaces. We instantiate the idea in emotion transfer where the\ngoal is to transform facial images to different target emotions. The proposed\napproach provides a principled way to gain explicit control over the continuous\nstyle space. We demonstrate the efficiency of the technique on popular facial\nemotion benchmarks, achieving low reconstruction cost and high emotion\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 19:05:56 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Lambert", "Alex", ""], ["Parekh", "Sanjeel", ""], ["Szab\u00f3", "Zolt\u00e1n", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "2102.05131", "submitter": "Dara Bahri", "authors": "Dara Bahri and Heinrich Jiang and Yi Tay and Donald Metzler", "title": "Label Smoothed Embedding Hypothesis for Out-of-Distribution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting out-of-distribution (OOD) examples is critical in many\napplications. We propose an unsupervised method to detect OOD samples using a\n$k$-NN density estimate with respect to a classification model's intermediate\nactivations on in-distribution samples. We leverage a recent insight about\nlabel smoothing, which we call the \\emph{Label Smoothed Embedding Hypothesis},\nand show that one of the implications is that the $k$-NN density estimator\nperforms better as an OOD detection method both theoretically and empirically\nwhen the model is trained with label smoothing. Finally, we show that our\nproposal outperforms many OOD baselines and also provide new finite-sample\nhigh-probability statistical results for $k$-NN density estimation's ability to\ndetect OOD examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 21:04:44 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bahri", "Dara", ""], ["Jiang", "Heinrich", ""], ["Tay", "Yi", ""], ["Metzler", "Donald", ""]]}, {"id": "2102.05135", "submitter": "Taman Narayan", "authors": "Taman Narayan, Serena Wang, Kevin Canini, Maya Gupta", "title": "Regularization Strategies for Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate different methods for regularizing quantile regression when\npredicting either a subset of quantiles or the full inverse CDF. We show that\nminimizing an expected pinball loss over a continuous distribution of quantiles\nis a good regularizer even when only predicting a specific quantile. For\npredicting multiple quantiles, we propose achieving the classic goal of\nnon-crossing quantiles by using deep lattice networks that treat the quantile\nas a monotonic input feature, and we discuss why monotonicity on other features\nis an apt regularizer for quantile regression. We show that lattice models\nenable regularizing the predicted distribution to a location-scale family.\nLastly, we propose applying rate constraints to improve the calibration of the\nquantile predictions on specific subsets of interest and improve fairness\nmetrics. We demonstrate our contributions on simulations, benchmark datasets,\nand real quantile regression problems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 21:10:35 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Narayan", "Taman", ""], ["Wang", "Serena", ""], ["Canini", "Kevin", ""], ["Gupta", "Maya", ""]]}, {"id": "2102.05164", "submitter": "X. Flora Meng", "authors": "X. Flora Meng, Tuhin Sarkar, Munther A. Dahleh", "title": "Nonstochastic Bandits with Infinitely Many Experts", "comments": "Added numerical experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of nonstochastic bandits with expert advice, extending\nthe setting from finitely many experts to any countably infinite set: A learner\naims to maximize the total reward by taking actions sequentially based on\nbandit feedback while benchmarking against a set of experts. We propose a\nvariant of Exp4.P that, for finitely many experts, enables inference of correct\nexpert rankings while preserving the order of the regret upper bound. We then\nincorporate the variant into a meta-algorithm that works on infinitely many\nexperts. We prove a high-probability upper bound of $\\tilde{\\mathcal{O}} \\big(\ni^*K + \\sqrt{KT} \\big)$ on the regret, up to polylog factors, where $i^*$ is\nthe unknown position of the best expert, $K$ is the number of actions, and $T$\nis the time horizon. We also provide an example of structured experts and\ndiscuss how to expedite learning in such case. Our meta-learning algorithm\nachieves optimal regret up to polylog factors when $i^* = \\tilde{\\mathcal{O}}\n\\big( \\sqrt{T/K} \\big)$. If a prior distribution is assumed to exist for $i^*$,\nthe probability of optimality increases with $T$, the rate of which can be\nfast.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 22:42:36 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 03:31:00 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Meng", "X. Flora", ""], ["Sarkar", "Tuhin", ""], ["Dahleh", "Munther A.", ""]]}, {"id": "2102.05198", "submitter": "Tesi Xiao", "authors": "Yanhao Jin, Tesi Xiao, Krishnakumar Balasubramanian", "title": "Statistical Inference for Polyak-Ruppert Averaged Zeroth-order\n  Stochastic Gradient Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning models are deployed in critical applications, it becomes\nimportant to not just provide point estimators of the model parameters (or\nsubsequent predictions), but also quantify the uncertainty associated with\nestimating the model parameters via confidence sets. In the last decade,\nestimating or training in several machine learning models has become synonymous\nwith running stochastic gradient algorithms. However, computing the stochastic\ngradients in several settings is highly expensive or even impossible at times.\nAn important question which has thus far not been addressed sufficiently in the\nstatistical machine learning literature is that of equipping zeroth-order\nstochastic gradient algorithms with practical yet rigorous inferential\ncapabilities. Towards this, in this work, we first establish a central limit\ntheorem for Polyak-Ruppert averaged stochastic gradient algorithm in the\nzeroth-order setting. We then provide online estimators of the asymptotic\ncovariance matrix appearing in the central limit theorem, thereby providing a\npractical procedure for constructing asymptotically valid confidence sets (or\nintervals) for parameter estimation (or prediction) in the zeroth-order\nsetting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 00:47:20 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 21:22:39 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Jin", "Yanhao", ""], ["Xiao", "Tesi", ""], ["Balasubramanian", "Krishnakumar", ""]]}, {"id": "2102.05208", "submitter": "Kuilin Chen", "authors": "Kuilin Chen, Chi-Guhn Lee", "title": "Attentive Gaussian processes for probabilistic time-series generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The transduction of sequence has been mostly done by recurrent networks,\nwhich are computationally demanding and often underestimate uncertainty\nseverely. We propose a computationally efficient attention-based network\ncombined with the Gaussian process regression to generate real-valued sequence,\nwhich we call the Attentive-GP. The proposed model not only improves the\ntraining efficiency by dispensing recurrence and convolutions but also learns\nthe factorized generative distribution with Bayesian representation. However,\nthe presence of the GP precludes the commonly used mini-batch approach to the\ntraining of the attention network. Therefore, we develop a block-wise training\nalgorithm to allow mini-batch training of the network while the GP is trained\nusing full-batch, resulting in a scalable training method. The algorithm has\nbeen proved to converge and shows comparable, if not better, quality of the\nfound solution. As the algorithm does not assume any specific network\narchitecture, it can be used with a wide range of hybrid models such as neural\nnetworks with kernel machine layers in the scarcity of resources for\ncomputation and memory.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 01:19:15 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Chen", "Kuilin", ""], ["Lee", "Chi-Guhn", ""]]}, {"id": "2102.05214", "submitter": "Andrew Wagenmaker", "authors": "Andrew Wagenmaker, Max Simchowitz, Kevin Jamieson", "title": "Task-Optimal Exploration in Linear Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in unknown environments is a fundamental problem in reinforcement\nlearning and control. In this work, we study task-guided exploration and\ndetermine what precisely an agent must learn about their environment in order\nto complete a particular task. Formally, we study a broad class of\ndecision-making problems in the setting of linear dynamical systems, a class\nthat includes the linear quadratic regulator problem. We provide instance- and\ntask-dependent lower bounds which explicitly quantify the difficulty of\ncompleting a task of interest. Motivated by our lower bound, we propose a\ncomputationally efficient experiment-design based exploration algorithm. We\nshow that it optimally explores the environment, collecting precisely the\ninformation needed to complete the task, and provide finite-time bounds\nguaranteeing that it achieves the instance- and task-optimal sample complexity,\nup to constant factors. Through several examples of the LQR problem, we show\nthat performing task-guided exploration provably improves on exploration\nschemes which do not take into account the task of interest. Along the way, we\nestablish that certainty equivalence decision making is instance- and\ntask-optimal, and obtain the first algorithm for the linear quadratic regulator\nproblem which is instance-optimal. We conclude with several experiments\nillustrating the effectiveness of our approach in practice.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 01:42:22 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 22:42:11 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wagenmaker", "Andrew", ""], ["Simchowitz", "Max", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2102.05242", "submitter": "Moritz Hardt", "authors": "Moritz Hardt and Benjamin Recht", "title": "Patterns, predictions, and actions: A story about machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This graduate textbook on machine learning tells a story of how patterns in\ndata support predictions and consequential actions. Starting with the\nfoundations of decision making, we cover representation, optimization, and\ngeneralization as the constituents of supervised learning. A chapter on\ndatasets as benchmarks examines their histories and scientific bases.\nSelf-contained introductions to causality, the practice of causal inference,\nsequential decision making, and reinforcement learning equip the reader with\nconcepts and tools to reason about actions and their consequences. Throughout,\nthe text discusses historical context and societal impact. We invite readers\nfrom all backgrounds; some experience with probability, calculus, and linear\nalgebra suffices.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 03:42:03 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Hardt", "Moritz", ""], ["Recht", "Benjamin", ""]]}, {"id": "2102.05262", "submitter": "Guillaume Charpiat", "authors": "Guillaume Charpiat, Nicolas Girard, Loris Felardos, Yuliya Tarabalka", "title": "Input Similarity from the Neural Network Perspective", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first exhibit a multimodal image registration task, for which a neural\nnetwork trained on a dataset with noisy labels reaches almost perfect accuracy,\nfar beyond noise variance. This surprising auto-denoising phenomenon can be\nexplained as a noise averaging effect over the labels of similar input\nexamples. This effect theoretically grows with the number of similar examples;\nthe question is then to define and estimate the similarity of examples.\n  We express a proper definition of similarity, from the neural network\nperspective, i.e. we quantify how undissociable two inputs $A$ and $B$ are,\ntaking a machine learning viewpoint: how much a parameter variation designed to\nchange the output for $A$ would impact the output for $B$ as well?\n  We study the mathematical properties of this similarity measure, and show how\nto use it on a trained network to estimate sample density, in low complexity,\nenabling new types of statistical analysis for neural networks. We analyze data\nby retrieving samples perceived as similar by the network, and are able to\nquantify the denoising effect without requiring true labels. We also propose,\nduring training, to enforce that examples known to be similar should also be\nseen as similar by the network, and notice speed-up training effects for\ncertain datasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 04:57:30 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Charpiat", "Guillaume", ""], ["Girard", "Nicolas", ""], ["Felardos", "Loris", ""], ["Tarabalka", "Yuliya", ""]]}, {"id": "2102.05263", "submitter": "Santiago Ontanon", "authors": "Robert C. Gray, Jichen Zhu, Santiago Onta\\~n\\'on", "title": "Regression Oracles and Exploration Strategies for Short-Horizon\n  Multi-Armed Bandits", "comments": "8 pages", "journal-ref": "In proceedings of the 2020 IEEE Conference on Games (CoG) (pp.\n  312-319)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores multi-armed bandit (MAB) strategies in very short horizon\nscenarios, i.e., when the bandit strategy is only allowed very few interactions\nwith the environment. This is an understudied setting in the MAB literature\nwith many applications in the context of games, such as player modeling.\nSpecifically, we pursue three different ideas. First, we explore the use of\nregression oracles, which replace the simple average used in strategies such as\nepsilon-greedy with linear regression models. Second, we examine different\nexploration patterns such as forced exploration phases. Finally, we introduce a\nnew variant of the UCB1 strategy called UCBT that has interesting properties\nand no tunable parameters. We present experimental results in a domain\nmotivated by exergames, where the goal is to maximize a player's daily steps.\nOur results show that the combination of epsilon-greedy or epsilon-decreasing\nwith regression oracles outperforms all other tested strategies in the short\nhorizon setting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 04:58:44 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Gray", "Robert C.", ""], ["Zhu", "Jichen", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2102.05269", "submitter": "Arian Ahmadi", "authors": "Arian Ahmadi and Omid Semiari", "title": "Reinforcement Learning for Optimized Beam Training in Multi-Hop\n  Terahertz Communications", "comments": "2021 IEEE International Conference on Communications (ICC): Mobile\n  and Wireless Networks Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI eess.SP math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Communication at terahertz (THz) frequency bands is a promising solution for\nachieving extremely high data rates in next-generation wireless networks. While\nthe THz communication is conventionally envisioned for short-range wireless\napplications due to the high atmospheric absorption at THz frequencies,\nmulti-hop directional transmissions can be enabled to extend the communication\nrange. However, to realize multi-hop THz communications, conventional beam\ntraining schemes, such as exhaustive search or hierarchical methods with a\nfixed number of training levels, can lead to a very large time overhead. To\naddress this challenge, in this paper, a novel hierarchical beam training\nscheme with dynamic training levels is proposed to optimize the performance of\nmulti-hop THz links. In fact, an optimization problem is formulated to maximize\nthe overall spectral efficiency of the multi-hop THz link by dynamically and\njointly selecting the number of beam training levels across all the constituent\nsingle-hop links. To solve this problem in presence of unknown channel state\ninformation, noise, and path loss, a new reinforcement learning solution based\non the multi-armed bandit (MAB) is developed. Simulation results show the fast\nconvergence of the proposed scheme in presence of random channels and noise.\nThe results also show that the proposed scheme can yield up to 75% performance\ngain, in terms of spectral efficiency, compared to the conventional\nhierarchical beam training with a fixed number of training levels.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 05:24:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Ahmadi", "Arian", ""], ["Semiari", "Omid", ""]]}, {"id": "2102.05274", "submitter": "Wenjia Zhang", "authors": "Yikai Zhang, Wenjia Zhang, Sammy Bald, Vamsi Pingali, Chao Chen,\n  Mayank Goswami", "title": "Stability of SGD: Tightness Analysis and Improved Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) based methods have been widely used for\ntraining large-scale machine learning models that also generalize well in\npractice. Several explanations have been offered for this generalization\nperformance, a prominent one being algorithmic stability [18]. However, there\nare no known examples of smooth loss functions for which the analysis can be\nshown to be tight. Furthermore, apart from the properties of the loss function,\ndata distribution has also been shown to be an important factor in\ngeneralization performance. This raises the question: is the stability analysis\nof [18] tight for smooth functions, and if not, for what kind of loss functions\nand data distributions can the stability analysis be improved? In this paper we\nfirst settle open questions regarding tightness of bounds in the\ndata-independent setting: we show that for general datasets, the existing\nanalysis for convex and strongly-convex loss functions is tight, but it can be\nimproved for non-convex loss functions. Next, we give a novel and improved\ndata-dependent bounds: we show stability upper bounds for a large class of\nconvex regularized loss functions, with negligible regularization parameters,\nand improve existing data-dependent bounds in the non-convex setting. We hope\nthat our results will initiate further efforts to better understand the\ndata-dependent setting under non-convex loss functions, leading to an improved\nunderstanding of the generalization abilities of deep networks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 05:43:27 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Zhang", "Yikai", ""], ["Zhang", "Wenjia", ""], ["Bald", "Sammy", ""], ["Pingali", "Vamsi", ""], ["Chen", "Chao", ""], ["Goswami", "Mayank", ""]]}, {"id": "2102.05291", "submitter": "Zhaowei Zhu", "authors": "Zhaowei Zhu, Yiwen Song, Yang Liu", "title": "Clusterability as an Alternative to Anchor Points When Learning with\n  Noisy Labels", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The label noise transition matrix, characterizing the probabilities of a\ntraining instance being wrongly annotated, is crucial to designing popular\nsolutions to learning with noisy labels. Existing works heavily rely on finding\n\"anchor points\" or their approximates, defined as instances belonging to a\nparticular class almost surely. Nonetheless, finding anchor points remains a\nnon-trivial task, and the estimation accuracy is also often throttled by the\nnumber of available anchor points. In this paper, we propose an alternative\noption to the above task. Our main contribution is the discovery of an\nefficient estimation procedure based on a clusterability condition. We prove\nthat with clusterable representations of features, using up to third-order\nconsensuses of noisy labels among neighbor representations is sufficient to\nestimate a unique transition matrix. Compared with methods using anchor points,\nour approach uses substantially more instances and benefits from a much better\nsample complexity. We demonstrate the estimation accuracy and advantages of our\nestimates using both synthetic noisy labels (on CIFAR-10/100) and real\nhuman-level noisy labels (on Clothing1M and our self-collected human-annotated\nCIFAR-10). Our code and human-level noisy CIFAR-10 labels are available at\nhttps://github.com/UCSC-REAL/HOC.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:22:56 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 21:33:49 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhu", "Zhaowei", ""], ["Song", "Yiwen", ""], ["Liu", "Yang", ""]]}, {"id": "2102.05298", "submitter": "Yunfei Chu", "authors": "Yunfei Chu, Xiaowei Wang, Jianxin Ma, Kunyang Jia, Jingren Zhou,\n  Hongxia Yang", "title": "Inductive Granger Causal Modeling for Multivariate Time Series", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causal modeling is an emerging topic that can uncover Granger causal\nrelationship behind multivariate time series data. In many real-world systems,\nit is common to encounter a large amount of multivariate time series data\ncollected from different individuals with sharing commonalities. However, there\nare ongoing concerns regarding Granger causality's applicability in such large\nscale complex scenarios, presenting both challenges and opportunities for\nGranger causal structure reconstruction. Existing methods usually train a\ndistinct model for each individual, suffering from inefficiency and\nover-fitting issues. To bridge this gap, we propose an Inductive GRanger cAusal\nmodeling (InGRA) framework for inductive Granger causality learning and common\ncausal structure detection on multivariate time series, which exploits the\nshared commonalities underlying the different individuals. In particular, we\ntrain one global model for individuals with different Granger causal structures\nthrough a novel attention mechanism, called prototypical Granger causal\nattention. The model can detect common causal structures for different\nindividuals and infer Granger causal structures for newly arrived individuals.\nExtensive experiments, as well as an online A/B test on an E-commercial\nadvertising platform, demonstrate the superior performances of InGRA.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:48:00 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Chu", "Yunfei", ""], ["Wang", "Xiaowei", ""], ["Ma", "Jianxin", ""], ["Jia", "Kunyang", ""], ["Zhou", "Jingren", ""], ["Yang", "Hongxia", ""]]}, {"id": "2102.05312", "submitter": "Chicheng Zhang", "authors": "Chicheng Zhang and Yinan Li", "title": "Improved Algorithms for Efficient Active Learning Halfspaces with\n  Massart and Tsybakov noise", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a computationally-efficient PAC active learning algorithm for\n$d$-dimensional homogeneous halfspaces that can tolerate Massart\nnoise~\\citep{massart2006risk} and Tsybakov noise~\\citep{tsybakov2004optimal}.\nSpecialized to the $\\eta$-Massart noise setting, our algorithm achieves an\ninformation-theoretic optimal label complexity of $\\tilde{O}\\left(\n\\frac{d}{(1-2\\eta)^2} \\mathrm{polylog}(\\frac1\\epsilon) \\right)$ under a wide\nrange of unlabeled data distributions (specifically, the family of \"structured\ndistributions\" defined in~\\citet{diakonikolas2020polynomial}). Under the more\nchallenging Tsybakov noise condition, we identify two subfamilies of noise\nconditions, under which our algorithm achieves computational efficiency and\nprovide label complexity guarantees strictly lower than passive learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 08:17:17 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Zhang", "Chicheng", ""], ["Li", "Yinan", ""]]}, {"id": "2102.05313", "submitter": "Joseph Mikael", "authors": "Carl Remlinger, Joseph Mikael, Romuald Elie", "title": "Conditional and Adversarial Euler-based Generators For Time Series", "comments": "14 page, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce three new generative models for time series. Based on Euler\ndiscretization and Wasserstein metrics, they are able to capture time marginal\ndistributions and temporal dynamics. Two of these methods rely on the\nadaptation of generative adversarial networks (GANs) to time series. Both of\nthem outperform state-of-the-art benchmarks by capturing the underlying\ntemporal structure on synthetic time series. The third algorithm, called\nConditional Euler Generator (CEGEN), minimizes a dedicated distance between the\ntransition probability distributions over all time steps. In the context of Ito\nprocesses, we provide theoretical guarantees that minimizing this criterion\nimplies accurate estimations of the drift and volatility parameters. We\ndemonstrate empirically that CEGEN outperforms state-of-the-art and GAN\ngenerators on both marginal and temporal dynamics metrics. Besides, it\nidentifies accurate correlation structures in high dimension. When few data\npoints are available, we verify the effectiveness of CEGEN, when combined with\ntransfer learning methods on Monte Carlo simulations. Finally, we illustrate\nthe robustness of our method on various real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 08:18:35 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:09:04 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 10:45:08 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 07:32:40 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Remlinger", "Carl", ""], ["Mikael", "Joseph", ""], ["Elie", "Romuald", ""]]}, {"id": "2102.05314", "submitter": "Yohann de Castro", "authors": "Yohann de Castro (ICJ, CERMICS), Luca Mencarelli (CERMICS)", "title": "Forecasting Nonnegative Time Series via Sliding Mask Method (SMM) and\n  Latent Clustered Forecast (LCF)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonnegative time series forecasting framework. Based on recent\nadvances in Nonnegative Matrix Factorization (NMF) and Archetypal Analysis, we\nintroduce two procedures referred to as Sliding Mask Method (SMM) and Latent\nClustered Forecast (LCF). SMM is a simple and powerful method based on time\nwindow prediction using Completion of Nonnegative Matrices. This new procedure\ncombines low nonnegative rank decomposition and matrix completion where the\nhidden values are to be forecasted. LCF is two stage: it leverages archetypal\nanalysis for dimension reduction and clustering of time series, then it uses\nany black-box supervised forecast solver on the clustered latent\nrepresentation. Theoretical guarantees on uniqueness and robustness of the\nsolution of NMF Completion-type problems are also provided for the first time.\nFinally, numerical experiments on real-world and synthetic data-set confirms\nforecasting accuracy for both the methodologies.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 08:29:55 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["de Castro", "Yohann", "", "ICJ, CERMICS"], ["Mencarelli", "Luca", "", "CERMICS"]]}, {"id": "2102.05320", "submitter": "Sen Na", "authors": "Sen Na, Mihai Anitescu, Mladen Kolar", "title": "An Adaptive Stochastic Sequential Quadratic Programming with\n  Differentiable Exact Augmented Lagrangians", "comments": "59 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of solving nonlinear optimization programs with\nstochastic objective and deterministic equality constraints. We assume for the\nobjective that the function evaluation, the gradient, and the Hessian are\ninaccessible, while one can compute their stochastic estimates by, for example,\nsubsampling. We propose a stochastic algorithm based on sequential quadratic\nprogramming (SQP) that uses a differentiable exact augmented Lagrangian as the\nmerit function. To motivate our algorithm, we revisit an old SQP method\n\\citep{Lucidi1990Recursive} developed for deterministic programs. We simplify\nthat method and derive an adaptive SQP, which serves as the skeleton of our\nstochastic algorithm. Based on the derived algorithm, we then propose a\nnon-adaptive SQP for optimizing stochastic objectives, where the gradient and\nthe Hessian are replaced by stochastic estimates but the stepsize is\ndeterministic and prespecified. Finally, we incorporate a recent stochastic\nline search procedure \\citep{Paquette2020Stochastic} into our non-adaptive\nstochastic SQP to arrive at an adaptive stochastic SQP. To our knowledge, the\nproposed algorithm is the first stochastic SQP that allows a line search\nprocedure and the first stochastic line search procedure that allows the\nconstraints. The global convergence for all proposed SQP methods is\nestablished, while numerical experiments on nonlinear problems in the CUTEst\ntest set demonstrate the superiority of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 08:40:55 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Na", "Sen", ""], ["Anitescu", "Mihai", ""], ["Kolar", "Mladen", ""]]}, {"id": "2102.05336", "submitter": "Yang Liu", "authors": "Yang Liu", "title": "Understanding Instance-Level Label Noise: Disparate Impacts and\n  Treatments", "comments": "Accepted to ICML 2021 as a long talk paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to provide understandings for the effect of an\nover-parameterized model, e.g. a deep neural network, memorizing\ninstance-dependent noisy labels. We first quantify the harms caused by\nmemorizing noisy instances, and show the disparate impacts of noisy labels for\nsample instances with different representation frequencies. We then analyze how\nseveral popular solutions for learning with noisy labels mitigate this harm at\nthe instance level. Our analysis reveals that existing approaches lead to\ndisparate treatments when handling noisy instances. While higher-frequency\ninstances often enjoy a high probability of an improvement by applying these\nsolutions, lower-frequency instances do not. Our analysis reveals new\nunderstandings for when these approaches work, and provides theoretical\njustifications for previously reported empirical observations. This observation\nrequires us to rethink the distribution of label noise across instances and\ncalls for different treatments for instances in different regimes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 09:19:11 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 08:53:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Liu", "Yang", ""]]}, {"id": "2102.05347", "submitter": "Thuy Duong Vuong", "authors": "Nima Anari and Thuy-Duong Vuong", "title": "From Sampling to Optimization on Discrete Domains withApplications to\n  Determinant Maximization", "comments": "Replacement, with significant new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a connection between sampling and optimization on discrete domains.\nFor a family of distributions $\\mu$ defined on size $k$ subsets of a ground set\nof elements that is closed under external fields, we show that rapid mixing of\nnatural local random walks implies the existence of simple approximation\nalgorithms to find $\\max \\mu(\\cdot)$. More precisely we show that if\n(multi-step) down-up random walks have spectral gap at least inverse\npolynomially large in $k$, then (multi-step) local search can find $\\max\n\\mu(\\cdot)$ within a factor of $k^{O(k)}$. As the main application of our\nresult, we show a simple nearly-optimal $k^{O(k)}$-factor approximation\nalgorithm for MAP inference on nonsymmetric DPPs. This is the first nontrivial\nmultiplicative approximation for finding the largest size $k$ principal minor\nof a square (not-necessarily-symmetric) matrix $L$ with $L+L^\\intercal\\succeq\n0$.\n  We establish the connection between sampling and optimization by showing that\nan exchange inequality, a concept rooted in discrete convex analysis, can be\nderived from fast mixing of local random walks. We further connect exchange\ninequalities with composable core-sets for optimization, generalizing recent\nresults on composable core-sets for DPP maximization to arbitrary distributions\nthat satisfy either the strongly Rayleigh property or that have a log-concave\ngenerating polynomial.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 09:34:44 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 21:07:33 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Anari", "Nima", ""], ["Vuong", "Thuy-Duong", ""]]}, {"id": "2102.05363", "submitter": "Liwei Wang", "authors": "Bohang Zhang, Tianle Cai, Zhou Lu, Di He, Liwei Wang", "title": "Towards Certifying L-infinity Robustness using Neural Networks with\n  L-inf-dist Neurons", "comments": "Appearing at International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that standard neural networks, even with a high\nclassification accuracy, are vulnerable to small $\\ell_\\infty$-norm bounded\nadversarial perturbations. Although many attempts have been made, most previous\nworks either can only provide empirical verification of the defense to a\nparticular attack method, or can only develop a certified guarantee of the\nmodel robustness in limited scenarios. In this paper, we seek for a new\napproach to develop a theoretically principled neural network that inherently\nresists $\\ell_\\infty$ perturbations. In particular, we design a novel neuron\nthat uses $\\ell_\\infty$-distance as its basic operation (which we call\n$\\ell_\\infty$-dist neuron), and show that any neural network constructed with\n$\\ell_\\infty$-dist neurons (called $\\ell_{\\infty}$-dist net) is naturally a\n1-Lipschitz function with respect to $\\ell_\\infty$-norm. This directly provides\na rigorous guarantee of the certified robustness based on the margin of\nprediction outputs. We then prove that such networks have enough expressive\npower to approximate any 1-Lipschitz function with robust generalization\nguarantee. We further provide a holistic training strategy that can greatly\nalleviate optimization difficulties. Experimental results show that using\n$\\ell_{\\infty}$-dist nets as basic building blocks, we consistently achieve\nstate-of-the-art performance on commonly used datasets: 93.09% certified\naccuracy on MNIST ($\\epsilon=0.3$), 35.42% on CIFAR-10 ($\\epsilon=8/255$) and\n16.31% on TinyImageNet ($\\epsilon=1/255$).\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 10:03:58 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 04:57:54 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 08:01:16 GMT"}, {"version": "v4", "created": "Mon, 14 Jun 2021 10:40:48 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Bohang", ""], ["Cai", "Tianle", ""], ["Lu", "Zhou", ""], ["He", "Di", ""], ["Wang", "Liwei", ""]]}, {"id": "2102.05375", "submitter": "Liu Ziyin", "authors": "Liu Ziyin, Kangqiao Liu, Takashi Mori, Masahito Ueda", "title": "Strength of Minibatch Noise in SGD", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The noise in stochastic gradient descent (SGD), caused by minibatch sampling,\nis poorly understood despite its practical importance in deep learning. In this\nwork, we study the nature of SGD noise and fluctuation. We show that some\ndegree of mismatch between model and data complexity is needed for SGD to\n``stir\" a noise; such mismatch may be due to a label or input noise,\nregularization, or underparametrization. Compared with previous works, the\npresent work focuses on deriving exactly solvable analytical results. Our work\nalso motivates a more accurate general formulation to describe minibatch noise,\nand we show that the SGD noise takes different shapes and strengths in\ndifferent kinds of minima.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 10:38:55 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 13:43:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ziyin", "Liu", ""], ["Liu", "Kangqiao", ""], ["Mori", "Takashi", ""], ["Ueda", "Masahito", ""]]}, {"id": "2102.05379", "submitter": "Emiel Hoogeboom", "authors": "Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forr\\'e, Max\n  Welling", "title": "Argmax Flows and Multinomial Diffusion: Learning Categorical\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative flows and diffusion models have been predominantly trained on\nordinal data, for example natural images. This paper introduces two extensions\nof flows and diffusion for categorical data such as language or image\nsegmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined\nby a composition of a continuous distribution (such as a normalizing flow), and\nan argmax function. To optimize this model, we learn a probabilistic inverse\nfor the argmax that lifts the categorical data to a continuous space.\nMultinomial Diffusion gradually adds categorical noise in a diffusion process,\nfor which the generative denoising process is learned. We demonstrate that our\nmethod outperforms existing dequantization approaches on text modelling and\nmodelling on image segmentation maps in log-likelihood.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 11:04:17 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 14:18:43 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Hoogeboom", "Emiel", ""], ["Nielsen", "Didrik", ""], ["Jaini", "Priyank", ""], ["Forr\u00e9", "Patrick", ""], ["Welling", "Max", ""]]}, {"id": "2102.05406", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Haipeng Luo", "title": "Non-stationary Reinforcement Learning without Prior Knowledge: An\n  Optimal Black-box Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a black-box reduction that turns a certain reinforcement learning\nalgorithm with optimal regret in a (near-)stationary environment into another\nalgorithm with optimal dynamic regret in a non-stationary environment,\nimportantly without any prior knowledge on the degree of non-stationarity. By\nplugging different algorithms into our black-box, we provide a list of examples\nshowing that our approach not only recovers recent results for (contextual)\nmulti-armed bandits achieved by very specialized algorithms, but also\nsignificantly improves the state of the art for (generalized) linear bandits,\nepisodic MDPs, and infinite-horizon MDPs in various ways. Specifically, in most\ncases our algorithm achieves the optimal dynamic regret\n$\\widetilde{\\mathcal{O}}(\\min\\{\\sqrt{LT}, \\Delta^{1/3}T^{2/3}\\})$ where $T$ is\nthe number of rounds and $L$ and $\\Delta$ are the number and amount of changes\nof the world respectively, while previous works only obtain suboptimal bounds\nand/or require the knowledge of $L$ and $\\Delta$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 12:43:31 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:57:04 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Luo", "Haipeng", ""]]}, {"id": "2102.05472", "submitter": "Marina Garrote-L\\'opez", "authors": "Marta Casanellas, Marina Garrote-L\\'opez and Piotr Zwiernik", "title": "Robust estimation of tree structured models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of learning undirected graphical models on trees from\ncorrupted data. Recently Katiyar et al. showed that it is possible to recover\ntrees from noisy binary data up to a small equivalence class of possible trees.\nTheir other paper on the Gaussian case follows a similar pattern. By framing\nthis as a special phylogenetic recovery problem we largely generalize these two\nsettings. Using the framework of linear latent tree models we discuss tree\nidentifiability for binary data under a continuous corruption model. For the\nIsing and the Gaussian tree model we also provide a characterisation of when\nthe Chow-Liu algorithm consistently learns the underlying tree from the noisy\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:58:40 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Casanellas", "Marta", ""], ["Garrote-L\u00f3pez", "Marina", ""], ["Zwiernik", "Piotr", ""]]}, {"id": "2102.05502", "submitter": "Richard Combes", "authors": "Raymond Zhang and Richard Combes", "title": "On the Suboptimality of Thompson Sampling in High Dimensions", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider Thompson Sampling for combinatorial semi-bandits.\nWe demonstrate that, perhaps surprisingly, Thompson Sampling is sub-optimal for\nthis problem in the sense that its regret scales exponentially in the ambient\ndimension, and its minimax regret scales almost linearly. This phenomenon\noccurs under a wide variety of assumptions including both non-linear and linear\nreward functions. We also show that including a fixed amount of forced\nexploration to Thompson Sampling does not alleviate the problem. We complement\nour theoretical results with numerical results and show that in practice\nThompson Sampling indeed can perform very poorly in high dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:44:43 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Zhang", "Raymond", ""], ["Combes", "Richard", ""]]}, {"id": "2102.05507", "submitter": "Simon Bing", "authors": "Simon Bing, Vincent Fortuin, Gunnar R\\\"atsch", "title": "On Disentanglement in Gaussian Process Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex multivariate time series arise in many fields, ranging from computer\nvision to robotics or medicine. Often we are interested in the independent\nunderlying factors that give rise to the high-dimensional data we are\nobserving. While many models have been introduced to learn such disentangled\nrepresentations, only few attempt to explicitly exploit the structure of\nsequential data. We investigate the disentanglement properties of Gaussian\nprocess variational autoencoders, a class of models recently introduced that\nhave been successful in different tasks on time series data. Our model exploits\nthe temporal structure of the data by modeling each latent channel with a GP\nprior and employing a structured variational distribution that can capture\ndependencies in time. We demonstrate the competitiveness of our approach\nagainst state-of-the-art unsupervised and weakly-supervised disentanglement\nmethods on a benchmark task. Moreover, we provide evidence that we can learn\nmeaningful disentangled representations on real-world medical time series data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:49:27 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bing", "Simon", ""], ["Fortuin", "Vincent", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "2102.05542", "submitter": "Antoine Houdard", "authors": "Antoine Houdard and Arthur Leclaire and Nicolas Papadakis and Julien\n  Rabin", "title": "On the Existence of Optimal Transport Gradient for Learning Generative\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of optimal transport cost for learning generative models has become\npopular with Wasserstein Generative Adversarial Networks (WGAN). Training of\nWGAN relies on a theoretical background: the calculation of the gradient of the\noptimal transport cost with respect to the generative model parameters. We\nfirst demonstrate that such gradient may not be defined, which can result in\nnumerical instabilities during gradient-based optimization. We address this\nissue by stating a valid differentiation theorem in the case of entropic\nregularized transport and specify conditions under which existence is ensured.\nBy exploiting the discrete nature of empirical data, we formulate the gradient\nin a semi-discrete setting and propose an algorithm for the optimization of the\ngenerative model parameters. Finally, we illustrate numerically the advantage\nof the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:28:20 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Houdard", "Antoine", ""], ["Leclaire", "Arthur", ""], ["Papadakis", "Nicolas", ""], ["Rabin", "Julien", ""]]}, {"id": "2102.05567", "submitter": "Werner Creixell", "authors": "Diego Lazcano, Nicol\\'as Fredes and Werner Creixell", "title": "Hyperbolic Generative Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, Hyperbolic Spaces in the context of Non-Euclidean Deep Learning\nhave gained popularity because of their ability to represent hierarchical data.\nWe propose that it is possible to take advantage of the hierarchical\ncharacteristic present in the images by using hyperbolic neural networks in a\nGAN architecture. In this study, different configurations using fully connected\nhyperbolic layers in the GAN, CGAN, and WGAN are tested, in what we call the\nHGAN, HCGAN, and HWGAN, respectively. The results are measured using the\nInception Score (IS) and the Fr\\'echet Inception Distance (FID) on the MNIST\ndataset. Depending on the configuration and space curvature, better results are\nachieved for each proposed hyperbolic versions than their euclidean\ncounterpart.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:55:27 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Lazcano", "Diego", ""], ["Fredes", "Nicol\u00e1s", ""], ["Creixell", "Werner", ""]]}, {"id": "2102.05573", "submitter": "Jonas M. K\\\"ubler", "authors": "Jonas M. K\\\"ubler, Wittawat Jitkrittum, Bernhard Sch\\\"olkopf, Krikamol\n  Muandet", "title": "A Witness Two-Sample Test", "comments": "Under Review - Code available upon personal request", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Maximum Mean Discrepancy (MMD) has been the state-of-the-art\nnonparametric test for tackling the two-sample problem. Its statistic is given\nby the difference in expectations of the witness function, a real-valued\nfunction defined as a weighted sum of kernel evaluations on a set of basis\npoints. Typically the kernel is optimized on a training set, and hypothesis\ntesting is performed on a separate test set to avoid overfitting (i.e., control\ntype-I error). That is, the test set is used to simultaneously estimate the\nexpectations and define the basis points, while the training set only serves to\nselect the kernel and is discarded. In this work, we argue that this data\nsplitting scheme is overly conservative, and propose to use the training data\nto also define the weights and the basis points for better data efficiency. We\nshow that 1) the new test is consistent and has a well-controlled type-I error;\n2) the optimal witness function is given by a precision-weighted mean in the\nreproducing kernel Hilbert space associated with the kernel, and is closely\nrelated to kernel Fisher discriminant analysis; and 3) the test power of the\nproposed test is comparable or exceeds that of the MMD and other modern tests,\nas verified empirically on challenging synthetic and real problems (e.g., Higgs\ndata).\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:13:21 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 13:28:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["K\u00fcbler", "Jonas M.", ""], ["Jitkrittum", "Wittawat", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Muandet", "Krikamol", ""]]}, {"id": "2102.05602", "submitter": "Hritik Bansal", "authors": "Hritik Bansal, Gantavya Bhatt, Pankaj Malhotra, Prathosh A.P", "title": "Systematic Generalization in Neural Networks-based Multivariate Time\n  Series Forecasting Models", "comments": "9 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic generalization aims to evaluate reasoning about novel combinations\nfrom known components, an intrinsic property of human cognition. In this work,\nwe study systematic generalization of NNs in forecasting future time series of\ndependent variables in a dynamical system, conditioned on past time series of\ndependent variables, and past and future control variables. We focus on\nsystematic generalization wherein the NN-based forecasting model should perform\nwell on previously unseen combinations or regimes of control variables after\nbeing trained on a limited set of the possible regimes. For NNs to depict such\nout-of-distribution generalization, they should be able to disentangle the\nvarious dependencies between control variables and dependent variables. We\nhypothesize that a modular NN architecture guided by the readily-available\nknowledge of independence of control variables as a potentially useful\ninductive bias to this end. Through extensive empirical evaluation on a toy\ndataset and a simulated electric motor dataset, we show that our proposed\nmodular NN architecture serves as a simple yet highly effective inductive bias\nthat enabling better forecasting of the dependent variables up to large\nhorizons in contrast to standard NNs, and indeed capture the true dependency\nrelations between the dependent and the control variables.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:00:45 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 16:11:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Bansal", "Hritik", ""], ["Bhatt", "Gantavya", ""], ["Malhotra", "Pankaj", ""], ["P", "Prathosh A.", ""]]}, {"id": "2102.05624", "submitter": "Kai Chen", "authors": "Kai Chen, Guang Chen, Dan Xu, Lijun Zhang, Yuyao Huang, Alois Knoll", "title": "NAST: Non-Autoregressive Spatial-Temporal Transformer for Time Series\n  Forecasting", "comments": "Not a satisfying work and need to be reformed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although Transformer has made breakthrough success in widespread domains\nespecially in Natural Language Processing (NLP), applying it to time series\nforecasting is still a great challenge. In time series forecasting, the\nautoregressive decoding of canonical Transformer models could introduce huge\naccumulative errors inevitably. Besides, utilizing Transformer to deal with\nspatial-temporal dependencies in the problem still faces tough difficulties.~To\ntackle these limitations, this work is the first attempt to propose a\nNon-Autoregressive Transformer architecture for time series forecasting, aiming\nat overcoming the time delay and accumulative error issues in the canonical\nTransformer. Moreover, we present a novel spatial-temporal attention mechanism,\nbuilding a bridge by a learned temporal influence map to fill the gaps between\nthe spatial and temporal attention, so that spatial and temporal dependencies\ncan be processed integrally. Empirically, we evaluate our model on diversified\nego-centric future localization datasets and demonstrate state-of-the-art\nperformance on both real-time and accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:36:11 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 07:47:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Kai", ""], ["Chen", "Guang", ""], ["Xu", "Dan", ""], ["Zhang", "Lijun", ""], ["Huang", "Yuyao", ""], ["Knoll", "Alois", ""]]}, {"id": "2102.05628", "submitter": "James Vuckovic", "authors": "James Vuckovic, Aristide Baratin, Remi Tachet des Combes", "title": "On the Regularity of Attention", "comments": "Conference version of arXiv:2007.02876", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is a powerful component of modern neural networks across a wide\nvariety of domains. In this paper, we seek to quantify the regularity (i.e. the\namount of smoothness) of the attention operation. To accomplish this goal, we\npropose a new mathematical framework that uses measure theory and integral\noperators to model attention. We show that this framework is consistent with\nthe usual definition, and that it captures the essential properties of\nattention. Then we use this framework to prove that, on compact domains, the\nattention operation is Lipschitz continuous and provide an estimate of its\nLipschitz constant. Additionally, by focusing on a specific type of attention,\nwe extend these Lipschitz continuity results to non-compact domains. We also\ndiscuss the effects regularity can have on NLP models, and applications to\ninvertible and infinitely-deep networks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:40:11 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Vuckovic", "James", ""], ["Baratin", "Aristide", ""], ["Combes", "Remi Tachet des", ""]]}, {"id": "2102.05629", "submitter": "Nikos Zarifis", "authors": "Ilias Diakonikolas, Daniel M. Kane, Vasilis Kontonis, Christos Tzamos,\n  Nikos Zarifis", "title": "Agnostic Proper Learning of Halfspaces under Gaussian Marginals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of agnostically learning halfspaces under the Gaussian\ndistribution. Our main result is the {\\em first proper} learning algorithm for\nthis problem whose sample complexity and computational complexity qualitatively\nmatch those of the best known improper agnostic learner. Building on this\nresult, we also obtain the first proper polynomial-time approximation scheme\n(PTAS) for agnostically learning homogeneous halfspaces. Our techniques\nnaturally extend to agnostically learning linear models with respect to other\nnon-linear activations, yielding in particular the first proper agnostic\nalgorithm for ReLU regression.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:40:44 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Kontonis", "Vasilis", ""], ["Tzamos", "Christos", ""], ["Zarifis", "Nikos", ""]]}, {"id": "2102.05639", "submitter": "Basak Guler", "authors": "Basak Guler, Aylin Yener", "title": "Energy-Harvesting Distributed Machine Learning", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a first study of utilizing energy harvesting for\nsustainable machine learning in distributed networks. We consider a distributed\nlearning setup in which a machine learning model is trained over a large number\nof devices that can harvest energy from the ambient environment, and develop a\npractical learning framework with theoretical convergence guarantees. We\ndemonstrate through numerical experiments that the proposed framework can\nsignificantly outperform energy-agnostic benchmarks. Our framework is scalable,\nrequires only local estimation of the energy statistics, and can be applied to\na wide range of distributed training settings, including machine learning in\nwireless networks, edge computing, and mobile internet of things.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:53:51 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Guler", "Basak", ""], ["Yener", "Aylin", ""]]}, {"id": "2102.05640", "submitter": "Yutong Wang", "authors": "Yutong Wang, Clayton D. Scott", "title": "An Exact Solver for the Weston-Watkins SVM Subproblem", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent empirical evidence suggests that the Weston-Watkins support vector\nmachine is among the best performing multiclass extensions of the binary SVM.\nCurrent state-of-the-art solvers repeatedly solve a particular subproblem\napproximately using an iterative strategy. In this work, we propose an\nalgorithm that solves the subproblem exactly using a novel reparametrization of\nthe Weston-Watkins dual problem. For linear WW-SVMs, our solver shows\nsignificant speed-up over the state-of-the-art solver when the number of\nclasses is large. Our exact subproblem solver also allows us to prove linear\nconvergence of the overall solver.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:54:33 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:44:41 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wang", "Yutong", ""], ["Scott", "Clayton D.", ""]]}, {"id": "2102.05724", "submitter": "Haoyun Wang", "authors": "Haoyun Wang, Liyan Xie, Yao Xie, Alex Cuozzo, Simon Mak", "title": "Sequential change-point detection for mutually exciting point processes\n  over networks", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new CUSUM procedure for sequentially detecting change-point in\nthe self and mutual exciting processes, a.k.a. Hawkes networks using discrete\nevents data. Hawkes networks have become a popular model for statistics and\nmachine learning due to their capability in modeling irregularly observed data\nwhere the timing between events carries a lot of information. The problem of\ndetecting abrupt changes in Hawkes networks arises from various applications,\nincluding neuronal imaging, sensor network, and social network monitoring.\nDespite this, there has not been a computationally and memory-efficient online\nalgorithm for detecting such changes from sequential data. We present an\nefficient online recursive implementation of the CUSUM statistic for Hawkes\nprocesses, both decentralized and memory-efficient, and establish the\ntheoretical properties of this new CUSUM procedure. We then show that the\nproposed CUSUM method achieves better performance than existing methods,\nincluding the Shewhart procedure based on count data, the generalized\nlikelihood ratio (GLR) in the existing literature, and the standard score\nstatistic. We demonstrate this via a simulated example and an application to\npopulation code change-detection in neuronal networks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 20:20:06 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Wang", "Haoyun", ""], ["Xie", "Liyan", ""], ["Xie", "Yao", ""], ["Cuozzo", "Alex", ""], ["Mak", "Simon", ""]]}, {"id": "2102.05743", "submitter": "Sakira Hassan", "authors": "Sakira Hassan, Simo S\\\"arkk\\\"a and \\'Angel F. Garc\\'ia-Fern\\'andez", "title": "Temporal Parallelization of Inference in Hidden Markov Models", "comments": "submitted to the IEEE transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents algorithms for parallelization of inference in hidden\nMarkov models (HMMs). In particular, we propose parallel backward-forward type\nof filtering and smoothing algorithm as well as parallel Viterbi-type\nmaximum-a-posteriori (MAP) algorithm. We define associative elements and\noperators to pose these inference problems as parallel-prefix-sum computations\nin sum-product and max-product algorithms and parallelize them using\nparallel-scan algorithms. The advantage of the proposed algorithms is that they\nare computationally efficient in HMM inference problems with long time\nhorizons. We empirically compare the performance of the proposed methods to\nclassical methods on a highly parallel graphical processing unit (GPU).\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 21:26:09 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hassan", "Sakira", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Garc\u00eda-Fern\u00e1ndez", "\u00c1ngel F.", ""]]}, {"id": "2102.05749", "submitter": "Ond\\v{r}ej C\\'ifka", "authors": "Ond\\v{r}ej C\\'ifka, Alexey Ozerov, Umut \\c{S}im\\c{s}ekli, Ga\\\"el\n  Richard", "title": "Self-Supervised VQ-VAE for One-Shot Music Style Transfer", "comments": "ICASSP 2021. Website: https://adasp.telecom-paris.fr/s/ss-vq-vae", "journal-ref": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (2021) 96-100", "doi": "10.1109/ICASSP39728.2021.9414235", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural style transfer, allowing to apply the artistic style of one image to\nanother, has become one of the most widely showcased computer vision\napplications shortly after its introduction. In contrast, related tasks in the\nmusic audio domain remained, until recently, largely untackled. While several\nstyle conversion methods tailored to musical signals have been proposed, most\nlack the 'one-shot' capability of classical image style transfer algorithms. On\nthe other hand, the results of existing one-shot audio style transfer methods\non musical inputs are not as compelling. In this work, we are specifically\ninterested in the problem of one-shot timbre transfer. We present a novel\nmethod for this task, based on an extension of the vector-quantized variational\nautoencoder (VQ-VAE), along with a simple self-supervised learning strategy\ndesigned to obtain disentangled representations of timbre and pitch. We\nevaluate the method using a set of objective metrics and show that it is able\nto outperform selected baselines.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 21:42:49 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 15:15:22 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["C\u00edfka", "Ond\u0159ej", ""], ["Ozerov", "Alexey", ""], ["\u015eim\u015fekli", "Umut", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "2102.05793", "submitter": "Jonathan Scarlett", "authors": "Xu Cai, Selwyn Gomes, Jonathan Scarlett", "title": "Lenient Regret and Good-Action Identification in Gaussian Process\n  Bandits", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of Gaussian process (GP) bandits under\nrelaxed optimization criteria stating that any function value above a certain\nthreshold is \"good enough\". On the theoretical side, we study various {\\em\nlenient regret} notions in which all near-optimal actions incur zero penalty,\nand provide upper bounds on the lenient regret for GP-UCB and an elimination\nalgorithm, circumventing the usual $O(\\sqrt{T})$ term (with time horizon $T$)\nresulting from zooming extremely close towards the function maximum. In\naddition, we complement these upper bounds with algorithm-independent lower\nbounds. On the practical side, we consider the problem of finding a single\n\"good action\" according to a known pre-specified threshold, and introduce\nseveral good-action identification algorithms that exploit knowledge of the\nthreshold. We experimentally find that such algorithms can often find a good\naction faster than standard optimization-based approaches.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 01:16:58 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 06:46:03 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Cai", "Xu", ""], ["Gomes", "Selwyn", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2102.05829", "submitter": "Raha Moraffah", "authors": "Raha Moraffah, Paras Sheth, Mansooreh Karami, Anchit Bhattacharya,\n  Qianru Wang, Anique Tahir, Adrienne Raglin, Huan Liu", "title": "Causal Inference for Time series Analysis: Problems, Methods and\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data is a collection of chronological observations which is\ngenerated by several domains such as medical and financial fields. Over the\nyears, different tasks such as classification, forecasting, and clustering have\nbeen proposed to analyze this type of data. Time series data has been also used\nto study the effect of interventions over time. Moreover, in many fields of\nscience, learning the causal structure of dynamic systems and time series data\nis considered an interesting task which plays an important role in scientific\ndiscoveries. Estimating the effect of an intervention and identifying the\ncausal relations from the data can be performed via causal inference. Existing\nsurveys on time series discuss traditional tasks such as classification and\nforecasting or explain the details of the approaches proposed to solve a\nspecific task. In this paper, we focus on two causal inference tasks, i.e.,\ntreatment effect estimation and causal discovery for time series data, and\nprovide a comprehensive review of the approaches in each task. Furthermore, we\ncurate a list of commonly used evaluation metrics and datasets for each task\nand provide in-depth insight. These metrics and datasets can serve as\nbenchmarks for research in the field.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 03:26:11 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Moraffah", "Raha", ""], ["Sheth", "Paras", ""], ["Karami", "Mansooreh", ""], ["Bhattacharya", "Anchit", ""], ["Wang", "Qianru", ""], ["Tahir", "Anique", ""], ["Raglin", "Adrienne", ""], ["Liu", "Huan", ""]]}, {"id": "2102.05855", "submitter": "Jiayuan Ye", "authors": "Rishav Chourasia, Jiayuan Ye, Reza Shokri", "title": "Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the information leakage of an iterative learning algorithm about its\ntraining data, when the internal state of the algorithm is \\emph{not}\nobservable? How much is the contribution of each specific training epoch to the\nfinal leakage? We study this problem for noisy gradient descent algorithms, and\nmodel the \\emph{dynamics} of R\\'enyi differential privacy loss throughout the\ntraining process. Our analysis traces a provably tight bound on the R\\'enyi\ndivergence between the pair of probability distributions over parameters of\nmodels with neighboring datasets. We prove that the privacy loss converges\nexponentially fast, for smooth and strongly convex loss functions, which is a\nsignificant improvement over composition theorems. For Lipschitz, smooth, and\nstrongly convex loss functions, we prove optimal utility for differential\nprivacy algorithms with a small gradient complexity.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 05:49:37 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 04:18:03 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 16:38:48 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chourasia", "Rishav", ""], ["Ye", "Jiayuan", ""], ["Shokri", "Reza", ""]]}, {"id": "2102.05884", "submitter": "Glenn Dawson", "authors": "Glenn Dawson and Robi Polikar", "title": "OpinionRank: Extracting Ground Truth Labels from Unreliable Expert\n  Opinions with Graph-Based Spectral Ranking", "comments": "8 pages, 5 figures, accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As larger and more comprehensive datasets become standard in contemporary\nmachine learning, it becomes increasingly more difficult to obtain reliable,\ntrustworthy label information with which to train sophisticated models. To\naddress this problem, crowdsourcing has emerged as a popular, inexpensive, and\nefficient data mining solution for performing distributed label collection.\nHowever, crowdsourced annotations are inherently untrustworthy, as the labels\nare provided by anonymous volunteers who may have varying, unreliable\nexpertise. Worse yet, some participants on commonly used platforms such as\nAmazon Mechanical Turk may be adversarial, and provide intentionally incorrect\nlabel information without the end user's knowledge. We discuss three\nconventional models of the label generation process, describing their\nparameterizations and the model-based approaches used to solve them. We then\npropose OpinionRank, a model-free, interpretable, graph-based spectral\nalgorithm for integrating crowdsourced annotations into reliable labels for\nperforming supervised or semi-supervised learning. Our experiments show that\nOpinionRank performs favorably when compared against more highly parameterized\nalgorithms. We also show that OpinionRank is scalable to very large datasets\nand numbers of label sources, and requires considerably fewer computational\nresources than previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 08:12:44 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 03:59:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dawson", "Glenn", ""], ["Polikar", "Robi", ""]]}, {"id": "2102.05912", "submitter": "Khai Nguyen", "authors": "Khai Nguyen, Quoc Nguyen, Nhat Ho, Tung Pham, Hung Bui, Dinh Phung,\n  Trung Le", "title": "BoMb-OT: On Batch of Mini-batches Optimal Transport", "comments": "36 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mini-batch optimal transport (m-OT) has been successfully used in practical\napplications that involve probability measures with intractable density, or\nprobability measures with a very high number of supports. The m-OT solves\nseveral sparser optimal transport problems and then returns the average of\ntheir costs and transportation plans. Despite its scalability advantage, the\nm-OT does not consider the relationship between mini-batches which leads to\nundesirable estimation. Moreover, the m-OT does not approximate a proper metric\nbetween probability measures since the identity property is not satisfied. To\naddress these problems, we propose a novel mini-batching scheme for optimal\ntransport, named Batch of Mini-batches Optimal Transport (BoMb-OT), that finds\nthe optimal coupling between mini-batches and it can be seen as an\napproximation to a well-defined distance on the space of probability measures.\nFurthermore, we show that the m-OT is a limit of the entropic regularized\nversion of the BoMb-OT when the regularized parameter goes to infinity.\nFinally, we carry out extensive experiments to show that the BoMb-OT can\nestimate a better transportation plan between two original measures than the\nm-OT. It leads to a favorable performance of the BoMb-OT in the matching and\ncolor transfer tasks. Furthermore, we observe that the BoMb-OT also provides a\nbetter objective loss than the m-OT for doing approximate Bayesian computation,\nestimating parameters of interest in parametric generative models, and learning\nnon-parametric generative models with gradient flow.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 09:56:25 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 04:36:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Nguyen", "Khai", ""], ["Nguyen", "Quoc", ""], ["Ho", "Nhat", ""], ["Pham", "Tung", ""], ["Bui", "Hung", ""], ["Phung", "Dinh", ""], ["Le", "Trung", ""]]}, {"id": "2102.05960", "submitter": "Muhammad Aamir", "authors": "Muhammad Naeem, Jian Yu, Muhammad Aamir, Sajjad Ahmad Khan, Olayinka\n  Adeleye, Zardad Khan", "title": "Comparative Analysis of Machine Learning Approaches to Analyze and\n  Predict the Covid-19 Outbreak", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background. Forecasting the time of forthcoming pandemic reduces the impact\nof diseases by taking precautionary steps such as public health messaging and\nraising the consciousness of doctors. With the continuous and rapid increase in\nthe cumulative incidence of COVID-19, statistical and outbreak prediction\nmodels including various machine learning (ML) models are being used by the\nresearch community to track and predict the trend of the epidemic, and also in\ndeveloping appropriate strategies to combat and manage its spread. Methods. In\nthis paper, we present a comparative analysis of various ML approaches\nincluding Support Vector Machine, Random Forest, K-Nearest Neighbor and\nArtificial Neural Network in predicting the COVID-19 outbreak in the\nepidemiological domain. We first apply the autoregressive distributed lag\n(ARDL) method to identify and model the short and long-run relationships of the\ntime-series COVID-19 datasets. That is, we determine the lags between a\nresponse variable and its respective explanatory time series variables as\nindependent variables. Then, the resulting significant variables concerning\ntheir lags are used in the regression model selected by the ARDL for predicting\nand forecasting the trend of the epidemic. Results. Statistical measures i.e.,\nRoot Mean Square Error (RMSE), Mean Absolute Error (MAE) and Mean Absolute\nPercentage Error (MAPE) are used for model accuracy. The values of MAPE for the\nbest selected models for confirmed, recovered and deaths cases are 0.407, 0.094\nand 0.124 respectively, which falls under the category of highly accurate\nforecasts. In addition, we computed fifteen days ahead forecast for the daily\ndeaths, recover, and confirm patients and the cases fluctuated across time in\nall aspects. Besides, the results reveal the advantages of ML algorithms for\nsupporting decision making of evolving short term policies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:57:33 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Naeem", "Muhammad", ""], ["Yu", "Jian", ""], ["Aamir", "Muhammad", ""], ["Khan", "Sajjad Ahmad", ""], ["Adeleye", "Olayinka", ""], ["Khan", "Zardad", ""]]}, {"id": "2102.05996", "submitter": "Nikola Konstantinov", "authors": "Nikola Konstantinov, Christoph H. Lampert", "title": "Fairness Through Regularization for Learning to Rank", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the abundance of applications of ranking in recent years, addressing\nfairness concerns around automated ranking systems becomes necessary for\nincreasing the trust among end-users. Previous work on fair ranking has mostly\nfocused on application-specific fairness notions, often tailored to online\nadvertising, and it rarely considers learning as part of the process. In this\nwork, we show how to transfer numerous fairness notions from binary\nclassification to a learning to rank setting. Our formalism allows us to design\nmethods for incorporating fairness objectives with provable generalization\nguarantees. An extensive experimental evaluation shows that our method can\nimprove ranking fairness substantially with no or only little loss of model\nquality.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 13:29:08 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 20:22:03 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Konstantinov", "Nikola", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2102.06004", "submitter": "Nikola Konstantinov", "authors": "Nikola Konstantinov, Christoph H. Lampert", "title": "Fairness-Aware Learning from Corrupted Data", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Addressing fairness concerns about machine learning models is a crucial step\ntowards their long-term adoption in real-world automated systems. While many\napproaches have been developed for training fair models from data, little is\nknown about the effects of data corruption on these methods. In this work we\nconsider fairness-aware learning under arbitrary data manipulations. We show\nthat an adversary can force any learner to return a biased classifier, with or\nwithout degrading accuracy, and that the strength of this bias increases for\nlearning problems with underrepresented protected groups in the data. We also\nprovide upper bounds that match these hardness results up to constant factors,\nby proving that two natural learning algorithms achieve order-optimal\nguarantees in terms of both accuracy and fairness under adversarial data\nmanipulations.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 13:48:41 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Konstantinov", "Nikola", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2102.06129", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Mikhail Konobeev, Manzil Zaheer, Chih-wei Hsu,\n  Martin Mladenov, Craig Boutilier, and Csaba Szepesvari", "title": "Meta-Thompson Sampling", "comments": "Proceedings of the 38th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration in bandits is a fundamental online learning problem. We\npropose a variant of Thompson sampling that learns to explore better as it\ninteracts with bandit instances drawn from an unknown prior. The algorithm\nmeta-learns the prior and thus we call it MetaTS. We propose several efficient\nimplementations of MetaTS and analyze it in Gaussian bandits. Our analysis\nshows the benefit of meta-learning and is of a broader interest, because we\nderive a novel prior-dependent Bayes regret bound for Thompson sampling. Our\ntheory is complemented by empirical evaluation, which shows that MetaTS quickly\nadapts to the unknown prior.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 17:07:25 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 06:38:33 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Kveton", "Branislav", ""], ["Konobeev", "Mikhail", ""], ["Zaheer", "Manzil", ""], ["Hsu", "Chih-wei", ""], ["Mladenov", "Martin", ""], ["Boutilier", "Craig", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "2102.06137", "submitter": "Antonio Vergari", "authors": "Antonio Vergari, YooJung Choi, Anji Liu, Stefano Teso, Guy Van den\n  Broeck", "title": "A Compositional Atlas of Tractable Circuit Operations: From Simple\n  Transformations to Complex Information-Theoretic Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Circuit representations are becoming the lingua franca to express and reason\nabout tractable generative and discriminative models. In this paper, we show\nhow complex inference scenarios for these models that commonly arise in machine\nlearning -- from computing the expectations of decision tree ensembles to\ninformation-theoretic divergences of deep mixture models -- can be represented\nin terms of tractable modular operations over circuits. Specifically, we\ncharacterize the tractability of a vocabulary of simple transformations --\nsums, products, quotients, powers, logarithms, and exponentials -- in terms of\nsufficient structural constraints of the circuits they operate on, and present\nnovel hardness results for the cases in which these properties are not\nsatisfied. Building on these operations, we derive a unified framework for\nreasoning about tractable models that generalizes several results in the\nliterature and opens up novel tractable inference scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 17:26:32 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Vergari", "Antonio", ""], ["Choi", "YooJung", ""], ["Liu", "Anji", ""], ["Teso", "Stefano", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2102.06143", "submitter": "Harris Partaourides", "authors": "Harris Partaourides, Andreas Voskou, Dimitrios Kosmopoulos, Sotirios\n  Chatzis, and Dimitris N. Metaxas", "title": "Variational Bayesian Sequence-to-Sequence Networks for Memory-Efficient\n  Sign Language Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Memory-efficient continuous Sign Language Translation is a significant\nchallenge for the development of assisted technologies with real-time\napplicability for the deaf. In this work, we introduce a paradigm of designing\nrecurrent deep networks whereby the output of the recurrent layer is derived\nfrom appropriate arguments from nonparametric statistics. A novel variational\nBayesian sequence-to-sequence network architecture is proposed that consists of\na) a full Gaussian posterior distribution for data-driven memory compression\nand b) a nonparametric Indian Buffet Process prior for regularization applied\non the Gated Recurrent Unit non-gate weights. We dub our approach\nStick-Breaking Recurrent network and show that it can achieve a substantial\nweight compression without diminishing modeling performance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 17:36:30 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Partaourides", "Harris", ""], ["Voskou", "Andreas", ""], ["Kosmopoulos", "Dimitrios", ""], ["Chatzis", "Sotirios", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "2102.06171", "submitter": "Andrew Brock", "authors": "Andrew Brock, Soham De, Samuel L. Smith, Karen Simonyan", "title": "High-Performance Large-Scale Image Recognition Without Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization is a key component of most image classification models,\nbut it has many undesirable properties stemming from its dependence on the\nbatch size and interactions between examples. Although recent work has\nsucceeded in training deep ResNets without normalization layers, these models\ndo not match the test accuracies of the best batch-normalized networks, and are\noften unstable for large learning rates or strong data augmentations. In this\nwork, we develop an adaptive gradient clipping technique which overcomes these\ninstabilities, and design a significantly improved class of Normalizer-Free\nResNets. Our smaller models match the test accuracy of an EfficientNet-B7 on\nImageNet while being up to 8.7x faster to train, and our largest models attain\na new state-of-the-art top-1 accuracy of 86.5%. In addition, Normalizer-Free\nmodels attain significantly better performance than their batch-normalized\ncounterparts when finetuning on ImageNet after large-scale pre-training on a\ndataset of 300 million labeled images, with our best models obtaining an\naccuracy of 89.2%. Our code is available at https://github.com/deepmind/\ndeepmind-research/tree/master/nfnets\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:23:20 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Brock", "Andrew", ""], ["De", "Soham", ""], ["Smith", "Samuel L.", ""], ["Simonyan", "Karen", ""]]}, {"id": "2102.06186", "submitter": "Viacheslav Borovitskiy", "authors": "Fedor Pavutnitskiy, Sergei O. Ivanov, Evgeny Abramov, Viacheslav\n  Borovitskiy, Artem Klochkov, Viktor Vialov, Anatolii Zaikovskii, Aleksandr\n  Petiushko", "title": "Quadric hypersurface intersection for manifold learning in feature space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge that data lies close to a particular submanifold of the ambient\nEuclidean space may be useful in a number of ways. For instance, one may want\nto automatically mark any point far away from the submanifold as an outlier, or\nto use its geodesic distance to measure similarity between points. Classical\nproblems for manifold learning are often posed in a very high dimension, e.g.\nfor spaces of images or spaces of representations of words. Today, with deep\nrepresentation learning on the rise in areas such as computer vision and\nnatural language processing, many problems of this kind may be transformed into\nproblems of moderately high dimension, typically of the order of hundreds.\nMotivated by this, we propose a manifold learning technique suitable for\nmoderately high dimension and large datasets. The manifold is learned from the\ntraining data in the form of an intersection of quadric hypersurfaces -- simple\nbut expressive objects. At test time, this manifold can be used to introduce an\noutlier score for arbitrary new points and to improve a given similarity metric\nby incorporating learned geometric structure into it.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:52:08 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Pavutnitskiy", "Fedor", ""], ["Ivanov", "Sergei O.", ""], ["Abramov", "Evgeny", ""], ["Borovitskiy", "Viacheslav", ""], ["Klochkov", "Artem", ""], ["Vialov", "Viktor", ""], ["Zaikovskii", "Anatolii", ""], ["Petiushko", "Aleksandr", ""]]}, {"id": "2102.06197", "submitter": "Johannes Ernst-Emanuel Buck", "authors": "Ngoc Mai Tran and Johannes Buck and Claudia Kl\\\"uppelberg", "title": "Causal Discovery of a River Network from its Extremes", "comments": "26 pages, 15 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference for extremes aims to discover cause and effect relations\nbetween large observed values of random variables. Over the last years, a\nnumber of methods have been proposed for solving the Hidden River Problem, with\nthe Danube data set as benchmark. In this paper, we provide \\QTree, a new and\nsimple algorithm to solve the Hidden River Problem that outperforms existing\nmethods. \\QTree\\ returns a directed graph and achieves almost perfect recovery\non the Danube as well as on new data from the Lower Colorado River. It can\nhandle missing data, has an automated parameter tuning procedure, and runs in\ntime $O(n |V|^2)$, where $n$ is the number of observations and $|V|$ the number\nof nodes in the graph. \\QTree\\ relies on qualitative aspects of the max-linear\nBayesian network model.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:57:21 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Tran", "Ngoc Mai", ""], ["Buck", "Johannes", ""], ["Kl\u00fcppelberg", "Claudia", ""]]}, {"id": "2102.06202", "submitter": "Anastasios Angelopoulos", "authors": "Anastasios N. Angelopoulos and Stephen Bates and Tijana Zrnic and\n  Michael I. Jordan", "title": "Private Prediction Sets", "comments": "Code available at\n  https://github.com/aangelopoulos/private_prediction_sets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world settings involving consequential decision-making, the\ndeployment of machine learning systems generally requires both reliable\nuncertainty quantification and protection of individuals' privacy. We present a\nframework that treats these two desiderata jointly. Our framework is based on\nconformal prediction, a methodology that augments predictive models to return\nprediction sets that provide uncertainty quantification -- they provably cover\nthe true response with a user-specified probability, such as 90%. One might\nhope that when used with privately-trained models, conformal prediction would\nyield privacy guarantees for the resulting prediction sets; unfortunately this\nis not the case. To remedy this key problem, we develop a method that takes any\npre-trained predictive model and outputs differentially private prediction\nsets. Our method follows the general approach of split conformal prediction; we\nuse holdout data to calibrate the size of the prediction sets but preserve\nprivacy by using a privatized quantile subroutine. This subroutine compensates\nfor the noise introduced to preserve privacy in order to guarantee correct\ncoverage. We evaluate the method with experiments on the CIFAR-10, ImageNet,\nand CoronaHack datasets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:59:11 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Angelopoulos", "Anastasios N.", ""], ["Bates", "Stephen", ""], ["Zrnic", "Tijana", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2102.06229", "submitter": "Mufan (Bill) Li", "authors": "Mufan Bill Li, Maxime Gazeau", "title": "Higher Order Generalization Error for First Order Discretization of\n  Langevin Diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel approach to analyze generalization error for\ndiscretizations of Langevin diffusion, such as the stochastic gradient Langevin\ndynamics (SGLD). For an $\\epsilon$ tolerance of expected generalization error,\nit is known that a first order discretization can reach this target if we run\n$\\Omega(\\epsilon^{-1} \\log (\\epsilon^{-1}) )$ iterations with\n$\\Omega(\\epsilon^{-1})$ samples. In this article, we show that with additional\nsmoothness assumptions, even first order methods can achieve arbitrarily\nruntime complexity. More precisely, for each $N>0$, we provide a sufficient\nsmoothness condition on the loss function such that a first order\ndiscretization can reach $\\epsilon$ expected generalization error given\n$\\Omega( \\epsilon^{-1/N} \\log (\\epsilon^{-1}) )$ iterations with\n$\\Omega(\\epsilon^{-1})$ samples.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 19:16:03 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Li", "Mufan Bill", ""], ["Gazeau", "Maxime", ""]]}, {"id": "2102.06234", "submitter": "Botao Hao", "authors": "Nevena Lazi\\'c, Botao Hao, Yasin Abbasi-Yadkori, Dale Schuurmans,\n  Csaba Szepesv\\'ari", "title": "Optimization Issues in KL-Constrained Approximate Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning algorithms can be seen as versions of approximate\npolicy iteration (API). While standard API often performs poorly, it has been\nshown that learning can be stabilized by regularizing each policy update by the\nKL-divergence to the previous policy. Popular practical algorithms such as\nTRPO, MPO, and VMPO replace regularization by a constraint on KL-divergence of\nconsecutive policies, arguing that this is easier to implement and tune. In\nthis work, we study this implementation choice in more detail. We compare the\nuse of KL divergence as a constraint vs. as a regularizer, and point out\nseveral optimization issues with the widely-used constrained approach. We show\nthat the constrained algorithm is not guaranteed to converge even on simple\nproblem instances where the constrained problem can be solved exactly, and in\nfact incurs linear expected regret. With approximate implementation using\nsoftmax policies, we show that regularization can improve the optimization\nlandscape of the original objective. We demonstrate these issues empirically on\nseveral bandit and RL environments.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 19:35:33 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Lazi\u0107", "Nevena", ""], ["Hao", "Botao", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Schuurmans", "Dale", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2102.06246", "submitter": "Sarah Cen", "authors": "Sarah H. Cen and Devavrat Shah", "title": "Regret, stability, and fairness in matching markets with bandit learners", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the two-sided matching market with bandit learners. In the\nstandard matching problem, users and providers are matched to ensure incentive\ncompatibility via the notion of stability. However, contrary to the core\nassumption of the matching problem, users and providers do not know their true\npreferences a priori and must learn them. To address this assumption, recent\nworks propose to blend the matching and multi-armed bandit problems. They\nestablish that it is possible to assign matchings that are stable (i.e.,\nincentive-compatible) at every time step while also allowing agents to learn\nenough so that the system converges to matchings that are stable under the\nagents' true preferences. However, while some agents may incur low regret under\nthese matchings, others can incur high regret -- specifically, $\\Omega(T)$\noptimal regret where $T$ is the time horizon. In this work, we incorporate\ncosts and transfers in the two-sided matching market with bandit learners in\norder to faithfully model competition between agents. We prove that, under our\nframework, it is possible to simultaneously guarantee four desiderata: (1)\nincentive compatibility, i.e., stability, (2) low regret, i.e., $O(\\log(T))$\noptimal regret, (3) fairness in the distribution of regret among agents, and\n(4) high social welfare.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 20:18:12 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Cen", "Sarah H.", ""], ["Shah", "Devavrat", ""]]}, {"id": "2102.06247", "submitter": "Jie Shen", "authors": "Jie Shen", "title": "Sample-Optimal PAC Learning of Halfspaces with Malicious Noise", "comments": "V2 polished writing; accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study efficient PAC learning of homogeneous halfspaces in $\\mathbb{R}^d$\nin the presence of malicious noise of Valiant~(1985). This is a challenging\nnoise model and only until recently has near-optimal noise tolerance bound been\nestablished under the mild condition that the unlabeled data distribution is\nisotropic log-concave. However, it remains unsettled how to obtain the optimal\nsample complexity simultaneously. In this work, we present a new analysis for\nthe algorithm of Awasthi~et~al.~(2017) and show that it essentially achieves\nthe near-optimal sample complexity bound of $\\tilde{O}(d)$, improving the best\nknown result of $\\tilde{O}(d^2)$. Our main ingredient is a novel incorporation\nof a matrix Chernoff-type inequality to bound the spectrum of an empirical\ncovariance matrix for well-behaved distributions, in conjunction with a careful\nexploration of the localization schemes of Awasthi~et~al.~(2017). We further\nextend the algorithm and analysis to the more general and stronger nasty noise\nmodel of Bshouty~et~al.~(2002), showing that it is still possible to achieve\nnear-optimal noise tolerance and sample complexity in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 20:18:20 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 20:56:20 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Shen", "Jie", ""]]}, {"id": "2102.06278", "submitter": "Gabriel Peyr\\'e", "authors": "Geert-Jan Huizing, Laura Cantini, Gabriel Peyr\\'e", "title": "Unsupervised Ground Metric Learning using Wasserstein Eigenvectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimal Transport (OT) defines geometrically meaningful \"Wasserstein\"\ndistances, used in machine learning applications to compare probability\ndistributions. However, a key bottleneck is the design of a \"ground\" cost which\nshould be adapted to the task under study. In most cases, supervised metric\nlearning is not accessible, and one usually resorts to some ad-hoc approach.\nUnsupervised metric learning is thus a fundamental problem to enable\ndata-driven applications of Optimal Transport. In this paper, we propose for\nthe first time a canonical answer by computing the ground cost as a positive\neigenvector of the function mapping a cost to the pairwise OT distances between\nthe inputs. This map is homogeneous and monotone, thus framing unsupervised\nmetric learning as a non-linear Perron-Frobenius problem. We provide criteria\nto ensure the existence and uniqueness of this eigenvector. In addition, we\nintroduce a scalable computational method using entropic regularization, which\n- in the large regularization limit - operates a principal component analysis\ndimensionality reduction. We showcase this method on synthetic examples and\ndatasets. Finally, we apply it in the context of biology to the analysis of a\nhigh-throughput single-cell RNA sequencing (scRNAseq) dataset, to improve cell\nclustering and infer the relationships between genes in an unsupervised way.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 21:32:59 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Huizing", "Geert-Jan", ""], ["Cantini", "Laura", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "2102.06280", "submitter": "Jian Li", "authors": "Guojun Xiong, Gang Yan, Rahul Singh, Jian Li", "title": "Straggler-Resilient Distributed Machine Learning with Dynamic Backup\n  Workers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demand for large-scale training of machine learning\nmodels, consensus-based distributed optimization methods have recently been\nadvocated as alternatives to the popular parameter server framework. In this\nparadigm, each worker maintains a local estimate of the optimal parameter\nvector, and iteratively updates it by waiting and averaging all estimates\nobtained from its neighbors, and then corrects it on the basis of its local\ndataset. However, the synchronization phase can be time consuming due to the\nneed to wait for \\textit{stragglers}, i.e., slower workers. An efficient way to\nmitigate this effect is to let each worker wait only for updates from the\nfastest neighbors before updating its local parameter. The remaining neighbors\nare called \\textit{backup workers.} To minimize the globally training time over\nthe network, we propose a fully distributed algorithm to dynamically determine\nthe number of backup workers for each worker. We show that our algorithm\nachieves a linear speedup for convergence (i.e., convergence performance\nincreases linearly with respect to the number of workers). We conduct extensive\nexperiments on MNIST and CIFAR-10 to verify our theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 21:39:53 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Xiong", "Guojun", ""], ["Yan", "Gang", ""], ["Singh", "Rahul", ""], ["Li", "Jian", ""]]}, {"id": "2102.06304", "submitter": "Massimiliano Pontil", "authors": "Andreas Maurer and Massimiliano Pontil", "title": "Some Hoeffding- and Bernstein-type Concentration Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove concentration inequalities for functions of independent random\nvariables {under} sub-gaussian and sub-exponential conditions. The utility of\nthe inequalities is demonstrated by an extension of the now classical method of\nRademacher complexities to Lipschitz function classes and unbounded\nsub-exponential distribution.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 23:09:13 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 17:25:58 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 07:37:29 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 13:03:37 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Maurer", "Andreas", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "2102.06350", "submitter": "Yifei Wang", "authors": "Yifei Wang, Peng Chen and Wuchen Li", "title": "Projected Wasserstein gradient descent for high-dimensional Bayesian\n  inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a projected Wasserstein gradient descent method (pWGD) for\nhigh-dimensional Bayesian inference problems. The underlying density function\nof a particle system of WGD is approximated by kernel density estimation (KDE),\nwhich faces the long-standing curse of dimensionality. We overcome this\nchallenge by exploiting the intrinsic low-rank structure in the difference\nbetween the posterior and prior distributions. The parameters are projected\ninto a low-dimensional subspace to alleviate the approximation error of KDE in\nhigh dimensions. We formulate a projected Wasserstein gradient flow and analyze\nits convergence property under mild assumptions. Several numerical experiments\nillustrate the accuracy, convergence, and complexity scalability of pWGD with\nrespect to parameter dimension, sample size, and processor cores.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 05:12:05 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 02:16:10 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Yifei", ""], ["Chen", "Peng", ""], ["Li", "Wuchen", ""]]}, {"id": "2102.06356", "submitter": "Zachary Nado", "authors": "Zachary Nado, Justin M. Gilmer, Christopher J. Shallue, Rohan Anil,\n  George E. Dahl", "title": "A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers\n  Suffice Across Batch Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the LARS and LAMB optimizers have been proposed for training neural\nnetworks faster using large batch sizes. LARS and LAMB add layer-wise\nnormalization to the update rules of Heavy-ball momentum and Adam,\nrespectively, and have become popular in prominent benchmarks and deep learning\nlibraries. However, without fair comparisons to standard optimizers, it remains\nan open question whether LARS and LAMB have any benefit over traditional,\ngeneric algorithms. In this work we demonstrate that standard optimization\nalgorithms such as Nesterov momentum and Adam can match or exceed the results\nof LARS and LAMB at large batch sizes. Our results establish new, stronger\nbaselines for future comparisons at these batch sizes and shed light on the\ndifficulties of comparing optimizers for neural network training more\ngenerally.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 05:57:01 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 21:22:54 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 19:39:11 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Nado", "Zachary", ""], ["Gilmer", "Justin M.", ""], ["Shallue", "Christopher J.", ""], ["Anil", "Rohan", ""], ["Dahl", "George E.", ""]]}, {"id": "2102.06387", "submitter": "Peter Kairouz", "authors": "Peter Kairouz and Ziyu Liu and Thomas Steinke", "title": "The Distributed Discrete Gaussian Mechanism for Federated Learning with\n  Secure Aggregation", "comments": "Accepted for publication at the 38th International Conference on\n  Machine Learning (ICML 2021).1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider training models on private data that are distributed across user\ndevices. To ensure privacy, we add on-device noise and use secure aggregation\nso that only the noisy sum is revealed to the server. We present a\ncomprehensive end-to-end system, which appropriately discretizes the data and\nadds discrete Gaussian noise before performing secure aggregation. We provide a\nnovel privacy analysis for sums of discrete Gaussians and carefully analyze the\neffects of data quantization and modular summation arithmetic. Our theoretical\nguarantees highlight the complex tension between communication, privacy, and\naccuracy. Our extensive experimental results demonstrate that our solution is\nessentially able to match the accuracy to central differential privacy with\nless than 16 bits of precision per value.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 08:20:18 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 04:24:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kairouz", "Peter", ""], ["Liu", "Ziyu", ""], ["Steinke", "Thomas", ""]]}, {"id": "2102.06416", "submitter": "Martin Jullum PhD", "authors": "Kjersti Aas, Thomas Nagler, Martin Jullum, Anders L{\\o}land", "title": "Explaining predictive models using Shapley values and non-parametric\n  vine copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original development of Shapley values for prediction explanation relied\non the assumption that the features being described were independent. If the\nfeatures in reality are dependent this may lead to incorrect explanations.\nHence, there have recently been attempts of appropriately modelling/estimating\nthe dependence between the features. Although the proposed methods clearly\noutperform the traditional approach assuming independence, they have their\nweaknesses. In this paper we propose two new approaches for modelling the\ndependence between the features.\n  Both approaches are based on vine copulas, which are flexible tools for\nmodelling multivariate non-Gaussian distributions able to characterise a wide\nrange of complex dependencies.\n  The performance of the proposed methods is evaluated on simulated data sets\nand a real data set. The experiments demonstrate that the vine copula\napproaches give more accurate approximations to the true Shapley values than\nits competitors.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 09:43:28 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Aas", "Kjersti", ""], ["Nagler", "Thomas", ""], ["Jullum", "Martin", ""], ["L\u00f8land", "Anders", ""]]}, {"id": "2102.06477", "submitter": "Pedro L. C. Rodrigues", "authors": "Pedro L. C. Rodrigues, Thomas Moreau, Gilles Louppe, Alexandre\n  Gramfort", "title": "Leveraging Global Parameters for Flow-based Neural Posterior Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inferring the parameters of a stochastic model based on experimental\nobservations is central to the scientific method. A particularly challenging\nsetting is when the model is strongly indeterminate, i.e., when distinct sets\nof parameters yield identical observations. This arises in many practical\nsituations, such as when inferring the distance and power of a radio source (is\nthe source close and weak or far and strong?) or when estimating the amplifier\ngain and underlying brain activity of an electrophysiological experiment. In\nthis work, we present a method for cracking such indeterminacy by exploiting\nadditional information conveyed by an auxiliary set of observations sharing\nglobal parameters. Our method extends recent developments in simulation-based\ninference(SBI) based on normalizing flows to Bayesian hierarchical models. We\nvalidate quantitatively our proposal on a motivating example amenable to\nanalytical solutions, and then apply it to invert a well known non-linear model\nfrom computational neuroscience.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 12:23:13 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 07:35:10 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Rodrigues", "Pedro L. C.", ""], ["Moreau", "Thomas", ""], ["Louppe", "Gilles", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "2102.06496", "submitter": "Christina Runkel", "authors": "Christina Runkel, Christian Etmann, Michael M\\\"oller, Carola-Bibiane\n  Sch\\\"onlieb", "title": "Depthwise Separable Convolutions Allow for Fast and Memory-Efficient\n  Spectral Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of models require the control of the spectral norm of\nconvolutional layers of a neural network. While there is an abundance of\nmethods for estimating and enforcing upper bounds on those during training,\nthey are typically costly in either memory or time. In this work, we introduce\na very simple method for spectral normalization of depthwise separable\nconvolutions, which introduces negligible computational and memory overhead. We\ndemonstrate the effectiveness of our method on image classification tasks using\nstandard architectures like MobileNetV2.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 12:55:42 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Runkel", "Christina", ""], ["Etmann", "Christian", ""], ["M\u00f6ller", "Michael", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "2102.06514", "submitter": "Shantanu Thakoor", "authors": "Shantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, R\\'emi\n  Munos, Petar Veli\\v{c}kovi\\'c, Michal Valko", "title": "Bootstrapped Representation Learning on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art self-supervised learning methods for graph neural\nnetworks (GNNs) are based on contrastive learning. As such, they heavily depend\non the construction of augmentations and negative examples. For example, on the\nstandard PPI benchmark, increasing the number of negative pairs improves\nperformance, thereby requiring computation and memory cost quadratic in the\nnumber of nodes to achieve peak performance. Inspired by BYOL, a recently\nintroduced method for self-supervised learning that does not require negative\npairs, we present Bootstrapped Graph Latents, BGRL, a self-supervised graph\nrepresentation method that gets rid of this potentially quadratic bottleneck.\nBGRL outperforms or matches the previous unsupervised state-of-the-art results\non several established benchmark datasets. Moreover, it enables the effective\nusage of graph attentional (GAT) encoders, allowing us to further improve the\nstate of the art. In particular on the PPI dataset, using GAT as an encoder we\nachieve state-of-the-art 70.49% Micro-F1, using the linear evaluation protocol.\nOn all other datasets under consideration, our model is competitive with the\nequivalent supervised GNN results, often exceeding them.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:36:39 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Thakoor", "Shantanu", ""], ["Tallec", "Corentin", ""], ["Azar", "Mohammad Gheshlaghi", ""], ["Munos", "R\u00e9mi", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Valko", "Michal", ""]]}, {"id": "2102.06521", "submitter": "Fredrik Wrede", "authors": "Fredrik Wrede, Robin Eriksson, Richard Jiang, Linda Petzold, Stefan\n  Engblom, Andreas Hellander, Prashant Singh", "title": "Robust and integrative Bayesian neural networks for likelihood-free\n  parameter inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art neural network-based methods for learning summary statistics\nhave delivered promising results for simulation-based likelihood-free parameter\ninference. Existing approaches require density estimation as a post-processing\nstep building upon deterministic neural networks, and do not take network\nprediction uncertainty into account. This work proposes a robust integrated\napproach that learns summary statistics using Bayesian neural networks, and\ndirectly estimates the posterior density using categorical distributions. An\nadaptive sampling scheme selects simulation locations to efficiently and\niteratively refine the predictive posterior of the network conditioned on\nobservations. This allows for more efficient and robust convergence on\ncomparatively large prior spaces. We demonstrate our approach on benchmark\nexamples and compare against related methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:45:23 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 16:39:14 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Wrede", "Fredrik", ""], ["Eriksson", "Robin", ""], ["Jiang", "Richard", ""], ["Petzold", "Linda", ""], ["Engblom", "Stefan", ""], ["Hellander", "Andreas", ""], ["Singh", "Prashant", ""]]}, {"id": "2102.06522", "submitter": "Samuel Wiqvist", "authors": "Samuel Wiqvist, Jes Frellsen, Umberto Picchini", "title": "Sequential Neural Posterior and Likelihood Approximation", "comments": "28 pages, 8 tables, 14 figures. The supplementary material is\n  attached to the main paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the sequential neural posterior and likelihood approximation\n(SNPLA) algorithm. SNPLA is a normalizing flows-based algorithm for inference\nin implicit models, and therefore is a simulation-based inference method that\nonly requires simulations from a generative model. SNPLA avoids Markov chain\nMonte Carlo sampling and correction-steps of the parameter proposal function\nthat are introduced in similar methods, but that can be numerically unstable or\nrestrictive. By utilizing the reverse KL divergence, SNPLA manages to learn\nboth the likelihood and the posterior in a sequential manner. Over four\nexperiments, we show that SNPLA performs competitively when utilizing the same\nnumber of model simulations as used in other methods, even though the inference\nproblem for SNPLA is more complex due to the joint learning of posterior and\nlikelihood function. Due to utilizing normalizing flows SNPLA generates\nposterior draws much faster (4 orders of magnitude) than MCMC-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:46:47 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 09:21:59 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wiqvist", "Samuel", ""], ["Frellsen", "Jes", ""], ["Picchini", "Umberto", ""]]}, {"id": "2102.06527", "submitter": "Francesco Sanna Passino", "authors": "Francesco Sanna Passino, Nicholas A. Heard", "title": "Mutually exciting point process graphs for modelling dynamic networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of models for dynamic networks is proposed, called mutually\nexciting point process graphs (MEG), motivated by a practical application in\ncomputer network security. MEG is a scalable network-wide statistical model for\npoint processes with dyadic marks, which can be used for anomaly detection when\nassessing the significance of previously unobserved connections. The model\ncombines mutually exciting point processes to estimate dependencies between\nevents and latent space models to infer relationships between the nodes. The\nintensity functions for each network edge are parameterised exclusively by\nnode-specific parameters, which allows information to be shared across the\nnetwork. Fast inferential procedures using modern gradient ascent algorithms\nare exploited. The model is tested on simulated graphs and real world computer\nnetwork datasets, demonstrating excellent performance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 10:14:55 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Passino", "Francesco Sanna", ""], ["Heard", "Nicholas A.", ""]]}, {"id": "2102.06539", "submitter": "Huadong Liao", "authors": "Huadong Liao and Jiawei He", "title": "Jacobian Determinant of Normalizing Flows", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows learn a diffeomorphic mapping between the target and base\ndistribution, while the Jacobian determinant of that mapping forms another\nreal-valued function. In this paper, we show that the Jacobian determinant\nmapping is unique for the given distributions, hence the likelihood objective\nof flows has a unique global optimum. In particular, the likelihood for a class\nof flows is explicitly expressed by the eigenvalues of the auto-correlation\nmatrix of individual data point, and independent of the parameterization of\nneural network, which provides a theoretical optimal value of likelihood\nobjective and relates to probabilistic PCA. Additionally, Jacobian determinant\nis a measure of local volume change and is maximized when MLE is used for\noptimization. To stabilize normalizing flows training, it is required to\nmaintain a balance between the expansiveness and contraction of volume, meaning\nLipschitz constraint on the diffeomorphic mapping and its inverse. With these\ntheoretical results, several principles of designing normalizing flow were\nproposed. And numerical experiments on highdimensional datasets (such as\nCelebA-HQ 1024x1024) were conducted to show the improved stability of training.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 14:09:28 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 06:56:35 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Liao", "Huadong", ""], ["He", "Jiawei", ""]]}, {"id": "2102.06548", "submitter": "Yuejie Chi", "authors": "Gen Li, Changxiao Cai, Yuxin Chen, Yuantao Gu, Yuting Wei, Yuejie Chi", "title": "Is Q-Learning Minimax Optimal? A Tight Sample Complexity Analysis", "comments": "v2 added a matching lower bound, and removed the finite-horizon\n  setting for brevity", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Q-learning, which seeks to learn the optimal Q-function of a Markov decision\nprocess (MDP) in a model-free fashion, lies at the heart of reinforcement\nlearning. When it comes to the synchronous setting (such that independent\nsamples for all state-action pairs are drawn from a generative model in each\niteration), substantial progress has been made recently towards understanding\nthe sample efficiency of Q-learning. Take a $\\gamma$-discounted\ninfinite-horizon MDP with state space $\\mathcal{S}$ and action space\n$\\mathcal{A}$: to yield an entrywise $\\varepsilon$-accurate estimate of the\noptimal Q-function, state-of-the-art theory for Q-learning proves that a sample\nsize on the order of\n$\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)^5\\varepsilon^{2}}$ is sufficient,\nwhich, however, fails to match with the existing minimax lower bound. This\ngives rise to natural questions: what is the sharp sample complexity of\nQ-learning? Is Q-learning provably sub-optimal? In this work, we settle these\nquestions by (1) demonstrating that the sample complexity of Q-learning is at\nmost on the order of\n$\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)^4\\varepsilon^2}$ (up to some log\nfactor) for any $0<\\varepsilon <1$, and (2) developing a matching lower bound\nto confirm the sharpness of our result. Our findings unveil both the\neffectiveness and limitation of Q-learning: its sample complexity matches that\nof speedy Q-learning without requiring extra computation and storage, albeit\nstill being considerably higher than the minimax lower bound.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 14:22:05 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 13:56:01 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Li", "Gen", ""], ["Cai", "Changxiao", ""], ["Chen", "Yuxin", ""], ["Gu", "Yuantao", ""], ["Wei", "Yuting", ""], ["Chi", "Yuejie", ""]]}, {"id": "2102.06559", "submitter": "Winnie Xu", "authors": "Winnie Xu, Ricky T.Q. Chen, Xuechen Li, David Duvenaud", "title": "Infinitely Deep Bayesian Neural Networks with Stochastic Differential\n  Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform scalable approximate inference in a continuous-depth Bayesian\nneural network family. In this model class, uncertainty about separate weights\nin each layer gives hidden units that follow a stochastic differential\nequation. We demonstrate gradient-based stochastic variational inference in\nthis infinite-parameter setting, producing arbitrarily-flexible approximate\nposteriors. We also derive a novel gradient estimator that approaches zero\nvariance as the approximate posterior over weights approaches the true\nposterior. This approach brings continuous-depth Bayesian neural nets to a\ncompetitive comparison against discrete-depth alternatives, while inheriting\nthe memory-efficient training and tunable precision of Neural ODEs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 14:48:58 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 21:03:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Winnie", ""], ["Chen", "Ricky T. Q.", ""], ["Li", "Xuechen", ""], ["Duvenaud", "David", ""]]}, {"id": "2102.06571", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin, Adri\\`a Garriga-Alonso, Florian Wenzel, Gunnar\n  R\\\"atsch, Richard Turner, Mark van der Wilk, Laurence Aitchison", "title": "Bayesian Neural Network Priors Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isotropic Gaussian priors are the de facto standard for modern Bayesian\nneural network inference. However, such simplistic priors are unlikely to\neither accurately reflect our true beliefs about the weight distributions, or\nto give optimal performance. We study summary statistics of neural network\nweights in different networks trained using SGD. We find that fully connected\nnetworks (FCNNs) display heavy-tailed weight distributions, while convolutional\nneural network (CNN) weights display strong spatial correlations. Building\nthese observations into the respective priors leads to improved performance on\na variety of image classification datasets. Moreover, we find that these priors\nalso mitigate the cold posterior effect in FCNNs, while in CNNs we see strong\nimprovements at all temperatures, and hence no reduction in the cold posterior\neffect.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 15:18:06 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Fortuin", "Vincent", ""], ["Garriga-Alonso", "Adri\u00e0", ""], ["Wenzel", "Florian", ""], ["R\u00e4tsch", "Gunnar", ""], ["Turner", "Richard", ""], ["van der Wilk", "Mark", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2102.06573", "submitter": "Alberto Caron", "authors": "Alberto Caron, Gianluca Baio and Ioanna Manolopoulou", "title": "Sparse Bayesian Causal Forests for Heterogeneous Treatment Effects\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a sparsity-inducing version of Bayesian Causal Forests, a\nrecently proposed nonparametric causal regression model that employs Bayesian\nAdditive Regression Trees and is specifically designed to estimate\nheterogeneous treatment effects using observational data. The sparsity-inducing\ncomponent we introduce is motivated by empirical studies where the number of\npre-treatment covariates available is non-negligible, leading to different\ndegrees of sparsity underlying the surfaces of interest in the estimation of\nindividual treatment effects. The extended version presented in this work,\nwhich we name Sparse Bayesian Causal Forest, is equipped with an additional\npair of priors allowing the model to adjust the weight of each covariate\nthrough the corresponding number of splits in the tree ensemble. These priors\nimprove the model's adaptability to sparse settings and allow to perform fully\nBayesian variable selection in a framework for treatment effects estimation,\nand thus to uncover the moderating factors driving heterogeneity. In addition,\nthe method allows prior knowledge about the relevant confounding pre-treatment\ncovariates and the relative magnitude of their impact on the outcome to be\nincorporated in the model. We illustrate the performance of our method in\nsimulated studies, in comparison to Bayesian Causal Forest and other\nstate-of-the-art models, to demonstrate how it scales up with an increasing\nnumber of covariates and how it handles strongly confounded scenarios. Finally,\nwe also provide an example of application using real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 15:24:50 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 18:13:08 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 20:59:06 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Caron", "Alberto", ""], ["Baio", "Gianluca", ""], ["Manolopoulou", "Ioanna", ""]]}, {"id": "2102.06589", "submitter": "Alec Farid", "authors": "Alec Farid and Anirudha Majumdar", "title": "PAC-BUS: Meta-Learning Bounds via PAC-Bayes and Uniform Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are motivated by the problem of providing strong generalization guarantees\nin the context of meta-learning. Existing generalization bounds are either\nchallenging to evaluate or provide vacuous guarantees in even relatively simple\nsettings. We derive a probably approximately correct (PAC) bound for\ngradient-based meta-learning using two different generalization frameworks in\norder to deal with the qualitatively different challenges of generalization at\nthe \"base\" and \"meta\" levels. We employ bounds for uniformly stable algorithms\nat the base level and bounds from the PAC-Bayes framework at the meta level.\nThe result is a novel PAC-bound that is tighter when the base learner adapts\nquickly, which is precisely the goal of meta-learning. We show that our bound\nprovides a tighter guarantee than other bounds on a toy non-convex problem on\nthe unit sphere and a text-based classification example. We also present a\npractical regularization scheme motivated by the bound in settings where the\nbound is loose and demonstrate improved performance over baseline techniques.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 15:57:45 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 15:14:17 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Farid", "Alec", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2102.06593", "submitter": "Yinglun Zhu", "authors": "Yinglun Zhu, Robert Nowak", "title": "Pareto Optimal Model Selection in Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a model selection problem in the linear bandit setting, where the\nlearner must adapt to the dimension of the optimal hypothesis class on the fly\nand balance exploration and exploitation. More specifically, we assume a\nsequence of nested linear hypothesis classes with dimensions $d_1 < d_2 <\n\\dots$, and the goal is to automatically adapt to the smallest hypothesis class\nthat contains the true linear model. Although previous papers provide various\nguarantees for this model selection problem, the analysis therein either works\nin favorable cases when one can cheaply conduct statistical testing to locate\nthe right hypothesis class or is based on the idea of \"corralling\" multiple\nbase algorithms which often performs relatively poorly in practice. These works\nalso mainly focus on upper bounding the regret. In this paper, we first\nestablish a lower bound showing that, even with a fixed action set, adaptation\nto the unknown intrinsic dimension $d_\\star$ comes at a cost: there is no\nalgorithm that can achieve the regret bound $\\widetilde{O}(\\sqrt{d_\\star T})$\nsimultaneously for all values of $d_\\star$. We also bring new ideas, i.e.,\nconstructing virtual mixture-arms to effectively summarize useful information,\ninto the model selection problem in linear bandits. Under a mild assumption on\nthe action set, we design a Pareto optimal algorithm with guarantees matching\nthe rate in the lower bound. Experimental results confirm our theoretical\nresults and show advantages of our algorithm compared to prior work.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 16:02:06 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Zhu", "Yinglun", ""], ["Nowak", "Robert", ""]]}, {"id": "2102.06602", "submitter": "Paramveer Dhillon", "authors": "Paramveer Dhillon and Sinan Aral", "title": "Modeling Dynamic User Interests: A Neural Matrix Factorization Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been significant interest in understanding users'\nonline content consumption patterns. But, the unstructured, high-dimensional,\nand dynamic nature of such data makes extracting valuable insights challenging.\nHere we propose a model that combines the simplicity of matrix factorization\nwith the flexibility of neural networks to efficiently extract nonlinear\npatterns from massive text data collections relevant to consumers' online\nconsumption patterns. Our model decomposes a user's content consumption journey\ninto nonlinear user and content factors that are used to model their dynamic\ninterests. This natural decomposition allows us to summarize each user's\ncontent consumption journey with a dynamic probabilistic weighting over a set\nof underlying content attributes. The model is fast to estimate, easy to\ninterpret and can harness external data sources as an empirical prior. These\nadvantages make our method well suited to the challenges posed by modern\ndatasets. We use our model to understand the dynamic news consumption interests\nof Boston Globe readers over five years. Thorough qualitative studies,\nincluding a crowdsourced evaluation, highlight our model's ability to\naccurately identify nuanced and coherent consumption patterns. These results\nare supported by our model's superior and robust predictive performance over\nseveral competitive baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 16:24:21 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Dhillon", "Paramveer", ""], ["Aral", "Sinan", ""]]}, {"id": "2102.06604", "submitter": "Frank Schneider", "authors": "Frank Schneider and Felix Dangel and Philipp Hennig", "title": "Cockpit: A Practical Debugging Tool for Training Deep Neural Networks", "comments": "Main text: 10 pages, 7 figures, 1 table; Supplements: 17 pages, 9\n  figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When engineers train deep learning models, they are very much \"flying blind\".\nCommonly used approaches for real-time training diagnostics, such as monitoring\nthe train/test loss, are limited. Assessing a network's training process solely\nthrough these performance indicators is akin to debugging software without\naccess to internal states through a debugger. To address this, we present\nCockpit, a collection of instruments that enable a closer look into the inner\nworkings of a learning machine, and a more informative and meaningful status\nreport for practitioners. It facilitates the identification of learning phases\nand failure modes, like ill-chosen hyperparameters. These instruments leverage\nnovel higher-order information about the gradient distribution and curvature,\nwhich has only recently become efficiently accessible. We believe that such a\ndebugging tool, which we open-source for PyTorch, represents an important step\nto improve troubleshooting the training process, reveal new insights, and help\ndevelop novel methods and heuristics.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 16:28:49 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Schneider", "Frank", ""], ["Dangel", "Felix", ""], ["Hennig", "Philipp", ""]]}, {"id": "2102.06622", "submitter": "Dirk van der Hoeven", "authors": "Tim van Erven, Wouter M. Koolen, Dirk van der Hoeven", "title": "MetaGrad: Adaptation using Multiple Learning Rates in Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a new adaptive method for online convex optimization, MetaGrad,\nthat is robust to general convex losses but achieves faster rates for a broad\nclass of special functions, including exp-concave and strongly convex\nfunctions, but also various types of stochastic and non-stochastic functions\nwithout any curvature. We prove this by drawing a connection to the Bernstein\ncondition, which is known to imply fast rates in offline statistical learning.\nMetaGrad further adapts automatically to the size of the gradients. Its main\nfeature is that it simultaneously considers multiple learning rates, which are\nweighted directly proportional to their empirical performance on the data using\na new meta-algorithm. We provide three versions of MetaGrad. The full matrix\nversion maintains a full covariance matrix and is applicable to learning tasks\nfor which we can afford update time quadratic in the dimension. The other two\nversions provide speed-ups for high-dimensional learning tasks with an update\ntime that is linear in the dimension: one is based on sketching, the other on\nrunning a separate copy of the basic algorithm per coordinate. We evaluate all\nversions of MetaGrad on benchmark online classification and regression tasks,\non which they consistently outperform both online gradient descent and AdaGrad.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:01:35 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["van Erven", "Tim", ""], ["Koolen", "Wouter M.", ""], ["van der Hoeven", "Dirk", ""]]}, {"id": "2102.06635", "submitter": "Christoph Hertrich", "authors": "Christoph Hertrich and Leon Sering", "title": "ReLU Neural Networks for Exact Maximum Flow Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the great empirical success of artificial neural networks (NNs)\nfrom a theoretical point of view is currently one of the hottest research\ntopics in computer science. In this paper we study the expressive power of NNs\nwith rectified linear units from a combinatorial optimization perspective. In\nparticular, we show that, given a directed graph with $n$ nodes and $m$ arcs,\nthere exists an NN of polynomial size that computes a maximum flow from any\npossible real-valued arc capacities as input. To prove this, we develop the\npseudo-code language Max-Affine Arithmetic Programs (MAAPs) and show\nequivalence between MAAPs and NNs concerning natural complexity measures. We\nthen design a MAAP to exactly solve the Maximum Flow Problem, which translates\nto an NN of size $\\mathcal{O}(m^2 n^2)$.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:23:34 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hertrich", "Christoph", ""], ["Sering", "Leon", ""]]}, {"id": "2102.06645", "submitter": "Alexandra Gessner", "authors": "Christian Fr\\\"ohlich, Alexandra Gessner, Philipp Hennig, Bernhard\n  Sch\\\"olkopf, Georgios Arvanitidis", "title": "Bayesian Quadrature on Riemannian Data Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Riemannian manifolds provide a principled way to model nonlinear geometric\nstructure inherent in data. A Riemannian metric on said manifolds determines\ngeometry-aware shortest paths and provides the means to define statistical\nmodels accordingly. However, these operations are typically computationally\ndemanding. To ease this computational burden, we advocate probabilistic\nnumerical methods for Riemannian statistics. In particular, we focus on\nBayesian quadrature (BQ) to numerically compute integrals over normal laws on\nRiemannian manifolds learned from data. In this task, each function evaluation\nrelies on the solution of an expensive initial value problem. We show that by\nleveraging both prior knowledge and an active exploration scheme, BQ\nsignificantly reduces the number of required evaluations and thus outperforms\nMonte Carlo methods on a wide range of integration problems. As a concrete\napplication, we highlight the merits of adopting Riemannian geometry with our\nproposed framework on a nonlinear dataset from molecular dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:38:04 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 09:06:42 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Fr\u00f6hlich", "Christian", ""], ["Gessner", "Alexandra", ""], ["Hennig", "Philipp", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Arvanitidis", "Georgios", ""]]}, {"id": "2102.06695", "submitter": "Andres Potapczynski", "authors": "Andres Potapczynski, Luhuan Wu, Dan Biderman, Geoff Pleiss and John P.\n  Cunningham", "title": "Bias-Free Scalable Gaussian Processes via Randomized Truncations", "comments": null, "journal-ref": "38th International Conference on Machine Learning (ICML 2021)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable Gaussian Process methods are computationally attractive, yet\nintroduce modeling biases that require rigorous study. This paper analyzes two\ncommon techniques: early truncated conjugate gradients (CG) and random Fourier\nfeatures (RFF). We find that both methods introduce a systematic bias on the\nlearned hyperparameters: CG tends to underfit while RFF tends to overfit. We\naddress these issues using randomized truncation estimators that eliminate bias\nin exchange for increased variance. In the case of RFF, we show that the\nbias-to-variance conversion is indeed a trade-off: the additional variance\nproves detrimental to optimization. However, in the case of CG, our unbiased\nlearning procedure meaningfully outperforms its biased counterpart with minimal\nadditional computation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 18:54:10 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 00:54:07 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Potapczynski", "Andres", ""], ["Wu", "Luhuan", ""], ["Biderman", "Dan", ""], ["Pleiss", "Geoff", ""], ["Cunningham", "John P.", ""]]}, {"id": "2102.06701", "submitter": "Ethan Dyer", "authors": "Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, Utkarsh Sharma", "title": "Explaining Neural Scaling Laws", "comments": "11 pages, 5 figures + Supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The test loss of well-trained neural networks often follows precise power-law\nscaling relations with either the size of the training dataset or the number of\nparameters in the network. We propose a theory that explains and connects these\nscaling laws. We identify variance-limited and resolution-limited scaling\nbehavior for both dataset and model size, for a total of four scaling regimes.\nThe variance-limited scaling follows simply from the existence of a\nwell-behaved infinite data or infinite width limit, while the\nresolution-limited regime can be explained by positing that models are\neffectively resolving a smooth data manifold. In the large width limit, this\ncan be equivalently obtained from the spectrum of certain kernels, and we\npresent evidence that large width and large dataset resolution-limited scaling\nexponents are related by a duality. We exhibit all four scaling regimes in the\ncontrolled setting of large random feature and pretrained models and test the\npredictions empirically on a range of standard architectures and datasets. We\nalso observe several empirical relationships between datasets and scaling\nexponents: super-classing image tasks does not change exponents, while changing\ninput distribution (via changing datasets or adding noise) has a strong effect.\nWe further explore the effect of architecture aspect ratio on scaling\nexponents.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 18:57:46 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Bahri", "Yasaman", ""], ["Dyer", "Ethan", ""], ["Kaplan", "Jared", ""], ["Lee", "Jaehoon", ""], ["Sharma", "Utkarsh", ""]]}, {"id": "2102.06735", "submitter": "Boyang Liu", "authors": "Boyang Liu, Mengying Sun, Ding Wang, Pang-Ning Tan, Jiayu Zhou", "title": "Learning Deep Neural Networks under Agnostic Corrupted Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural models in the presence of corrupted supervision is\nchallenging as the corrupted data points may significantly impact the\ngeneralization performance. To alleviate this problem, we present an efficient\nrobust algorithm that achieves strong guarantees without any assumption on the\ntype of corruption and provides a unified framework for both classification and\nregression problems. Unlike many existing approaches that quantify the quality\nof the data points (e.g., based on their individual loss values), and filter\nthem accordingly, the proposed algorithm focuses on controlling the collective\nimpact of data points on the average gradient. Even when a corrupted data point\nfailed to be excluded by our algorithm, the data point will have a very limited\nimpact on the overall loss, as compared with state-of-the-art filtering methods\nbased on loss values. Extensive experiments on multiple benchmark datasets have\ndemonstrated the robustness of our algorithm under different types of\ncorruption.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 19:36:04 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Liu", "Boyang", ""], ["Sun", "Mengying", ""], ["Wang", "Ding", ""], ["Tan", "Pang-Ning", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2102.06737", "submitter": "Yi Ren", "authors": "Yi Ren, Donald Goldfarb", "title": "Kronecker-factored Quasi-Newton Methods for Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second-order methods have the capability of accelerating optimization by\nusing much richer curvature information than first-order methods. However, most\nare impractical in a deep learning setting where the number of training\nparameters is huge. In this paper, we propose KF-QN-CNN, a new\nKronecker-factored quasi-Newton method for training convolutional neural\nnetworks (CNNs), where the Hessian is approximated by a layer-wise block\ndiagonal matrix and each layer's diagonal block is further approximated by a\nKronecker product corresponding to the structure of the Hessian restricted to\nthat layer. New damping and Hessian-action techniques for BFGS are designed to\ndeal with the non-convexity and the particularly large size of Kronecker\nmatrices in CNN models and convergence results are proved for a variant of\nKF-QN-CNN under relatively mild conditions. KF-QN-CNN has memory requirements\ncomparable to first-order methods and much less per-iteration time complexity\nthan traditional second-order methods. Compared with state-of-the-art first-\nand second-order methods on several CNN models, KF-QN-CNN consistently\nexhibited superior performance in all of our tests.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 19:40:34 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ren", "Yi", ""], ["Goldfarb", "Donald", ""]]}, {"id": "2102.06740", "submitter": "Nicholas Baskerville", "authors": "Nicholas P Baskerville and Diego Granziol and Jonathan P Keating", "title": "Applicability of Random Matrix Theory in Deep Learning", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the local spectral statistics of the loss surface Hessians of\nartificial neural networks, where we discover excellent agreement with Gaussian\nOrthogonal Ensemble statistics across several network architectures and\ndatasets. These results shed new light on the applicability of Random Matrix\nTheory to modelling neural networks and suggest a previously unrecognised role\nfor it in the study of loss surfaces in deep learning. Inspired by these\nobservations, we propose a novel model for the true loss surfaces of neural\nnetworks, consistent with our observations, which allows for Hessian spectral\ndensities with rank degeneracy and outliers, extensively observed in practice,\nand predicts a growing independence of loss gradients as a function of distance\nin weight-space. We further investigate the importance of the true loss surface\nin neural networks and find, in contrast to previous work, that the exponential\nhardness of locating the global minimum has practical consequences for\nachieving state of the art performance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 19:49:19 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Baskerville", "Nicholas P", ""], ["Granziol", "Diego", ""], ["Keating", "Jonathan P", ""]]}, {"id": "2102.06752", "submitter": "Usman Khan", "authors": "Ran Xin and Usman A. Khan and Soummya Kar", "title": "A Hybrid Variance-Reduced Method for Decentralized Stochastic Non-Convex\n  Optimization", "comments": "Accepted in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers decentralized stochastic optimization over a network of\n$n$ nodes, where each node possesses a smooth non-convex local cost function\nand the goal of the networked nodes is to find an $\\epsilon$-accurate\nfirst-order stationary point of the sum of the local costs. We focus on an\nonline setting, where each node accesses its local cost only by means of a\nstochastic first-order oracle that returns a noisy version of the exact\ngradient. In this context, we propose a novel single-loop decentralized hybrid\nvariance-reduced stochastic gradient method, called GT-HSGD, that outperforms\nthe existing approaches in terms of both the oracle complexity and practical\nimplementation. The GT-HSGD algorithm implements specialized local hybrid\nstochastic gradient estimators that are fused over the network to track the\nglobal gradient. Remarkably, GT-HSGD achieves a network topology-independent\noracle complexity of $O(n^{-1}\\epsilon^{-3})$ when the required error tolerance\n$\\epsilon$ is small enough, leading to a linear speedup with respect to the\ncentralized optimal online variance-reduced approaches that operate on a single\nnode. Numerical experiments are provided to illustrate our main technical\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 20:13:05 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 16:03:24 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2102.06790", "submitter": "Tianlong Chen", "authors": "Tianlong Chen, Yongduo Sui, Xuxi Chen, Aston Zhang, Zhangyang Wang", "title": "A Unified Lottery Ticket Hypothesis for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With graphs rapidly growing in size and deeper graph neural networks (GNNs)\nemerging, the training and inference of GNNs become increasingly expensive.\nExisting network weight pruning algorithms cannot address the main space and\ncomputational bottleneck in GNNs, caused by the size and connectivity of the\ngraph. To this end, this paper first presents a unified GNN sparsification\n(UGS) framework that simultaneously prunes the graph adjacency matrix and the\nmodel weights, for effectively accelerating GNN inference on large-scale\ngraphs. Leveraging this new tool, we further generalize the recently popular\nlottery ticket hypothesis to GNNs for the first time, by defining a graph\nlottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network,\nwhich can be jointly identified from the original GNN and the full dense graph\nby iteratively applying UGS. Like its counterpart in convolutional neural\nnetworks, GLT can be trained in isolation to match the performance of training\nwith the full model and graph, and can be drawn from both randomly initialized\nand self-supervised pre-trained GNNs. Our proposal has been experimentally\nverified across various GNN architectures and diverse tasks, on both\nsmall-scale graph datasets (Cora, Citeseer and PubMed), and large-scale\ndatasets from the challenging Open Graph Benchmark (OGB). Specifically, for\nnode classification, our found GLTs achieve the same accuracies with 20%~98%\nMACs saving on small graphs and 25%~85% MACs saving on large ones. For link\nprediction, GLTs lead to 48%~97% and 70% MACs saving on small and large graph\ndatasets, respectively, without compromising predictive performance. Codes\navailable at https://github.com/VITA-Group/Unified-LTH-GNN.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 21:52:43 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:45:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chen", "Tianlong", ""], ["Sui", "Yongduo", ""], ["Chen", "Xuxi", ""], ["Zhang", "Aston", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2102.06806", "submitter": "Alejandro Carderera", "authors": "Alejandro Carderera, Jelena Diakonikolas, Cheuk Yin Lin, Sebastian\n  Pokutta", "title": "Parameter-free Locally Accelerated Conditional Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projection-free conditional gradient (CG) methods are the algorithms of\nchoice for constrained optimization setups in which projections are often\ncomputationally prohibitive but linear optimization over the constraint set\nremains computationally feasible. Unlike in projection-based methods, globally\naccelerated convergence rates are in general unattainable for CG. However, a\nvery recent work on Locally accelerated CG (LaCG) has demonstrated that local\nacceleration for CG is possible for many settings of interest. The main\ndownside of LaCG is that it requires knowledge of the smoothness and strong\nconvexity parameters of the objective function. We remove this limitation by\nintroducing a novel, Parameter-Free Locally accelerated CG (PF-LaCG) algorithm,\nfor which we provide rigorous convergence guarantees. Our theoretical results\nare complemented by numerical experiments, which demonstrate local acceleration\nand showcase the practical improvements of PF-LaCG over non-accelerated\nalgorithms, both in terms of iteration count and wall-clock time.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 22:50:01 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 22:09:31 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Carderera", "Alejandro", ""], ["Diakonikolas", "Jelena", ""], ["Lin", "Cheuk Yin", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "2102.06828", "submitter": "Xiaoyong Jin", "authors": "Xiaoyong Jin, Youngsuk Park, Danielle C. Maddix, Yuyang Wang, Xifeng\n  Yan", "title": "Domain Adaptation for Time Series Forecasting via Attention Sharing", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent years have witnessed deep neural networks gaining increasing\npopularity in the field of time series forecasting. A primary reason of their\nsuccess is their ability to effectively capture complex temporal dynamics\nacross multiple related time series. However, the advantages of these deep\nforecasters only start to emerge in the presence of a sufficient amount of\ndata. This poses a challenge for typical forecasting problems in practice,\nwhere one either has a small number of time series, or limited observations per\ntime series, or both. To cope with the issue of data scarcity, we propose a\nnovel domain adaptation framework, Domain Adaptation Forecaster (DAF), that\nleverages the statistical strengths from another relevant domain with abundant\ndata samples (source) to improve the performance on the domain of interest with\nlimited data (target). In particular, we propose an attention-based shared\nmodule with a domain discriminator across domains as well as private modules\nfor individual domains. This allows us to jointly train the source and target\ndomains by generating domain-invariant latent features while retraining\ndomain-specific features. Extensive experiments on various domains demonstrate\nthat our proposed method outperforms state-of-the-art baselines on synthetic\nand real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 00:26:35 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 19:26:00 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 16:55:42 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jin", "Xiaoyong", ""], ["Park", "Youngsuk", ""], ["Maddix", "Danielle C.", ""], ["Wang", "Yuyang", ""], ["Yan", "Xifeng", ""]]}, {"id": "2102.06849", "submitter": "Harikrishna Narasimhan", "authors": "Andrew Cotter, Aditya Krishna Menon, Harikrishna Narasimhan, Ankit\n  Singh Rawat, Sashank J. Reddi, Yichen Zhou", "title": "Distilling Double Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distillation is the technique of training a \"student\" model based on examples\nthat are labeled by a separate \"teacher\" model, which itself is trained on a\nlabeled dataset. The most common explanations for why distillation \"works\" are\npredicated on the assumption that student is provided with \\emph{soft} labels,\n\\eg probabilities or confidences, from the teacher model. In this work, we\nshow, that, even when the teacher model is highly overparameterized, and\nprovides \\emph{hard} labels, using a very large held-out unlabeled dataset to\ntrain the student model can result in a model that outperforms more\n\"traditional\" approaches.\n  Our explanation for this phenomenon is based on recent work on \"double\ndescent\". It has been observed that, once a model's complexity roughly exceeds\nthe amount required to memorize the training data, increasing the complexity\n\\emph{further} can, counterintuitively, result in \\emph{better} generalization.\nResearchers have identified several settings in which it takes place, while\nothers have made various attempts to explain it (thus far, with only partial\nsuccess). In contrast, we avoid these questions, and instead seek to\n\\emph{exploit} this phenomenon by demonstrating that a highly-overparameterized\nteacher can avoid overfitting via double descent, while a student trained on a\nlarger independent dataset labeled by this teacher will avoid overfitting due\nto the size of its training set.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 02:26:48 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cotter", "Andrew", ""], ["Menon", "Aditya Krishna", ""], ["Narasimhan", "Harikrishna", ""], ["Rawat", "Ankit Singh", ""], ["Reddi", "Sashank J.", ""], ["Zhou", "Yichen", ""]]}, {"id": "2102.06857", "submitter": "Khang Le", "authors": "Khang Le, Huy Nguyen, Quang Nguyen, Nhat Ho, Tung Pham, Hung Bui", "title": "On Robust Optimal Transport: Computational Complexity, Low-rank\n  Approximation, and Barycenter Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider two robust versions of optimal transport, named $\\textit{Robust\nSemi-constrained Optimal Transport}$ (RSOT) and $\\textit{Robust Unconstrained\nOptimal Transport}$ (ROT), formulated by relaxing the marginal constraints with\nKullback-Leibler divergence. For both problems in the discrete settings, we\npropose Sinkhorn-based algorithms that produce $\\varepsilon$-approximations of\nRSOT and ROT in $\\widetilde{\\mathcal{O}}(\\frac{n^2}{\\varepsilon})$ time, where\n$n$ is the number of supports of the probability distributions. Furthermore, to\nreduce the dependency of the complexity of the Sinkhorn-based algorithms on\n$n$, we apply Nystr\\\"{o}m method to approximate the kernel matrix in both RSOT\nand ROT by a matrix of rank $r$ before passing it to these Sinkhorn-based\nalgorithms. We demonstrate that these new algorithms have\n$\\widetilde{\\mathcal{O}}(n r^2 + \\frac{nr}{\\varepsilon})$ runtime to obtain the\nRSOT and ROT $\\varepsilon$-approximations. Finally, we consider a barycenter\nproblem based on RSOT, named $\\textit{Robust Semi-Constrained Barycenter}$\nproblem (RSBP), and develop a robust iterative Bregman projection algorithm,\ncalled $\\textbf{Normalized-RobustIBP}$ algorithm, to solve the RSBP in the\ndiscrete settings of probability distributions. We show that an\n$\\varepsilon$-approximated solution of the RSBP can be achieved in\n$\\widetilde{\\mathcal{O}}(\\frac{mn^2}{\\varepsilon})$ time using\n$\\textbf{Normalized-RobustIBP}$ algorithm when $m = 2$, which is better than\nthe previous complexity $\\widetilde{\\mathcal{O}}(\\frac{mn^2}{\\varepsilon^2})$\nof IBP algorithm for approximating the Wasserstein barycenter. Extensive\nexperiments confirm our theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 03:55:52 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Le", "Khang", ""], ["Nguyen", "Huy", ""], ["Nguyen", "Quang", ""], ["Ho", "Nhat", ""], ["Pham", "Tung", ""], ["Bui", "Hung", ""]]}, {"id": "2102.06866", "submitter": "Kento Nozawa", "authors": "Kento Nozawa, Issei Sato", "title": "Understanding Negative Samples in Instance Discriminative\n  Self-supervised Representation Learning", "comments": "24 pages, 5 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance discriminative self-supervised representation learning has been\nattracted attention thanks to its unsupervised nature and informative feature\nrepresentation for downstream tasks. In practice, it commonly uses a larger\nnumber of negative samples than the number of supervised classes. However,\nthere is an inconsistency in the existing analysis; theoretically, a large\nnumber of negative samples degrade classification performance on a downstream\nsupervised task, while empirically, they improve the performance. We provide a\nnovel framework to analyze this empirical result regarding negative samples\nusing the coupon collector's problem. Our bound can implicitly incorporate the\nsupervised loss of the downstream task in the self-supervised loss by\nincreasing the number of negative samples. We confirm that our proposed\nanalysis holds on real-world benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 05:46:33 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 15:39:00 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nozawa", "Kento", ""], ["Sato", "Issei", ""]]}, {"id": "2102.06879", "submitter": "Yitian Xu", "authors": "Yuzhou Cao, Lei Feng, Yitian Xu, Bo An, Gang Niu, Masashi Sugiyama", "title": "Learning from Similarity-Confidence Data", "comments": "33 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised learning has drawn considerable attention recently to\nreduce the expensive time and labor consumption of labeling massive data. In\nthis paper, we investigate a novel weakly supervised learning problem of\nlearning from similarity-confidence (Sconf) data, where we aim to learn an\neffective binary classifier from only unlabeled data pairs equipped with\nconfidence that illustrates their degree of similarity (two examples are\nsimilar if they belong to the same class). To solve this problem, we propose an\nunbiased estimator of the classification risk that can be calculated from only\nSconf data and show that the estimation error bound achieves the optimal\nconvergence rate. To alleviate potential overfitting when flexible models are\nused, we further employ a risk correction scheme on the proposed risk\nestimator. Experimental results demonstrate the effectiveness of the proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 07:31:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cao", "Yuzhou", ""], ["Feng", "Lei", ""], ["Xu", "Yitian", ""], ["An", "Bo", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2102.06924", "submitter": "Lior Shani", "authors": "Lior Shani, Tom Zahavy and Shie Mannor", "title": "Online Apprenticeship Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Apprenticeship Learning (AL), we are given a Markov Decision Process (MDP)\nwithout access to the cost function. Instead, we observe trajectories sampled\nby an expert that acts according to some policy. The goal is to find a policy\nthat matches the expert's performance on some predefined set of cost functions.\nWe introduce an online variant of AL (Online Apprenticeship Learning; OAL),\nwhere the agent is expected to perform comparably to the expert while\ninteracting with the environment. We show that the OAL problem can be\neffectively solved by combining two mirror descent based no-regret algorithms:\none for policy optimization and another for learning the worst case cost. To\nthis end, we derive a convergent algorithm with $O(\\sqrt{K})$ regret, where $K$\nis the number of interactions with the MDP, and an additional linear error term\nthat depends on the amount of expert trajectories available. Importantly, our\nalgorithm avoids the need to solve an MDP at each iteration, making it more\npractical compared to prior AL methods. Finally, we implement a deep variant of\nour algorithm which shares some similarities to GAIL \\cite{ho2016generative},\nbut where the discriminator is replaced with the costs learned by the OAL\nproblem. Our simulations demonstrate our theoretically grounded approach\noutperforms the baselines.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 12:57:51 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Shani", "Lior", ""], ["Zahavy", "Tom", ""], ["Mannor", "Shie", ""]]}, {"id": "2102.06933", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Wei Jiang, Shiyin Lu, Tianbao Yang", "title": "Revisiting Smoothed Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the problem of smoothed online learning, in which\nthe online learner suffers both a hitting cost and a switching cost, and target\ntwo performance metrics: competitive ratio and dynamic regret with switching\ncost.\n  To bound the competitive ratio, we assume the hitting cost is known to the\nlearner in each round, and investigate the simple idea of balancing the two\ncosts by an optimization problem. Surprisingly, we find that minimizing the\nhitting cost alone is $\\max(1, \\frac{2}{\\alpha})$-competitive for\n$\\alpha$-polyhedral functions and $1 + \\frac{4}{\\lambda}$-competitive for\n$\\lambda$-quadratic growth functions, both of which improve state-of-the-art\nresults significantly. Moreover, when the hitting cost is both convex and\n$\\lambda$-quadratic growth, we reduce the competitive ratio to $1 +\n\\frac{2}{\\sqrt{\\lambda}}$ by minimizing the weighted sum of the hitting cost\nand the switching cost.\n  To bound the dynamic regret with switching cost, we follow the standard\nsetting of online convex optimization, in which the hitting cost is convex but\nhidden from the learner before making predictions. We modify Ader, an existing\nalgorithm designed for dynamic regret, slightly to take into account the\nswitching cost when measuring the performance. The proposed algorithm, named as\nSmoothed Ader, attains an optimal $O(\\sqrt{T(1+P_T)})$ bound for dynamic regret\nwith switching cost, where $P_T$ is the path-length of the comparator sequence.\nFurthermore, if the hitting cost is accessible in the beginning of each round,\nwe obtain a similar guarantee without the bounded gradient condition, and\nestablish an $\\Omega(\\sqrt{T(1+P_T)})$ lower bound to confirm the optimality.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 14:15:55 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 05:59:58 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 09:03:07 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zhang", "Lijun", ""], ["Jiang", "Wei", ""], ["Lu", "Shiyin", ""], ["Yang", "Tianbao", ""]]}, {"id": "2102.06966", "submitter": "Aseem Baranwal", "authors": "Aseem Baranwal, Kimon Fountoulakis, Aukosh Jagannath", "title": "Graph Convolution for Semi-Supervised Classification: Improved Linear\n  Separability and Out-of-Distribution Generalization", "comments": "30 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been increased interest in semi-supervised classification\nin the presence of graphical information. A new class of learning models has\nemerged that relies, at its most basic level, on classifying the data after\nfirst applying a graph convolution. To understand the merits of this approach,\nwe study the classification of a mixture of Gaussians, where the data\ncorresponds to the node attributes of a stochastic block model. We show that\ngraph convolution extends the regime in which the data is linearly separable by\na factor of roughly $1/\\sqrt{D}$, where $D$ is the expected degree of a node,\nas compared to the mixture model data on its own. Furthermore, we find that the\nlinear classifier obtained by minimizing the cross-entropy loss after the graph\nconvolution generalizes to out-of-distribution data where the unseen data can\nhave different intra- and inter-class edge probabilities from the training\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 17:46:57 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 20:17:15 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 09:32:50 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Baranwal", "Aseem", ""], ["Fountoulakis", "Kimon", ""], ["Jagannath", "Aukosh", ""]]}, {"id": "2102.06984", "submitter": "Hanbaek Lyu", "authors": "Hanbaek Lyu, Yacoub H. Kureh, Joshua Vendrow, Mason A. Porter", "title": "Learning low-rank latent mesoscale structures in networks", "comments": "55 pages, 14 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG math.OC physics.soc-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is common to use networks to encode the architecture of interactions\nbetween entities in complex systems in the physical, biological, social, and\ninformation sciences. Moreover, to study the large-scale behavior of complex\nsystems, it is important to study mesoscale structures in networks as building\nblocks that influence such behavior. In this paper, we present a new approach\nfor describing low-rank mesoscale structure in networks, and we illustrate our\napproach using several synthetic network models and empirical friendship,\ncollaboration, and protein--protein interaction (PPI) networks. We find that\nthese networks possess a relatively small number of `latent motifs' that\ntogether can successfully approximate most subnetworks at a fixed mesoscale. We\nuse an algorithm that we call \"network dictionary learning\" (NDL), which\ncombines a network sampling method and nonnegative matrix factorization, to\nlearn the latent motifs of a given network. The ability to encode a network\nusing a set of latent motifs has a wide range of applications to\nnetwork-analysis tasks, such as comparison, denoising, and edge inference.\nAdditionally, using our new network denoising and reconstruction (NDR)\nalgorithm, we demonstrate how to denoise a corrupted network by using only the\nlatent motifs that one learns directly from the corrupted networks.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 18:54:49 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 16:45:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lyu", "Hanbaek", ""], ["Kureh", "Yacoub H.", ""], ["Vendrow", "Joshua", ""], ["Porter", "Mason A.", ""]]}, {"id": "2102.06988", "submitter": "Xiaowu Dai", "authors": "Xiaowu Dai and Michael I. Jordan", "title": "Multi-Stage Decentralized Matching Markets: Uncertain Preferences and\n  Strategic Behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching markets are often organized in a multi-stage and decentralized\nmanner. Moreover, participants in real-world matching markets often have\nuncertain preferences. This article develops a framework for learning optimal\nstrategies in such settings, based on a nonparametric statistical approach and\nvariational analysis. We propose an efficient algorithm, built upon concepts of\n\"lower uncertainty bound\" and \"calibrated decentralized matching,\" for\nmaximizing the participants' expected payoff. We show that there exists a\nwelfare-versus-fairness trade-off that is characterized by the uncertainty\nlevel of acceptance. Participants will strategically act in favor of a low\nuncertainty level to reduce competition and increase expected payoff. We study\nsignaling mechanisms that help to clear the congestion in such decentralized\nmarkets and find that the effects of signaling are heterogeneous, showing a\ndependence on the participants and matching stages. We prove that participants\ncan be better off with multi-stage matching compared to single-stage matching.\nThe deferred acceptance procedure assumes no limit on the number of stages and\nattains efficiency and fairness but may make some participants worse off than\nmulti-stage matching. We demonstrate aspects of the theoretical predictions\nthrough simulations and an experiment using real data from college admissions.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 19:25:52 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dai", "Xiaowu", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2102.07002", "submitter": "Xiaoyu Li", "authors": "Xiaoyu Li and Mingrui Liu and Francesco Orabona", "title": "On the Last Iterate Convergence of Momentum Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SGD with Momentum (SGDM) is widely used for large scale optimization of\nmachine learning problems. Yet, the theoretical understanding of this algorithm\nis not complete. In fact, even the most recent results require changes to the\nalgorithm like an averaging scheme and a projection onto a bounded domain,\nwhich are never used in practice. Also, no lower bound is known for SGDM. In\nthis paper, we prove for the first time that for any constant momentum factor,\nthere exists a Lipschitz and convex function for which the last iterate of SGDM\nsuffers from an error $\\Omega(\\frac{\\log T}{\\sqrt{T}})$ after $T$ steps. Based\non this fact, we study a new class of (both adaptive and non-adaptive)\nFollow-The-Regularized-Leader-based SGDM algorithms with \\emph{increasing\nmomentum} and \\emph{shrinking updates}. For these algorithms, we show that the\nlast iterate has optimal convergence $O (\\frac{1}{\\sqrt{T}})$ for unconstrained\nconvex optimization problems. Further, we show that in the interpolation\nsetting with convex and smooth functions, our new SGDM algorithm automatically\nconverges at a rate of $O(\\frac{\\log T}{T})$. Empirical results are shown as\nwell.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 21:16:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Li", "Xiaoyu", ""], ["Liu", "Mingrui", ""], ["Orabona", "Francesco", ""]]}, {"id": "2102.07005", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Rahul G. Krishnan, David Sontag", "title": "Clustering Left-Censored Multivariate Time-Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised learning seeks to uncover patterns in data. However, different\nkinds of noise may impede the discovery of useful substructure from real-world\ntime-series data. In this work, we focus on mitigating the interference of\nleft-censorship in the task of clustering. We provide conditions under which\nclusters and left-censorship may be identified; motivated by this result, we\ndevelop a deep generative, continuous-time model of time-series data that\nclusters while correcting for censorship time. We demonstrate accurate, stable,\nand interpretable results on synthetic data that outperform several benchmarks.\nTo showcase the utility of our framework on real-world problems, we study how\nleft-censorship can adversely affect the task of disease phenotyping, resulting\nin the often incorrect assumption that longitudinal patient data are aligned by\ndisease stage. In reality, patients at the time of diagnosis are at different\nstages of the disease -- both late and early due to differences in when\npatients seek medical care and such discrepancy can confound unsupervised\nlearning algorithms. On two clinical datasets, our model corrects for this form\nof censorship and recovers known clinical subtypes.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 21:22:40 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 01:27:19 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Chen", "Irene Y.", ""], ["Krishnan", "Rahul G.", ""], ["Sontag", "David", ""]]}, {"id": "2102.07006", "submitter": "Alexander Camuto", "authors": "Alexander Camuto, Xiaoyu Wang, Lingjiong Zhu, Chris Holmes, Mert\n  G\\\"urb\\\"uzbalaban, Umut \\c{S}im\\c{s}ekli", "title": "Asymmetric Heavy Tails and Implicit Bias in Gaussian Noise Injections", "comments": "Main paper of 12 pages, followed by appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian noise injections (GNIs) are a family of simple and widely-used\nregularisation methods for training neural networks, where one injects additive\nor multiplicative Gaussian noise to the network activations at every iteration\nof the optimisation algorithm, which is typically chosen as stochastic gradient\ndescent (SGD). In this paper we focus on the so-called `implicit effect' of\nGNIs, which is the effect of the injected noise on the dynamics of SGD. We show\nthat this effect induces an asymmetric heavy-tailed noise on SGD gradient\nupdates. In order to model this modified dynamics, we first develop a\nLangevin-like stochastic differential equation that is driven by a general\nfamily of asymmetric heavy-tailed noise. Using this model we then formally\nprove that GNIs induce an `implicit bias', which varies depending on the\nheaviness of the tails and the level of asymmetry. Our empirical results\nconfirm that different types of neural networks trained with GNIs are\nwell-modelled by the proposed dynamics and that the implicit effect of these\ninjections induces a bias that degrades the performance of networks.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 21:28:09 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 20:27:38 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Camuto", "Alexander", ""], ["Wang", "Xiaoyu", ""], ["Zhu", "Lingjiong", ""], ["Holmes", "Chris", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""], ["\u015eim\u015fekli", "Umut", ""]]}, {"id": "2102.07030", "submitter": "Victor Araman", "authors": "Victor F. Araman, Rene Caldentey", "title": "Diffusion Approximations for a Class of Sequential Testing Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decision maker who must choose an action in order to maximize a\nreward function that depends also on an unknown parameter {\\Theta}. The\ndecision maker can delay taking the action in order to experiment and gather\nadditional information on {\\Theta}. We model the decision maker's problem using\na Bayesian sequential experimentation framework and use dynamic programming and\ndiffusion-asymptotic analysis to solve it. For that, we scale our problem in a\nway that both the average number of experiments that is conducted per unit of\ntime is large and the informativeness of each individual experiment is low.\nUnder such regime, we derive a diffusion approximation for the sequential\nexperimentation problem, which provides a number of important insights about\nthe nature of the problem and its solution. Our solution method also shows that\nthe complexity of the problem grows only quadratically with the cardinality of\nthe set of actions from which the decision maker can choose. We illustrate our\nmethodology and results using a concrete application in the context of\nassortment selection and new product introduction. Specifically, we study the\nproblem of a seller who wants to select an optimal assortment of products to\nlaunch into the marketplace and is uncertain about consumers' preferences.\nMotivated by emerging practices in e-commerce, we assume that the seller is\nable to use a crowdvoting system to learn these preferences before a final\nassortment decision is made. In this context, we undertake an extensive\nnumerical analysis to assess the value of learning and demonstrate the\neffectiveness and robustness of the heuristics derived from the diffusion\napproximation.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 23:21:29 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 11:04:59 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 09:40:51 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Araman", "Victor F.", ""], ["Caldentey", "Rene", ""]]}, {"id": "2102.07035", "submitter": "Aditya Modi", "authors": "Aditya Modi, Jinglin Chen, Akshay Krishnamurthy, Nan Jiang, Alekh\n  Agarwal", "title": "Model-free Representation Learning and Exploration in Low-rank MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low rank MDP has emerged as an important model for studying\nrepresentation learning and exploration in reinforcement learning. With a known\nrepresentation, several model-free exploration strategies exist. In contrast,\nall algorithms for the unknown representation setting are model-based, thereby\nrequiring the ability to model the full dynamics. In this work, we present the\nfirst model-free representation learning algorithms for low rank MDPs. The key\nalgorithmic contribution is a new minimax representation learning objective,\nfor which we provide variants with differing tradeoffs in their statistical and\ncomputational properties. We interleave this representation learning step with\nan exploration strategy to cover the state space in a reward-free manner. The\nresulting algorithms are provably sample efficient and can accommodate general\nfunction approximation to scale to complex environments.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 00:06:54 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Modi", "Aditya", ""], ["Chen", "Jinglin", ""], ["Krishnamurthy", "Akshay", ""], ["Jiang", "Nan", ""], ["Agarwal", "Alekh", ""]]}, {"id": "2102.07048", "submitter": "Yao-Yuan Yang", "authors": "Michal Moshkovitz and Yao-Yuan Yang and Kamalika Chaudhuri", "title": "Connecting Interpretability and Robustness in Decision Trees through\n  Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has recognized interpretability and robustness as essential\nproperties of trustworthy classification. Curiously, a connection between\nrobustness and interpretability was empirically observed, but the theoretical\nreasoning behind it remained elusive. In this paper, we rigorously investigate\nthis connection. Specifically, we focus on interpretation using decision trees\nand robustness to $l_{\\infty}$-perturbation. Previous works defined the notion\nof $r$-separation as a sufficient condition for robustness. We prove upper and\nlower bounds on the tree size in case the data is $r$-separated. We then show\nthat a tighter bound on the size is possible when the data is linearly\nseparated. We provide the first algorithm with provable guarantees both on\nrobustness, interpretability, and accuracy in the context of decision trees.\nExperiments confirm that our algorithm yields classifiers that are both\ninterpretable and robust and have high accuracy. The code for the experiments\nis available at https://github.com/yangarbiter/interpretable-robust-trees .\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 02:08:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Moshkovitz", "Michal", ""], ["Yang", "Yao-Yuan", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2102.07060", "submitter": "Anand Deo", "authors": "Anand Deo, Karthyek Murthy", "title": "Achieving Efficiency in Black Box Simulation of Distribution Tails with\n  Self-structuring Importance Samplers", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the increasing adoption of models which facilitate greater\nautomation in risk management and decision-making, this paper presents a novel\nImportance Sampling (IS) scheme for measuring distribution tails of objectives\nmodelled with enabling tools such as feature-based decision rules, mixed\ninteger linear programs, deep neural networks, etc. Conventional efficient IS\napproaches suffer from feasibility and scalability concerns due to the need to\nintricately tailor the sampler to the underlying probability distribution and\nthe objective. This challenge is overcome in the proposed black-box scheme by\nautomating the selection of an effective IS distribution with a transformation\nthat implicitly learns and replicates the concentration properties observed in\nless rare samples. This novel approach is guided by a large deviations\nprinciple that brings out the phenomenon of self-similarity of optimal IS\ndistributions. The proposed sampler is the first to attain asymptotically\noptimal variance reduction across a spectrum of multivariate distributions\ndespite being oblivious to the underlying structure. The large deviations\nprinciple additionally results in new distribution tail asymptotics capable of\nyielding operational insights. The applicability is illustrated by considering\nproduct distribution networks and portfolio credit risk models informed by\nneural networks as examples.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 03:37:22 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 03:41:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Deo", "Anand", ""], ["Murthy", "Karthyek", ""]]}, {"id": "2102.07106", "submitter": "Samuel Cohen", "authors": "Samuel Cohen, Rendani Mbuvha, Tshilidzi Marwala, Marc Peter Deisenroth", "title": "Healing Products of Gaussian Processes", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are nonparametric Bayesian models that have been\napplied to regression and classification problems. One of the approaches to\nalleviate their cubic training cost is the use of local GP experts trained on\nsubsets of the data. In particular, product-of-expert models combine the\npredictive distributions of local experts through a tractable product\noperation. While these expert models allow for massively distributed\ncomputation, their predictions typically suffer from erratic behaviour of the\nmean or uncalibrated uncertainty quantification. By calibrating predictions via\na tempered softmax weighting, we provide a solution to these problems for\nmultiple product-of-expert models, including the generalised product of experts\nand the robust Bayesian committee machine. Furthermore, we leverage the optimal\ntransport literature and propose a new product-of-expert model that combines\npredictions of local experts by computing their Wasserstein barycenter, which\ncan be applied to both regression and classification.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 08:53:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cohen", "Samuel", ""], ["Mbuvha", "Rendani", ""], ["Marwala", "Tshilidzi", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2102.07115", "submitter": "Samuel Cohen", "authors": "Samuel Cohen, K S Sesh Kumar, Marc Peter Deisenroth", "title": "Sliced Multi-Marginal Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study multi-marginal optimal transport, a generalization of optimal\ntransport that allows us to define discrepancies between multiple measures. It\nprovides a framework to solve multi-task learning problems and to perform\nbarycentric averaging. However, multi-marginal distances between multiple\nmeasures are typically challenging to compute because they require estimating a\ntransport plan with $N^P$ variables. In this paper, we address this issue in\nthe following way: 1) we efficiently solve the one-dimensional multi-marginal\nMonge-Wasserstein problem for a classical cost function in closed form, and 2)\nwe propose a higher-dimensional multi-marginal discrepancy via slicing and\nstudy its generalized metric properties. We show that computing the sliced\nmulti-marginal discrepancy is massively scalable for a large number of\nprobability measures with support as large as $10^7$ samples. Our approach can\nbe applied to solving problems such as barycentric averaging, multi-task\ndensity estimation and multi-task reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 09:58:47 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cohen", "Samuel", ""], ["Kumar", "K S Sesh", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2102.07140", "submitter": "Muhammad Zaid Hameed", "authors": "Muhammad Zaid Hameed, Andras Gyorgy", "title": "Perceptually Constrained Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by previous observations that the usually applied $L_p$ norms\n($p=1,2,\\infty$) do not capture the perceptual quality of adversarial examples\nin image classification, we propose to replace these norms with the structural\nsimilarity index (SSIM) measure, which was developed originally to measure the\nperceptual similarity of images. Through extensive experiments with\nadversarially trained classifiers for MNIST and CIFAR-10, we demonstrate that\nour SSIM-constrained adversarial attacks can break state-of-the-art\nadversarially trained classifiers and achieve similar or larger success rate\nthan the elastic net attack, while consistently providing adversarial images of\nbetter perceptual quality. Utilizing SSIM to automatically identify and\ndisallow adversarial images of low quality, we evaluate the performance of\nseveral defense schemes in a perceptually much more meaningful way than was\ndone previously in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 12:28:51 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hameed", "Muhammad Zaid", ""], ["Gyorgy", "Andras", ""]]}, {"id": "2102.07143", "submitter": "James Brofos", "authors": "James A. Brofos, Marcus A. Brubaker, Roy R. Lederman", "title": "Manifold Density Estimation via Generalized Dequantization", "comments": "Additional experiments and theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation is an important technique for characterizing distributions\ngiven observations. Much existing research on density estimation has focused on\ncases wherein the data lies in a Euclidean space. However, some kinds of data\nare not well-modeled by supposing that their underlying geometry is Euclidean.\nInstead, it can be useful to model such data as lying on a {\\it manifold} with\nsome known structure. For instance, some kinds of data may be known to lie on\nthe surface of a sphere. We study the problem of estimating densities on\nmanifolds. We propose a method, inspired by the literature on \"dequantization,\"\nwhich we interpret through the lens of a coordinate transformation of an\nambient Euclidean space and a smooth manifold of interest. Using methods from\nnormalizing flows, we apply this method to the dequantization of smooth\nmanifold structures in order to model densities on the sphere, tori, and the\northogonal group.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 12:40:41 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 10:33:59 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Brofos", "James A.", ""], ["Brubaker", "Marcus A.", ""], ["Lederman", "Roy R.", ""]]}, {"id": "2102.07181", "submitter": "Koby Bibas", "authors": "Koby Bibas and Meir Feder", "title": "Distribution Free Uncertainty for the Minimum Norm Solution of\n  Over-parameterized Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fundamental principle of learning theory is that there is a trade-off\nbetween the complexity of a prediction rule and its ability to generalize.\nModern machine learning models do not obey this paradigm: They produce an\naccurate prediction even with a perfect fit to the training set. We investigate\nover-parameterized linear regression models focusing on the minimum norm\nsolution: This is the solution with the minimal norm that attains a perfect fit\nto the training set. We utilize the recently proposed predictive normalized\nmaximum likelihood (pNML) learner which is the min-max regret solution for the\ndistribution-free setting. We derive an upper bound of this min-max regret\nwhich is associated with the prediction uncertainty. We show that if the test\nsample lies mostly in a subspace spanned by the eigenvectors associated with\nthe large eigenvalues of the empirical correlation matrix of the training data,\nthe model generalizes despite its over-parameterized nature. We demonstrate the\nuse of the pNML regret as a point-wise learnability measure on synthetic data\nand successfully observe the double-decent phenomenon of the over-parameterized\nmodels on UCI datasets.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 15:49:04 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 11:33:01 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bibas", "Koby", ""], ["Feder", "Meir", ""]]}, {"id": "2102.07188", "submitter": "Xingchen Wan", "authors": "Xingchen Wan, Vu Nguyen, Huong Ha, Binxin Ru, Cong Lu, Michael A.\n  Osborne", "title": "Think Global and Act Local: Bayesian Optimisation over High-Dimensional\n  Categorical and Mixed Search Spaces", "comments": "ICML 2021. 9 page, 6 figures (26 pages, 16 figures, 2 tables\n  including references and appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional black-box optimisation remains an important yet notoriously\nchallenging problem. Despite the success of Bayesian optimisation methods on\ncontinuous domains, domains that are categorical, or that mix continuous and\ncategorical variables, remain challenging. We propose a novel solution -- we\ncombine local optimisation with a tailored kernel design, effectively handling\nhigh-dimensional categorical and mixed search spaces, whilst retaining sample\nefficiency. We further derive convergence guarantee for the proposed approach.\nFinally, we demonstrate empirically that our method outperforms the current\nbaselines on a variety of synthetic and real-world tasks in terms of\nperformance, computational costs, or both.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 16:18:36 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 04:10:59 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Wan", "Xingchen", ""], ["Nguyen", "Vu", ""], ["Ha", "Huong", ""], ["Ru", "Binxin", ""], ["Lu", "Cong", ""], ["Osborne", "Michael A.", ""]]}, {"id": "2102.07206", "submitter": "Yue Sun", "authors": "Halil Ibrahim Gulluk, Yue Sun, Samet Oymak, Maryam Fazel", "title": "Sample Efficient Subspace-based Representations for Nonlinear\n  Meta-Learning", "comments": "To appear in ICASSP 21'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constructing good representations is critical for learning complex tasks in a\nsample efficient manner. In the context of meta-learning, representations can\nbe constructed from common patterns of previously seen tasks so that a future\ntask can be learned quickly. While recent works show the benefit of\nsubspace-based representations, such results are limited to linear-regression\ntasks. This work explores a more general class of nonlinear tasks with\napplications ranging from binary classification, generalized linear models and\nneural nets. We prove that subspace-based representations can be learned in a\nsample-efficient manner and provably benefit future tasks in terms of sample\ncomplexity. Numerical results verify the theoretical predictions in\nclassification and neural-network regression tasks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 17:40:04 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 19:06:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Gulluk", "Halil Ibrahim", ""], ["Sun", "Yue", ""], ["Oymak", "Samet", ""], ["Fazel", "Maryam", ""]]}, {"id": "2102.07211", "submitter": "Yiliang Zhang", "authors": "Yiliang Zhang, Zhiqi Bu", "title": "Efficient Designs of SLOPE Penalty Sequences in Finite Dimension", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear regression, SLOPE is a new convex analysis method that generalizes\nthe Lasso via the sorted L1 penalty: larger fitted coefficients are penalized\nmore heavily. This magnitude-dependent regularization requires an input of\npenalty sequence $\\lambda$, instead of a scalar penalty as in the Lasso case,\nthus making the design extremely expensive in computation. In this paper, we\npropose two efficient algorithms to design the possibly high-dimensional SLOPE\npenalty, in order to minimize the mean squared error. For Gaussian data\nmatrices, we propose a first order Projected Gradient Descent (PGD) under the\nApproximate Message Passing regime. For general data matrices, we present a\nzero-th order Coordinate Descent (CD) to design a sub-class of SLOPE, referred\nto as the k-level SLOPE. Our CD allows a useful trade-off between the accuracy\nand the computation speed. We demonstrate the performance of SLOPE with our\ndesigns via extensive experiments on synthetic data and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 18:06:56 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 02:59:27 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Zhang", "Yiliang", ""], ["Bu", "Zhiqi", ""]]}, {"id": "2102.07238", "submitter": "Ouns El Harzli", "authors": "Ouns El Harzli, Guillermo Valle-P\\'erez and Ard A. Louis", "title": "Double-descent curves in neural networks: a new perspective using\n  Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Double-descent curves in neural networks describe the phenomenon that the\ngeneralisation error initially descends with increasing parameters, then grows\nafter reaching an optimal number of parameters which is less than the number of\ndata points, but then descends again in the overparameterised regime. Here we\nuse a neural network Gaussian process (NNGP) which maps exactly to a fully\nconnected network (FCN) in the infinite width limit, combined with techniques\nfrom random matrix theory, to calculate this generalisation behaviour, with a\nparticular focus on the overparameterised regime. An advantage of our NNGP\napproach is that the analytical calculations are easier to interpret. We argue\nthat neural network generalization performance improves in the\noverparameterised regime precisely because that is where they converge to their\nequivalent Gaussian process.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 20:31:49 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 11:37:05 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 21:27:01 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Harzli", "Ouns El", ""], ["Valle-P\u00e9rez", "Guillermo", ""], ["Louis", "Ard A.", ""]]}, {"id": "2102.07254", "submitter": "Richard Combes", "authors": "Thibaut Cuvelier and Richard Combes and Eric Gourdin", "title": "Asymptotically Optimal Strategies For Combinatorial Semi-Bandits in\n  Polynomial Time", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider combinatorial semi-bandits with uncorrelated Gaussian rewards. In\nthis article, we propose the first method, to the best of our knowledge, that\nenables to compute the solution of the Graves-Lai optimization problem in\npolynomial time for many combinatorial structures of interest. In turn, this\nimmediately yields the first known approach to implement asymptotically optimal\nalgorithms in polynomial time for combinatorial semi-bandits.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 22:14:28 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cuvelier", "Thibaut", ""], ["Combes", "Richard", ""], ["Gourdin", "Eric", ""]]}, {"id": "2102.07266", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh, Liang Zheng", "title": "Sparse Attention Guided Dynamic Value Estimation for Single-Task\n  Multi-Scene Reinforcement Learning", "comments": "This work is a merger of arXiv:2005.12254 and arXiv:2011.12574", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training deep reinforcement learning agents on environments with multiple\nlevels / scenes from the same task, has become essential for many applications\naiming to achieve generalization and domain transfer from simulation to the\nreal world. While such a strategy is helpful with generalization, the use of\nmultiple scenes significantly increases the variance of samples collected for\npolicy gradient computations. Current methods, effectively continue to view\nthis collection of scenes as a single Markov decision process (MDP), and thus\nlearn a scene-generic value function V(s). However, we argue that the sample\nvariance for a multi-scene environment is best minimized by treating each scene\nas a distinct MDP, and then learning a joint value function V(s,M) dependent on\nboth state s and MDP M. We further demonstrate that the true joint value\nfunction for a multi-scene environment, follows a multi-modal distribution\nwhich is not captured by traditional CNN / LSTM based critic networks. To this\nend, we propose a dynamic value estimation (DVE) technique, which approximates\nthe true joint value function through a sparse attention mechanism over\nmultiple value function hypothesis / modes. The resulting agent not only shows\nsignificant improvements in the final reward score across a range of OpenAI\nProcGen environments, but also exhibits enhanced navigation efficiency and\nprovides an implicit mechanism for unsupervised state-space skill\ndecomposition.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 23:30:13 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2102.07301", "submitter": "Quanquan Gu", "authors": "Yue Wu and Dongruo Zhou and Quanquan Gu", "title": "Nearly Minimax Optimal Regret for Learning Infinite-horizon\n  Average-reward MDPs with Linear Function Approximation", "comments": "40 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning in an infinite-horizon average-reward setting\nwith linear function approximation, where the transition probability function\nof the underlying Markov Decision Process (MDP) admits a linear form over a\nfeature mapping of the current state, action, and next state. We propose a new\nalgorithm UCRL2-VTR, which can be seen as an extension of the UCRL2 algorithm\nwith linear function approximation. We show that UCRL2-VTR with Bernstein-type\nbonus can achieve a regret of $\\tilde{O}(d\\sqrt{DT})$, where $d$ is the\ndimension of the feature mapping, $T$ is the horizon, and $\\sqrt{D}$ is the\ndiameter of the MDP. We also prove a matching lower bound\n$\\tilde{\\Omega}(d\\sqrt{DT})$, which suggests that the proposed UCRL2-VTR is\nminimax optimal up to logarithmic factors. To the best of our knowledge, our\nalgorithm is the first nearly minimax optimal RL algorithm with function\napproximation in the infinite-horizon average-reward setting.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 02:08:39 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wu", "Yue", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "2102.07336", "submitter": "Asuka Takatsu", "authors": "Asuka Takatsu", "title": "Relaxation of optimal transport problem via strictly convex functions", "comments": "20pages. Comments are welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optimal transport problem on finite spaces is a linear program. Recently,\na relaxation of the optimal transport problem via strictly convex functions,\nespecially via the Kullback--Leibler divergence, sheds new light on data\nsciences. This paper provides the mathematical foundations and an iterative\nprocess based on a gradient descent for the relaxed optimal transport problem\nvia Bregman divergences.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 04:32:13 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 07:17:01 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Takatsu", "Asuka", ""]]}, {"id": "2102.07346", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi", "title": "On the Theory of Implicit Deep Learning: Global Convergence with\n  Implicit Layers", "comments": "ICLR 2021. Selected for ICLR Spotlight (top 6% submissions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep equilibrium model uses implicit layers, which are implicitly defined\nthrough an equilibrium point of an infinite sequence of computation. It avoids\nany explicit computation of the infinite sequence by finding an equilibrium\npoint directly via root-finding and by computing gradients via implicit\ndifferentiation. In this paper, we analyze the gradient dynamics of deep\nequilibrium models with nonlinearity only on weight matrices and non-convex\nobjective functions of weights for regression and classification. Despite\nnon-convexity, convergence to global optimum at a linear rate is guaranteed\nwithout any assumption on the width of the models, allowing the width to be\nsmaller than the output dimension and the number of data points. Moreover, we\nprove a relation between the gradient dynamics of the deep implicit layer and\nthe dynamics of trust region Newton method of a shallow explicit layer. This\nmathematically proven relation along with our numerical observation suggests\nthe importance of understanding implicit bias of implicit layers and an open\nproblem on the topic. Our proofs deal with implicit layers, weight tying and\nnonlinearity on weights, and differ from those in the related literature.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 05:08:11 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 18:39:14 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kawaguchi", "Kenji", ""]]}, {"id": "2102.07367", "submitter": "Prashant Khanduri", "authors": "Prashant Khanduri, Siliang Zeng, Mingyi Hong, Hoi-To Wai, Zhaoran Wang\n  and Zhuoran Yang", "title": "A Near-Optimal Algorithm for Stochastic Bilevel Optimization via\n  Double-Momentum", "comments": "36 Pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new algorithm -- the \\underline{S}ingle-timescale\nDo\\underline{u}ble-momentum \\underline{St}ochastic\n\\underline{A}pprox\\underline{i}matio\\underline{n} (SUSTAIN) -- for tackling\nstochastic unconstrained bilevel optimization problems. We focus on bilevel\nproblems where the lower level subproblem is strongly-convex and the upper\nlevel objective function is smooth. Unlike prior works which rely on\n\\emph{two-timescale} or \\emph{double loop} techniques, we design a stochastic\nmomentum-assisted gradient estimator for both the upper and lower level\nupdates. The latter allows us to control the error in the stochastic gradient\nupdates due to inaccurate solution to both subproblems. If the upper objective\nfunction is smooth but possibly non-convex, we show that {\\aname}~requires\n$\\mathcal{O}(\\epsilon^{-3/2})$ iterations (each using ${\\cal O}(1)$ samples) to\nfind an $\\epsilon$-stationary solution. The $\\epsilon$-stationary solution is\ndefined as the point whose squared norm of the gradient of the outer function\nis less than or equal to $\\epsilon$. The total number of stochastic gradient\nsamples required for the upper and lower level objective functions matches the\nbest-known complexity for single-level stochastic gradient algorithms. We also\nanalyze the case when the upper level objective function is strongly-convex.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 07:10:33 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 06:38:35 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 06:43:34 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Khanduri", "Prashant", ""], ["Zeng", "Siliang", ""], ["Hong", "Mingyi", ""], ["Wai", "Hoi-To", ""], ["Wang", "Zhaoran", ""], ["Yang", "Zhuoran", ""]]}, {"id": "2102.07404", "submitter": "Quanquan Gu", "authors": "Zixiang Chen and Dongruo Zhou and Quanquan Gu", "title": "Almost Optimal Algorithms for Two-player Markov Games with Linear\n  Function Approximation", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning for two-player zero-sum Markov games with\nsimultaneous moves in the finite-horizon setting, where the transition kernel\nof the underlying Markov games can be parameterized by a linear function over\nthe current state, both players' actions and the next state. In particular, we\nassume that we can control both players and aim to find the Nash Equilibrium by\nminimizing the duality gap. We propose an algorithm Nash-UCRL-VTR based on the\nprinciple \"Optimism-in-Face-of-Uncertainty\". Our algorithm only needs to find a\nCoarse Correlated Equilibrium (CCE), which is computationally very efficient.\nSpecifically, we show that Nash-UCRL-VTR can provably achieve an\n$\\tilde{O}(dH\\sqrt{T})$ regret, where $d$ is the linear function dimension, $H$\nis the length of the game and $T$ is the total number of steps in the game. To\naccess the optimality of our algorithm, we also prove an $\\tilde{\\Omega}(\ndH\\sqrt{T})$ lower bound on the regret. Our upper bound matches the lower bound\nup to logarithmic factors, which suggests the optimality of our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 09:09:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Chen", "Zixiang", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "2102.07405", "submitter": "Wu Lin", "authors": "Wu Lin, Frank Nielsen, Mohammad Emtiyaz Khan, Mark Schmidt", "title": "Tractable structured natural gradient descent using local\n  parameterizations", "comments": "An extented version of the ICML 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural-gradient descent (NGD) on structured parameter spaces (e.g., low-rank\ncovariances) is computationally challenging due to difficult Fisher-matrix\ncomputations. We address this issue by using \\emph{local-parameter coordinates}\nto obtain a flexible and efficient NGD method that works well for a\nwide-variety of structured parameterizations. We show four applications where\nour method (1) generalizes the exponential natural evolutionary strategy, (2)\nrecovers existing Newton-like algorithms, (3) yields new structured\nsecond-order algorithms, and (4) gives new algorithms to learn covariances of\nGaussian and Wishart-based distributions. We show results on a range of\nproblems from deep learning, variational inference, and evolution strategies.\nOur work opens a new direction for scalable structured geometric methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 09:09:20 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 10:00:09 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 09:36:48 GMT"}, {"version": "v4", "created": "Mon, 3 May 2021 05:48:07 GMT"}, {"version": "v5", "created": "Tue, 22 Jun 2021 22:31:08 GMT"}, {"version": "v6", "created": "Mon, 12 Jul 2021 10:54:59 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Lin", "Wu", ""], ["Nielsen", "Frank", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Schmidt", "Mark", ""]]}, {"id": "2102.07432", "submitter": "Pierre Ablin", "authors": "Pierre Ablin and Gabriel Peyr\\'e", "title": "Fast and accurate optimization on the orthogonal manifold without\n  retraction", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of minimizing a function over the manifold of\northogonal matrices. The majority of algorithms for this problem compute a\ndirection in the tangent space, and then use a retraction to move in that\ndirection while staying on the manifold. Unfortunately, the numerical\ncomputation of retractions on the orthogonal manifold always involves some\nexpensive linear algebra operation, such as matrix inversion or matrix\nsquare-root. These operations quickly become expensive as the dimension of the\nmatrices grows. To bypass this limitation, we propose the landing algorithm\nwhich does not involve retractions. The algorithm is not constrained to stay on\nthe manifold but its evolution is driven by a potential energy which\nprogressively attracts it towards the manifold. One iteration of the landing\nalgorithm only involves matrix multiplications, which makes it cheap compared\nto its retraction counterparts. We provide an analysis of the convergence of\nthe algorithm, and demonstrate its promises on large-scale problems, where it\nis faster and less prone to numerical errors than retraction-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 10:12:05 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ablin", "Pierre", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "2102.07501", "submitter": "Michael Arbel", "authors": "Michael Arbel, Alexander G. D. G. Matthews, Arnaud Doucet", "title": "Annealed Flow Transport Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annealed Importance Sampling (AIS) and its Sequential Monte Carlo (SMC)\nextensions are state-of-the-art methods for estimating normalizing constants of\nprobability distributions. We propose here a novel Monte Carlo algorithm,\nAnnealed Flow Transport (AFT), that builds upon AIS and SMC and combines them\nwith normalizing flows (NFs) for improved performance. This method transports a\nset of particles using not only importance sampling (IS), Markov chain Monte\nCarlo (MCMC) and resampling steps - as in SMC, but also relies on NFs which are\nlearned sequentially to push particles towards the successive annealed targets.\nWe provide limit theorems for the resulting Monte Carlo estimates of the\nnormalizing constant and expectations with respect to the target distribution.\nAdditionally, we show that a continuous-time scaling limit of the population\nversion of AFT is given by a Feynman--Kac measure which simplifies to the law\nof a controlled diffusion for expressive NFs. We demonstrate experimentally the\nbenefits and limitations of our methodology on a variety of applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:05:56 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 12:32:38 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Arbel", "Michael", ""], ["Matthews", "Alexander G. D. G.", ""], ["Doucet", "Arnaud", ""]]}, {"id": "2102.07521", "submitter": "Dirk van der Hoeven", "authors": "Dirk van der Hoeven, H\\'edi Hadiji, Tim van Erven", "title": "Distributed Online Learning for Joint Regret with Communication\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we consider a distributed online learning\n  setting for joint regret with communication constraints. This is a\nmulti-agent setting in which in each round $t$ an adversary activates an agent,\nwhich has to issue a prediction. A subset of all the agents may then\ncommunicate a $b$-bit message to their neighbors in a graph. All agents\ncooperate to control the joint regret, which is the sum of the losses of the\nagents minus the losses evaluated at the best fixed common comparator\nparameters $\\pmb{u}$. We provide a comparator-adaptive algorithm for this\nsetting, which means that the joint regret scales with the norm of the\ncomparator $\\|\\pmb{u}\\|$. To address communication constraints we provide\ndeterministic and stochastic gradient compression schemes and show that with\nthese compression schemes our algorithm has worst-case optimal regret for the\ncase that all agents communicate in every round. Additionally, we exploit the\ncomparator-adaptive property of our algorithm to learn the best partition from\na set of candidate partitions, which allows different subsets of agents to\nlearn a different comparator.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:48:33 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["van der Hoeven", "Dirk", ""], ["Hadiji", "H\u00e9di", ""], ["van Erven", "Tim", ""]]}, {"id": "2102.07559", "submitter": "Alexander Camuto", "authors": "Ben Barrett, Alexander Camuto, Matthew Willetts, Tom Rainforth", "title": "Certifiably Robust Variational Autoencoders", "comments": "12 pages and appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an approach for training Variational Autoencoders (VAEs) that\nare certifiably robust to adversarial attack. Specifically, we first derive\nactionable bounds on the minimal size of an input perturbation required to\nchange a VAE's reconstruction by more than an allowed amount, with these bounds\ndepending on certain key parameters such as the Lipschitz constants of the\nencoder and decoder. We then show how these parameters can be controlled,\nthereby providing a mechanism to ensure a priori that a VAE will attain a\ndesired level of robustness. Moreover, we extend this to a complete practical\napproach for training such VAEs to ensure our criteria are met. Critically, our\nmethod allows one to specify a desired level of robustness upfront and then\ntrain a VAE that is guaranteed to achieve this robustness. We further\ndemonstrate that these Lipschitz--constrained VAEs are more robust to attack\nthan standard VAEs in practice.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:56:54 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Barrett", "Ben", ""], ["Camuto", "Alexander", ""], ["Willetts", "Matthew", ""], ["Rainforth", "Tom", ""]]}, {"id": "2102.07586", "submitter": "Pablo Jim\\'enez", "authors": "Alain Durmus, Pablo Jim\\'enez, \\'Eric Moulines, Salem Said", "title": "On Riemannian Stochastic Approximation Schemes with Fixed Step-Size", "comments": "37 pages, 4 figures, to appear in AISTAT21", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies fixed step-size stochastic approximation (SA) schemes,\nincluding stochastic gradient schemes, in a Riemannian framework. It is\nmotivated by several applications, where geodesics can be computed explicitly,\nand their use accelerates crude Euclidean methods. A fixed step-size scheme\ndefines a family of time-homogeneous Markov chains, parametrized by the\nstep-size. Here, using this formulation, non-asymptotic performance bounds are\nderived, under Lyapunov conditions. Then, for any step-size, the corresponding\nMarkov chain is proved to admit a unique stationary distribution, and to be\ngeometrically ergodic. This result gives rise to a family of stationary\ndistributions indexed by the step-size, which is further shown to converge to a\nDirac measure, concentrated at the solution of the problem at hand, as the\nstep-size goes to 0. Finally, the asymptotic rate of this convergence is\nestablished, through an asymptotic expansion of the bias, and a central limit\ntheorem.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 14:56:09 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 14:44:46 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Durmus", "Alain", ""], ["Jim\u00e9nez", "Pablo", ""], ["Moulines", "\u00c9ric", ""], ["Said", "Salem", ""]]}, {"id": "2102.07606", "submitter": "Filippo Portera", "authors": "Filippo Portera", "title": "A generalized quadratic loss for SVM and Deep Neural Networks", "comments": "12 pages, 2 figures, LOD 2020 Conference work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider some supervised binary classification tasks and a regression\ntask, whereas SVM and Deep Learning, at present, exhibit the best\ngeneralization performances. We extend the work [3] on a generalized quadratic\nloss for learning problems that examines pattern correlations in order to\nconcentrate the learning problem into input space regions where patterns are\nmore densely distributed. From a shallow methods point of view (e.g.: SVM),\nsince the following mathematical derivation of problem (9) in [3] is incorrect,\nwe restart from problem (8) in [3] and we try to solve it with one procedure\nthat iterates over the dual variables until the primal and dual objective\nfunctions converge. In addition we propose another algorithm that tries to\nsolve the classification problem directly from the primal problem formulation.\nWe make also use of Multiple Kernel Learning to improve generalization\nperformances. Moreover, we introduce for the first time a custom loss that\ntakes in consideration pattern correlation for a shallow and a Deep Learning\ntask. We propose some pattern selection criteria and the results on 4 UCI\ndata-sets for the SVM method. We also report the results on a larger binary\nclassification data-set based on Twitter, again drawn from UCI, combined with\nshallow Learning Neural Networks, with and without the generalized quadratic\nloss. At last, we test our loss with a Deep Neural Network within a larger\nregression task taken from UCI. We compare the results of our optimizers with\nthe well known solver SVMlight and with Keras Multi-Layers Neural Networks with\nstandard losses and with a parameterized generalized quadratic loss, and we\nobtain comparable results.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 15:49:08 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Portera", "Filippo", ""]]}, {"id": "2102.07612", "submitter": "Ath\\'ena\\\"is Gautier", "authors": "Ath\\'ena\\\"is Gautier, David Ginsbourger, Guillaume Pirot", "title": "Goal-oriented adaptive sampling under random field modelling of response\n  probability distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.OC stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the study of natural and artificial complex systems, responses that are\nnot completely determined by the considered decision variables are commonly\nmodelled probabilistically, resulting in response distributions varying across\ndecision space. We consider cases where the spatial variation of these response\ndistributions does not only concern their mean and/or variance but also other\nfeatures including for instance shape or uni-modality versus multi-modality.\nOur contributions build upon a non-parametric Bayesian approach to modelling\nthe thereby induced fields of probability distributions, and in particular to a\nspatial extension of the logistic Gaussian model.\n  The considered models deliver probabilistic predictions of response\ndistributions at candidate points, allowing for instance to perform\n(approximate) posterior simulations of probability density functions, to\njointly predict multiple moments and other functionals of target distributions,\nas well as to quantify the impact of collecting new samples on the state of\nknowledge of the distribution field of interest. In particular, we introduce\nadaptive sampling strategies leveraging the potential of the considered random\ndistribution field models to guide system evaluations in a goal-oriented way,\nwith a view towards parsimoniously addressing calibration and related problems\nfrom non-linear (stochastic) inversion and global optimisation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 15:55:23 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:42:47 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Gautier", "Ath\u00e9na\u00efs", ""], ["Ginsbourger", "David", ""], ["Pirot", "Guillaume", ""]]}, {"id": "2102.07663", "submitter": "Yangyi Lu", "authors": "Yangyi Lu, Amirhossein Meisami, Ambuj Tewari", "title": "Causal Markov Decision Processes: Learning Good Interventions\n  Efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce causal Markov Decision Processes (C-MDPs), a new formalism for\nsequential decision making which combines the standard MDP formulation with\ncausal structures over state transition and reward functions. Many contemporary\nand emerging application areas such as digital healthcare and digital marketing\ncan benefit from modeling with C-MDPs due to the causal mechanisms underlying\nthe relationship between interventions and states/rewards. We propose the\ncausal upper confidence bound value iteration (C-UCBVI) algorithm that exploits\nthe causal structure in C-MDPs and improves the performance of standard\nreinforcement learning algorithms that do not take causal knowledge into\naccount. We prove that C-UCBVI satisfies an $\\tilde{O}(HS\\sqrt{ZT})$ regret\nbound, where $T$ is the the total time steps, $H$ is the episodic horizon, and\n$S$ is the cardinality of the state space. Notably, our regret bound does not\nscale with the size of actions/interventions ($A$), but only scales with a\ncausal graph dependent quantity $Z$ which can be exponentially smaller than\n$A$. By extending C-UCBVI to the factored MDP setting, we propose the causal\nfactored UCBVI (CF-UCBVI) algorithm, which further reduces the regret\nexponentially in terms of $S$. Furthermore, we show that RL algorithms for\nlinear MDP problems can also be incorporated in C-MDPs. We empirically show the\nbenefit of our causal approaches in various settings to validate our algorithms\nand theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 16:48:54 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lu", "Yangyi", ""], ["Meisami", "Amirhossein", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2102.07686", "submitter": "Dylan Ashley", "authors": "Dylan R. Ashley, Sina Ghiassian, Richard S. Sutton", "title": "Does the Adam Optimizer Exacerbate Catastrophic Forgetting?", "comments": "9 pages in main text + 3 pages of references + 16 pages of\n  appendices, 6 figures in main text + 21 figures in appendices, 6 tables in\n  appendices; source code available at\n  https://github.com/dylanashley/catastrophic-forgetting/tree/arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Catastrophic forgetting remains a severe hindrance to the broad application\nof artificial neural networks (ANNs), however, it continues to be a poorly\nunderstood phenomenon. Despite the extensive amount of work on catastrophic\nforgetting, we argue that it is still unclear how exactly the phenomenon should\nbe quantified, and, moreover, to what degree all of the choices we make when\ndesigning learning systems affect the amount of catastrophic forgetting. We use\nvarious testbeds from the reinforcement learning and supervised learning\nliterature to (1) provide evidence that the choice of which modern\ngradient-based optimization algorithm is used to train an ANN has a significant\nimpact on the amount of catastrophic forgetting and show that-surprisingly-in\nmany instances classical algorithms such as vanilla SGD experience less\ncatastrophic forgetting than the more modern algorithms such as Adam. We\nempirically compare four different existing metrics for quantifying\ncatastrophic forgetting and (2) show that the degree to which the learning\nsystems experience catastrophic forgetting is sufficiently sensitive to the\nmetric used that a change from one principled metric to another is enough to\nchange the conclusions of a study dramatically. Our results suggest that a much\nmore rigorous experimental methodology is required when looking at catastrophic\nforgetting. Based on our results, we recommend inter-task forgetting in\nsupervised learning must be measured with both retention and relearning metrics\nconcurrently, and intra-task forgetting in reinforcement learning must-at the\nvery least-be measured with pairwise interference.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 17:32:39 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 19:56:24 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 15:52:01 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 17:00:09 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ashley", "Dylan R.", ""], ["Ghiassian", "Sina", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2102.07695", "submitter": "Aritra Guha", "authors": "Sunrit Chakraborty, Aritra Guha, Rayleigh Lei, XuanLong Nguyen", "title": "Scalable nonparametric Bayesian learning for heterogeneous and dynamic\n  velocity fields", "comments": "5 tables, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of heterogeneous patterns in complex spatio-temporal data finds\nusage across various domains in applied science and engineering, including\ntraining autonomous vehicles to navigate in complex traffic scenarios.\nMotivated by applications arising in the transportation domain, in this paper\nwe develop a model for learning heterogeneous and dynamic patterns of velocity\nfield data. We draw from basic nonparameric Bayesian modeling elements such as\nhierarchical Dirichlet process and infinite hidden Markov model, while the\nsmoothness of each homogeneous velocity field element is captured with a\nGaussian process prior. Of particular focus is a scalable approximate inference\nmethod for the proposed model; this is achieved by employing sequential MAP\nestimates from the infinite HMM model and an efficient sequential GP posterior\ncomputation technique, which is shown to work effectively on simulated data\nsets. Finally, we demonstrate the effectiveness of our techniques to the NGSIM\ndataset of complex multi-vehicle interactions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 17:45:46 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Chakraborty", "Sunrit", ""], ["Guha", "Aritra", ""], ["Lei", "Rayleigh", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "2102.07698", "submitter": "Zachary Izzo", "authors": "Zachary Izzo, Lexing Ying, James Zou", "title": "How to Learn when Data Reacts to Your Model: Performative Gradient\n  Descent", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performative distribution shift captures the setting where the choice of\nwhich ML model is deployed changes the data distribution. For example, a bank\nwhich uses the number of open credit lines to determine a customer's risk of\ndefault on a loan may induce customers to open more credit lines in order to\nimprove their chances of being approved. Because of the interactions between\nthe model and data distribution, finding the optimal model parameters is\nchallenging. Works in this area have focused on finding stable points, which\ncan be far from optimal. Here we introduce performative gradient descent\n(PerfGD), which is the first algorithm which provably converges to the\nperformatively optimal point. PerfGD explicitly captures how changes in the\nmodel affects the data distribution and is simple to use. We support our\nfindings with theory and experiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 17:49:36 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 16:07:05 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Izzo", "Zachary", ""], ["Ying", "Lexing", ""], ["Zou", "James", ""]]}, {"id": "2102.07711", "submitter": "Anshuka Rangi", "authors": "Anshuka Rangi, Long Tran-Thanh, Haifeng Xu, Massimo Franceschetti", "title": "Secure-UCB: Saving Stochastic Bandits from Poisoning Attacks via Limited\n  Data Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies bandit algorithms under data poisoning attacks in a\nbounded reward setting. We consider a strong attacker model in which the\nattacker can observe both the selected actions and their corresponding rewards,\nand can contaminate the rewards with additive noise. We show that \\emph{any}\nbandit algorithm with regret $O(\\log T)$ can be forced to suffer a regret\n$\\Omega(T)$ with an expected amount of contamination $O(\\log T)$. This amount\nof contamination is also necessary, as we prove that there exists an $O(\\log\nT)$ regret bandit algorithm, specifically the classical UCB, that requires\n$\\Omega(\\log T)$ amount of contamination to suffer regret $\\Omega(T)$. To\ncombat such poising attacks, our second main contribution is to propose a novel\nalgorithm, Secure-UCB, which uses limited \\emph{verification} to access a\nlimited number of uncontaminated rewards. We show that with $O(\\log T)$\nexpected number of verifications, Secure-UCB can restore the order optimal\n$O(\\log T)$ regret \\emph{irrespective of the amount of contamination} used by\nthe attacker. Finally, we prove that for any bandit algorithm, this number of\nverifications $O(\\log T)$ is necessary to recover the order-optimal regret. We\ncan then conclude that Secure-UCB is order-optimal in terms of both the\nexpected regret and the expected number of verifications, and can save\nstochastic bandits from any data poisoning attack.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:02:46 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Rangi", "Anshuka", ""], ["Tran-Thanh", "Long", ""], ["Xu", "Haifeng", ""], ["Franceschetti", "Massimo", ""]]}, {"id": "2102.07767", "submitter": "Mohammad Taha Toghani", "authors": "Mohammad Taha Toghani, Cesar A. Uribe", "title": "Communication-Efficient Distributed Cooperative Learning with Compressed\n  Beliefs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of distributed cooperative learning, where a group of\nagents seek to agree on a set of hypotheses that best describes a sequence of\nprivate observations. In the scenario where the set of hypotheses is large, we\npropose a belief update rule where agents share compressed (either sparse or\nquantized) beliefs with an arbitrary positive compression rate. Our algorithm\nleverages a unified and straightforward communication rule that enables agents\nto access wide-ranging compression operators as black-box modules. We prove the\nalmost sure asymptotic exponential convergence of beliefs around the set of\noptimal hypotheses. Additionally, we show a non-asymptotic, explicit, and\nlinear concentration rate in probability of the beliefs on the optimal\nhypothesis set. We provide numerical experiments to illustrate the\ncommunication benefits of our method. The simulation results show that the\nnumber of transmitted bits can be reduced to 5-10% of the non-compressed method\nin the studied scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 06:19:36 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Toghani", "Mohammad Taha", ""], ["Uribe", "Cesar A.", ""]]}, {"id": "2102.07770", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Kyungwoo Song, Seungjae Shin, Wanmo Kang, Il-Chul Moon", "title": "Posterior-Aided Regularization for Likelihood-Free Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development of likelihood-free inference aims training a flexible\ndensity estimator for the target posterior with a set of input-output pairs\nfrom simulation. Given the diversity of simulation structures, it is difficult\nto find a single unified inference method for each simulation model. This paper\nproposes a universally applicable regularization technique, called\nPosterior-Aided Regularization (PAR), which is applicable to learning the\ndensity estimator, regardless of the model structure. Particularly, PAR solves\nthe mode collapse problem that arises as the output dimension of the simulation\nincreases. PAR resolves this posterior mode degeneracy through a mixture of 1)\nthe reverse KL divergence with the mode seeking property; and 2) the mutual\ninformation for the high quality representation on likelihood. Because of the\nestimation intractability of PAR, we provide a unified estimation method of PAR\nto estimate both reverse KL term and mutual information term with a single\nneural network. Afterwards, we theoretically prove the asymptotic convergence\nof the regularized optimal solution to the unregularized optimal solution as\nthe regularization magnitude converges to zero. Additionally, we empirically\nshow that past sequential neural likelihood inferences in conjunction with PAR\npresent the statistically significant gains on diverse simulation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 16:59:30 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kim", "Dongjun", ""], ["Song", "Kyungwoo", ""], ["Shin", "Seungjae", ""], ["Kang", "Wanmo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2102.07800", "submitter": "Rajat Sen", "authors": "Rajat Sen, Alexander Rakhlin, Lexing Ying, Rahul Kidambi, Dean Foster,\n  Daniel Hill, Inderjit Dhillon", "title": "Top-$k$ eXtreme Contextual Bandits with Arm Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by modern applications, such as online advertisement and\nrecommender systems, we study the top-$k$ extreme contextual bandits problem,\nwhere the total number of arms can be enormous, and the learner is allowed to\nselect $k$ arms and observe all or some of the rewards for the chosen arms. We\nfirst propose an algorithm for the non-extreme realizable setting, utilizing\nthe Inverse Gap Weighting strategy for selecting multiple arms. We show that\nour algorithm has a regret guarantee of $O(k\\sqrt{(A-k+1)T \\log\n(|\\mathcal{F}|T)})$, where $A$ is the total number of arms and $\\mathcal{F}$ is\nthe class containing the regression function, while only requiring\n$\\tilde{O}(A)$ computation per time step. In the extreme setting, where the\ntotal number of arms can be in the millions, we propose a practically-motivated\narm hierarchy model that induces a certain structure in mean rewards to ensure\nstatistical and computational efficiency. The hierarchical structure allows for\nan exponential reduction in the number of relevant arms for each context, thus\nresulting in a regret guarantee of $O(k\\sqrt{(\\log A-k+1)T \\log\n(|\\mathcal{F}|T)})$. Finally, we implement our algorithm using a hierarchical\nlinear function class and show superior performance with respect to well-known\nbenchmarks on simulated bandit feedback experiments using extreme multi-label\nclassification datasets. On a dataset with three million arms, our reduction\nscheme has an average inference time of only 7.9 milliseconds, which is a 100x\nimprovement.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 19:10:52 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Sen", "Rajat", ""], ["Rakhlin", "Alexander", ""], ["Ying", "Lexing", ""], ["Kidambi", "Rahul", ""], ["Foster", "Dean", ""], ["Hill", "Daniel", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2102.07802", "submitter": "Varun Kanade", "authors": "Adam Kalai, Varun Kanade", "title": "Efficient Learning with Arbitrary Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an efficient algorithm for learning a binary function in a given\nclass C of bounded VC dimension, with training data distributed according to P\nand test data according to Q, where P and Q may be arbitrary distributions over\nX. This is the generic form of what is called covariate shift, which is\nimpossible in general as arbitrary P and Q may not even overlap. However,\nrecently guarantees were given in a model called PQ-learning (Goldwasser et\nal., 2020) where the learner has: (a) access to unlabeled test examples from Q\n(in addition to labeled samples from P, i.e., semi-supervised learning); and\n(b) the option to reject any example and abstain from classifying it (i.e.,\nselective classification). The algorithm of Goldwasser et al. (2020) requires\nan (agnostic) noise tolerant learner for C. The present work gives a\npolynomial-time PQ-learning algorithm that uses an oracle to a \"reliable\"\nlearner for C, where reliable learning (Kalai et al., 2012) is a model of\nlearning with one-sided noise. Furthermore, our reduction is optimal in the\nsense that we show the equivalence of reliable and PQ learning.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 19:14:25 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kalai", "Adam", ""], ["Kanade", "Varun", ""]]}, {"id": "2102.07826", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama, Masaya Abe, Kei Nakagawa, Kenichiro McAlinn", "title": "Controlling False Discovery Rates under Cross-Sectional Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider controlling the false discovery rate for testing many time series\nwith an unknown cross-sectional correlation structure. Given a large number of\nhypotheses, false and missing discoveries can plague an analysis. While many\nprocedures have been proposed to control false discovery, most of them either\nassume independent hypotheses or lack statistical power. A problem of\nparticular interest is in financial asset pricing, where the goal is to\ndetermine which ``factors\" lead to excess returns out of a large number of\npotential factors. Our contribution is two-fold. First, we show the consistency\nof Fama and French's prominent method under multiple testing. Second, we\npropose a novel method for false discovery control using double bootstrapping.\nWe achieve superior statistical power to existing methods and prove that the\nfalse discovery rate is controlled. Simulations and a real data application\nillustrate the efficacy of our method over existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 20:07:17 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 04:53:42 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Komiyama", "Junpei", ""], ["Abe", "Masaya", ""], ["Nakagawa", "Kei", ""], ["McAlinn", "Kenichiro", ""]]}, {"id": "2102.07834", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Nam-Hwui Kim, Ryan P. Browne, Matthias Schonlau", "title": "One Line To Rule Them All: Generating LO-Shot Soft-Label Prototypes", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly large datasets are rapidly driving up the computational costs of\nmachine learning. Prototype generation methods aim to create a small set of\nsynthetic observations that accurately represent a training dataset but greatly\nreduce the computational cost of learning from it. Assigning soft labels to\nprototypes can allow increasingly small sets of prototypes to accurately\nrepresent the original training dataset. Although foundational work on `less\nthan one'-shot learning has proven the theoretical plausibility of learning\nwith fewer than one observation per class, developing practical algorithms for\ngenerating such prototypes remains an unexplored territory. We propose a novel,\nmodular method for generating soft-label prototypical lines that still\nmaintains representational accuracy even when there are fewer prototypes than\nthe number of classes in the data. In addition, we propose the Hierarchical\nSoft-Label Prototype k-Nearest Neighbor classification algorithm based on these\nprototypical lines. We show that our method maintains high classification\naccuracy while greatly reducing the number of prototypes required to represent\na dataset, even when working with severely imbalanced and difficult data. Our\ncode is available at https://github.com/ilia10000/SLkNN.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 20:21:29 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Kim", "Nam-Hwui", ""], ["Browne", "Ryan P.", ""], ["Schonlau", "Matthias", ""]]}, {"id": "2102.07835", "submitter": "Bastian Rieck", "authors": "Max Horn, Edward De Brouwer, Michael Moor, Yves Moreau, Bastian Rieck,\n  Karsten Borgwardt", "title": "Topological Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are a powerful architecture for tackling graph\nlearning tasks, yet have been shown to be oblivious to eminent substructures,\nsuch as cycles. We present TOGL, a novel layer that incorporates global\ntopological information of a graph using persistent homology. TOGL can be\neasily integrated into any type of GNN and is strictly more expressive in terms\nof the Weisfeiler--Lehman test of isomorphism. Augmenting GNNs with our layer\nleads to beneficial predictive performance for graph and node classification\ntasks, both on synthetic data sets, which can be classified by humans using\ntheir topology but not by ordinary GNNs, and on real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 20:27:56 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 20:04:24 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Horn", "Max", ""], ["De Brouwer", "Edward", ""], ["Moor", "Michael", ""], ["Moreau", "Yves", ""], ["Rieck", "Bastian", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "2102.07850", "submitter": "James Thornton Mr", "authors": "Adrien Corenflos, James Thornton, George Deligiannidis, Arnaud Doucet", "title": "Differentiable Particle Filtering via Entropy-Regularized Optimal\n  Transport", "comments": "9 pages of content + 11 pages supplementary, accepted for oral at\n  ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Particle Filtering (PF) methods are an established class of procedures for\nperforming inference in non-linear state-space models. Resampling is a key\ningredient of PF, necessary to obtain low variance likelihood and states\nestimates. However, traditional resampling methods result in PF-based loss\nfunctions being non-differentiable with respect to model and PF parameters. In\na variational inference context, resampling also yields high variance gradient\nestimates of the PF-based evidence lower bound. By leveraging optimal transport\nideas, we introduce a principled differentiable particle filter and provide\nconvergence results. We demonstrate this novel method on a variety of\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 21:05:33 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 10:23:44 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 12:25:38 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Corenflos", "Adrien", ""], ["Thornton", "James", ""], ["Deligiannidis", "George", ""], ["Doucet", "Arnaud", ""]]}, {"id": "2102.07856", "submitter": "Yu Bai", "authors": "Yu Bai, Song Mei, Huan Wang, Caiming Xiong", "title": "Don't Just Blame Over-parametrization for Over-confidence: Theoretical\n  Analysis of Calibration in Binary Classification", "comments": "Appearing at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning models with high accuracy are often miscalibrated --\nthe predicted top probability does not reflect the actual accuracy, and tends\nto be over-confident. It is commonly believed that such over-confidence is\nmainly due to over-parametrization, in particular when the model is large\nenough to memorize the training data and maximize the confidence.\n  In this paper, we show theoretically that over-parametrization is not the\nonly reason for over-confidence. We prove that logistic regression is\ninherently over-confident, in the realizable, under-parametrized setting where\nthe data is generated from the logistic model, and the sample size is much\nlarger than the number of parameters. Further, this over-confidence happens for\ngeneral well-specified binary classification problems as long as the activation\nis symmetric and concave on the positive part. Perhaps surprisingly, we also\nshow that over-confidence is not always the case -- there exists another\nactivation function (and a suitable loss function) under which the learned\nclassifier is under-confident at some probability values. Overall, our theory\nprovides a precise characterization of calibration in realizable binary\nclassification, which we verify on simulations and real data experiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 21:38:09 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 18:21:37 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Bai", "Yu", ""], ["Mei", "Song", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""]]}, {"id": "2102.07870", "submitter": "Michael E. Sander", "authors": "Michael E. Sander, Pierre Ablin, Mathieu Blondel, Gabriel Peyr\\'e", "title": "Momentum Residual Neural Networks", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The training of deep residual neural networks (ResNets) with backpropagation\nhas a memory cost that increases linearly with respect to the depth of the\nnetwork. A way to circumvent this issue is to use reversible architectures. In\nthis paper, we propose to change the forward rule of a ResNet by adding a\nmomentum term. The resulting networks, momentum residual neural networks\n(Momentum ResNets), are invertible. Unlike previous invertible architectures,\nthey can be used as a drop-in replacement for any existing ResNet block. We\nshow that Momentum ResNets can be interpreted in the infinitesimal step size\nregime as second-order ordinary differential equations (ODEs) and exactly\ncharacterize how adding momentum progressively increases the representation\ncapabilities of Momentum ResNets. Our analysis reveals that Momentum ResNets\ncan learn any linear mapping up to a multiplicative factor, while ResNets\ncannot. In a learning to optimize setting, where convergence to a fixed point\nis required, we show theoretically and empirically that our method succeeds\nwhile existing invertible architectures fail. We show on CIFAR and ImageNet\nthat Momentum ResNets have the same accuracy as ResNets, while having a much\nsmaller memory footprint, and show that pre-trained Momentum ResNets are\npromising for fine-tuning models.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 22:24:52 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 12:29:54 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 08:18:05 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sander", "Michael E.", ""], ["Ablin", "Pierre", ""], ["Blondel", "Mathieu", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "2102.07927", "submitter": "Son Ngyen", "authors": "Son Nguyen and Duong Nguyen and Khai Nguyen and Nhat Ho and Khoat Than\n  and Hung Bui", "title": "Structured Dropout Variational Inference for Bayesian Neural Networks", "comments": "39 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate inference in deep Bayesian networks exhibits a dilemma of how to\nyield high fidelity posterior approximations while maintaining computational\nefficiency and scalability. We tackle this challenge by introducing a novel\nvariational structured approximation inspired by the Bayesian interpretation of\nDropout regularization. Concretely, we focus on the inflexibility of the\nfactorized structure in Dropout posterior and then propose an improved method\ncalled Variational Structured Dropout (VSD). VSD employs an orthogonal\ntransformation to learn a structured representation on the variational noise\nand consequently induces statistical dependencies in the approximate posterior.\nTheoretically, VSD successfully addresses the pathologies of previous\nVariational Dropout methods and thus offers a standard Bayesian justification.\nWe further show that VSD induces an adaptive regularization term with several\ndesirable properties which contribute to better generalization. Finally, we\nconduct extensive experiments on standard benchmarks to demonstrate the\neffectiveness of VSD over state-of-the-art variational methods on predictive\naccuracy, uncertainty estimation, and out-of-distribution detection.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 02:33:43 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 11:09:09 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Nguyen", "Son", ""], ["Nguyen", "Duong", ""], ["Nguyen", "Khai", ""], ["Ho", "Nhat", ""], ["Than", "Khoat", ""], ["Bui", "Hung", ""]]}, {"id": "2102.07937", "submitter": "Gregory Dexter", "authors": "Gregory Dexter, Kevin Bello, and Jean Honorio", "title": "Inverse Reinforcement Learning in the Continuous Setting with Formal\n  Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse Reinforcement Learning (IRL) is the problem of finding a reward\nfunction which describes observed/known expert behavior. IRL is useful for\nautomated control in situations where the reward function is difficult to\nspecify manually, which impedes reinforcement learning. We provide a new IRL\nalgorithm for the continuous state space setting with unknown transition\ndynamics by modeling the system using a basis of orthonormal functions. We\nprovide a proof of correctness and formal guarantees on the sample and time\ncomplexity of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 03:17:23 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Dexter", "Gregory", ""], ["Bello", "Kevin", ""], ["Honorio", "Jean", ""]]}, {"id": "2102.07954", "submitter": "Dilin Wang", "authors": "Dilin Wang, Chengyue Gong, Meng Li, Qiang Liu, Vikas Chandra", "title": "AlphaNet: Improved Training of Supernets with Alpha-Divergence", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Weight-sharing neural architecture search (NAS) is an effective technique for\nautomating efficient neural architecture design. Weight-sharing NAS builds a\nsupernet that assembles all the architectures as its sub-networks and jointly\ntrains the supernet with the sub-networks. The success of weight-sharing NAS\nheavily relies on distilling the knowledge of the supernet to the sub-networks.\nHowever, we find that the widely used distillation divergence, i.e., KL\ndivergence, may lead to student sub-networks that over-estimate or\nunder-estimate the uncertainty of the teacher supernet, leading to inferior\nperformance of the sub-networks. In this work, we propose to improve the\nsupernet training with a more generalized alpha-divergence. By adaptively\nselecting the alpha-divergence, we simultaneously prevent the over-estimation\nor under-estimation of the uncertainty of the teacher model. We apply the\nproposed alpha-divergence based supernets training to both slimmable neural\nnetworks and weight-sharing NAS, and demonstrate significant improvements.\nSpecifically, our discovered model family, AlphaNet, outperforms prior-art\nmodels on a wide range of FLOPs regimes, including BigNAS, Once-for-All\nnetworks, and AttentiveNAS. We achieve ImageNet top-1 accuracy of 80.0% with\nonly 444M FLOPs. Our code and pretrained models are available at\nhttps://github.com/facebookresearch/AlphaNet.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 04:23:55 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 17:19:59 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Wang", "Dilin", ""], ["Gong", "Chengyue", ""], ["Li", "Meng", ""], ["Liu", "Qiang", ""], ["Chandra", "Vikas", ""]]}, {"id": "2102.07987", "submitter": "Nima Hamidi", "authors": "Nima Hamidi, Mohsen Bayati", "title": "The Randomized Elliptical Potential Lemma with an Application to Linear\n  Thompson Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note, we introduce a randomized version of the well-known elliptical\npotential lemma that is widely used in the analysis of algorithms in sequential\nlearning and decision-making problems such as stochastic linear bandits. Our\nrandomized elliptical potential lemma relaxes the Gaussian assumption on the\nobservation noise and on the prior distribution of the problem parameters. We\nthen use this generalization to prove an improved Bayesian regret bound for\nThompson sampling for the linear stochastic bandits with changing action sets\nwhere prior and noise distributions are general. This bound is minimax optimal\nup to constants.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 07:30:04 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Hamidi", "Nima", ""], ["Bayati", "Mohsen", ""]]}, {"id": "2102.08014", "submitter": "Kei Kobayashi", "authors": "Daisuke Takehara, Kei Kobayashi", "title": "Enhancing Hierarchical Information by Using Metric Cones for Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding is becoming an important method with applications in various\nareas, including social networks and knowledge graph completion. In particular,\nPoincar\\'e embedding has been proposed to capture the hierarchical structure of\ngraphs, and its effectiveness has been reported. However, most of the existing\nmethods have isometric mappings in the embedding space, and the choice of the\norigin point can be arbitrary. This fact is not desirable when the distance\nfrom the origin is used as an indicator of hierarchy, as in the case of\nPoincar\\'e embedding. In this paper, we propose graph embedding in a metric\ncone to solve such a problem, and we gain further benefits: 1) we provide an\nindicator of hierarchical information that is both geometrically and\nintuitively natural to interpret, 2) we can extract the hierarchical structure\nfrom a graph embedding output of other methods by learning additional\none-dimensional parameters, and 3) we can change the curvature of the embedding\nspace via a hyperparameter.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:23:59 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Takehara", "Daisuke", ""], ["Kobayashi", "Kei", ""]]}, {"id": "2102.08019", "submitter": "Kevin Bello", "authors": "Kevin Bello, Chuyang Ke and Jean Honorio", "title": "A Thorough View of Exact Inference in Graphs from the Degree-4\n  Sum-of-Squares Hierarchy", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing inference in graphs is a common task within several machine\nlearning problems, e.g., image segmentation, community detection, among others.\nFor a given undirected connected graph, we tackle the statistical problem of\nexactly recovering an unknown ground-truth binary labeling of the nodes from a\nsingle corrupted observation of each edge. Such problem can be formulated as a\nquadratic combinatorial optimization problem over the boolean hypercube, where\nit has been shown before that one can (with high probability and in polynomial\ntime) exactly recover the ground-truth labeling of graphs that have an\nisoperimetric number that grows with respect to the number of nodes (e.g.,\ncomplete graphs, regular expanders). In this work, we apply a powerful\nhierarchy of relaxations, known as the sum-of-squares (SoS) hierarchy, to the\ncombinatorial problem. Motivated by empirical evidence on the improvement in\nexact recoverability, we center our attention on the degree-4 SoS relaxation\nand set out to understand the origin of such improvement from a graph\ntheoretical perspective. We show that the solution of the dual of the relaxed\nproblem is related to finding edge weights of the Johnson and Kneser graphs,\nwhere the weights fulfill the SoS constraints and intuitively allow the input\ngraph to increase its algebraic connectivity. Finally, as byproduct of our\nanalysis, we derive a novel Cheeger-type lower bound for the algebraic\nconnectivity of graphs with signed edge weights.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:36:19 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:38:36 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Bello", "Kevin", ""], ["Ke", "Chuyang", ""], ["Honorio", "Jean", ""]]}, {"id": "2102.08020", "submitter": "Cosme Louart", "authors": "Cosme Louart and Romain Couillet", "title": "Concentration of measure and generalized product of random vectors with\n  an application to Hanson-Wright-like inequalities", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from concentration of measure hypotheses on $m$ random vectors\n$Z_1,\\ldots, Z_m$, this article provides an expression of the concentration of\nfunctionals $\\phi(Z_1,\\ldots, Z_m)$ where the variations of $\\phi$ on each\nvariable depend on the product of the norms (or semi-norms) of the other\nvariables (as if $\\phi$ were a product). We illustrate the importance of this\nresult through various generalizations of the Hanson-Wright concentration\ninequality as well as through a study of the random matrix $XDX^T$ and its\nresolvent $Q = (I_p - \\frac{1}{n}XDX^T)^{-1}$, where $X$ and $D$ are random,\nwhich have fundamental interest in statistical machine learning applications.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:36:28 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 14:31:59 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Louart", "Cosme", ""], ["Couillet", "Romain", ""]]}, {"id": "2102.08023", "submitter": "Sylvain Le Corff", "authors": "Jean Ollion, Charles Ollion (CMAP), Elisabeth Gassiat (LMO), Luc\n  Leh\\'ericy (JAD), Sylvain Le Corff (IP Paris, TIPIC-SAMOVAR, SAMOVAR)", "title": "Joint self-supervised blind denoising and noise estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel self-supervised image blind denoising approach in which\ntwo neural networks jointly predict the clean signal and infer the noise\ndistribution. Assuming that the noisy observations are independent\nconditionally to the signal, the networks can be jointly trained without clean\ntraining data. Therefore, our approach is particularly relevant for biomedical\nimage denoising where the noise is difficult to model precisely and clean\ntraining data are usually unavailable. Our method significantly outperforms\ncurrent state-of-the-art self-supervised blind denoising algorithms, on six\npublicly available biomedical image datasets. We also show empirically with\nsynthetic noisy data that our model captures the noise distribution\nefficiently. Finally, the described framework is simple, lightweight and\ncomputationally efficient, making it useful in practical cases.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:37:47 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ollion", "Jean", "", "CMAP"], ["Ollion", "Charles", "", "CMAP"], ["Gassiat", "Elisabeth", "", "LMO"], ["Leh\u00e9ricy", "Luc", "", "JAD"], ["Corff", "Sylvain Le", "", "IP Paris, TIPIC-SAMOVAR, SAMOVAR"]]}, {"id": "2102.08087", "submitter": "Etienne Boursier", "authors": "Etienne Boursier and Tristan Garrec and Vianney Perchet and Marco\n  Scarsini", "title": "Making the most of your day: online learning for optimal allocation of\n  time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online learning for optimal allocation when the resource to be\nallocated is time. Examples of possible applications include a driver filling a\nday with rides, a landlord renting an estate, etc. Following our initial\nmotivation, a driver receives ride proposals sequentially according to a\nPoisson process and can either accept or reject a proposed ride. If she accepts\nthe proposal, she is busy for the duration of the ride and obtains a reward\nthat depends on the ride duration. If she rejects it, she remains on hold until\na new ride proposal arrives. We study the regret incurred by the driver first\nwhen she knows her reward function but does not know the distribution of the\nride duration, and then when she does not know her reward function, either.\nFaster rates are finally obtained by adding structural assumptions on the\ndistribution of rides or on the reward function. This natural setting bears\nsimilarities with contextual (one-armed) bandits, but with the crucial\ndifference that the normalized reward associated to a context depends on the\nwhole distribution of contexts.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 11:19:51 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Boursier", "Etienne", ""], ["Garrec", "Tristan", ""], ["Perchet", "Vianney", ""], ["Scarsini", "Marco", ""]]}, {"id": "2102.08093", "submitter": "Hisham Husain", "authors": "Hisham Husain, Borja Balle", "title": "A Law of Robustness for Weight-bounded Neural Networks", "comments": "The main result does not resolve the conjecture as claimed. However\n  the proof technique can be used to obtain a weaker result. The manuscript\n  will be updated at a later date", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of deep neural networks against adversarial perturbations is a\npressing concern motivated by recent findings showing the pervasive nature of\nsuch vulnerabilities. One method of characterizing the robustness of a neural\nnetwork model is through its Lipschitz constant, which forms a robustness\ncertificate. A natural question to ask is, for a fixed model class (such as\nneural networks) and a dataset of size $n$, what is the smallest achievable\nLipschitz constant among all models that fit the dataset? Recently, (Bubeck et\nal., 2020) conjectured that when using two-layer networks with $k$ neurons to\nfit a generic dataset, the smallest Lipschitz constant is\n$\\Omega(\\sqrt{\\frac{n}{k}})$. This implies that one would require one neuron\nper data point to robustly fit the data. In this work we derive a lower bound\non the Lipschitz constant for any arbitrary model class with bounded Rademacher\ncomplexity. Our result coincides with that conjectured in (Bubeck et al., 2020)\nfor two-layer networks under the assumption of bounded weights. However, due to\nour result's generality, we also derive bounds for multi-layer neural networks,\ndiscovering that one requires $\\log n$ constant-sized layers to robustly fit\nthe data. Thus, our work establishes a law of robustness for weight bounded\nneural networks and provides formal evidence on the necessity of\nover-parametrization in deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 11:28:59 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 08:32:40 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Husain", "Hisham", ""], ["Balle", "Borja", ""]]}, {"id": "2102.08114", "submitter": "Assaf Rabinowicz", "authors": "Assaf Rabinowicz and Saharon Rosset", "title": "Trees-Based Models for Correlated Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new approach for trees-based regression, such as simple\nregression tree, random forest and gradient boosting, in settings involving\ncorrelated data. We show the problems that arise when implementing standard\ntrees-based regression models, which ignore the correlation structure. Our new\napproach explicitly takes the correlation structure into account in the\nsplitting criterion, stopping rules and fitted values in the leaves, which\ninduces some major modifications of standard methodology. The superiority of\nour new approach over trees-based models that do not account for the\ncorrelation is supported by simulation experiments and real data analyses.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 12:30:48 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Rabinowicz", "Assaf", ""], ["Rosset", "Saharon", ""]]}, {"id": "2102.08127", "submitter": "Bruno Loureiro", "authors": "Bruno Loureiro, C\\'edric Gerbelot, Hugo Cui, Sebastian Goldt, Florent\n  Krzakala, Marc M\\'ezard, Lenka Zdeborov\\'a", "title": "Learning curves of generic features maps for realistic datasets with a\n  teacher-student model", "comments": "main: 11 pages, 5 figures; appendix: 50 pages, 4 figures; v2: revised\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teacher-student models provide a framework in which the typical-case\nperformance of high-dimensional supervised learning can be described in closed\nform. The assumptions of Gaussian i.i.d. input data underlying the canonical\nteacher-student model may, however, be perceived as too restrictive to capture\nthe behaviour of realistic data sets. In this paper, we introduce a Gaussian\ncovariate generalisation of the model where the teacher and student can act on\ndifferent spaces, generated with fixed, but generic feature maps. While still\nsolvable in a closed form, this generalization is able to capture the learning\ncurves for a broad range of realistic data sets, thus redeeming the potential\nof the teacher-student framework. Our contribution is then two-fold: First, we\nprove a rigorous formula for the asymptotic training loss and generalisation\nerror. Second, we present a number of situations where the learning curve of\nthe model captures the one of a realistic data set learned with kernel\nregression and classification, with out-of-the-box feature maps such as random\nprojections or scattering transforms, or with pre-learned ones - such as the\nfeatures learned by training multi-layer neural networks. We discuss both the\npower and the limitations of the framework.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 12:49:15 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:19:46 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Loureiro", "Bruno", ""], ["Gerbelot", "C\u00e9dric", ""], ["Cui", "Hugo", ""], ["Goldt", "Sebastian", ""], ["Krzakala", "Florent", ""], ["M\u00e9zard", "Marc", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2102.08184", "submitter": "Assaf Ben-Yishai", "authors": "Assaf Ben-Yishai and Or Ordentlich", "title": "Constructing Multiclass Classifiers using Binary Classifiers Under\n  Log-Loss", "comments": "A shorter version of this contribution was submitted to ISIT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The construction of multiclass classifiers from binary classifiers is studied\nin this paper, and performance is quantified by the regret, defined with\nrespect to the Bayes optimal log-loss. We start by proving that the regret of\nthe well known One vs. All (OVA) method is upper bounded by the sum of the\nregrets of its constituent binary classifiers. We then present a new method\ncalled Conditional OVA (COVA), and prove that its regret is given by the\nweighted sum of the regrets corresponding to the constituent binary\nclassifiers. Lastly, we present a method termed Leveraged COVA (LCOVA),\ndesignated to reduce the regret of a multiclass classifier by breaking it down\nto independently optimized binary classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 14:34:59 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ben-Yishai", "Assaf", ""], ["Ordentlich", "Or", ""]]}, {"id": "2102.08208", "submitter": "Junhyung Park", "authors": "Junhyung Park and Uri Shalit and Bernhard Sch\\\"olkopf and Krikamol\n  Muandet", "title": "Conditional Distributional Treatment Effect with Kernel Conditional Mean\n  Embeddings and U-Statistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to analyse the conditional distributional treatment effect\n(CoDiTE), which, in contrast to the more common conditional average treatment\neffect (CATE), is designed to encode a treatment's distributional aspects\nbeyond the mean. We first introduce a formal definition of the CoDiTE\nassociated with a distance function between probability measures. Then we\ndiscuss the CoDiTE associated with the maximum mean discrepancy via kernel\nconditional mean embeddings, which, coupled with a hypothesis test, tells us\nwhether there is any conditional distributional effect of the treatment.\nFinally, we investigate what kind of conditional distributional effect the\ntreatment has, both in an exploratory manner via the conditional witness\nfunction, and in a quantitative manner via U-statistic regression, generalising\nthe CATE to higher-order moments. Experiments on synthetic, semi-synthetic and\nreal datasets demonstrate the merits of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 15:09:23 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 19:41:10 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 16:09:18 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 15:42:24 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Park", "Junhyung", ""], ["Shalit", "Uri", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Muandet", "Krikamol", ""]]}, {"id": "2102.08232", "submitter": "Mark de Rooij", "authors": "Mark de Rooij and Patrick J. F. Groenen", "title": "The MELODIC family for simultaneous binary logistic regression in a\n  reduced space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logistic regression is a commonly used method for binary classification.\nResearchers often have more than a single binary response variable and\nsimultaneous analysis is beneficial because it provides insight into the\ndependencies among response variables as well as between the predictor\nvariables and the responses. Moreover, in such a simultaneous analysis the\nequations can lend each other strength, which might increase predictive\naccuracy. In this paper, we propose the MELODIC family for simultaneous binary\nlogistic regression modeling. In this family, the regression models are defined\nin a Euclidean space of reduced dimension, based on a distance rule. The model\nmay be interpreted in terms of logistic regression coefficients or in terms of\na biplot. We discuss a fast iterative majorization (or MM) algorithm for\nparameter estimation. Two applications are shown in detail: one relating\npersonality characteristics to drug consumption profiles and one relating\npersonality characteristics to depressive and anxiety disorders. We present a\nthorough comparison of our MELODIC family with alternative approaches for\nmultivariate binary data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 15:47:20 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["de Rooij", "Mark", ""], ["Groenen", "Patrick J. F.", ""]]}, {"id": "2102.08248", "submitter": "Jakob Drachmann Havtorn Mr", "authors": "Jakob D. Havtorn, Jes Frellsen, S{\\o}ren Hauberg, Lars Maal{\\o}e", "title": "Hierarchical VAEs Know What They Don't Know", "comments": "Appeared in Proceedings of the 38th International Conference on\n  Machine Learning (ICML 2021). 18 pages, source code available at\n  https://github.com/JakobHavtorn/hvae-oodd,\n  https://github.com/vlievin/biva-pytorch and\n  https://github.com/larsmaaloee/BIVA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have been demonstrated as state-of-the-art density\nestimators. Yet, recent work has found that they often assign a higher\nlikelihood to data from outside the training distribution. This seemingly\nparadoxical behavior has caused concerns over the quality of the attained\ndensity estimates. In the context of hierarchical variational autoencoders, we\nprovide evidence to explain this behavior by out-of-distribution data having\nin-distribution low-level features. We argue that this is both expected and\ndesirable behavior. With this insight in hand, we develop a fast, scalable and\nfully unsupervised likelihood-ratio score for OOD detection that requires data\nto be in-distribution across all feature-levels. We benchmark the method on a\nvast set of data and model combinations and achieve state-of-the-art results on\nout-of-distribution detection.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 16:08:04 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 09:35:30 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 09:54:43 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 07:44:50 GMT"}, {"version": "v5", "created": "Fri, 11 Jun 2021 11:55:39 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Havtorn", "Jakob D.", ""], ["Frellsen", "Jes", ""], ["Hauberg", "S\u00f8ren", ""], ["Maal\u00f8e", "Lars", ""]]}, {"id": "2102.08308", "submitter": "Ecenaz Erdemir", "authors": "Ecenaz Erdemir and Pier Luigi Dragotti and Deniz Gunduz", "title": "Active Privacy-utility Trade-off Against a Hypothesis Testing Adversary", "comments": "Accepted to IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a user releasing her data containing some personal information in\nreturn of a service. We model user's personal information as two correlated\nrandom variables, one of them, called the secret variable, is to be kept\nprivate, while the other, called the useful variable, is to be disclosed for\nutility. We consider active sequential data release, where at each time step\nthe user chooses from among a finite set of release mechanisms, each revealing\nsome information about the user's personal information, i.e., the true\nhypotheses, albeit with different statistics. The user manages data release in\nan online fashion such that maximum amount of information is revealed about the\nlatent useful variable, while the confidence for the sensitive variable is kept\nbelow a predefined level. For the utility, we consider both the probability of\ncorrect detection of the useful variable and the mutual information (MI)\nbetween the useful variable and released data. We formulate both problems as a\nMarkov decision process (MDP), and numerically solve them by advantage\nactor-critic (A2C) deep reinforcement learning (RL).\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:49:31 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 11:59:00 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Erdemir", "Ecenaz", ""], ["Dragotti", "Pier Luigi", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2102.08310", "submitter": "Elizabeth Fons", "authors": "Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane, Alexandros\n  Iosifidis", "title": "Adaptive Weighting Scheme for Automatic Time-Series Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation methods have been shown to be a fundamental technique to\nimprove generalization in tasks such as image, text and audio classification.\nRecently, automated augmentation methods have led to further improvements on\nimage classification and object detection leading to state-of-the-art\nperformances. Nevertheless, little work has been done on time-series data, an\narea that could greatly benefit from automated data augmentation given the\nusually limited size of the datasets. We present two sample-adaptive automatic\nweighting schemes for data augmentation: the first learns to weight the\ncontribution of the augmented samples to the loss, and the second method\nselects a subset of transformations based on the ranking of the predicted\ntraining loss. We validate our proposed methods on a large, noisy financial\ndataset and on time-series datasets from the UCR archive. On the financial\ndataset, we show that the methods in combination with a trading strategy lead\nto improvements in annualized returns of over 50$\\%$, and on the time-series\ndata we outperform state-of-the-art models on over half of the datasets, and\nachieve similar performance in accuracy on the others.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:50:51 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Fons", "Elizabeth", ""], ["Dawson", "Paula", ""], ["Zeng", "Xiao-jun", ""], ["Keane", "John", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2102.08314", "submitter": "David Burt", "authors": "Artem Artemev, David R. Burt and Mark van der Wilk", "title": "Tighter Bounds on the Log Marginal Likelihood of Gaussian Process\n  Regression Using Conjugate Gradients", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a lower bound on the log marginal likelihood of Gaussian process\nregression models that can be computed without matrix factorisation of the full\nkernel matrix. We show that approximate maximum likelihood learning of model\nparameters by maximising our lower bound retains many of the sparse variational\napproach benefits while reducing the bias introduced into parameter learning.\nThe basis of our bound is a more careful analysis of the log-determinant term\nappearing in the log marginal likelihood, as well as using the method of\nconjugate gradients to derive tight lower bounds on the term involving a\nquadratic form. Our approach is a step forward in unifying methods relying on\nlower bound maximisation (e.g. variational methods) and iterative approaches\nbased on conjugate gradients for training Gaussian processes. In experiments,\nwe show improved predictive performance with our model for a comparable amount\nof training time compared to other conjugate gradient based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:54:59 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Artemev", "Artem", ""], ["Burt", "David R.", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2102.08329", "submitter": "Berivan Isik", "authors": "Berivan Isik, Albert No, Tsachy Weissman", "title": "Rate-Distortion Theoretic Model Compression: Successive Refinement for\n  Pruning", "comments": "Title changed. Previous title: Successive pruning for model\n  compression via rate distortion theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the neural network (NN) compression problem, viewing the tension\nbetween the compression ratio and NN performance through the lens of\nrate-distortion theory. We choose a distortion metric that reflects the effect\nof NN compression on the model output and then derive the tradeoff between rate\n(compression ratio) and distortion. In addition to characterizing theoretical\nlimits of NN compression, this formulation shows that \\emph{pruning},\nimplicitly or explicitly, must be a part of a good compression algorithm. This\nobservation bridges a gap between parts of the literature pertaining to NN and\ndata compression, respectively, providing insight into the empirical success of\npruning for NN compression. Finally, we propose a novel pruning strategy\nderived from our information-theoretic formulation and show that it outperforms\nthe relevant baselines on CIFAR-10 and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:17:57 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 10:33:10 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 13:10:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Isik", "Berivan", ""], ["No", "Albert", ""], ["Weissman", "Tsachy", ""]]}, {"id": "2102.08352", "submitter": "Yura Malitsky", "authors": "Ahmet Alacaoglu, Yura Malitsky", "title": "Stochastic Variance Reduction for Variational Inequality Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose stochastic variance reduced algorithms for solving convex-concave\nsaddle point problems, monotone variational inequalities, and monotone\ninclusions. Our framework applies to extragradient, forward-backward-forward,\nand forward-reflected-backward methods both in Euclidean and Bregman setups.\nAll proposed methods converge in exactly the same setting as their\ndeterministic counterparts and they either match or improve the best-known\ncomplexities for solving structured min-max problems. Our results reinforce the\ncorrespondence between variance reduction in variational inequalities and\nminimization. We also illustrate the improvements of our approach with\nnumerical evaluations on matrix games.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:39:16 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Alacaoglu", "Ahmet", ""], ["Malitsky", "Yura", ""]]}, {"id": "2102.08354", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Kyle Istvan", "title": "Topological Deep Learning: Classification Neural Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:2008.13697", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological deep learning is a formalism that is aimed at introducing\ntopological language to deep learning for the purpose of utilizing the minimal\nmathematical structures to formalize problems that arise in a generic deep\nlearning problem. This is the first of a sequence of articles with the purpose\nof introducing and studying this formalism. In this article, we define and\nstudy the classification problem in machine learning in a topological setting.\nUsing this topological framework, we show when the classification problem is\npossible or not possible in the context of neural networks. Finally, we\ndemonstrate how our topological setting immediately illuminates aspects of this\nproblem that are not as readily apparent using traditional tools.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:41:09 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Hajij", "Mustafa", ""], ["Istvan", "Kyle", ""]]}, {"id": "2102.08373", "submitter": "Phan-Minh Nguyen", "authors": "Phan-Minh Nguyen", "title": "Analysis of feature learning in weight-tied autoencoders via the mean\n  field lens", "comments": "121 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoencoders are among the earliest introduced nonlinear models for\nunsupervised learning. Although they are widely adopted beyond research, it has\nbeen a longstanding open problem to understand mathematically the feature\nextraction mechanism that trained nonlinear autoencoders provide.\n  In this work, we make progress in this problem by analyzing a class of\ntwo-layer weight-tied nonlinear autoencoders in the mean field framework. Upon\na suitable scaling, in the regime of a large number of neurons, the models\ntrained with stochastic gradient descent are shown to admit a mean field\nlimiting dynamics. This limiting description reveals an asymptotically precise\npicture of feature learning by these models: their training dynamics exhibit\ndifferent phases that correspond to the learning of different principal\nsubspaces of the data, with varying degrees of nonlinear shrinkage dependent on\nthe $\\ell_{2}$-regularization and stopping time. While we prove these results\nunder an idealized assumption of (correlated) Gaussian data, experiments on\nreal-life data demonstrate an interesting match with the theory.\n  The autoencoder setup of interests poses a nontrivial mathematical challenge\nto proving these results. In this setup, the \"Lipschitz\" constants of the\nmodels grow with the data dimension $d$. Consequently an adaptation of previous\nanalyses requires a number of neurons $N$ that is at least exponential in $d$.\nOur main technical contribution is a new argument which proves that the\nrequired $N$ is only polynomial in $d$. We conjecture that $N\\gg d$ is\nsufficient and that $N$ is necessarily larger than a data-dependent intrinsic\ndimension, a behavior that is fundamentally different from previously studied\nsetups.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:58:37 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Nguyen", "Phan-Minh", ""]]}, {"id": "2102.08374", "submitter": "Konstantin Mishchenko", "authors": "Konstantin Mishchenko and Bokun Wang and Dmitry Kovalev and Peter\n  Richt\\'arik", "title": "IntSGD: Floatless Compression of Stochastic Gradients", "comments": "25 pages, 8 figures, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of lossy integer compressions for Stochastic Gradient\nDescent (SGD) that do not communicate a single float. This is achieved by\nmultiplying floating-point vectors with a number known to every device and then\nrounding to an integer number. Our theory shows that the iteration complexity\nof SGD does not change up to constant factors when the vectors are scaled\nproperly. Moreover, this holds for both convex and non-convex functions, with\nand without overparameterization. In contrast to other compression-based\nalgorithms, ours preserves the convergence rate of SGD even on non-smooth\nproblems. Finally, we show that when the data is significantly heterogeneous,\nit may become increasingly hard to keep the integers bounded and propose an\nalternative algorithm, IntDIANA, to solve this type of problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:58:57 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Mishchenko", "Konstantin", ""], ["Wang", "Bokun", ""], ["Kovalev", "Dmitry", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2102.08380", "submitter": "Dan Roberts", "authors": "Joshua Batson, C. Grace Haaf, Yonatan Kahn, Daniel A. Roberts", "title": "Topological Obstructions to Autoencoding", "comments": "24 + 20 pages, 26 figures; no autoencoders were harmed in the making\n  of this project. v2: JHEP published version", "journal-ref": "JHEP04(2021)280", "doi": "10.1007/JHEP04(2021)280", "report-no": "MIT-CTP/5264", "categories": "hep-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders have been proposed as a powerful tool for model-independent\nanomaly detection in high-energy physics. The operating principle is that\nevents which do not belong to the space of training data will be reconstructed\npoorly, thus flagging them as anomalies. We point out that in a variety of\nexamples of interest, the connection between large reconstruction error and\nanomalies is not so clear. In particular, for data sets with nontrivial\ntopology, there will always be points that erroneously seem anomalous due to\nglobal issues. Conversely, neural networks typically have an inductive bias or\nprior to locally interpolate such that undersampled or rare events may be\nreconstructed with small error, despite actually being the desired anomalies.\nTaken together, these facts are in tension with the simple picture of the\nautoencoder as an anomaly detector. Using a series of illustrative\nlow-dimensional examples, we show explicitly how the intrinsic and extrinsic\ntopology of the dataset affects the behavior of an autoencoder and how this\ntopology is manifested in the latent space representation during training. We\nground this analysis in the discussion of a mock \"bump hunt\" in which the\nautoencoder fails to identify an anomalous \"signal\" for reasons tied to the\nintrinsic topology of $n$-particle phase space.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:00:00 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 14:55:22 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Batson", "Joshua", ""], ["Haaf", "C. Grace", ""], ["Kahn", "Yonatan", ""], ["Roberts", "Daniel A.", ""]]}, {"id": "2102.08410", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Alex Beutel, Matthaeus Kleindessner, Jamie\n  Morgenstern, Xuezhi Wang", "title": "Evaluating Fairness of Machine Learning Models Under Uncertain and\n  Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training and evaluation of fair classifiers is a challenging problem. This is\npartly due to the fact that most fairness metrics of interest depend on both\nthe sensitive attribute information and label information of the data points.\nIn many scenarios it is not possible to collect large datasets with such\ninformation. An alternate approach that is commonly used is to separately train\nan attribute classifier on data with sensitive attribute information, and then\nuse it later in the ML pipeline to evaluate the bias of a given classifier.\nWhile such decoupling helps alleviate the problem of demographic scarcity, it\nraises several natural questions such as: how should the attribute classifier\nbe trained?, and how should one use a given attribute classifier for accurate\nbias estimation? In this work we study this question from both theoretical and\nempirical perspectives.\n  We first experimentally demonstrate that the test accuracy of the attribute\nclassifier is not always correlated with its effectiveness in bias estimation\nfor a downstream model. In order to further investigate this phenomenon, we\nanalyze an idealized theoretical model and characterize the structure of the\noptimal classifier. Our analysis has surprising and counter-intuitive\nimplications where in certain regimes one might want to distribute the error of\nthe attribute classifier as unevenly as possible among the different subgroups.\nBased on our analysis we develop heuristics for both training and using\nattribute classifiers for bias estimation in the data scarce regime. We\nempirically demonstrate the effectiveness of our approach on real and simulated\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:02:55 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Beutel", "Alex", ""], ["Kleindessner", "Matthaeus", ""], ["Morgenstern", "Jamie", ""], ["Wang", "Xuezhi", ""]]}, {"id": "2102.08427", "submitter": "Wenting Zhao", "authors": "Wenting Zhao, Carla Gomes", "title": "Evaluating Multi-label Classifiers with Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-label classification (MLC) is a generalization of standard\nclassification where multiple labels may be assigned to a given sample. In the\nreal world, it is more common to deal with noisy datasets than clean datasets,\ngiven how modern datasets are labeled by a large group of annotators on\ncrowdsourcing platforms, but little attention has been given to evaluating\nmulti-label classifiers with noisy labels. Exploiting label correlations now\nbecomes a standard component of a multi-label classifier to achieve competitive\nperformance. However, this component makes the classifier more prone to poor\ngeneralization - it overfits labels as well as label dependencies. We identify\nthree common real-world label noise scenarios and show how previous approaches\nper-form poorly with noisy labels. To address this issue, we present a\nContext-Based Multi-LabelClassifier (CbMLC) that effectively handles noisy\nlabels when learning label dependencies, without requiring additional\nsupervision. We compare CbMLC against other domain-specific state-of-the-art\nmodels on a variety of datasets, under both the clean and the noisy settings.\nWe show CbMLC yields substantial improvements over the previous methods in most\ncases.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:50:52 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Zhao", "Wenting", ""], ["Gomes", "Carla", ""]]}, {"id": "2102.08446", "submitter": "Abhishek Shetty", "authors": "Nika Haghtalab, Tim Roughgarden, Abhishek Shetty", "title": "Smoothed Analysis with Adaptive Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove novel algorithmic guarantees for several online problems in the\nsmoothed analysis model. In this model, at each time an adversary chooses an\ninput distribution with density function bounded above by $\\tfrac{1}{\\sigma}$\ntimes that of the uniform distribution; nature then samples an input from this\ndistribution. Crucially, our results hold for {\\em adaptive} adversaries that\ncan choose an input distribution based on the decisions of the algorithm and\nthe realizations of the inputs in the previous time steps.\n  This paper presents a general technique for proving smoothed algorithmic\nguarantees against adaptive adversaries, in effect reducing the setting of\nadaptive adversaries to the simpler case of oblivious adversaries. We apply\nthis technique to prove strong smoothed guarantees for three problems:\n  -Online learning: We consider the online prediction problem, where instances\nare generated from an adaptive sequence of $\\sigma$-smooth distributions and\nthe hypothesis class has VC dimension $d$. We bound the regret by\n$\\tilde{O}\\big(\\sqrt{T d\\ln(1/\\sigma)} + d\\sqrt{\\ln(T/\\sigma)}\\big)$. This\nanswers open questions of [RST11,Hag18].\n  -Online discrepancy minimization: We consider the online Koml\\'os problem,\nwhere the input is generated from an adaptive sequence of $\\sigma$-smooth and\nisotropic distributions on the $\\ell_2$ unit ball. We bound the $\\ell_\\infty$\nnorm of the discrepancy vector by $\\tilde{O}\\big(\\ln^2\\!\\big(\n\\frac{nT}{\\sigma}\\big) \\big)$.\n  -Dispersion in online optimization: We consider online optimization of\npiecewise Lipschitz functions where functions with $\\ell$ discontinuities are\nchosen by a smoothed adaptive adversary and show that the resulting sequence is\n$\\big( {\\sigma}/{\\sqrt{T\\ell}}, \\tilde O\\big(\\sqrt{T\\ell}\n\\big)\\big)$-dispersed. This matches the parameters of [BDV18] for oblivious\nadversaries, up to log factors.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 20:54:49 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Haghtalab", "Nika", ""], ["Roughgarden", "Tim", ""], ["Shetty", "Abhishek", ""]]}, {"id": "2102.08452", "submitter": "Klas Leino", "authors": "Klas Leino, Zifan Wang, Matt Fredrikson", "title": "Globally-Robust Neural Networks", "comments": "Appearing in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threat of adversarial examples has motivated work on training certifiably\nrobust neural networks to facilitate efficient verification of local robustness\nat inference time. We formalize a notion of global robustness, which captures\nthe operational properties of on-line local robustness certification while\nyielding a natural learning objective for robust training. We show that\nwidely-used architectures can be easily adapted to this objective by\nincorporating efficient global Lipschitz bounds into the network, yielding\ncertifiably-robust models by construction that achieve state-of-the-art\nverifiable accuracy. Notably, this approach requires significantly less time\nand memory than recent certifiable training methods, and leads to negligible\ncosts when certifying points on-line; for example, our evaluation shows that it\nis possible to train a large robust Tiny-Imagenet model in a matter of hours.\nOur models effectively leverage inexpensive global Lipschitz bounds for\nreal-time certification, despite prior suggestions that tighter local bounds\nare needed for good performance; we posit this is possible because our models\nare specifically trained to achieve tighter global bounds. Namely, we prove\nthat the maximum achievable verifiable accuracy for a given dataset is not\nimproved by using a local bound.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 21:10:52 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 20:36:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Leino", "Klas", ""], ["Wang", "Zifan", ""], ["Fredrikson", "Matt", ""]]}, {"id": "2102.08454", "submitter": "Emily Diana", "authors": "Emily Diana, Wesley Gill, Ira Globus-Harris, Michael Kearns, Aaron\n  Roth and Saeed Sharifi-Malvajerdi", "title": "Lexicographically Fair Learning: Algorithms and Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the notion of minimax fairness in supervised learning problems to\nits natural conclusion: lexicographic minimax fairness (or lexifairness for\nshort). Informally, given a collection of demographic groups of interest,\nminimax fairness asks that the error of the group with the highest error be\nminimized. Lexifairness goes further and asks that amongst all minimax fair\nsolutions, the error of the group with the second highest error should be\nminimized, and amongst all of those solutions, the error of the group with the\nthird highest error should be minimized, and so on. Despite its naturalness,\ncorrectly defining lexifairness is considerably more subtle than minimax\nfairness, because of inherent sensitivity to approximation error. We give a\nnotion of approximate lexifairness that avoids this issue, and then derive\noracle-efficient algorithms for finding approximately lexifair solutions in a\nvery general setting. When the underlying empirical risk minimization problem\nabsent fairness constraints is convex (as it is, for example, with linear and\nlogistic regression), our algorithms are provably efficient even in the worst\ncase. Finally, we show generalization bounds -- approximate lexifairness on the\ntraining sample implies approximate lexifairness on the true distribution with\nhigh probability. Our ability to prove generalization bounds depends on our\nchoosing definitions that avoid the instability of naive definitions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 21:15:42 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Diana", "Emily", ""], ["Gill", "Wesley", ""], ["Globus-Harris", "Ira", ""], ["Kearns", "Michael", ""], ["Roth", "Aaron", ""], ["Sharifi-Malvajerdi", "Saeed", ""]]}, {"id": "2102.08474", "submitter": "Jia-Jie Zhu", "authors": "Jia-Jie Zhu, Christina Kouridi, Yassine Nemmour, Bernhard Sch\\\"olkopf", "title": "Adversarially Robust Kernel Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the adversarially robust kernel smoothing (ARKS) algorithm,\ncombining kernel smoothing, robust optimization, and adversarial training for\nrobust learning. Our methods are motivated by the convex analysis perspective\nof distributionally robust optimization based on probability metrics, such as\nthe Wasserstein distance and the maximum mean discrepancy. We adapt the\nintegral operator using supremal convolution in convex analysis to form a novel\nfunction majorant used for enforcing robustness. Our method is simple in form\nand applies to general loss functions and machine learning models. Furthermore,\nwe report experiments with general machine learning models, such as deep neural\nnetworks, to demonstrate that ARKS performs competitively with the\nstate-of-the-art methods based on the Wasserstein distance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 22:25:18 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 13:12:12 GMT"}, {"version": "v3", "created": "Sun, 4 Jul 2021 16:23:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhu", "Jia-Jie", ""], ["Kouridi", "Christina", ""], ["Nemmour", "Yassine", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2102.08498", "submitter": "Atif Raza", "authors": "Atif Raza, Stefan Kramer", "title": "Pattern Sampling for Shapelet-based Time Series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Subsequence-based time series classification algorithms provide accurate and\ninterpretable models, but training these models is extremely computation\nintensive. The asymptotic time complexity of subsequence-based algorithms\nremains a higher-order polynomial, because these algorithms are based on\nexhaustive search for highly discriminative subsequences. Pattern sampling has\nbeen proposed as an effective alternative to mitigate the pattern explosion\nphenomenon. Therefore, we employ pattern sampling to extract discriminative\nfeatures from discretized time series data. A weighted trie is created based on\nthe discretized time series data to sample highly discriminative patterns.\nThese sampled patterns are used to identify the shapelets which are used to\ntransform the time series classification problem into a feature-based\nclassification problem. Finally, a classification model can be trained using\nany off-the-shelf algorithm. Creating a pattern sampler requires a small number\nof patterns to be evaluated compared to an exhaustive search as employed by\nprevious approaches. Compared to previously proposed algorithms, our approach\nrequires considerably less computational and memory resources. Experiments\ndemonstrate how the proposed approach fares in terms of classification accuracy\nand runtime performance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 23:35:10 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Raza", "Atif", ""], ["Kramer", "Stefan", ""]]}, {"id": "2102.08501", "submitter": "Salem Lahlou", "authors": "Moksh Jain, Salem Lahlou, Hadi Nekoei, Victor Butoi, Paul Bertin,\n  Jarrid Rector-Brooks, Maksym Korablyov, Yoshua Bengio", "title": "DEUP: Direct Epistemic Uncertainty Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epistemic uncertainty is the part of out-of-sample prediction error due to\nthe lack of knowledge of the learner. Whereas previous work was focusing on\nmodel variance, we propose a principled approach for directly estimating\nepistemic uncertainty by learning to predict generalization error and\nsubtracting an estimate of aleatoric uncertainty, i.e., intrinsic\nunpredictability. This estimator of epistemic uncertainty includes the effect\nof model bias and can be applied in non-stationary learning environments\narising in active learning or reinforcement learning. In addition to\ndemonstrating these properties of Direct Epistemic Uncertainty Prediction\n(DEUP), we illustrate its advantage against existing methods for uncertainty\nestimation on downstream tasks including sequential model optimization and\nreinforcement learning. We also evaluate the quality of uncertainty estimates\nfrom DEUP for probabilistic classification of images and for estimating\nuncertainty about synergistic drug combinations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 23:50:35 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Jain", "Moksh", ""], ["Lahlou", "Salem", ""], ["Nekoei", "Hadi", ""], ["Butoi", "Victor", ""], ["Bertin", "Paul", ""], ["Rector-Brooks", "Jarrid", ""], ["Korablyov", "Maksym", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2102.08533", "submitter": "Aahlad Manas Puli", "authors": "Aahlad Puli, Adler J. Perotte, Rajesh Ranganath", "title": "Causal Estimation with Functional Confounders", "comments": "17 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference relies on two fundamental assumptions: ignorability and\npositivity. We study causal inference when the true confounder value can be\nexpressed as a function of the observed data; we call this setting estimation\nwith functional confounders (EFC). In this setting, ignorability is satisfied,\nhowever positivity is violated, and causal inference is impossible in general.\nWe consider two scenarios where causal effects are estimable. First, we discuss\ninterventions on a part of the treatment called functional interventions and a\nsufficient condition for effect estimation of these interventions called\nfunctional positivity. Second, we develop conditions for nonparametric effect\nestimation based on the gradient fields of the functional confounder and the\ntrue outcome function. To estimate effects under these conditions, we develop\nLevel-set Orthogonal Descent Estimation (LODE). Further, we prove error bounds\non LODE's effect estimates, evaluate our methods on simulated and real data,\nand empirically demonstrate the value of EFC.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 02:16:21 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Puli", "Aahlad", ""], ["Perotte", "Adler J.", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2102.08534", "submitter": "Eugene Seo", "authors": "Eugene Seo, Rebecca A. Hutchinson, Xiao Fu, Chelsea Li, Tyler A.\n  Hallman, John Kilbride, W. Douglas Robinson", "title": "StatEcoNet: Statistical Ecology Neural Networks for Species Distribution\n  Modeling", "comments": "To appear in the Proceeding of the 35th AAAI Conference on Artificial\n  Intelligence (AAAI-21); Added supplemental material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.PE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper focuses on a core task in computational sustainability and\nstatistical ecology: species distribution modeling (SDM). In SDM, the\noccurrence pattern of a species on a landscape is predicted by environmental\nfeatures based on observations at a set of locations. At first, SDM may appear\nto be a binary classification problem, and one might be inclined to employ\nclassic tools (e.g., logistic regression, support vector machines, neural\nnetworks) to tackle it. However, wildlife surveys introduce structured noise\n(especially under-counting) in the species observations. If unaccounted for,\nthese observation errors systematically bias SDMs. To address the unique\nchallenges of SDM, this paper proposes a framework called StatEcoNet.\nSpecifically, this work employs a graphical generative model in statistical\necology to serve as the skeleton of the proposed computational framework and\ncarefully integrates neural networks under the framework. The advantages of\nStatEcoNet over related approaches are demonstrated on simulated datasets as\nwell as bird species data. Since SDMs are critical tools for ecological science\nand natural resource management, StatEcoNet may offer boosted computational and\nanalytical powers to a wide range of applications that have significant social\nimpacts, e.g., the study and conservation of threatened species.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 02:19:00 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 04:37:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Seo", "Eugene", ""], ["Hutchinson", "Rebecca A.", ""], ["Fu", "Xiao", ""], ["Li", "Chelsea", ""], ["Hallman", "Tyler A.", ""], ["Kilbride", "John", ""], ["Robinson", "W. Douglas", ""]]}, {"id": "2102.08554", "submitter": "Ashish Katiyar", "authors": "Ashish Katiyar, Soumya Basu, Vatsal Shah, Constantine Caramanis", "title": "Recoverability Landscape of Tree Structured Markov Random Fields under\n  Symmetric Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of learning tree-structured Markov random fields (MRF)\non discrete random variables with common support when the observations are\ncorrupted by a $k$-ary symmetric noise channel with unknown probability of\nerror. For Ising models (support size = 2), past work has shown that graph\nstructure can only be recovered up to the leaf clusters (a leaf node, its\nparent, and its siblings form a leaf cluster) and exact recovery is impossible.\nNo prior work has addressed the setting of support size of 3 or more, and\nindeed this setting is far richer. As we show, when the support size is 3 or\nmore, the structure of the leaf clusters may be partially or fully\nidentifiable. We provide a precise characterization of this phenomenon and show\nthat the extent of recoverability is dictated by the joint PMF of the random\nvariables. In particular, we provide necessary and sufficient conditions for\nexact recoverability. Furthermore, we present a polynomial time, sample\nefficient algorithm that recovers the exact tree when this is possible, or up\nto the unidentifiability as promised by our characterization, when full\nrecoverability is impossible. Finally, we demonstrate the efficacy of our\nalgorithm experimentally.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 03:47:26 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 02:22:57 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 12:55:09 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Katiyar", "Ashish", ""], ["Basu", "Soumya", ""], ["Shah", "Vatsal", ""], ["Caramanis", "Constantine", ""]]}, {"id": "2102.08570", "submitter": "Tijana Zrnic", "authors": "John Miller, Juan C. Perdomo, Tijana Zrnic", "title": "Outside the Echo Chamber: Optimizing the Performative Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In performative prediction, predictions guide decision-making and hence can\ninfluence the distribution of future data. To date, work on performative\nprediction has focused on finding performatively stable models, which are the\nfixed points of repeated retraining. However, stable solutions can be far from\noptimal when evaluated in terms of the performative risk, the loss experienced\nby the decision maker when deploying a model. In this paper, we shift attention\nbeyond performative stability and focus on optimizing the performative risk\ndirectly. We identify a natural set of properties of the loss function and\nmodel-induced distribution shift under which the performative risk is convex, a\nproperty which does not follow from convexity of the loss alone. Furthermore,\nwe develop algorithms that leverage our structural assumptions to optimize the\nperformative risk with better sample efficiency than generic methods for\nderivative-free convex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 04:36:39 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 23:51:08 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Miller", "John", ""], ["Perdomo", "Juan C.", ""], ["Zrnic", "Tijana", ""]]}, {"id": "2102.08591", "submitter": "Anthony Christidis", "authors": "Anthony-Alexander Christidis, Stefan Van Aelst, Ruben Zamar", "title": "Data-Driven Diverse Logistic Regression Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel framework for statistical learning is introduced which combines ideas\nfrom regularization and ensembling. This framework is applied to learn an\nensemble of logistic regression models for high-dimensional binary\nclassification. In the new framework the models in the ensemble are learned\nsimultaneously by optimizing a multi-convex objective function. To enforce\ndiversity between the models the objective function penalizes overlap between\nthe models in the ensemble. Measures of diversity in classifier ensembles are\nused to show how our method learns the ensemble by exploiting the\naccuracy-diversity trade-off for ensemble models. In contrast to other\nensembling approaches, the resulting ensemble model is fully interpretable as a\nlogistic regression model, asymptotically consistent, and at the same time\nyields excellent prediction accuracy as demonstrated in an extensive simulation\nstudy and gene expression data applications. The models found by the proposed\nensemble methodology can also reveal alternative mechanisms that can explain\nthe relationship between the predictors and the response variable. An\nopen-source compiled software library implementing the proposed method is\nbriefly discussed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 05:57:26 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 05:58:10 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 20:00:37 GMT"}, {"version": "v4", "created": "Wed, 28 Jul 2021 04:12:02 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Christidis", "Anthony-Alexander", ""], ["Van Aelst", "Stefan", ""], ["Zamar", "Ruben", ""]]}, {"id": "2102.08606", "submitter": "Lemeng Wu", "authors": "Lemeng Wu, Xingchao Liu, Qiang Liu", "title": "Centroid Transformers: Learning to Abstract with Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention, as the key block of transformers, is a powerful mechanism for\nextracting features from the inputs. In essence, what self-attention does is to\ninfer the pairwise relations between the elements of the inputs, and modify the\ninputs by propagating information between input pairs. As a result, it maps\ninputs to N outputs and casts a quadratic $O(N^2)$ memory and time complexity.\nWe propose centroid attention, a generalization of self-attention that maps N\ninputs to M outputs $(M\\leq N)$, such that the key information in the inputs\nare summarized in the smaller number of outputs (called centroids). We design\ncentroid attention by amortizing the gradient descent update rule of a\nclustering objective function on the inputs, which reveals an underlying\nconnection between attention and clustering. By compressing the inputs to the\ncentroids, we extract the key information useful for prediction and also reduce\nthe computation of the attention module and the subsequent layers. We apply our\nmethod to various applications, including abstractive text summarization, 3D\nvision, and image processing. Empirical results demonstrate the effectiveness\nof our method over the standard transformers.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 07:04:19 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 14:34:27 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Wu", "Lemeng", ""], ["Liu", "Xingchao", ""], ["Liu", "Qiang", ""]]}, {"id": "2102.08607", "submitter": "Junyu Zhang", "authors": "Junyu Zhang, Chengzhuo Ni, Zheng Yu, Csaba Szepesvari, Mengdi Wang", "title": "On the Convergence and Sample Efficiency of Variance-Reduced Policy\n  Gradient Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Policy gradient (PG) gives rise to a rich class of reinforcement learning\n(RL) methods. Recently, there has been an emerging trend to accelerate the\nexisting PG methods such as REINFORCE by the \\emph{variance reduction}\ntechniques. However, all existing variance-reduced PG methods heavily rely on\nan uncheckable importance weight assumption made for every single iteration of\nthe algorithms. In this paper, a simple gradient truncation mechanism is\nproposed to address this issue. Moreover, we design a Truncated Stochastic\nIncremental Variance-Reduced Policy Gradient (TSIVR-PG) method, which is able\nto maximize not only a cumulative sum of rewards but also a general utility\nfunction over a policy's long-term visiting distribution. We show an\n$\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ sample complexity for TSIVR-PG to find an\n$\\epsilon$-stationary policy. By assuming the overparameterizaiton of policy\nand exploiting the hidden convexity of the problem, we further show that\nTSIVR-PG converges to global $\\epsilon$-optimal policy with\n$\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ samples.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 07:06:19 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 22:08:32 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zhang", "Junyu", ""], ["Ni", "Chengzhuo", ""], ["Yu", "Zheng", ""], ["Szepesvari", "Csaba", ""], ["Wang", "Mengdi", ""]]}, {"id": "2102.08622", "submitter": "Kai Sheng Tai", "authors": "Kai Sheng Tai, Peter Bailis, Gregory Valiant", "title": "Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed\n  Self-Training", "comments": "ICML 2021 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Self-training is a standard approach to semi-supervised learning where the\nlearner's own predictions on unlabeled data are used as supervision during\ntraining. In this paper, we reinterpret this label assignment process as an\noptimal transportation problem between examples and classes, wherein the cost\nof assigning an example to a class is mediated by the current predictions of\nthe classifier. This formulation facilitates a practical annealing strategy for\nlabel assignment and allows for the inclusion of prior knowledge on class\nproportions via flexible upper bound constraints. The solutions to these\nassignment problems can be efficiently approximated using Sinkhorn iteration,\nthus enabling their use in the inner loop of standard stochastic optimization\nalgorithms. We demonstrate the effectiveness of our algorithm on the CIFAR-10,\nCIFAR-100, and SVHN datasets in comparison with FixMatch, a state-of-the-art\nself-training algorithm. Our code is available at\nhttps://github.com/stanford-futuredata/sinkhorn-label-allocation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 08:23:15 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 00:07:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Tai", "Kai Sheng", ""], ["Bailis", "Peter", ""], ["Valiant", "Gregory", ""]]}, {"id": "2102.08649", "submitter": "Paul Viallard", "authors": "Paul Viallard (LHC), Pascal Germain, Amaury Habrard (LHC), Emilie\n  Morvant (LHC)", "title": "A General Framework for the Derandomization of PAC-Bayesian Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PAC-Bayesian bounds are known to be tight and informative when studying the\ngeneralization ability of randomized classifiers. However, when applied to some\nfamily of deterministic models such as neural networks, they require a loose\nand costly derandomization step. As an alternative to this step, we introduce\nthree new PAC-Bayesian generalization bounds that have the originality to be\npointwise, meaning that they provide guarantees over one single hypothesis\ninstead of the usual averaged analysis. Our bounds are rather general,\npotentially parameterizable, and provide novel insights for various machine\nlearning settings that rely on randomized algorithms. We illustrate the\ninterest of our theoretical result for the analysis of neural network training.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 09:36:46 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Viallard", "Paul", "", "LHC"], ["Germain", "Pascal", "", "LHC"], ["Habrard", "Amaury", "", "LHC"], ["Morvant", "Emilie", "", "LHC"]]}, {"id": "2102.08659", "submitter": "Marco Puts", "authors": "Marco J.H. Puts and Piet J.H. Daas", "title": "Unbiased Estimations based on Binary Classifiers: A Maximum Likelihood\n  Approach", "comments": "2 pages, 2 figures, SDSS symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Binary classifiers trained on a certain proportion of positive items\nintroduce a bias when applied to data sets with different proportions of\npositive items. Most solutions for dealing with this issue assume that some\ninformation on the latter distribution is known. However, this is not always\nthe case, certainly when this proportion is the target variable. In this paper\na maximum likelihood estimator for the true proportion of positives in data\nsets is suggested and tested on synthetic and real world data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 09:57:56 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Puts", "Marco J. H.", ""], ["Daas", "Piet J. H.", ""]]}, {"id": "2102.08668", "submitter": "Dan Mikulincer", "authors": "Ronen Eldan and Dan Mikulincer and Tselil Schramm", "title": "Non-asymptotic approximations of neural networks by Gaussian processes", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the extent to which wide neural networks may be approximated by\nGaussian processes when initialized with random weights. It is a\nwell-established fact that as the width of a network goes to infinity, its law\nconverges to that of a Gaussian process. We make this quantitative by\nestablishing explicit convergence rates for the central limit theorem in an\ninfinite-dimensional functional space, metrized with a natural transportation\ndistance. We identify two regimes of interest; when the activation function is\npolynomial, its degree determines the rate of convergence, while for\nnon-polynomial activations, the rate is governed by the smoothness of the\nfunction.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 10:19:26 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Eldan", "Ronen", ""], ["Mikulincer", "Dan", ""], ["Schramm", "Tselil", ""]]}, {"id": "2102.08685", "submitter": "Xiequan Fan", "authors": "Xiequan Fan, Pierre Alquier, Paul Doukhan", "title": "Deviation inequalities for stochastic approximation by averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of Markov chains, that contains the model of stochastic\napproximation by averaging and non-averaging. Using martingale approximation\nmethod, we establish various deviation inequalities for separately Lipschitz\nfunctions of such a chain, with different moment conditions on some dominating\nrandom variables of martingale differences.Finally, we apply these inequalities\nto the stochastic approximation by averaging.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 10:57:37 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Fan", "Xiequan", ""], ["Alquier", "Pierre", ""], ["Doukhan", "Paul", ""]]}, {"id": "2102.08754", "submitter": "Tommaso Cesari", "authors": "Nicol\\`o Cesa-Bianchi, Tommaso Cesari (TSE), Roberto Colomboni (IIT),\n  Federico Fusco, Stefano Leonardi", "title": "A Regret Analysis of Bilateral Trade", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.TH stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilateral trade, a fundamental topic in economics, models the problem of\nintermediating between two strategic agents, a seller and a buyer, willing to\ntrade a good for which they hold private valuations. Despite the simplicity of\nthis problem, a classical result by Myerson and Satterthwaite (1983) affirms\nthe impossibility of designing a mechanism which is simultaneously efficient,\nincentive compatible, individually rational, and budget balanced. This\nimpossibility result fostered an intense investigation of meaningful trade-offs\nbetween these desired properties. Much work has focused on approximately\nefficient fixed-price mechanisms, i.e., Blumrosen and Dobzinski (2014; 2016),\nColini-Baldeschi et al. (2016), which have been shown to fully characterize\nstrong budget balanced and ex-post individually rational direct revelation\nmechanisms. All these results, however, either assume some knowledge on the\npriors of the seller/buyer valuations, or a black box access to some samples of\nthe distributions, as in D{\\\"u}tting et al. (2021). In this paper, we cast for\nthe first time the bilateral trade problem in a regret minimization framework\nover rounds of seller/buyer interactions, with no prior knowledge on the\nprivate seller/buyer valuations. Our main contribution is a complete\ncharacterization of the regret regimes for fixed-price mechanisms with\ndifferent models of feedback and private valuations, using as benchmark the\nbest fixed price in hindsight. More precisely, we prove the following bounds on\nthe regret:\n  $\\bullet$ $\\widetilde{\\Theta}(\\sqrt{T})$ for full-feedback (i.e., direct\nrevelation mechanisms);\n  $\\bullet$ $\\widetilde{\\Theta}(T^{2/3})$ for realistic feedback (i.e.,\nposted-price mechanisms) and independent seller/buyer valuations with bounded\ndensities;\n  $\\bullet$ $\\Theta(T)$ for realistic feedback and seller/buyer valuations with\nbounded densities;\n  $\\bullet$ $\\Theta(T)$ for realistic feedback and independent seller/buyer\nvaluations;\n  $\\bullet$ $\\Theta(T)$ for the adversarial setting.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:53:17 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", "", "TSE"], ["Cesari", "Tommaso", "", "TSE"], ["Colomboni", "Roberto", "", "IIT"], ["Fusco", "Federico", ""], ["Leonardi", "Stefano", ""]]}, {"id": "2102.08759", "submitter": "Makoto Kawano", "authors": "Makoto Kawano, Wataru Kumagai, Akiyoshi Sannai, Yusuke Iwasawa and\n  Yutaka Matsuo", "title": "Group Equivariant Conditional Neural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the group equivariant conditional neural process (EquivCNP), a\nmeta-learning method with permutation invariance in a data set as in\nconventional conditional neural processes (CNPs), and it also has\ntransformation equivariance in data space. Incorporating group equivariance,\nsuch as rotation and scaling equivariance, provides a way to consider the\nsymmetry of real-world data. We give a decomposition theorem for\npermutation-invariant and group-equivariant maps, which leads us to construct\nEquivCNPs with an infinite-dimensional latent space to handle group symmetries.\nIn this paper, we build architecture using Lie group convolutional layers for\npractical implementation. We show that EquivCNP with translation equivariance\nachieves comparable performance to conventional CNPs in a 1D regression task.\nMoreover, we demonstrate that incorporating an appropriate Lie group\nequivariance, EquivCNP is capable of zero-shot generalization for an\nimage-completion task by selecting an appropriate Lie group equivariance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 13:50:07 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Kawano", "Makoto", ""], ["Kumagai", "Wataru", ""], ["Sannai", "Akiyoshi", ""], ["Iwasawa", "Yusuke", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "2102.08769", "submitter": "Benjamin Riu", "authors": "Karim Lounici, Katia Meziani and Benjamin Riu", "title": "Muddling Labels for Regularization, a novel approach to generalization", "comments": "arXiv admin note: text overlap with arXiv:2006.06705", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is a central problem in Machine Learning. Indeed most\nprediction methods require careful calibration of hyperparameters usually\ncarried out on a hold-out \\textit{validation} dataset to achieve\ngeneralization. The main goal of this paper is to introduce a novel approach to\nachieve generalization without any data splitting, which is based on a new risk\nmeasure which directly quantifies a model's tendency to overfit. To fully\nunderstand the intuition and advantages of this new approach, we illustrate it\nin the simple linear regression model ($Y=X\\beta+\\xi$) where we develop a new\ncriterion. We highlight how this criterion is a good proxy for the true\ngeneralization risk. Next, we derive different procedures which tackle several\nstructures simultaneously (correlation, sparsity,...). Noticeably, these\nprocedures \\textbf{concomitantly} train the model and calibrate the\nhyperparameters. In addition, these procedures can be implemented via classical\ngradient descent methods when the criterion is differentiable w.r.t. the\nhyperparameters. Our numerical experiments reveal that our procedures are\ncomputationally feasible and compare favorably to the popular approach (Ridge,\nLASSO and Elastic-Net combined with grid-search cross-validation) in term of\ngeneralization. They also outperform the baseline on two additional tasks:\nestimation and support recovery of $\\beta$. Moreover, our procedures do not\nrequire any expertise for the calibration of the initial parameters which\nremain the same for all the datasets we experimented on.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:02:30 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lounici", "Karim", ""], ["Meziani", "Katia", ""], ["Riu", "Benjamin", ""]]}, {"id": "2102.08791", "submitter": "J\\'ulio Hoffimann", "authors": "J\\'ulio Hoffimann, Maciel Zortea, Breno de Carvalho, Bianca Zadrozny", "title": "Geostatistical Learning: Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical learning theory provides the foundation to applied machine\nlearning, and its various successful applications in computer vision, natural\nlanguage processing and other scientific domains. The theory, however, does not\ntake into account the unique challenges of performing statistical learning in\ngeospatial settings. For instance, it is well known that model errors cannot be\nassumed to be independent and identically distributed in geospatial (a.k.a.\nregionalized) variables due to spatial correlation; and trends caused by\ngeophysical processes lead to covariate shifts between the domain where the\nmodel was trained and the domain where it will be applied, which in turn harm\nthe use of classical learning methodologies that rely on random samples of the\ndata. In this work, we introduce the geostatistical (transfer) learning\nproblem, and illustrate the challenges of learning from geospatial data by\nassessing widely-used methods for estimating generalization error of learning\nmodels, under covariate shift and spatial correlation. Experiments with\nsynthetic Gaussian process data as well as with real data from geophysical\nsurveys in New Zealand indicate that none of the methods are adequate for model\nselection in a geospatial context. We provide general guidelines regarding the\nchoice of these methods in practice while new methods are being actively\nresearched.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:33:15 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Hoffimann", "J\u00falio", ""], ["Zortea", "Maciel", ""], ["de Carvalho", "Breno", ""], ["Zadrozny", "Bianca", ""]]}, {"id": "2102.08792", "submitter": "Thijs van de Laar PhD", "authors": "Thijs van de Laar, Ismail Senoz, Ay\\c{c}a \\\"Oz\\c{c}elikkale, Henk\n  Wymeersch", "title": "Chance-Constrained Active Inference", "comments": null, "journal-ref": null, "doi": "10.1162/neco_a_01427", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Inference (ActInf) is an emerging theory that explains perception and\naction in biological agents, in terms of minimizing a free energy bound on\nBayesian surprise. Goal-directed behavior is elicited by introducing prior\nbeliefs on the underlying generative model. In contrast to prior beliefs, which\nconstrain all realizations of a random variable, we propose an alternative\napproach through chance constraints, which allow for a (typically small)\nprobability of constraint violation, and demonstrate how such constraints can\nbe used as intrinsic drivers for goal-directed behavior in ActInf. We\nillustrate how chance-constrained ActInf weights all imposed (prior)\nconstraints on the generative model, allowing e.g., for a trade-off between\nrobust control and empirical chance constraint violation. Secondly, we\ninterpret the proposed solution within a message passing framework.\nInterestingly, the message passing interpretation is not only relevant to the\ncontext of ActInf, but also provides a general purpose approach that can\naccount for chance constraints on graphical models. The chance constraint\nmessage updates can then be readily combined with other pre-derived message\nupdate rules, without the need for custom derivations. The proposed\nchance-constrained message passing framework thus accelerates the search for\nworkable models in general, and can be used to complement message-passing\nformulations on generative neural models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:36:40 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 13:18:26 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["van de Laar", "Thijs", ""], ["Senoz", "Ismail", ""], ["\u00d6z\u00e7elikkale", "Ay\u00e7a", ""], ["Wymeersch", "Henk", ""]]}, {"id": "2102.08817", "submitter": "Florian Graf", "authors": "Florian Graf, Christoph D. Hofer, Marc Niethammer, Roland Kwitt", "title": "Dissecting Supervised Contrastive Learning", "comments": "ICML 2021 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing cross-entropy over the softmax scores of a linear map composed\nwith a high-capacity encoder is arguably the most popular choice for training\nneural networks on supervised learning tasks. However, recent works show that\none can directly optimize the encoder instead, to obtain equally (or even more)\ndiscriminative representations via a supervised variant of a contrastive\nobjective. In this work, we address the question whether there are fundamental\ndifferences in the sought-for representation geometry in the output space of\nthe encoder at minimal loss. Specifically, we prove, under mild assumptions,\nthat both losses attain their minimum once the representations of each class\ncollapse to the vertices of a regular simplex, inscribed in a hypersphere. We\nprovide empirical evidence that this configuration is attained in practice and\nthat reaching a close-to-optimal state typically indicates good generalization\nperformance. Yet, the two losses show remarkably different optimization\nbehavior. The number of iterations required to perfectly fit to data scales\nsuperlinearly with the amount of randomly flipped labels for the supervised\ncontrastive loss. This is in contrast to the approximately linear scaling\npreviously reported for networks trained with cross-entropy.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 15:22:38 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 09:37:31 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 13:03:07 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Graf", "Florian", ""], ["Hofer", "Christoph D.", ""], ["Niethammer", "Marc", ""], ["Kwitt", "Roland", ""]]}, {"id": "2102.08868", "submitter": "Fartash Faghri", "authors": "Fartash Faghri, Sven Gowal, Cristina Vasconcelos, David J. Fleet,\n  Fabian Pedregosa, Nicolas Le Roux", "title": "Bridging the Gap Between Adversarial Robustness and Optimization Bias", "comments": "New CIFAR-10 experiments and Fourier attack variations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that the choice of optimizer, neural network architecture, and\nregularizer significantly affect the adversarial robustness of linear neural\nnetworks, providing guarantees without the need for adversarial training. To\nthis end, we revisit a known result linking maximally robust classifiers and\nminimum norm solutions, and combine it with recent results on the implicit bias\nof optimizers. First, we show that, under certain conditions, it is possible to\nachieve both perfect standard accuracy and a certain degree of robustness,\nsimply by training an overparametrized model using the implicit bias of the\noptimization. In that regime, there is a direct relationship between the type\nof the optimizer and the attack to which the model is robust. To the best of\nour knowledge, this work is the first to study the impact of optimization\nmethods such as sign gradient descent and proximal methods on adversarial\nrobustness. Second, we characterize the robustness of linear convolutional\nmodels, showing that they resist attacks subject to a constraint on the\nFourier-$\\ell_\\infty$ norm. To illustrate these findings we design a novel\nFourier-$\\ell_\\infty$ attack that finds adversarial examples with controllable\nfrequencies. We evaluate Fourier-$\\ell_\\infty$ robustness of\nadversarially-trained deep CIFAR-10 models from the standard RobustBench\nbenchmark and visualize adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 16:58:04 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:27:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Faghri", "Fartash", ""], ["Gowal", "Sven", ""], ["Vasconcelos", "Cristina", ""], ["Fleet", "David J.", ""], ["Pedregosa", "Fabian", ""], ["Roux", "Nicolas Le", ""]]}, {"id": "2102.08895", "submitter": "Hanbyul Lee", "authors": "Hanbyul Lee and Kevin Bello and Jean Honorio", "title": "On the Fundamental Limits of Exact Inference in Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference is a main task in structured prediction and it is naturally modeled\nwith a graph. In the context of Markov random fields, noisy observations\ncorresponding to nodes and edges are usually involved, and the goal of exact\ninference is to recover the unknown true label for each node precisely. The\nfocus of this paper is on the fundamental limits of exact recovery irrespective\nof computational efficiency, assuming the generative process proposed by\nGloberson et al. (2015). We derive the necessary condition for any algorithm\nand the sufficient condition for maximum likelihood estimation to achieve exact\nrecovery with high probability, and reveal that the sufficient and necessary\nconditions are tight up to a logarithmic factor for a wide range of graphs.\nFinally, we show that there exists a gap between the fundamental limits and the\nperformance of the computationally tractable method of Bello and Honorio\n(2019), which implies the need for further development of algorithms for exact\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 17:44:21 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lee", "Hanbyul", ""], ["Bello", "Kevin", ""], ["Honorio", "Jean", ""]]}, {"id": "2102.08897", "submitter": "Wenyu Zhang", "authors": "Wenyu Zhang, Mohamed Ragab, Ramon Sagarna", "title": "Robust Domain-Free Domain Generalization with Class-aware Alignment", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While deep neural networks demonstrate state-of-the-art performance on a\nvariety of learning tasks, their performance relies on the assumption that\ntrain and test distributions are the same, which may not hold in real-world\napplications. Domain generalization addresses this issue by employing multiple\nsource domains to build robust models that can generalize to unseen target\ndomains subject to shifts in data distribution. In this paper, we propose\nDomain-Free Domain Generalization (DFDG), a model-agnostic method to achieve\nbetter generalization performance on the unseen test domain without the need\nfor source domain labels. DFDG uses novel strategies to learn domain-invariant\nclass-discriminative features. It aligns class relationships of samples through\nclass-conditional soft labels, and uses saliency maps, traditionally developed\nfor post-hoc analysis of image classification networks, to remove superficial\nobservations from training inputs. DFDG obtains competitive performance on both\ntime series sensor and image classification public datasets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 17:46:06 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Zhang", "Wenyu", ""], ["Ragab", "Mohamed", ""], ["Sagarna", "Ramon", ""]]}, {"id": "2102.08903", "submitter": "Yulai Zhao", "authors": "Yulai Zhao, Yuandong Tian, Jason D. Lee, Simon S. Du", "title": "Provably Efficient Policy Gradient Methods for Two-Player Zero-Sum\n  Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Policy gradient methods are widely used in solving two-player zero-sum games\nto achieve superhuman performance in practice. However, it remains elusive when\nthey can provably find a near-optimal solution and how many samples and\niterations are needed. The current paper studies natural extensions of Natural\nPolicy Gradient algorithm for solving two-player zero-sum games where function\napproximation is used for generalization across states. We thoroughly\ncharacterize the algorithms' performance in terms of the number of samples,\nnumber of iterations, concentrability coefficients, and approximation error. To\nour knowledge, this is the first quantitative analysis of policy gradient\nmethods with function approximation for two-player zero-sum Markov games.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 17:49:57 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Zhao", "Yulai", ""], ["Tian", "Yuandong", ""], ["Lee", "Jason D.", ""], ["Du", "Simon S.", ""]]}, {"id": "2102.08907", "submitter": "Wenyu Zhang", "authors": "Wenyu Zhang", "title": "POLA: Online Time Series Prediction by Adaptive Learning Rates", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online prediction for streaming time series data has practical use for many\nreal-world applications where downstream decisions depend on accurate forecasts\nfor the future. Deployment in dynamic environments requires models to adapt\nquickly to changing data distributions without overfitting. We propose POLA\n(Predicting Online by Learning rate Adaptation) to automatically regulate the\nlearning rate of recurrent neural network models to adapt to changing time\nseries patterns across time. POLA meta-learns the learning rate of the\nstochastic gradient descent (SGD) algorithm by assimilating the prequential or\ninterleaved-test-then-train evaluation scheme for online prediction. We\nevaluate POLA on two real-world datasets across three commonly-used recurrent\nneural network models. POLA demonstrates overall comparable or better\npredictive performance over other online prediction methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 17:56:12 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Zhang", "Wenyu", ""]]}, {"id": "2102.08921", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa, Boris van Breugel, Evgeny Saveliev, Mihaela van der\n  Schaar", "title": "How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating\n  and Auditing Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devising domain- and model-agnostic evaluation metrics for generative models\nis an important and as yet unresolved problem. Most existing metrics, which\nwere tailored solely to the image synthesis setup, exhibit a limited capacity\nfor diagnosing the different modes of failure of generative models across\nbroader application domains. In this paper, we introduce a 3-dimensional\nevaluation metric, ($\\alpha$-Precision, $\\beta$-Recall, Authenticity), that\ncharacterizes the fidelity, diversity and generalization performance of any\ngenerative model in a domain-agnostic fashion. Our metric unifies statistical\ndivergence measures with precision-recall analysis, enabling sample- and\ndistribution-level diagnoses of model fidelity and diversity. We introduce\ngeneralization as an additional, independent dimension (to the\nfidelity-diversity trade-off) that quantifies the extent to which a model\ncopies training data -- a crucial performance indicator when modeling sensitive\ndata with requirements on privacy. The three metric components correspond to\n(interpretable) probabilistic quantities, and are estimated via sample-level\nbinary classification. The sample-level nature of our metric inspires a novel\nuse case which we call model auditing, wherein we judge the quality of\nindividual samples generated by a (black-box) model, discarding low-quality\nsamples and hence improving the overall model performance in a post-hoc manner.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 18:25:30 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["van Breugel", "Boris", ""], ["Saveliev", "Evgeny", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2102.08940", "submitter": "Quanquan Gu", "authors": "Jiafan He and Dongruo Zhou and Quanquan Gu", "title": "Nearly Optimal Regret for Learning Adversarial MDPs with Linear Function\n  Approximation", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reinforcement learning for finite-horizon episodic Markov\ndecision processes with adversarial reward and full information feedback, where\nthe unknown transition probability function is a linear function of a given\nfeature mapping. We propose an optimistic policy optimization algorithm with\nBernstein bonus and show that it can achieve $\\tilde{O}(dH\\sqrt{T})$ regret,\nwhere $H$ is the length of the episode, $T$ is the number of interaction with\nthe MDP and $d$ is the dimension of the feature mapping. Furthermore, we also\nprove a matching lower bound of $\\tilde{\\Omega}(dH\\sqrt{T})$ up to logarithmic\nfactors. To the best of our knowledge, this is the first computationally\nefficient, nearly minimax optimal algorithm for adversarial Markov decision\nprocesses with linear function approximation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 18:54:08 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["He", "Jiafan", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "2102.08991", "submitter": "Leonardo Banchi", "authors": "Leonardo Banchi, Jason Pereira, Stefano Pirandola", "title": "Generalization in Quantum Machine Learning: a Quantum Information\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the machine learning problem of generalization when quantum\noperations are used to classify either classical data or quantum channels,\nwhere in both cases the task is to learn from data how to assign a certain\nclass $c$ to inputs $x$ via measurements on a quantum state $\\rho(x)$. A\ntrained quantum model generalizes when it is able to predict the correct class\nfor previously unseen data. We show that the accuracy and generalization\ncapability of quantum classifiers depend on the (R\\'enyi) mutual informations\n$I(C{:}Q)$ and $I_2(X{:}Q)$ between the quantum embedding $Q$ and the classical\ninput space $X$ or class space $C$. Based on the above characterization, we\nthen show how different properties of $Q$ affect classification accuracy and\ngeneralization, such as the dimension of the Hilbert space, the amount of\nnoise, and the amount of neglected information via, e.g., pooling layers.\nMoreover, we introduce a quantum version of the Information Bottleneck\nprinciple that allows us to explore the various tradeoffs between accuracy and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 19:35:21 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Banchi", "Leonardo", ""], ["Pereira", "Jason", ""], ["Pirandola", "Stefano", ""]]}, {"id": "2102.08993", "submitter": "Takuya Kanazawa", "authors": "Takuya Kanazawa", "title": "Using Distance Correlation for Efficient Bayesian Optimization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for Bayesian optimization, called\n$\\textsf{GP-DC}$, which combines Gaussian processes with distance correlation.\nIt balances exploration and exploitation automatically, and requires no manual\nparameter tuning. We evaluate $\\textsf{GP-DC}$ on a number of benchmark\nfunctions and observe that it outperforms state-of-the-art methods such as\n$\\textsf{GP-UCB}$ and max-value entropy search, as well as the classical\nexpected improvement heuristic. We also apply $\\textsf{GP-DC}$ to optimize\nsequential integral observations with a variable integration range and verify\nits empirical efficiency on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 19:37:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kanazawa", "Takuya", ""]]}, {"id": "2102.09009", "submitter": "Louis Tiao", "authors": "Louis C. Tiao, Aaron Klein, Matthias Seeger, Edwin V. Bonilla, Cedric\n  Archambeau, Fabio Ramos", "title": "BORE: Bayesian Optimization by Density-Ratio Estimation", "comments": "preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian optimization (BO) is among the most effective and widely-used\nblackbox optimization methods. BO proposes solutions according to an\nexplore-exploit trade-off criterion encoded in an acquisition function, many of\nwhich are computed from the posterior predictive of a probabilistic surrogate\nmodel. Prevalent among these is the expected improvement (EI) function. The\nneed to ensure analytical tractability of the predictive often poses\nlimitations that can hinder the efficiency and applicability of BO. In this\npaper, we cast the computation of EI as a binary classification problem,\nbuilding on the link between class-probability estimation and density-ratio\nestimation, and the lesser-known link between density-ratios and EI. By\ncircumventing the tractability constraints, this reformulation provides\nnumerous advantages, not least in terms of expressiveness, versatility, and\nscalability.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 20:04:11 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Tiao", "Louis C.", ""], ["Klein", "Aaron", ""], ["Seeger", "Matthias", ""], ["Bonilla", "Edwin V.", ""], ["Archambeau", "Cedric", ""], ["Ramos", "Fabio", ""]]}, {"id": "2102.09030", "submitter": "Nhuong Nguyen", "authors": "Marten van Dijk, Nhuong V. Nguyen, Toan N. Nguyen, Lam M. Nguyen and\n  Phuong Ha Nguyen", "title": "Bringing Differential Private SGD to Practice: On the Independence of\n  Gaussian Noise and the Number of Training Rounds", "comments": "arXiv admin note: text overlap with arXiv:2007.09208", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the context of DP-SGD each round communicates a local SGD update which\nleaks some new information about the underlying local data set to the outside\nworld. In order to provide privacy, Gaussian noise is added to local SGD\nupdates. However, privacy leakage still aggregates over multiple training\nrounds. Therefore, in order to control privacy leakage over an increasing\nnumber of training rounds, we need to increase the added Gaussian noise per\nlocal SGD update. This dependence of the amount of Gaussian noise $\\sigma$ on\nthe number of training rounds $T$ may impose an impractical upper bound on $T$\n(because $\\sigma$ cannot be too large) leading to a low accuracy global model\n(because the global model receives too few local SGD updates). DP-SGD much less\ncompetitive compared to other existing privacy techniques.\n  We show for the first time that for $(\\epsilon,\\delta)$-differential privacy\n$\\sigma$ can be chosen equal to $\\sqrt{2(\\epsilon +\\ln(1/\\delta))/\\epsilon}$\nregardless the total number of training rounds $T$. In other words, $\\sigma$\ndoes not depend on $T$ anymore (and aggregation of privacy leakage increases to\na limit). This important discovery brings DP-SGD to practice because $\\sigma$\ncan remain small to make the trained model have high accuracy even for large\n$T$ as usually happens in practice.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 21:19:39 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 21:05:08 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["van Dijk", "Marten", ""], ["Nguyen", "Nhuong V.", ""], ["Nguyen", "Toan N.", ""], ["Nguyen", "Lam M.", ""], ["Nguyen", "Phuong Ha", ""]]}, {"id": "2102.09042", "submitter": "Ali Hasan", "authors": "Ali Hasan, Khalil Elkhalil, Joao M. Pereira, Sina Farsiu, Jose H.\n  Blanchet, Vahid Tarokh", "title": "Deep Extreme Value Copulas for Estimation and Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new method for modeling the distribution function of high\ndimensional extreme value distributions. The Pickands dependence function\nmodels the relationship between the covariates in the tails, and we learn this\nfunction using a neural network that is designed to satisfy its required\nproperties. Moreover, we present new methods for recovering the spectral\nrepresentation of extreme distributions and propose a generative model for\nsampling from extreme copulas. Numerical examples are provided demonstrating\nthe efficacy and promise of our proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 22:02:47 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hasan", "Ali", ""], ["Elkhalil", "Khalil", ""], ["Pereira", "Joao M.", ""], ["Farsiu", "Sina", ""], ["Blanchet", "Jose H.", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2102.09111", "submitter": "Dan Li", "authors": "Dan Li, Dariush Fooladivanda, Sonia Martinez", "title": "Online Optimization and Learning in Uncertain Dynamical Environments\n  with Performance Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.DS math.OC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework to solve online optimization and learning problems\nin unknown and uncertain dynamical environments. This framework enables us to\nsimultaneously learn the uncertain dynamical environment while making online\ndecisions in a quantifiably robust manner. The main technical approach relies\non the theory of distributional robust optimization that leverages adaptive\nprobabilistic ambiguity sets. However, as defined, the ambiguity set usually\nleads to online intractable problems, and the first part of our work is\ndirected to find reformulations in the form of online convex problems for two\nsub-classes of objective functions. To solve the resulting problems in the\nproposed framework, we further introduce an online version of the Nesterov\naccelerated-gradient algorithm. We determine how the proposed solution system\nachieves a probabilistic regret bound under certain conditions. Two\napplications illustrate the applicability of the proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 01:49:06 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Li", "Dan", ""], ["Fooladivanda", "Dariush", ""], ["Martinez", "Sonia", ""]]}, {"id": "2102.09159", "submitter": "Sewoong Oh", "authors": "Xiyang Liu, Weihao Kong, Sham Kakade, and Sewoong Oh", "title": "Robust and Differentially Private Mean Estimation", "comments": "55 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differential privacy has emerged as a standard requirement in a variety of\napplications ranging from the U.S. Census to data collected in commercial\ndevices, initiating an extensive line of research in accurately and privately\nreleasing statistics of a database. An increasing number of such databases\nconsist of data from multiple sources, not all of which can be trusted. This\nleaves existing private analyses vulnerable to attacks by an adversary who\ninjects corrupted data. Despite the significance of designing algorithms that\nguarantee privacy and robustness (to a fraction of data being corrupted)\nsimultaneously, even the simplest questions remain open. For the canonical\nproblem of estimating the mean from i.i.d. samples, we introduce the first\nefficient algorithm that achieves both privacy and robustness for a wide range\nof distributions. This achieves optimal accuracy matching the known lower\nbounds for robustness, but the sample complexity has a factor of $d^{1/2}$ gap\nfrom known lower bounds. We further show that this gap is due to the\ncomputational efficiency; we introduce the first family of algorithms that\nclose this gap but takes exponential time. The innovation is in exploiting\nresilience (a key property in robust estimation) to adaptively bound the\nsensitivity and improve privacy.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 05:02:49 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Liu", "Xiyang", ""], ["Kong", "Weihao", ""], ["Kakade", "Sham", ""], ["Oh", "Sewoong", ""]]}, {"id": "2102.09191", "submitter": "Yasunori Akagi", "authors": "Yasunori Akagi, Naoki Marumo, Hideaki Kim, Takeshi Kurashima and\n  Hiroyuki Toda", "title": "Non-approximate Inference for Collective Graphical Models on Path Graphs\n  via Discrete Difference of Convex Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of aggregated count data, which is calculated from the data of\nmultiple individuals, continues to increase. Collective Graphical Model (CGM)\nis a probabilistic approach to the analysis of aggregated data. One of the most\nimportant operations in CGM is maximum a posteriori (MAP) inference of\nunobserved variables under given observations. Because the MAP inference\nproblem for general CGMs has been shown to be NP-hard, an approach that solves\nan approximate problem has been proposed. However, this approach has two major\ndrawbacks. First, the quality of the solution deteriorates when the values in\nthe count tables are small, because the approximation becomes inaccurate.\nSecond, since continuous relaxation is applied, the integrality constraints of\nthe output are violated. To resolve these problems, this paper proposes a new\nmethod for MAP inference for CGMs on path graphs. First we show that the MAP\ninference problem can be formulated as a (non-linear) minimum cost flow\nproblem. Then, we apply Difference of Convex Algorithm (DCA), which is a\ngeneral methodology to minimize a function represented as the sum of a convex\nfunction and a concave function. In our algorithm, important subroutines in DCA\ncan be efficiently calculated by minimum convex cost flow algorithms.\nExperiments show that the proposed method outputs higher quality solutions than\nthe conventional approach.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 07:28:18 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Akagi", "Yasunori", ""], ["Marumo", "Naoki", ""], ["Kim", "Hideaki", ""], ["Kurashima", "Takeshi", ""], ["Toda", "Hiroyuki", ""]]}, {"id": "2102.09198", "submitter": "Andrey Y. Lokhov", "authors": "Christopher X. Ren, Sidhant Misra, Marc Vuffray, Andrey Y. Lokhov", "title": "Learning Continuous Exponential Families Beyond Gaussian", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning of continuous exponential family\ndistributions with unbounded support. While a lot of progress has been made on\nlearning of Gaussian graphical models, we are still lacking scalable algorithms\nfor reconstructing general continuous exponential families modeling\nhigher-order moments of the data beyond the mean and the covariance. Here, we\nintroduce a computationally efficient method for learning continuous graphical\nmodels based on the Interaction Screening approach. Through a series of\nnumerical experiments, we show that our estimator maintains similar\nrequirements in terms of accuracy and sample complexity compared to alternative\napproaches such as maximization of conditional likelihood, while considerably\nimproving upon the algorithm's run-time.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 07:44:53 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Ren", "Christopher X.", ""], ["Misra", "Sidhant", ""], ["Vuffray", "Marc", ""], ["Lokhov", "Andrey Y.", ""]]}, {"id": "2102.09204", "submitter": "Hugo Lavenant", "authors": "Hugo Lavenant, Stephen Zhang, Young-Heon Kim, Geoffrey Schiebinger", "title": "Towards a mathematical theory of trajectory inference", "comments": "The first two authors contributed equally to this work; 62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise a theoretical framework and a numerical method to infer\ntrajectories of a stochastic process from snapshots of its temporal marginals.\nThis problem arises in the analysis of single cell RNA-sequencing data, which\nprovide high dimensional measurements of cell states but cannot track the\ntrajectories of the cells over time. We prove that for a class of stochastic\nprocesses it is possible to recover the ground truth trajectories from limited\nsamples of the temporal marginals at each time-point, and provide an efficient\nalgorithm to do so in practice. The method we develop, Global Waddington-OT\n(gWOT), boils down to a smooth convex optimization problem posed globally over\nall time-points involving entropy-regularized optimal transport. We demonstrate\nthat this problem can be solved efficiently in practice and yields good\nreconstructions, as we show on several synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 07:58:47 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Lavenant", "Hugo", ""], ["Zhang", "Stephen", ""], ["Kim", "Young-Heon", ""], ["Schiebinger", "Geoffrey", ""]]}, {"id": "2102.09210", "submitter": "Yuma Iwasaki", "authors": "Yuma Iwasaki and Masahiko Ishida", "title": "Data-driven formulation of natural laws by recursive-LASSO-based\n  symbolic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of new natural laws has for a long time relied on the inspiration\nof some genius. Recently, however, machine learning technologies, which analyze\nbig data without human prejudice and bias, are expected to find novel natural\nlaws. Here we demonstrate that our proposed machine learning,\nrecursive-LASSO-based symbolic (RLS) regression, enables data-driven\nformulation of natural laws from noisy data. The RLS regression recurrently\nrepeats feature generation and feature selection, eventually constructing a\ndata-driven model with highly nonlinear features. This data-driven formulation\nmethod is quite general and thus can discover new laws in various scientific\nfields.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 08:20:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Iwasaki", "Yuma", ""], ["Ishida", "Masahiko", ""]]}, {"id": "2102.09225", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor and Jonas Mueller and Kavosh Asadi and Pratik Chaudhari\n  and Alexander J. Smola", "title": "Continuous Doubly Constrained Batch Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliant on too many experiments to learn good actions, current Reinforcement\nLearning (RL) algorithms have limited applicability in real-world settings,\nwhich can be too expensive to allow exploration. We propose an algorithm for\nbatch RL, where effective policies are learned using only a fixed offline\ndataset instead of online interactions with the environment. The limited data\nin batch RL produces inherent uncertainty in value estimates of states/actions\nthat were insufficiently represented in the training data. This leads to\nparticularly severe extrapolation when our candidate policies diverge from one\nthat generated the data. We propose to mitigate this issue via two\nstraightforward penalties: a policy-constraint to reduce this divergence and a\nvalue-constraint that discourages overly optimistic estimates. Over a\ncomprehensive set of 32 continuous-action batch RL benchmarks, our approach\ncompares favorably to state-of-the-art methods, regardless of how the offline\ndata were collected.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 08:54:14 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 10:34:35 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 09:26:19 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Fakoor", "Rasool", ""], ["Mueller", "Jonas", ""], ["Asadi", "Kavosh", ""], ["Chaudhari", "Pratik", ""], ["Smola", "Alexander J.", ""]]}, {"id": "2102.09232", "submitter": "Wei-Ting Lai", "authors": "Wei-Ting Lai, Ray-Bing Chen, Ying Chen, Thorsten Koch", "title": "The Variational Bayesian Inference for Network Autoregression Models", "comments": "40 pages, 38 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a variational Bayesian (VB) approach for estimating large-scale\ndynamic network models in the network autoregression framework. The VB approach\nallows for the automatic identification of the dynamic structure of such a\nmodel and obtains a direct approximation of the posterior density. Compared to\nMarkov Chain Monte Carlo (MCMC) based sampling approaches, the VB approach\nachieves enhanced computational efficiency without sacrificing estimation\naccuracy. In the simulation study conducted here, the proposed VB approach\ndetects various types of proper active structures for dynamic network models.\nCompared to the alternative approach, the proposed method achieves similar or\nbetter accuracy, and its computational time is halved. In a real data analysis\nscenario of day-ahead natural gas flow prediction in the German gas\ntransmission network with 51 nodes between October 2013 and September 2015, the\nVB approach delivers promising forecasting accuracy along with clearly detected\nstructures in terms of dynamic dependence.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 09:26:39 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Lai", "Wei-Ting", ""], ["Chen", "Ray-Bing", ""], ["Chen", "Ying", ""], ["Koch", "Thorsten", ""]]}, {"id": "2102.09235", "submitter": "Shihua Zhang", "authors": "Kuo Gai and Shihua Zhang", "title": "A Mathematical Principle of Deep Learning: Learn the Geodesic Curve in\n  the Wasserstein Space", "comments": "40 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies revealed the mathematical connection of deep neural network\n(DNN) and dynamic system. However, the fundamental principle of DNN has not\nbeen fully characterized with dynamic system in terms of optimization and\ngeneralization. To this end, we build the connection of DNN and continuity\nequation where the measure is conserved to model the forward propagation\nprocess of DNN which has not been addressed before. DNN learns the\ntransformation of the input distribution to the output one. However, in the\nmeasure space, there are infinite curves connecting two distributions. Which\none can lead to good optimization and generaliztion for DNN? By diving the\noptimal transport theory, we find DNN with weight decay attempts to learn the\ngeodesic curve in the Wasserstein space, which is induced by the optimal\ntransport map. Compared with plain network, ResNet is a better approximation to\nthe geodesic curve, which explains why ResNet can be optimized and generalize\nbetter. Numerical experiments show that the data tracks of both plain network\nand ResNet tend to be line-shape in term of line-shape score (LSS), and the map\nlearned by ResNet is closer to the optimal transport map in term of optimal\ntransport score (OTS). In a word, we conclude a mathematical principle of deep\nlearning is to learn the geodesic curve in the Wasserstein space; and deep\nlearning is a great engineering realization of continuous transformation in\nhigh-dimensional space.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 09:37:49 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 01:54:06 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gai", "Kuo", ""], ["Zhang", "Shihua", ""]]}, {"id": "2102.09260", "submitter": "Milan Straka", "authors": "Milan Straka, Lucia Piatrikov\\'a, Peter van Bokhoven, \\v{L}ubo\\v{s}\n  Buzna", "title": "A matrix approach to detect temporal behavioral patterns at electric\n  vehicle charging stations", "comments": "8 pages, 5 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the electric vehicle (EV) arrival times and the duration of EV\nconnection to the charging station, we identify charging patterns and derive\ngroups of charging stations with similar charging patterns applying two\napproaches. The ruled based approach derives the charging patterns by\nspecifying a set of time intervals and a threshold value. In the second\napproach, we combine the modified l-p norm (as a matrix dissimilarity measure)\nwith hierarchical clustering and apply them to automatically identify charging\npatterns and groups of charging stations associated with such patterns. A\ndataset collected in a large network of public charging stations is used to\ntest both approaches. Using both methods, we derived charging patterns. The\nfirst, rule-based approach, performed well at deriving predefined patterns and\nthe latter, hierarchical clustering, showed the capability of delivering\nunexpected charging patterns.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 10:37:32 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Straka", "Milan", ""], ["Piatrikov\u00e1", "Lucia", ""], ["van Bokhoven", "Peter", ""], ["Buzna", "\u013dubo\u0161", ""]]}, {"id": "2102.09270", "submitter": "Lucas Theis", "authors": "Lucas Theis and Eirikur Agustsson", "title": "On the advantages of stochastic encoders", "comments": null, "journal-ref": "ICLR 2021 Neural Compression Workshop", "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic encoders have been used in rate-distortion theory and neural\ncompression because they can be easier to handle. However, in performance\ncomparisons with deterministic encoders they often do worse, suggesting that\nnoise in the encoding process may generally be a bad idea. It is poorly\nunderstood if and when stochastic encoders do better than deterministic\nencoders. In this paper we provide one illustrative example which shows that\nstochastic encoders can significantly outperform the best deterministic\nencoders. Our toy example suggests that stochastic encoders may be particularly\nuseful in the regime of \"perfect perceptual quality\".\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 11:09:51 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 10:21:48 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Theis", "Lucas", ""], ["Agustsson", "Eirikur", ""]]}, {"id": "2102.09305", "submitter": "Karan Singh", "authors": "Elad Hazan, Karan Singh", "title": "Boosting for Online Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider the decision-making framework of online convex optimization with\na very large number of experts. This setting is ubiquitous in contextual and\nreinforcement learning problems, where the size of the policy class renders\nenumeration and search within the policy class infeasible.\n  Instead, we consider generalizing the methodology of online boosting. We\ndefine a weak learning algorithm as a mechanism that guarantees\nmultiplicatively approximate regret against a base class of experts. In this\naccess model, we give an efficient boosting algorithm that guarantees\nnear-optimal regret against the convex hull of the base class. We consider both\nfull and partial (a.k.a. bandit) information feedback models. We also give an\nanalogous efficient boosting algorithm for the i.i.d. statistical setting.\n  Our results simultaneously generalize online boosting and gradient boosting\nguarantees to contextual learning model, online convex optimization and bandit\nlinear optimization settings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 12:30:49 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hazan", "Elad", ""], ["Singh", "Karan", ""]]}, {"id": "2102.09310", "submitter": "Alexander Shekhovtsov", "authors": "Dmitrij Schlesinger, Alexander Shekhovtsov, Boris Flach", "title": "VAE Approximation Error: ELBO and Conditional Independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The importance of Variational Autoencoders reaches far beyond standalone\ngenerative models -- the approach is also used for learning latent\nrepresentations and can be generalized to semi-supervised learning. This\nrequires a thorough analysis of their commonly known shortcomings: posterior\ncollapse and approximation errors. This paper analyzes VAE approximation errors\ncaused by the combination of the ELBO objective with the choice of the encoder\nprobability family, in particular under conditional independence assumptions.\nWe identify the subclass of generative models consistent with the encoder\nfamily. We show that the ELBO optimizer is pulled from the likelihood optimizer\ntowards this consistent subset. Furthermore, this subset can not be enlarged,\nand the respective error cannot be decreased, by only considering deeper\nencoder networks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 12:54:42 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Schlesinger", "Dmitrij", ""], ["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""]]}, {"id": "2102.09318", "submitter": "Zaiwei Chen", "authors": "Sajad Khodadadian, Zaiwei Chen, and Siva Theja Maguluri", "title": "Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we provide finite-sample convergence guarantees for an\noff-policy variant of the natural actor-critic (NAC) algorithm based on\nImportance Sampling. In particular, we show that the algorithm converges to a\nglobal optimal policy with a sample complexity of\n$\\mathcal{O}(\\epsilon^{-3}\\log^2(1/\\epsilon))$ under an appropriate choice of\nstepsizes. In order to overcome the issue of large variance due to Importance\nSampling, we propose the $Q$-trace algorithm for the critic, which is inspired\nby the V-trace algorithm \\cite{espeholt2018impala}. This enables us to\nexplicitly control the bias and variance, and characterize the trade-off\nbetween them. As an advantage of off-policy sampling, a major feature of our\nresult is that we do not need any additional assumptions, beyond the ergodicity\nof the Markov chain induced by the behavior policy.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 13:22:59 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 19:17:04 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Khodadadian", "Sajad", ""], ["Chen", "Zaiwei", ""], ["Maguluri", "Siva Theja", ""]]}, {"id": "2102.09393", "submitter": "Xiaoyu Wang", "authors": "Xiaoyu Wang, Sindri Magn\\'usson and Mikael Johansson", "title": "On the Convergence of Step Decay Step-Size for Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence of stochastic gradient descent is highly dependent on the\nstep-size, especially on non-convex problems such as neural network training.\nStep decay step-size schedules (constant and then cut) are widely used in\npractice because of their excellent convergence and generalization qualities,\nbut their theoretical properties are not yet well understood. We provide the\nconvergence results for step decay in the non-convex regime, ensuring that the\ngradient norm vanishes at an $\\mathcal{O}(\\ln T/\\sqrt{T})$ rate. We also\nprovide the convergence guarantees for general (possibly non-smooth) convex\nproblems, ensuring an $\\mathcal{O}(\\ln T/\\sqrt{T})$ convergence rate. Finally,\nin the strongly convex case, we establish an $\\mathcal{O}(\\ln T/T)$ rate for\nsmooth problems, which we also prove to be tight, and an $\\mathcal{O}(\\ln^2 T\n/T)$ rate without the smoothness assumption. We illustrate the practical\nefficiency of the step decay step-size in several large scale deep neural\nnetwork training tasks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 14:37:25 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Wang", "Xiaoyu", ""], ["Magn\u00fasson", "Sindri", ""], ["Johansson", "Mikael", ""]]}, {"id": "2102.09468", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Yuanhao Wang, Laurent Lessard, Roger Grosse", "title": "Near-optimal Local Convergence of Alternating Gradient Descent-Ascent\n  for Minimax Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smooth minimax games often proceed by simultaneous or alternating gradient\nupdates. Although algorithms with alternating updates are commonly used in\npractice for many applications (e.g., GAN training), the majority of existing\ntheoretical analyses focus on simultaneous algorithms for convenience of\nanalysis. In this paper, we study alternating gradient descent-ascent (Alt-GDA)\nin minimax games and show that Alt-GDA is superior to its simultaneous\ncounterpart (Sim-GDA) in many settings. In particular, we prove that Alt-GDA\nachieves a near-optimal local convergence rate for strongly convex-strongly\nconcave (SCSC) problems while Sim-GDA converges at a much slower rate. To our\nknowledge, this is the \\emph{first} result of any setting showing that Alt-GDA\nconverges faster than Sim-GDA by more than a constant. We further prove that\nthe acceleration effect of alternating updates remains when the minimax problem\nhas only strong concavity in the dual variables. Lastly, we adapt the theory of\nintegral quadratic constraints and show that Alt-GDA attains the same rate\n\\emph{globally} for a class of SCSC minimax problems. Numerical experiments on\nquadratic minimax games validate our claims. Empirically, we demonstrate that\nalternating updates speed up GAN training significantly and the use of optimism\nonly helps for simultaneous algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 16:39:35 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 17:00:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Guodong", ""], ["Wang", "Yuanhao", ""], ["Lessard", "Laurent", ""], ["Grosse", "Roger", ""]]}, {"id": "2102.09492", "submitter": "Gaurush Hiranandani", "authors": "Gaurush Hiranandani, Jatin Mathur, Harikrishna Narasimhan, Mahdi\n  Milani Fard, Oluwasanmi Koyejo", "title": "Optimizing Black-box Metrics with Iterative Example Weighting", "comments": "The paper to appear at ICML 2021. This version includes the\n  camera-ready edits. 42 pages, 2 figures, and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning to optimize a classification metric defined by a\nblack-box function of the confusion matrix. Such black-box learning settings\nare ubiquitous, for example, when the learner only has query access to the\nmetric of interest, or in noisy-label and domain adaptation applications where\nthe learner must evaluate the metric via performance evaluation using a small\nvalidation sample. Our approach is to adaptively learn example weights on the\ntraining dataset such that the resulting weighted objective best approximates\nthe metric on the validation sample. We show how to model and estimate the\nexample weights and use them to iteratively post-shift a pre-trained class\nprobability estimator to construct a classifier. We also analyze the resulting\nprocedure's statistical properties. Experiments on various label noise, domain\nshift, and fair classification setups confirm that our proposal compares\nfavorably to the state-of-the-art baselines for each application.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 17:19:09 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 22:30:49 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Hiranandani", "Gaurush", ""], ["Mathur", "Jatin", ""], ["Narasimhan", "Harikrishna", ""], ["Fard", "Mahdi Milani", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "2102.09504", "submitter": "David Obst", "authors": "David Obst and Badih Ghattas and Jairo Cugliari and Georges Oppenheim\n  and Sandra Claudel and Yannig Goude", "title": "Transfer Learning for Linear Regression: a Statistical Test of Gain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning, also referred as knowledge transfer, aims at reusing\nknowledge from a source dataset to a similar target one. While many empirical\nstudies illustrate the benefits of transfer learning, few theoretical results\nare established especially for regression problems. In this paper a theoretical\nframework for the problem of parameter transfer for the linear model is\nproposed. It is shown that the quality of transfer for a new input vector $x$\ndepends on its representation in an eigenbasis involving the parameters of the\nproblem. Furthermore a statistical test is constructed to predict whether a\nfine-tuned model has a lower prediction quadratic risk than the base target\nmodel for an unobserved sample. Efficiency of the test is illustrated on\nsynthetic data as well as real electricity consumption data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 17:46:26 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Obst", "David", ""], ["Ghattas", "Badih", ""], ["Cugliari", "Jairo", ""], ["Oppenheim", "Georges", ""], ["Claudel", "Sandra", ""], ["Goude", "Yannig", ""]]}, {"id": "2102.09526", "submitter": "Tapio Helin", "authors": "Tatiana A. Bubba and Martin Burger and Tapio Helin and Luca Ratti", "title": "Convex regularization in statistical inverse learning problems", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a statistical inverse learning problem, where the task is to\nestimate a function $f$ based on noisy point evaluations of $Af$, where $A$ is\na linear operator. The function $Af$ is evaluated at i.i.d. random design\npoints $u_n$, $n=1,...,N$ generated by an unknown general probability\ndistribution. We consider Tikhonov regularization with general convex and\n$p$-homogeneous penalty functionals and derive concentration rates of the\nregularized solution to the ground truth measured in the symmetric Bregman\ndistance induced by the penalty functional. We derive concrete rates for Besov\nnorm penalties and numerically demonstrate the correspondence with the observed\nrates in the context of X-ray tomography.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:12:08 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 07:29:17 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bubba", "Tatiana A.", ""], ["Burger", "Martin", ""], ["Helin", "Tapio", ""], ["Ratti", "Luca", ""]]}, {"id": "2102.09540", "submitter": "Nikos Karampatziakis", "authors": "Nikos Karampatziakis, Paul Mineiro, Aaditya Ramdas", "title": "Off-policy Confidence Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop confidence bounds that hold uniformly over time for off-policy\nevaluation in the contextual bandit setting. These confidence sequences are\nbased on recent ideas from martingale analysis and are non-asymptotic,\nnon-parametric, and valid at arbitrary stopping times. We provide algorithms\nfor computing these confidence sequences that strike a good balance between\ncomputational and statistical efficiency. We empirically demonstrate the\ntightness of our approach in terms of failure probability and width and apply\nit to the \"gated deployment\" problem of safely upgrading a production\ncontextual bandit system.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:40:30 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Karampatziakis", "Nikos", ""], ["Mineiro", "Paul", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2102.09544", "submitter": "Christopher Morris", "authors": "Quentin Cappart, Didier Ch\\'etelat, Elias Khalil, Andrea Lodi,\n  Christopher Morris, Petar Veli\\v{c}kovi\\'c", "title": "Combinatorial optimization and reasoning with graph neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization is a well-established area in operations research\nand computer science. Until recently, its methods have focused on solving\nproblem instances in isolation, ignoring the fact that they often stem from\nrelated data distributions in practice. However, recent years have seen a surge\nof interest in using machine learning, especially graph neural networks (GNNs),\nas a key building block for combinatorial tasks, either directly as solvers or\nby enhancing exact solvers. The inductive bias of GNNs effectively encodes\ncombinatorial and relational input due to their invariance to permutations and\nawareness of input sparsity. This paper presents a conceptual review of recent\nkey advancements in this emerging field, aiming at researchers in both\noptimization and machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:47:20 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 23:47:38 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Cappart", "Quentin", ""], ["Ch\u00e9telat", "Didier", ""], ["Khalil", "Elias", ""], ["Lodi", "Andrea", ""], ["Morris", "Christopher", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "2102.09560", "submitter": "Juan Sosa", "authors": "Juan Sosa and Brenda Betancourt", "title": "A Latent Space Model for Multilayer Network Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a Bayesian statistical model to simultaneously\ncharacterize two or more social networks defined over a common set of actors.\nThe key feature of the model is a hierarchical prior distribution that allows\nus to represent the entire system jointly, achieving a compromise between\ndependent and independent networks. Among others things, such a specification\neasily allows us to visualize multilayer network data in a low-dimensional\nEuclidean space, generate a weighted network that reflects the consensus\naffinity between actors, establish a measure of correlation between networks,\nassess cognitive judgements that subjects form about the relationships among\nactors, and perform clustering tasks at different social instances. Our model's\ncapabilities are illustrated using several real-world data sets, taking into\naccount different types of actors, sizes, and relations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 00:53:44 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Sosa", "Juan", ""], ["Betancourt", "Brenda", ""]]}, {"id": "2102.09612", "submitter": "Ka Kin Lam", "authors": "Ka Kin Lam, Bo Wang", "title": "Multipopulation mortality modelling and forecasting: The multivariate\n  functional principal component with time weightings approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human mortality patterns and trajectories in closely related populations are\nlikely linked together and share similarities. It is always desirable to model\nthem simultaneously while taking their heterogeneity into account. This paper\nintroduces two new models for joint mortality modelling and forecasting\nmultiple subpopulations in adaptations of the multivariate functional principal\ncomponent analysis techniques. The first model extends the independent\nfunctional data model to a multi-population modelling setting. In the second\none, we propose a novel multivariate functional principal component method for\ncoherent modelling. Its design primarily fulfils the idea that when several\nsubpopulation groups have similar socio-economic conditions or common\nbiological characteristics, such close connections are expected to evolve in a\nnon-diverging fashion. We demonstrate the proposed methods by using\nsex-specific mortality data. Their forecast performances are further compared\nwith several existing models, including the independent functional data model\nand the Product-Ratio model, through comparisons with mortality data of ten\ndeveloped countries. Our experiment results show that the first proposed model\nmaintains a comparable forecast ability with the existing methods. In contrast,\nthe second proposed model outperforms the first model as well as the current\nmodels in terms of forecast accuracy, in addition to several desirable\nproperties.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 21:01:58 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Lam", "Ka Kin", ""], ["Wang", "Bo", ""]]}, {"id": "2102.09626", "submitter": "Wenjie Li", "authors": "Wenjie Li and Adarsh Barik and Jean Honorio", "title": "A Simple Unified Framework for High Dimensional Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic high dimensional bandit problems with low dimensional structures\nare useful in different applications such as online advertising and drug\ndiscovery. In this work, we propose a simple unified algorithm for such\nproblems and present a general analysis framework for the regret upper bound of\nour algorithm. We show that under some mild unified assumptions, our algorithm\ncan be applied to different high dimensional bandit problems. Our framework\nutilizes the low dimensional structure to guide the parameter estimation in the\nproblem, therefore our algorithm achieves the best regret bounds in the LASSO\nbandit, as well as novel bounds in the low-rank matrix bandit, the group sparse\nmatrix bandit, and in a new problem: the multi-agent LASSO bandit.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 21:35:32 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 04:39:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Wenjie", ""], ["Barik", "Adarsh", ""], ["Honorio", "Jean", ""]]}, {"id": "2102.09645", "submitter": "Sharan Vaswani", "authors": "Benjamin Dubois-Taine, Sharan Vaswani, Reza Babanezhad, Mark Schmidt,\n  Simon Lacoste-Julien", "title": "SVRG Meets AdaGrad: Painless Variance Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variance reduction (VR) methods for finite-sum minimization typically require\nthe knowledge of problem-dependent constants that are often unknown and\ndifficult to estimate. To address this, we use ideas from adaptive gradient\nmethods to propose AdaSVRG, which is a fully adaptive variant of SVRG, a common\nVR method. AdaSVRG uses AdaGrad in the inner loop of SVRG, making it robust to\nthe choice of step-size, and allowing it to adaptively determine the length of\neach inner-loop. When minimizing a sum of $n$ smooth convex functions, we prove\nthat AdaSVRG requires $O(n + 1/\\epsilon)$ gradient evaluations to achieve an\n$\\epsilon$-suboptimality, matching the typical rate, but without needing to\nknow problem-dependent constants. However, VR methods including AdaSVRG are\nslower than SGD when used with over-parameterized models capable of\ninterpolating the training data. Hence, we also propose a hybrid algorithm that\ncan adaptively switch from AdaGrad to AdaSVRG, achieving the best of both\nstochastic gradient and VR methods, but without needing to tune their\nstep-sizes. Via experiments on synthetic and standard real-world datasets, we\nvalidate the robustness and effectiveness of AdaSVRG, demonstrating its\nsuperior performance over other \"tune-free\" VR methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 22:26:19 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Dubois-Taine", "Benjamin", ""], ["Vaswani", "Sharan", ""], ["Babanezhad", "Reza", ""], ["Schmidt", "Mark", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2102.09669", "submitter": "Daniel Sousa", "authors": "Daniel Sousa, Christopher Small", "title": "Joint Characterization of Multiscale Information in High Dimensional\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML physics.data-an physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High dimensional data can contain multiple scales of variance. Analysis tools\nthat preferentially operate at one scale can be ineffective at capturing all\nthe information present in this cross-scale complexity. We propose a multiscale\njoint characterization approach designed to exploit synergies between global\nand local approaches to dimensionality reduction. We illustrate this approach\nusing Principal Components Analysis (PCA) to characterize global variance\nstructure and t-stochastic neighbor embedding (t-sne) to characterize local\nvariance structure. Using both synthetic images and real-world imaging\nspectroscopy data, we show that joint characterization is capable of detecting\nand isolating signals which are not evident from either PCA or t-sne alone.\nBroadly, t-sne is effective at rendering a randomly oriented low-dimensional\nmap of local clusters, and PCA renders this map interpretable by providing\nglobal, physically meaningful structure. This approach is illustrated using\nimaging spectroscopy data, and may prove particularly useful for other\ngeospatial data given robust local variance structure due to spatial\nautocorrelation and physical interpretability of global variance structure due\nto spectral properties of Earth surface materials. However, the fundamental\npremise could easily be extended to other high dimensional datasets, including\nimage time series and non-image data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:33:00 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Sousa", "Daniel", ""], ["Small", "Christopher", ""]]}, {"id": "2102.09671", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen, Pierre Brechet, Marco Mondelli", "title": "On Connectivity of Solutions in Deep Learning: The Role of\n  Over-parameterization and Feature Quality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been empirically observed that, in deep neural networks, the solutions\nfound by stochastic gradient descent from different random initializations can\nbe often connected by a path with low loss. Recent works have shed light on\nthis intriguing phenomenon by assuming either the over-parameterization of the\nnetwork or the dropout stability of the solutions. In this paper, we reconcile\nthese two views and present a novel condition for ensuring the connectivity of\ntwo arbitrary points in parameter space. This condition is provably milder than\ndropout stability, and it provides a connection between the problem of finding\nlow-loss paths and the memorization capacity of neural nets. This last point\nbrings about a trade-off between the quality of features at each layer and the\nover-parameterization of the network. As an extreme example of this trade-off,\nwe show that (i) if subsets of features at each layer are linearly separable,\nthen almost no over-parameterization is needed, and (ii) under generic\nassumptions on the features at each layer, it suffices that the last two hidden\nlayers have $\\Omega(\\sqrt{N})$ neurons, $N$ being the number of samples.\nFinally, we provide experimental evidence demonstrating that the presented\ncondition is satisfied in practical settings even when dropout stability does\nnot hold.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:44:08 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Nguyen", "Quynh", ""], ["Brechet", "Pierre", ""], ["Mondelli", "Marco", ""]]}, {"id": "2102.09672", "submitter": "Prafulla Dhariwal", "authors": "Alex Nichol, Prafulla Dhariwal", "title": "Improved Denoising Diffusion Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising diffusion probabilistic models (DDPM) are a class of generative\nmodels which have recently been shown to produce excellent samples. We show\nthat with a few simple modifications, DDPMs can also achieve competitive\nlog-likelihoods while maintaining high sample quality. Additionally, we find\nthat learning variances of the reverse diffusion process allows sampling with\nan order of magnitude fewer forward passes with a negligible difference in\nsample quality, which is important for the practical deployment of these\nmodels. We additionally use precision and recall to compare how well DDPMs and\nGANs cover the target distribution. Finally, we show that the sample quality\nand likelihood of these models scale smoothly with model capacity and training\ncompute, making them easily scalable. We release our code at\nhttps://github.com/openai/improved-diffusion\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:44:17 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Nichol", "Alex", ""], ["Dhariwal", "Prafulla", ""]]}, {"id": "2102.09676", "submitter": "Ka Kin Lam", "authors": "Ka Kin Lam, Bo Wang", "title": "Robust non-parametric mortality and fertility modelling and forecasting:\n  Gaussian process regression approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A rapid decline in mortality and fertility has become major issues in many\ndeveloped countries over the past few decades. A precise model for forecasting\ndemographic movements is important for decision making in social welfare\npolicies and resource budgeting among the government and many industry sectors.\nThis article introduces a novel non-parametric approach using Gaussian process\nregression with a natural cubic spline mean function and a spectral mixture\ncovariance function for mortality and fertility modelling and forecasting.\nUnlike most of the existing approaches in demographic modelling literature,\nwhich rely on time parameters to decide the movements of the whole mortality or\nfertility curve shifting from one year to another over time, we consider the\nmortality and fertility curves from their components of all age-specific\nmortality and fertility rates and assume each of them following a Gaussian\nprocess over time to fit the whole curves in a discrete but intensive style.\nThe proposed Gaussian process regression approach shows significant\nimprovements in terms of preciseness and robustness compared to other\nmainstream demographic modelling approaches in the short-, mid- and long-term\nforecasting using the mortality and fertility data of several developed\ncountries in our numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:49:25 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Lam", "Ka Kin", ""], ["Wang", "Bo", ""]]}, {"id": "2102.09685", "submitter": "Massimiliano Esposito", "authors": "Massimiliano Esposito, Nader Ganaba", "title": "Convolutional Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As the deep neural networks are being applied to complex tasks, the size of\nthe networks and architecture increases and their topology becomes more\ncomplicated too. At the same time, training becomes slow and at some instances\ninefficient. This motivated the introduction of various normalization\ntechniques such as Batch Normalization and Layer Normalization. The\naforementioned normalization methods use arithmetic operations to compute an\napproximation statistics (mainly the first and second moments) of the layer's\ndata and use it to normalize it. The aforementioned methods use plain Monte\nCarlo method to approximate the statistics and such method fails when\napproximating the statistics whose distribution is complex. Here, we propose an\napproach that uses weighted sum, implemented using depth-wise convolutional\nneural networks, to not only approximate the statistics, but to learn the\ncoefficients of the sum.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 00:14:56 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Esposito", "Massimiliano", ""], ["Ganaba", "Nader", ""]]}, {"id": "2102.09718", "submitter": "Shashank Rajput", "authors": "Shashank Rajput, Kangwook Lee, Dimitris Papailiopoulos", "title": "Permutation-Based SGD: Is Random Optimal?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of ground-breaking results for permutation-based SGD has\ncorroborated a widely observed phenomenon: random permutations offer faster\nconvergence than with-replacement sampling. However, is random optimal? We show\nthat this depends heavily on what functions we are optimizing, and the\nconvergence gap between optimal and random permutations can vary from\nexponential to nonexistent. We first show that for 1-dimensional strongly\nconvex functions, with smooth second derivatives, there exist optimal\npermutations that offer exponentially faster convergence compared to random.\nHowever, for general strongly convex functions, random permutations are\noptimal. Finally, we show that for quadratic, strongly-convex functions, there\nare easy-to-construct permutations that lead to accelerated convergence\ncompared to random. Our results suggest that a general convergence\ncharacterization of optimal permutations cannot capture the nuances of\nindividual function classes, and can mistakenly indicate that one cannot do\nmuch better than random.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 03:14:28 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Rajput", "Shashank", ""], ["Lee", "Kangwook", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "2102.09759", "submitter": "Nishant Kumar", "authors": "Nishant Kumar, Martin Raubal", "title": "Applications of deep learning in traffic congestion alleviation: A\n  survey", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction tasks related to congestion are targeted at improving the level of\nservice of the transportation network. With increasing access to larger\ndatasets of higher resolution, the relevance of deep learning in such\nprediction tasks, is increasing. Several comprehensive survey papers in recent\nyears have summarised the deep learning applications in the transportation\ndomain. However, the system dynamics of the transportation network vary greatly\nbetween the non-congested state and the congested state -- thereby\nnecessitating the need for a clear understanding of the challenges specific to\ncongestion prediction. In this survey, we present the current state of deep\nlearning applications in the tasks related to detection, prediction and\npropagation of congestion. Recurrent and non-recurrent congestion are discussed\nseparately. Our survey leads us to uncover inherent challenges and gaps in the\ncurrent state of research. Finally, we present some suggestions for future\nresearch directions as answers to the identified challenges.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 06:23:35 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Kumar", "Nishant", ""], ["Raubal", "Martin", ""]]}, {"id": "2102.09844", "submitter": "Victor Garcia Satorras", "authors": "Victor Garcia Satorras, Emiel Hoogeboom, Max Welling", "title": "E(n) Equivariant Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new model to learn graph neural networks equivariant\nto rotations, translations, reflections and permutations called\nE(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing\nmethods, our work does not require computationally expensive higher-order\nrepresentations in intermediate layers while it still achieves competitive or\nbetter performance. In addition, whereas existing methods are limited to\nequivariance on 3 dimensional spaces, our model is easily scaled to\nhigher-dimensional spaces. We demonstrate the effectiveness of our method on\ndynamical systems modelling, representation learning in graph autoencoders and\npredicting molecular properties.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:25:33 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 16:09:17 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Satorras", "Victor Garcia", ""], ["Hoogeboom", "Emiel", ""], ["Welling", "Max", ""]]}, {"id": "2102.09854", "submitter": "Sao Mai Nguyen", "authors": "Nicolas Duminy (Lab-STICC), Sao Mai Nguyen (U2IS), Junshuai Zhu (IMT\n  Atlantique), Dominique Duhaut (UBS), Jerome Kerdreux (Lab-STICC)", "title": "Intrinsically Motivated Open-Ended Multi-Task Learning Using Transfer\n  Learning to Discover Task Hierarchy", "comments": null, "journal-ref": "Applied Sciences, MDPI, 2021, 11 (3), pp.975", "doi": "10.3390/app11030975", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open-ended continuous environments, robots need to learn multiple\nparameterised control tasks in hierarchical reinforcement learning. We\nhypothesise that the most complex tasks can be learned more easily by\ntransferring knowledge from simpler tasks, and faster by adapting the\ncomplexity of the actions to the task. We propose a task-oriented\nrepresentation of complex actions, called procedures, to learn online task\nrelationships and unbounded sequences of action primitives to control the\ndifferent observables of the environment. Combining both goal-babbling with\nimitation learning, and active learning with transfer of knowledge based on\nintrinsic motivation, our algorithm self-organises its learning process. It\nchooses at any given time a task to focus on; and what, how, when and from whom\nto transfer knowledge. We show with a simulation and a real industrial robot\narm, in cross-task and cross-learner transfer settings, that task composition\nis key to tackle highly complex tasks. Task decomposition is also efficiently\ntransferred across different embodied learners and by active imitation, where\nthe robot requests just a small amount of demonstrations and the adequate type\nof information. The robot learns and exploits task dependencies so as to learn\ntasks of every complexity.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:44:08 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Duminy", "Nicolas", "", "Lab-STICC"], ["Nguyen", "Sao Mai", "", "U2IS"], ["Zhu", "Junshuai", "", "IMT\n  Atlantique"], ["Duhaut", "Dominique", "", "UBS"], ["Kerdreux", "Jerome", "", "Lab-STICC"]]}, {"id": "2102.09864", "submitter": "Chlo\\'e Rouyer", "authors": "Chlo\\'e Rouyer, Yevgeny Seldin, Nicol\\`o Cesa-Bianchi", "title": "An Algorithm for Stochastic and Adversarial Bandits with Switching Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for stochastic and adversarial multiarmed bandits\nwith switching costs, where the algorithm pays a price $\\lambda$ every time it\nswitches the arm being played. Our algorithm is based on adaptation of the\nTsallis-INF algorithm of Zimmert and Seldin (2021) and requires no prior\nknowledge of the regime or time horizon. In the oblivious adversarial setting\nit achieves the minimax optimal regret bound of $O\\big((\\lambda K)^{1/3}T^{2/3}\n+ \\sqrt{KT}\\big)$, where $T$ is the time horizon and $K$ is the number of arms.\nIn the stochastically constrained adversarial regime, which includes the\nstochastic regime as a special case, it achieves a regret bound of\n$O\\left(\\big((\\lambda K)^{2/3} T^{1/3} + \\ln T\\big)\\sum_{i \\neq i^*}\n\\Delta_i^{-1}\\right)$, where $\\Delta_i$ are the suboptimality gaps and $i^*$ is\na unique optimal arm. In the special case of $\\lambda = 0$ (no switching\ncosts), both bounds are minimax optimal within constants. We also explore\nvariants of the problem, where switching cost is allowed to change over time.\nWe provide experimental evaluation showing competitiveness of our algorithm\nwith the relevant baselines in the stochastic, stochastically constrained\nadversarial, and adversarial regimes with fixed switching cost.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 11:03:51 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Rouyer", "Chlo\u00e9", ""], ["Seldin", "Yevgeny", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""]]}, {"id": "2102.09907", "submitter": "Luofeng Liao", "authors": "Luofeng Liao, Zuyue Fu, Zhuoran Yang, Yixin Wang, Mladen Kolar,\n  Zhaoran Wang", "title": "Instrumental Variable Value Iteration for Causal Offline Reinforcement\n  Learning", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In offline reinforcement learning (RL) an optimal policy is learnt solely\nfrom a priori collected observational data. However, in observational data,\nactions are often confounded by unobserved variables. Instrumental variables\n(IVs), in the context of RL, are the variables whose influence on the state\nvariables are all mediated through the action. When a valid instrument is\npresent, we can recover the confounded transition dynamics through\nobservational data. We study a confounded Markov decision process where the\ntransition dynamics admit an additive nonlinear functional form. Using IVs, we\nderive a conditional moment restriction (CMR) through which we can identify\ntransition dynamics based on observational data. We propose a provably\nefficient IV-aided Value Iteration (IVVI) algorithm based on a primal-dual\nreformulation of CMR. To the best of our knowledge, this is the first provably\nefficient algorithm for instrument-aided offline RL.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 13:01:40 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 03:22:57 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Liao", "Luofeng", ""], ["Fu", "Zuyue", ""], ["Yang", "Zhuoran", ""], ["Wang", "Yixin", ""], ["Kolar", "Mladen", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2102.09972", "submitter": "Noam Razin", "authors": "Noam Razin, Asaf Maman, Nadav Cohen", "title": "Implicit Regularization in Tensor Factorization", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts to unravel the mystery of implicit regularization in deep\nlearning have led to a theoretical focus on matrix factorization -- matrix\ncompletion via linear neural network. As a step further towards practical deep\nlearning, we provide the first theoretical analysis of implicit regularization\nin tensor factorization -- tensor completion via certain type of non-linear\nneural network. We circumvent the notorious difficulty of tensor problems by\nadopting a dynamical systems perspective, and characterizing the evolution\ninduced by gradient descent. The characterization suggests a form of greedy low\ntensor rank search, which we rigorously prove under certain conditions, and\nempirically demonstrate under others. Motivated by tensor rank capturing the\nimplicit regularization of a non-linear neural network, we empirically explore\nit as a measure of complexity, and find that it captures the essence of\ndatasets on which neural networks generalize. This leads us to believe that\ntensor rank may pave way to explaining both implicit regularization in deep\nlearning, and the properties of real-world data translating this implicit\nregularization to generalization.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 15:10:26 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 20:21:46 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 17:16:17 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Razin", "Noam", ""], ["Maman", "Asaf", ""], ["Cohen", "Nadav", ""]]}, {"id": "2102.10019", "submitter": "Claire Lazar Reich", "authors": "Claire Lazar Reich", "title": "Resolving the Disparate Impact of Uncertainty: Affirmative Action vs.\n  Affirmative Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic risk assessments hold the promise of greatly advancing accurate\ndecision-making, but in practice, multiple real-world examples have been shown\nto distribute errors disproportionately across demographic groups. In this\npaper, we characterize why error disparities arise in the first place. We show\nthat predictive uncertainty often leads classifiers to systematically\ndisadvantage groups with lower-mean outcomes, assigning them smaller true and\nfalse positive rates than their higher-mean counterparts. This can occur even\nwhen prediction is group-blind. We prove that to avoid these error imbalances,\nindividuals in lower-mean groups must either be over-represented among positive\nclassifications or be assigned more accurate predictions than those in\nhigher-mean groups. We focus on the latter condition as a solution to bridge\nerror rate divides and show that data acquisition for low-mean groups can\nincrease access to opportunity. We call the strategy \"affirmative information\"\nand compare it to traditional affirmative action in the classification task of\nidentifying creditworthy borrowers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:40:47 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Reich", "Claire Lazar", ""]]}, {"id": "2102.10025", "submitter": "Tianyi Zhang", "authors": "Daniel Russo, Assaf Zeevi, Tianyi Zhang", "title": "Learning to Stop with Surprisingly Few Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a discounted infinite horizon optimal stopping problem. If the\nunderlying distribution is known a priori, the solution of this problem is\nobtained via dynamic programming (DP) and is given by a well known threshold\nrule. When information on this distribution is lacking, a natural (though\nnaive) approach is \"explore-then-exploit,\" whereby the unknown distribution or\nits parameters are estimated over an initial exploration phase, and this\nestimate is then used in the DP to determine actions over the residual\nexploitation phase. We show: (i) with proper tuning, this approach leads to\nperformance comparable to the full information DP solution; and (ii) despite\ncommon wisdom on the sensitivity of such \"plug in\" approaches in DP due to\npropagation of estimation errors, a surprisingly \"short\" (logarithmic in the\nhorizon) exploration horizon suffices to obtain said performance. In cases\nwhere the underlying distribution is heavy-tailed, these observations are even\nmore pronounced: a ${\\it single \\, sample}$ exploration phase suffices.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:51:07 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 04:25:24 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Russo", "Daniel", ""], ["Zeevi", "Assaf", ""], ["Zhang", "Tianyi", ""]]}, {"id": "2102.10032", "submitter": "Alberto Bietti", "authors": "Alberto Bietti", "title": "Approximation and Learning with Deep Convolutional Models: a Kernel\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The empirical success of deep convolutional networks on tasks involving\nhigh-dimensional data such as images or audio suggests that they can\nefficiently approximate certain functions that are well-suited for such tasks.\nIn this paper, we study this through the lens of kernel methods, by considering\nsimple hierarchical kernels with two or three convolution and pooling layers,\ninspired by convolutional kernel networks. These achieve good empirical\nperformance on standard vision datasets, while providing a simple enough\ndescription of the functional space to shed light on their inductive bias. We\nshow that the RKHS consists of additive models of interaction terms between\npatches, and that its norm encourages structured spatial similarities between\nthese terms through pooling layers. We then provide generalization bounds which\nillustrate how pooling yields improved sample complexity guarantees when the\ntarget function presents such regularities.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 17:03:42 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 23:20:41 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bietti", "Alberto", ""]]}, {"id": "2102.10080", "submitter": "Guang Cheng", "authors": "Yang Yu, Shih-Kang Chao, Guang Cheng", "title": "Distributed Bootstrap for Simultaneous Inference Under High\n  Dimensionality", "comments": "arXiv admin note: text overlap with arXiv:2002.08443", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a distributed bootstrap method for simultaneous inference on\nhigh-dimensional massive data that are stored and processed with many machines.\nThe method produces a $\\ell_\\infty$-norm confidence region based on a\ncommunication-efficient de-biased lasso, and we propose an efficient\ncross-validation approach to tune the method at every iteration. We\ntheoretically prove a lower bound on the number of communication rounds\n$\\tau_{\\min}$ that warrants the statistical accuracy and efficiency.\nFurthermore, $\\tau_{\\min}$ only increases logarithmically with the number of\nworkers and intrinsic dimensionality, while nearly invariant to the nominal\ndimensionality. We test our theory by extensive simulation studies, and a\nvariable screening task on a semi-synthetic dataset based on the US Airline\nOn-time Performance dataset. The code to reproduce the numerical results is\navailable at GitHub: https://github.com/skchao74/Distributed-bootstrap.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:28:29 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Yu", "Yang", ""], ["Chao", "Shih-Kang", ""], ["Cheng", "Guang", ""]]}, {"id": "2102.10085", "submitter": "Yibo Yang", "authors": "Yibo Yang, Antoine Blanchard, Themistoklis Sapsis, Paris Perdikaris", "title": "Output-Weighted Sampling for Multi-Armed Bandits with Extreme Payoffs", "comments": "10 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new type of acquisition functions for online decision making in\nmulti-armed and contextual bandit problems with extreme payoffs. Specifically,\nwe model the payoff function as a Gaussian process and formulate a novel type\nof upper confidence bound (UCB) acquisition function that guides exploration\ntowards the bandits that are deemed most relevant according to the variability\nof the observed rewards. This is achieved by computing a tractable likelihood\nratio that quantifies the importance of the output relative to the inputs and\nessentially acts as an \\textit{attention mechanism} that promotes exploration\nof extreme rewards. We demonstrate the benefits of the proposed methodology\nacross several synthetic benchmarks, as well as a realistic example involving\nnoisy sensor network data. Finally, we provide a JAX library for efficient\nbandit optimization using Gaussian processes.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:36:03 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Yang", "Yibo", ""], ["Blanchard", "Antoine", ""], ["Sapsis", "Themistoklis", ""], ["Perdikaris", "Paris", ""]]}, {"id": "2102.10148", "submitter": "Roman Vershynin", "authors": "Pierre Baldi, Roman Vershynin", "title": "A theory of capacity and sparse neural encoding", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by biological considerations, we study sparse neural maps from an\ninput layer to a target layer with sparse activity, and specifically the\nproblem of storing $K$ input-target associations $(x,y)$, or memories, when the\ntarget vectors $y$ are sparse. We mathematically prove that $K$ undergoes a\nphase transition and that in general, and somewhat paradoxically, sparsity in\nthe target layers increases the storage capacity of the map. The target vectors\ncan be chosen arbitrarily, including in random fashion, and the memories can be\nboth encoded and decoded by networks trained using local learning rules,\nincluding the simple Hebb rule. These results are robust under a variety of\nstatistical assumptions on the data. The proofs rely on elegant properties of\nrandom polytopes and sub-gaussian random vector variables. Open problems and\nconnections to capacity theories and polynomial threshold maps are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 20:24:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Baldi", "Pierre", ""], ["Vershynin", "Roman", ""]]}, {"id": "2102.10200", "submitter": "Richard Combes", "authors": "Cindy Trinh and Richard Combes", "title": "A High Performance, Low Complexity Algorithm for Multi-Player Bandits\n  Without Collision Sensing Information", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in cognitive radio networks, we consider the\ndecentralized multi-player multi-armed bandit problem, without collision nor\nsensing information. We propose Randomized Selfish KL-UCB, an algorithm with\nvery low computational complexity, inspired by the Selfish KL-UCB algorithm,\nwhich has been abandoned as it provably performs sub-optimally in some cases.\nWe subject Randomized Selfish KL-UCB to extensive numerical experiments showing\nthat it far outperforms state-of-the-art algorithms in almost all environments,\nsometimes by several orders of magnitude, and without the additional knowledge\nrequired by state-of-the-art algorithms. We also emphasize the potential of\nthis algorithm for the more realistic dynamic setting, and support our claims\nwith further experiments. We believe that the low complexity and high\nperformance of Randomized Selfish KL-UCB makes it the most suitable for\nimplementation in practical systems amongst known algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 23:10:48 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Trinh", "Cindy", ""], ["Combes", "Richard", ""]]}, {"id": "2102.10204", "submitter": "Puoya Tabaghi", "authors": "Puoya Tabaghi, Eli Chien, Chao Pan, Jianhao Peng, Olgica Milenkovi\\'c", "title": "Linear Classifiers in Product Space Forms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding methods for product spaces are powerful techniques for\nlow-distortion and low-dimensional representation of complex data structures.\nNevertheless, little is known regarding downstream learning and optimization\nproblems in such spaces. Here, we address the problem of linear classification\nin a product space form -- a mix of Euclidean, spherical, and hyperbolic\nspaces. First, we describe new formulations for linear classifiers on a\nRiemannian manifold using geodesics and Riemannian metrics which generalize\nstraight lines and inner products in vector spaces, respectively. Second, we\nprove that linear classifiers in $d$-dimensional space forms of any curvature\nhave the same expressive power, i.e., they can shatter exactly $d+1$ points.\nThird, we formalize linear classifiers in product space forms, describe the\nfirst corresponding perceptron and SVM classification algorithms, and establish\nrigorous convergence results for the former. We support our theoretical\nfindings with simulation results on several datasets, including synthetic data,\nCIFAR-100, MNIST, Omniglot, and single-cell RNA sequencing data. The results\nshow that learning methods applied to small-dimensional embeddings in product\nspace forms outperform their algorithmic counterparts in each space form.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 23:29:03 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 14:56:49 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Tabaghi", "Puoya", ""], ["Chien", "Eli", ""], ["Pan", "Chao", ""], ["Peng", "Jianhao", ""], ["Milenkovi\u0107", "Olgica", ""]]}, {"id": "2102.10221", "submitter": "Jianyu Xu", "authors": "Jianyu Xu and Yu-xiang Wang (Computer Science Department, UC Santa\n  Barbara)", "title": "Logarithmic Regret in Feature-based Dynamic Pricing", "comments": "51 pages, 1 figures (with 2 sub-figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature-based dynamic pricing is an increasingly popular model of setting\nprices for highly differentiated products with applications in digital\nmarketing, online sales, real estate and so on. The problem was formally\nstudied as an online learning problem (Cohen et al., 2016; Javanmard &\nNazerzadeh, 2019) where a seller needs to propose prices on the fly for a\nsequence of $T$ products based on their features $x$ while having a small\nregret relative to the best -- \"omniscient\" -- pricing strategy she could have\ncome up with in hindsight. We revisit this problem and provide two algorithms\n(EMLP and ONSP) for stochastic and adversarial feature settings, respectively,\nand prove the optimal $O(d\\log{T})$ regret bounds for both. In comparison, the\nbest existing results are $O\\left(\\min\\left\\{\\frac{1}{\\lambda_{\\min}^2}\\log{T},\n\\sqrt{T}\\right\\}\\right)$ and $O(T^{2/3})$ respectively, with $\\lambda_{\\min}$\nbeing the smallest eigenvalue of $\\mathbb{E}[xx^T]$ that could be arbitrarily\nclose to $0$. We also prove an $\\Omega(\\sqrt{T})$ information-theoretic lower\nbound for a slightly more general setting, which demonstrates that\n\"knowing-the-demand-curve\" leads to an exponential improvement in feature-based\ndynamic pricing.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 00:45:33 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Xu", "Jianyu", "", "Computer Science Department, UC Santa\n  Barbara"], ["Wang", "Yu-xiang", "", "Computer Science Department, UC Santa\n  Barbara"]]}, {"id": "2102.10226", "submitter": "Teng Zhang", "authors": "Xing Fan, Marianna Pensky, Feng Yu, Teng Zhang", "title": "ALMA: Alternating Minimization Algorithm for Clustering Mixture\n  Multilayer Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers a Mixture Multilayer Stochastic Block Model (MMLSBM),\nwhere layers can be partitioned into groups of similar networks, and networks\nin each group are equipped with a distinct Stochastic Block Model. The goal is\nto partition the multilayer network into clusters of similar layers, and to\nidentify communities in those layers. Jing et al. (2020) introduced the MMLSBM\nand developed a clustering methodology, TWIST, based on regularized tensor\ndecomposition.\n  The present paper proposes a different technique, an alternating minimization\nalgorithm (ALMA), that aims at simultaneous recovery of the layer partition,\ntogether with estimation of the matrices of connection probabilities of the\ndistinct layers. Compared to TWIST, ALMA achieves higher accuracy both\ntheoretically and numerically.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 01:26:55 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 17:15:18 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 19:52:03 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Fan", "Xing", ""], ["Pensky", "Marianna", ""], ["Yu", "Feng", ""], ["Zhang", "Teng", ""]]}, {"id": "2102.10231", "submitter": "Ahmed Shifaz", "authors": "Ahmed Shifaz, Charlotte Pelletier, Francois Petitjean, Geoffrey I.\n  Webb", "title": "Elastic Similarity Measures for Multivariate Time Series Classification", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elastic similarity measures are a class of similarity measures specifically\ndesigned to work with time series data. When scoring the similarity between two\ntime series, they allow points that do not correspond in timestamps to be\naligned. This can compensate for misalignments in the time axis of time series\ndata, and for similar processes that proceed at variable and differing paces.\nElastic similarity measures are widely used in machine learning tasks such as\nclassification, clustering and outlier detection when using time series data.\n  There is a multitude of research on various univariate elastic similarity\nmeasures. However, except for multivariate versions of the well known Dynamic\nTime Warping (DTW) there is a lack of work to generalise other similarity\nmeasures for multivariate cases. This paper adapts two existing strategies used\nin multivariate DTW, namely, Independent and Dependent DTW, to several commonly\nused elastic similarity measures.\n  Using 23 datasets from the University of East Anglia (UEA) multivariate\narchive, for nearest neighbour classification, we demonstrate that each measure\noutperforms all others on at least one dataset and that there are datasets for\nwhich either the dependent versions of all measures are more accurate than\ntheir independent counterparts or vice versa. This latter finding suggests that\nthese differences arise from a fundamental property of the data. We also show\nthat an ensemble of such nearest neighbour classifiers is highly competitive\nwith other state-of-the-art multivariate time series classifiers.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 02:24:33 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Shifaz", "Ahmed", ""], ["Pelletier", "Charlotte", ""], ["Petitjean", "Francois", ""], ["Webb", "Geoffrey I.", ""]]}, {"id": "2102.10234", "submitter": "Shaogao Lv", "authors": "Shaogao Lv", "title": "Generalization bounds for graph convolutional neural networks via\n  Rademacher complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at studying the sample complexity of graph convolutional\nnetworks (GCNs), by providing tight upper bounds of Rademacher complexity for\nGCN models with a single hidden layer. Under regularity conditions, theses\nderived complexity bounds explicitly depend on the largest eigenvalue of graph\nconvolution filter and the degree distribution of the graph. Again, we provide\na lower bound of Rademacher complexity for GCNs to show optimality of our\nderived upper bounds. Taking two commonly used examples as representatives, we\ndiscuss the implications of our results in designing graph convolution filters\nan graph distribution.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 02:51:13 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Lv", "Shaogao", ""]]}, {"id": "2102.10252", "submitter": "Hadi Jahanshahi", "authors": "Hadi Jahanshahi and Mustafa Gokce Baydogan", "title": "nTreeClus: a Tree-based Sequence Encoder for Clustering Categorical\n  Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overwhelming presence of categorical/sequential data in diverse domains\nemphasizes the importance of sequence mining. The challenging nature of\nsequences proves the need for continuing research to find a more accurate and\nfaster approach providing a better understanding of their (dis)similarities.\nThis paper proposes a new Model-based approach for clustering sequence data,\nnamely nTreeClus. The proposed method deploys Tree-based Learners, k-mers, and\nautoregressive models for categorical time series, culminating with a novel\nnumerical representation of the categorical sequences. Adopting this new\nrepresentation, we cluster sequences, considering the inherent patterns in\ncategorical time series. Accordingly, the model showed robustness to its\nparameter. Under different simulated scenarios, nTreeClus improved the baseline\nmethods for various internal and external cluster validation metrics for up to\n10.7% and 2.7%, respectively. The empirical evaluation using synthetic and real\ndatasets, protein sequences, and categorical time series showed that nTreeClus\nis competitive or superior to most state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 03:58:17 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Jahanshahi", "Hadi", ""], ["Baydogan", "Mustafa Gokce", ""]]}, {"id": "2102.10263", "submitter": "Hayden Helm", "authors": "Hayden S. Helm, Weiwei Yang, Sujeeth Bharadwaj, Kate Lytvynets, Oriana\n  Riva, Christopher White, Ali Geisa, Carey E. Priebe", "title": "Inducing a hierarchy for multi-class classification problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications where categorical labels follow a natural hierarchy,\nclassification methods that exploit the label structure often outperform those\nthat do not. Un-fortunately, the majority of classification datasets do not\ncome pre-equipped with a hierarchical structure and classical flat classifiers\nmust be employed. In this paper, we investigate a class of methods that induce\na hierarchy that can similarly improve classification performance over flat\nclassifiers. The class of methods follows the structure of first clustering the\nconditional distributions and subsequently using a hierarchical classifier with\nthe induced hierarchy. We demonstrate the effectiveness of the class of methods\nboth for discovering a latent hierarchy and for improving accuracy in\nprincipled simulation settings and three real data applications.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 05:40:42 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Helm", "Hayden S.", ""], ["Yang", "Weiwei", ""], ["Bharadwaj", "Sujeeth", ""], ["Lytvynets", "Kate", ""], ["Riva", "Oriana", ""], ["White", "Christopher", ""], ["Geisa", "Ali", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2102.10264", "submitter": "Saurabh Garg", "authors": "Saurabh Garg, Joshua Zhanson, Emilio Parisotto, Adarsh Prasad, J. Zico\n  Kolter, Zachary C. Lipton, Sivaraman Balakrishnan, Ruslan Salakhutdinov and\n  Pradeep Ravikumar", "title": "On Proximal Policy Optimization's Heavy-tailed Gradients", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern policy gradient algorithms such as Proximal Policy Optimization (PPO)\nrely on an arsenal of heuristics, including loss clipping and gradient\nclipping, to ensure successful learning. These heuristics are reminiscent of\ntechniques from robust statistics, commonly used for estimation in outlier-rich\n(``heavy-tailed'') regimes. In this paper, we present a detailed empirical\nstudy to characterize the heavy-tailed nature of the gradients of the PPO\nsurrogate reward function. We demonstrate that the gradients, especially for\nthe actor network, exhibit pronounced heavy-tailedness and that it increases as\nthe agent's policy diverges from the behavioral policy (i.e., as the agent goes\nfurther off policy). Further examination implicates the likelihood ratios and\nadvantages in the surrogate reward as the main sources of the observed\nheavy-tailedness. We then highlight issues arising due to the heavy-tailed\nnature of the gradients. In this light, we study the effects of the standard\nPPO clipping heuristics, demonstrating that these tricks primarily serve to\noffset heavy-tailedness in gradients. Thus motivated, we propose incorporating\nGMOM, a high-dimensional robust estimator, into PPO as a substitute for three\nclipping tricks. Despite requiring less hyperparameter tuning, our method\nmatches the performance of PPO (with all heuristics enabled) on a battery of\nMuJoCo continuous control tasks.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 05:51:28 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 03:07:45 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Garg", "Saurabh", ""], ["Zhanson", "Joshua", ""], ["Parisotto", "Emilio", ""], ["Prasad", "Adarsh", ""], ["Kolter", "J. Zico", ""], ["Lipton", "Zachary C.", ""], ["Balakrishnan", "Sivaraman", ""], ["Salakhutdinov", "Ruslan", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "2102.10307", "submitter": "Stefano Peluchetti", "authors": "Daniele Bracale, Stefano Favaro, Sandra Fortini, Stefano Peluchetti", "title": "Large-width functional asymptotics for deep Gaussian neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider fully connected feed-forward deep neural networks\nwhere weights and biases are independent and identically distributed according\nto Gaussian distributions. Extending previous results (Matthews et al.,\n2018a;b; Yang, 2019) we adopt a function-space perspective, i.e. we look at\nneural networks as infinite-dimensional random elements on the input space\n$\\mathbb{R}^I$. Under suitable assumptions on the activation function we show\nthat: i) a network defines a continuous Gaussian process on the input space\n$\\mathbb{R}^I$; ii) a network with re-scaled weights converges weakly to a\ncontinuous Gaussian process in the large-width limit; iii) the limiting\nGaussian process has almost surely locally $\\gamma$-H\\\"older continuous paths,\nfor $0 < \\gamma <1$. Our results contribute to recent theoretical studies on\nthe interplay between infinitely wide deep neural networks and Gaussian\nprocesses by establishing weak convergence in function-space with respect to a\nstronger metric.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 10:14:37 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bracale", "Daniele", ""], ["Favaro", "Stefano", ""], ["Fortini", "Sandra", ""], ["Peluchetti", "Stefano", ""]]}, {"id": "2102.10333", "submitter": "Bryn Elesedy", "authors": "Bryn Elesedy and Sheheryar Zaidi", "title": "Provably Strict Generalisation Benefit for Equivariant Models", "comments": "A shortened version appears in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is widely believed that engineering a model to be invariant/equivariant\nimproves generalisation. Despite the growing popularity of this approach, a\nprecise characterisation of the generalisation benefit is lacking. By\nconsidering the simplest case of linear models, this paper provides the first\nprovably non-zero improvement in generalisation for invariant/equivariant\nmodels when the target distribution is invariant/equivariant with respect to a\ncompact group. Moreover, our work reveals an interesting relationship between\ngeneralisation, the number of training examples and properties of the group\naction. Our results rest on an observation of the structure of function spaces\nunder averaging operators which, along with its consequences for feature\naveraging, may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 12:47:32 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 09:35:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Elesedy", "Bryn", ""], ["Zaidi", "Sheheryar", ""]]}, {"id": "2102.10346", "submitter": "Hongjian Wang", "authors": "Hongjian Wang, Mert G\\\"urb\\\"uzbalaban, Lingjiong Zhu, Umut\n  \\c{S}im\\c{s}ekli, Murat A. Erdogdu", "title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise\n  Variance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have provided both empirical and theoretical evidence\nillustrating that heavy tails can emerge in stochastic gradient descent (SGD)\nin various scenarios. Such heavy tails potentially result in iterates with\ndiverging variance, which hinders the use of conventional convergence analysis\ntechniques that rely on the existence of the second-order moments. In this\npaper, we provide convergence guarantees for SGD under a state-dependent and\nheavy-tailed noise with a potentially infinite variance, for a class of\nstrongly convex objectives. In the case where the $p$-th moment of the noise\nexists for some $p\\in [1,2)$, we first identify a condition on the Hessian,\ncoined '$p$-positive (semi-)definiteness', that leads to an interesting\ninterpolation between positive semi-definite matrices ($p=2$) and diagonally\ndominant matrices with non-negative diagonal entries ($p=1$). Under this\ncondition, we then provide a convergence rate for the distance to the global\noptimum in $L^p$. Furthermore, we provide a generalized central limit theorem,\nwhich shows that the properly scaled Polyak-Ruppert averaging converges weakly\nto a multivariate $\\alpha$-stable random vector. Our results indicate that even\nunder heavy-tailed noise with infinite variance, SGD can converge to the global\noptimum without necessitating any modification neither to the loss function or\nto the algorithm itself, as typically required in robust statistics. We\ndemonstrate the implications of our results to applications such as linear\nregression and generalized linear models subject to heavy-tailed data.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 13:45:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wang", "Hongjian", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""], ["Zhu", "Lingjiong", ""], ["\u015eim\u015fekli", "Umut", ""], ["Erdogdu", "Murat A.", ""]]}, {"id": "2102.10362", "submitter": "Thomas Spooner", "authors": "Thomas Spooner, Nelson Vadori, Sumitra Ganesh", "title": "Causal Policy Gradients: Leveraging Structure for Efficient Learning in\n  (Factored) MOMDPs", "comments": "19 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods can solve complex tasks but often fail when the\ndimensionality of the action-space or objective multiplicity grow very large.\nThis occurs, in part, because the variance on score-based gradient estimators\nscales quadratically. In this paper, we address this problem through a causal\nbaseline which exploits independence structure encoded in a novel action-target\ninfluence network. Causal policy gradients (CPGs), which follow, provide a\ncommon framework for analysing key state-of-the-art algorithms, are shown to\ngeneralise traditional policy gradients, and yield a principled way of\nincorporating prior knowledge of a problem domain's generative processes. We\nprovide an analysis of the proposed estimator and identify the conditions under\nwhich variance is reduced. The algorithmic aspects of CPGs are discussed,\nincluding optimal policy factorisation, as characterised by minimum biclique\ncoverings, and the implications for the bias-variance trade-off of incorrectly\nspecifying the network. Finally, we demonstrate the performance advantages of\nour algorithm on large-scale bandit and traffic intersection problems,\nproviding a novel contribution to the latter in the form of a spatio-causal\napproximation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 14:51:12 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 09:45:16 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Spooner", "Thomas", ""], ["Vadori", "Nelson", ""], ["Ganesh", "Sumitra", ""]]}, {"id": "2102.10439", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Ernst Ahlberg, Lars\n  Carlsson, and Alex Gammerman", "title": "Retrain or not retrain: Conformal test martingales for change-point\n  detection", "comments": "22 pages, 19 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue for supplementing the process of training a prediction algorithm by\nsetting up a scheme for detecting the moment when the distribution of the data\nchanges and the algorithm needs to be retrained. Our proposed schemes are based\non exchangeability martingales, i.e., processes that are martingales under any\nexchangeable distribution for the data. Our method, based on conformal\nprediction, is general and can be applied on top of any modern prediction\nalgorithm. Its validity is guaranteed, and in this paper we make first steps in\nexploring its efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 20:39:05 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Vovk", "Vladimir", ""], ["Petej", "Ivan", ""], ["Nouretdinov", "Ilia", ""], ["Ahlberg", "Ernst", ""], ["Carlsson", "Lars", ""], ["Gammerman", "Alex", ""]]}, {"id": "2102.10490", "submitter": "Junru Wu", "authors": "Junru Wu, Xiyang Dai, Dongdong Chen, Yinpeng Chen, Mengchen Liu, Ye\n  Yu, Zhangyang Wang, Zicheng Liu, Mei Chen, Lu Yuan", "title": "Stronger NAS with Weaker Predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Architecture Search (NAS) often trains and evaluates a large number of\narchitectures. Recent predictor-based NAS approaches attempt to address such\nheavy computation costs with two key steps: sampling some\narchitecture-performance pairs and fitting a proxy accuracy predictor. Given\nlimited samples, these predictors, however, are far from accurate to locate top\narchitectures due to the difficulty of fitting the huge search space. This\npaper reflects on a simple yet crucial question: if our final goal is to find\nthe best architecture, do we really need to model the whole space well?. We\npropose a paradigm shift from fitting the whole architecture space using one\nstrong predictor, to progressively fitting a search path towards the\nhigh-performance sub-space through a set of weaker predictors. As a key\nproperty of the proposed weak predictors, their probabilities of sampling\nbetter architectures keep increasing. Hence we only sample a few well-performed\narchitectures guided by the previously learned predictor and estimate a new\nbetter weak predictor. This embarrassingly easy framework produces\ncoarse-to-fine iteration to refine the ranking of sampling space gradually.\nExtensive experiments demonstrate that our method costs fewer samples to find\ntop-performance architectures on NAS-Bench-101 and NAS-Bench-201, as well as\nachieves the state-of-the-art ImageNet performance on the NASNet search space.\nIn particular, compared to state-of-the-art (SOTA) predictor-based NAS methods,\nWeakNAS outperforms all of them with notable margins, e.g., requiring at least\n7.5x less samples to find global optimal on NAS-Bench-101; and WeakNAS can also\nabsorb them for further performance boost. We further strike the new SOTA\nresult of 81.3% in the ImageNet MobileNet Search Space. The code is available\nat https://github.com/VITA-Group/WeakNAS.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 01:58:43 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 04:04:59 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Wu", "Junru", ""], ["Dai", "Xiyang", ""], ["Chen", "Dongdong", ""], ["Chen", "Yinpeng", ""], ["Liu", "Mengchen", ""], ["Yu", "Ye", ""], ["Wang", "Zhangyang", ""], ["Liu", "Zicheng", ""], ["Chen", "Mei", ""], ["Yuan", "Lu", ""]]}, {"id": "2102.10492", "submitter": "David Rolnick", "authors": "Boris Hanin, Ryan Jeong, David Rolnick", "title": "Deep ReLU Networks Preserve Expected Length", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessing the complexity of functions computed by a neural network helps us\nunderstand how the network will learn and generalize. One natural measure of\ncomplexity is how the network distorts length - if the network takes a\nunit-length curve as input, what is the length of the resulting curve of\noutputs? It has been widely believed that this length grows exponentially in\nnetwork depth. We prove that in fact this is not the case: the expected length\ndistortion does not grow with depth, and indeed shrinks slightly, for ReLU\nnetworks with standard random initialization. We also generalize this result by\nproving upper bounds both for higher moments of the length distortion and for\nthe distortion of higher-dimensional volumes. These theoretical results are\ncorroborated by our experiments.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 02:24:55 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 01:22:30 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Hanin", "Boris", ""], ["Jeong", "Ryan", ""], ["Rolnick", "David", ""]]}, {"id": "2102.10707", "submitter": "HanQin Cai", "authors": "HanQin Cai, Yuchen Lou, Daniel McKenzie, Wotao Yin", "title": "A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale\n  Black-Box Optimization", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the zeroth-order optimization problem in the huge-scale setting,\nwhere the dimension of the problem is so large that performing even basic\nvector operations on the decision variables is infeasible. In this paper, we\npropose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query\ncomplexity and has a much smaller per-iteration computational complexity. In\naddition, we discuss how the memory footprint of ZO-BCD can be reduced even\nfurther by the clever use of circulant measurement matrices. As an application\nof our new method, we propose the idea of crafting adversarial attacks on\nneural network based classifiers in a wavelet domain, which can result in\nproblem dimensions of over 1.7 million. In particular, we show that crafting\nadversarial examples to audio classifiers in a wavelet domain can achieve the\nstate-of-the-art attack success rate of 97.9%.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 23:06:35 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 04:30:50 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Cai", "HanQin", ""], ["Lou", "Yuchen", ""], ["McKenzie", "Daniel", ""], ["Yin", "Wotao", ""]]}, {"id": "2102.10749", "submitter": "Hang Liu", "authors": "Hang Liu, Xiaojun Yuan, Ying-Jun Angela Zhang", "title": "CSIT-Free Model Aggregation for Federated Edge Learning via\n  Reconfigurable Intelligent Surface", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study over-the-air model aggregation in federated edge learning (FEEL)\nsystems, where channel state information at the transmitters (CSIT) is assumed\nto be unavailable. We leverage the reconfigurable intelligent surface (RIS)\ntechnology to align the cascaded channel coefficients for CSIT-free model\naggregation. To this end, we jointly optimize the RIS and the receiver by\nminimizing the aggregation error under the channel alignment constraint. We\nthen develop a difference-of-convex algorithm for the resulting non-convex\noptimization. Numerical experiments on image classification show that the\nproposed method is able to achieve a similar learning accuracy as the\nstate-of-the-art CSIT-based solution, demonstrating the efficiency of our\napproach in combating the lack of CSIT.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 03:24:23 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 10:49:48 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 10:31:45 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Hang", ""], ["Yuan", "Xiaojun", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "2102.10769", "submitter": "Rahul Kidambi", "authors": "Rahul Kidambi, Jonathan Chang, Wen Sun", "title": "MobILE: Model-Based Imitation Learning From Observation Alone", "comments": "27 pages, 5 figures, 2 tabular columns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies Imitation Learning from Observations alone (ILFO) where\nthe learner is presented with expert demonstrations that consist only of states\nvisited by an expert (without access to actions taken by the expert). We\npresent a provably efficient model-based framework MobILE to solve the ILFO\nproblem. MobILE involves carefully trading off strategic exploration against\nimitation - this is achieved by integrating the idea of optimism in the face of\nuncertainty into the distribution matching imitation learning (IL) framework.\nWe provide a unified analysis for MobILE, and demonstrate that MobILE enjoys\nstrong performance guarantees for classes of MDP dynamics that satisfy certain\nwell studied notions of structural complexity. We also show that the ILFO\nproblem is strictly harder than the standard IL problem by presenting an\nexponential sample complexity separation between IL and ILFO. We complement\nthese theoretical results with experimental simulations on benchmark OpenAI Gym\ntasks that indicate the efficacy of MobILE.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 04:38:03 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 05:46:17 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kidambi", "Rahul", ""], ["Chang", "Jonathan", ""], ["Sun", "Wen", ""]]}, {"id": "2102.10771", "submitter": "Xueying Chen", "authors": "Xueying Chen, Jerry Q. Cheng, Min-ge Xie", "title": "Divide-and-conquer methods for big data analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of big data analysis, the divide-and-conquer methodology\nrefers to a multiple-step process: first splitting a data set into several\nsmaller ones; then analyzing each set separately; finally combining results\nfrom each analysis together. This approach is effective in handling large data\nsets that are unsuitable to be analyzed entirely by a single computer due to\nlimits either from memory storage or computational time. The combined results\nwill provide a statistical inference which is similar to the one from analyzing\nthe entire data set. This article reviews some recently developments of\ndivide-and-conquer methods in a variety of settings, including combining based\non parametric, semiparametric and nonparametric models, online sequential\nupdating methods, among others. Theoretical development on the efficiency of\nthe divide-and-conquer methods is also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 04:40:55 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Chen", "Xueying", ""], ["Cheng", "Jerry Q.", ""], ["Xie", "Min-ge", ""]]}, {"id": "2102.10773", "submitter": "Vassilis Digalakis Jr.", "authors": "Dimitris Bertsimas, Vassilis Digalakis Jr., Michael Linghzi Li, Omar\n  Skali Lami", "title": "Slowly Varying Regression under Sparsity", "comments": "Submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of parameter estimation in slowly varying regression\nmodels with sparsity constraints. We formulate the problem as a mixed integer\noptimization problem and demonstrate that it can be reformulated exactly as a\nbinary convex optimization problem through a novel exact relaxation. The\nrelaxation utilizes a new equality on Moore-Penrose inverses that convexifies\nthe non-convex objective function while coinciding with the original objective\non all feasible binary points. This allows us to solve the problem\nsignificantly more efficiently and to provable optimality using a cutting\nplane-type algorithm. We develop a highly optimized implementation of such\nalgorithm, which substantially improves upon the asymptotic computational\ncomplexity of a straightforward implementation. We further develop a heuristic\nmethod that is guaranteed to produce a feasible solution and, as we empirically\nillustrate, generates high quality warm-start solutions for the binary\noptimization problem. We show, on both synthetic and real-world datasets, that\nthe resulting algorithm outperforms competing formulations in comparable times\nacross a variety of metrics including out-of-sample predictive performance,\nsupport recovery accuracy, and false positive rate. The algorithm enables us to\ntrain models with 10,000s of parameters, is robust to noise, and able to\neffectively capture the underlying slowly changing support of the data\ngenerating process.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 04:51:44 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Digalakis", "Vassilis", "Jr."], ["Li", "Michael Linghzi", ""], ["Lami", "Omar Skali", ""]]}, {"id": "2102.10936", "submitter": "Inga Str\\\"umke", "authors": "Daniel Fryer and Inga Str\\\"umke and Hien Nguyen", "title": "Shapley values for feature selection: The good, the bad, and the axioms", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Shapley value has become popular in the Explainable AI (XAI) literature,\nthanks, to a large extent, to a solid theoretical foundation, including four\n\"favourable and fair\" axioms for attribution in transferable utility games. The\nShapley value is provably the only solution concept satisfying these axioms. In\nthis paper, we introduce the Shapley value and draw attention to its recent\nuses as a feature selection tool. We call into question this use of the Shapley\nvalue, using simple, abstract \"toy\" counterexamples to illustrate that the\naxioms may work against the goals of feature selection. From this, we develop a\nnumber of insights that are then investigated in concrete simulation settings,\nwith a variety of Shapley value formulations, including SHapley Additive\nexPlanations (SHAP) and Shapley Additive Global importancE (SAGE).\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 12:09:08 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Fryer", "Daniel", ""], ["Str\u00fcmke", "Inga", ""], ["Nguyen", "Hien", ""]]}, {"id": "2102.10951", "submitter": "Alexander Hepburn", "authors": "Alexander Hepburn, Raul Santos-Rodriguez", "title": "Explainers in the Wild: Making Surrogate Explainers Robust to\n  Distortions through Perception", "comments": null, "journal-ref": "2021 IEEE International Conference on Image Processing (ICIP),\n  Anchorage, Alaska, USA", "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining the decisions of models is becoming pervasive in the image\nprocessing domain, whether it is by using post-hoc methods or by creating\ninherently interpretable models. While the widespread use of surrogate\nexplainers is a welcome addition to inspect and understand black-box models,\nassessing the robustness and reliability of the explanations is key for their\nsuccess. Additionally, whilst existing work in the explainability field\nproposes various strategies to address this problem, the challenges of working\nwith data in the wild is often overlooked. For instance, in image\nclassification, distortions to images can not only affect the predictions\nassigned by the model, but also the explanation. Given a clean and a distorted\nversion of an image, even if the prediction probabilities are similar, the\nexplanation may still be different. In this paper we propose a methodology to\nevaluate the effect of distortions in explanations by embedding perceptual\ndistances that tailor the neighbourhoods used to training surrogate explainers.\nWe also show that by operating in this way, we can make the explanations more\nrobust to distortions. We generate explanations for images in the Imagenet-C\ndataset and demonstrate how using a perceptual distances in the surrogate\nexplainer creates more coherent explanations for the distorted and reference\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 12:38:53 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 10:39:04 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Hepburn", "Alexander", ""], ["Santos-Rodriguez", "Raul", ""]]}, {"id": "2102.10964", "submitter": "Hugo Richard", "authors": "Hugo Richard (1) and Pierre Ablin (2) and Aapo Hyv\\\"arinen (1 and 3)\n  and Alexandre Gramfort (1) and Bertrand Thirion (1) ((1) Inria,\n  Universit\\'e-Paris Saclay, Saclay, France (2) Ecole normale sup\\'erieure,\n  Paris, France (3) University of Helsinky, Finland)", "title": "Adaptive Multi-View ICA: Estimation of noise levels for optimal\n  inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-view learning problem known as group independent\ncomponent analysis (group ICA), where the goal is to recover shared independent\nsources from many views. The statistical modeling of this problem requires to\ntake noise into account. When the model includes additive noise on the\nobservations, the likelihood is intractable. By contrast, we propose Adaptive\nmultiView ICA (AVICA), a noisy ICA model where each view is a linear mixture of\nshared independent sources with additive noise on the sources. In this setting,\nthe likelihood has a tractable expression, which enables either direct\noptimization of the log-likelihood using a quasi-Newton method, or generalized\nEM. Importantly, we consider that the noise levels are also parameters that are\nlearned from the data. This enables sources estimation with a closed-form\nMinimum Mean Squared Error (MMSE) estimator which weights each view according\nto its relative noise level. On synthetic data, AVICA yields better sources\nestimates than other group ICA methods thanks to its explicit MMSE estimator.\nOn real magnetoencephalograpy (MEG) data, we provide evidence that the\ndecomposition is less sensitive to sampling noise and that the noise variance\nestimates are biologically plausible. Lastly, on functional magnetic resonance\nimaging (fMRI) data, AVICA exhibits best performance in transferring\ninformation across views.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 13:10:12 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Richard", "Hugo", "", "1 and 3"], ["Ablin", "Pierre", "", "1 and 3"], ["Hyv\u00e4rinen", "Aapo", "", "1 and 3"], ["Gramfort", "Alexandre", ""], ["Thirion", "Bertrand", ""]]}, {"id": "2102.11010", "submitter": "Ginevra Carbone", "authors": "Ginevra Carbone, Guido Sanguinetti, Luca Bortolussi", "title": "Resilience of Bayesian Layer-Wise Explanations under Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of the stability of saliency-based explanations of\nNeural Network predictions under adversarial attacks in a classification task.\nSaliency interpretations of deterministic Neural Networks are remarkably\nbrittle even when the attacks fail, i.e. for attacks that do not change the\nclassification label. We empirically show that interpretations provided by\nBayesian Neural Networks are considerably more stable under adversarial\nperturbations. By leveraging recent results, we also provide a theoretical\nexplanation of this result in terms of the geometry of adversarial attacks.\nAdditionally, we discuss the stability of the interpretations of high level\nrepresentations of the inputs in the internal layers of a Network. Our results\nnot only confirm that Bayesian Neural Networks are more robust to adversarial\nattacks, but also demonstrate that Bayesian methods have the potential to\nprovide more stable and interpretable assessments of Neural Network\npredictions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:07:24 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 08:10:17 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Carbone", "Ginevra", ""], ["Sanguinetti", "Guido", ""], ["Bortolussi", "Luca", ""]]}, {"id": "2102.11050", "submitter": "Fransisca Susan", "authors": "Rad Niazadeh (1), Negin Golrezaei (2), Joshua Wang (3), Fransisca\n  Susan (2), Ashwinkumar Badanidiyuru (3) ((1) Chicago Booth School of\n  Business, Operations Management, (2) MIT Sloan School of Management,\n  Operations Management, (3) Google Research Mountain View)", "title": "Online Learning via Offline Greedy Algorithms: Applications in Market\n  Design and Optimization", "comments": "70 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by online decision-making in time-varying combinatorial\nenvironments, we study the problem of transforming offline algorithms to their\nonline counterparts. We focus on offline combinatorial problems that are\namenable to a constant factor approximation using a greedy algorithm that is\nrobust to local errors. For such problems, we provide a general framework that\nefficiently transforms offline robust greedy algorithms to online ones using\nBlackwell approachability. We show that the resulting online algorithms have\n$O(\\sqrt{T})$ (approximate) regret under the full information setting. We\nfurther introduce a bandit extension of Blackwell approachability that we call\nBandit Blackwell approachability. We leverage this notion to transform greedy\nrobust offline algorithms into a $O(T^{2/3})$ (approximate) regret in the\nbandit setting. Demonstrating the flexibility of our framework, we apply our\noffline-to-online transformation to several problems at the intersection of\nrevenue management, market design, and online optimization, including product\nranking optimization in online platforms, reserve price optimization in\nauctions, and submodular maximization. We show that our transformation, when\napplied to these applications, leads to new regret bounds or improves the\ncurrent known bounds.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 19:05:26 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Niazadeh", "Rad", ""], ["Golrezaei", "Negin", ""], ["Wang", "Joshua", ""], ["Susan", "Fransisca", ""], ["Badanidiyuru", "Ashwinkumar", ""]]}, {"id": "2102.11062", "submitter": "Martin Ferianc", "authors": "Martin Ferianc, Partha Maji, Matthew Mattina and Miguel Rodrigues", "title": "On the Effects of Quantisation on Model Uncertainty in Bayesian Neural\n  Networks", "comments": "Accepted at UAI2021. Code at:\n  https://github.com/martinferianc/quantised-bayesian-nets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) are making significant progress in many\nresearch areas where decision-making needs to be accompanied by uncertainty\nestimation. Being able to quantify uncertainty while making decisions is\nessential for understanding when the model is over-/under-confident, and hence\nBNNs are attracting interest in safety-critical applications, such as\nautonomous driving, healthcare, and robotics. Nevertheless, BNNs have not been\nas widely used in industrial practice, mainly because of their increased memory\nand compute costs. In this work, we investigate quantisation of BNNs by\ncompressing 32-bit floating-point weights and activations to their integer\ncounterparts, that has already been successful in reducing the compute demand\nin standard pointwise neural networks. We study three types of quantised BNNs,\nwe evaluate them under a wide range of different settings, and we empirically\ndemonstrate that a uniform quantisation scheme applied to BNNs does not\nsubstantially decrease their quality of uncertainty estimation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:36:29 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 13:20:28 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ferianc", "Martin", ""], ["Maji", "Partha", ""], ["Mattina", "Matthew", ""], ["Rodrigues", "Miguel", ""]]}, {"id": "2102.11069", "submitter": "Guillaume Vidot", "authors": "Guillaume Vidot (IRIT), Paul Viallard (LHC), Amaury Habrard (LHC),\n  Emilie Morvant (LHC)", "title": "A PAC-Bayes Analysis of Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first general PAC-Bayesian generalization bounds for\nadversarial robustness, that estimate, at test time, how much a model will be\ninvariant to imperceptible perturbations in the input. Instead of deriving a\nworst-case analysis of the risk of a hypothesis over all the possible\nperturbations, we leverage the PAC-Bayesian framework to bound the averaged\nrisk on the perturbations for majority votes (over the whole class of\nhypotheses). Our theoretically founded analysis has the advantage to provide\ngeneral bounds (i) independent from the type of perturbations (i.e., the\nadversarial attacks), (ii) that are tight thanks to the PAC-Bayesian framework,\n(iii) that can be directly minimized during the learning phase to obtain a\nrobust model on different attacks at test time.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:23:48 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Vidot", "Guillaume", "", "IRIT"], ["Viallard", "Paul", "", "LHC"], ["Habrard", "Amaury", "", "LHC"], ["Morvant", "Emilie", "", "LHC"]]}, {"id": "2102.11076", "submitter": "Rahul Singh", "authors": "Rahul Singh", "title": "Debiased Kernel Methods", "comments": "32 pages. arXiv admin note: text overlap with arXiv:2010.04855", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I propose a practical procedure based on bias correction and sample splitting\nto calculate confidence intervals for functionals of generic kernel methods,\ni.e. nonparametric estimators learned in a reproducing kernel Hilbert space\n(RKHS). For example, an analyst may desire confidence intervals for functionals\nof kernel ridge regression. I propose a bias correction that mirrors kernel\nridge regression. The framework encompasses (i) evaluations over discrete\ndomains, (ii) derivatives over continuous domains, (iii) treatment effects of\ndiscrete treatments, and (iv) incremental treatment effects of continuous\ntreatments. For the target quantity, whether it is (i)-(iv), I prove root-n\nconsistency, Gaussian approximation, and semiparametric efficiency by finite\nsample arguments. I show that the classic assumptions of RKHS learning theory\nalso imply inference.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:46:23 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 22:22:54 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Singh", "Rahul", ""]]}, {"id": "2102.11077", "submitter": "Boris Ndjia Njike", "authors": "Boris Ndjia Njike, Xavier Siebert", "title": "Nonparametric adaptive active learning under local smoothness condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active learning is typically used to label data, when the labeling process is\nexpensive. Several active learning algorithms have been theoretically proved to\nperform better than their passive counterpart. However, these algorithms rely\non some assumptions, which themselves contain some specific parameters. This\npaper adresses the problem of adaptive active learning in a nonparametric\nsetting with minimal assumptions. We present a novel algorithm that is valid\nunder more general assumptions than the previously known algorithms, and that\ncan moreover adapt to the parameters used in these assumptions. This allows us\nto work with a larger class of distributions, thereby avoiding to exclude\nimportant densities like gaussians. Our algorithm achieves a minimax rate of\nconvergence, and therefore performs almost as well as the best known\nnon-adaptive algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:47:21 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Njike", "Boris Ndjia", ""], ["Siebert", "Xavier", ""]]}, {"id": "2102.11120", "submitter": "Takeyuki Sasai", "authors": "Takeyuki Sasai and Hironori Fujisawa", "title": "Adversarial robust weighted Huber regression", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to estimate the coefficients of linear regression\nwhen outputs and inputs are contaminated by malicious outliers. Our method\nconsists of two-step: (i) Make appropriate weights\n$\\left\\{\\hat{w}_i\\right\\}_{i=1}^n$ such that the weighted sample mean of\nregression covariates robustly estimates the population mean of the regression\ncovariate, (ii) Process Huber regression using\n$\\left\\{\\hat{w}_i\\right\\}_{i=1}^n$. When (a-1) the regression covariate is a\nsequence with i.i.d. random vectors drawn from sub-Gaussian distribution\nsatisfying $L_4$-$L_2$ norm equivalence with unknown mean and known identity\ncovariance and (a-2) the absolute moment of the random noise is finite, our\nmethod attains a convergence rate, which is information theoretically optimal\nup to constant factor about noise term. When (b-1) the regression covariate is\na sequence with i.i.d. random vectors drawn from heavy tailed distribution\nsatisfying $L_4$-$L_2$ norm equivalence with unknown mean and (b-2) the\nabsolute moment of the random noise is finite, our method attains a convergence\nrate, which is information theoretically optimal up to constant factor.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 15:50:34 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 15:38:56 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Sasai", "Takeyuki", ""], ["Fujisawa", "Hironori", ""]]}, {"id": "2102.11158", "submitter": "Shuxiao Chen", "authors": "Qinqing Zheng, Shuxiao Chen, Qi Long, Weijie J. Su", "title": "Federated $f$-Differential Privacy", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a training paradigm where the clients\ncollaboratively learn models by repeatedly sharing information without\ncompromising much on the privacy of their local sensitive data. In this paper,\nwe introduce federated $f$-differential privacy, a new notion specifically\ntailored to the federated setting, based on the framework of Gaussian\ndifferential privacy. Federated $f$-differential privacy operates on record\nlevel: it provides the privacy guarantee on each individual record of one\nclient's data against adversaries. We then propose a generic private federated\nlearning framework {PriFedSync} that accommodates a large family of\nstate-of-the-art FL algorithms, which provably achieves federated\n$f$-differential privacy. Finally, we empirically demonstrate the trade-off\nbetween privacy guarantee and prediction performance for models trained by\n{PriFedSync} in computer vision tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:28:21 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zheng", "Qinqing", ""], ["Chen", "Shuxiao", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "2102.11203", "submitter": "Tianle Cai", "authors": "Tianle Cai, Ruiqi Gao, Jason D. Lee, Qi Lei", "title": "A Theory of Label Propagation for Subpopulation Shift", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central problems in machine learning is domain adaptation. Unlike\npast theoretical work, we consider a new model for subpopulation shift in the\ninput or representation space. In this work, we propose a provably effective\nframework for domain adaptation based on label propagation. In our analysis, we\nuse a simple but realistic expansion assumption, proposed in\n\\citet{wei2021theoretical}. Using a teacher classifier trained on the source\ndomain, our algorithm not only propagates to the target domain but also\nimproves upon the teacher. By leveraging existing generalization bounds, we\nalso obtain end-to-end finite-sample guarantees on the entire algorithm. In\naddition, we extend our theoretical framework to a more general setting of\nsource-to-target transfer based on a third unlabeled dataset, which can be\neasily applied in various learning scenarios. Inspired by our theory, we adapt\nconsistency-based semi-supervised learning methods to domain adaptation\nsettings and gain significant improvements.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 17:27:47 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 09:26:46 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 01:59:03 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cai", "Tianle", ""], ["Gao", "Ruiqi", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""]]}, {"id": "2102.11206", "submitter": "Alexander Terenin", "authors": "Andreas Hochlehnert and Alexander Terenin and Steind\\'or\n  S{\\ae}mundsson and Marc Peter Deisenroth", "title": "Learning Contact Dynamics using Physically Structured Neural Networks", "comments": null, "journal-ref": "Artificial Intelligence and Statistics, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning physically structured representations of dynamical systems that\ninclude contact between different objects is an important problem for\nlearning-based approaches in robotics. Black-box neural networks can learn to\napproximately represent discontinuous dynamics, but they typically require\nlarge quantities of data and often suffer from pathological behaviour when\nforecasting for longer time horizons. In this work, we use connections between\ndeep neural networks and differential equations to design a family of deep\nnetwork architectures for representing contact dynamics between objects. We\nshow that these networks can learn discontinuous contact events in a\ndata-efficient manner from noisy observations in settings that are\ntraditionally difficult for black-box approaches and recent physics inspired\nneural networks. Our results indicate that an idealised form of touch feedback\n-- which is heavily relied upon by biological systems -- is a key component of\nmaking this learning problem tractable. Together with the inductive biases\nintroduced through the network architectures, our techniques enable accurate\nlearning of contact dynamics from observations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 17:33:51 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Hochlehnert", "Andreas", ""], ["Terenin", "Alexander", ""], ["S\u00e6mundsson", "Steind\u00f3r", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2102.11249", "submitter": "Iwona Hawryluk", "authors": "Iwona Hawryluk, Henrique Hoeltgebaum, Swapnil Mishra, Xenia\n  Miscouridou, Ricardo P Schnekenberg, Charles Whittaker, Michaela Vollmer,\n  Seth Flaxman, Samir Bhatt, Thomas A Mellan", "title": "Gaussian Process Nowcasting: Application to COVID-19 Mortality Reporting", "comments": "26 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Updating observations of a signal due to the delays in the measurement\nprocess is a common problem in signal processing, with prominent examples in a\nwide range of fields. An important example of this problem is the nowcasting of\nCOVID-19 mortality: given a stream of reported counts of daily deaths, can we\ncorrect for the delays in reporting to paint an accurate picture of the\npresent, with uncertainty? Without this correction, raw data will often mislead\nby suggesting an improving situation. We present a flexible approach using a\nlatent Gaussian process that is capable of describing the changing\nauto-correlation structure present in the reporting time-delay surface. This\napproach also yields robust estimates of uncertainty for the estimated\nnowcasted numbers of deaths. We test assumptions in model specification such as\nthe choice of kernel or hyper priors, and evaluate model performance on a\nchallenging real dataset from Brazil. Our experiments show that Gaussian\nprocess nowcasting performs favourably against both comparable methods, and\nagainst a small sample of expert human predictions. Our approach has\nsubstantial practical utility in disease modelling -- by applying our approach\nto COVID-19 mortality data from Brazil, where reporting delays are large, we\ncan make informative predictions on important epidemiological quantities such\nas the current effective reproduction number.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:32:44 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 20:20:28 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Hawryluk", "Iwona", ""], ["Hoeltgebaum", "Henrique", ""], ["Mishra", "Swapnil", ""], ["Miscouridou", "Xenia", ""], ["Schnekenberg", "Ricardo P", ""], ["Whittaker", "Charles", ""], ["Vollmer", "Michaela", ""], ["Flaxman", "Seth", ""], ["Bhatt", "Samir", ""], ["Mellan", "Thomas A", ""]]}, {"id": "2102.11252", "submitter": "Micha{\\l} Daniluk", "authors": "Micha{\\l} Daniluk, Barbara Rychalska, Konrad Go{\\l}uchowski, Jacek\n  D\\k{a}browski", "title": "Modeling Multi-Destination Trips with Sketch-Based Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed EMDE (Efficient Manifold Density Estimator) model\nachieves state of-the-art results in session-based recommendation. In this work\nwe explore its application to Booking Data Challenge competition. The aim of\nthe challenge is to make the best recommendation for the next destination of a\nuser trip, based on dataset with millions of real anonymized accommodation\nreservations. We achieve 2nd place in this competition. First, we use Cleora -\nour graph embedding method - to represent cities as a directed graph and learn\ntheir vector representation. Next, we apply EMDE to predict the next user\ndestination based on previously visited cities and some features associated\nwith each trip. We release the source code at:\nhttps://github.com/Synerise/booking-challenge.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:36:11 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 07:47:16 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 20:19:57 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Daniluk", "Micha\u0142", ""], ["Rychalska", "Barbara", ""], ["Go\u0142uchowski", "Konrad", ""], ["D\u0105browski", "Jacek", ""]]}, {"id": "2102.11270", "submitter": "Yuxin Chen", "authors": "Gen Li and Yuting Wei and Yuejie Chi and Yuantao Gu and Yuxin Chen", "title": "Softmax Policy Gradient Methods Can Take Exponential Time to Converge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.SY eess.SY math.IT math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The softmax policy gradient (PG) method, which performs gradient ascent under\nsoftmax policy parameterization, is arguably one of the de facto\nimplementations of policy optimization in modern reinforcement learning. For\n$\\gamma$-discounted infinite-horizon tabular Markov decision processes (MDPs),\nremarkable progress has recently been achieved towards establishing global\nconvergence of softmax PG methods in finding a near-optimal policy. However,\nprior results fall short of delineating clear dependencies of convergence rates\non salient parameters such as the cardinality of the state space $\\mathcal{S}$\nand the effective horizon $\\frac{1}{1-\\gamma}$, both of which could be\nexcessively large. In this paper, we deliver a pessimistic message regarding\nthe iteration complexity of softmax PG methods, despite assuming access to\nexact gradient computation. Specifically, we demonstrate that the softmax PG\nmethod with stepsize $\\eta$ can take \\[\n  \\frac{1}{\\eta} |\\mathcal{S}|^{2^{\\Omega\\big(\\frac{1}{1-\\gamma}\\big)}}\n~\\text{iterations} \\] to converge, even in the presence of a benign policy\ninitialization and an initial state distribution amenable to exploration (so\nthat the distribution mismatch coefficient is not exceedingly large). This is\naccomplished by characterizing the algorithmic dynamics over a\ncarefully-constructed MDP containing only three actions. Our exponential lower\nbound hints at the necessity of carefully adjusting update rules or enforcing\nproper regularization in accelerating PG methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:56:26 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 03:36:42 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Li", "Gen", ""], ["Wei", "Yuting", ""], ["Chi", "Yuejie", ""], ["Gu", "Yuantao", ""], ["Chen", "Yuxin", ""]]}, {"id": "2102.11297", "submitter": "Jeffrey Wong", "authors": "Jeffrey Wong, Eskil Forsell, Randall Lewis, Tobias Mao and Matthew\n  Wardrop", "title": "You Only Compress Once: Optimal Data Compression for Estimating Linear\n  Models", "comments": "v2: Further reduce matrix algebra and fix typo in Section 5.3.3.\n  Improve the relationships across Section 5.3.1, 5.3.2, and 5.3.3. v3: Change\n  citation styles and update Section 5.3.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear models are used in online decision making, such as in machine\nlearning, policy algorithms, and experimentation platforms. Many engineering\nsystems that use linear models achieve computational efficiency through\ndistributed systems and expert configuration. While there are strengths to this\napproach, it is still difficult to have an environment that enables researchers\nto interactively iterate and explore data and models, as well as leverage\nanalytics solutions from the open source community. Consequently, innovation\ncan be blocked.\n  Conditionally sufficient statistics is a unified data compression and\nestimation strategy that is useful for the model development process, as well\nas the engineering deployment process. The strategy estimates linear models\nfrom compressed data without loss on the estimated parameters and their\ncovariances, even when errors are autocorrelated within clusters of\nobservations. Additionally, the compression preserves almost all interactions\nwith the the original data, unlocking better productivity for both researchers\nand engineering systems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 19:00:18 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 18:07:14 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 17:34:31 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Wong", "Jeffrey", ""], ["Forsell", "Eskil", ""], ["Lewis", "Randall", ""], ["Mao", "Tobias", ""], ["Wardrop", "Matthew", ""]]}, {"id": "2102.11394", "submitter": "Jan Achterhold", "authors": "Jan Achterhold and Joerg Stueckler", "title": "Explore the Context: Optimal Data Collection for Context-Conditional\n  Dynamics Models", "comments": "Accepted for publication at the 24th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2021, with supplementary\n  material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we learn dynamics models for parametrized families of\ndynamical systems with varying properties. The dynamics models are formulated\nas stochastic processes conditioned on a latent context variable which is\ninferred from observed transitions of the respective system. The probabilistic\nformulation allows us to compute an action sequence which, for a limited number\nof environment interactions, optimally explores the given system within the\nparametrized family. This is achieved by steering the system through\ntransitions being most informative for the context variable. We demonstrate the\neffectiveness of our method for exploration on a non-linear toy-problem and two\nwell-known reinforcement learning environments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 22:52:39 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Achterhold", "Jan", ""], ["Stueckler", "Joerg", ""]]}, {"id": "2102.11409", "submitter": "Joost van Amersfoort", "authors": "Joost van Amersfoort, Lewis Smith, Andrew Jesson, Oscar Key, Yarin Gal", "title": "On Feature Collapse and Deep Kernel Learning for Single Forward Pass\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are often considered a gold standard in uncertainty\nestimation with low dimensional data, but they have difficulty scaling to high\ndimensional inputs. Deep Kernel Learning (DKL) was introduced as a solution to\nthis problem: a deep feature extractor is used to transform the inputs over\nwhich a Gaussian process' kernel is defined. However, DKL has been shown to\nprovide unreliable uncertainty estimates in practice. We study why, and show\nthat for certain feature extractors, \"far-away\" data points are mapped to the\nsame features as those of training-set points. With this insight we propose to\nconstrain DKL's feature extractor to approximately preserve distances through a\nbi-Lipschitz constraint, resulting in a feature space favorable to DKL. We\nobtain a model, DUE, which demonstrates uncertainty quality outperforming\nprevious DKL and single forward pass uncertainty methods, while maintaining the\nspeed and accuracy of softmax neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 23:29:12 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 17:43:31 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["van Amersfoort", "Joost", ""], ["Smith", "Lewis", ""], ["Jesson", "Andrew", ""], ["Key", "Oscar", ""], ["Gal", "Yarin", ""]]}, {"id": "2102.11436", "submitter": "Alexander Robey", "authors": "Alexander Robey and George J. Pappas and Hamed Hassani", "title": "Model-Based Domain Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable success in a variety of applications, it is well-known\nthat deep learning can fail catastrophically when presented with\nout-of-distribution data. Toward addressing this challenge, we consider the\ndomain generalization problem, wherein predictors are trained using data drawn\nfrom a family of related training domains and then evaluated on a distinct and\nunseen test domain. We show that under a natural model of data generation and a\nconcomitant invariance condition, the domain generalization problem is\nequivalent to an infinite-dimensional constrained statistical learning problem;\nthis problem forms the basis of our approach, which we call Model-Based Domain\nGeneralization. Due to the inherent challenges in solving constrained\noptimization problems in deep learning, we exploit nonconvex duality theory to\ndevelop unconstrained relaxations of this statistical problem with tight bounds\non the duality gap. Based on this theoretical motivation, we propose a novel\ndomain generalization algorithm with convergence guarantees. In our\nexperiments, we report improvements of up to 30 percentage points over\nstate-of-the-art domain generalization baselines on several benchmarks\nincluding ColoredMNIST, Camelyon17-WILDS, FMoW-WILDS, and PACS.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 00:59:02 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 20:14:09 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 15:35:42 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Robey", "Alexander", ""], ["Pappas", "George J.", ""], ["Hassani", "Hamed", ""]]}, {"id": "2102.11494", "submitter": "Yu Bai", "authors": "Yu Bai, Chi Jin, Huan Wang, Caiming Xiong", "title": "Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world applications such as economics and policy making often involve\nsolving multi-agent games with two unique features: (1) The agents are\ninherently asymmetric and partitioned into leaders and followers; (2) The\nagents have different reward functions, thus the game is general-sum. The\nmajority of existing results in this field focuses on either symmetric solution\nconcepts (e.g. Nash equilibrium) or zero-sum games. It remains vastly open how\nto learn the Stackelberg equilibrium -- an asymmetric analog of the Nash\nequilibrium -- in general-sum games efficiently from samples.\n  This paper initiates the theoretical study of sample-efficient learning of\nthe Stackelberg equilibrium, in the bandit feedback setting where we only\nobserve noisy samples of the reward. We consider three representative\ntwo-player general-sum games: bandit games, bandit-reinforcement learning\n(bandit-RL) games, and linear bandit games. In all these games, we identify a\nfundamental gap between the exact value of the Stackelberg equilibrium and its\nestimated version using finitely many noisy samples, which can not be closed\ninformation-theoretically regardless of the algorithm. We then establish sharp\npositive results on sample-efficient learning of Stackelberg equilibrium with\nvalue optimal up to the gap identified above, with matching lower bounds in the\ndependency on the gap, error tolerance, and the size of the action spaces.\nOverall, our results unveil unique challenges in learning Stackelberg\nequilibria under noisy bandit feedback, which we hope could shed light on\nfuture research on this topic.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:11:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 03:48:56 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bai", "Yu", ""], ["Jin", "Chi", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""]]}, {"id": "2102.11582", "submitter": "Jishnu Mukhoti", "authors": "Jishnu Mukhoti, Andreas Kirsch, Joost van Amersfoort, Philip H.S.\n  Torr, Yarin Gal", "title": "Deterministic Neural Networks with Inductive Biases Capture Epistemic\n  and Aleatoric Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a single softmax neural net with minimal changes can beat the\nuncertainty predictions of Deep Ensembles and other more complex\nsingle-forward-pass uncertainty approaches. Standard softmax neural nets suffer\nfrom feature collapse and extrapolate arbitrarily for OoD points. This results\nin arbitrary softmax entropies for OoD points which can have high entropy, low,\nor anything in between, thus cannot capture epistemic uncertainty reliably. We\nprove that this failure lies at the core of \"why\" Deep Ensemble Uncertainty\nworks well. Instead of using softmax entropy, we show that with appropriate\ninductive biases softmax neural nets trained with maximum likelihood reliably\ncapture epistemic uncertainty through their feature-space density. This density\nis obtained using simple Gaussian Discriminant Analysis, but it cannot\nrepresent aleatoric uncertainty reliably. We show that it is necessary to\ncombine feature-space density with softmax entropy to disentangle uncertainties\nwell. We evaluate the epistemic uncertainty quality on active learning and OoD\ndetection, achieving SOTA ~98 AUROC on CIFAR-10 vs SVHN without fine-tuning on\nOoD data.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:44:09 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 09:07:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Mukhoti", "Jishnu", ""], ["Kirsch", "Andreas", ""], ["van Amersfoort", "Joost", ""], ["Torr", "Philip H. S.", ""], ["Gal", "Yarin", ""]]}, {"id": "2102.11600", "submitter": "Jungmin Kwon", "authors": "Jungmin Kwon, Jeongseop Kim, Hyunseo Park and In Kwon Choi", "title": "ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning\n  of Deep Neural Networks", "comments": "13 pages, 4 figures, To be published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, learning algorithms motivated from sharpness of loss surface as an\neffective measure of generalization gap have shown state-of-the-art\nperformances. Nevertheless, sharpness defined in a rigid region with a fixed\nradius, has a drawback in sensitivity to parameter re-scaling which leaves the\nloss unaffected, leading to weakening of the connection between sharpness and\ngeneralization gap. In this paper, we introduce the concept of adaptive\nsharpness which is scale-invariant and propose the corresponding generalization\nbound. We suggest a novel learning method, adaptive sharpness-aware\nminimization (ASAM), utilizing the proposed generalization bound. Experimental\nresults in various benchmark datasets show that ASAM contributes to significant\nimprovement of model generalization performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 10:26:54 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 06:32:34 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 06:42:34 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kwon", "Jungmin", ""], ["Kim", "Jeongseop", ""], ["Park", "Hyunseo", ""], ["Choi", "In Kwon", ""]]}, {"id": "2102.11646", "submitter": "Niv Nayman", "authors": "Niv Nayman, Yonathan Aflalo, Asaf Noy, Lihi Zelnik-Manor", "title": "HardCoRe-NAS: Hard Constrained diffeRentiable Neural Architecture Search", "comments": "Niv Nayman and Yonathan Aflalo contributed equally. An implementation\n  of HardCoRe-NAS is available at: https://github.com/Alibaba-MIIL/HardCoReNAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realistic use of neural networks often requires adhering to multiple\nconstraints on latency, energy and memory among others. A popular approach to\nfind fitting networks is through constrained Neural Architecture Search (NAS),\nhowever, previous methods enforce the constraint only softly. Therefore, the\nresulting networks do not exactly adhere to the resource constraint and their\naccuracy is harmed. In this work we resolve this by introducing Hard\nConstrained diffeRentiable NAS (HardCoRe-NAS), that is based on an accurate\nformulation of the expected resource requirement and a scalable search method\nthat satisfies the hard constraint throughout the search. Our experiments show\nthat HardCoRe-NAS generates state-of-the-art architectures, surpassing other\nNAS methods, while strictly satisfying the hard resource constraints without\nany tuning required.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 11:56:30 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nayman", "Niv", ""], ["Aflalo", "Yonathan", ""], ["Noy", "Asaf", ""], ["Zelnik-Manor", "Lihi", ""]]}, {"id": "2102.11658", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Taiji Suzuki", "title": "A Goodness-of-fit Test on the Number of Biclusters in a Relational Data\n  Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is a method for detecting homogeneous submatrices in a given\nobserved matrix, and it is an effective tool for relational data analysis.\nAlthough there are many studies that estimate the underlying bicluster\nstructure of a matrix, few have enabled us to determine the appropriate number\nof biclusters in an observed matrix. Recently, a statistical test on the number\nof biclusters has been proposed for a regular-grid bicluster structure, where\nwe assume that the latent bicluster structure can be represented by row-column\nclustering. However, when the latent bicluster structure does not satisfy such\nregular-grid assumption, the previous test requires a larger number of\nbiclusters than necessary (i.e., a finer bicluster structure than necessary)\nfor the null hypothesis to be accepted, which is not desirable in terms of\ninterpreting the accepted bicluster structure. In this study, we propose a new\nstatistical test on the number of biclusters that does not require the\nregular-grid assumption and derive the asymptotic behavior of the proposed test\nstatistic in both null and alternative cases. We illustrate the effectiveness\nof the proposed method by applying it to both synthetic and practical\nrelational data matrices.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 12:25:58 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 06:03:40 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 14:25:32 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2102.11724", "submitter": "Lu Cheng", "authors": "Lu Cheng, Ruocheng Guo, Huan Liu", "title": "Causal Mediation Analysis with Hidden Confounders", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important problem in causal inference is to break down the total effect of\ntreatment into different causal pathways and quantify the causal effect in each\npathway. Causal mediation analysis (CMA) is a formal statistical approach for\nidentifying and estimating these causal effects. Central to CMA is the\nsequential ignorability assumption that implies all pre-treatment confounders\nare measured and they can capture different types of confounding, e.g.,\npost-treatment confounders and hidden confounders. Typically unverifiable in\nobservational studies, this assumption restrains both the coverage and\npracticality of conventional methods. This work, therefore, aims to circumvent\nthe stringent assumption by following a causal graph with a unified confounder\nand its proxy variables. Our core contribution is an algorithm that combines\ndeep latent-variable models and proxy strategy to jointly infer a unified\nsurrogate confounder and estimate different causal effects in CMA from observed\nvariables. Empirical evaluations using both synthetic and semi-synthetic\ndatasets validate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:46:11 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Cheng", "Lu", ""], ["Guo", "Ruocheng", ""], ["Liu", "Huan", ""]]}, {"id": "2102.11742", "submitter": "Sebastian Goldt", "authors": "Maria Refinetti, Sebastian Goldt, Florent Krzakala, Lenka Zdeborov\\'a", "title": "Classifying high-dimensional Gaussian mixtures: Where kernel methods\n  fail and neural networks succeed", "comments": "The accompanying code for this paper is available at\n  https://github.com/mariaref/rfvs2lnn_GMM_online", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent series of theoretical works showed that the dynamics of neural\nnetworks with a certain initialisation are well-captured by kernel methods.\nConcurrent empirical work demonstrated that kernel methods can come close to\nthe performance of neural networks on some image classification tasks. These\nresults raise the question of whether neural networks only learn successfully\nif kernels also learn successfully, despite neural networks being more\nexpressive. Here, we show theoretically that two-layer neural networks (2LNN)\nwith only a few hidden neurons can beat the performance of kernel learning on a\nsimple Gaussian mixture classification task. We study the high-dimensional\nlimit where the number of samples is linearly proportional to the input\ndimension, and show that while small 2LNN achieve near-optimal performance on\nthis task, lazy training approaches such as random features and kernel methods\ndo not. Our analysis is based on the derivation of a closed set of equations\nthat track the learning dynamics of the 2LNN and thus allow to extract the\nasymptotic performance of the network as a function of signal-to-noise ratio\nand other hyperparameters. We finally illustrate how over-parametrising the\nneural network leads to faster convergence, but does not improve its final\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:10:15 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 16:24:03 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Refinetti", "Maria", ""], ["Goldt", "Sebastian", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2102.11755", "submitter": "Stefano Sarao Mannelli", "authors": "Stefano Sarao Mannelli and Pierfrancesco Urbani", "title": "Just a Momentum: Analytical Study of Momentum-Based Acceleration Methods\n  in Paradigmatic High-Dimensional Non-Convex Problems", "comments": "8 pages, 5 figures + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When optimizing over loss functions it is common practice to use\nmomentum-based accelerated methods rather than vanilla gradient-based method.\nDespite widely applied to arbitrary loss function, their behaviour in\ngenerically non-convex, high dimensional landscapes is poorly understood. In\nthis work we used dynamical mean field theory techniques to describe\nanalytically the average behaviour of these methods in a prototypical\nnon-convex model: the (spiked) matrix-tensor model. We derive a closed set of\nequations that describe the behaviours of several algorithms including\nheavy-ball momentum and Nesterov acceleration. Additionally we characterize the\nevolution of a mathematically equivalent physical system of massive particles\nrelaxing toward the bottom of an energetic landscape. Under the correct mapping\nthe two dynamics are equivalent and it can be noticed that having a large mass\nincreases the effective time step of the heavy ball dynamics leading to a speed\nup.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:30:57 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 09:40:16 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 14:03:30 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Mannelli", "Stefano Sarao", ""], ["Urbani", "Pierfrancesco", ""]]}, {"id": "2102.11756", "submitter": "Wouter Kool", "authors": "Wouter Kool, Herke van Hoof, Joaquim Gromicho and Max Welling", "title": "Deep Policy Dynamic Programming for Vehicle Routing Problems", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing problems are a class of combinatorial problems with many practical\napplications. Recently, end-to-end deep learning methods have been proposed to\nlearn approximate solution heuristics for such problems. In contrast, classical\ndynamic programming (DP) algorithms can find optimal solutions, but scale badly\nwith the problem size. We propose Deep Policy Dynamic Programming (DPDP), which\naims to combine the strengths of learned neural heuristics with those of DP\nalgorithms. DPDP prioritizes and restricts the DP state space using a policy\nderived from a deep neural network, which is trained to predict edges from\nexample solutions. We evaluate our framework on the travelling salesman problem\n(TSP) and the vehicle routing problem (VRP) and show that the neural policy\nimproves the performance of (restricted) DP algorithms, making them competitive\nto strong alternatives such as LKH, while also outperforming other `neural\napproaches' for solving TSPs and VRPs with 100 nodes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:33:57 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Kool", "Wouter", ""], ["van Hoof", "Herke", ""], ["Gromicho", "Joaquim", ""], ["Welling", "Max", ""]]}, {"id": "2102.11757", "submitter": "Zhisheng Xiao", "authors": "Zhisheng Xiao, Qing Yan, Yali Amit", "title": "EBMs Trained with Maximum Likelihood are Generator Models Trained with a\n  Self-adverserial Loss", "comments": "EBM Wrokshop at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum likelihood estimation is widely used in training Energy-based models\n(EBMs). Training requires samples from an unnormalized distribution, which is\nusually intractable, and in practice, these are obtained by MCMC algorithms\nsuch as Langevin dynamics. However, since MCMC in high-dimensional space\nconverges extremely slowly, the current understanding of maximum likelihood\ntraining, which assumes approximate samples from the model can be drawn, is\nproblematic. In this paper, we try to understand this training procedure by\nreplacing Langevin dynamics with deterministic solutions of the associated\ngradient descent ODE. Doing so allows us to study the density induced by the\ndynamics (if the dynamics are invertible), and connect with GANs by treating\nthe dynamics as generator models, the initial values as latent variables and\nthe loss as optimizing a critic defined by the very same energy that determines\nthe generator through its gradient. Hence the term - self-adversarial loss. We\nshow that reintroducing the noise in the dynamics does not lead to a\nqualitative change in the behavior, and merely reduces the quality of the\ngenerator. We thus show that EBM training is effectively a self-adversarial\nprocedure rather than maximum likelihood estimation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:34:12 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 00:39:34 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Xiao", "Zhisheng", ""], ["Yan", "Qing", ""], ["Amit", "Yali", ""]]}, {"id": "2102.11830", "submitter": "Lorenz Richter", "authors": "Lorenz Richter, Leon Sallandt, Nikolas N\\\"usken", "title": "Solving high-dimensional parabolic PDEs using the tensor train format", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.PR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-dimensional partial differential equations (PDEs) are ubiquitous in\neconomics, science and engineering. However, their numerical treatment poses\nformidable challenges since traditional grid-based methods tend to be\nfrustrated by the curse of dimensionality. In this paper, we argue that tensor\ntrains provide an appealing approximation framework for parabolic PDEs: the\ncombination of reformulations in terms of backward stochastic differential\nequations and regression-type methods in the tensor format holds the promise of\nleveraging latent low-rank structures enabling both compression and efficient\ncomputation. Following this paradigm, we develop novel iterative schemes,\ninvolving either explicit and fast or implicit and accurate updates. We\ndemonstrate in a number of examples that our methods achieve a favorable\ntrade-off between accuracy and computational efficiency in comparison with\nstate-of-the-art neural network based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:04:00 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 14:38:16 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Richter", "Lorenz", ""], ["Sallandt", "Leon", ""], ["N\u00fcsken", "Nikolas", ""]]}, {"id": "2102.11845", "submitter": "Daniel Levy", "authors": "Daniel Levy, Ziteng Sun, Kareem Amin, Satyen Kale, Alex Kulesza,\n  Mehryar Mohri, Ananda Theertha Suresh", "title": "Learning with User-Level Privacy", "comments": "39 pages, 0 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze algorithms to solve a range of learning tasks under\nuser-level differential privacy constraints. Rather than guaranteeing only the\nprivacy of individual samples, user-level DP protects a user's entire\ncontribution ($m \\ge 1$ samples), providing more stringent but more realistic\nprotection against information leaks. We show that for high-dimensional mean\nestimation, empirical risk minimization with smooth losses, stochastic convex\noptimization, and learning hypothesis class with finite metric entropy, the\nprivacy cost decreases as $O(1/\\sqrt{m})$ as users provide more samples. In\ncontrast, when increasing the number of users $n$, the privacy cost decreases\nat a faster $O(1/n)$ rate. We complement these results with lower bounds\nshowing the worst-case optimality of our algorithm for mean estimation and\nstochastic convex optimization. Our algorithms rely on novel techniques for\nprivate mean estimation in arbitrary dimension with error scaling as the\nconcentration radius $\\tau$ of the distribution rather than the entire range.\nUnder uniform convergence, we derive an algorithm that privately answers a\nsequence of $K$ adaptively chosen queries with privacy cost proportional to\n$\\tau$, and apply it to solve the learning tasks we consider.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:25:13 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 06:37:09 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Levy", "Daniel", ""], ["Sun", "Ziteng", ""], ["Amin", "Kareem", ""], ["Kale", "Satyen", ""], ["Kulesza", "Alex", ""], ["Mohri", "Mehryar", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2102.11856", "submitter": "Vinay Verma Kumar", "authors": "Vinay Kumar Verma, Kevin Liang, Nikhil Mehta, Lawrence Carin", "title": "Meta-Learned Attribute Self-Gating for Continual Generalized Zero-Shot\n  Learning", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zero-shot learning (ZSL) has been shown to be a promising approach to\ngeneralizing a model to categories unseen during training by leveraging class\nattributes, but challenges still remain. Recently, methods using generative\nmodels to combat bias towards classes seen during training have pushed the\nstate of the art of ZSL, but these generative models can be slow or\ncomputationally expensive to train. Additionally, while many previous ZSL\nmethods assume a one-time adaptation to unseen classes, in reality, the world\nis always changing, necessitating a constant adjustment for deployed models.\nModels unprepared to handle a sequential stream of data are likely to\nexperience catastrophic forgetting. We propose a meta-continual zero-shot\nlearning (MCZSL) approach to address both these issues. In particular, by\npairing self-gating of attributes and scaled class normalization with\nmeta-learning based training, we are able to outperform state-of-the-art\nresults while being able to train our models substantially faster\n($>100\\times$) than expensive generative-based approaches. We demonstrate this\nby performing experiments on five standard ZSL datasets (CUB, aPY, AWA1, AWA2\nand SUN) in both generalized zero-shot learning and generalized continual\nzero-shot learning settings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:36:14 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Verma", "Vinay Kumar", ""], ["Liang", "Kevin", ""], ["Mehta", "Nikhil", ""], ["Carin", "Lawrence", ""]]}, {"id": "2102.11860", "submitter": "Chengyuan Yao", "authors": "Chengyuan Yao, Pavol Bielik, Petar Tsankov, Martin Vechev", "title": "Automated Discovery of Adaptive Attacks on Adversarial Defenses", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable evaluation of adversarial defenses is a challenging task, currently\nlimited to an expert who manually crafts attacks that exploit the defense's\ninner workings, or to approaches based on ensemble of fixed attacks, none of\nwhich may be effective for the specific defense at hand. Our key observation is\nthat custom attacks are composed from a set of reusable building blocks, such\nas fine-tuning relevant attack parameters, network transformations, and custom\nloss functions. Based on this observation, we present an extensible framework\nthat defines a search space over these reusable building blocks and\nautomatically discovers an effective attack on a given model with an unknown\ndefense by searching over suitable combinations of these blocks. We evaluated\nour framework on 23 adversarial defenses and showed it outperforms AutoAttack,\nthe current state-of-the-art tool for reliable evaluation of adversarial\ndefenses: our discovered attacks are either stronger, producing 3.0%-50.8%\nadditional adversarial examples (10 cases), or are typically 2x faster while\nenjoying similar adversarial robustness (13 cases).\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:43:24 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 18:46:50 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Yao", "Chengyuan", ""], ["Bielik", "Pavol", ""], ["Tsankov", "Petar", ""], ["Vechev", "Martin", ""]]}, {"id": "2102.11866", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhuoran Yang, Zhaoran Wang, Yingbin Liang", "title": "Doubly Robust Off-Policy Actor-Critic: Convergence and Optimality", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designing off-policy reinforcement learning algorithms is typically a very\nchallenging task, because a desirable iteration update often involves an\nexpectation over an on-policy distribution. Prior off-policy actor-critic (AC)\nalgorithms have introduced a new critic that uses the density ratio for\nadjusting the distribution mismatch in order to stabilize the convergence, but\nat the cost of potentially introducing high biases due to the estimation errors\nof both the density ratio and value function. In this paper, we develop a\ndoubly robust off-policy AC (DR-Off-PAC) for discounted MDP, which can take\nadvantage of learned nuisance functions to reduce estimation errors. Moreover,\nDR-Off-PAC adopts a single timescale structure, in which both actor and critics\nare updated simultaneously with constant stepsize, and is thus more sample\nefficient than prior algorithms that adopt either two timescale or nested-loop\nstructure. We study the finite-time convergence rate and characterize the\nsample complexity for DR-Off-PAC to attain an $\\epsilon$-accurate optimal\npolicy. We also show that the overall convergence of DR-Off-PAC is doubly\nrobust to the approximation errors that depend only on the expressive power of\napproximation functions. To the best of our knowledge, our study establishes\nthe first overall sample complexity analysis for a single time-scale off-policy\nAC algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:56:13 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 15:00:18 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 04:49:32 GMT"}, {"version": "v4", "created": "Sun, 18 Jul 2021 00:01:10 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Xu", "Tengyu", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Liang", "Yingbin", ""]]}, {"id": "2102.11868", "submitter": "Justin  Reyes", "authors": "Justin Reyes, Sayandip Dhara, Eduardo R. Mucciolo", "title": "Machine Learning Regression for Operator Dynamics", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.str-el stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Determining the dynamics of the expectation values for operators acting on a\nquantum many-body (QMB) system is a challenging task. Matrix product states\n(MPS) have traditionally been the \"go-to\" models for these systems because\ncalculating expectation values in this representation can be done with relative\nsimplicity and high accuracy. However, such calculations can become\ncomputationally costly when extended to long times. Here, we present a solution\nfor efficiently extending the computation of expectation values to long time\nintervals. We utilize a multi-layer perceptron (MLP) model as a tool for\nregression on MPS expectation values calculated within the regime of short time\nintervals. With this model, the computational cost of generating long-time\ndynamics is significantly reduced, while maintaining a high accuracy. These\nresults are demonstrated with operators relevant to quantum spin models in one\nspatial dimension.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:58:04 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Reyes", "Justin", ""], ["Dhara", "Sayandip", ""], ["Mucciolo", "Eduardo R.", ""]]}, {"id": "2102.11887", "submitter": "Zhou Shangnan", "authors": "Zhou Shangnan, Yixu Wang", "title": "Quantum Cross Entropy and Maximum Likelihood Principle", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT cs.LG hep-th math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantum machine learning is an emerging field at the intersection of machine\nlearning and quantum computing. Classical cross entropy plays a central role in\nmachine learning. We define its quantum generalization, the quantum cross\nentropy, and investigate its relations with the quantum fidelity and the\nmaximum likelihood principle. We also discuss its physical implications on\nquantum measurements.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 19:00:06 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Shangnan", "Zhou", ""], ["Wang", "Yixu", ""]]}, {"id": "2102.11904", "submitter": "Irina Degtiar", "authors": "Irina Degtiar and Sherri Rose", "title": "A Review of Generalizability and Transportability", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When assessing causal effects, determining the target population to which the\nresults are intended to generalize is a critical decision. Randomized and\nobservational studies each have strengths and limitations for estimating causal\neffects in a target population. Estimates from randomized data may have\ninternal validity but are often not representative of the target population.\nObservational data may better reflect the target population, and hence be more\nlikely to have external validity, but are subject to potential bias due to\nunmeasured confounding. While much of the causal inference literature has\nfocused on addressing internal validity bias, both internal and external\nvalidity are necessary for unbiased estimates in a target population. This\npaper presents a framework for addressing external validity bias, including a\nsynthesis of approaches for generalizability and transportability, the\nassumptions they require, as well as tests for the heterogeneity of treatment\neffects and differences between study and target populations.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 19:34:13 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Degtiar", "Irina", ""], ["Rose", "Sherri", ""]]}, {"id": "2102.11926", "submitter": "Alexander Tarr", "authors": "Alexander Tarr and Kosuke Imai", "title": "Estimating Average Treatment Effects with Support Vector Machines", "comments": "37 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machine (SVM) is one of the most popular classification\nalgorithms in the machine learning literature. We demonstrate that SVM can be\nused to balance covariates and estimate average causal effects under the\nunconfoundedness assumption. Specifically, we adapt the SVM classifier as a\nkernel-based weighting procedure that minimizes the maximum mean discrepancy\nbetween the treatment and control groups while simultaneously maximizing\neffective sample size. We also show that SVM is a continuous relaxation of the\nquadratic integer program for computing the largest balanced subset,\nestablishing its direct relation to the cardinality matching method. Another\nimportant feature of SVM is that the regularization parameter controls the\ntrade-off between covariate balance and effective sample size. As a result, the\nexisting SVM path algorithm can be used to compute the balance-sample size\nfrontier. We characterize the bias of causal effect estimation arising from\nthis trade-off, connecting the proposed SVM procedure to the existing kernel\nbalancing methods. Finally, we conduct simulation and empirical studies to\nevaluate the performance of the proposed methodology and find that SVM is\ncompetitive with the state-of-the-art covariate balancing methods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 20:22:56 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 17:41:14 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Tarr", "Alexander", ""], ["Imai", "Kosuke", ""]]}, {"id": "2102.11934", "submitter": "Akshay Sood", "authors": "Akshay Sood and Mark Craven", "title": "Feature Importance Explanations for Temporal Black-Box Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models in the supervised learning framework may capture rich and complex\nrepresentations over the features that are hard for humans to interpret.\nExisting methods to explain such models are often specific to architectures and\ndata where the features do not have a time-varying component. In this work, we\npropose TIME, a method to explain models that are inherently temporal in\nnature. Our approach (i) uses a model-agnostic permutation-based approach to\nanalyze global feature importance, (ii) identifies the importance of salient\nfeatures with respect to their temporal ordering as well as localized windows\nof influence, and (iii) uses hypothesis testing to provide statistical rigor.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 20:41:07 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Sood", "Akshay", ""], ["Craven", "Mark", ""]]}, {"id": "2102.11976", "submitter": "Dana Yang", "authors": "Jiaming Xu, Kuang Xu and Dana Yang", "title": "Learner-Private Online Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online convex optimization is a framework where a learner sequentially\nqueries an external data source in order to arrive at the optimal solution of a\nconvex function. The paradigm has gained significant popularity recently thanks\nto its scalability in large-scale optimization and machine learning. The\nrepeated interactions, however, expose the learner to privacy risks from\neavesdropping adversary that observe the submitted queries. In this paper, we\nstudy how to optimally obfuscate the learner's queries in first-order online\nconvex optimization, so that their learned optimal value is provably difficult\nto estimate for the eavesdropping adversary. We consider two formulations of\nlearner privacy: a Bayesian formulation in which the convex function is drawn\nrandomly, and a minimax formulation in which the function is fixed and the\nadversary's probability of error is measured with respect to a minimax\ncriterion. We show that, if the learner wants to ensure the probability of\naccurate prediction by the adversary be kept below $1/L$, then the overhead in\nquery complexity is additive in $L$ in the minimax formulation, but\nmultiplicative in $L$ in the Bayesian formulation. Compared to existing\nlearner-private sequential learning models with binary feedback, our results\napply to the significantly richer family of general convex functions with\nfull-gradient feedback. Our proofs are largely enabled by tools from the theory\nof Dirichlet processes, as well as more sophisticated lines of analysis aimed\nat measuring the amount of information leakage under a full-gradient oracle.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 23:00:44 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Xu", "Jiaming", ""], ["Xu", "Kuang", ""], ["Yang", "Dana", ""]]}, {"id": "2102.12002", "submitter": "Ecenaz Erdemir", "authors": "Ecenaz Erdemir, Jeffrey Bickford, Luca Melis and Sergul Aydore", "title": "Adversarial Robustness with Non-uniform Perturbations", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of machine learning models is critical for security related\napplications, where real-world adversaries are uniquely focused on evading\nneural network based detectors. Prior work mainly focus on crafting adversarial\nexamples (AEs) with small uniform norm-bounded perturbations across features to\nmaintain the requirement of imperceptibility. However, uniform perturbations do\nnot result in realistic AEs in domains such as malware, finance, and social\nnetworks. For these types of applications, features typically have some\nsemantically meaningful dependencies. The key idea of our proposed approach is\nto enable non-uniform perturbations that can adequately represent these feature\ndependencies during adversarial training. We propose using characteristics of\nthe empirical data distribution, both on correlations between the features and\nthe importance of the features themselves. Using experimental datasets for\nmalware classification, credit risk prediction, and spam detection, we show\nthat our approach is more robust to real-world attacks. Finally, we present\nrobustness certification utilizing non-uniform perturbation bounds, and show\nthat non-uniform bounds achieve better certification.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 00:54:43 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 21:40:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Erdemir", "Ecenaz", ""], ["Bickford", "Jeffrey", ""], ["Melis", "Luca", ""], ["Aydore", "Sergul", ""]]}, {"id": "2102.12013", "submitter": "Jianfeng Chi", "authors": "Jianfeng Chi, Yuan Tian, Geoffrey J. Gordon, Han Zhao", "title": "Understanding and Mitigating Accuracy Disparity in Regression", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread deployment of large-scale prediction systems in\nhigh-stakes domains, e.g., face recognition, criminal justice, etc., disparity\nin prediction accuracy between different demographic subgroups has called for\nfundamental understanding on the source of such disparity and algorithmic\nintervention to mitigate it. In this paper, we study the accuracy disparity\nproblem in regression. To begin with, we first propose an error decomposition\ntheorem, which decomposes the accuracy disparity into the distance between\nmarginal label distributions and the distance between conditional\nrepresentations, to help explain why such accuracy disparity appears in\npractice. Motivated by this error decomposition and the general idea of\ndistribution alignment with statistical distances, we then propose an algorithm\nto reduce this disparity, and analyze its game-theoretic optima of the proposed\nobjective functions. To corroborate our theoretical findings, we also conduct\nexperiments on five benchmark datasets. The experimental results suggest that\nour proposed algorithms can effectively mitigate accuracy disparity while\nmaintaining the predictive power of the regression models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 01:24:50 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 01:41:56 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chi", "Jianfeng", ""], ["Tian", "Yuan", ""], ["Gordon", "Geoffrey J.", ""], ["Zhao", "Han", ""]]}, {"id": "2102.12066", "submitter": "Gil Kur", "authors": "Gil Kur, Alexander Rakhlin", "title": "On the Minimal Error of Empirical Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimal error of the Empirical Risk Minimization (ERM) procedure\nin the task of regression, both in the random and the fixed design settings.\nOur sharp lower bounds shed light on the possibility (or impossibility) of\nadapting to simplicity of the model generating the data. In the fixed design\nsetting, we show that the error is governed by the global complexity of the\nentire class. In contrast, in random design, ERM may only adapt to simpler\nmodels if the local neighborhoods around the regression function are nearly as\ncomplex as the class itself, a somewhat counter-intuitive conclusion. We\nprovide sharp lower bounds for performance of ERM for both Donsker and\nnon-Donsker classes. We also discuss our results through the lens of recent\nstudies on interpolation in overparameterized models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 04:47:55 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Kur", "Gil", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "2102.12108", "submitter": "Sebastian Ober", "authors": "Sebastian W. Ober, Carl E. Rasmussen, Mark van der Wilk", "title": "The Promises and Pitfalls of Deep Kernel Learning", "comments": "Accepted for the 37th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2021), 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep kernel learning (DKL) and related techniques aim to combine the\nrepresentational power of neural networks with the reliable uncertainty\nestimates of Gaussian processes. One crucial aspect of these models is an\nexpectation that, because they are treated as Gaussian process models optimized\nusing the marginal likelihood, they are protected from overfitting. However, we\nidentify situations where this is not the case. We explore this behavior,\nexplain its origins and consider how it applies to real datasets. Through\ncareful experimentation on the UCI, CIFAR-10, and the UTKFace datasets, we find\nthat the overfitting from overparameterized maximum marginal likelihood, in\nwhich the model is \"somewhat Bayesian\", can in certain scenarios be worse than\nthat from not being Bayesian at all. We explain how and when DKL can still be\nsuccessful by investigating optimization dynamics. We also find that failures\nof DKL can be rectified by a fully Bayesian treatment, which leads to the\ndesired performance improvements over standard neural networks and Gaussian\nprocesses.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 07:56:49 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 15:42:13 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Ober", "Sebastian W.", ""], ["Rasmussen", "Carl E.", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2102.12178", "submitter": "Julien Lacombe", "authors": "Julien Lacombe, Julie Digne, Nicolas Courty, Nicolas Bonneel", "title": "Learning to Generate Wasserstein Barycenters", "comments": "18 pages, 16 figures, submitted to the Machine Learning journal\n  (Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimal transport is a notoriously difficult problem to solve numerically,\nwith current approaches often remaining intractable for very large scale\napplications such as those encountered in machine learning. Wasserstein\nbarycenters -- the problem of finding measures in-between given input measures\nin the optimal transport sense -- is even more computationally demanding as it\nrequires to solve an optimization problem involving optimal transport\ndistances. By training a deep convolutional neural network, we improve by a\nfactor of 60 the computational speed of Wasserstein barycenters over the\nfastest state-of-the-art approach on the GPU, resulting in milliseconds\ncomputational times on $512\\times512$ regular grids. We show that our network,\ntrained on Wasserstein barycenters of pairs of measures, generalizes well to\nthe problem of finding Wasserstein barycenters of more than two measures. We\ndemonstrate the efficiency of our approach for computing barycenters of\nsketches and transferring colors between multiple images.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 10:13:48 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Lacombe", "Julien", ""], ["Digne", "Julie", ""], ["Courty", "Nicolas", ""], ["Bonneel", "Nicolas", ""]]}, {"id": "2102.12196", "submitter": "Leo Schwinn", "authors": "Leo Schwinn and An Nguyen and Ren\\'e Raab and Leon Bungert and Daniel\n  Tenbrinck and Dario Zanca and Martin Burger and Bjoern Eskofier", "title": "Identifying Untrustworthy Predictions in Neural Networks by Geometric\n  Gradient Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The susceptibility of deep neural networks to untrustworthy predictions,\nincluding out-of-distribution (OOD) data and adversarial examples, still\nprevent their widespread use in safety-critical applications. Most existing\nmethods either require a re-training of a given model to achieve robust\nidentification of adversarial attacks or are limited to out-of-distribution\nsample detection only. In this work, we propose a geometric gradient analysis\n(GGA) to improve the identification of untrustworthy predictions without\nretraining of a given model. GGA analyzes the geometry of the loss landscape of\nneural networks based on the saliency maps of their respective input. To\nmotivate the proposed approach, we provide theoretical connections between\ngradients' geometrical properties and local minima of the loss function.\nFurthermore, we demonstrate that the proposed method outperforms prior\napproaches in detecting OOD data and adversarial attacks, including\nstate-of-the-art and adaptive attacks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 10:49:02 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Schwinn", "Leo", ""], ["Nguyen", "An", ""], ["Raab", "Ren\u00e9", ""], ["Bungert", "Leon", ""], ["Tenbrinck", "Daniel", ""], ["Zanca", "Dario", ""], ["Burger", "Martin", ""], ["Eskofier", "Bjoern", ""]]}, {"id": "2102.12238", "submitter": "Meena Jagadeesan", "authors": "Meena Jagadeesan, Ilya Razenshteyn, Suriya Gunasekar", "title": "Inductive Bias of Multi-Channel Linear Convolutional Networks with\n  Bounded Weight Norm", "comments": "Updated version with revised and expanded content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the function space characterization of the inductive bias resulting\nfrom controlling the $\\ell_2$ norm of the weights in linear convolutional\nnetworks. We view this in terms of an induced regularizer in the function space\ngiven by the minimum norm of weights required to realize a linear function. For\ntwo layer linear convolutional networks with $C$ output channels and kernel\nsize $K$, we show the following: (a) If the inputs to the network have a single\nchannel, the induced regularizer for any $K$ is a norm given by a semidefinite\nprogram (SDP) that is independent of the number of output channels $C$. (b) In\ncontrast, for networks with multi-channel inputs, multiple output channels can\nbe necessary to merely realize all matrix-valued linear functions and thus the\ninductive bias does depend on $C$. Further, for sufficiently large $C$, the\ninduced regularizer for $K=1$ and $K=D$ are the nuclear norm and the\n$\\ell_{2,1}$ group-sparse norm, respectively, of the Fourier coefficients. (c)\nComplementing our theoretical results, we show through experiments on MNIST and\nCIFAR-10 that our key findings extend to implicit biases from gradient descent\nin overparameterized networks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 12:01:23 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 23:53:01 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Jagadeesan", "Meena", ""], ["Razenshteyn", "Ilya", ""], ["Gunasekar", "Suriya", ""]]}, {"id": "2102.12258", "submitter": "Nicolas Schreuder", "authors": "Nicolas Schreuder and Evgenii Chzhen", "title": "Classification with abstention but without disparities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification with abstention has gained a lot of attention in recent years\nas it allows to incorporate human decision-makers in the process. Yet,\nabstention can potentially amplify disparities and lead to discriminatory\npredictions. The goal of this work is to build a general purpose classification\nalgorithm, which is able to abstain from prediction, while avoiding disparate\nimpact. We formalize this problem as risk minimization under fairness and\nabstention constraints for which we derive the form of the optimal classifier.\nBuilding on this result, we propose a post-processing classification algorithm,\nwhich is able to modify any off-the-shelf score-based classifier using only\nunlabeled sample. We establish finite sample risk, fairness, and abstention\nguarantees for the proposed algorithm. In particular, it is shown that fairness\nand abstention constraints can be achieved independently from the initial\nclassifier as long as sufficiently many unlabeled data is available. The risk\nguarantee is established in terms of the quality of the initial classifier. Our\npost-processing scheme reduces to a sparse linear program allowing for an\nefficient implementation, which we provide. Finally, we validate our method\nempirically showing that moderate abstention rates allow to bypass the\nrisk-fairness trade-off.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 12:43:55 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Schreuder", "Nicolas", ""], ["Chzhen", "Evgenii", ""]]}, {"id": "2102.12261", "submitter": "Kody Law", "authors": "Kody J. H. Law and Vitaly Zankin", "title": "Sparse online variational Bayesian regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers variational Bayesian inference as an inexpensive and\nscalable alternative to a fully Bayesian approach in the context of\nsparsity-promoting priors. In particular, the priors considered arise from\nscale mixtures of Normal distributions with a generalized inverse Gaussian\nmixing distribution. This includes the variational Bayesian LASSO as an\ninexpensive and scalable alternative to the Bayesian LASSO introduced in [56].\nIt also includes priors which more strongly promote sparsity. For linear models\nthe method requires only the iterative solution of deterministic least squares\nproblems. Furthermore, for $n\\rightarrow \\infty$ data points and p unknown\ncovariates the method can be implemented exactly online with a cost of O(p$^3$)\nin computation and O(p$^2$) in memory. For large p an approximation is able to\nachieve promising results for a cost of O(p) in both computation and memory.\nStrategies for hyper-parameter tuning are also considered. The method is\nimplemented for real and simulated data. It is shown that the performance in\nterms of variable selection and uncertainty quantification of the variational\nBayesian LASSO can be comparable to the Bayesian LASSO for problems which are\ntractable with that method, and for a fraction of the cost. The present method\ncomfortably handles n = p = 131,073 on a laptop in minutes, and n = 10$^5$, p =\n10$^6$ overnight.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 12:49:42 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Law", "Kody J. H.", ""], ["Zankin", "Vitaly", ""]]}, {"id": "2102.12293", "submitter": "Florent Chatelain", "authors": "Romain Couillet and Florent Chatelain and Nicolas Le Bihan", "title": "Two-way kernel matrix puncturing: towards resource-efficient PCA and\n  spectral clustering", "comments": "24 pages (10 for the core paper, 14 for the proofs in supplementary\n  materials) , 10 figures. Final version to be published in ICML 2021\n  proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article introduces an elementary cost and storage reduction method for\nspectral clustering and principal component analysis. The method consists in\nrandomly \"puncturing\" both the data matrix $X\\in\\mathbb{C}^{p\\times n}$ (or\n$\\mathbb{R}^{p\\times n}$) and its corresponding kernel (Gram) matrix $K$\nthrough Bernoulli masks: $S\\in\\{0,1\\}^{p\\times n}$ for $X$ and\n$B\\in\\{0,1\\}^{n\\times n}$ for $K$. The resulting \"two-way punctured\" kernel is\nthus given by $K=\\frac{1}{p}[(X \\odot S)^{\\sf H} (X \\odot S)] \\odot B$. We\ndemonstrate that, for $X$ composed of independent columns drawn from a Gaussian\nmixture model, as $n,p\\to\\infty$ with $p/n\\to c_0\\in(0,\\infty)$, the spectral\nbehavior of $K$ -- its limiting eigenvalue distribution, as well as its\nisolated eigenvalues and eigenvectors -- is fully tractable and exhibits a\nseries of counter-intuitive phenomena. We notably prove, and empirically\nconfirm on GAN-generated image databases, that it is possible to drastically\npuncture the data, thereby providing possibly huge computational and storage\ngains, for a virtually constant (clustering of PCA) performance. This\npreliminary study opens as such the path towards rethinking, from a large\ndimensional standpoint, computational and storage costs in elementary machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:01:58 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 16:16:06 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 06:58:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Couillet", "Romain", ""], ["Chatelain", "Florent", ""], ["Bihan", "Nicolas Le", ""]]}, {"id": "2102.12301", "submitter": "Aditya Desai", "authors": "Aditya Desai, Benjamin Coleman, Anshumali Shrivastava", "title": "Density Sketches for Sampling and Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Density sketches (DS): a succinct online summary of the data\ndistribution. DS can accurately estimate point wise probability density.\nInterestingly, DS also provides a capability to sample unseen novel data from\nthe underlying data distribution. Thus, analogous to popular generative models,\nDS allows us to succinctly replace the real-data in almost all machine learning\npipelines with synthetic examples drawn from the same distribution as the\noriginal data. However, unlike generative models, which do not have any\nstatistical guarantees, DS leads to theoretically sound asymptotically\nconverging consistent estimators of the underlying density function. Density\nsketches also have many appealing properties making them ideal for large-scale\ndistributed applications. DS construction is an online algorithm. The sketches\nare additive, i.e., the sum of two sketches is the sketch of the combined data.\nThese properties allow data to be collected from distributed sources,\ncompressed into a density sketch, efficiently transmitted in the sketch form to\na central server, merged, and re-sampled into a synthetic database for modeling\napplications. Thus, density sketches can potentially revolutionize how we\nstore, communicate, and distribute data.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:30:18 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Desai", "Aditya", ""], ["Coleman", "Benjamin", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2102.12318", "submitter": "Evgenii Chzhen", "authors": "Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Titouan Lorieul", "title": "Set-valued classification -- overview via a unified framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-class classification problem is among the most popular and well-studied\nstatistical frameworks. Modern multi-class datasets can be extremely ambiguous\nand single-output predictions fail to deliver satisfactory performance. By\nallowing predictors to predict a set of label candidates, set-valued\nclassification offers a natural way to deal with this ambiguity. Several\nformulations of set-valued classification are available in the literature and\neach of them leads to different prediction strategies. The present survey aims\nto review popular formulations using a unified statistical framework. The\nproposed framework encompasses previously considered and leads to new\nformulations as well as it allows to understand underlying trade-offs of each\nformulation. We provide infinite sample optimal set-valued classification\nstrategies and review a general plug-in principle to construct data-driven\nalgorithms. The exposition is supported by examples and pointers to both\ntheoretical and practical contributions. Finally, we provide experiments on\nreal-world datasets comparing these approaches in practice and providing\ngeneral practical guidelines.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:54:07 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Chzhen", "Evgenii", ""], ["Denis", "Christophe", ""], ["Hebiri", "Mohamed", ""], ["Lorieul", "Titouan", ""]]}, {"id": "2102.12342", "submitter": "Zi-Jing Liu", "authors": "Zijing Liu, Mauricio Barahona", "title": "Similarity measure for sparse time course data based on Gaussian\n  processes", "comments": "10pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a similarity measure for sparsely sampled time course data in the\nform of a log-likelihood ratio of Gaussian processes (GP). The proposed GP\nsimilarity is similar to a Bayes factor and provides enhanced robustness to\nnoise in sparse time series, such as those found in various biological\nsettings, e.g., gene transcriptomics. We show that the GP measure is equivalent\nto the Euclidean distance when the noise variance in the GP is negligible\ncompared to the noise variance of the signal. Our numerical experiments on both\nsynthetic and real data show improved performance of the GP similarity when\nused in conjunction with two distance-based clustering methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:23:30 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Liu", "Zijing", ""], ["Barahona", "Mauricio", ""]]}, {"id": "2102.12353", "submitter": "Chaochao Lu", "authors": "Chaochao Lu, Yuhuai Wu, Jo\\'se Miguel Hern\\'andez-Lobato, Bernhard\n  Sch\\\"olkopf", "title": "Nonlinear Invariant Risk Minimization: A Causal Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to spurious correlations, machine learning systems often fail to\ngeneralize to environments whose distributions differ from the ones used at\ntraining time. Prior work addressing this, either explicitly or implicitly,\nattempted to find a data representation that has an invariant relationship with\nthe target. This is done by leveraging a diverse set of training environments\nto reduce the effect of spurious features and build an invariant predictor.\nHowever, these methods have generalization guarantees only when both data\nrepresentation and classifiers come from a linear model class. We propose\ninvariant Causal Representation Learning (iCaRL), an approach that enables\nout-of-distribution (OOD) generalization in the nonlinear setting (i.e.,\nnonlinear representations and nonlinear classifiers). It builds upon a\npractical and general assumption: the prior over the data representation (i.e.,\na set of latent variables encoding the data) given the target and the\nenvironment belongs to general exponential family distributions. Based on this,\nwe show that it is possible to identify the data representation up to simple\ntransformations. We also prove that all direct causes of the target can be\nfully discovered, which further enables us to obtain generalization guarantees\nin the nonlinear setting. Extensive experiments on both synthetic and\nreal-world datasets show that our approach outperforms a variety of baseline\nmethods. Finally, in the discussion, we further explore the aforementioned\nassumption and propose a more general hypothesis, called the Agnostic\nHypothesis: there exist a set of hidden causal factors affecting both inputs\nand outcomes. The Agnostic Hypothesis can provide a unifying view of machine\nlearning. More importantly, it can inspire a new direction to explore a general\ntheory for identifying hidden causal factors, which is key to enabling the OOD\ngeneralization guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:38:41 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 16:47:25 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 13:36:49 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Lu", "Chaochao", ""], ["Wu", "Yuhuai", ""], ["Hern\u00e1ndez-Lobato", "Jo\u015be Miguel", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2102.12412", "submitter": "Antti Koskela", "authors": "Antti Koskela and Antti Honkela", "title": "Computing Differential Privacy Guarantees for Heterogeneous Compositions\n  Using FFT", "comments": "44 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recently proposed Fast Fourier Transform (FFT)-based accountant for\nevaluating $(\\varepsilon,\\delta)$-differential privacy guarantees using the\nprivacy loss distribution formalism has been shown to give tighter bounds than\ncommonly used methods such as R\\'enyi accountants when applied to homogeneous\ncompositions, i.e., to compositions of identical mechanisms. In this paper, we\nextend this approach to heterogeneous compositions. We carry out a full error\nanalysis that allows choosing the parameters of the algorithm such that a\ndesired accuracy is obtained. The analysis also extends previous results by\ntaking into account all the parameters of the algorithm. Using the error\nanalysis, we also give a bound for the computational complexity in terms of the\nerror which is analogous to and slightly tightens the one given by Murtagh and\nVadhan (2018). We also show how to speed up the evaluation of tight privacy\nguarantees using the Plancherel theorem at the cost of increased\npre-computation and memory usage.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 17:05:38 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 11:27:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Koskela", "Antti", ""], ["Honkela", "Antti", ""]]}, {"id": "2102.12430", "submitter": "Tianyi Liu", "authors": "Tianyi Liu, Yan Li, Song Wei, Enlu Zhou and Tuo Zhao", "title": "Noisy Gradient Descent Converges to Flat Minima for Nonconvex Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous empirical evidences have corroborated the importance of noise in\nnonconvex optimization problems. The theory behind such empirical observations,\nhowever, is still largely unknown. This paper studies this fundamental problem\nthrough investigating the nonconvex rectangular matrix factorization problem,\nwhich has infinitely many global minima due to rotation and scaling invariance.\nHence, gradient descent (GD) can converge to any optimum, depending on the\ninitialization. In contrast, we show that a perturbed form of GD with an\narbitrary initialization converges to a global optimum that is uniquely\ndetermined by the injected noise. Our result implies that the noise imposes\nimplicit bias towards certain optima. Numerical experiments are provided to\nsupport our theory.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 17:50:17 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Liu", "Tianyi", ""], ["Li", "Yan", ""], ["Wei", "Song", ""], ["Zhou", "Enlu", ""], ["Zhao", "Tuo", ""]]}, {"id": "2102.12439", "submitter": "I\\~nigo Urteaga", "authors": "Kathy Li and I\\~nigo Urteaga and Amanda Shea and Virginia J. Vitzthum\n  and Chris H. Wiggins and No\\'emie Elhadad", "title": "A generative, predictive model for menstrual cycle lengths that accounts\n  for potential self-tracking artifacts in mobile health data", "comments": "Extended version of the work presented at the NeurIPS 2020 Machine\n  Learning for Mobile Health Workshop (see\n  https://sites.google.com/view/ml4mobilehealth-neurips-2020/home)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile health (mHealth) apps such as menstrual trackers provide a rich source\nof self-tracked health observations that can be leveraged for health-relevant\nresearch. However, such data streams have questionable reliability since they\nhinge on user adherence to the app. Therefore, it is crucial for researchers to\nseparate true behavior from self-tracking artifacts. By taking a machine\nlearning approach to modeling self-tracked cycle lengths, we can both make more\ninformed predictions and learn the underlying structure of the observed data.\nIn this work, we propose and evaluate a hierarchical, generative model for\npredicting next cycle length based on previously-tracked cycle lengths that\naccounts explicitly for the possibility of users skipping tracking their\nperiod. Our model offers several advantages: 1) accounting explicitly for\nself-tracking artifacts yields better prediction accuracy as likelihood of\nskipping increases; 2) because it is a generative model, predictions can be\nupdated online as a given cycle evolves, and we can gain interpretable insight\ninto how these predictions change over time; and 3) its hierarchical nature\nenables modeling of an individual's cycle length history while incorporating\npopulation-level information. Our experiments using mHealth cycle length data\nencompassing over 186,000 menstruators with over 2 million natural menstrual\ncycles show that our method yields state-of-the-art performance against neural\nnetwork-based and summary statistic-based baselines, while providing insights\non disentangling menstrual patterns from self-tracking artifacts. This work can\nbenefit users, mHealth app developers, and researchers in better understanding\ncycle patterns and user adherence.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 18:00:26 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 20:47:42 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Li", "Kathy", ""], ["Urteaga", "I\u00f1igo", ""], ["Shea", "Amanda", ""], ["Vitzthum", "Virginia J.", ""], ["Wiggins", "Chris H.", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "2102.12467", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey", "title": "No-Regret Algorithms for Private Gaussian Process Bandit Optimization", "comments": "AISTATS21 Camera Ready v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread proliferation of data-driven decision-making has ushered in a\nrecent interest in the design of privacy-preserving algorithms. In this paper,\nwe consider the ubiquitous problem of gaussian process (GP) bandit optimization\nfrom the lens of privacy-preserving statistics. We propose a solution for\ndifferentially private GP bandit optimization that combines a uniform kernel\napproximator with random perturbations, providing a generic framework to create\ndifferentially-private (DP) Gaussian process bandit algorithms. For two\nspecific DP settings - joint and local differential privacy, we provide\nalgorithms based on efficient quadrature Fourier feature approximators, that\nare computationally efficient and provably no-regret for popular stationary\nkernel functions. Our algorithms maintain differential privacy throughout the\noptimization procedure and critically do not rely explicitly on the sample path\nfor prediction, making the parameters straightforward to release as well.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 18:52:24 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Dubey", "Abhimanyu", ""]]}, {"id": "2102.12470", "submitter": "Zhiyuan Li", "authors": "Zhiyuan Li, Sadhika Malladi, Sanjeev Arora", "title": "On the Validity of Modeling SGD with Stochastic Differential Equations\n  (SDEs)", "comments": "36 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It is generally recognized that finite learning rate (LR), in contrast to\ninfinitesimal LR, is important for good generalization in real-life deep nets.\nMost attempted explanations propose approximating finite-LR SGD with Ito\nStochastic Differential Equations (SDEs), but formal justification for this\napproximation (e.g., (Li et al., 2019)) only applies to SGD with tiny LR.\nExperimental verification of the approximation appears computationally\ninfeasible. The current paper clarifies the picture with the following\ncontributions: (a) An efficient simulation algorithm SVAG that provably\nconverges to the conventionally used Ito SDE approximation. (b) A theoretically\nmotivated testable necessary condition for the SDE approximation and its most\nfamous implication, the linear scaling rule (Goyal et al., 2017), to hold. (c)\nExperiments using this simulation to demonstrate that the previously proposed\nSDE approximation can meaningfully capture the training and generalization\nproperties of common deep nets.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 18:55:00 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 18:00:13 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Li", "Zhiyuan", ""], ["Malladi", "Sadhika", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2102.12478", "submitter": "W.J. Handley", "authors": "Justin Alsing and Will Handley", "title": "Nested sampling with any prior you like", "comments": "5 pages, 2 figures, Published as an MNRAS letter", "journal-ref": "MNRAS 505, L95-L99 (2021)", "doi": "10.1093/mnrasl/slab057", "report-no": null, "categories": "astro-ph.IM astro-ph.CO physics.data-an stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested sampling is an important tool for conducting Bayesian analysis in\nAstronomy and other fields, both for sampling complicated posterior\ndistributions for parameter inference, and for computing marginal likelihoods\nfor model comparison. One technical obstacle to using nested sampling in\npractice is the requirement (for most common implementations) that prior\ndistributions be provided in the form of transformations from the unit\nhyper-cube to the target prior density. For many applications - particularly\nwhen using the posterior from one experiment as the prior for another - such a\ntransformation is not readily available. In this letter we show that parametric\nbijectors trained on samples from a desired prior density provide a\ngeneral-purpose method for constructing transformations from the uniform base\ndensity to a target prior, enabling the practical use of nested sampling under\narbitrary priors. We demonstrate the use of trained bijectors in conjunction\nwith nested sampling on a number of examples from cosmology.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 18:45:13 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 21:02:29 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 15:37:48 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Alsing", "Justin", ""], ["Handley", "Will", ""]]}, {"id": "2102.12561", "submitter": "Indrayudh Ghosal", "authors": "Indrayudh Ghosal, Giles Hooker", "title": "Generalised Boosted Forests", "comments": "Paper: 14 pages, 4 figures, 3 tables; Appendix: 34 pages, 28 figures,\n  1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper extends recent work on boosting random forests to model\nnon-Gaussian responses. Given an exponential family $\\mathbb{E}[Y|X] =\ng^{-1}(f(X))$ our goal is to obtain an estimate for $f$. We start with an\nMLE-type estimate in the link space and then define generalised residuals from\nit. We use these residuals and some corresponding weights to fit a base random\nforest and then repeat the same to obtain a boost random forest. We call the\nsum of these three estimators a \\textit{generalised boosted forest}. We show\nwith simulated and real data that both the random forest steps reduces test-set\nlog-likelihood, which we treat as our primary metric. We also provide a\nvariance estimator, which we can obtain with the same computational cost as the\noriginal estimate itself. Empirical experiments on real-world data and\nsimulations demonstrate that the methods can effectively reduce bias, and that\nconfidence interval coverage is conservative in the bulk of the covariate\ndistribution.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 21:17:31 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 23:15:16 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Ghosal", "Indrayudh", ""], ["Hooker", "Giles", ""]]}, {"id": "2102.12569", "submitter": "Tianfang Zhang", "authors": "Tianfang Zhang and Rasmus Bokrantz and Jimmy Olsson", "title": "Probabilistic feature extraction, dose statistic prediction and dose\n  mimicking for automated radiation therapy treatment planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: We propose a general framework for quantifying predictive\nuncertainties of dose-related quantities and leveraging this information in a\ndose mimicking problem in the context of automated radiation therapy treatment\nplanning.\n  Methods: A three-step pipeline, comprising feature extraction, dose statistic\nprediction and dose mimicking, is employed. In particular, the features are\nproduced by a convolutional variational autoencoder and used as inputs in a\npreviously developed nonparametric Bayesian statistical method, estimating the\nmultivariate predictive distribution of a collection of predefined dose\nstatistics. Specially developed objective functions are then used to construct\na probabilistic dose mimicking problem based on the produced distributions,\ncreating deliverable treatment plans.\n  Results: The numerical experiments are performed using a dataset of 94\nretrospective treatment plans of prostate cancer patients. We show that the\nfeatures extracted by the variational autoencoder capture geometric information\nof substantial relevance to the dose statistic prediction problem and are\nrelated to dose statistics in a more regularized fashion than hand-crafted\nfeatures. The estimated predictive distributions are reasonable and outperforms\na non-input-dependent benchmark method, and the deliverable plans produced by\nthe probabilistic dose mimicking agree better with their clinical counterparts\nthan for a non-probabilistic formulation.\n  Conclusions: We demonstrate that prediction of dose-related quantities may be\nextended to include uncertainty estimation and that such probabilistic\ninformation may be leveraged in a dose mimicking problem. The treatment plans\nproduced by the proposed pipeline resemble their original counterparts well,\nillustrating the merits of a holistic approach to automated planning based on\nprobabilistic modeling.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 21:35:44 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 14:51:41 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 10:43:45 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhang", "Tianfang", ""], ["Bokrantz", "Rasmus", ""], ["Olsson", "Jimmy", ""]]}, {"id": "2102.12608", "submitter": "Asaf Cassel", "authors": "Asaf Cassel (1), Tomer Koren ((1) School of Computer Science, Tel Aviv\n  University)", "title": "Online Policy Gradient for Model Free Learning of Linear Quadratic\n  Regulators with $\\sqrt{T}$ Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of learning to control a linear dynamical system under\nfixed quadratic costs, known as the Linear Quadratic Regulator (LQR) problem.\nWhile model-free approaches are often favorable in practice, thus far only\nmodel-based methods, which rely on costly system identification, have been\nshown to achieve regret that scales with the optimal dependence on the time\nhorizon T. We present the first model-free algorithm that achieves similar\nregret guarantees. Our method relies on an efficient policy gradient scheme,\nand a novel and tighter analysis of the cost of exploration in policy space in\nthis setting.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 00:25:41 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Cassel", "Asaf", ""], ["Koren", "Tomer", ""]]}, {"id": "2102.12611", "submitter": "Dong Yin", "authors": "Nevena Lazic, Dong Yin, Yasin Abbasi-Yadkori, Csaba Szepesvari", "title": "Improved Regret Bound and Experience Replay in Regularized Policy\n  Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study algorithms for learning in infinite-horizon\nundiscounted Markov decision processes (MDPs) with function approximation. We\nfirst show that the regret analysis of the Politex algorithm (a version of\nregularized policy iteration) can be sharpened from $O(T^{3/4})$ to\n$O(\\sqrt{T})$ under nearly identical assumptions, and instantiate the bound\nwith linear function approximation. Our result provides the first\nhigh-probability $O(\\sqrt{T})$ regret bound for a computationally efficient\nalgorithm in this setting. The exact implementation of Politex with neural\nnetwork function approximation is inefficient in terms of memory and\ncomputation. Since our analysis suggests that we need to approximate the\naverage of the action-value functions of past policies well, we propose a\nsimple efficient implementation where we train a single Q-function on a replay\nbuffer with past data. We show that this often leads to superior performance\nover other implementation choices, especially in terms of wall-clock time. Our\nwork also provides a novel theoretical justification for using experience\nreplay within policy iteration algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 00:55:07 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Lazic", "Nevena", ""], ["Yin", "Dong", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "2102.12643", "submitter": "Thanh Nguyen", "authors": "Thanh V. Nguyen, Gauri Jagatap and Chinmay Hegde", "title": "Provable Compressed Sensing with Generative Priors via Langevin Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have emerged as a powerful class of priors for signals\nin various inverse problems such as compressed sensing, phase retrieval and\nsuper-resolution. Here, we assume an unknown signal to lie in the range of some\npre-trained generative model. A popular approach for signal recovery is via\ngradient descent in the low-dimensional latent space. While gradient descent\nhas achieved good empirical performance, its theoretical behavior is not well\nunderstood. In this paper, we introduce the use of stochastic gradient Langevin\ndynamics (SGLD) for compressed sensing with a generative prior. Under mild\nassumptions on the generative model, we prove the convergence of SGLD to the\ntrue signal. We also demonstrate competitive empirical performance to standard\ngradient descent.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 02:35:14 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Nguyen", "Thanh V.", ""], ["Jagatap", "Gauri", ""], ["Hegde", "Chinmay", ""]]}, {"id": "2102.12648", "submitter": "Yuanqing Wang", "authors": "Yuanqing Wang, Theofanis Karaletsos", "title": "Stochastic Aggregation in Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) manifest pathologies including over-smoothing\nand limited discriminating power as a result of suboptimally expressive\naggregating mechanisms. We herein present a unifying framework for stochastic\naggregation (STAG) in GNNs, where noise is (adaptively) injected into the\naggregation process from the neighborhood to form node embeddings. We provide\ntheoretical arguments that STAG models, with little overhead, remedy both of\nthe aforementioned problems. In addition to fixed-noise models, we also propose\nprobabilistic versions of STAG models and a variational inference framework to\nlearn the noise posterior. We conduct illustrative experiments clearly\ntargeting oversmoothing and multiset aggregation limitations. Furthermore, STAG\nenhances general performance of GNNs demonstrated by competitive performance in\ncommon citation and molecule graph benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 02:52:03 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 04:46:00 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Wang", "Yuanqing", ""], ["Karaletsos", "Theofanis", ""]]}, {"id": "2102.12660", "submitter": "Mohammad Mahdi Kamani", "authors": "Yuyang Deng, Mohammad Mahdi Kamani, Mehrdad Mahdavi", "title": "Distributionally Robust Federated Averaging", "comments": "Published in NeurIPS 2020:\n  https://proceedings.neurips.cc/paper/2020/hash/ac450d10e166657ec8f93a1b65ca1b14-Abstract.html", "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS), Vol.\n  33, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study communication efficient distributed algorithms for\ndistributionally robust federated learning via periodic averaging with adaptive\nsampling. In contrast to standard empirical risk minimization, due to the\nminimax structure of the underlying optimization problem, a key difficulty\narises from the fact that the global parameter that controls the mixture of\nlocal losses can only be updated infrequently on the global stage. To\ncompensate for this, we propose a Distributionally Robust Federated Averaging\n(DRFA) algorithm that employs a novel snapshotting scheme to approximate the\naccumulation of history gradients of the mixing parameter. We analyze the\nconvergence rate of DRFA in both convex-linear and nonconvex-linear settings.\nWe also generalize the proposed idea to objectives with regularization on the\nmixture parameter and propose a proximal variant, dubbed as DRFA-Prox, with\nprovable convergence rates. We also analyze an alternative optimization method\nfor regularized cases in strongly-convex-strongly-concave and non-convex (under\nPL condition)-strongly-concave settings. To the best of our knowledge, this\npaper is the first to solve distributionally robust federated learning with\nreduced communication, and to analyze the efficiency of local descent methods\non distributed minimax problems. We give corroborating experimental evidence\nfor our theoretical results in federated learning settings.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 03:32:09 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Deng", "Yuyang", ""], ["Kamani", "Mohammad Mahdi", ""], ["Mahdavi", "Mehrdad", ""]]}, {"id": "2102.12669", "submitter": "Felix Xiaofeng Ye", "authors": "Xingjie Li, Fei Lu, Felix X.-F. Ye", "title": "ISALT: Inference-based schemes adaptive to large time-stepping for\n  locally Lipschitz ergodic systems", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient simulation of SDEs is essential in many applications, particularly\nfor ergodic systems that demand efficient simulation of both short-time\ndynamics and large-time statistics. However, locally Lipschitz SDEs often\nrequire special treatments such as implicit schemes with small time-steps to\naccurately simulate the ergodic measure. We introduce a framework to construct\ninference-based schemes adaptive to large time-steps (ISALT) from data,\nachieving a reduction in time by several orders of magnitudes. The key is the\nstatistical learning of an approximation to the infinite-dimensional\ndiscrete-time flow map. We explore the use of numerical schemes (such as the\nEuler-Maruyama, a hybrid RK4, and an implicit scheme) to derive informed basis\nfunctions, leading to a parameter inference problem. We introduce a scalable\nalgorithm to estimate the parameters by least squares, and we prove the\nconvergence of the estimators as data size increases.\n  We test the ISALT on three non-globally Lipschitz SDEs: the 1D double-well\npotential, a 2D multi-scale gradient system, and the 3D stochastic Lorenz\nequation with degenerate noise. Numerical results show that ISALT can tolerate\ntime-step magnitudes larger than plain numerical schemes. It reaches optimal\naccuracy in reproducing the invariant measure when the time-step is\nmedium-large.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 03:51:58 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Li", "Xingjie", ""], ["Lu", "Fei", ""], ["Ye", "Felix X. -F.", ""]]}, {"id": "2102.12679", "submitter": "Yu Gong", "authors": "Yu Gong and Hossein Hajimirsadeghi and Jiawei He and Thibaut Durand\n  and Greg Mori", "title": "Variational Selective Autoencoder: Learning from Partially-Observed\n  Heterogeneous Data", "comments": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from heterogeneous data poses challenges such as combining data from\nvarious sources and of different types. Meanwhile, heterogeneous data are often\nassociated with missingness in real-world applications due to heterogeneity and\nnoise of input sources. In this work, we propose the variational selective\nautoencoder (VSAE), a general framework to learn representations from\npartially-observed heterogeneous data. VSAE learns the latent dependencies in\nheterogeneous data by modeling the joint distribution of observed data,\nunobserved data, and the imputation mask which represents how the data are\nmissing. It results in a unified model for various downstream tasks including\ndata generation and imputation. Evaluation on both low-dimensional and\nhigh-dimensional heterogeneous datasets for these two tasks shows improvement\nover state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 04:39:13 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gong", "Yu", ""], ["Hajimirsadeghi", "Hossein", ""], ["He", "Jiawei", ""], ["Durand", "Thibaut", ""], ["Mori", "Greg", ""]]}, {"id": "2102.12685", "submitter": "Zhuangyan Fang", "authors": "Zhuangyan Fang and Yue Liu and Zhi Geng and Yangbo He", "title": "A Local Method for Identifying Causal Relations under Markov Equivalence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality is important for designing interpretable and robust methods in\nartificial intelligence research. We propose a local approach to identify\nwhether a variable is a cause of a given target based on causal graphical\nmodels of directed acyclic graphs (DAGs). In general, the causal relation\nbetween two variables may not be identifiable from observational data as many\ncausal DAGs encoding different causal relations are Markov equivalent. In this\npaper, we first introduce a sufficient and necessary graphical condition to\ncheck the existence of a causal path from a variable to a target in every\nMarkov equivalent DAG. Next, we provide local criteria for identifying whether\nthe variable is a cause/non-cause of the target. Finally, we propose a local\nlearning algorithm for this causal query via learning local structure of the\nvariable and some additional statistical independence tests related to the\ntarget. Simulation studies show that our local algorithm is efficient and\neffective, compared with other state-of-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 05:01:44 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Fang", "Zhuangyan", ""], ["Liu", "Yue", ""], ["Geng", "Zhi", ""], ["He", "Yangbo", ""]]}, {"id": "2102.12723", "submitter": "Dmitry Ignatov", "authors": "L\\'eonard Kwuida and Dmitry I. Ignatov", "title": "On Interpretability and Similarity in Concept-Based Machine Learning", "comments": "Invited Talk at AIST 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM math.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) provides important techniques for classification and\npredictions. Most of these are black-box models for users and do not provide\ndecision-makers with an explanation. For the sake of transparency or more\nvalidity of decisions, the need to develop explainable/interpretable ML-methods\nis gaining more and more importance. Certain questions need to be addressed:\n  How does an ML procedure derive the class for a particular entity? Why does a\nparticular clustering emerge from a particular unsupervised ML procedure? What\ncan we do if the number of attributes is very large? What are the possible\nreasons for the mistakes for concrete cases and models?\n  For binary attributes, Formal Concept Analysis (FCA) offers techniques in\nterms of intents of formal concepts, and thus provides plausible reasons for\nmodel prediction. However, from the interpretable machine learning viewpoint,\nwe still need to provide decision-makers with the importance of individual\nattributes to the classification of a particular object, which may facilitate\nexplanations by experts in various domains with high-cost errors like medicine\nor finance.\n  We discuss how notions from cooperative game theory can be used to assess the\ncontribution of individual attributes in classification and clustering\nprocesses in concept-based machine learning. To address the 3rd question, we\npresent some ideas on how to reduce the number of attributes using similarities\nin large contexts.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 07:57:28 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Kwuida", "L\u00e9onard", ""], ["Ignatov", "Dmitry I.", ""]]}, {"id": "2102.12731", "submitter": "Gaspard Beugnot", "authors": "Gaspard Beugnot, Aude Genevay, Kristjan Greenewald, Justin Solomon", "title": "Improving Approximate Optimal Transport Distances using Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) is a popular tool in machine learning to compare\nprobability measures geometrically, but it comes with substantial computational\nburden. Linear programming algorithms for computing OT distances scale\ncubically in the size of the input, making OT impractical in the large-sample\nregime. We introduce a practical algorithm, which relies on a quantization\nstep, to estimate OT distances between measures given cheap sample access. We\nalso provide a variant of our algorithm to improve the performance of\napproximate solvers, focusing on those for entropy-regularized transport. We\ngive theoretical guarantees on the benefits of this quantization step and\ndisplay experiments showing that it behaves well in practice, providing a\npractical approximation algorithm that can be used as a drop-in replacement for\nexisting OT estimators.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 08:45:06 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Beugnot", "Gaspard", ""], ["Genevay", "Aude", ""], ["Greenewald", "Kristjan", ""], ["Solomon", "Justin", ""]]}, {"id": "2102.12736", "submitter": "Xuhui Zhang", "authors": "Jose Blanchet, Fernando Hernandez, Viet Anh Nguyen, Markus Pelger,\n  Xuhui Zhang", "title": "Time-Series Imputation with Wasserstein Interpolation for Optimal\n  Look-Ahead-Bias and Variance Tradeoff", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Missing time-series data is a prevalent practical problem. Imputation methods\nin time-series data often are applied to the full panel data with the purpose\nof training a model for a downstream out-of-sample task. For example, in\nfinance, imputation of missing returns may be applied prior to training a\nportfolio optimization model. Unfortunately, this practice may result in a\nlook-ahead-bias in the future performance on the downstream task. There is an\ninherent trade-off between the look-ahead-bias of using the full data set for\nimputation and the larger variance in the imputation from using only the\ntraining data. By connecting layers of information revealed in time, we propose\na Bayesian posterior consensus distribution which optimally controls the\nvariance and look-ahead-bias trade-off in the imputation. We demonstrate the\nbenefit of our methodology both in synthetic and real financial data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 09:05:35 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Blanchet", "Jose", ""], ["Hernandez", "Fernando", ""], ["Nguyen", "Viet Anh", ""], ["Pelger", "Markus", ""], ["Zhang", "Xuhui", ""]]}, {"id": "2102.12756", "submitter": "Edgar Beck M.Sc.", "authors": "Edgar Beck, Carsten Bockelmann and Armin Dekorsy", "title": "Learning a Probabilistic Relaxation of Discrete Variables for Soft\n  Detection with Low Complexity: CMDNet", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the great success of Machine Learning (ML), especially Deep Neural\nNetworks (DNNs), in many research domains in 2010s, several ML-based approaches\nwere proposed for detection in large inverse linear problems, e.g., massive\nMIMO systems. The main motivation behind is that the complexity of Maximum\nA-Posteriori (MAP) detection grows exponentially with system dimensions.\nInstead of using DNNs, essentially being a black-box, we take a slightly\ndifferent approach and introduce a probabilistic Continuous relaxation of\ndisCrete variables to MAP detection. Enabling close approximation and\ncontinuous optimization, we derive an iterative detection algorithm: Concrete\nMAP Detection (CMD). Furthermore, extending CMD by the idea of deep unfolding\ninto CMDNet, we allow for (online) optimization of a small number of parameters\nto different working points while limiting complexity. In contrast to recent\nDNN-based approaches, we select the optimization criterion and output of CMDNet\nbased on information theory and are thus able to learn approximate\nprobabilities of the individual optimal detector. This is crucial for soft\ndecoding in today's communication systems. Numerical simulation results in MIMO\nsystems reveal CMDNet to feature a promising accuracy complexity trade-off\ncompared to State of the Art. Notably, we demonstrate CMDNet's soft outputs to\nbe reliable for decoders.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 09:54:25 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 13:01:07 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Beck", "Edgar", ""], ["Bockelmann", "Carsten", ""], ["Dekorsy", "Armin", ""]]}, {"id": "2102.12769", "submitter": "Vincent Zhuang", "authors": "Vincent Zhuang, Yanan Sui", "title": "No-Regret Reinforcement Learning with Heavy-Tailed Rewards", "comments": "AISTATS 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms typically assume rewards to be sampled from\nlight-tailed distributions, such as Gaussian or bounded. However, a wide\nvariety of real-world systems generate rewards that follow heavy-tailed\ndistributions. We consider such scenarios in the setting of undiscounted\nreinforcement learning. By constructing a lower bound, we show that the\ndifficulty of learning heavy-tailed rewards asymptotically dominates the\ndifficulty of learning transition probabilities. Leveraging techniques from\nrobust mean estimation, we propose Heavy-UCRL2 and Heavy-Q-Learning, and show\nthat they achieve near-optimal regret bounds in this setting. Our algorithms\nalso naturally generalize to deep reinforcement learning applications; we\ninstantiate Heavy-DQN as an example of this. We demonstrate that all of our\nalgorithms outperform baselines on both synthetic MDPs and standard RL\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 10:25:57 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Zhuang", "Vincent", ""], ["Sui", "Yanan", ""]]}, {"id": "2102.12781", "submitter": "Harshay Shah", "authors": "Harshay Shah, Prateek Jain, Praneeth Netrapalli", "title": "Do Input Gradients Highlight Discriminative Features?", "comments": "Code: https://github.com/harshays/inputgradients", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Post-hoc gradient-based interpretability methods [Simonyan et al., 2013,\nSmilkov et al., 2017] that provide instance-specific explanations of model\npredictions are often based on assumption (A): magnitude of input gradients --\ngradients of logits with respect to input -- noisily highlight discriminative\ntask-relevant features. In this work, we test the validity of assumption (A)\nusing a three-pronged approach. First, we develop an evaluation framework,\nDiffROAR, to test assumption (A) on four image classification benchmarks. Our\nresults suggest that (i) input gradients of standard models (i.e., trained on\noriginal data) may grossly violate (A), whereas (ii) input gradients of\nadversarially robust models satisfy (A). Second, we then introduce BlockMNIST,\nan MNIST-based semi-real dataset, that by design encodes a priori knowledge of\ndiscriminative features. Our analysis on BlockMNIST leverages this information\nto validate as well as characterize differences between input gradient\nattributions of standard and robust models. Finally, we theoretically prove\nthat our empirical findings hold on a simplified version of the BlockMNIST\ndataset. Specifically, we prove that input gradients of standard\none-hidden-layer MLPs trained on this dataset do not highlight\ninstance-specific signal coordinates, thus grossly violating assumption (A).\nOur findings motivate the need to formalize and test common assumptions in\ninterpretability in a falsifiable manner [Leavitt and Morcos, 2020].\nAdditionally, we believe that the DiffROAR evaluation framework and\nBlockMNIST-based datasets can serve as sanity checks to audit instance-specific\ninterpretability methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 11:04:38 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 15:30:11 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shah", "Harshay", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "2102.12792", "submitter": "Changyong Oh", "authors": "Changyong Oh, Efstratios Gavves, Max Welling", "title": "Mixed Variable Bayesian Optimization with Frequency Modulated Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sample efficiency of Bayesian optimization(BO) is often boosted by\nGaussian Process(GP) surrogate models. However, on mixed variable spaces,\nsurrogate models other than GPs are prevalent, mainly due to the lack of\nkernels which can model complex dependencies across different types of\nvariables. In this paper, we propose the frequency modulated (FM) kernel\nflexibly modeling dependencies among different types of variables, so that BO\ncan enjoy the further improved sample efficiency. The FM kernel uses distances\non continuous variables to modulate the graph Fourier spectrum derived from\ndiscrete variables. However, the frequency modulation does not always define a\nkernel with the similarity measure behavior which returns higher values for\npairs of more similar points. Therefore, we specify and prove conditions for FM\nkernels to be positive definite and to exhibit the similarity measure behavior.\nIn experiments, we demonstrate the improved sample efficiency of GP BO using FM\nkernels (BO-FM).On synthetic problems and hyperparameter optimization problems,\nBO-FM outperforms competitors consistently. Also, the importance of the\nfrequency modulation principle is empirically demonstrated on the same\nproblems. On joint optimization of neural architectures and SGD\nhyperparameters, BO-FM outperforms competitors including Regularized\nevolution(RE) and BOHB. Remarkably, BO-FM performs better even than RE and BOHB\nusing three times as many evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 11:28:46 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Oh", "Changyong", ""], ["Gavves", "Efstratios", ""], ["Welling", "Max", ""]]}, {"id": "2102.12810", "submitter": "Samuel Horv\\'ath", "authors": "Samuel Horv\\'ath, Aaron Klein, Peter Richt\\'arik, C\\'edric Archambeau", "title": "Hyperparameter Transfer Learning with Adaptive Complexity", "comments": "12 pages, Proceedings of the 24th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2021, San Diego, California,\n  USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a sample efficient approach to automatically\ntune the hyperparameters of machine learning models. In practice, one\nfrequently has to solve similar hyperparameter tuning problems sequentially.\nFor example, one might have to tune a type of neural network learned across a\nseries of different classification problems. Recent work on multi-task BO\nexploits knowledge gained from previous tuning tasks to speed up a new tuning\ntask. However, previous approaches do not account for the fact that BO is a\nsequential decision making procedure. Hence, there is in general a mismatch\nbetween the number of evaluations collected in the current tuning task compared\nto the number of evaluations accumulated in all previously completed tasks. In\nthis work, we enable multi-task BO to compensate for this mismatch, such that\nthe transfer learning procedure is able to handle different data regimes in a\nprincipled way. We propose a new multi-task BO method that learns a set of\nordered, non-linear basis functions of increasing complexity via nested\ndrop-out and automatic relevance determination. Experiments on a variety of\nhyperparameter tuning problems show that our method improves the sample ef\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 12:26:52 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Horv\u00e1th", "Samuel", ""], ["Klein", "Aaron", ""], ["Richt\u00e1rik", "Peter", ""], ["Archambeau", "C\u00e9dric", ""]]}, {"id": "2102.12841", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Nobukatsu Hojo", "title": "MaskCycleGAN-VC: Learning Non-parallel Voice Conversion with Filling in\n  Frames", "comments": "Accepted to ICASSP 2021. Project page:\n  http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/maskcyclegan-vc/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel voice conversion (VC) is a technique for training voice\nconverters without a parallel corpus. Cycle-consistent adversarial\nnetwork-based VCs (CycleGAN-VC and CycleGAN-VC2) are widely accepted as\nbenchmark methods. However, owing to their insufficient ability to grasp\ntime-frequency structures, their application is limited to mel-cepstrum\nconversion and not mel-spectrogram conversion despite recent advances in\nmel-spectrogram vocoders. To overcome this, CycleGAN-VC3, an improved variant\nof CycleGAN-VC2 that incorporates an additional module called time-frequency\nadaptive normalization (TFAN), has been proposed. However, an increase in the\nnumber of learned parameters is imposed. As an alternative, we propose\nMaskCycleGAN-VC, which is another extension of CycleGAN-VC2 and is trained\nusing a novel auxiliary task called filling in frames (FIF). With FIF, we apply\na temporal mask to the input mel-spectrogram and encourage the converter to\nfill in missing frames based on surrounding frames. This task allows the\nconverter to learn time-frequency structures in a self-supervised manner and\neliminates the need for an additional module such as TFAN. A subjective\nevaluation of the naturalness and speaker similarity showed that\nMaskCycleGAN-VC outperformed both CycleGAN-VC2 and CycleGAN-VC3 with a model\nsize similar to that of CycleGAN-VC2. Audio samples are available at\nhttp://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/maskcyclegan-vc/index.html.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 13:26:58 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Kameoka", "Hirokazu", ""], ["Tanaka", "Kou", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "2102.12918", "submitter": "Jingjing Li", "authors": "Jingjing Li and Zhuo Sun and Lei Zhang and Hongyu Zhu", "title": "Dual MINE-based Neural Secure Communications under Gaussian Wiretap\n  Channel", "comments": "6 pages, 6 figures, ICC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some researches are devoted to the topic of end-to-end learning a\nphysical layer secure communication system based on autoencoder under Gaussian\nwiretap channel. However, in those works, the reliability and security of the\nencoder model were learned through necessary decoding outputs of not only\nlegitimate receiver but also the eavesdropper. In fact, the assumption of known\neavesdropper's decoder or its output is not practical. To address this issue,\nin this paper we propose a dual mutual information neural estimation (MINE)\nbased neural secure communications model. The security constraints of this\nmethod is constructed only with the input and output signal samples of the\nlegal and eavesdropper channels and benefit that training the encoder is\ncompletely independent of the decoder. Moreover, since the design of secure\ncoding does not rely on the eavesdropper's decoding results, the security\nperformance would not be affected by the eavesdropper's decoding means.\nNumerical results show that the performance of our model is guaranteed whether\nthe eavesdropper learns the decoder himself or uses the legal decoder.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 15:09:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Li", "Jingjing", ""], ["Sun", "Zhuo", ""], ["Zhang", "Lei", ""], ["Zhu", "Hongyu", ""]]}, {"id": "2102.12924", "submitter": "Joery De Vries", "authors": "Joery A. de Vries, Ken S. Voskuil, Thomas M. Moerland and Aske Plaat", "title": "Visualizing MuZero Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MuZero, a model-based reinforcement learning algorithm that uses a value\nequivalent dynamics model, achieved state-of-the-art performance in Chess,\nShogi and the game of Go. In contrast to standard forward dynamics models that\npredict a full next state, value equivalent models are trained to predict a\nfuture value, thereby emphasizing value relevant information in the\nrepresentations. While value equivalent models have shown strong empirical\nsuccess, there is no research yet that visualizes and investigates what types\nof representations these models actually learn. Therefore, in this paper we\nvisualize the latent representation of MuZero agents. We find that action\ntrajectories may diverge between observation embeddings and internal state\ntransition dynamics, which could lead to instability during planning. Based on\nthis insight, we propose two regularization techniques to stabilize MuZero's\nperformance. Additionally, we provide an open-source implementation of MuZero\nalong with an interactive visualizer of learned representations, which may aid\nfurther investigation of value equivalent algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 15:25:17 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 12:25:28 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["de Vries", "Joery A.", ""], ["Voskuil", "Ken S.", ""], ["Moerland", "Thomas M.", ""], ["Plaat", "Aske", ""]]}, {"id": "2102.12948", "submitter": "Nived Rajaraman", "authors": "Nived Rajaraman, Yanjun Han, Lin F. Yang, Kannan Ramchandran, Jiantao\n  Jiao", "title": "Provably Breaking the Quadratic Error Compounding Barrier in Imitation\n  Learning, Optimally", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical limits of Imitation Learning (IL) in episodic Markov\nDecision Processes (MDPs) with a state space $\\mathcal{S}$. We focus on the\nknown-transition setting where the learner is provided a dataset of $N$\nlength-$H$ trajectories from a deterministic expert policy and knows the MDP\ntransition. We establish an upper bound $O(|\\mathcal{S}|H^{3/2}/N)$ for the\nsuboptimality using the Mimic-MD algorithm in Rajaraman et al (2020) which we\nprove to be computationally efficient. In contrast, we show the minimax\nsuboptimality grows as $\\Omega( H^{3/2}/N)$ when $|\\mathcal{S}|\\geq 3$ while\nthe unknown-transition setting suffers from a larger sharp rate\n$\\Theta(|\\mathcal{S}|H^2/N)$ (Rajaraman et al (2020)). The lower bound is\nestablished by proving a two-way reduction between IL and the value estimation\nproblem of the unknown expert policy under any given reward function, as well\nas building connections with linear functional estimation with subsampled\nobservations. We further show that under the additional assumption that the\nexpert is optimal for the true reward function, there exists an efficient\nalgorithm, which we term as Mimic-Mixture, that provably achieves suboptimality\n$O(1/N)$ for arbitrary 3-state MDPs with rewards only at the terminal layer. In\ncontrast, no algorithm can achieve suboptimality $O(\\sqrt{H}/N)$ with high\nprobability if the expert is not constrained to be optimal. Our work formally\nestablishes the benefit of the expert optimal assumption in the known\ntransition setting, while Rajaraman et al (2020) showed it does not help when\ntransitions are unknown.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 15:50:19 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Rajaraman", "Nived", ""], ["Han", "Yanjun", ""], ["Yang", "Lin F.", ""], ["Ramchandran", "Kannan", ""], ["Jiao", "Jiantao", ""]]}, {"id": "2102.12956", "submitter": "Nikolas Nuesken", "authors": "Nikolas N\\\"usken, D.R. Michiel Renger", "title": "Stein Variational Gradient Descent: many-particle and long-time\n  asymptotics", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.AP math.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein variational gradient descent (SVGD) refers to a class of methods for\nBayesian inference based on interacting particle systems. In this paper, we\nconsider the originally proposed deterministic dynamics as well as a stochastic\nvariant, each of which represent one of the two main paradigms in Bayesian\ncomputational statistics: variational inference and Markov chain Monte Carlo.\nAs it turns out, these are tightly linked through a correspondence between\ngradient flow structures and large-deviation principles rooted in statistical\nphysics. To expose this relationship, we develop the cotangent space\nconstruction for the Stein geometry, prove its basic properties, and determine\nthe large-deviation functional governing the many-particle limit for the\nempirical measure. Moreover, we identify the Stein-Fisher information (or\nkernelised Stein discrepancy) as its leading order contribution in the\nlong-time and many-particle regime in the sense of $\\Gamma$-convergence,\nshedding some light on the finite-particle properties of SVGD. Finally, we\nestablish a comparison principle between the Stein-Fisher information and\nRKHS-norms that might be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 16:03:04 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["N\u00fcsken", "Nikolas", ""], ["Renger", "D. R. Michiel", ""]]}, {"id": "2102.12959", "submitter": "Xi Wang", "authors": "Xi Wang, Laurence Aitchison", "title": "Undefined class-label detection vs out-of-distribution detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new problem, that of undefined class-label (UCL) detection.\nFor instance, if we try to classify an image of a radio as cat vs dog, there\nwill be no well-defined class label. In contrast, in out-of-distribution (OOD)\ndetection, we are interested in the related but different problem of\nidentifying regions of the input space with little training data, which might\nresult in poor classifier performance. This difference is critical: it is quite\npossible for there to be a region of the input space where little training data\nis available but where class-labels are well-defined. Likewise, there may be\nregions with lots of training data, but without well-defined class-labels\n(though in practice this would often be the result of a bug in the labelling\npipeline). We note that certain methods originally intended to detect OOD\ninputs might actually be detecting UCL points and develop a method for training\non UCL points based on a generative model of data-curation originally used to\nexplain the cold posterior effect in Bayesian neural networks. This approach\ngives superior performance to past methods originally intended for OOD\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 12:35:43 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 14:03:06 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Xi", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2102.12961", "submitter": "The Tien Mai", "authors": "The Tien Mai", "title": "On continual single index learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we generalize the problem of single index model to the context\nof continual learning in which a learner is challenged with a sequence of tasks\none by one and the dataset of each task is revealed in an online fashion. We\npropose a strategy that is able to learn a common single index for all tasks\nand a specific link function for each task. The common single index allows to\ntransfer the informaton gained from the previous tasks to a new one. We provide\na theoretical analysis of our proposed strategy by proving some regret bounds.\nMoreover, as a by-product from our work to provide an example of a within-task\nalgorithm, we develop a novel online algorithm for learning single index model\nin an online setting and provide its regret bound.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 16:05:51 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Mai", "The Tien", ""]]}, {"id": "2102.12967", "submitter": "Matan Haroush", "authors": "Matan Haroush, Tzivel Frostig, Ruth Heller and Daniel Soudry", "title": "Statistical Testing for Efficient Out of Distribution Detection in Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonly, Deep Neural Networks (DNNs) generalize well on samples drawn from a\ndistribution similar to that of the training set. However, DNNs' predictions\nare brittle and unreliable when the test samples are drawn from a dissimilar\ndistribution. This presents a major concern for deployment in real-world\napplications, where such behavior may come at a great cost -- as in the case of\nautonomous vehicles or healthcare applications.\n  This paper frames the Out Of Distribution (OOD) detection problem in DNN as a\nstatistical hypothesis testing problem. Unlike previous OOD detection\nheuristics, our framework is guaranteed to maintain the false positive rate\n(detecting OOD as in-distribution) for test data. We build on this framework to\nsuggest a novel OOD procedure based on low-order statistics. Our method\nachieves comparable or better than state-of-the-art results on well-accepted\nOOD benchmarks without retraining the network parameters -- and at a fraction\nof the computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 16:14:47 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Haroush", "Matan", ""], ["Frostig", "Tzivel", ""], ["Heller", "Ruth", ""], ["Soudry", "Daniel", ""]]}, {"id": "2102.13004", "submitter": "Vijay Keswani", "authors": "Vijay Keswani, Matthew Lease, Krishnaram Kenthapadi", "title": "Towards Unbiased and Accurate Deferral to Multiple Experts", "comments": "This paper has been accepted for publication at the AAAI/ACM\n  Conference on Artificial Intelligence, Ethics, and Society (AIES 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are often implemented in cohort with humans in the\npipeline, with the model having an option to defer to a domain expert in cases\nwhere it has low confidence in its inference. Our goal is to design mechanisms\nfor ensuring accuracy and fairness in such prediction systems that combine\nmachine learning model inferences and domain expert predictions. Prior work on\n\"deferral systems\" in classification settings has focused on the setting of a\npipeline with a single expert and aimed to accommodate the inaccuracies and\nbiases of this expert to simultaneously learn an inference model and a deferral\nsystem. Our work extends this framework to settings where multiple experts are\navailable, with each expert having their own domain of expertise and biases. We\npropose a framework that simultaneously learns a classifier and a deferral\nsystem, with the deferral system choosing to defer to one or more human experts\nin cases of input where the classifier has low confidence. We test our\nframework on a synthetic dataset and a content moderation dataset with biased\nsynthetic experts, and show that it significantly improves the accuracy and\nfairness of the final predictions, compared to the baselines. We also collect\ncrowdsourced labels for the content moderation task to construct a real-world\ndataset for the evaluation of hybrid machine-human frameworks and show that our\nproposed learning framework outperforms baselines on this real-world dataset as\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:08:39 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 20:34:31 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Keswani", "Vijay", ""], ["Lease", "Matthew", ""], ["Kenthapadi", "Krishnaram", ""]]}, {"id": "2102.13028", "submitter": "Quanquan Gu", "authors": "Quanquan Gu and Amin Karbasi and Khashayar Khosravi and Vahab Mirrokni\n  and Dongruo Zhou", "title": "Batched Neural Bandits", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many sequential decision-making problems, the individuals are split into\nseveral batches and the decision-maker is only allowed to change her policy at\nthe end of batches. These batch problems have a large number of applications,\nranging from clinical trials to crowdsourcing. Motivated by this, we study the\nstochastic contextual bandit problem for general reward distributions under the\nbatched setting. We propose the BatchNeuralUCB algorithm which combines neural\nnetworks with optimism to address the exploration-exploitation tradeoff while\nkeeping the total number of batches limited. We study BatchNeuralUCB under both\nfixed and adaptive batch size settings and prove that it achieves the same\nregret as the fully sequential version while reducing the number of policy\nupdates considerably. We confirm our theoretical results via simulations on\nboth synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:36:44 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gu", "Quanquan", ""], ["Karbasi", "Amin", ""], ["Khosravi", "Khashayar", ""], ["Mirrokni", "Vahab", ""], ["Zhou", "Dongruo", ""]]}, {"id": "2102.13042", "submitter": "Andrew Wilson", "authors": "Gregory W. Benton, Wesley J. Maddox, Sanae Lotfi, Andrew Gordon Wilson", "title": "Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a better understanding of the loss surfaces for multilayer networks, we\ncan build more robust and accurate training procedures. Recently it was\ndiscovered that independently trained SGD solutions can be connected along\none-dimensional paths of near-constant training loss. In this paper, we show\nthat there are mode-connecting simplicial complexes that form multi-dimensional\nmanifolds of low loss, connecting many independently trained models. Inspired\nby this discovery, we show how to efficiently build simplicial complexes for\nfast ensembling, outperforming independently trained deep ensembles in\naccuracy, calibration, and robustness to dataset shift. Notably, our approach\nonly requires a few training epochs to discover a low-loss simplex, starting\nfrom a pre-trained solution. Code is available at\nhttps://github.com/g-benton/loss-surface-simplexes.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:53:24 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Benton", "Gregory W.", ""], ["Maddox", "Wesley J.", ""], ["Lotfi", "Sanae", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2102.13069", "submitter": "Shuangping Li", "authors": "Emmanuel Abbe, Shuangping Li, Allan Sly", "title": "Proof of the Contiguity Conjecture and Lognormal Limit for the Symmetric\n  Perceptron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the symmetric binary perceptron model, a simple model of neural\nnetworks that has gathered significant attention in the statistical physics,\ninformation theory and probability theory communities, with recent connections\nmade to the performance of learning algorithms in Baldassi et al. '15.\n  We establish that the partition function of this model, normalized by its\nexpected value, converges to a lognormal distribution. As a consequence, this\nallows us to establish several conjectures for this model: (i) it proves the\ncontiguity conjecture of Aubin et al. '19 between the planted and unplanted\nmodels in the satisfiable regime; (ii) it establishes the sharp threshold\nconjecture; (iii) it proves the frozen 1-RSB conjecture in the symmetric case,\nconjectured first by Krauth-M\\'ezard '89 in the asymmetric case.\n  In a recent concurrent work of Perkins-Xu [PX21], the last two conjectures\nwere also established by proving that the partition function concentrates on an\nexponential scale. This left open the contiguity conjecture and the lognormal\nlimit characterization, which are established here. In particular, our proof\ntechnique relies on a dense counter-part of the small graph conditioning\nmethod, which was developed for sparse models in the celebrated work of\nRobinson and Wormald.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:39:08 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Li", "Shuangping", ""], ["Sly", "Allan", ""]]}, {"id": "2102.13079", "submitter": "Ping Li", "authors": "Xiaoyun Li and Ping Li", "title": "Quantization Algorithms for Random Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The method of random projection (RP) is the standard technique in machine\nlearning and many other areas, for dimensionality reduction, approximate near\nneighbor search, compressed sensing, etc. Basically, RP provides a simple and\neffective scheme for approximating pairwise inner products and Euclidean\ndistances in massive data. Closely related to RP, the method of random Fourier\nfeatures (RFF) has also become popular, for approximating the Gaussian kernel.\nRFF applies a specific nonlinear transformation on the projected data from\nrandom projections. In practice, using the (nonlinear) Gaussian kernel often\nleads to better performance than the linear kernel (inner product), partly due\nto the tuning parameter $(\\gamma)$ introduced in the Gaussian kernel. Recently,\nthere has been a surge of interest in studying properties of RFF.\n  After random projections, quantization is an important step for efficient\ndata storage, computation, and transmission. Quantization for RP has also been\nextensive studied in the literature. In this paper, we focus on developing\nquantization algorithms for RFF. The task is in a sense challenging due to the\ntuning parameter $\\gamma$ in the Gaussian kernel. For example, the quantizer\nand the quantized data might be tied to each specific tuning parameter\n$\\gamma$. Our contribution begins with an interesting discovery, that the\nmarginal distribution of RFF is actually free of the Gaussian kernel parameter\n$\\gamma$. This small finding significantly simplifies the design of the\nLloyd-Max (LM) quantization scheme for RFF in that there would be only one LM\nquantizer for RFF (regardless of $\\gamma$). We also develop a variant named\nLM$^2$-RFF quantizer, which in certain cases is more accurate. Experiments\nconfirm that the proposed quantization schemes perform well.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:51:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Li", "Xiaoyun", ""], ["Li", "Ping", ""]]}, {"id": "2102.13085", "submitter": "Nikola Jovanovi\\'c", "authors": "Nikola Jovanovi\\'c, Zhao Meng, Lukas Faber, Roger Wattenhofer", "title": "Towards Robust Graph Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of adversarially robust self-supervised learning on\ngraphs. In the contrastive learning framework, we introduce a new method that\nincreases the adversarial robustness of the learned representations through i)\nadversarial transformations and ii) transformations that not only remove but\nalso insert edges. We evaluate the learned representations in a preliminary set\nof experiments, obtaining promising results. We believe this work takes an\nimportant step towards incorporating robustness as a viable auxiliary task in\ngraph contrastive learning.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:55:15 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Jovanovi\u0107", "Nikola", ""], ["Meng", "Zhao", ""], ["Faber", "Lukas", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2102.13088", "submitter": "Kenneth Borup", "authors": "Kenneth Borup, Lars N. Andersen", "title": "Even your Teacher Needs Guidance: Ground-Truth Targets Dampen\n  Regularization Imposed by Self-Distillation", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is classically a procedure where a neural network is\ntrained on the output of another network along with the original targets in\norder to transfer knowledge between the architectures. The special case of\nself-distillation, where the network architectures are identical, has been\nobserved to improve generalization accuracy. In this paper, we consider an\niterative variant of self-distillation in a kernel regression setting, in which\nsuccessive steps incorporate both model outputs and the ground-truth targets.\nThis allows us to provide the first theoretical results on the importance of\nusing the weighted ground-truth targets in self-distillation. Our focus is on\nfitting nonlinear functions to training data with a weighted mean square error\nobjective function suitable for distillation, subject to $\\ell_2$\nregularization of the model parameters. We show that any such function obtained\nwith self-distillation can be calculated directly as a function of the initial\nfit, and that infinite distillation steps yields the same optimization problem\nas the original with amplified regularization. Finally, we examine empirically,\nboth in a regression setting and with ResNet networks, how the choice of\nweighting parameter influences the generalization performance after\nself-distillation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:56:09 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Borup", "Kenneth", ""], ["Andersen", "Lars N.", ""]]}, {"id": "2102.13101", "submitter": "Cong Shen", "authors": "Chengshuai Shi, Cong Shen, Jing Yang", "title": "Federated Multi-armed Bandits with Personalization", "comments": "Accepted to AISTATS 2021, oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general framework of personalized federated multi-armed bandits (PF-MAB) is\nproposed, which is a new bandit paradigm analogous to the federated learning\n(FL) framework in supervised learning and enjoys the features of FL with\npersonalization. Under the PF-MAB framework, a mixed bandit learning problem\nthat flexibly balances generalization and personalization is studied. A lower\nbound analysis for the mixed model is presented. We then propose the\nPersonalized Federated Upper Confidence Bound (PF-UCB) algorithm, where the\nexploration length is chosen carefully to achieve the desired balance of\nlearning the local model and supplying global information for the mixed\nlearning objective. Theoretical analysis proves that PF-UCB achieves an\n$O(\\log(T))$ regret regardless of the degree of personalization, and has a\nsimilar instance dependency as the lower bound. Experiments using both\nsynthetic and real-world datasets corroborate the theoretical analysis and\ndemonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:59:43 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Shi", "Chengshuai", ""], ["Shen", "Cong", ""], ["Yang", "Jing", ""]]}, {"id": "2102.13128", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski", "title": "An Online Learning Approach to Interpolation and Extrapolation in Domain\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular assumption for out-of-distribution generalization is that the\ntraining data comprises sub-datasets, each drawn from a distinct distribution;\nthe goal is then to \"interpolate\" these distributions and \"extrapolate\" beyond\nthem -- this objective is broadly known as domain generalization. A common\nbelief is that ERM can interpolate but not extrapolate and that the latter is\nconsiderably more difficult, but these claims are vague and lack formal\njustification. In this work, we recast generalization over sub-groups as an\nonline game between a player minimizing risk and an adversary presenting new\ntest distributions. Under an existing notion of inter- and extrapolation based\non reweighting of sub-group likelihoods, we rigorously demonstrate that\nextrapolation is computationally much harder than interpolation, though their\nstatistical complexity is not significantly different. Furthermore, we show\nthat ERM -- or a noisy variant -- is provably minimax-optimal for both tasks.\nOur framework presents a new avenue for the formal analysis of domain\ngeneralization algorithms which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 19:06:48 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Ravikumar", "Pradeep", ""], ["Risteski", "Andrej", ""]]}, {"id": "2102.13135", "submitter": "Nafiseh Ghoroghchian Ms.", "authors": "Nafiseh Ghoroghchian, Gautam Dasarathy, and Stark C. Draper", "title": "Graph Community Detection from Coarse Measurements: Recovery Conditions\n  for the Coarsened Weighted Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG eess.SP math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of community recovery from coarse measurements of a\ngraph. In contrast to the problem of community recovery of a fully observed\ngraph, one often encounters situations when measurements of a graph are made at\nlow-resolution, each measurement integrating across multiple graph nodes. Such\nlow-resolution measurements effectively induce a coarse graph with its own\ncommunities. Our objective is to develop conditions on the graph structure, the\nquantity, and properties of measurements, under which we can recover the\ncommunity organization in this coarse graph. In this paper, we build on the\nstochastic block model by mathematically formalizing the coarsening process,\nand characterizing its impact on the community members and connections. Through\nthis novel setup and modeling, we characterize an error bound for community\nrecovery. The error bound yields simple and closed-form asymptotic conditions\nto achieve the perfect recovery of the coarse graph communities.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 19:24:33 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ghoroghchian", "Nafiseh", ""], ["Dasarathy", "Gautam", ""], ["Draper", "Stark C.", ""]]}, {"id": "2102.13156", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi and Alexandros Kalousis", "title": "Physics-Integrated Variational Autoencoders for Robust and Interpretable\n  Generative Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Integrating physics models within machine learning models holds considerable\npromise toward learning robust models with improved interpretability and\nabilities to extrapolate. In this work, we focus on the integration of\nincomplete physics models into deep generative models. In particular, we\nintroduce an architecture of variational autoencoders (VAEs) in which a part of\nthe latent space is grounded by physics. A key technical challenge is to strike\na balance between the incomplete physics and trainable components such as\nneural networks for ensuring that the physics part is used in a meaningful\nmanner. To this end, we propose a regularized learning method that controls the\neffect of the trainable components and preserves the semantics of the\nphysics-based latent variables as intended. We not only demonstrate generative\nperformance improvements over a set of synthetic and real-world datasets, but\nwe also show that we learn robust models that can consistently extrapolate\nbeyond the training distribution in a meaningful manner. Moreover, we show that\nwe can control the generative process in an interpretable manner.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 20:28:52 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 08:03:42 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Takeishi", "Naoya", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "2102.13179", "submitter": "Enayat Ullah", "authors": "Enayat Ullah, Tung Mai, Anup Rao, Ryan Rossi, Raman Arora", "title": "Machine Unlearning via Algorithmic Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of machine unlearning and identify a notion of\nalgorithmic stability, Total Variation (TV) stability, which we argue, is\nsuitable for the goal of exact unlearning. For convex risk minimization\nproblems, we design TV-stable algorithms based on noisy Stochastic Gradient\nDescent (SGD). Our key contribution is the design of corresponding efficient\nunlearning algorithms, which are based on constructing a (maximal) coupling of\nMarkov chains for the noisy SGD procedure. To understand the trade-offs between\naccuracy and unlearning efficiency, we give upper and lower bounds on excess\nempirical and populations risk of TV stable algorithms for convex risk\nminimization. Our techniques generalize to arbitrary non-convex functions, and\nour algorithms are differentially private as well.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 21:16:56 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Ullah", "Enayat", ""], ["Mai", "Tung", ""], ["Rao", "Anup", ""], ["Rossi", "Ryan", ""], ["Arora", "Raman", ""]]}, {"id": "2102.13182", "submitter": "Yves-Laurent Kom Samo", "authors": "Yves-Laurent Kom Samo", "title": "Inductive Mutual Information Estimation: A Convex Maximum-Entropy Copula\n  Approach", "comments": "Code: https://github.com/kxytechnologies/kxy-python", "journal-ref": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR:\n  Volume 130. Copyright 2021 by the author(s)", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose a novel estimator of the mutual information between two ordinal\nvectors $x$ and $y$. Our approach is inductive (as opposed to deductive) in\nthat it depends on the data generating distribution solely through some\nnonparametric properties revealing associations in the data, and does not\nrequire having enough data to fully characterize the true joint distributions\n$P_{x, y}$. Specifically, our approach consists of (i) noting that $I\\left(y;\nx\\right) = I\\left(u_y; u_x\\right)$ where $u_y$ and $u_x$ are the copula-uniform\ndual representations of $y$ and $x$ (i.e. their images under the probability\nintegral transform), and (ii) estimating the copula entropies\n$h\\left(u_y\\right)$, $h\\left(u_x\\right)$ and $h\\left(u_y, u_x\\right)$ by\nsolving a maximum-entropy problem over the space of copula densities under a\nconstraint of the type $\\alpha_m = E\\left[\\phi_m(u_y, u_x)\\right]$. We prove\nthat, so long as the constraint is feasible, this problem admits a unique\nsolution, it is in the exponential family, and it can be learned by solving a\nconvex optimization problem. The resulting estimator, which we denote MIND, is\nmarginal-invariant, always non-negative, unbounded for any sample size $n$,\nconsistent, has MSE rate $O(1/n)$, and is more data-efficient than competing\napproaches. Beyond mutual information estimation, we illustrate that our\napproach may be used to mitigate mode collapse in GANs by maximizing the\nentropy of the copula of fake samples, a model we refer to as Copula Entropy\nRegularized GAN (CER-GAN).\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 21:21:40 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 17:01:58 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Samo", "Yves-Laurent Kom", ""]]}, {"id": "2102.13189", "submitter": "Yi Zhang", "authors": "Sanjeev Arora, Yi Zhang", "title": "Rip van Winkle's Razor: A Simple Estimate of Overfit to Test Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional statistics forbids use of test data (a.k.a. holdout data) during\ntraining. Dwork et al. 2015 pointed out that current practices in machine\nlearning, whereby researchers build upon each other's models, copying\nhyperparameters and even computer code -- amounts to implicitly training on the\ntest set. Thus error rate on test data may not reflect the true population\nerror. This observation initiated {\\em adaptive data analysis}, which provides\nevaluation mechanisms with guaranteed upper bounds on this difference. With\nstatistical query (i.e. test accuracy) feedbacks, the best upper bound is\nfairly pessimistic: the deviation can hit a practically vacuous value if the\nnumber of models tested is quadratic in the size of the test set.\n  In this work, we present a simple new estimate, {\\em Rip van Winkle's Razor}.\nIt relies upon a new notion of \\textquotedblleft information\ncontent\\textquotedblright\\ of a model: the amount of information that would\nhave to be provided to an expert referee who is intimately familiar with the\nfield and relevant science/math, and who has been just been woken up after\nfalling asleep at the moment of the creation of the test data (like\n\\textquotedblleft Rip van Winkle\\textquotedblright\\ of the famous fairy tale).\nThis notion of information content is used to provide an estimate of the above\ndeviation which is shown to be non-vacuous in many modern settings.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 21:47:03 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Arora", "Sanjeev", ""], ["Zhang", "Yi", ""]]}, {"id": "2102.13202", "submitter": "Maria Dimakopoulou", "authors": "Maria Dimakopoulou, Zhimei Ren, Zhengyuan Zhou", "title": "Online Multi-Armed Bandits with Adaptive Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During online decision making in Multi-Armed Bandits (MAB), one needs to\nconduct inference on the true mean reward of each arm based on data collected\nso far at each step. However, since the arms are adaptively selected--thereby\nyielding non-iid data--conducting inference accurately is not straightforward.\nIn particular, sample averaging, which is used in the family of UCB and\nThompson sampling (TS) algorithms, does not provide a good choice as it suffers\nfrom bias and a lack of good statistical properties (e.g. asymptotic\nnormality). Our thesis in this paper is that more sophisticated inference\nschemes that take into account the adaptive nature of the sequentially\ncollected data can unlock further performance gains, even though both UCB and\nTS type algorithms are optimal in the worst case. In particular, we propose a\nvariant of TS-style algorithms--which we call doubly adaptive TS--that\nleverages recent advances in causal inference and adaptively reweights the\nterms of a doubly robust estimator on the true mean reward of each arm. Through\n20 synthetic domain experiments and a semi-synthetic experiment based on data\nfrom an A/B test of a web service, we demonstrate that using an adaptive\ninferential scheme (while still retaining the exploration efficacy of TS)\nprovides clear benefits in online decision making: the proposed DATS algorithm\nhas superior empirical performance to existing baselines (UCB and TS) in terms\nof regret and sample complexity in identifying the best arm. In addition, we\nalso provide a finite-time regret bound of doubly adaptive TS that matches (up\nto log factors) those of UCB and TS algorithms, thereby establishing that its\nimproved practical benefits do not come at the expense of worst-case\nsuboptimality.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 22:29:25 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 00:27:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Dimakopoulou", "Maria", ""], ["Ren", "Zhimei", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "2102.13219", "submitter": "Theodor Misiakiewicz Mr.", "authors": "Song Mei, Theodor Misiakiewicz, Andrea Montanari", "title": "Learning with invariances in random features and kernel models", "comments": "63 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of machine learning tasks entail a high degree of invariance: the\ndata distribution does not change if we act on the data with a certain group of\ntransformations. For instance, labels of images are invariant under\ntranslations of the images. Certain neural network architectures -- for\ninstance, convolutional networks -- are believed to owe their success to the\nfact that they exploit such invariance properties. With the objective of\nquantifying the gain achieved by invariant architectures, we introduce two\nclasses of models: invariant random features and invariant kernel methods. The\nlatter includes, as a special case, the neural tangent kernel for convolutional\nnetworks with global average pooling. We consider uniform covariates\ndistributions on the sphere and hypercube and a general invariant target\nfunction. We characterize the test error of invariant methods in a\nhigh-dimensional regime in which the sample size and number of hidden units\nscale as polynomials in the dimension, for a class of groups that we call\n`degeneracy $\\alpha$', with $\\alpha \\leq 1$. We show that exploiting invariance\nin the architecture saves a $d^\\alpha$ factor ($d$ stands for the dimension) in\nsample size and number of hidden units to achieve the same test error as for\nunstructured architectures.\n  Finally, we show that output symmetrization of an unstructured kernel\nestimator does not give a significant statistical improvement; on the other\nhand, data augmentation with an unstructured kernel estimator is equivalent to\nan invariant kernel estimator and enjoys the same improvement in statistical\nefficiency.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 23:06:21 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Mei", "Song", ""], ["Misiakiewicz", "Theodor", ""], ["Montanari", "Andrea", ""]]}, {"id": "2102.13229", "submitter": "Yan Sun", "authors": "Yan Sun, Qifan Song, Faming Liang", "title": "Consistent Sparse Deep Learning: Theory and Computation", "comments": "Accepted by JASA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been the engine powering many successes of data science.\nHowever, the deep neural network (DNN), as the basic model of deep learning, is\noften excessively over-parameterized, causing many difficulties in training,\nprediction and interpretation. We propose a frequentist-like method for\nlearning sparse DNNs and justify its consistency under the Bayesian framework:\nthe proposed method could learn a sparse DNN with at most $O(n/\\log(n))$\nconnections and nice theoretical guarantees such as posterior consistency,\nvariable selection consistency and asymptotically optimal generalization\nbounds. In particular, we establish posterior consistency for the sparse DNN\nwith a mixture Gaussian prior, show that the structure of the sparse DNN can be\nconsistently determined using a Laplace approximation-based marginal posterior\ninclusion probability approach, and use Bayesian evidence to elicit sparse DNNs\nlearned by an optimization method such as stochastic gradient descent in\nmultiple runs with different initializations. The proposed method is\ncomputationally more efficient than standard Bayesian methods for large-scale\nsparse DNNs. The numerical results indicate that the proposed method can\nperform very well for large-scale network compression and high-dimensional\nnonlinear variable selection, both advancing interpretable machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 23:31:24 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 02:45:09 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Sun", "Yan", ""], ["Song", "Qifan", ""], ["Liang", "Faming", ""]]}, {"id": "2102.13240", "submitter": "Sanath Kumar Krishnamurthy", "authors": "Sanath Kumar Krishnamurthy, Vitor Hadad, and Susan Athey", "title": "Adapting to Misspecification in Contextual Bandits with Offline\n  Regression Oracles", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computationally efficient contextual bandits are often based on estimating a\npredictive model of rewards given contexts and arms using past data. However,\nwhen the reward model is not well-specified, the bandit algorithm may incur\nunexpected regret, so recent work has focused on algorithms that are robust to\nmisspecification. We propose a simple family of contextual bandit algorithms\nthat adapt to misspecification error by reverting to a good safe policy when\nthere is evidence that misspecification is causing a regret increase. Our\nalgorithm requires only an offline regression oracle to ensure regret\nguarantees that gracefully degrade in terms of a measure of the average\nmisspecification level. Compared to prior work, we attain similar regret\nguarantees, but we do no rely on a master algorithm, and do not require more\nrobust oracles like online or constrained regression oracles (e.g., Foster et\nal. (2020a); Krishnamurthy et al. (2020)). This allows us to design algorithms\nfor more general function approximation classes.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 00:15:04 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 17:24:30 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Krishnamurthy", "Sanath Kumar", ""], ["Hadad", "Vitor", ""], ["Athey", "Susan", ""]]}, {"id": "2102.13276", "submitter": "Yariv Aizenbud", "authors": "Yariv Aizenbud, Ariel Jaffe, Meng Wang, Amber Hu, Noah Amsel, Boaz\n  Nadler, Joseph T. Chang, Yuval Kluger", "title": "Spectral Top-Down Recovery of Latent Tree Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the distribution of high dimensional data by a latent tree graphical\nmodel is a common approach in multiple scientific domains. A common task is to\ninfer the underlying tree structure given only observations of the terminal\nnodes. Many algorithms for tree recovery are computationally intensive, which\nlimits their applicability to trees of moderate size. For large trees, a common\napproach, termed divide-and-conquer, is to recover the tree structure in two\nsteps. First, recover the structure separately for multiple randomly selected\nsubsets of the terminal nodes. Second, merge the resulting subtrees to form a\nfull tree. Here, we develop Spectral Top-Down Recovery (STDR), a\ndivide-and-conquer approach for inference of large latent tree models. Unlike\nprevious methods, STDR's partitioning step is non-random. Instead, it is based\non the Fiedler vector of a suitable Laplacian matrix related to the observed\nnodes. We prove that under certain conditions this partitioning is consistent\nwith the tree structure. This, in turn leads to a significantly simpler merging\nprocedure of the small subtrees. We prove that STDR is statistically\nconsistent, and bound the number of samples required to accurately recover the\ntree with high probability. Using simulated data from several common tree\nmodels in phylogenetics, we demonstrate that STDR has a significant advantage\nin terms of runtime, with improved or similar accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 02:47:42 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Aizenbud", "Yariv", ""], ["Jaffe", "Ariel", ""], ["Wang", "Meng", ""], ["Hu", "Amber", ""], ["Amsel", "Noah", ""], ["Nadler", "Boaz", ""], ["Chang", "Joseph T.", ""], ["Kluger", "Yuval", ""]]}, {"id": "2102.13278", "submitter": "Eric Lock", "authors": "Elise F. Palzer, Christine Wendt, Russell Bowler, Craig P. Hersh,\n  Sandra E. Safo, and Eric F. Lock", "title": "sJIVE: Supervised Joint and Individual Variation Explained", "comments": "23 pages, 8 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analyzing multi-source data, which are multiple views of data on the same\nsubjects, has become increasingly common in molecular biomedical research.\nRecent methods have sought to uncover underlying structure and relationships\nwithin and/or between the data sources, and other methods have sought to build\na predictive model for an outcome using all sources. However, existing methods\nthat do both are presently limited because they either (1) only consider data\nstructure shared by all datasets while ignoring structures unique to each\nsource, or (2) they extract underlying structures first without consideration\nto the outcome. We propose a method called supervised joint and individual\nvariation explained (sJIVE) that can simultaneously (1) identify shared (joint)\nand source-specific (individual) underlying structure and (2) build a linear\nprediction model for an outcome using these structures. These two components\nare weighted to compromise between explaining variation in the multi-source\ndata and in the outcome. Simulations show sJIVE to outperform existing methods\nwhen large amounts of noise are present in the multi-source data. An\napplication to data from the COPDGene study reveals gene expression and\nproteomic patterns that are predictive of lung function. Functions to perform\nsJIVE are included in the R.JIVE package, available online at\nhttp://github.com/lockEF/r.jive .\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 02:54:45 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Palzer", "Elise F.", ""], ["Wendt", "Christine", ""], ["Bowler", "Russell", ""], ["Hersh", "Craig P.", ""], ["Safo", "Sandra E.", ""], ["Lock", "Eric F.", ""]]}, {"id": "2102.13347", "submitter": "Clement Benard", "authors": "Cl\\'ement B\\'enard (LPSM), S\\'ebastien da Veiga, Erwan Scornet (CMAP)", "title": "MDA for random forests: inconsistency, and a practical solution via the\n  Sobol-MDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable importance measures are the main tools to analyze the black-box\nmechanism of random forests. Although the Mean Decrease Accuracy (MDA) is\nwidely accepted as the most efficient variable importance measure for random\nforests, little is known about its theoretical properties. In fact, the exact\nMDA definition varies across the main random forest software. In this article,\nour objective is to rigorously analyze the behavior of the main MDA\nimplementations. Consequently, we mathematically formalize the various\nimplemented MDA algorithms, and then establish their limits when the sample\nsize increases. In particular, we break down these limits in three components:\nthe first two are related to Sobol indices, which are well-defined measures of\na variable contribution to the output variance, widely used in the sensitivity\nanalysis field, as opposed to the third term, whose value increases with\ndependence within input variables. Thus, we theoretically demonstrate that the\nMDA does not target the right quantity when inputs are dependent, a fact that\nhas already been noticed experimentally. To address this issue, we define a new\nimportance measure for random forests, the Sobol-MDA, which fixes the flaws of\nthe original MDA. We prove the consistency of the Sobol-MDA and show its good\nempirical performance through experiments on both simulated and real data. An\nopen source implementation in R and C++ is available online.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 07:53:39 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["B\u00e9nard", "Cl\u00e9ment", "", "LPSM"], ["da Veiga", "S\u00e9bastien", "", "CMAP"], ["Scornet", "Erwan", "", "CMAP"]]}, {"id": "2102.13380", "submitter": "Elsa Cazelles", "authors": "Elsa Cazelles and Felipe Tobar and Joaquin Fontbona", "title": "Streaming computation of optimal weak transport barycenters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the weak barycenter of a family of probability distributions,\nbased on the recently developed notion of optimal weak transport of measures\narXiv:1412.7480(v4). We provide a theoretical analysis of the weak barycenter\nand its relationship to the classic Wasserstein barycenter, and discuss its\nmeaning in the light of convex ordering between probability measures. In\nparticular, we argue that, rather than averaging the information of the input\ndistributions as done by the usual optimal transport barycenters, weak\nbarycenters contain geometric information shared across all input\ndistributions, which can be interpreted as a latent random variable affecting\nall the measures. We also provide iterative algorithms to compute a weak\nbarycenter for either finite or infinite families of arbitrary measures (with\nfinite moments of order 2), which are particularly well suited for the\nstreaming setting, i.e., when measures arrive sequentially. In particular, our\nstreaming computation of weak barycenters does not require to smooth empirical\nmeasures or to define a common grid for them, as some of the previous\napproaches to Wasserstin barycenters do. The concept of weak barycenter and our\ncomputation approaches are illustrated on synthetic examples, validated on 2D\nreal-world data and compared to the classical Wasserstein barycenters.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 10:08:02 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Cazelles", "Elsa", ""], ["Tobar", "Felipe", ""], ["Fontbona", "Joaquin", ""]]}, {"id": "2102.13382", "submitter": "Changyong Oh", "authors": "Changyong Oh, Roberto Bondesan, Efstratios Gavves, Max Welling", "title": "Batch Bayesian Optimization on Permutations using Acquisition Weighted\n  Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a batch Bayesian optimization method for\ncombinatorial problems on permutations, which is well suited for expensive cost\nfunctions on permutations. We introduce LAW, a new efficient batch acquisition\nmethod based on the determinantal point process, using an acquisition weighted\nkernel. Relying on multiple parallel evaluations, LAW accelerates the search\nfor the optimal permutation. We provide a regret analysis for our method to\ngain insight in its theoretical properties. We then apply the framework to\npermutation problems, which have so far received little attention in the\nBayesian Optimization literature, despite their practical importance. We call\nthis method LAW2ORDER. We evaluate the method on several standard combinatorial\nproblems involving permutations such as quadratic assignment, flowshop\nscheduling and the traveling salesman, as well as on a structure learning task.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 10:15:57 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Oh", "Changyong", ""], ["Bondesan", "Roberto", ""], ["Gavves", "Efstratios", ""], ["Welling", "Max", ""]]}, {"id": "2102.13388", "submitter": "Aur\\'elie Boisbunon", "authors": "Aur\\'elie Boisbunon, Carlo Fanara, Ingrid Grenet, Jonathan Daeden,\n  Alexis Vighi, Marc Schoenauer", "title": "Zoetrope Genetic Programming for Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Zoetrope Genetic Programming (ZGP) algorithm is based on an original\nrepresentation for mathematical expressions, targeting evolutionary symbolic\nregression.The zoetropic representation uses repeated fusion operations between\npartial expressions, starting from the terminal set. Repeated fusions within an\nindividual gradually generate more complex expressions, ending up in what can\nbe viewed as new features. These features are then linearly combined to best\nfit the training data. ZGP individuals then undergo specific crossover and\nmutation operators, and selection takes place between parents and offspring.\nZGP is validated using a large number of public domain regression datasets, and\ncompared to other symbolic regression algorithms, as well as to traditional\nmachine learning algorithms. ZGP reaches state-of-the-art performance with\nrespect to both types of algorithms, and demonstrates a low computational time\ncompared to other symbolic regression approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 10:47:10 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Boisbunon", "Aur\u00e9lie", ""], ["Fanara", "Carlo", ""], ["Grenet", "Ingrid", ""], ["Daeden", "Jonathan", ""], ["Vighi", "Alexis", ""], ["Schoenauer", "Marc", ""]]}, {"id": "2102.13416", "submitter": "D\\'avid Terj\\'ek", "authors": "D\\'avid Terj\\'ek", "title": "Moreau-Yosida $f$-divergences", "comments": "ICML 2021 camera ready with appendix, 38 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.FA math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational representations of $f$-divergences are central to many machine\nlearning algorithms, with Lipschitz constrained variants recently gaining\nattention. Inspired by this, we define the Moreau-Yosida approximation of\n$f$-divergences with respect to the Wasserstein-$1$ metric. The corresponding\nvariational formulas provide a generalization of a number of recent results,\nnovel special cases of interest and a relaxation of the hard Lipschitz\nconstraint. Additionally, we prove that the so-called tight variational\nrepresentation of $f$-divergences can be to be taken over the quotient space of\nLipschitz functions, and give a characterization of functions achieving the\nsupremum in the variational representation. On the practical side, we propose\nan algorithm to calculate the tight convex conjugate of $f$-divergences\ncompatible with automatic differentiation frameworks. As an application of our\nresults, we propose the Moreau-Yosida $f$-GAN, providing an implementation of\nthe variational formulas for the Kullback-Leibler, reverse Kullback-Leibler,\n$\\chi^2$, reverse $\\chi^2$, squared Hellinger, Jensen-Shannon, Jeffreys,\ntriangular discrimination and total variation divergences as GANs trained on\nCIFAR-10, leading to competitive results and a simple solution to the problem\nof uniqueness of the optimal critic.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 11:46:10 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 14:51:48 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Terj\u00e9k", "D\u00e1vid", ""]]}, {"id": "2102.13419", "submitter": "Fabian B. Fuchs Mr", "authors": "Fabian B. Fuchs, Edward Wagstaff, Justas Dauparas, Ingmar Posner", "title": "Iterative SE(3)-Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When manipulating three-dimensional data, it is possible to ensure that\nrotational and translational symmetries are respected by applying so-called\nSE(3)-equivariant models. Protein structure prediction is a prominent example\nof a task which displays these symmetries. Recent work in this area has\nsuccessfully made use of an SE(3)-equivariant model, applying an iterative\nSE(3)-equivariant attention mechanism. Motivated by this application, we\nimplement an iterative version of the SE(3)-Transformer, an SE(3)-equivariant\nattention-based model for graph data. We address the additional complications\nwhich arise when applying the SE(3)-Transformer in an iterative fashion,\ncompare the iterative and single-pass versions on a toy problem, and consider\nwhy an iterative model may be beneficial in some problem settings. We make the\ncode for our implementation available to the community.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 11:56:34 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 17:40:47 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Fuchs", "Fabian B.", ""], ["Wagstaff", "Edward", ""], ["Dauparas", "Justas", ""], ["Posner", "Ingmar", ""]]}, {"id": "2102.13478", "submitter": "Naman Agarwal", "authors": "Naman Agarwal, Elad Hazan, Anirudha Majumdar, Karan Singh", "title": "A Regret Minimization Approach to Iterative Learning Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of iterative learning control, or model-based policy\nlearning in the presence of uncertain, time-varying dynamics. In this setting,\nwe propose a new performance metric, planning regret, which replaces the\nstandard stochastic uncertainty assumptions with worst case regret. Based on\nrecent advances in non-stochastic control, we design a new iterative algorithm\nfor minimizing planning regret that is more robust to model mismatch and\nuncertainty. We provide theoretical and empirical evidence that the proposed\nalgorithm outperforms existing methods on several benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 13:48:49 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Agarwal", "Naman", ""], ["Hazan", "Elad", ""], ["Majumdar", "Anirudha", ""], ["Singh", "Karan", ""]]}, {"id": "2102.13503", "submitter": "Baptiste Barreau", "authors": "Baptiste Barreau, Laurent Carlier", "title": "History-Augmented Collaborative Filtering for Financial Recommendations", "comments": null, "journal-ref": "RecSys '20: Fourteenth ACM Conference on Recommender Systems, Sep\n  2020, Virtual Event, Brazil. pp.492-497", "doi": "10.1145/3383313.3412206", "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many businesses, and particularly in finance, the behavior of a client\nmight drastically change over time. It is consequently crucial for recommender\nsystems used in such environments to be able to adapt to these changes. In this\nstudy, we propose a novel collaborative filtering algorithm that captures the\ntemporal context of a user-item interaction through the users' and items'\nrecent interaction histories to provide dynamic recommendations. The algorithm,\ndesigned with issues specific to the financial world in mind, uses a custom\nneural network architecture that tackles the non-stationarity of users' and\nitems' behaviors. The performance and properties of the algorithm are monitored\nin a series of experiments on a G10 bond request for quotation proprietary\ndatabase from BNP Paribas Corporate and Institutional Banking.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 14:24:04 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Barreau", "Baptiste", ""], ["Carlier", "Laurent", ""]]}, {"id": "2102.13515", "submitter": "V\\'ictor Campos", "authors": "V\\'ictor Campos, Pablo Sprechmann, Steven Hansen, Andre Barreto,\n  Steven Kapturowski, Alex Vitvitskyi, Adri\\`a Puigdom\\`enech Badia, Charles\n  Blundell", "title": "Beyond Fine-Tuning: Transferring Behavior in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Designing agents that acquire knowledge autonomously and use it to solve new\ntasks efficiently is an important challenge in reinforcement learning.\nKnowledge acquired during an unsupervised pre-training phase is often\ntransferred by fine-tuning neural network weights once rewards are exposed, as\nis common practice in supervised domains. Given the nature of the reinforcement\nlearning problem, we argue that standard fine-tuning strategies alone are not\nenough for efficient transfer in challenging domains. We introduce Behavior\nTransfer (BT), a technique that leverages pre-trained policies for exploration\nand that is complementary to transferring neural network weights. Our\nexperiments show that, when combined with large-scale pre-training in the\nabsence of rewards, existing intrinsic motivation objectives can lead to the\nemergence of complex behaviors. These pre-trained policies can then be\nleveraged by BT to discover better solutions than without pre-training, and\ncombining BT with standard fine-tuning strategies results in additional\nbenefits. The largest gains are generally observed in domains requiring\nstructured exploration, including settings where the behavior of the\npre-trained policies is misaligned with the downstream task.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 16:51:02 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 10:08:08 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 09:36:51 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Campos", "V\u00edctor", ""], ["Sprechmann", "Pablo", ""], ["Hansen", "Steven", ""], ["Barreto", "Andre", ""], ["Kapturowski", "Steven", ""], ["Vitvitskyi", "Alex", ""], ["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["Blundell", "Charles", ""]]}, {"id": "2102.13519", "submitter": "Stefan Bl\\\"ucher", "authors": "Stefan Bl\\\"ucher and Nils Strodthoff", "title": "PredDiff: Explanations and Interactions from Conditional Expectations", "comments": "8 pages, 4 Figures, clarified main text and revised Appendix D, code\n  available at https://github.com/PredDiff/PredDiffTabular", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  PredDiff is a model-agnostic, local attribution method that is firmly rooted\nin probability theory. Its simple intuition is to measure prediction changes\nwhen marginalizing out feature variables. In this work, we clarify properties\nof PredDiff and put forward several extensions of the original formalism. Most\nnotably, we introduce a new measure for interaction effects. Interactions are\nan inevitable step towards a comprehensive understanding of black-box models.\nImportantly, our framework readily allows to investigate interactions between\narbitrary feature subsets and scales linearly with their number. We demonstrate\nthe soundness of PredDiff relevances and interactions both in the\nclassification and regression setting. To this end, we use different analytic,\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 14:46:47 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 14:27:07 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bl\u00fccher", "Stefan", ""], ["Strodthoff", "Nils", ""]]}, {"id": "2102.13522", "submitter": "Xinyan Li", "authors": "Xinyan Li and Arindam Banerjee", "title": "Experiments with Rich Regime Training for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of advances in understanding lazy training, recent work attributes\nthe practical success of deep learning to the rich regime with complex\ninductive bias. In this paper, we study rich regime training empirically with\nbenchmark datasets, and find that while most parameters are lazy, there is\nalways a small number of active parameters which change quite a bit during\ntraining. We show that re-initializing (resetting to their initial random\nvalues) the active parameters leads to worse generalization. Further, we show\nthat most of the active parameters are in the bottom layers, close to the\ninput, especially as the networks become wider. Based on such observations, we\nstudy static Layer-Wise Sparse (LWS) SGD, which only updates some subsets of\nlayers. We find that only updating the top and bottom layers have good\ngeneralization and, as expected, only updating the top layers yields a fast\nalgorithm. Inspired by this, we investigate probabilistic LWS-SGD, which mostly\nupdates the top layers and occasionally updates the full network. We show that\nprobabilistic LWS-SGD matches the generalization performance of vanilla SGD and\nthe back-propagation time can be 2-5 times more efficient.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 14:49:28 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Li", "Xinyan", ""], ["Banerjee", "Arindam", ""]]}, {"id": "2102.13566", "submitter": "Borjan Geshkovski", "authors": "Carlos Esteve Yag\\\"ue and Borjan Geshkovski", "title": "Sparse approximation in learning via neural ODEs", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the continuous-time, neural ordinary differential equation\n(neural ODE) perspective of deep supervised learning, and study the impact of\nthe final time horizon $T$ in training. We focus on a cost consisting of an\nintegral of the empirical risk over the time interval, and $L^1$--parameter\nregularization. Under homogeneity assumptions on the dynamics (typical for ReLU\nactivations), we prove that any global minimizer is sparse, in the sense that\nthere exists a positive stopping time $T^*$ beyond which the optimal parameters\nvanish. Moreover, under appropriate interpolation assumptions on the neural\nODE, we provide quantitative estimates of the stopping time $T^\\ast$, and of\nthe training error of the trajectories at the stopping time. The latter\nstipulates a quantitative approximation property of neural ODE flows with\nsparse parameters. In practical terms, a shorter time-horizon in the training\nproblem can be interpreted as considering a shallower residual neural network\n(ResNet), and since the optimal parameters are concentrated over a shorter time\nhorizon, such a consideration may lower the computational cost of training\nwithout discarding relevant information.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 16:23:02 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Yag\u00fce", "Carlos Esteve", ""], ["Geshkovski", "Borjan", ""]]}, {"id": "2102.13625", "submitter": "Haofeng Zhang", "authors": "Haoxian Chen, Ziyi Huang, Henry Lam, Huajie Qian, Haofeng Zhang", "title": "Learning Prediction Intervals for Regression: Generalization and\n  Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the generation of prediction intervals in regression for uncertainty\nquantification. This task can be formalized as an empirical constrained\noptimization problem that minimizes the average interval width while\nmaintaining the coverage accuracy across data. We strengthen the existing\nliterature by studying two aspects of this empirical optimization. First is a\ngeneral learning theory to characterize the optimality-feasibility tradeoff\nthat encompasses Lipschitz continuity and VC-subgraph classes, which are\nexemplified in regression trees and neural networks. Second is a calibration\nmachinery and the corresponding statistical theory to optimally select the\nregularization parameter that manages this tradeoff, which bypasses the\noverfitting issues in previous approaches in coverage attainment. We\nempirically demonstrate the strengths of our interval generation and\ncalibration algorithms in terms of testing performances compared to existing\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 17:55:30 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Chen", "Haoxian", ""], ["Huang", "Ziyi", ""], ["Lam", "Henry", ""], ["Qian", "Huajie", ""], ["Zhang", "Haofeng", ""]]}, {"id": "2102.13640", "submitter": "Jakob Heiss", "authors": "Jakob Heiss, Jakob Weissteiner, Hanna Wutte, Sven Seuken, Josef\n  Teichmann", "title": "NOMU: Neural Optimization-based Model Uncertainty", "comments": "9 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods for estimating model uncertainty for neural networks (NNs).\nTo isolate the effect of model uncertainty, we focus on a noiseless setting\nwith scarce training data. We introduce five important desiderata regarding\nmodel uncertainty that any method should satisfy. However, we find that\nestablished benchmarks often fail to reliably capture some of these desiderata,\neven those that are required by Bayesian theory. To address this, we introduce\na new approach for capturing model uncertainty for NNs, which we call Neural\nOptimization-based Model Uncertainty (NOMU). The main idea of NOMU is to design\na network architecture consisting of two connected sub-NNs, one for model\nprediction and one for model uncertainty, and to train it using a\ncarefully-designed loss function. Importantly, our design enforces that NOMU\nsatisfies our five desiderata. Due to its modular architecture, NOMU can\nprovide model uncertainty for any given (previously trained) NN if given access\nto its training data. We first experimentally study noiseless regression with\nscarce training data to highlight the deficiencies of the established\nbenchmarks. Finally, we study the important task of Bayesian optimization (BO)\nwith costly evaluations, where good model uncertainty estimates are essential.\nOur results show that NOMU performs as well or better than state-of-the-art\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 18:34:43 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 16:53:19 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 22:00:03 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Heiss", "Jakob", ""], ["Weissteiner", "Jakob", ""], ["Wutte", "Hanna", ""], ["Seuken", "Sven", ""], ["Teichmann", "Josef", ""]]}, {"id": "2102.13647", "submitter": "Alexander Reisach", "authors": "Alexander G. Reisach, Christof Seiler, Sebastian Weichwald", "title": "Beware of the Simulated DAG! Varsortability in Additive Noise Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive noise models are a class of causal models in which each variable is\ndefined as a function of its causes plus independent noise. In such models, the\nordering of variables by marginal variances may be indicative of the causal\norder. We introduce varsortability as a measure of agreement between the\nordering by marginal variance and the causal order. We show how varsortability\ndominates the performance of continuous structure learning algorithms on\nsynthetic data. On real-world data, varsortability is an implausible and\nuntestable assumption and we find no indication of high varsortability. We aim\nto raise awareness that varsortability easily occurs in simulated additive\nnoise models. We provide a baseline method that explicitly exploits\nvarsortability and advocate reporting varsortability in benchmarking data.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 18:52:27 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Reisach", "Alexander G.", ""], ["Seiler", "Christof", ""], ["Weichwald", "Sebastian", ""]]}, {"id": "2102.13653", "submitter": "Ali Ramezani-Kebrya", "authors": "Ali Ramezani-Kebrya, Ashish Khisti, Ben Liang", "title": "On the Generalization of Stochastic Gradient Descent with Momentum", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.04564", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While momentum-based methods, in conjunction with stochastic gradient descent\n(SGD), are widely used when training machine learning models, there is little\ntheoretical understanding on the generalization error of such methods. In this\nwork, we first show that there exists a convex loss function for which\nalgorithmic stability fails to establish generalization guarantees when SGD\nwith standard heavy-ball momentum (SGDM) is run for multiple epochs. Then, for\nsmooth Lipschitz loss functions, we analyze a modified momentum-based update\nrule, i.e., SGD with early momentum (SGDEM), and show that it admits an\nupper-bound on the generalization error. Thus, our results show that machine\nlearning models can be trained for multiple epochs of SGDEM with a guarantee\nfor generalization. Finally, for the special case of strongly convex loss\nfunctions, we find a range of momentum such that multiple epochs of standard\nSGDM, as a special form of SGDEM, also generalizes. Extending our results on\ngeneralization, we also develop an upper-bound on the expected true risk, in\nterms of the number of training steps, the size of the training set, and the\nmomentum parameter. Experimental evaluations verify the consistency between the\nnumerical results and our theoretical bounds and the effectiveness of SGDEM for\nsmooth Lipschitz loss functions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 18:58:29 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Ramezani-Kebrya", "Ali", ""], ["Khisti", "Ashish", ""], ["Liang", "Ben", ""]]}]