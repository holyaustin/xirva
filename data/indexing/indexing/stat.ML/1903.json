[{"id": "1903.00001", "submitter": "Heyi Li", "authors": "Heyi Li, Dongdong Chen, William H. Nailon, Mike E. Davies and Dave\n  Laurenson", "title": "A Deep DUAL-PATH Network for Improved Mammogram Image Processing", "comments": "To Appear in ICCASP 2019 May", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present, for the first time, a novel deep neural network architecture\ncalled \\dcn with a dual-path connection between the input image and output\nclass label for mammogram image processing. This architecture is built upon\nU-Net, which non-linearly maps the input data into a deep latent space. One\npath of the \\dcnn, the locality preserving learner, is devoted to\nhierarchically extracting and exploiting intrinsic features of the input, while\nthe other path, called the conditional graph learner, focuses on modeling the\ninput-mask correlations. The learned mask is further used to improve\nclassification results, and the two learning paths complement each other. By\nintegrating the two learners our new architecture provides a simple but\neffective way to jointly learn the segmentation and predict the class label.\nBenefiting from the powerful expressive capacity of deep neural networks a more\ndiscriminative representation can be learned, in which both the semantics and\nstructure are well preserved. Experimental results show that \\dcn achieves the\nbest mammography segmentation and classification simultaneously, outperforming\nrecent state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 11:51:47 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Li", "Heyi", ""], ["Chen", "Dongdong", ""], ["Nailon", "William H.", ""], ["Davies", "Mike E.", ""], ["Laurenson", "Dave", ""]]}, {"id": "1903.00027", "submitter": "Sergey Kolesnikov", "authors": "Sergey Kolesnikov, Oleksii Hrinchuk", "title": "Catalyst.RL: A Distributed Framework for Reproducible RL Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent progress in deep reinforcement learning field (RL), and,\narguably because of it, a large body of work remains to be done in reproducing\nand carefully comparing different RL algorithms. We present catalyst.RL, an\nopen source framework for RL research with a focus on reproducibility and\nflexibility. Main features of our library include large-scale asynchronous\ndistributed training, easy-to-use configuration files with the complete list of\nhyperparameters for the particular experiments, efficient implementations of\nvarious RL algorithms and auxiliary tricks, such as frame stacking, n-step\nreturns, value distributions, etc. To vindicate the usefulness of our\nframework, we evaluate it on a range of benchmarks in a continuous control, as\nwell as on the task of developing a controller to enable a\nphysiologically-based human model with a prosthetic leg to walk and run. The\nlatter task was introduced at NeurIPS 2018 AI for Prosthetics Challenge, where\nour team took the 3rd place, capitalizing on the ability of catalyst.RL to\ntrain high-quality and sample-efficient RL agents.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 19:06:00 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kolesnikov", "Sergey", ""], ["Hrinchuk", "Oleksii", ""]]}, {"id": "1903.00058", "submitter": "Ankur Bapna", "authors": "Ankur Bapna and Orhan Firat", "title": "Non-Parametric Adaptation for Neural Machine Translation", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks trained with gradient descent are known to be susceptible to\ncatastrophic forgetting caused by parameter shift during the training process.\nIn the context of Neural Machine Translation (NMT) this results in poor\nperformance on heterogeneous datasets and on sub-tasks like rare phrase\ntranslation. On the other hand, non-parametric approaches are immune to\nforgetting, perfectly complementing the generalization ability of NMT. However,\nattempts to combine non-parametric or retrieval based approaches with NMT have\nonly been successful on narrow domains, possibly due to over-reliance on\nsentence level retrieval. We propose a novel n-gram level retrieval approach\nthat relies on local phrase level similarities, allowing us to retrieve\nneighbors that are useful for translation even when overall sentence similarity\nis low. We complement this with an expressive neural network, allowing our\nmodel to extract information from the noisy retrieved context. We evaluate our\nsemi-parametric NMT approach on a heterogeneous dataset composed of WMT, IWSLT,\nJRC-Acquis and OpenSubtitles, and demonstrate gains on all 4 evaluation sets.\nThe semi-parametric nature of our approach opens the door for non-parametric\ndomain adaptation, demonstrating strong inference-time adaptation performance\non new domains without the need for any parameter updates.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 20:33:00 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 18:57:37 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Bapna", "Ankur", ""], ["Firat", "Orhan", ""]]}, {"id": "1903.00066", "submitter": "Ting Bai", "authors": "Ting Bai and Pan Du and Wayne Xin Zhao and Ji-Rong Wen and Jian-Yun\n  Nie", "title": "A Long-Short Demands-Aware Model for Next-Item Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending the right products is the central problem in recommender\nsystems, but the right products should also be recommended at the right time to\nmeet the demands of users, so as to maximize their values. Users' demands,\nimplying strong purchase intents, can be the most useful way to promote\nproducts sales if well utilized. Previous recommendation models mainly focused\non user's general interests to find the right products. However, the aspect of\nmeeting users' demands at the right time has been much less explored. To\naddress this problem, we propose a novel Long-Short Demands-aware Model (LSDM),\nin which both user's interests towards items and user's demands over time are\nincorporated. We summarize two aspects: termed as long-time demands (e.g.,\npurchasing the same product repetitively showing a long-time persistent\ninterest) and short-time demands (e.g., co-purchase like buying paintbrushes\nafter pigments). To utilize such long-short demands of users, we create\ndifferent clusters to group the successive product purchases together according\nto different time spans, and use recurrent neural networks to model each\nsequence of clusters at a time scale. The long-short purchase demands with\nmulti-time scales are finally aggregated by joint learning strategies.\nExperimental results on three real-world commerce datasets demonstrate the\neffectiveness of our model for next-item recommendation, showing the usefulness\nof modeling users' long-short purchase demands of items with multi-time scales.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 07:41:56 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Bai", "Ting", ""], ["Du", "Pan", ""], ["Zhao", "Wayne Xin", ""], ["Wen", "Ji-Rong", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "1903.00070", "submitter": "Binghong Chen", "authors": "Binghong Chen, Bo Dai, Qinjie Lin, Guo Ye, Han Liu, Le Song", "title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation\n  Trees", "comments": "26 pages, 74 figures, ICLR 2020 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a meta path planning algorithm named \\emph{Neural\nExploration-Exploitation Trees~(NEXT)} for learning from prior experience for\nsolving new path planning problems in high dimensional continuous state and\naction spaces. Compared to more classical sampling-based methods like RRT, our\napproach achieves much better sample efficiency in high-dimensions and can\nbenefit from prior experience of planning in similar environments. More\nspecifically, NEXT exploits a novel neural architecture which can learn\npromising search directions from problem structures. The learned prior is then\nintegrated into a UCB-type algorithm to achieve an online balance between\n\\emph{exploration} and \\emph{exploitation} when solving a new problem. We\nconduct thorough experiments to show that NEXT accomplishes new planning\nproblems with more compact search trees and significantly outperforms\nstate-of-the-art methods on several benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 20:53:13 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 18:48:51 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 21:59:45 GMT"}, {"version": "v4", "created": "Sun, 23 Feb 2020 08:49:42 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chen", "Binghong", ""], ["Dai", "Bo", ""], ["Lin", "Qinjie", ""], ["Ye", "Guo", ""], ["Liu", "Han", ""], ["Song", "Le", ""]]}, {"id": "1903.00073", "submitter": "Yash Sharma", "authors": "Yash Sharma, Gavin Weiguang Ding, Marcus Brubaker", "title": "On the Effectiveness of Low Frequency Perturbations", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carefully crafted, often imperceptible, adversarial perturbations have been\nshown to cause state-of-the-art models to yield extremely inaccurate outputs,\nrendering them unsuitable for safety-critical application domains. In addition,\nrecent work has shown that constraining the attack space to a low frequency\nregime is particularly effective. Yet, it remains unclear whether this is due\nto generally constraining the attack search space or specifically removing high\nfrequency components from consideration. By systematically controlling the\nfrequency components of the perturbation, evaluating against the top-placing\ndefense submissions in the NeurIPS 2017 competition, we empirically show that\nperformance improvements in both the white-box and black-box transfer settings\nare yielded only when low frequency components are preserved. In fact, the\ndefended models based on adversarial training are roughly as vulnerable to low\nfrequency perturbations as undefended models, suggesting that the purported\nrobustness of state-of-the-art ImageNet defenses is reliant upon adversarial\nperturbations being high frequency in nature. We do find that under\n$\\ell_\\infty$ $\\epsilon=16/255$, the competition distortion bound, low\nfrequency perturbations are indeed perceptible. This questions the use of the\n$\\ell_\\infty$-norm, in particular, as a distortion metric, and, in turn,\nsuggests that explicitly considering the frequency space is promising for\nlearning robust models which better align with human perception.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 21:25:45 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 00:36:16 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sharma", "Yash", ""], ["Ding", "Gavin Weiguang", ""], ["Brubaker", "Marcus", ""]]}, {"id": "1903.00091", "submitter": "Prakash Mohan", "authors": "Prakash Mohan, Marc T. Henry de Frahan, Ryan King, Ray W. Grout", "title": "A block-random algorithm for learning on distributed, heterogeneous data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning models are based on deep neural networks with multiple\nlayers between input and output. The parameters defining these layers are\ninitialized using random values and are \"learned\" from data, typically using\nstochastic gradient descent based algorithms. These algorithms rely on data\nbeing randomly shuffled before optimization. The randomization of the data\nprior to processing in batches that is formally required for stochastic\ngradient descent algorithm to effectively derive a useful deep learning model\nis expected to be prohibitively expensive for in situ model training because of\nthe resulting data communications across the processor nodes. We show that the\nstochastic gradient descent (SGD) algorithm can still make useful progress if\nthe batches are defined on a per-processor basis and processed in random order\neven though (i) the batches are constructed from data samples from a single\nclass or specific flow region, and (ii) the overall data samples are\nheterogeneous. We present block-random gradient descent, a new algorithm that\nworks on distributed, heterogeneous data without having to pre-shuffle. This\nalgorithm enables in situ learning for exascale simulations. The performance of\nthis algorithm is demonstrated on a set of benchmark classification models and\nthe construction of a subgrid scale large eddy simulations (LES) model for\nturbulent channel flow using a data model similar to that which will be\nencountered in exascale simulation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 22:28:37 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Mohan", "Prakash", ""], ["de Frahan", "Marc T. Henry", ""], ["King", "Ryan", ""], ["Grout", "Ray W.", ""]]}, {"id": "1903.00092", "submitter": "Rohan Kodialam", "authors": "Rohan Kodialam", "title": "Optimal Algorithms for Ski Rental with Soft Machine-Learned Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the classic Ski Rental online algorithm with\napplications to machine learning. In our variant, we allow the skier access to\na black-box machine-learning algorithm that provides an estimate of the\nprobability that there will be at most a threshold number of ski-days. We\nderive a class of optimal randomized algorithms to determine the strategy that\nminimizes the worst-case expected competitive ratio for the skier given a\nprediction from the machine learning algorithm,and analyze the performance and\nrobustness of these algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 22:34:46 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 20:29:57 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kodialam", "Rohan", ""]]}, {"id": "1903.00099", "submitter": "Peng Jiang", "authors": "Peng Jiang and Yingrui Yang (co-first authors), Gann Bierner, Fengjie\n  Alex Li, Ruhan Wang, Azadeh Moghtaderi", "title": "Ranking in Genealogy: Search Results Fusion at Ancestry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Genealogy research is the study of family history using available resources\nsuch as historical records. Ancestry provides its customers with one of the\nworld's largest online genealogical index with billions of records from a wide\nrange of sources, including vital records such as birth and death certificates,\ncensus records, court and probate records among many others. Search at Ancestry\naims to return relevant records from various record types, allowing our\nsubscribers to build their family trees, research their family history, and\nmake meaningful discoveries about their ancestors from diverse perspectives. In\na modern search engine designed for genealogical study, the appropriate ranking\nof search results to provide highly relevant information represents a daunting\nchallenge. In particular, the disparity in historical records makes it\ninherently difficult to score records in an equitable fashion. Herein, we\nprovide an overview of our solutions to overcome such record disparity problems\nin the Ancestry search engine. Specifically, we introduce customized coordinate\nascent (customized CA) to speed up ranking within a specific record type. We\nthen propose stochastic search (SS) that linearly combines ranked results\nfederated across contents from various record types. Furthermore, we propose a\nnovel information retrieval metric, normalized cumulative entropy (NCE), to\nmeasure the diversity of results. We demonstrate the effectiveness of these two\nalgorithms in terms of relevance (by NDCG) and diversity (by NCE) if applicable\nin the offline experiments using real customer data at Ancestry.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 08:02:33 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Jiang", "Peng", "", "co-first authors"], ["Yang", "Yingrui", "", "co-first authors"], ["Bierner", "Gann", ""], ["Li", "Fengjie Alex", ""], ["Wang", "Ruhan", ""], ["Moghtaderi", "Azadeh", ""]]}, {"id": "1903.00100", "submitter": "Shaojie Xu", "authors": "Shaojie Xu, Anvesha Amaravati, Justin Romberg, Arijit Raychowdhury", "title": "Appearance-based Gesture recognition in the compressed domain", "comments": "arXiv admin note: text overlap with arXiv:1605.08313", "journal-ref": "2017 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), New Orleans, LA, 2017, pp. 1722-1726", "doi": "10.1109/ICASSP.2017.7952451", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel appearance-based gesture recognition algorithm using\ncompressed domain signal processing techniques. Gesture features are extracted\ndirectly from the compressed measurements, which are the block averages and the\ncoded linear combinations of the image sensor's pixel values. We also improve\nboth the computational efficiency and the memory requirement of the previous\nDTW-based K-NN gesture classifiers. Both simulation testing and hardware\nimplementation strongly support the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 06:05:12 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Xu", "Shaojie", ""], ["Amaravati", "Anvesha", ""], ["Romberg", "Justin", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "1903.00103", "submitter": "Xiaorui Wu", "authors": "Xiaorui Wu, Hong Xu, Honglin Zhang, Huaming Chen, Jian Wang", "title": "Saec: Similarity-Aware Embedding Compression in Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production recommendation systems rely on embedding methods to represent\nvarious features. An impeding challenge in practice is that the large embedding\nmatrix incurs substantial memory footprint in serving as the number of features\ngrows over time. We propose a similarity-aware embedding matrix compression\nmethod called Saec to address this challenge. Saec clusters similar features\nwithin a field to reduce the embedding matrix size. Saec also adopts a fast\nclustering optimization based on feature frequency to drastically improve\nclustering time. We implement and evaluate Saec on Numerous, the production\ndistributed machine learning system in Tencent, with 10-day worth of feature\ndata from QQ mobile browser. Testbed experiments show that Saec reduces the\nnumber of embedding vectors by two orders of magnitude, compresses the\nembedding size by ~27x, and delivers the same AUC and log loss performance.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 05:00:22 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Wu", "Xiaorui", ""], ["Xu", "Hong", ""], ["Zhang", "Honglin", ""], ["Chen", "Huaming", ""], ["Wang", "Jian", ""]]}, {"id": "1903.00114", "submitter": "Clement Lee", "authors": "Clement Lee and Darren J Wilkinson", "title": "A Review of Stochastic Block Models and Extensions for Graph Clustering", "comments": "93 pages, 3 figures, 4 tables", "journal-ref": null, "doi": "10.1007/s41109-019-0232-2", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There have been rapid developments in model-based clustering of graphs, also\nknown as block modelling, over the last ten years or so. We review different\napproaches and extensions proposed for different aspects in this area, such as\nthe type of the graph, the clustering approach, the inference approach, and\nwhether the number of groups is selected or estimated. We also review models\nthat combine block modelling with topic modelling and/or longitudinal\nmodelling, regarding how these models deal with multiple types of data. How\ndifferent approaches cope with various issues will be summarised and compared,\nto facilitate the demand of practitioners for a concise overview of the current\nstatus of these areas of literature.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 00:30:09 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 20:46:20 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Lee", "Clement", ""], ["Wilkinson", "Darren J", ""]]}, {"id": "1903.00197", "submitter": "Eryu Xia", "authors": "Eryu Xia, Xin Du, Jing Mei, Wen Sun, Suijun Tong, Zhiqing Kang, Jian\n  Sheng, Jian Li, Changsheng Ma, Jianzeng Dong, Shaochun Li", "title": "Outcome-Driven Clustering of Acute Coronary Syndrome Patients using\n  Multi-Task Neural Network with Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster analysis aims at separating patients into phenotypically heterogenous\ngroups and defining therapeutically homogeneous patient subclasses. It is an\nimportant approach in data-driven disease classification and subtyping. Acute\ncoronary syndrome (ACS) is a syndrome due to sudden decrease of coronary artery\nblood flow, where disease classification would help to inform therapeutic\nstrategies and provide prognostic insights. Here we conducted outcome-driven\ncluster analysis of ACS patients, which jointly considers treatment and patient\noutcome as indicators for patient state. Multi-task neural network with\nattention was used as a modeling framework, including learning of the patient\nstate, cluster analysis, and feature importance profiling. Seven patient\nclusters were discovered. The clusters have different characteristics, as well\nas different risk profiles to the outcome of in-hospital major adverse cardiac\nevents. The results demonstrate cluster analysis using outcome-driven\nmulti-task neural network as promising for patient classification and\nsubtyping.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 08:20:28 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 07:08:04 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Xia", "Eryu", ""], ["Du", "Xin", ""], ["Mei", "Jing", ""], ["Sun", "Wen", ""], ["Tong", "Suijun", ""], ["Kang", "Zhiqing", ""], ["Sheng", "Jian", ""], ["Li", "Jian", ""], ["Ma", "Changsheng", ""], ["Dong", "Jianzeng", ""], ["Li", "Shaochun", ""]]}, {"id": "1903.00201", "submitter": "{\\L}ukasz Maziarka", "authors": "Przemys{\\l}aw Spurek, Aleksandra Nowak, Jacek Tabor, {\\L}ukasz\n  Maziarka, Stanis{\\l}aw Jastrz\\k{e}bski", "title": "Non-linear ICA based on Cramer-Wold metric", "comments": null, "journal-ref": "Neural Information Processing. ICONIP 2020", "doi": "10.1007/978-3-030-63836-8_25", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear source separation is a challenging open problem with many\napplications. We extend a recently proposed Adversarial Non-linear ICA (ANICA)\nmodel, and introduce Cramer-Wold ICA (CW-ICA). In contrast to ANICA we use a\nsimple, closed--form optimization target instead of a discriminator--based\nindependence measure. Our results show that CW-ICA achieves comparable results\nto ANICA, while foregoing the need for adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 08:42:16 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Spurek", "Przemys\u0142aw", ""], ["Nowak", "Aleksandra", ""], ["Tabor", "Jacek", ""], ["Maziarka", "\u0141ukasz", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""]]}, {"id": "1903.00278", "submitter": "Cedric Renggli", "authors": "Cedric Renggli, Bojan Karla\\v{s}, Bolin Ding, Feng Liu, Kevin\n  Schawinski, Wentao Wu and Ce Zhang", "title": "Continuous Integration of Machine Learning Models with ease.ml/ci:\n  Towards a Rigorous Yet Practical Treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous integration is an indispensable step of modern software\nengineering practices to systematically manage the life cycles of system\ndevelopment. Developing a machine learning model is no difference - it is an\nengineering process with a life cycle, including design, implementation,\ntuning, testing, and deployment. However, most, if not all, existing continuous\nintegration engines do not support machine learning as first-class citizens.\n  In this paper, we present ease.ml/ci, to our best knowledge, the first\ncontinuous integration system for machine learning. The challenge of building\nease.ml/ci is to provide rigorous guarantees, e.g., single accuracy point error\ntolerance with 0.999 reliability, with a practical amount of labeling effort,\ne.g., 2K labels per test. We design a domain specific language that allows\nusers to specify integration conditions with reliability constraints, and\ndevelop simple novel optimizations that can lower the number of labels required\nby up to two orders of magnitude for test conditions popularly used in real\nproduction systems.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 13:15:55 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Renggli", "Cedric", ""], ["Karla\u0161", "Bojan", ""], ["Ding", "Bolin", ""], ["Liu", "Feng", ""], ["Schawinski", "Kevin", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""]]}, {"id": "1903.00345", "submitter": "Mikel Elkano", "authors": "Mikel Elkano and Mikel Uriz and Humberto Bustince and Mikel Galar", "title": "On the usage of the probability integral transform to reduce the\n  complexity of multi-way fuzzy decision trees in Big Data classification\n  problems", "comments": "Appeared in 2018 IEEE International Congress on Big Data (BigData\n  Congress). arXiv admin note: text overlap with arXiv:1902.09357", "journal-ref": null, "doi": "10.1109/BigDataCongress.2018.00011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new distributed fuzzy partitioning method to reduce the\ncomplexity of multi-way fuzzy decision trees in Big Data classification\nproblems. The proposed algorithm builds a fixed number of fuzzy sets for all\nvariables and adjusts their shape and position to the real distribution of\ntraining data. A two-step process is applied : 1) transformation of the\noriginal distribution into a standard uniform distribution by means of the\nprobability integral transform. Since the original distribution is generally\nunknown, the cumulative distribution function is approximated by computing the\nq-quantiles of the training set; 2) construction of a Ruspini strong fuzzy\npartition in the transformed attribute space using a fixed number of equally\ndistributed triangular membership functions. Despite the aforementioned\ntransformation, the definition of every fuzzy set in the original space can be\nrecovered by applying the inverse cumulative distribution function (also known\nas quantile function). The experimental results reveal that the proposed\nmethodology allows the state-of-the-art multi-way fuzzy decision tree (FMDT)\ninduction algorithm to maintain classification accuracy with up to 6 million\nfewer leaves.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 07:48:51 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Elkano", "Mikel", ""], ["Uriz", "Mikel", ""], ["Bustince", "Humberto", ""], ["Galar", "Mikel", ""]]}, {"id": "1903.00359", "submitter": "Minhan Li", "authors": "Hiva Ghanbari, Minhan Li and Katya Scheinberg", "title": "Novel and Efficient Approximations for Zero-One Loss of Linear\n  Classifiers", "comments": "arXiv admin note: text overlap with arXiv:1802.02535", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The predictive quality of machine learning models is typically measured in\nterms of their (approximate) expected prediction accuracy or the so-called Area\nUnder the Curve (AUC). Minimizing the reciprocals of these measures are the\ngoals of supervised learning. However, when the models are constructed by the\nmeans of empirical risk minimization (ERM), surrogate functions such as the\nlogistic loss or hinge loss are optimized instead. In this work, we show that\nin the case of linear predictors, the expected error and the expected ranking\nloss can be effectively approximated by smooth functions whose closed form\nexpressions and those of their first (and second) order derivatives depend on\nthe first and second moments of the data distribution, which can be\nprecomputed. Hence, the complexity of an optimization algorithm applied to\nthese functions does not depend on the size of the training data. These\napproximation functions are derived under the assumption that the output of the\nlinear classifier for a given data set has an approximately normal\ndistribution. We argue that this assumption is significantly weaker than the\nGaussian assumption on the data itself and we support this claim by\ndemonstrating that our new approximation is quite accurate on data sets that\nare not necessarily Gaussian. We present computational results that show that\nour proposed approximations and related optimization algorithms can produce\nlinear classifiers with similar or better test accuracy or AUC, than those\nobtained using state-of-the-art approaches, in a fraction of the time.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:04:51 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Ghanbari", "Hiva", ""], ["Li", "Minhan", ""], ["Scheinberg", "Katya", ""]]}, {"id": "1903.00374", "submitter": "Piotr Mi{\\l}o\\'s", "authors": "Lukasz Kaiser, Mohammad Babaeizadeh, Piotr Milos, Blazej Osinski, Roy\n  H Campbell, Konrad Czechowski, Dumitru Erhan, Chelsea Finn, Piotr Kozakowski,\n  Sergey Levine, Afroz Mohiuddin, Ryan Sepassi, George Tucker, Henryk\n  Michalewski", "title": "Model-Based Reinforcement Learning for Atari", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) can be used to learn effective\npolicies for complex tasks, such as Atari games, even from image observations.\nHowever, this typically requires very large amounts of interaction --\nsubstantially more, in fact, than a human would need to learn the same games.\nHow can people learn so quickly? Part of the answer may be that people can\nlearn how the game works and predict which actions will lead to desirable\noutcomes. In this paper, we explore how video prediction models can similarly\nenable agents to solve Atari games with fewer interactions than model-free\nmethods. We describe Simulated Policy Learning (SimPLe), a complete model-based\ndeep RL algorithm based on video prediction models and present a comparison of\nseveral model architectures, including a novel architecture that yields the\nbest results in our setting. Our experiments evaluate SimPLe on a range of\nAtari games in low data regime of 100k interactions between the agent and the\nenvironment, which corresponds to two hours of real-time play. In most games\nSimPLe outperforms state-of-the-art model-free algorithms, in some games by\nover an order of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 15:40:19 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 17:22:45 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 12:42:06 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 23:00:23 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kaiser", "Lukasz", ""], ["Babaeizadeh", "Mohammad", ""], ["Milos", "Piotr", ""], ["Osinski", "Blazej", ""], ["Campbell", "Roy H", ""], ["Czechowski", "Konrad", ""], ["Erhan", "Dumitru", ""], ["Finn", "Chelsea", ""], ["Kozakowski", "Piotr", ""], ["Levine", "Sergey", ""], ["Mohiuddin", "Afroz", ""], ["Sepassi", "Ryan", ""], ["Tucker", "George", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1903.00386", "submitter": "Nicola Bulso", "authors": "Nicola Bulso, Matteo Marsili, Yasser Roudi", "title": "On the complexity of logistic regression models", "comments": "29 pages, 6 figures, The supplementary material is an ancillary file\n  and can be downloaded from a link on the right", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of logistic regression models which is defined\nby counting the number of indistinguishable distributions that the model can\nrepresent (Balasubramanian, 1997). We find that the complexity of logistic\nmodels with binary inputs does not only depend on the number of parameters but\nalso on the distribution of inputs in a non-trivial way which standard\ntreatments of complexity do not address. In particular, we observe that\ncorrelations among inputs induce effective dependencies among parameters thus\nconstraining the model and, consequently, reducing its complexity. We derive\nsimple relations for the upper and lower bounds of the complexity. Furthermore,\nwe show analytically that, defining the model parameters on a finite support\nrather than the entire axis, decreases the complexity in a manner that\ncritically depends on the size of the domain. Based on our findings, we propose\na novel model selection criterion which takes into account the entropy of the\ninput distribution. We test our proposal on the problem of selecting the input\nvariables of a logistic regression model in a Bayesian Model Selection\nframework. In our numerical tests, we find that, while the reconstruction\nerrors of standard model selection approaches (AIC, BIC, $\\ell_1$\nregularization) strongly depend on the sparsity of the ground truth, the\nreconstruction error of our method is always close to the minimum in all\nconditions of sparsity, data size and strength of input correlations. Finally,\nwe observe that, when considering categorical instead of binary inputs, in a\nsimple and mathematically tractable case, the contribution of the alphabet size\nto the complexity is very small compared to that of parameter space dimension.\nWe further explore the issue by analysing the dataset of the \"13 keys to the\nWhite House\" which is a method for forecasting the outcomes of US presidential\nelections.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:10:55 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Bulso", "Nicola", ""], ["Marsili", "Matteo", ""], ["Roudi", "Yasser", ""]]}, {"id": "1903.00402", "submitter": "Karla DiazOrdaz", "authors": "Noemi Kreif and Karla DiazOrdaz", "title": "Machine learning in policy evaluation: new tools for causal inference", "comments": "40 pages 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning (ML) methods have received a lot of attention in\nrecent years, these methods are primarily for prediction. Empirical researchers\nconducting policy evaluations are, on the other hand, pre-occupied with causal\nproblems, trying to answer counterfactual questions: what would have happened\nin the absence of a policy? Because these counterfactuals can never be directly\nobserved (described as the \"fundamental problem of causal inference\")\nprediction tools from the ML literature cannot be readily used for causal\ninference. In the last decade, major innovations have taken place incorporating\nsupervised ML tools into estimators for causal parameters such as the average\ntreatment effect (ATE). This holds the promise of attenuating model\nmisspecification issues, and increasing of transparency in model selection. One\nparticularly mature strand of the literature include approaches that\nincorporate supervised ML approaches in the estimation of the ATE of a binary\ntreatment, under the \\textit{unconfoundedness} and positivity assumptions (also\nknown as exchangeability and overlap assumptions).\n  This article reviews popular supervised machine learning algorithms,\nincluding the Super Learner. Then, some specific uses of machine learning for\ntreatment effect estimation are introduced and illustrated, namely (1) to\ncreate balance among treated and control groups, (2) to estimate so-called\nnuisance models (e.g. the propensity score, or conditional expectations of the\noutcome) in semi-parametric estimators that target causal parameters (e.g.\ntargeted maximum likelihood estimation or the double ML estimator), and (3) the\nuse of machine learning for variable selection in situations with a high number\nof covariates.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:52:51 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kreif", "Noemi", ""], ["DiazOrdaz", "Karla", ""]]}, {"id": "1903.00405", "submitter": "Aritra Chowdhury", "authors": "Aritra Chowdhury, Malik Magdon-Ismail, Bulent Yener", "title": "Quantifying contribution and propagation of error from computational\n  steps, algorithms and hyperparameter choices in image classification\n  pipelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science relies on pipelines that are organized in the form of\ninterdependent computational steps. Each step consists of various candidate\nalgorithms that maybe used for performing a particular function. Each algorithm\nconsists of several hyperparameters. Algorithms and hyperparameters must be\noptimized as a whole to produce the best performance. Typical machine learning\npipelines consist of complex algorithms in each of the steps. Not only is the\nselection process combinatorial, but it is also important to interpret and\nunderstand the pipelines. We propose a method to quantify the importance of\ndifferent components in the pipeline, by computing an error contribution\nrelative to an agnostic choice of computational steps, algorithms and\nhyperparameters. We also propose a methodology to quantify the propagation of\nerror from individual components of the pipeline with the help of a naive set\nof benchmark algorithms not involved in the pipeline. We demonstrate our\nmethodology on image classification pipelines. The agnostic and naive\nmethodologies quantify the error contribution and propagation respectively from\nthe computational steps, algorithms and hyperparameters in the image\nclassification pipeline. We show that algorithm selection and hyperparameter\noptimization methods like grid search, random search and Bayesian optimization\ncan be used to quantify the error contribution and propagation, and that random\nsearch is able to quantify them more accurately than Bayesian optimization.\nThis methodology can be used by domain experts to understand machine learning\nand data analysis pipelines in terms of their individual components, which can\nhelp in prioritizing different components of the pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 14:42:52 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Chowdhury", "Aritra", ""], ["Magdon-Ismail", "Malik", ""], ["Yener", "Bulent", ""]]}, {"id": "1903.00410", "submitter": "Rafiq Mohammed", "authors": "Rafiq Ahmed Mohammed, Kok-Wai Wong, Mohd Fairuz Shiratuddin, Xuequn\n  Wang", "title": "Improving fraud prediction with incremental data balancing technique for\n  massive data streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of classification algorithms with a massive and highly\nimbalanced data stream depends upon efficient balancing strategy. Some\ntechniques of balancing strategy have been applied in the past with Batch data\nto resolve the class imbalance problem. This paper proposes a new incremental\ndata balancing framework which can work with massive imbalanced data streams.\nIn this paper, we choose Racing Algorithm as an automated data balancing\ntechnique which optimizes the balancing techniques. We applied Random Forest\nclassification algorithm which can deal with the massive data stream. We\ninvestigated the suitability of Racing Algorithm and Random Forest in the\nproposed framework. Applying new technique in the proposed framework on the\nEuropean Credit Card dataset, provided better results than the Batch mode. The\nproposed framework is more scalable to handle online massive data streams.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 07:08:20 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 04:38:15 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Mohammed", "Rafiq Ahmed", ""], ["Wong", "Kok-Wai", ""], ["Shiratuddin", "Mohd Fairuz", ""], ["Wang", "Xuequn", ""]]}, {"id": "1903.00450", "submitter": "Klaus Greff", "authors": "Klaus Greff, Rapha\\\"el Lopez Kaufman, Rishabh Kabra, Nick Watters,\n  Chris Burgess, Daniel Zoran, Loic Matthey, Matthew Botvinick, Alexander\n  Lerchner", "title": "Multi-Object Representation Learning with Iterative Variational\n  Inference", "comments": null, "journal-ref": "ICML 2019 (PMLR 97:2424-2433)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human perception is structured around objects which form the basis for our\nhigher-level cognition and impressive systematic generalization abilities. Yet\nmost work on representation learning focuses on feature learning without even\nconsidering multiple objects, or treats segmentation as an (often supervised)\npreprocessing step. Instead, we argue for the importance of learning to segment\nand represent objects jointly. We demonstrate that, starting from the simple\nassumption that a scene is composed of multiple entities, it is possible to\nlearn to segment images into interpretable objects with disentangled\nrepresentations. Our method learns -- without supervision -- to inpaint\noccluded parts, and extrapolates to scenes with more objects and to unseen\nobjects with novel feature combinations. We also show that, due to the use of\niterative variational inference, our system is able to learn multi-modal\nposteriors for ambiguous inputs and extends naturally to sequences.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 18:21:02 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 23:21:01 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 19:55:14 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Greff", "Klaus", ""], ["Kaufman", "Rapha\u00ebl Lopez", ""], ["Kabra", "Rishabh", ""], ["Watters", "Nick", ""], ["Burgess", "Chris", ""], ["Zoran", "Daniel", ""], ["Matthey", "Loic", ""], ["Botvinick", "Matthew", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1903.00516", "submitter": "Stanislav Borysov S", "authors": "Stanislav S. Borysov, Jeppe Rich", "title": "Introducing Super Pseudo Panels: Application to Transport Preference\n  Dynamics", "comments": "22 pages, 10 figures, 5 tables", "journal-ref": null, "doi": "10.1007/s11116-020-10137-5", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for constructing synthetic pseudo-panel data from\ncross-sectional data. The pseudo panel and the preferences it intends to\ndescribe is constructed at the individual level and is not affected by\naggregation bias across cohorts. This is accomplished by creating a\nhigh-dimensional probabilistic model representation of the entire data set,\nwhich allows sampling from the probabilistic model in such a way that all of\nthe intrinsic correlation properties of the original data are preserved. The\nkey to this is the use of deep learning algorithms based on the Conditional\nVariational Autoencoder (CVAE) framework. From a modelling perspective, the\nconcept of a model-based resampling creates a number of opportunities in that\ndata can be organized and constructed to serve very specific needs of which the\nforming of heterogeneous pseudo panels represents one. The advantage, in that\nrespect, is the ability to trade a serious aggregation bias (when aggregating\ninto cohorts) for an unsystematic noise disturbance. Moreover, the approach\nmakes it possible to explore high-dimensional sparse preference distributions\nand their linkage to individual specific characteristics, which is not possible\nif applying traditional pseudo-panel methods. We use the presented approach to\nreveal the dynamics of transport preferences for a fixed pseudo panel of\nindividuals based on a large Danish cross-sectional data set covering the\nperiod from 2006 to 2016. The model is also utilized to classify individuals\ninto 'slow' and 'fast' movers with respect to the speed at which their\npreferences change over time. It is found that the prototypical fast mover is a\nyoung woman who lives as a single in a large city whereas the typical slow\nmover is a middle-aged man with high income from a nuclear family who lives in\na detached house outside a city.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 19:58:23 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Borysov", "Stanislav S.", ""], ["Rich", "Jeppe", ""]]}, {"id": "1903.00519", "submitter": "Laura Rieger", "authors": "Laura Rieger and Lars Kai Hansen", "title": "Aggregating explanation methods for stable and robust explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a growing literature on explaining neural networks, no consensus has\nbeen reached on how to explain a neural network decision or how to evaluate an\nexplanation. Our contributions in this paper are twofold. First, we investigate\nschemes to combine explanation methods and reduce model uncertainty to obtain a\nsingle aggregated explanation. We provide evidence that the aggregation is\nbetter at identifying important features, than on individual methods.\nAdversarial attacks on explanations is a recent active research topic. As our\nsecond contribution, we present evidence that aggregate explanations are much\nmore robust to attacks than individual explanation methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 20:11:06 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 12:41:00 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 21:41:23 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 12:51:36 GMT"}, {"version": "v5", "created": "Fri, 20 Mar 2020 08:52:24 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Rieger", "Laura", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1903.00534", "submitter": "Anna Ritz", "authors": "Marika Swanberg, Ira Globus-Harris, Iris Griffith, Anna Ritz, Adam\n  Groce, and Andrew Bray", "title": "Improved Differentially Private Analysis of Variance", "comments": "Proceedings of the 19th Privacy Enhancing Technologies Symposium\n  (PETS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing is one of the most common types of data analysis and forms\nthe backbone of scientific research in many disciplines. Analysis of variance\n(ANOVA) in particular is used to detect dependence between a categorical and a\nnumerical variable. Here we show how one can carry out this hypothesis test\nunder the restrictions of differential privacy. We show that the $F$-statistic,\nthe optimal test statistic in the public setting, is no longer optimal in the\nprivate setting, and we develop a new test statistic $F_1$ with much higher\nstatistical power. We show how to rigorously compute a reference distribution\nfor the $F_1$ statistic and give an algorithm that outputs accurate $p$-values.\nWe implement our test and experimentally optimize several parameters. We then\ncompare our test to the only previous work on private ANOVA testing, using the\nsame effect size as that work. We see an order of magnitude improvement, with\nour test requiring only 7% as much data to detect the effect.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 20:39:21 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Swanberg", "Marika", ""], ["Globus-Harris", "Ira", ""], ["Griffith", "Iris", ""], ["Ritz", "Anna", ""], ["Groce", "Adam", ""], ["Bray", "Andrew", ""]]}, {"id": "1903.00543", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Combinatorial Bandits with Relative Feedback", "comments": "47 pages, 12 fgures", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider combinatorial online learning with subset choices when only\nrelative feedback information from subsets is available, instead of bandit or\nsemi-bandit feedback which is absolute. Specifically, we study two regret\nminimisation problems over subsets of a finite ground set $[n]$, with\nsubset-wise relative preference information feedback according to the\nMultinomial logit choice model. In the first setting, the learner can play\nsubsets of size bounded by a maximum size and receives top-$m$ rank-ordered\nfeedback, while in the second setting the learner can play subsets of a fixed\nsize $k$ with a full subset ranking observed as feedback. For both settings, we\ndevise instance-dependent and order-optimal regret algorithms with regret\n$O(\\frac{n}{m} \\ln T)$ and $O(\\frac{n}{k} \\ln T)$, respectively. We derive\nfundamental limits on the regret performance of online learning with\nsubset-wise preferences, proving the tightness of our regret guarantees. Our\nresults also show the value of eliciting more general top-$m$ rank-ordered\nfeedback over single winner feedback ($m=1$). Our theoretical results are\ncorroborated with empirical evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 21:25:22 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 21:11:57 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1903.00558", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce\n  Model", "comments": "56 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider PAC-learning a good item from $k$-subsetwise feedback information\nsampled from a Plackett-Luce probability model, with instance-dependent sample\ncomplexity performance. In the setting where subsets of a fixed size can be\ntested and top-ranked feedback is made available to the learner, we give an\nalgorithm with optimal instance-dependent sample complexity, for PAC best arm\nidentification, of $O\\bigg(\\frac{\\theta_{[k]}}{k}\\sum_{i =\n2}^n\\max\\Big(1,\\frac{1}{\\Delta_i^2}\\Big) \\ln\\frac{k}{\\delta}\\Big(\\ln\n\\frac{1}{\\Delta_i}\\Big)\\bigg)$, $\\Delta_i$ being the Plackett-Luce parameter\ngap between the best and the $i^{th}$ best item, and $\\theta_{[k]}$ is the sum\nof the \\pl\\, parameters for the top-$k$ items. The algorithm is based on a\nwrapper around a PAC winner-finding algorithm with weaker performance\nguarantees to adapt to the hardness of the input instance. The sample\ncomplexity is also shown to be multiplicatively better depending on the length\nof rank-ordered feedback available in each subset-wise play. We show optimality\nof our algorithms with matching sample complexity lower bounds. We next address\nthe winner-finding problem in Plackett-Luce models in the fixed-budget setting\nwith instance dependent upper and lower bounds on the misidentification\nprobability, of $\\Omega\\left(\\exp(-2 \\tilde \\Delta Q) \\right)$ for a given\nbudget $Q$, where $\\tilde \\Delta$ is an explicit instance-dependent problem\ncomplexity parameter. Numerical performance results are also reported.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 22:12:10 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 23:29:46 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1903.00562", "submitter": "Shubhra Kanti Karmaker Santu", "authors": "Shubhra Kanti Karmaker Santu, Liangda Li, Yi Chang, ChengXiang Zhai", "title": "JIM: Joint Influence Modeling for Collective Search Behavior", "comments": null, "journal-ref": null, "doi": "10.1145/3269206.3271681", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that popular trending events are important external\nfactors which pose significant influence on user search behavior and also\nprovided a way to computationally model this influence. However, their problem\nformulation was based on the strong assumption that each event poses its\ninfluence independently. This assumption is unrealistic as there are many\ncorrelated events in the real world which influence each other and thus, would\npose a joint influence on the user search behavior rather than posing influence\nindependently. In this paper, we study this novel problem of Modeling the Joint\nInfluences posed by multiple correlated events on user search behavior. We\npropose a Joint Influence Model based on the Multivariate Hawkes Process which\ncaptures the inter-dependency among multiple events in terms of their influence\nupon user search behavior. We evaluate the proposed Joint Influence Model using\ntwo months query-log data from https://search.yahoo.com/. Experimental results\nshow that the model can indeed capture the temporal dynamics of the joint\ninfluence over time and also achieves superior performance over different\nbaseline methods when applied to solve various interesting prediction problems\nas well as real-word application scenarios, e.g., query auto-completion.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 22:20:47 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Santu", "Shubhra Kanti Karmaker", ""], ["Li", "Liangda", ""], ["Chang", "Yi", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "1903.00585", "submitter": "Uiwon Hwang", "authors": "Uiwon Hwang, Jaewoo Park, Hyemi Jang, Sungroh Yoon, Nam Ik Cho", "title": "PuVAE: A Variational Autoencoder to Purify Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used and exhibit excellent performance in\nmany areas. However, they are vulnerable to adversarial attacks that compromise\nthe network at the inference time by applying elaborately designed perturbation\nto input data. Although several defense methods have been proposed to address\nspecific attacks, other attack methods can circumvent these defense mechanisms.\nTherefore, we propose Purifying Variational Autoencoder (PuVAE), a method to\npurify adversarial examples. The proposed method eliminates an adversarial\nperturbation by projecting an adversarial example on the manifold of each\nclass, and determines the closest projection as a purified sample. We\nexperimentally illustrate the robustness of PuVAE against various attack\nmethods without any prior knowledge. In our experiments, the proposed method\nexhibits performances competitive with state-of-the-art defense methods, and\nthe inference time is approximately 130 times faster than that of Defense-GAN\nthat is the state-of-the art purifier model.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 00:38:38 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Hwang", "Uiwon", ""], ["Park", "Jaewoo", ""], ["Jang", "Hyemi", ""], ["Yoon", "Sungroh", ""], ["Cho", "Nam Ik", ""]]}, {"id": "1903.00614", "submitter": "Azade Nazi", "authors": "Azade Nazi, Will Hang, Anna Goldie, Sujith Ravi, Azalia Mirhoseini", "title": "GAP: Generalizable Approximate Graph Partitioning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph partitioning is the problem of dividing the nodes of a graph into\nbalanced partitions while minimizing the edge cut across the partitions. Due to\nits combinatorial nature, many approximate solutions have been developed,\nincluding variants of multi-level methods and spectral clustering. We propose\nGAP, a Generalizable Approximate Partitioning framework that takes a deep\nlearning approach to graph partitioning. We define a differentiable loss\nfunction that represents the partitioning objective and use backpropagation to\noptimize the network parameters. Unlike baselines that redo the optimization\nper graph, GAP is capable of generalization, allowing us to train models that\nproduce performant partitions at inference time, even on unseen graphs.\nFurthermore, because we learn the representation of the graph while jointly\noptimizing for the partitioning loss function, GAP can be easily tuned for a\nvariety of graph structures. We evaluate the performance of GAP on graphs of\nvarying sizes and structures, including graphs of widely used machine learning\nmodels (e.g., ResNet, VGG, and Inception-V3), scale-free graphs, and random\ngraphs. We show that GAP achieves competitive partitions while being up to 100\ntimes faster than the baseline and generalizes to unseen graphs.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 03:06:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Nazi", "Azade", ""], ["Hang", "Will", ""], ["Goldie", "Anna", ""], ["Ravi", "Sujith", ""], ["Mirhoseini", "Azalia", ""]]}, {"id": "1903.00617", "submitter": "Reza Hajargasht", "authors": "Reza Hajargasht", "title": "Approximation Properties of Variational Bayes for Vector Autoregressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayes (VB) is a recent approximate method for Bayesian inference.\nIt has the merit of being a fast and scalable alternative to Markov Chain Monte\nCarlo (MCMC) but its approximation error is often unknown. In this paper, we\nderive the approximation error of VB in terms of mean, mode, variance,\npredictive density and KL divergence for the linear Gaussian multi-equation\nregression. Our results indicate that VB approximates the posterior mean\nperfectly. Factors affecting the magnitude of underestimation in posterior\nvariance and mode are revealed. Importantly, We demonstrate that VB estimates\npredictive densities accurately.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 03:24:16 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Hajargasht", "Reza", ""]]}, {"id": "1903.00637", "submitter": "Menglei Hu", "authors": "Menglei Hu, Songcan Chen", "title": "One-Pass Incomplete Multi-view Clustering", "comments": "9 pages, published in the AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real data are often with multiple modalities or from multiple heterogeneous\nsources, thus forming so-called multi-view data, which receives more and more\nattentions in machine learning. Multi-view clustering (MVC) becomes its\nimportant paradigm. In real-world applications, some views often suffer from\ninstances missing. Clustering on such multi-view datasets is called incomplete\nmulti-view clustering (IMC) and quite challenging. To date, though many\napproaches have been developed, most of them are offline and have high\ncomputational and memory costs especially for large scale datasets. To address\nthis problem, in this paper, we propose an One-Pass Incomplete Multi-view\nClustering framework (OPIMC). With the help of regularized matrix factorization\nand weighted matrix factorization, OPIMC can relatively easily deal with such\nproblem. Different from the existing and sole online IMC method, OPIMC can\ndirectly get clustering results and effectively determine the termination of\niteration process by introducing two global statistics. Finally, extensive\nexperiments conducted on four real datasets demonstrate the efficiency and\neffectiveness of the proposed OPIMC method.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 06:16:40 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Hu", "Menglei", ""], ["Chen", "Songcan", ""]]}, {"id": "1903.00667", "submitter": "Giulia Luise", "authors": "Giulia Luise, Dimitris Stamos, Massimiliano Pontil, Carlo Ciliberto", "title": "Leveraging Low-Rank Relations Between Surrogate Tasks in Structured\n  Prediction", "comments": "42 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interplay between surrogate methods for structured prediction\nand techniques from multitask learning designed to leverage relationships\nbetween surrogate outputs. We propose an efficient algorithm based on trace\nnorm regularization which, differently from previous methods, does not require\nexplicit knowledge of the coding/decoding functions of the surrogate framework.\nAs a result, our algorithm can be applied to the broad class of problems in\nwhich the surrogate space is large or even infinite dimensional. We study\nexcess risk bounds for trace norm regularized structured prediction, implying\nthe consistency and learning rates for our estimator. We also identify relevant\nregimes in which our approach can enjoy better generalization performance than\nprevious methods. Numerical experiments on ranking problems indicate that\nenforcing low-rank relations among surrogate outputs may indeed provide a\nsignificant advantage in practice.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 09:47:56 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Luise", "Giulia", ""], ["Stamos", "Dimitris", ""], ["Pontil", "Massimiliano", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "1903.00687", "submitter": "Michael Unser", "authors": "Michael Unser", "title": "A unifying representer theorem for inverse problems and machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard approach for dealing with the ill-posedness of the training\nproblem in machine learning and/or the reconstruction of a signal from a\nlimited number of measurements is regularization. The method is applicable\nwhenever the problem is formulated as an optimization task. The standard\nstrategy consists in augmenting the original cost functional by an energy that\npenalizes solutions with undesirable behavior. The effect of regularization is\nvery well understood when the penalty involves a Hilbertian norm. Another\npopular configuration is the use of an $\\ell_1$-norm (or some variant thereof)\nthat favors sparse solutions. In this paper, we propose a higher-level\nformulation of regularization within the context of Banach spaces. We present a\ngeneral representer theorem that characterizes the solutions of a remarkably\nbroad class of optimization problems. We then use our theorem to retrieve a\nnumber of known results in the literature---e.g., the celebrated representer\ntheorem of machine leaning for RKHS, Tikhonov regularization, representer\ntheorems for sparsity promoting functionals, the recovery of spikes---as well\nas a few new ones.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 12:01:04 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 17:21:52 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 07:57:48 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Unser", "Michael", ""]]}, {"id": "1903.00702", "submitter": "Fei Wen", "authors": "Fei Wen, Rendong Ying, Peilin Liu, Trieu-Kien Truong", "title": "Matrix Completion via Nonconvex Regularization: Convergence of the\n  Proximal Gradient Algorithm", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion has attracted much interest in the past decade in machine\nlearning and computer vision. For low-rank promotion in matrix completion, the\nnuclear norm penalty is convenient due to its convexity but has a bias problem.\nRecently, various algorithms using nonconvex penalties have been proposed,\namong which the proximal gradient descent (PGD) algorithm is one of the most\nefficient and effective. For the nonconvex PGD algorithm, whether it converges\nto a local minimizer and its convergence rate are still unclear. This work\nprovides a nontrivial analysis on the PGD algorithm in the nonconvex case.\nBesides the convergence to a stationary point for a generalized nonconvex\npenalty, we provide more deep analysis on a popular and important class of\nnonconvex penalties which have discontinuous thresholding functions. For such\npenalties, we establish the finite rank convergence, convergence to restricted\nstrictly local minimizer and eventually linear convergence rate of the PGD\nalgorithm. Meanwhile, convergence to a local minimizer has been proved for the\nhard-thresholding penalty. Our result is the first shows that, nonconvex\nregularized matrix completion only has restricted strictly local minimizers,\nand the PGD algorithm can converge to such minimizers with eventually linear\nrate under certain conditions. Illustration of the PGD algorithm via\nexperiments has also been provided. Code is available at\nhttps://github.com/FWen/nmc.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 13:29:39 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Wen", "Fei", ""], ["Ying", "Rendong", ""], ["Liu", "Peilin", ""], ["Truong", "Trieu-Kien", ""]]}, {"id": "1903.00711", "submitter": "Nirmit Desai", "authors": "Nirmit Desai and Linsong Chu and Raghu K. Ganti and Sebastian Stein\n  and Mudhakar Srivatsa", "title": "neuralRank: Searching and ranking ANN-based model repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread applications of deep learning have led to a plethora of\npre-trained neural network models for common tasks. Such models are often\nadapted from other models via transfer learning. The models may have varying\ntraining sets, training algorithms, network architectures, and\nhyper-parameters. For a given application, what isthe most suitable model in a\nmodel repository? This is a critical question for practical deployments but it\nhas not received much attention. This paper introduces the novel problem of\nsearching and ranking models based on suitability relative to a target dataset\nand proposes a ranking algorithm called \\textit{neuralRank}. The key idea\nbehind this algorithm is to base model suitability on the discriminating power\nof a model, using a novel metric to measure it. With experimental results on\nthe MNIST, Fashion, and CIFAR10 datasets, we demonstrate that (1) neuralRank is\nindependent of the domain, the training set, or the network architecture and\n(2) that the models ranked highly by neuralRank ranking tend to have higher\nmodel accuracy in practice.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 14:45:41 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Desai", "Nirmit", ""], ["Chu", "Linsong", ""], ["Ganti", "Raghu K.", ""], ["Stein", "Sebastian", ""], ["Srivatsa", "Mudhakar", ""]]}, {"id": "1903.00715", "submitter": "Yang Yu", "authors": "Ruo-Ze Liu, Haifeng Guo, Xiaozhong Ji, Yang Yu, Zhen-Jia Pang, Zitai\n  Xiao, Yuzhou Wu, Tong Lu", "title": "Efficient Reinforcement Learning for StarCraft by Abstract Forward\n  Models and Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Injecting human knowledge is an effective way to accelerate reinforcement\nlearning (RL). However, these methods are underexplored. This paper presents\nour discovery that an abstract forward model (Thought-game (TG)) combined with\ntransfer learning is an effective way. We take StarCraft II as the study\nenvironment. With the help of a designed TG, the agent can learn a 99\\%\nwin-rate on a 64$\\times$64 map against the Level-7 built-in AI, using only 1.08\nhours in a single commercial machine. We also show that the TG method is not as\nrestrictive as it was thought to be. It can work with roughly designed TGs, and\ncan also be useful when the environment changes. Comparing with previous\nmodel-based RL, we show TG is more effective. We also present a TG hypothesis\nthat gives the influence of fidelity levels of TG. For real games that have\nunequal state and action spaces, we proposed a novel XfrNet of which usefulness\nis validated while achieving a 90\\% win-rate against the cheating Level-10 AI.\nWe argue the TG method might shed light on further studies of efficient RL with\nhuman knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:02:03 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 05:30:22 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 19:53:22 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Liu", "Ruo-Ze", ""], ["Guo", "Haifeng", ""], ["Ji", "Xiaozhong", ""], ["Yu", "Yang", ""], ["Pang", "Zhen-Jia", ""], ["Xiao", "Zitai", ""], ["Wu", "Yuzhou", ""], ["Lu", "Tong", ""]]}, {"id": "1903.00719", "submitter": "Lukas Pfannschmidt", "authors": "Lukas Pfannschmidt, Christina G\\\"opfert, Ursula Neumann, Dominik\n  Heider, Barbara Hammer", "title": "FRI -- Feature Relevance Intervals for Interpretable and Interactive\n  Data Exploration", "comments": "Addition of IEEE copyright notice. Accepted for CIBCB 2019\n  (https://cibcb2019.icas.xyz/)", "journal-ref": null, "doi": "10.1109/CIBCB.2019.8791489", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing feature selection methods are insufficient for analytic\npurposes as soon as high dimensional data or redundant sensor signals are dealt\nwith since features can be selected due to spurious effects or correlations\nrather than causal effects. To support the finding of causal features in\nbiomedical experiments, we hereby present FRI, an open source Python library\nthat can be used to identify all-relevant variables in linear classification\nand (ordinal) regression problems. Using the recently proposed feature\nrelevance method, FRI is able to provide the base for further general\nexperimentation or in specific can facilitate the search for alternative\nbiomarkers. It can be used in an interactive context, by providing model\nmanipulation and visualization methods, or in a batch process as a filter\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:16:15 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 17:21:03 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 14:41:04 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Pfannschmidt", "Lukas", ""], ["G\u00f6pfert", "Christina", ""], ["Neumann", "Ursula", ""], ["Heider", "Dominik", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.00725", "submitter": "Wenhao Yang", "authors": "Xiang Li, Wenhao Yang, Zhihua Zhang", "title": "A Regularized Approach to Sparse Optimal Policy in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a general framework for regularized Markov decision\nprocesses (MDPs) where the goal is to find an optimal policy that maximizes the\nexpected discounted total reward plus a policy regularization term. The extant\nentropy-regularized MDPs can be cast into our framework. Moreover, under our\nframework, many regularization terms can bring multi-modality and sparsity,\nwhich are potentially useful in reinforcement learning. In particular, we\npresent sufficient and necessary conditions that induce a sparse optimal\npolicy. We also conduct a full mathematical analysis of the proposed\nregularized MDPs, including the optimality condition, performance error, and\nsparseness control. We provide a generic method to devise regularization forms\nand propose off-policy actor critic algorithms in complex environment settings.\nWe empirically analyze the numerical properties of optimal policies and compare\nthe performance of different sparse regularization forms in discrete and\ncontinuous environments.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:34:25 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 03:50:50 GMT"}, {"version": "v3", "created": "Sun, 20 Oct 2019 15:28:06 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Li", "Xiang", ""], ["Yang", "Wenhao", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1903.00739", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Jianguo Yu, Ahmed H Tewfik", "title": "Speech Recognition with no speech or with noisy speech", "comments": "Accepted for ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition systems(ASR) degrades in the\npresence of noisy speech. This paper demonstrates that using\nelectroencephalography (EEG) can help automatic speech recognition systems\novercome performance loss in the presence of noise. The paper also shows that\ndistillation training of automatic speech recognition systems using EEG\nfeatures will increase their performance. Finally, we demonstrate the ability\nto recognize words from EEG with no speech signal on a limited English\nvocabulary with high accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 17:53:49 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Yu", "Jianguo", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1903.00743", "submitter": "Udayan Khurana", "authors": "Udayan Khurana and Horst Samulowitz", "title": "Automating Predictive Modeling Process using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a good predictive model requires an array of activities such as data\nimputation, feature transformations, estimator selection, hyper-parameter\nsearch and ensemble construction. Given the large, complex and heterogenous\nspace of options, off-the-shelf optimization methods are infeasible for\nrealistic response times. In practice, much of the predictive modeling process\nis conducted by experienced data scientists, who selectively make use of\navailable tools. Over time, they develop an understanding of the behavior of\noperators, and perform serial decision making under uncertainty, colloquially\nreferred to as educated guesswork. With an unprecedented demand for application\nof supervised machine learning, there is a call for solutions that\nautomatically search for a good combination of parameters across these tasks to\nminimize the modeling error. We introduce a novel system called APRL\n(Autonomous Predictive modeler via Reinforcement Learning), that uses past\nexperience through reinforcement learning to optimize such sequential decision\nmaking from within a set of diverse actions under a time constraint on a\npreviously unseen predictive learning problem. APRL actions are taken to\noptimize the performance of a final ensemble. This is in contrast to other\nsystems, which maximize individual model accuracy first and create ensembles as\na disconnected post-processing step. As a result, APRL is able to reduce up to\n71\\% of classification error on average over a wide variety of problems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 18:22:19 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Khurana", "Udayan", ""], ["Samulowitz", "Horst", ""]]}, {"id": "1903.00750", "submitter": "Sainyam Galhotra Mr", "authors": "Sainyam Galhotra, Sandhya Saisubramanian and Shlomo Zilberstein", "title": "Lexicographically Ordered Multi-Objective Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a rich model for multi-objective clustering with lexicographic\nordering over objectives and a slack. The slack denotes the allowed\nmultiplicative deviation from the optimal objective value of the higher\npriority objective to facilitate improvement in lower-priority objectives. We\nthen propose an algorithm called Zeus to solve this class of problems, which is\ncharacterized by a makeshift function. The makeshift fine tunes the clusters\nformed by the processed objectives so as to improve the clustering with respect\nto the unprocessed objectives, given the slack. We present makeshift for\nsolving three different classes of objectives and analyze their solution\nguarantees. Finally, we empirically demonstrate the effectiveness of our\napproach on three applications using real-world data.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 19:32:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1903.00755", "submitter": "Ziming Zhang", "authors": "Ziming Zhang, Anil Kag, Alan Sullivan, Venkatesh Saligrama", "title": "Equilibrated Recurrent Neural Network: Neuronal Time-Delayed\n  Self-Feedback Improves Accuracy and Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel {\\it Equilibrated Recurrent Neural Network} (ERNN) to\ncombat the issues of inaccuracy and instability in conventional RNNs. Drawing\nupon the concept of autapse in neuroscience, we propose augmenting an RNN with\na time-delayed self-feedback loop. Our sole purpose is to modify the dynamics\nof each internal RNN state and, at any time, enforce it to evolve close to the\nequilibrium point associated with the input signal at that time. We show that\nsuch self-feedback helps stabilize the hidden state transitions leading to fast\nconvergence during training while efficiently learning discriminative latent\nfeatures that result in state-of-the-art results on several benchmark datasets\nat test-time. We propose a novel inexact Newton method to solve fixed-point\nconditions given model parameters for generating the latent features at each\nhidden state. We prove that our inexact Newton method converges locally with\nlinear rate (under mild conditions). We leverage this result for efficient\ntraining of ERNNs based on backpropagation.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 20:01:44 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zhang", "Ziming", ""], ["Kag", "Anil", ""], ["Sullivan", "Alan", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1903.00757", "submitter": "Zhaocheng Zhu", "authors": "Zhaocheng Zhu, Shizhen Xu, Meng Qu, Jian Tang", "title": "GraphVite: A High-Performance CPU-GPU Hybrid System for Node Embedding", "comments": "accepted at WWW 2019", "journal-ref": null, "doi": "10.1145/3308558.3313508", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning continuous representations of nodes is attracting growing interest\nin both academia and industry recently, due to their simplicity and\neffectiveness in a variety of applications. Most of existing node embedding\nalgorithms and systems are capable of processing networks with hundreds of\nthousands or a few millions of nodes. However, how to scale them to networks\nthat have tens of millions or even hundreds of millions of nodes remains a\nchallenging problem. In this paper, we propose GraphVite, a high-performance\nCPU-GPU hybrid system for training node embeddings, by co-optimizing the\nalgorithm and the system. On the CPU end, augmented edge samples are parallelly\ngenerated by random walks in an online fashion on the network, and serve as the\ntraining data. On the GPU end, a novel parallel negative sampling is proposed\nto leverage multiple GPUs to train node embeddings simultaneously, without much\ndata transfer and synchronization. Moreover, an efficient collaboration\nstrategy is proposed to further reduce the synchronization cost between CPUs\nand GPUs. Experiments on multiple real-world networks show that GraphVite is\nsuper efficient. It takes only about one minute for a network with 1 million\nnodes and 5 million edges on a single machine with 4 GPUs, and takes around 20\nhours for a network with 66 million nodes and 1.8 billion edges. Compared to\nthe current fastest system, GraphVite is about 50 times faster without any\nsacrifice on performance.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 20:06:58 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zhu", "Zhaocheng", ""], ["Xu", "Shizhen", ""], ["Qu", "Meng", ""], ["Tang", "Jian", ""]]}, {"id": "1903.00760", "submitter": "Ziming Zhang", "authors": "Ziming Zhang, Wenju Xu, Alan Sullivan", "title": "Time-Delay Momentum: A Regularization Perspective on the Convergence and\n  Generalization of Stochastic Momentum for Deep Learning", "comments": "has errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of convergence and generalization error\nbound of stochastic momentum for deep learning from the perspective of\nregularization. To do so, we first interpret momentum as solving an\n$\\ell_2$-regularized minimization problem to learn the offsets between\narbitrary two successive model parameters. We call this {\\em time-delay\nmomentum} because the model parameter is updated after a few iterations towards\nfinding the minimizer. We then propose our learning algorithm, \\ie stochastic\ngradient descent (SGD) with time-delay momentum. We show that our algorithm can\nbe interpreted as solving a sequence of strongly convex optimization problems\nusing SGD. We prove that under mild conditions our algorithm can converge to a\nstationary point with rate of $O(\\frac{1}{\\sqrt{K}})$ and generalization error\nbound of $O(\\frac{1}{\\sqrt{n\\delta}})$ with probability at least $1-\\delta$,\nwhere $K,n$ are the numbers of model updates and training samples,\nrespectively. We demonstrate the empirical superiority of our algorithm in deep\nlearning in comparison with the state-of-the-art deep learning solvers.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 20:21:38 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 23:05:37 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Ziming", ""], ["Xu", "Wenju", ""], ["Sullivan", "Alan", ""]]}, {"id": "1903.00780", "submitter": "Alex Beutel", "authors": "Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Li Wei, Yi Wu, Lukasz\n  Heldt, Zhe Zhao, Lichan Hong, Ed H. Chi, Cristos Goodrow", "title": "Fairness in Recommendation Ranking through Pairwise Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are one of the most pervasive applications of machine\nlearning in industry, with many services using them to match users to products\nor information. As such it is important to ask: what are the possible fairness\nrisks, how can we quantify them, and how should we address them? In this paper\nwe offer a set of novel metrics for evaluating algorithmic fairness concerns in\nrecommender systems. In particular we show how measuring fairness based on\npairwise comparisons from randomized experiments provides a tractable means to\nreason about fairness in rankings from recommender systems. Building on this\nmetric, we offer a new regularizer to encourage improving this metric during\nmodel training and thus improve fairness in the resulting rankings. We apply\nthis pairwise regularization to a large-scale, production recommender system\nand show that we are able to significantly improve the system's pairwise\nfairness.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 22:29:42 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Beutel", "Alex", ""], ["Chen", "Jilin", ""], ["Doshi", "Tulsee", ""], ["Qian", "Hai", ""], ["Wei", "Li", ""], ["Wu", "Yi", ""], ["Heldt", "Lukasz", ""], ["Zhao", "Zhe", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""], ["Goodrow", "Cristos", ""]]}, {"id": "1903.00784", "submitter": "Joseph Suarez", "authors": "Joseph Suarez, Yilun Du, Phillip Isola, Igor Mordatch", "title": "Neural MMO: A Massively Multiagent Game Environment for Training and\n  Evaluating Intelligent Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of complex life on Earth is often attributed to the arms race\nthat ensued from a huge number of organisms all competing for finite resources.\nWe present an artificial intelligence research environment, inspired by the\nhuman game genre of MMORPGs (Massively Multiplayer Online Role-Playing Games,\na.k.a. MMOs), that aims to simulate this setting in microcosm. As with MMORPGs\nand the real world alike, our environment is persistent and supports a large\nand variable number of agents. Our environment is well suited to the study of\nlarge-scale multiagent interaction: it requires that agents learn robust combat\nand navigation policies in the presence of large populations attempting to do\nthe same. Baseline experiments reveal that population size magnifies and\nincentivizes the development of skillful behaviors and results in agents that\noutcompete agents trained in smaller populations. We further show that the\npolicies of agents with unshared weights naturally diverge to fill different\nniches in order to avoid competition.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 22:42:33 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Suarez", "Joseph", ""], ["Du", "Yilun", ""], ["Isola", "Phillip", ""], ["Mordatch", "Igor", ""]]}, {"id": "1903.00802", "submitter": "Aviral Kumar", "authors": "Aviral Kumar, Sunita Sarawagi", "title": "Calibration of Encoder Decoder Models for Neural Machine Translation", "comments": "12 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the calibration of several state of the art neural machine\ntranslation(NMT) systems built on attention-based encoder-decoder models. For\nstructured outputs like in NMT, calibration is important not just for reliable\nconfidence with predictions, but also for proper functioning of beam-search\ninference. We show that most modern NMT models are surprisingly miscalibrated\neven when conditioned on the true previous tokens. Our investigation leads to\ntwo main reasons -- severe miscalibration of EOS (end of sequence marker) and\nsuppression of attention uncertainty. We design recalibration methods based on\nthese signals and demonstrate improved accuracy, better sequence-level\ncalibration, and more intuitive results from beam-search.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 01:08:47 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Kumar", "Aviral", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1903.00816", "submitter": "Martin Pavlovski", "authors": "Nino Arsov, Martin Pavlovski, Ljupco Kocarev", "title": "Stability of decision trees and logistic regression", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees and logistic regression are one of the most popular and\nwell-known machine learning algorithms, frequently used to solve a variety of\nreal-world problems. Stability of learning algorithms is a powerful tool to\nanalyze their performance and sensitivity and subsequently allow researchers to\ndraw reliable conclusions. The stability of these two algorithms has remained\nobscure. To that end, in this paper, we derive two stability notions for\ndecision trees and logistic regression: hypothesis and pointwise hypothesis\nstability. Additionally, we derive these notions for L2-regularized logistic\nregression and confirm existing findings that it is uniformly stable. We show\nthat the stability of decision trees depends on the number of leaves in the\ntree, i.e., its depth, while for logistic regression, it depends on the\nsmallest eigenvalue of the Hessian matrix of the cross-entropy loss. We show\nthat logistic regression is not a stable learning algorithm. We construct the\nupper bounds on the generalization error of all three algorithms. Moreover, we\npresent a novel stability measuring framework that allows one to measure the\naforementioned notions of stability. The measures are equivalent to estimates\nof expected loss differences at an input example and then leverage bootstrap\nsampling to yield statistically reliable estimates. Finally, we apply this\nframework to the three algorithms analyzed in this paper to confirm our\ntheoretical findings and, in addition, we discuss the possibilities of\ndeveloping new training techniques to optimize the stability of logistic\nregression, and hence decrease its generalization error.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 03:38:54 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Arsov", "Nino", ""], ["Pavlovski", "Martin", ""], ["Kocarev", "Ljupco", ""]]}, {"id": "1903.00827", "submitter": "Zhizheng Zhang", "authors": "Zhizheng Zhang, Jiale Chen, Zhibo Chen, Weiping Li", "title": "Asynchronous Episodic Deep Deterministic Policy Gradient: Towards\n  Continuous Control in Computationally Complex Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Deterministic Policy Gradient (DDPG) has been proved to be a successful\nreinforcement learning (RL) algorithm for continuous control tasks. However,\nDDPG still suffers from data insufficiency and training inefficiency,\nespecially in computationally complex environments. In this paper, we propose\nAsynchronous Episodic DDPG (AE-DDPG), as an expansion of DDPG, which can\nachieve more effective learning with less training time required. First, we\ndesign a modified scheme for data collection in an asynchronous fashion.\nGenerally, for asynchronous RL algorithms, sample efficiency or/and training\nstability diminish as the degree of parallelism increases. We consider this\nproblem from the perspectives of both data generation and data utilization. In\ndetail, we re-design experience replay by introducing the idea of episodic\ncontrol so that the agent can latch on good trajectories rapidly. In addition,\nwe also inject a new type of noise in action space to enrich the exploration\nbehaviors. Experiments demonstrate that our AE-DDPG achieves higher rewards and\nrequires less time consuming than most popular RL algorithms in Learning to Run\ntask which has a computationally complex environment. Not limited to the\ncontrol tasks in computationally complex environments, AE-DDPG also achieves\nhigher rewards and 2- to 4-fold improvement in sample efficiency on average\ncompared to other variants of DDPG in MuJoCo environments. Furthermore, we\nverify the effectiveness of each proposed technique component through abundant\nablation study.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 04:26:32 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zhang", "Zhizheng", ""], ["Chen", "Jiale", ""], ["Chen", "Zhibo", ""], ["Li", "Weiping", ""]]}, {"id": "1903.00840", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Yao-Chong Lim, Paul Pu Liang, Louis-Philippe Morency", "title": "Variational Auto-Decoder: A Method for Neural Generative Modeling from\n  Incomplete Data", "comments": "Link to code and data available from\n  https://github.com/A2Zadeh/Variational-Autodecoder", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a generative model from partial data (data with missingness) is a\nchallenging area of machine learning research. We study a specific\nimplementation of the Auto-Encoding Variational Bayes (AEVB) algorithm, named\nin this paper as a Variational Auto-Decoder (VAD). VAD is a generic framework\nwhich uses Variational Bayes and Markov Chain Monte Carlo (MCMC) methods to\nlearn a generative model from partial data. The main distinction between VAD\nand Variational Auto-Encoder (VAE) is the encoder component, as VAD does not\nhave one. Using a proposed efficient inference method from a multivariate\nGaussian approximate posterior, VAD models allow inference to be performed via\nsimple gradient ascent rather than MCMC sampling from a probabilistic decoder.\nThis technique reduces the inference computational cost, allows for using more\ncomplex optimization techniques during latent space inference (which are shown\nto be crucial due to a high degree of freedom in the VAD latent space), and\nkeeps the framework simple to implement. Through extensive experiments over\nseveral datasets and different missing ratios, we show that encoders cannot\nefficiently marginalize the input volatility caused by imputed missing values.\nWe study multimodal datasets in this paper, which is a particular area of\nimpact for VAD models.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 06:19:55 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 02:47:29 GMT"}, {"version": "v3", "created": "Sun, 24 Mar 2019 00:39:41 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 21:04:05 GMT"}, {"version": "v5", "created": "Sun, 26 May 2019 13:45:51 GMT"}, {"version": "v6", "created": "Sun, 3 Jan 2021 08:27:20 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zadeh", "Amir", ""], ["Lim", "Yao-Chong", ""], ["Liang", "Paul Pu", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1903.00843", "submitter": "Xiang Liu", "authors": "Xiang Liu, Ziyang Tang, Huyunting Huang, Tonglin Zhang, Baijian Yang", "title": "Multiple Learning for Regression in big data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression problems that have closed-form solutions are well understood and\ncan be easily implemented when the dataset is small enough to be all loaded\ninto the RAM. Challenges arise when data is too big to be stored in RAM to\ncompute the closed form solutions. Many techniques were proposed to overcome or\nalleviate the memory barrier problem but the solutions are often local optimal.\nIn addition, most approaches require accessing the raw data again when updating\nthe models. Parallel computing clusters are also expected if multiple models\nneed to be computed simultaneously. We propose multiple learning approaches\nthat utilize an array of sufficient statistics (SS) to address this big data\nchallenge. This memory oblivious approach breaks the memory barrier when\ncomputing regressions with closed-form solutions, including but not limited to\nlinear regression, weighted linear regression, linear regression with Box-Cox\ntransformation (Box-Cox regression) and ridge regression models. The\ncomputation and update of the SS array can be handled at per row level or per\nmini-batch level. And updating a model is as easy as matrix addition and\nsubtraction. Furthermore, multiple SS arrays for different models can be easily\ncomputed simultaneously to obtain multiple models at one pass through the\ndataset. We implemented our approaches on Spark and evaluated over the\nsimulated datasets. Results showed our approaches can achieve closed-form\nsolutions of multiple models at the cost of half training time of the\ntraditional methods for a single model.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 06:34:24 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 00:39:30 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Liu", "Xiang", ""], ["Tang", "Ziyang", ""], ["Huang", "Huyunting", ""], ["Zhang", "Tonglin", ""], ["Yang", "Baijian", ""]]}, {"id": "1903.00863", "submitter": "Kelvin Hsu", "authors": "Kelvin Hsu and Fabio Ramos", "title": "Bayesian Learning of Conditional Kernel Mean Embeddings for Automatic\n  Likelihood-Free Inference", "comments": "To appear in the Proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In likelihood-free settings where likelihood evaluations are intractable,\napproximate Bayesian computation (ABC) addresses the formidable inference task\nto discover plausible parameters of simulation programs that explain the\nobservations. However, they demand large quantities of simulation calls.\nCritically, hyperparameters that determine measures of simulation discrepancy\ncrucially balance inference accuracy and sample efficiency, yet are difficult\nto tune. In this paper, we present kernel embedding likelihood-free inference\n(KELFI), a holistic framework that automatically learns model hyperparameters\nto improve inference accuracy given limited simulation budget. By leveraging\nlikelihood smoothness with conditional mean embeddings, we nonparametrically\napproximate likelihoods and posteriors as surrogate densities and sample from\nclosed-form posterior mean embeddings, whose hyperparameters are learned under\nits approximate marginal likelihood. Our modular framework demonstrates\nimproved accuracy and efficiency on challenging inference problems in ecology.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 09:02:55 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Hsu", "Kelvin", ""], ["Ramos", "Fabio", ""]]}, {"id": "1903.00904", "submitter": "Xuhong Wang", "authors": "Xuhong Wang, Ying Du, Shijie Lin, Ping Cui, Yuntian Shen and Yupu Yang", "title": "adVAE: A self-adversarial variational autoencoder with Gaussian anomaly\n  prior knowledge for anomaly detection", "comments": "This paper has been accepted by Knowledge-based Systems", "journal-ref": null, "doi": "10.1016/j.knosys.2019.105187", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep generative models have become increasingly popular in\nunsupervised anomaly detection. However, deep generative models aim at\nrecovering the data distribution rather than detecting anomalies. Besides, deep\ngenerative models have the risk of overfitting training samples, which has\ndisastrous effects on anomaly detection performance. To solve the above two\nproblems, we propose a Self-adversarial Variational Autoencoder with a Gaussian\nanomaly prior assumption. We assume that both the anomalous and the normal\nprior distribution are Gaussian and have overlaps in the latent space.\nTherefore, a Gaussian transformer net T is trained to synthesize anomalous but\nnear-normal latent variables. Keeping the original training objective of\nVariational Autoencoder, besides, the generator G tries to distinguish between\nthe normal latent variables and the anomalous ones synthesized by T, and the\nencoder E is trained to discriminate whether the output of G is real. These new\nobjectives we added not only give both G and E the ability to discriminate but\nalso introduce additional regularization to prevent overfitting. Compared with\nthe SOTA baselines, the proposed model achieves significant improvements in\nextensive experiments. Datasets and our model are available at a Github\nrepository.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 13:26:19 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 03:37:40 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 12:20:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Wang", "Xuhong", ""], ["Du", "Ying", ""], ["Lin", "Shijie", ""], ["Cui", "Ping", ""], ["Shen", "Yuntian", ""], ["Yang", "Yupu", ""]]}, {"id": "1903.00906", "submitter": "Bokang Zhu", "authors": "Bokang Zhu, Richong Zhang, Dingkun Long and Yongyi Mao", "title": "Understanding Feature Selection and Feature Memorization in Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a test, called Flagged-1-Bit (F1B) test, to study\nthe intrinsic capability of recurrent neural networks in sequence learning.\nFour different recurrent network models are studied both analytically and\nexperimentally using this test. Our results suggest that in general there\nexists a conflict between feature selection and feature memorization in\nsequence learning. Such a conflict can be resolved either using a gating\nmechanism as in LSTM, or by increasing the state dimension as in Vanilla RNN.\nGated models resolve this conflict by adaptively adjusting their state-update\nequations, whereas Vanilla RNN resolves this conflict by assigning different\ndimensions different tasks. Insights into feature selection and memorization in\nrecurrent networks are given.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 13:29:33 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zhu", "Bokang", ""], ["Zhang", "Richong", ""], ["Long", "Dingkun", ""], ["Mao", "Yongyi", ""]]}, {"id": "1903.00919", "submitter": "Bing Yu", "authors": "Bing Yu, Mengzhang Li, Jiyong Zhang, Zhanxing Zhu", "title": "3D Graph Convolutional Networks with Temporal Graphs: A Spatial\n  Information Free Framework For Traffic Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal prediction plays an important role in many application areas\nespecially in traffic domain. However, due to complicated spatio-temporal\ndependency and high non-linear dynamics in road networks, traffic prediction\ntask is still challenging. Existing works either exhibit heavy training cost or\nfail to accurately capture the spatio-temporal patterns, also ignore the\ncorrelation between distant roads that share the similar patterns. In this\npaper, we propose a novel deep learning framework to overcome these issues: 3D\nTemporal Graph Convolutional Networks (3D-TGCN). Two novel components of our\nmodel are introduced. (1) Instead of constructing the road graph based on\nspatial information, we learn it by comparing the similarity between time\nseries for each road, thus providing a spatial information free framework. (2)\nWe propose an original 3D graph convolution model to model the spatio-temporal\ndata more accurately. Empirical results show that 3D-TGCN could outperform\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 14:44:07 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Yu", "Bing", ""], ["Li", "Mengzhang", ""], ["Zhang", "Jiyong", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1903.00925", "submitter": "Jasmine Collins", "authors": "Jasmine Collins and Johannes Balle and Jonathon Shlens", "title": "Accelerating Training of Deep Neural Networks with a Standardization\n  Loss", "comments": "Technical report. Results presented at WiML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant advance in accelerating neural network training has been the\ndevelopment of normalization methods, permitting the training of deep models\nboth faster and with better accuracy. These advances come with practical\nchallenges: for instance, batch normalization ties the prediction of individual\nexamples with other examples within a batch, resulting in a network that is\nheavily dependent on batch size. Layer normalization and group normalization\nare data-dependent and thus must be continually used, even at test-time. To\naddress the issues that arise from using explicit normalization techniques, we\npropose to replace existing normalization methods with a simple, secondary\nobjective loss that we term a standardization loss. This formulation is\nflexible and robust across different batch sizes and surprisingly, this\nsecondary objective accelerates learning on the primary training objective.\nBecause it is a training loss, it is simply removed at test-time, and no\nfurther effort is needed to maintain normalized activations. We find that a\nstandardization loss accelerates training on both small- and large-scale image\nclassification experiments, works with a variety of architectures, and is\nlargely robust to training across different batch sizes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 15:17:06 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Collins", "Jasmine", ""], ["Balle", "Johannes", ""], ["Shlens", "Jonathon", ""]]}, {"id": "1903.00939", "submitter": "Sebastian Schmon", "authors": "Sebastian M Schmon, Arnaud Doucet, George Deligiannidis", "title": "Bernoulli Race Particle Filters", "comments": "19 pages", "journal-ref": "The 22nd International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2019)", "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the weights in a particle filter are not available analytically,\nstandard resampling methods cannot be employed. To circumvent this problem\nstate-of-the-art algorithms replace the true weights with non-negative unbiased\nestimates. This algorithm is still valid but at the cost of higher variance of\nthe resulting filtering estimates in comparison to a particle filter using the\ntrue weights. We propose here a novel algorithm that allows for resampling\naccording to the true intractable weights when only an unbiased estimator of\nthe weights is available. We demonstrate our algorithm on several examples.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 16:49:53 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Schmon", "Sebastian M", ""], ["Doucet", "Arnaud", ""], ["Deligiannidis", "George", ""]]}, {"id": "1903.00954", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss, Fabio Ferreira, Simon Walther, Maxim Ulrich", "title": "Conditional Density Estimation with Neural Networks: Best Practices and\n  Benchmarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.CP q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a set of empirical observations, conditional density estimation aims to\ncapture the statistical relationship between a conditional variable\n$\\mathbf{x}$ and a dependent variable $\\mathbf{y}$ by modeling their\nconditional probability $p(\\mathbf{y}|\\mathbf{x})$. The paper develops best\npractices for conditional density estimation for finance applications with\nneural networks, grounded on mathematical insights and empirical evaluations.\nIn particular, we introduce a noise regularization and data normalization\nscheme, alleviating problems with over-fitting, initialization and\nhyper-parameter sensitivity of such estimators. We compare our proposed\nmethodology with popular semi- and non-parametric density estimators, underpin\nits effectiveness in various benchmarks on simulated and Euro Stoxx 50 data and\nshow its superior performance. Our methodology allows to obtain high-quality\nestimators for statistical expectations of higher moments, quantiles and\nnon-linear return transformations, with very little assumptions about the\nreturn dynamic.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 18:15:20 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 11:20:14 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Ferreira", "Fabio", ""], ["Walther", "Simon", ""], ["Ulrich", "Maxim", ""]]}, {"id": "1903.00974", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky", "title": "Anytime Online-to-Batch Conversions, Optimism, and Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard way to obtain convergence guarantees in stochastic convex\noptimization is to run an online learning algorithm and then output the average\nof its iterates: the actual iterates of the online learning algorithm do not\ncome with individual guarantees. We close this gap by introducing a black-box\nmodification to any online learning algorithm whose iterates converge to the\noptimum in stochastic scenarios. We then consider the case of smooth losses,\nand show that combining our approach with optimistic online learning algorithms\nimmediately yields a fast convergence rate of $O(L/T^{3/2}+\\sigma/\\sqrt{T})$ on\n$L$-smooth problems with $\\sigma^2$ variance in the gradients. Finally, we\nprovide a reduction that converts any adaptive online algorithm into one that\nobtains the optimal accelerated rate of $\\tilde O(L/T^2 + \\sigma/\\sqrt{T})$,\nwhile still maintaining $\\tilde O(1/\\sqrt{T})$ convergence in the non-smooth\nsetting. Importantly, our algorithms adapt to $L$ and $\\sigma$ automatically:\nthey do not need to know either to obtain these rates.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 19:56:32 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Cutkosky", "Ashok", ""]]}, {"id": "1903.00979", "submitter": "Sarthak Chatterjee", "authors": "Sarthak Chatterjee, Orlando Romero, S\\'ergio Pequito", "title": "Analysis of a Generalized Expectation-Maximization Algorithm for\n  Gaussian Mixture Models: A Control Systems Perspective", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm is one of the most popular\nmethods used to solve the problem of parametric distribution-based clustering\nin unsupervised learning. In this paper, we propose to analyze a generalized EM\n(GEM) algorithm in the context of Gaussian mixture models, where the\nmaximization step in the EM is replaced by an increasing step. We show that\nthis GEM algorithm can be understood as a linear time-invariant (LTI) system\nwith a feedback nonlinearity. Therefore, we explore some of its convergence\nproperties by leveraging tools from robust control theory. Lastly, we explain\nhow the proposed GEM can be designed, and present a pedagogical example to\nunderstand the advantages of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 20:09:39 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 17:48:29 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 22:37:00 GMT"}, {"version": "v4", "created": "Tue, 18 May 2021 04:46:31 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Chatterjee", "Sarthak", ""], ["Romero", "Orlando", ""], ["Pequito", "S\u00e9rgio", ""]]}, {"id": "1903.00985", "submitter": "Didong Li", "authors": "Didong Li and David B Dunson", "title": "Classification via local manifold approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers label data as belonging to one of a set of groups based on input\nfeatures. It is challenging to obtain accurate classification performance when\nthe feature distributions in the different classes are complex, with nonlinear,\noverlapping and intersecting supports. This is particularly true when training\ndata are limited. To address this problem, this article proposes a new type of\nclassifier based on obtaining a local approximation to the support of the data\nwithin each class in a neighborhood of the feature to be classified, and\nassigning the feature to the class having the closest support. This general\nalgorithm is referred to as LOcal Manifold Approximation (LOMA) classification.\nAs a simple and theoretically supported special case having excellent\nperformance in a broad variety of examples, we use spheres for local\napproximation, obtaining a SPherical Approximation (SPA) classifier. We\nillustrate substantial gains for SPA over competitors on a variety of\nchallenging simulated and real data examples.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 20:54:47 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Li", "Didong", ""], ["Dunson", "David B", ""]]}, {"id": "1903.01004", "submitter": "Edouard Leurent", "authors": "Nicolas Carrara, Edouard Leurent, Romain Laroche, Tanguy Urvoy,\n  Odalric-Ambrym Maillard, Olivier Pietquin", "title": "Budgeted Reinforcement Learning in Continuous State Space", "comments": "N. Carrara and E. Leurent have equally contributed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Budgeted Markov Decision Process (BMDP) is an extension of a Markov\nDecision Process to critical applications requiring safety constraints. It\nrelies on a notion of risk implemented in the shape of a cost signal\nconstrained to lie below an - adjustable - threshold. So far, BMDPs could only\nbe solved in the case of finite state spaces with known dynamics. This work\nextends the state-of-the-art to continuous spaces environments and unknown\ndynamics. We show that the solution to a BMDP is a fixed point of a novel\nBudgeted Bellman Optimality operator. This observation allows us to introduce\nnatural extensions of Deep Reinforcement Learning algorithms to address\nlarge-scale BMDPs. We validate our approach on two simulated applications:\nspoken dialogue and autonomous driving.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 22:24:01 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 17:37:51 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 21:50:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Carrara", "Nicolas", ""], ["Leurent", "Edouard", ""], ["Laroche", "Romain", ""], ["Urvoy", "Tanguy", ""], ["Maillard", "Odalric-Ambrym", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1903.01026", "submitter": "Hossein Aboutalebi", "authors": "Hossein Aboutalebi, Doina Precup, Tibor Schuster", "title": "Learning Modular Safe Policies in the Bandit Setting with Application to\n  Adaptive Clinical Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic multi-armed bandit problem is a well-known model for studying\nthe exploration-exploitation trade-off. It has significant possible\napplications in adaptive clinical trials, which allow for dynamic changes in\nthe treatment allocation probabilities of patients. However, most bandit\nlearning algorithms are designed with the goal of minimizing the expected\nregret. While this approach is useful in many areas, in clinical trials, it can\nbe sensitive to outlier data, especially when the sample size is small. In this\npaper, we define and study a new robustness criterion for bandit problems.\nSpecifically, we consider optimizing a function of the distribution of returns\nas a regret measure. This provides practitioners more flexibility to define an\nappropriate regret measure. The learning algorithm we propose to solve this\ntype of problem is a modification of the BESA algorithm [Baransi et al., 2014],\nwhich considers a more general version of regret. We present a regret bound for\nour approach and evaluate it empirically both on synthetic problems as well as\non a dataset from the clinical trial literature. Our approach compares\nfavorably to a suite of standard bandit algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 00:42:41 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 17:59:48 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 15:18:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Aboutalebi", "Hossein", ""], ["Precup", "Doina", ""], ["Schuster", "Tibor", ""]]}, {"id": "1903.01032", "submitter": "Fabio Pasqualetti", "authors": "Abed AlRahman Al Makdah, Vaibhav Katewa, and Fabio Pasqualetti", "title": "A Fundamental Performance Limitation for Adversarial Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread use of machine learning algorithms to solve problems\nof technological, economic, and social relevance, provable guarantees on the\nperformance of these data-driven algorithms are critically lacking, especially\nwhen the data originates from unreliable sources and is transmitted over\nunprotected and easily accessible channels. In this paper we take an important\nstep to bridge this gap and formally show that, in a quest to optimize their\naccuracy, binary classification algorithms -- including those based on\nmachine-learning techniques -- inevitably become more sensitive to adversarial\nmanipulation of the data. Further, for a given class of algorithms with the\nsame complexity (i.e., number of classification boundaries), the fundamental\ntradeoff curve between accuracy and sensitivity depends solely on the\nstatistics of the data, and cannot be improved by tuning the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 01:22:40 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 00:25:25 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Makdah", "Abed AlRahman Al", ""], ["Katewa", "Vaibhav", ""], ["Pasqualetti", "Fabio", ""]]}, {"id": "1903.01045", "submitter": "Hasan Poonawala", "authors": "Baoyang Song, Hasan Poonawala, Laura Wynter, Sebastien Blandin", "title": "Robust commuter movement inference from connected mobile devices", "comments": "International Conference on Data Mining 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preponderance of connected devices provides unprecedented opportunities\nfor fine-grained monitoring of the public infrastructure. However while\nclassical models expect high quality application-specific data streams, the\npromise of the Internet of Things (IoT) is that of an abundance of disparate\nand noisy datasets from connected devices. In this context, we consider the\nproblem of estimation of the level of service of a city-wide public transport\nnetwork. We first propose a robust unsupervised model for train movement\ninference from wifi traces, via the application of robust clustering methods to\na one dimensional spatio-temporal setting. We then explore the extent to which\nthe demand-supply gap can be estimated from connected devices. We propose a\nclassification model of real-time commuter patterns, including both a batch\ntraining phase and an online learning component. We describe our deployment\narchitecture and assess our system accuracy on a large-scale anonymized dataset\ncomprising more than 10 billion records.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 02:18:31 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Song", "Baoyang", ""], ["Poonawala", "Hasan", ""], ["Wynter", "Laura", ""], ["Blandin", "Sebastien", ""]]}, {"id": "1903.01057", "submitter": "Dong Huang", "authors": "Dong Huang, Chang-Dong Wang, Jian-Sheng Wu, Jian-Huang Lai, Chee-Keong\n  Kwoh", "title": "Ultra-Scalable Spectral Clustering and Ensemble Clustering", "comments": "To appear in IEEE Transactions on Knowledge and Data Engineering,\n  2019", "journal-ref": null, "doi": "10.1109/TKDE.2019.2903410", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on scalability and robustness of spectral clustering for\nextremely large-scale datasets with limited resources. Two novel algorithms are\nproposed, namely, ultra-scalable spectral clustering (U-SPEC) and\nultra-scalable ensemble clustering (U-SENC). In U-SPEC, a hybrid representative\nselection strategy and a fast approximation method for K-nearest\nrepresentatives are proposed for the construction of a sparse affinity\nsub-matrix. By interpreting the sparse sub-matrix as a bipartite graph, the\ntransfer cut is then utilized to efficiently partition the graph and obtain the\nclustering result. In U-SENC, multiple U-SPEC clusterers are further integrated\ninto an ensemble clustering framework to enhance the robustness of U-SPEC while\nmaintaining high efficiency. Based on the ensemble generation via multiple\nU-SEPC's, a new bipartite graph is constructed between objects and base\nclusters and then efficiently partitioned to achieve the consensus clustering\nresult. It is noteworthy that both U-SPEC and U-SENC have nearly linear time\nand space complexity, and are capable of robustly and efficiently partitioning\nten-million-level nonlinearly-separable datasets on a PC with 64GB memory.\nExperiments on various large-scale datasets have demonstrated the scalability\nand robustness of our algorithms. The MATLAB code and experimental data are\navailable at https://www.researchgate.net/publication/330760669.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 03:30:23 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 07:33:18 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Huang", "Dong", ""], ["Wang", "Chang-Dong", ""], ["Wu", "Jian-Sheng", ""], ["Lai", "Jian-Huang", ""], ["Kwoh", "Chee-Keong", ""]]}, {"id": "1903.01061", "submitter": "Zhi-Gang Liu", "authors": "Zhi-Gang Liu and Matthew Mattina", "title": "Learning low-precision neural networks without Straight-Through\n  Estimator(STE)", "comments": "conference version accepted by IJCAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Straight-Through Estimator (STE) is widely used for back-propagating\ngradients through the quantization function, but the STE technique lacks a\ncomplete theoretical understanding. We propose an alternative methodology\ncalled alpha-blending (AB), which quantizes neural networks to low-precision\nusing stochastic gradient descent (SGD). Our method (AB) avoids STE\napproximation by replacing the quantized weight in the loss function by an\naffine combination of the quantized weight w_q and the corresponding\nfull-precision weight w with non-trainable scalar coefficient $\\alpha$ and\n$1-\\alpha$. During training, $\\alpha$ is gradually increased from 0 to 1; the\ngradient updates to the weights are through the full-precision term,\n$(1-\\alpha)w$, of the affine combination; the model is converted from\nfull-precision to low-precision progressively. To evaluate the method, a 1-bit\nBinaryNet on CIFAR10 dataset and 8-bits, 4-bits MobileNet v1, ResNet_50 v1/2 on\nImageNet dataset are trained using the alpha-blending approach, and the\nevaluation indicates that AB improves top-1 accuracy by 0.9%, 0.82% and 2.93%\nrespectively compared to the results of STE based quantization.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 03:47:19 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 19:09:40 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Liu", "Zhi-Gang", ""], ["Mattina", "Matthew", ""]]}, {"id": "1903.01063", "submitter": "Yuxiang Yang", "authors": "Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, Chelsea Finn", "title": "NoRML: No-Reward Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently adapting to new environments and changes in dynamics is critical\nfor agents to successfully operate in the real world. Reinforcement learning\n(RL) based approaches typically rely on external reward feedback for\nadaptation. However, in many scenarios this reward signal might not be readily\navailable for the target task, or the difference between the environments can\nbe implicit and only observable from the dynamics. To this end, we introduce a\nmethod that allows for self-adaptation of learned policies: No-Reward Meta\nLearning (NoRML). NoRML extends Model Agnostic Meta Learning (MAML) for RL and\nuses observable dynamics of the environment instead of an explicit reward\nfunction in MAML's finetune step. Our method has a more expressive update step\nthan MAML, while maintaining MAML's gradient based foundation. Additionally, in\norder to allow more targeted exploration, we implement an extension to MAML\nthat effectively disconnects the meta-policy parameters from the fine-tuned\npolicies' parameters. We first study our method on a number of synthetic\ncontrol problems and then validate our method on common benchmark environments,\nshowing that NoRML outperforms MAML when the dynamics change between tasks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 04:00:38 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Yang", "Yuxiang", ""], ["Caluwaerts", "Ken", ""], ["Iscen", "Atil", ""], ["Tan", "Jie", ""], ["Finn", "Chelsea", ""]]}, {"id": "1903.01069", "submitter": "Michael Mozer", "authors": "Been Kim, Emily Reif, Martin Wattenberg, Samy Bengio, Michael C. Mozer", "title": "Neural Networks Trained on Natural Scenes Exhibit Gestalt Closure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gestalt laws of perceptual organization, which describe how visual\nelements in an image are grouped and interpreted, have traditionally been\nthought of as innate despite their ecological validity. We use deep-learning\nmethods to investigate whether natural scene statistics might be sufficient to\nderive the Gestalt laws. We examine the law of closure, which asserts that\nhuman visual perception tends to \"close the gap\" by assembling elements that\ncan jointly be interpreted as a complete figure or object. We demonstrate that\na state-of-the-art convolutional neural network, trained to classify natural\nimages, exhibits closure on synthetic displays of edge fragments, as assessed\nby similarity of internal representations. This finding provides support for\nthe hypothesis that the human perceptual system is even more elegant than the\nGestaltists imagined: a single law---adaptation to the statistical structure of\nthe environment---might suffice as fundamental.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 04:44:19 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 17:00:13 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 02:36:49 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 23:02:58 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kim", "Been", ""], ["Reif", "Emily", ""], ["Wattenberg", "Martin", ""], ["Bengio", "Samy", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1903.01083", "submitter": "Shuai Li", "authors": "Shuai Li, Wei Chen, Zheng Wen, Kwong-Sak Leung", "title": "Stochastic Online Learning with Probabilistic Graph Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of stochastic online learning with general\nprobabilistic graph feedback, where each directed edge in the feedback graph\nhas probability $p_{ij}$. Two cases are covered. (a) The one-step case, where\nafter playing arm $i$ the learner observes a sample reward feedback of arm $j$\nwith independent probability $p_{ij}$. (b) The cascade case where after playing\narm $i$ the learner observes feedback of all arms $j$ in a probabilistic\ncascade starting from $i$ -- for each $(i,j)$ with probability $p_{ij}$, if arm\n$i$ is played or observed, then a reward sample of arm $j$ would be observed\nwith independent probability $p_{ij}$. Previous works mainly focus on\ndeterministic graphs which corresponds to one-step case with $p_{ij} \\in\n\\{0,1\\}$, an adversarial sequence of graphs with certain topology guarantees,\nor a specific type of random graphs. We analyze the asymptotic lower bounds and\ndesign algorithms in both cases. The regret upper bounds of the algorithms\nmatch the lower bounds with high probability.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 05:56:20 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 08:32:27 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Li", "Shuai", ""], ["Chen", "Wei", ""], ["Wen", "Zheng", ""], ["Leung", "Kwong-Sak", ""]]}, {"id": "1903.01167", "submitter": "Prayag Tiwari Mr.", "authors": "Prayag Tiwari, Massimo Melucci", "title": "Binary Classifier Inspired by Quantum Theory", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) helps us to recognize patterns from raw data. ML is\nused in numerous domains i.e. biomedical, agricultural, food technology, etc.\nDespite recent technological advancements, there is still room for substantial\nimprovement in prediction. Current ML models are based on classical theories of\nprobability and statistics, which can now be replaced by Quantum Theory (QT)\nwith the aim of improving the effectiveness of ML. In this paper, we propose\nthe Binary Classifier Inspired by Quantum Theory (BCIQT) model, which\noutperforms the state of the art classification in terms of recall for every\ncategory.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 10:53:01 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Tiwari", "Prayag", ""], ["Melucci", "Massimo", ""]]}, {"id": "1903.01182", "submitter": "Hao-Yun Chen", "authors": "Hao-Yun Chen, Pei-Hsin Wang, Chun-Hao Liu, Shih-Chieh Chang, Jia-Yu\n  Pan, Yu-Ting Chen, Wei Wei, Da-Cheng Juan", "title": "Complement Objective Training", "comments": "ICLR'19 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with a primary objective, such as softmax cross entropy for\nclassification and sequence generation, has been the norm for training deep\nneural networks for years. Although being a widely-adopted approach, using\ncross entropy as the primary objective exploits mostly the information from the\nground-truth class for maximizing data likelihood, and largely ignores\ninformation from the complement (incorrect) classes. We argue that, in addition\nto the primary objective, training also using a complement objective that\nleverages information from the complement classes can be effective in improving\nmodel performance. This motivates us to study a new training paradigm that\nmaximizes the likelihood of the groundtruth class while neutralizing the\nprobabilities of the complement classes. We conduct extensive experiments on\nmultiple tasks ranging from computer vision to natural language understanding.\nThe experimental results confirm that, compared to the conventional training\nwith just one primary objective, training also with the complement objective\nfurther improves the performance of the state-of-the-art models across all\ntasks. In addition to the accuracy improvement, we also show that models\ntrained with both primary and complement objectives are more robust to\nsingle-step adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 11:35:27 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 18:33:12 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Chen", "Hao-Yun", ""], ["Wang", "Pei-Hsin", ""], ["Liu", "Chun-Hao", ""], ["Chang", "Shih-Chieh", ""], ["Pan", "Jia-Yu", ""], ["Chen", "Yu-Ting", ""], ["Wei", "Wei", ""], ["Juan", "Da-Cheng", ""]]}, {"id": "1903.01254", "submitter": "Frederik Diehl", "authors": "Frederik Diehl, Thomas Brunner, Michael Truong Le, Alois Knoll", "title": "Graph Neural Networks for Modelling Traffic Participant Interaction", "comments": "To be published at IEEE Intelligent Vehicles Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By interpreting a traffic scene as a graph of interacting vehicles, we gain a\nflexible abstract representation which allows us to apply Graph Neural Network\n(GNN) models for traffic prediction. These naturally take interaction between\ntraffic participants into account while being computationally efficient and\nproviding large model capacity. We evaluate two state-of-the art GNN\narchitectures and introduce several adaptations for our specific scenario. We\nshow that prediction error in scenarios with much interaction decreases by 30%\ncompared to a model that does not take interactions into account. This suggests\nthat interaction is important, and shows that we can model it using graphs.\nThis makes GNNs a worthwhile addition to traffic prediction systems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:15:07 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 08:53:01 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Diehl", "Frederik", ""], ["Brunner", "Thomas", ""], ["Le", "Michael Truong", ""], ["Knoll", "Alois", ""]]}, {"id": "1903.01293", "submitter": "Sundeep Rangan", "authors": "Parthe Pandit, Mojtaba Sahraee, Sundeep Rangan, Alyson K. Fletcher", "title": "Asymptotics of MAP Inference in Deep Networks", "comments": "11 pages. arXiv admin note: text overlap with arXiv:1706.06549", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative priors are a powerful tool for reconstruction problems with\ncomplex data such as images and text. Inverse problems using such models\nrequire solving an inference problem of estimating the input and hidden units\nof the multi-layer network from its output. Maximum a priori (MAP) estimation\nis a widely-used inference method as it is straightforward to implement, and\nhas been successful in practice. However, rigorous analysis of MAP inference in\nmulti-layer networks is difficult. This work considers a recently-developed\nmethod, multi-layer vector approximate message passing (ML-VAMP), to study MAP\ninference in deep networks. It is shown that the mean squared error of the\nML-VAMP estimate can be exactly and rigorously characterized in a certain\nhigh-dimensional random limit. The proposed method thus provides a tractable\nmethod for MAP inference with exact performance guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:25:55 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Pandit", "Parthe", ""], ["Sahraee", "Mojtaba", ""], ["Rangan", "Sundeep", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "1903.01298", "submitter": "Elvin Isufi", "authors": "Elvin Isufi, Fernando Gama, Alejandro Ribeiro", "title": "Generalizing Graph Convolutional Neural Networks with Edge-Variant\n  Recursions on Graphs", "comments": "submitted to EUSIPCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews graph convolutional neural networks (GCNNs) through the\nlens of edge-variant graph filters. The edge-variant graph filter is a finite\norder, linear, and local recursion that allows each node, in each iteration, to\nweigh differently the information of its neighbors. By exploiting this\nrecursion, we formulate a general framework for GCNNs which considers\nstate-of-the-art solutions as particular cases. This framework results useful\nto i) understand the tradeoff between local detail and the number of parameters\nof each solution and ii) provide guidelines for developing a myriad of novel\napproaches that can be implemented locally in the vertex domain. One of such\napproaches is presented here showing superior performance w.r.t. current\nalternatives in graph signal classification problems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:05:36 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Isufi", "Elvin", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1903.01310", "submitter": "Arvind Prasadan", "authors": "Arvind Prasadan and Raj Rao Nadakuditi", "title": "Time Series Source Separation using Dynamic Mode Decomposition", "comments": "Accepted in SIADS (SIAM's Journal of Applied Dynamical Systems)", "journal-ref": null, "doi": "10.5281/zenodo.2656681", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Dynamic Mode Decomposition (DMD) extracted dynamic modes are the\nnon-orthogonal eigenvectors of the matrix that best approximates the one-step\ntemporal evolution of the multivariate samples. In the context of dynamical\nsystem analysis, the extracted dynamic modes are a generalization of global\nstability modes. We apply DMD to a data matrix whose rows are linearly\nindependent, additive mixtures of latent time series. We show that when the\nlatent time series are uncorrelated at a lag of one time-step then, in the\nlarge sample limit, the recovered dynamic modes will approximate, up to a\ncolumn-wise normalization, the columns of the mixing matrix. Thus, DMD is a\ntime series blind source separation algorithm in disguise, but is different\nfrom closely related second order algorithms such as the Second-Order Blind\nIdentification (SOBI) method and the Algorithm for Multiple Unknown Signals\nExtraction (AMUSE). All can unmix mixed stationary, ergodic Gaussian time\nseries in a way that kurtosis-based Independent Components Analysis (ICA)\nfundamentally cannot. We use our insights on single lag DMD to develop a\nhigher-lag extension, analyze the finite sample performance with and without\nrandomly missing data, and identify settings where the higher lag variant can\noutperform the conventional single lag variant. We validate our results with\nnumerical simulations, and highlight how DMD can be used in change point\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:37:14 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 17:08:16 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 16:16:05 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 21:57:15 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Prasadan", "Arvind", ""], ["Nadakuditi", "Raj Rao", ""]]}, {"id": "1903.01334", "submitter": "Florian Dumpert", "authors": "Florian Dumpert", "title": "Quantitative Robustness of Localized Support Vector Machines", "comments": "arXiv admin note: text overlap with arXiv:1703.06528", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The huge amount of available data nowadays is a challenge for kernel-based\nmachine learning algorithms like SVMs with respect to runtime and storage\ncapacities. Local approaches might help to relieve these issues and to improve\nstatistical accuracy. It has already been shown that these local approaches are\nconsistent and robust in a basic sense. This article refines the analysis of\nrobustness properties towards the so-called influence function which expresses\nthe differentiability of the learning method: We show that there is a\ndifferentiable dependency of our locally learned predictor on the underlying\ndistribution. The assumptions of the proven theorems can be verified without\nknowing anything about this distribution. This makes the results interesting\nalso from an applied point of view.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 15:12:15 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Dumpert", "Florian", ""]]}, {"id": "1903.01341", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G. C. A. Cimino, Gigliola Vaglini", "title": "Using stigmergy as a computational memory in the design of recurrent\n  neural networks", "comments": null, "journal-ref": null, "doi": "10.5220/0007581508300836", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel architecture of Recurrent Neural Network (RNN) is\ndesigned and experimented. The proposed RNN adopts a computational memory based\non the concept of stigmergy. The basic principle of a Stigmergic Memory (SM) is\nthat the activity of deposit/removal of a quantity in the SM stimulates the\nnext activities of deposit/removal. Accordingly, subsequent SM activities tend\nto reinforce/weaken each other, generating a coherent coordination between the\nSM activities and the input temporal stimulus. We show that, in a problem of\nsupervised classification, the SM encodes the temporal input in an emergent\nrepresentational model, by coordinating the deposit, removal and classification\nactivities. This study lays down a basic framework for the derivation of a\nSM-RNN. A formal ontology of SM is discussed, and the SM-RNN architecture is\ndetailed. To appreciate the computational power of an SM-RNN, comparative NNs\nhave been selected and trained to solve the MNIST handwritten digits\nrecognition benchmark in its two variants: spatial (sequences of bitmap rows)\nand temporal (sequences of pen strokes).\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 22:26:39 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1903.01344", "submitter": "Zhou Fan", "authors": "Zhou Fan, Rui Su, Weinan Zhang and Yong Yu", "title": "Hybrid Actor-Critic Reinforcement Learning in Parameterized Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a hybrid architecture of actor-critic algorithms for\nreinforcement learning in parameterized action space, which consists of\nmultiple parallel sub-actor networks to decompose the structured action space\ninto simpler action spaces along with a critic network to guide the training of\nall sub-actor networks. While this paper is mainly focused on parameterized\naction space, the proposed architecture, which we call hybrid actor-critic, can\nbe extended for more general action spaces which has a hierarchical structure.\nWe present an instance of the hybrid actor-critic architecture based on\nproximal policy optimization (PPO), which we refer to as hybrid proximal policy\noptimization (H-PPO). Our experiments test H-PPO on a collection of tasks with\nparameterized action space, where H-PPO demonstrates superior performance over\nprevious methods of parameterized action reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:33:15 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 08:32:06 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 13:02:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Fan", "Zhou", ""], ["Su", "Rui", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1903.01385", "submitter": "Minne Li", "authors": "Minne Li, Zheng Tian, Pranav Nashikkar, Ian Davies, Ying Wen, Jun Wang", "title": "Joint Perception and Control as Inference with an Object-based\n  Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing model-based reinforcement learning methods often study perception\nmodeling and decision making separately. We introduce joint Perception and\nControl as Inference (PCI), a general framework to combine perception and\ncontrol for partially observable environments through Bayesian inference. Based\non the fact that object-level inductive biases are critical in human perceptual\nlearning and reasoning, we propose Object-based Perception Control (OPC), an\ninstantiation of PCI which manages to facilitate control using automatic\ndiscovered object-based representations. We develop an unsupervised end-to-end\nsolution and analyze the convergence of the perception model update.\nExperiments in a high-dimensional pixel environment demonstrate the learning\neffectiveness of our object-based perception control approach. Specifically, we\nshow that OPC achieves good perceptual grouping quality and outperforms several\nstrong baselines in accumulated rewards.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 17:30:12 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 10:44:50 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 12:54:29 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Li", "Minne", ""], ["Tian", "Zheng", ""], ["Nashikkar", "Pranav", ""], ["Davies", "Ian", ""], ["Wen", "Ying", ""], ["Wang", "Jun", ""]]}, {"id": "1903.01395", "submitter": "Adityanand Guntuboyina", "authors": "Billy Fang and Adityanand Guntuboyina and Bodhisattva Sen", "title": "Multivariate extensions of isotonic regression and total variation\n  denoising via entire monotonicity and Hardy-Krause variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of nonparametric regression when the covariate is\n$d$-dimensional, where $d \\geq 1$. In this paper we introduce and study two\nnonparametric least squares estimators (LSEs) in this setting---the entirely\nmonotonic LSE and the constrained Hardy-Krause variation LSE. We show that\nthese two LSEs are natural generalizations of univariate isotonic regression\nand univariate total variation denoising, respectively, to multiple dimensions.\nWe discuss the characterization and computation of these two LSEs obtained from\n$n$ data points. We provide a detailed study of their risk properties under the\nsquared error loss and fixed uniform lattice design. We show that the finite\nsample risk of these LSEs is always bounded from above by $n^{-2/3}$ modulo\nlogarithmic factors depending on $d$; thus these nonparametric LSEs avoid the\ncurse of dimensionality to some extent. We also prove nearly matching minimax\nlower bounds. Further, we illustrate that these LSEs are particularly useful in\nfitting rectangular piecewise constant functions. Specifically, we show that\nthe risk of the entirely monotonic LSE is almost parametric (at most $1/n$ up\nto logarithmic factors) when the true function is well-approximable by a\nrectangular piecewise constant entirely monotone function with not too many\nconstant pieces. A similar result is also shown to hold for the constrained\nHardy-Krause variation LSE for a simple subclass of rectangular piecewise\nconstant functions. We believe that the proposed LSEs yield a novel approach to\nestimating multivariate functions using convex optimization that avoid the\ncurse of dimensionality to some extent.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 17:43:42 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 07:35:35 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 20:07:34 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Fang", "Billy", ""], ["Guntuboyina", "Adityanand", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1903.01422", "submitter": "Osman Dai", "authors": "Osman Emre Dai, Daniel Cullina, Negar Kiyavash", "title": "Database Alignment with Gaussian Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aligning a pair of databases with jointly Gaussian\nfeatures. We consider two algorithms, complete database alignment via MAP\nestimation among all possible database alignments, and partial alignment via a\nthresholding approach of log likelihood ratios. We derive conditions on mutual\ninformation between feature pairs, identifying the regimes where the algorithms\nare guaranteed to perform reliably and those where they cannot be expected to\nsucceed.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:30:22 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 21:50:08 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Dai", "Osman Emre", ""], ["Cullina", "Daniel", ""], ["Kiyavash", "Negar", ""]]}, {"id": "1903.01432", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky", "title": "Data Amplification: Instance-Optimal Property Estimation", "comments": "In this new version, we strengthened the previous results by\n  eliminating unnecessary assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best-known and most commonly used distribution-property estimation\ntechnique uses a plug-in estimator, with empirical frequency replacing the\nunderlying distribution. We present novel linear-time-computable estimators\nthat significantly \"amplify\" the effective amount of data available. For a\nlarge variety of distribution properties including four of the most popular\nones and for every underlying distribution, they achieve the accuracy that the\nempirical-frequency plug-in estimators would attain using a logarithmic-factor\nmore samples.\n  Specifically, for Shannon entropy and a very broad class of properties\nincluding $\\ell_1$-distance, the new estimators use $n$ samples to achieve the\naccuracy attained by the empirical estimators with $n\\log n$ samples. For\nsupport-size and coverage, the new estimators use $n$ samples to achieve the\nperformance of empirical frequency with sample size $n$ times the logarithm of\nthe property value. Significantly strengthening the traditional min-max\nformulation, these results hold not only for the worst distributions, but for\neach and every underlying distribution. Furthermore, the logarithmic\namplification factors are optimal. Experiments on a wide variety of\ndistributions show that the new estimators outperform the previous\nstate-of-the-art estimators designed for each specific property.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:55:09 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 18:55:10 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""]]}, {"id": "1903.01435", "submitter": "Ping Li", "authors": "Jun-Kun Wang, Xiaoyun Li, Belhal Karimi, Ping Li", "title": "An Optimistic Acceleration of AMSGrad for Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new variant of AMSGrad, a popular adaptive gradient based\noptimization algorithm widely used for training deep neural networks. Our\nalgorithm adds prior knowledge about the sequence of consecutive mini-batch\ngradients and leverages its underlying structure making the gradients\nsequentially predictable. By exploiting the predictability and ideas from\noptimistic online learning, the proposed algorithm can accelerate the\nconvergence and increase sample efficiency. After establishing a tighter upper\nbound under some convexity conditions on the regret, we offer a complimentary\nview of our algorithm which generalizes the offline and stochastic version of\nnonconvex optimization. In the nonconvex case, we establish a non-asymptotic\nconvergence bound independently of the initialization. We illustrate the\npractical speedup on several deep learning models via numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:56:40 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 15:00:02 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 17:57:21 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Jun-Kun", ""], ["Li", "Xiaoyun", ""], ["Karimi", "Belhal", ""], ["Li", "Ping", ""]]}, {"id": "1903.01454", "submitter": "Brijnesh Jain", "authors": "Brijnesh Jain", "title": "Making the Dynamic Time Warping Distance Warping-Invariant", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.09964", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature postulates that the dynamic time warping (dtw) distance can\ncope with temporal variations but stores and processes time series in a form as\nif the dtw-distance cannot cope with such variations. To address this\ninconsistency, we first show that the dtw-distance is not warping-invariant.\nThe lack of warping-invariance contributes to the inconsistency mentioned above\nand to a strange behavior. To eliminate these peculiarities, we convert the\ndtw-distance to a warping-invariant semi-metric, called time-warp-invariant\n(twi) distance. Empirical results suggest that the error rates of the twi and\ndtw nearest-neighbor classifier are practically equivalent in a Bayesian sense.\nHowever, the twi-distance requires less storage and computation time than the\ndtw-distance for a broad range of problems. These results challenge the current\npractice of applying the dtw-distance in nearest-neighbor classification and\nsuggest the proposed twi-distance as a more efficient and consistent option.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 09:50:23 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 17:31:08 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Jain", "Brijnesh", ""]]}, {"id": "1903.01461", "submitter": "Ruihao Zhu", "authors": "Wang Chi Cheung and David Simchi-Levi and Ruihao Zhu", "title": "Hedging the Drift: Learning to Optimize under Non-Stationarity", "comments": "Journal version of the AISTATS 2019 version (available at\n  arXiv:1810.03024). This version fixed an error in the proof of Theorem 2 with\n  Assumption 4 of arXiv:2103.05750", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce data-driven decision-making algorithms that achieve\nstate-of-the-art \\emph{dynamic regret} bounds for non-stationary bandit\nsettings. These settings capture applications such as advertisement allocation,\ndynamic pricing, and traffic network routing in changing environments. We show\nhow the difficulty posed by the (unknown \\emph{a priori} and possibly\nadversarial) non-stationarity can be overcome by an unconventional marriage\nbetween stochastic and adversarial bandit learning algorithms. Our main\ncontribution is a general algorithmic recipe for a wide variety of\nnon-stationary bandit problems. Specifically, we design and analyze the sliding\nwindow-upper confidence bound algorithm that achieves the optimal dynamic\nregret bound for each of the settings when we know the respective underlying\n\\emph{variation budget}, which quantifies the total amount of temporal\nvariation of the latent environments. Boosted by the novel bandit-over-bandit\nframework that adapts to the latent changes, we can further enjoy the (nearly)\noptimal dynamic regret bounds in a (surprisingly) parameter-free manner. In\naddition to the classical exploration-exploitation trade-off, our algorithms\nleverage the power of the \"forgetting principle\" in the learning processes,\nwhich is vital in changing environments. Our extensive numerical experiments on\nboth synthetic and real world online auto-loan datasets show that our proposed\nalgorithms achieve superior empirical performance compared to existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:51:41 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 14:57:29 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 14:37:49 GMT"}, {"version": "v4", "created": "Wed, 17 Mar 2021 21:30:08 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Cheung", "Wang Chi", ""], ["Simchi-Levi", "David", ""], ["Zhu", "Ruihao", ""]]}, {"id": "1903.01463", "submitter": "Dheeraj Nagaraj", "authors": "Prateek Jain, Dheeraj Nagaraj and Praneeth Netrapalli", "title": "SGD without Replacement: Sharper Rates for General Smooth Convex\n  Functions", "comments": "Version 2 corrects a minor error in the bounds for K", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic gradient descent {\\em without replacement} (\\sgdwor) for\nsmooth convex functions. \\sgdwor is widely observed to converge faster than\ntrue \\sgd where each sample is drawn independently {\\em with replacement}\n\\cite{bottou2009curiously} and hence, is more popular in practice. But it's\nconvergence properties are not well understood as sampling without replacement\nleads to coupling between iterates and gradients. By using method of\nexchangeable pairs to bound Wasserstein distance, we provide the first\nnon-asymptotic results for \\sgdwor when applied to {\\em general smooth,\nstrongly-convex} functions. In particular, we show that \\sgdwor converges at a\nrate of $O(1/K^2)$ while \\sgd is known to converge at $O(1/K)$ rate, where $K$\ndenotes the number of passes over data and is required to be {\\em large\nenough}. Existing results for \\sgdwor in this setting require additional {\\em\nHessian Lipschitz assumption} \\cite{gurbuzbalaban2015random,haochen2018random}.\n  For {\\em small} $K$, we show \\sgdwor can achieve same convergence rate as\n\\sgd for {\\em general smooth strongly-convex} functions. Existing results in\nthis setting require $K=1$ and hold only for generalized linear models\n\\cite{shamir2016without}. In addition, by careful analysis of the coupling, for\nboth large and small $K$, we obtain better dependence on problem dependent\nparameters like condition number.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:52:23 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 03:26:57 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Jain", "Prateek", ""], ["Nagaraj", "Dheeraj", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1903.01531", "submitter": "Dibakar Gope", "authors": "Dibakar Gope, Ganesh Dasika, Matthew Mattina", "title": "Ternary Hybrid Neural-Tree Networks for Highly Constrained IoT\n  Applications", "comments": null, "journal-ref": "2nd Conference on Systems and Machine Learning (SysML), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based applications are increasingly prevalent in IoT\ndevices. The power and storage constraints of these devices make it\nparticularly challenging to run modern neural networks, limiting the number of\nnew applications that can be deployed on an IoT system. A number of compression\ntechniques have been proposed, each with its own trade-offs. We propose a\nhybrid network which combines the strengths of current neural- and tree-based\nlearning techniques in conjunction with ternary quantization, and show a\ndetailed analysis of the associated model design space. Using this hybrid model\nwe obtained a 11.1% reduction in the number of computations, a 52.2% reduction\nin the model size, and a 30.6% reduction in the overall memory footprint over a\nstate-of-the-art keyword-spotting neural network, with negligible loss in\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 20:41:06 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Gope", "Dibakar", ""], ["Dasika", "Ganesh", ""], ["Mattina", "Matthew", ""]]}, {"id": "1903.01537", "submitter": "Navyata Sanghvi", "authors": "Navyata Sanghvi, Ryo Yonetani, Kris Kitani", "title": "MGpi: A Computational Model of Multiagent Group Perception and\n  Interaction", "comments": "To be published in: Proceedings of the 19th International Conference\n  on Autonomous Agents and Multiagent Systems (AAMAS 2020), May 2020, Auckland,\n  New Zealand", "journal-ref": "Proceedings of the 19th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2020), pp. 1196-1205", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toward enabling next-generation robots capable of socially intelligent\ninteraction with humans, we present a $\\mathbf{computational\\; model}$ of\ninteractions in a social environment of multiple agents and multiple groups.\nThe Multiagent Group Perception and Interaction (MGpi) network is a deep neural\nnetwork that predicts the appropriate social action to execute in a group\nconversation (e.g., speak, listen, respond, leave), taking into account\nneighbors' observable features (e.g., location of people, gaze orientation,\ndistraction, etc.). A central component of MGpi is the Kinesic-Proxemic-Message\n(KPM) gate, that performs social signal gating to extract important information\nfrom a group conversation. In particular, KPM gate filters incoming social cues\nfrom nearby agents by observing their body gestures (kinesics) and spatial\nbehavior (proxemics). The MGpi network and its KPM gate are learned via\nimitation learning, using demonstrations from our designed $\\mathbf{social\\;\ninteraction\\; simulator}$. Further, we demonstrate the efficacy of the KPM gate\nas a social attention mechanism, achieving state-of-the-art performance on the\ntask of $\\mathbf{group\\; identification}$ without using explicit group\nannotations, layout assumptions, or manually chosen parameters.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 21:04:22 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 20:39:57 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Sanghvi", "Navyata", ""], ["Yonetani", "Ryo", ""], ["Kitani", "Kris", ""]]}, {"id": "1903.01540", "submitter": "Zebang Shen", "authors": "Zebang Shen, Pan Zhou, Cong Fang, Alejandro Ribeiro", "title": "A Stochastic Trust Region Method for Non-convex Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We target the problem of finding a local minimum in non-convex finite-sum\nminimization. Towards this goal, we first prove that the trust region method\nwith inexact gradient and Hessian estimation can achieve a convergence rate of\norder $\\mathcal{O}(1/{k^{2/3}})$ as long as those differential estimations are\nsufficiently accurate. Combining such result with a novel Hessian estimator, we\npropose the sample-efficient stochastic trust region (STR) algorithm which\nfinds an $(\\epsilon, \\sqrt{\\epsilon})$-approximate local minimum within\n$\\mathcal{O}({\\sqrt{n}}/{\\epsilon^{1.5}})$ stochastic Hessian oracle queries.\nThis improves state-of-the-art result by $\\mathcal{O}(n^{1/6})$. Experiments\nverify theoretical conclusions and the efficiency of STR.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 21:12:30 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Shen", "Zebang", ""], ["Zhou", "Pan", ""], ["Fang", "Cong", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1903.01552", "submitter": "Morteza Zabihi", "authors": "Morteza Zabihi, Ali Bahrami Rad, Serkan Kiranyaz, Simo S\\\"arkk\\\"a,\n  Moncef Gabbouj", "title": "1D Convolutional Neural Network Models for Sleep Arousal Detection", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep arousals transition the depth of sleep to a more superficial stage. The\noccurrence of such events is often considered as a protective mechanism to\nalert the body of harmful stimuli. Thus, accurate sleep arousal detection can\nlead to an enhanced understanding of the underlying causes and influencing the\nassessment of sleep quality. Previous studies and guidelines have suggested\nthat sleep arousals are linked mainly to abrupt frequency shifts in EEG\nsignals, but the proposed rules are shown to be insufficient for a\ncomprehensive characterization of arousals. This study investigates the\napplication of five recent convolutional neural networks (CNNs) for sleep\narousal detection and performs comparative evaluations to determine the best\nmodel for this task. The investigated state-of-the-art CNN models have\noriginally been designed for image or speech processing. A detailed set of\nevaluations is performed on the benchmark dataset provided by\nPhysioNet/Computing in Cardiology Challenge 2018, and the results show that the\nbest 1D CNN model has achieved an average of 0.31 and 0.84 for the area under\nthe precision-recall and area under the ROC curves, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 15:10:53 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Zabihi", "Morteza", ""], ["Rad", "Ali Bahrami", ""], ["Kiranyaz", "Serkan", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1903.01563", "submitter": "Bryse Flowers", "authors": "Bryse Flowers, R. Michael Buehrer, and William C. Headley", "title": "Evaluating Adversarial Evasion Attacks in the Context of Wireless\n  Communications", "comments": "13 pages, 14 figures, Submitted to IEEE Transactions on Information\n  Forensics & Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in radio frequency machine learning (RFML) have\ndemonstrated the use of raw in-phase and quadrature (IQ) samples for multiple\nspectrum sensing tasks. Yet, deep learning techniques have been shown, in other\napplications, to be vulnerable to adversarial machine learning (ML) techniques,\nwhich seek to craft small perturbations that are added to the input to cause a\nmisclassification. The current work differentiates the threats that adversarial\nML poses to RFML systems based on where the attack is executed from: direct\naccess to classifier input, synchronously transmitted over the air (OTA), or\nasynchronously transmitted from a separate device. Additionally, the current\nwork develops a methodology for evaluating adversarial success in the context\nof wireless communications, where the primary metric of interest is bit error\nrate and not human perception, as is the case in image recognition. The\nmethodology is demonstrated using the well known Fast Gradient Sign Method to\nevaluate the vulnerabilities of raw IQ based Automatic Modulation\nClassification and concludes RFML is vulnerable to adversarial examples, even\nin OTA attacks. However, RFML domain specific receiver effects, which would be\nencountered in an OTA attack, can present significant impairments to\nadversarial evasion.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:21:34 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Flowers", "Bryse", ""], ["Buehrer", "R. Michael", ""], ["Headley", "William C.", ""]]}, {"id": "1903.01599", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Amanpreet Singh, Ahmed Touati, Anirudh Goyal, Yoshua\n  Bengio, Devi Parikh, Dhruv Batra", "title": "Learning Dynamics Model in Reinforcement Learning by Incorporating the\n  Long Term Future", "comments": "To appear at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-based reinforcement learning, the agent interleaves between model\nlearning and planning. These two components are inextricably intertwined. If\nthe model is not able to provide sensible long-term prediction, the executed\nplanner would exploit model flaws, which can yield catastrophic failures. This\npaper focuses on building a model that reasons about the long-term future and\ndemonstrates how to use this for efficient planning and exploration. To this\nend, we build a latent-variable autoregressive model by leveraging recent ideas\nin variational inference. We argue that forcing latent variables to carry\nfuture information through an auxiliary task substantially improves long-term\npredictions. Moreover, by planning in the latent space, the planner's solution\nis ensured to be within regions where the model is valid. An exploration\nstrategy can be devised by searching for unlikely trajectories under the model.\nOur method achieves higher reward faster compared to baselines on a variety of\ntasks and environments in both the imitation learning and model-based\nreinforcement learning settings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:15:21 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 17:10:08 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Singh", "Amanpreet", ""], ["Touati", "Ahmed", ""], ["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1903.01608", "submitter": "Maxim Raginsky", "authors": "Belinda Tzen and Maxim Raginsky", "title": "Theoretical guarantees for sampling and inference in generative models\n  with latent diffusions", "comments": "To appear in COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a class of probabilistic generative models, where the\nlatent object is a finite-dimensional diffusion process on a finite time\ninterval and the observed variable is drawn conditionally on the terminal point\nof the diffusion. We make the following contributions:\n  We provide a unified viewpoint on both sampling and variational inference in\nsuch generative models through the lens of stochastic control.\n  We quantify the expressiveness of diffusion-based generative models.\nSpecifically, we show that one can efficiently sample from a wide class of\nterminal target distributions by choosing the drift of the latent diffusion\nfrom the class of multilayer feedforward neural nets, with the accuracy of\nsampling measured by the Kullback-Leibler divergence to the target\ndistribution.\n  Finally, we present and analyze a scheme for unbiased simulation of\ngenerative models with latent diffusions and provide bounds on the variance of\nthe resulting estimators. This scheme can be implemented as a deep generative\nmodel with a random number of layers.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:38:49 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:23:24 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Tzen", "Belinda", ""], ["Raginsky", "Maxim", ""]]}, {"id": "1903.01610", "submitter": "Huijun Wu", "authors": "Huijun Wu, Chen Wang, Yuriy Tyshetskiy, Andrew Docherty, Kai Lu,\n  Liming Zhu", "title": "Adversarial Examples on Graph Data: Deep Insights into Attack and\n  Defense", "comments": "to appear in IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph deep learning models, such as graph convolutional networks (GCN)\nachieve remarkable performance for tasks on graph data. Similar to other types\nof deep models, graph deep learning models often suffer from adversarial\nattacks. However, compared with non-graph data, the discrete features, graph\nconnections and different definitions of imperceptible perturbations bring\nunique challenges and opportunities for the adversarial attacks and defenses\nfor graph data. In this paper, we propose both attack and defense techniques.\nFor attack, we show that the discreteness problem could easily be resolved by\nintroducing integrated gradients which could accurately reflect the effect of\nperturbing certain features or edges while still benefiting from the parallel\ncomputations. For defense, we observe that the adversarially manipulated graph\nfor the targeted attack differs from normal graphs statistically. Based on this\nobservation, we propose a defense approach which inspects the graph and\nrecovers the potential adversarial perturbations. Our experiments on a number\nof datasets show the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:43:48 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 05:20:00 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 08:45:44 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Wu", "Huijun", ""], ["Wang", "Chen", ""], ["Tyshetskiy", "Yuriy", ""], ["Docherty", "Andrew", ""], ["Lu", "Kai", ""], ["Zhu", "Liming", ""]]}, {"id": "1903.01611", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M. Roy, Michael\n  Carbin", "title": "Stabilizing the Lottery Ticket Hypothesis", "comments": "This article has been subsumed by \"Linear Mode Connectivity and the\n  Lottery Ticket Hypothesis\" (arXiv:1912.05671, ICML 2020). Please read/cite\n  that article instead", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is a well-established technique for removing unnecessary structure\nfrom neural networks after training to improve the performance of inference.\nSeveral recent results have explored the possibility of pruning at\ninitialization time to provide similar benefits during training. In particular,\nthe \"lottery ticket hypothesis\" conjectures that typical neural networks\ncontain small subnetworks that can train to similar accuracy in a commensurate\nnumber of steps. The evidence for this claim is that a procedure based on\niterative magnitude pruning (IMP) reliably finds such subnetworks retroactively\non small vision tasks. However, IMP fails on deeper networks, and proposed\nmethods to prune before training or train pruned networks encounter similar\nscaling limitations. In this paper, we argue that these efforts have struggled\non deeper networks because they have focused on pruning precisely at\ninitialization. We modify IMP to search for subnetworks that could have been\nobtained by pruning early in training (0.1% to 7% through) rather than at\niteration 0. With this change, it finds small subnetworks of deeper networks\n(e.g., 80% sparsity on Resnet-50) that can complete the training process to\nmatch the accuracy of the original network on more challenging tasks (e.g.,\nImageNet). In situations where IMP fails at iteration 0, the accuracy benefits\nof delaying pruning accrue rapidly over the earliest iterations of training. To\nexplain these behaviors, we study subnetwork \"stability,\" finding that - as\naccuracy improves in this fashion - IMP subnetworks train to parameters closer\nto those of the full network and do so with improved consistency in the face of\ngradient noise. These results offer new insights into the opportunity to prune\nlarge-scale networks early in training and the behaviors underlying the lottery\nticket hypothesis\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:52:12 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 23:40:16 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 16:50:33 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Frankle", "Jonathan", ""], ["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""], ["Carbin", "Michael", ""]]}, {"id": "1903.01620", "submitter": "Pasha Khosravi", "authors": "Pasha Khosravi, Yitao Liang, YooJung Choi, Guy Van den Broeck", "title": "What to Expect of Classifiers? Reasoning about Logistic Regression with\n  Missing Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While discriminative classifiers often yield strong predictive performance,\nmissing feature values at prediction time can still be a challenge. Classifiers\nmay not behave as expected under certain ways of substituting the missing\nvalues, since they inherently make assumptions about the data distribution they\nwere trained on. In this paper, we propose a novel framework that classifies\nexamples with missing features by computing the expected prediction with\nrespect to a feature distribution. Moreover, we use geometric programming to\nlearn a naive Bayes distribution that embeds a given logistic regression\nclassifier and can efficiently take its expected predictions. Empirical\nevaluations show that our model achieves the same performance as the logistic\nregression with all features observed, and outperforms standard imputation\ntechniques when features go missing during prediction time. Furthermore, we\ndemonstrate that our method can be used to generate \"sufficient explanations\"\nof logistic regression classifications, by removing features that do not affect\nthe classification.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 01:16:10 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 19:36:26 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Khosravi", "Pasha", ""], ["Liang", "Yitao", ""], ["Choi", "YooJung", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1903.01666", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Xiaojin Zhu, Laurent Lessard", "title": "Online Data Poisoning Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study data poisoning attacks in the online setting where training items\narrive sequentially, and the attacker may perturb the current item to\nmanipulate online learning. Importantly, the attacker has no knowledge of\nfuture training items nor the data generating distribution. We formulate online\ndata poisoning attack as a stochastic optimal control problem, and solve it\nwith model predictive control and deep reinforcement learning. We also upper\nbound the suboptimality suffered by the attacker for not knowing the data\ngenerating distribution. Experiments validate our control approach in\ngenerating near-optimal attacks on both supervised and unsupervised learning\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 04:50:56 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 23:02:31 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""], ["Lessard", "Laurent", ""]]}, {"id": "1903.01669", "submitter": "Vijaya Sai Krishna Gottipati", "authors": "Sai Krishna, Keehong Seo, Dhaivat Bhatt, Vincent Mai, Krishna Murthy,\n  Liam Paull", "title": "Deep Active Localization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Active localization is the problem of generating robot actions that allow it\nto maximally disambiguate its pose within a reference map. Traditional\napproaches to this use an information-theoretic criterion for action selection\nand hand-crafted perceptual models. In this work we propose an end-to-end\ndifferentiable method for learning to take informative actions that is\ntrainable entirely in simulation and then transferable to real robot hardware\nwith zero refinement. The system is composed of two modules: a convolutional\nneural network for perception, and a deep reinforcement learned planning\nmodule. We introduce a multi-scale approach to the learned perceptual model\nsince the accuracy needed to perform action selection with reinforcement\nlearning is much less than the accuracy needed for robot control. We\ndemonstrate that the resulting system outperforms using the traditional\napproach for either perception or planning. We also demonstrate our approaches\nrobustness to different map configurations and other nuisance parameters\nthrough the use of domain randomization in training. The code is also\ncompatible with the OpenAI gym framework, as well as the Gazebo simulator.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 05:00:08 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Krishna", "Sai", ""], ["Seo", "Keehong", ""], ["Bhatt", "Dhaivat", ""], ["Mai", "Vincent", ""], ["Murthy", "Krishna", ""], ["Paull", "Liam", ""]]}, {"id": "1903.01672", "submitter": "Biwei Huang", "authors": "Biwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Ruben\n  Sanchez-Romero, Clark Glymour, Bernhard Sch\\\"olkopf", "title": "Causal Discovery from Heterogeneous/Nonstationary Data with Independent\n  Changes", "comments": null, "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-53", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonplace to encounter heterogeneous or nonstationary data, of which\nthe underlying generating process changes across domains or over time. Such a\ndistribution shift feature presents both challenges and opportunities for\ncausal discovery. In this paper, we develop a framework for causal discovery\nfrom such data, called Constraint-based causal Discovery from\nheterogeneous/NOnstationary Data (CD-NOD), to find causal skeleton and\ndirections and estimate the properties of mechanism changes. First, we propose\nan enhanced constraint-based procedure to detect variables whose local\nmechanisms change and recover the skeleton of the causal structure over\nobserved variables. Second, we present a method to determine causal\norientations by making use of independent changes in the data distribution\nimplied by the underlying causal model, benefiting from information carried by\nchanging distributions. After learning the causal structure, next, we\ninvestigate how to efficiently estimate the \"driving force\" of the\nnonstationarity of a causal mechanism. That is, we aim to extract from data a\nlow-dimensional representation of changes. The proposed methods are\nnonparametric, with no hard restrictions on data distributions and causal\nmechanisms, and do not rely on window segmentation. Furthermore, we find that\ndata heterogeneity benefits causal structure identification even with\nparticular types of confounders. Finally, we show the connection between\nheterogeneity/nonstationarity and soft intervention in causal discovery.\nExperimental results on various synthetic and real-world data sets (task-fMRI\nand stock market data) are presented to demonstrate the efficacy of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 05:07:13 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 14:22:19 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 02:24:19 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 14:23:55 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 14:39:01 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Huang", "Biwei", ""], ["Zhang", "Kun", ""], ["Zhang", "Jiji", ""], ["Ramsey", "Joseph", ""], ["Sanchez-Romero", "Ruben", ""], ["Glymour", "Clark", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1903.01678", "submitter": "Ruimin Ke", "authors": "Ruimin Ke, Wan Li, Zhiyong Cui, Yinhai Wang", "title": "Two-Stream Multi-Channel Convolutional Neural Network (TM-CNN) for\n  Multi-Lane Traffic Speed Prediction Considering Traffic Volume Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic speed prediction is a critically important component of intelligent\ntransportation systems (ITS). Recently, with the rapid development of deep\nlearning and transportation data science, a growing body of new traffic speed\nprediction models have been designed, which achieved high accuracy and\nlarge-scale prediction. However, existing studies have two major limitations.\nFirst, they predict aggregated traffic speed rather than lane-level traffic\nspeed; second, most studies ignore the impact of other traffic flow parameters\nin speed prediction. To address these issues, we propose a two-stream\nmulti-channel convolutional neural network (TM-CNN) model for multi-lane\ntraffic speed prediction considering traffic volume impact. In this model, we\nfirst introduce a new data conversion method that converts raw traffic speed\ndata and volume data into spatial-temporal multi-channel matrices. Then we\ncarefully design a two-stream deep neural network to effectively learn the\nfeatures and correlations between individual lanes, in the spatial-temporal\ndimensions, and between speed and volume. Accordingly, a new loss function that\nconsiders the volume impact in speed prediction is developed. A case study\nusing one-year data validates the TM-CNN model and demonstrates its\nsuperiority. This paper contributes to two research areas: (1) traffic speed\nprediction, and (2) multi-lane traffic flow study.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 05:31:12 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Ke", "Ruimin", ""], ["Li", "Wan", ""], ["Cui", "Zhiyong", ""], ["Wang", "Yinhai", ""]]}, {"id": "1903.01680", "submitter": "Daniel Andrade", "authors": "Daniel Andrade, Kenji Fukumizu, Yuzuru Okajima", "title": "Convex Covariate Clustering for Classification", "comments": "Under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering, like covariate selection for classification, is an important step\nto compress and interpret the data. However, clustering of covariates is often\nperformed independently of the classification step, which can lead to\nundesirable clustering results that harm interpretability and compression rate.\nTherefore, we propose a method that can cluster covariates while taking into\naccount class label information of samples. We formulate the problem as a\nconvex optimization problem which uses both, a-priori similarity information\nbetween covariates, and information from class-labeled samples. Like ordinary\nconvex clustering [Chi and Lange, 2015], the proposed method offers a unique\nglobal minima making it insensitive to initialization. In order to solve the\nconvex problem, we propose a specialized alternating direction method of\nmultipliers (ADMM), which scales up to several thousands of variables.\nFurthermore, in order to circumvent computationally expensive cross-validation,\nwe propose a model selection criterion based on approximating the marginal\nlikelihood. Experiments on synthetic and real data confirm the usefulness of\nthe proposed clustering method and the selection criterion.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 05:36:43 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 02:21:23 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Andrade", "Daniel", ""], ["Fukumizu", "Kenji", ""], ["Okajima", "Yuzuru", ""]]}, {"id": "1903.01689", "submitter": "Yifan Wu", "authors": "Yifan Wu, Ezra Winston, Divyansh Kaushik, Zachary Lipton", "title": "Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation addresses the common problem when the target distribution\ngenerating our test data drifts from the source (training) distribution. While\nabsent assumptions, domain adaptation is impossible, strict conditions, e.g.\ncovariate or label shift, enable principled algorithms. Recently-proposed\ndomain-adversarial approaches consist of aligning source and target encodings,\noften motivating this approach as minimizing two (of three) terms in a\ntheoretical bound on target error. Unfortunately, this minimization can cause\narbitrary increases in the third term, e.g. they can break down under shifting\nlabel distributions. We propose asymmetrically-relaxed distribution alignment,\na new approach that overcomes some limitations of standard domain-adversarial\nalgorithms. Moreover, we characterize precise assumptions under which our\nalgorithm is theoretically principled and demonstrate empirical benefits on\nboth synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 06:11:07 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 21:25:26 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Wu", "Yifan", ""], ["Winston", "Ezra", ""], ["Kaushik", "Divyansh", ""], ["Lipton", "Zachary", ""]]}, {"id": "1903.01707", "submitter": "Yang Li", "authors": "Yang Li, Kevin Korb, Lloyd Allison", "title": "The Complexity of Morality: Checking Markov Blanket Consistency with\n  DAGs via Morality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A family of Markov blankets in a faithful Bayesian network satisfies the\nsymmetry and consistency properties. In this paper, we draw a bijection between\nfamilies of consistent Markov blankets and moral graphs. We define the new\nconcepts of weak recursive simpliciality and perfect elimination kits. We prove\nthat they are equivalent to graph morality. In addition, we prove that morality\ncan be decided in polynomial time for graphs with maximum degree less than $5$,\nbut the problem is NP-complete for graphs with higher maximum degrees.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:39:46 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Li", "Yang", ""], ["Korb", "Kevin", ""], ["Allison", "Lloyd", ""]]}, {"id": "1903.01730", "submitter": "R\\'emi Domingues", "authors": "R\\'emi Domingues", "title": "Probabilistic Modeling for Novelty Detection with Applications to Fraud\n  Identification", "comments": "PhD thesis; 167 pages, 40 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novelty detection is the unsupervised problem of identifying anomalies in\ntest data which significantly differ from the training set. Novelty detection\nis one of the classic challenges in Machine Learning and a core component of\nseveral research areas such as fraud detection, intrusion detection, medical\ndiagnosis, data cleaning, and fault prevention. While numerous algorithms were\ndesigned to address this problem, most methods are only suitable to model\ncontinuous numerical data. Tackling datasets composed of mixed-type features,\nsuch as numerical and categorical data, or temporal datasets describing\ndiscrete event sequences is a challenging task. In addition to the supported\ndata types, the key criteria for efficient novelty detection methods are the\nability to accurately dissociate novelties from nominal samples, the\ninterpretability, the scalability and the robustness to anomalies located in\nthe training data.\n  In this thesis, we investigate novel ways to tackle these issues. In\nparticular, we propose (i) an experimental comparison of novelty detection\nmethods for mixed-type data (ii) an experimental comparison of novelty\ndetection methods for sequence data, (iii) a probabilistic nonparametric\nnovelty detection method for mixed-type data based on Dirichlet process\nmixtures and exponential-family distributions and (iv) an autoencoder-based\nnovelty detection model with encoder/decoder modelled as deep Gaussian\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 08:54:24 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Domingues", "R\u00e9mi", ""]]}, {"id": "1903.01734", "submitter": "Jiaqiyu Zhan", "authors": "Jiaqiyu Zhan, Zhiqiang Bai, Yuesheng Zhu", "title": "A Novel Efficient Approach with Data-Adaptive Capability for OMP-based\n  Sparse Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal Matching Pursuit (OMP) plays an important role in data science and\nits applications such as sparse subspace clustering and image processing.\nHowever, the existing OMP-based approaches lack of data adaptiveness so that\nthe data cannot be represented well enough and may lose the accuracy. This\npaper proposes a novel approach to enhance the data-adaptive capability for\nOMP-based sparse subspace clustering. In our method a parameter selection\nprocess is developed to adjust the parameters based on the data distribution\nfor information representation. Our theoretical analysis indicates that the\nparameter selection process can efficiently coordinate with any OMP-based\nmethods to improve the clustering performance. Also a new\nSelf-Expressive-Affinity (SEA) ratio metric is defined to measure the sparse\nrepresentation conversion efficiency for spectral clustering to obtain data\nsegmentations. Our experiments show that proposed approach can achieve better\nperformances compared with other OMP-based sparse subspace clustering\nalgorithms in terms of clustering accuracy, SEA ratio and representation\nquality, also keep the time efficiency and anti-noise ability.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:00:58 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 09:32:37 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zhan", "Jiaqiyu", ""], ["Bai", "Zhiqiang", ""], ["Zhu", "Yuesheng", ""]]}, {"id": "1903.01747", "submitter": "Ziyu Liu", "authors": "Ziyu Liu, Meng Zhou, Weiqing Cao, Qiang Qu, Henry Wing Fung Yeung,\n  Vera Yuk Ying Chung", "title": "Towards Understanding Chinese Checkers with Heuristics, Monte Carlo Tree\n  Search, and Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of Chinese Checkers is a challenging traditional board game of\nperfect information that differs from other traditional games in two main\naspects: first, unlike Chess, all checkers remain indefinitely in the game and\nhence the branching factor of the search tree does not decrease as the game\nprogresses; second, unlike Go, there are also no upper bounds on the depth of\nthe search tree since repetitions and backward movements are allowed.\nTherefore, even in a restricted game instance, the state-space of the game can\nstill be unbounded, making it challenging for a computer program to excel. In\nthis work, we present an approach that effectively combines the use of\nheuristics, Monte Carlo tree search, and deep reinforcement learning for\nbuilding a Chinese Checkers agent without the use of any human game-play data.\nExperiment results show that our agent is competent under different scenarios\nand reaches the level of experienced human players.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:44:22 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 12:35:10 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Liu", "Ziyu", ""], ["Zhou", "Meng", ""], ["Cao", "Weiqing", ""], ["Qu", "Qiang", ""], ["Yeung", "Henry Wing Fung", ""], ["Chung", "Vera Yuk Ying", ""]]}, {"id": "1903.01777", "submitter": "Amedeo Esposito", "authors": "Amedeo Roberto Esposito, Michael Gastpar, Ibrahim Issa", "title": "A New Approach to Adaptive Data Analysis and Learning via Maximal\n  Leakage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing concern that most current published research findings\nare false. The main cause seems to lie in the fundamental disconnection between\ntheory and practice in data analysis. While the former typically relies on\nstatistical independence, the latter is an inherently adaptive process: new\nhypotheses are formulated based on the outcomes of previous analyses. A recent\nline of work tries to mitigate these issues by enforcing constraints, such as\ndifferential privacy, that compose adaptively while degrading gracefully and\nthus provide statistical guarantees even in adaptive contexts. Our contribution\nconsists in the introduction of a new approach, based on the concept of Maximal\nLeakage, an information-theoretic measure of leakage of information. The main\nresult allows us to compare the probability of an event happening when\nadaptivity is considered with respect to the non-adaptive scenario. The bound\nwe derive represents a generalization of the bounds used in non-adaptive\nscenarios (e.g., McDiarmid's inequality for $c$-sensitive functions, false\ndiscovery error control via significance level, etc.), and allows us to\nreplicate or even improve, in certain regimes, the results obtained using\nMax-Information or Differential Privacy. In contrast with the line of work\nstarted by Dwork et al., our results do not rely on Differential Privacy but\nare, in principle, applicable to every algorithm that has a bounded leakage,\nincluding the differentially private algorithms and the ones with a short\ndescription length.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 11:59:06 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Esposito", "Amedeo Roberto", ""], ["Gastpar", "Michael", ""], ["Issa", "Ibrahim", ""]]}, {"id": "1903.01818", "submitter": "Khanh Hien Le", "authors": "Le Thi Khanh Hien, Nicolas Gillis, Panagiotis Patrinos", "title": "Inertial Block Proximal Methods for Non-Convex Non-Smooth Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose inertial versions of block coordinate descent methods for solving\nnon-convex non-smooth composite optimization problems. Our methods possess\nthree main advantages compared to current state-of-the-art accelerated\nfirst-order methods: (1) they allow using two different extrapolation points to\nevaluate the gradients and to add the inertial force (we will empirically show\nthat it is more efficient than using a single extrapolation point), (2) they\nallow to randomly picking the block of variables to update, and (3) they do not\nrequire a restarting step. We prove the subsequential convergence of the\ngenerated sequence under mild assumptions, prove the global convergence under\nsome additional assumptions, and provide convergence rates. We deploy the\nproposed methods to solve non-negative matrix factorization (NMF) and show that\nthey compete favorably with the state-of-the-art NMF algorithms. Additional\nexperiments on non-negative approximate canonical polyadic decomposition, also\nknown as non-negative tensor factorization, are also provided.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 13:39:06 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 13:17:16 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 21:20:23 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Hien", "Le Thi Khanh", ""], ["Gillis", "Nicolas", ""], ["Patrinos", "Panagiotis", ""]]}, {"id": "1903.01867", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Multiple-Kernel Dictionary Learning for Reconstruction and Clustering of\n  Unseen Multivariate Time-series", "comments": "6 pages, ESANN 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist many approaches for description and recognition of unseen classes\nin datasets. Nevertheless, it becomes a challenging problem when we deal with\nmultivariate time-series (MTS) (e.g., motion data), where we cannot apply the\nvectorial algorithms directly to the inputs. In this work, we propose a novel\nmultiple-kernel dictionary learning (MKD) which learns semantic attributes\nbased on specific combinations of MTS dimensions in the feature space. Hence,\nMKD can fully/partially reconstructs the unseen classes based on the training\ndata (seen classes). Furthermore, we obtain sparse encodings for unseen classes\nbased on the learned MKD attributes, and upon which we propose a simple but\neffective incremental clustering algorithm to categorize the unseen MTS classes\nin an unsupervised way. According to the empirical evaluation of our MKD\nframework on real benchmarks, it provides an interpretable reconstruction of\nunseen MTS data as well as a high performance regarding their online\nclustering.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 14:53:15 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 10:32:48 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 21:31:04 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.01868", "submitter": "Giovanni Parmigiani", "authors": "Giovanni Parmigiani", "title": "The Fuzzy ROC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fuzzy ROC extends Receiver Operating Curve (ROC) visualization to the\nsituation where some data points, falling in an indeterminacy region, are not\nclassified. It addresses two challenges: definition of sensitivity and\nspecificity bounds under indeterminacy; and visual summarization of the large\nnumber of possibilities arising from different choices of indeterminacy zones.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:32:10 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Parmigiani", "Giovanni", ""]]}, {"id": "1903.01879", "submitter": "Irene Unceta", "authors": "Irene Unceta, Jordi Nin, Oriol Pujol", "title": "Copying Machine Learning Classifiers", "comments": "22 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model-agnostic copies of machine learning classifiers. We develop\nthe theory behind the problem of copying, highlighting its differences with\nthat of learning, and propose a framework to copy the functionality of any\nclassifier using no prior knowledge of its parameters or training data\ndistribution. We identify the different sources of loss and provide guidelines\non how best to generate synthetic sets for the copying process. We further\nintroduce a set of metrics to evaluate copies in practice. We validate our\nframework through extensive experiments using data from a series of well-known\nproblems. We demonstrate the value of copies in use cases where desiderata such\nas interpretability, fairness or productivization constrains need to be\naddressed. Results show that copies can be exploited to enhance existing\nsolutions and improve them adding new features and characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 15:03:37 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 16:23:58 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Unceta", "Irene", ""], ["Nin", "Jordi", ""], ["Pujol", "Oriol", ""]]}, {"id": "1903.01882", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Brenden M. Lake", "title": "Learning a smooth kernel regularizer for convolutional neural networks", "comments": "Submitted to CogSci 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural networks require a tremendous amount of data to train,\noften needing hundreds or thousands of labeled examples to learn an effective\nrepresentation. For these networks to work with less data, more structure must\nbe built into their architectures or learned from previous experience. The\nlearned weights of convolutional neural networks (CNNs) trained on large\ndatasets for object recognition contain a substantial amount of structure.\nThese representations have parallels to simple cells in the primary visual\ncortex, where receptive fields are smooth and contain many regularities.\nIncorporating smoothness constraints over the kernel weights of modern CNN\narchitectures is a promising way to improve their sample complexity. We propose\na smooth kernel regularizer that encourages spatial correlations in convolution\nkernel weights. The correlation parameters of this regularizer are learned from\nprevious experience, yielding a method with a hierarchical Bayesian\ninterpretation. We show that our correlated regularizer can help constrain\nmodels for visual recognition, improving over an L2 regularization baseline.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 15:07:29 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Feinman", "Reuben", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1903.01886", "submitter": "Simyung Chang", "authors": "Simyung Chang, John Yang, Jaeseok Choi, Nojun Kwak", "title": "Genetic-Gated Networks for Deep Reinforcement", "comments": null, "journal-ref": null, "doi": null, "report-no": "14pages, This paper is accepted at NIPS 2018", "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Genetic-Gated Networks (G2Ns), simple neural networks that\ncombine a gate vector composed of binary genetic genes in the hidden layer(s)\nof networks. Our method can take both advantages of gradient-free optimization\nand gradient-based optimization methods, of which the former is effective for\nproblems with multiple local minima, while the latter can quickly find local\nminima. In addition, multiple chromosomes can define different models, making\nit easy to construct multiple models and can be effectively applied to problems\nthat require multiple models. We show that this G2N can be applied to typical\nreinforcement learning algorithms to achieve a large improvement in sample\nefficiency and performance.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 21:56:05 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Chang", "Simyung", ""], ["Yang", "John", ""], ["Choi", "Jaeseok", ""], ["Kwak", "Nojun", ""]]}, {"id": "1903.01888", "submitter": "Luana Ruiz", "authors": "Luana Ruiz, Fernando Gama and Alejandro Ribeiro", "title": "Gated Graph Convolutional Recurrent Neural Networks", "comments": "Accepted at EUSIPCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph processes model a number of important problems such as identifying the\nepicenter of an earthquake or predicting weather. In this paper, we propose a\nGraph Convolutional Recurrent Neural Network (GCRNN) architecture specifically\ntailored to deal with these problems. GCRNNs use convolutional filter banks to\nkeep the number of trainable parameters independent of the size of the graph\nand of the time sequences considered. We also put forward Gated GCRNNs, a\ntime-gated variation of GCRNNs akin to LSTMs. When compared with GNNs and\nanother graph recurrent architecture in experiments using both synthetic and\nreal-word data, GCRNNs significantly improve performance while using\nconsiderably less parameters.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 15:13:02 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 14:15:19 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 14:55:04 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Ruiz", "Luana", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1903.01895", "submitter": "Marijn Van Knippenberg", "authors": "Marijn van Knippenberg, Vlado Menkovski, Sergio Consoli", "title": "Evolutionary Construction of Convolutional Neural Networks", "comments": null, "journal-ref": "Springer Lecture Notes in Computer Science 11331 (2018) 293-304", "doi": "10.1007/978-3-030-13709-0_25", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuro-Evolution is a field of study that has recently gained significantly\nincreased traction in the deep learning community. It combines deep neural\nnetworks and evolutionary algorithms to improve and/or automate the\nconstruction of neural networks. Recent Neuro-Evolution approaches have shown\npromising results, rivaling hand-crafted neural networks in terms of accuracy.\nA two-step approach is introduced where a convolutional autoencoder is created\nthat efficiently compresses the input data in the first step, and a\nconvolutional neural network is created to classify the compressed data in the\nsecond step. The creation of networks in both steps is guided by by an\nevolutionary process, where new networks are constantly being generated by\nmutating members of a collection of existing networks. Additionally, a method\nis introduced that considers the trade-off between compression and information\nloss of different convolutional autoencoders. This is used to select the\noptimal convolutional autoencoder from among those evolved to compress the data\nfor the second step. The complete framework is implemented, tested on the\npopular CIFAR-10 data set, and the results are discussed. Finally, a number of\npossible directions for future work with this particular framework in mind are\nconsidered, including opportunities to improve its efficiency and its\napplication in particular areas.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 12:30:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["van Knippenberg", "Marijn", ""], ["Menkovski", "Vlado", ""], ["Consoli", "Sergio", ""]]}, {"id": "1903.01930", "submitter": "Matteo Stefanini", "authors": "Matteo Stefanini, Riccardo Lancellotti, Lorenzo Baraldi, Simone\n  Calderara", "title": "A Deep Learning based approach to VM behavior identification in cloud\n  systems", "comments": "Accepted at CLOSER2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing data centers are growing in size and complexity to the point\nwhere monitoring and management of the infrastructure become a challenge due to\nscalability issues. A possible approach to cope with the size of such data\ncenters is to identify VMs exhibiting a similar behavior. Existing literature\ndemonstrated that clustering together VMs that show a similar behavior may\nimprove the scalability of both monitoring andmanagement of a data center.\nHowever, available techniques suffer from a trade-off between accuracy and time\nto achieve this result. Throughout this paper we propose a different approach\nwhere, instead of an unsupervised clustering, we rely on classifiers based on\ndeep learning techniques to assigna newly deployed VMs to a cluster of\nalready-known VMs. The two proposed classifiers, namely DeepConv and DeepFFT\nuse a convolution neural network and (in the latter model) exploits Fast\nFourier Transformation to classify the VMs. Our proposal is validated using a\nset of traces describing the behavior of VMs from a realcloud data center. The\nexperiments compare our proposal with state-of-the-art solutions available in\nliterature, demonstrating that our proposal achieve better performance.\nFurthermore, we show that our solution issignificantly faster than the\nalternatives as it can produce a perfect classification even with just a few\nsamples of data, making our proposal viable also toclassify on-demand VMs that\nare characterized by a short life span.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 16:49:00 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Stefanini", "Matteo", ""], ["Lancellotti", "Riccardo", ""], ["Baraldi", "Lorenzo", ""], ["Calderara", "Simone", ""]]}, {"id": "1903.01939", "submitter": "Yuuki Takai", "authors": "Akiyoshi Sannai, Yuuki Takai, Matthieu Cordonnier", "title": "Universal approximations of permutation invariant/equivariant functions\n  by deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a theory about the relationship between\n$G$-invariant/equivariant functions and deep neural networks for finite group\n$G$. Especially, for a given $G$-invariant/equivariant function, we construct\nits universal approximator by deep neural network whose layers equip\n$G$-actions and each affine transformations are $G$-equivariant/invariant. Due\nto representation theory, we can show that this approximator has exponentially\nfewer free parameters than usual models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 17:17:02 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 08:12:15 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 05:43:19 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Sannai", "Akiyoshi", ""], ["Takai", "Yuuki", ""], ["Cordonnier", "Matthieu", ""]]}, {"id": "1903.01944", "submitter": "Chao Gao", "authors": "Chao Gao, Yuan Yao, Weizhi Zhu", "title": "Generative Adversarial Nets for Robust Scatter Estimation: A Proper\n  Scoring Rule Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust scatter estimation is a fundamental task in statistics. The recent\ndiscovery on the connection between robust estimation and generative\nadversarial nets (GANs) by Gao et al. (2018) suggests that it is possible to\ncompute depth-like robust estimators using similar techniques that optimize\nGANs. In this paper, we introduce a general learning via classification\nframework based on the notion of proper scoring rules. This framework allows us\nto understand both matrix depth function and various GANs through the lens of\nvariational approximations of $f$-divergences induced by proper scoring rules.\nWe then propose a new class of robust scatter estimators in this framework by\ncarefully constructing discriminators with appropriate neural network\nstructures. These estimators are proved to achieve the minimax rate of scatter\nestimation under Huber's contamination model. Our numerical results demonstrate\nits good performance under various settings against competitors in the\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 17:29:04 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Gao", "Chao", ""], ["Yao", "Yuan", ""], ["Zhu", "Weizhi", ""]]}, {"id": "1903.01969", "submitter": "Saeed Amizadeh", "authors": "Saeed Amizadeh, Sergiy Matusevych, Markus Weimer", "title": "PDP: A General Neural Framework for Learning Constraint Satisfaction\n  Solvers", "comments": "Neuro-symbolic Methods, Neural Combinatorial Optimization, Geometric\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been recent efforts for incorporating Graph Neural Network models\nfor learning full-stack solvers for constraint satisfaction problems (CSP) and\nparticularly Boolean satisfiability (SAT). Despite the unique representational\npower of these neural embedding models, it is not clear how the search strategy\nin the learned models actually works. On the other hand, by fixing the search\nstrategy (e.g. greedy search), we would effectively deprive the neural models\nof learning better strategies than those given. In this paper, we propose a\ngeneric neural framework for learning CSP solvers that can be described in\nterms of probabilistic inference and yet learn search strategies beyond greedy\nsearch. Our framework is based on the idea of propagation, decimation and\nprediction (and hence the name PDP) in graphical models, and can be trained\ndirectly toward solving CSP in a fully unsupervised manner via energy\nminimization, as shown in the paper. Our experimental results demonstrate the\neffectiveness of our framework for SAT solving compared to both neural and the\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:26:33 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Amizadeh", "Saeed", ""], ["Matusevych", "Sergiy", ""], ["Weimer", "Markus", ""]]}, {"id": "1903.01980", "submitter": "Matthew Wicker", "authors": "Luca Cardelli, Marta Kwiatkowska, Luca Laurenti, Nicola Paoletti,\n  Andrea Patane, and Matthew Wicker", "title": "Statistical Guarantees for the Robustness of Bayesian Neural Networks", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a probabilistic robustness measure for Bayesian Neural Networks\n(BNNs), defined as the probability that, given a test point, there exists a\npoint within a bounded set such that the BNN prediction differs between the\ntwo. Such a measure can be used, for instance, to quantify the probability of\nthe existence of adversarial examples. Building on statistical verification\ntechniques for probabilistic models, we develop a framework that allows us to\nestimate probabilistic robustness for a BNN with statistical guarantees, i.e.,\nwith a priori error and confidence bounds. We provide experimental comparison\nfor several approximate BNN inference techniques on image classification tasks\nassociated to MNIST and a two-class subset of the GTSRB dataset. Our results\nenable quantification of uncertainty of BNN predictions in adversarial\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:49:40 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Cardelli", "Luca", ""], ["Kwiatkowska", "Marta", ""], ["Laurenti", "Luca", ""], ["Paoletti", "Nicola", ""], ["Patane", "Andrea", ""], ["Wicker", "Matthew", ""]]}, {"id": "1903.01997", "submitter": "Masayoshi Kubo", "authors": "Masayoshi Kubo, Ryotaro Banno, Hidetaka Manabe and Masataka Minoji", "title": "Implicit Regularization in Over-parameterized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized neural networks generalize well in practice without any\nexplicit regularization. Although it has not been proven yet, empirical\nevidence suggests that implicit regularization plays a crucial role in deep\nlearning and prevents the network from overfitting. In this work, we introduce\nthe gradient gap deviation and the gradient deflection as statistical measures\ncorresponding to the network curvature and the Hessian matrix to analyze\nvariations of network derivatives with respect to input parameters, and\ninvestigate how implicit regularization works in ReLU neural networks from both\ntheoretical and empirical perspectives. Our result reveals that the network\noutput between each pair of input samples is properly controlled by random\ninitialization and stochastic gradient descent to keep interpolating between\nsamples almost straight, which results in low complexity of over-parameterized\nneural networks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:00:01 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Kubo", "Masayoshi", ""], ["Banno", "Ryotaro", ""], ["Manabe", "Hidetaka", ""], ["Minoji", "Masataka", ""]]}, {"id": "1903.01998", "submitter": "Hongyu Shen", "authors": "Hongyu Shen, E. A. Huerta, Eamonn O'Shea, Prayush Kumar, Zhizhen Zhao", "title": "Statistically-informed deep learning for gravitational wave parameter\n  estimation", "comments": "v3: 14 pages, 6 figures, First application of Neural Networks for\n  gravitational wave parameter posterior estimation across multiple events with\n  single training", "journal-ref": null, "doi": null, "report-no": null, "categories": "gr-qc astro-ph.HE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep learning models for gravitational wave parameter estimation\nthat combine a modified $\\texttt{WaveNet}$ architecture with\n$\\textit{constrastive learning}$ and $\\textit{normalizing flow}$. To ascertain\nthe statistical consistency of these models, we validated their predictions\nagainst a Gaussian conjugate prior family whose posterior distribution is\ndescribed by a closed analytical expression. Upon confirming that our models\nproduce statistically consistent results, we used them to estimate the\nastrophysical parameters of five binary black holes: $\\texttt{GW150914}$,\n$\\texttt{GW170104}$, $\\texttt{GW170814}$, $\\texttt{GW190521}$ and\n$\\texttt{GW190630}$. Our findings indicate that our deep learning approach\npredicts posterior distributions that encode physical correlations, and that\nour data-driven median results and $90\\%$ confidence intervals are consistent\nwith those obtained with gravitational wave Bayesian analyses. This methodology\nrequires a single V100 $\\texttt{NVIDIA}$ GPU to produce median values and\nposterior distributions within two milliseconds for each event. This neural\nnetwork, and a tutorial for its use, are available at the $\\texttt{Data and\nLearning Hub for Science}$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:00:02 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 17:39:55 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 01:48:35 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Shen", "Hongyu", ""], ["Huerta", "E. A.", ""], ["O'Shea", "Eamonn", ""], ["Kumar", "Prayush", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1903.02013", "submitter": "Michael Wojnowicz", "authors": "Michael Thomas Wojnowicz and Xuan Zhao", "title": "PROPS: Probabilistic personalization of black-box sequence models", "comments": null, "journal-ref": "2018 IEEE International Conference on Big Data (Big Data),\n  4768-4774", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PROPS, a lightweight transfer learning mechanism for sequential\ndata. PROPS learns probabilistic perturbations around the predictions of one or\nmore arbitrarily complex, pre-trained black box models (such as recurrent\nneural networks). The technique pins the black-box prediction functions to\n\"source nodes\" of a hidden Markov model (HMM), and uses the remaining nodes as\n\"perturbation nodes\" for learning customized perturbations around those\npredictions. In this paper, we describe the PROPS model, provide an algorithm\nfor online learning of its parameters, and demonstrate the consistency of this\nestimation. We also explore the utility of PROPS in the context of personalized\nlanguage modeling. In particular, we construct a baseline language model by\ntraining a LSTM on the entire Wikipedia corpus of 2.5 million articles (around\n6.6 billion words), and then use PROPS to provide lightweight customization\ninto a personalized language model of President Donald J. Trump's tweeting. We\nachieved good customization after only 2,000 additional words, and find that\nthe PROPS model, being fully probabilistic, provides insight into when\nPresident Trump's speech departs from generic patterns in the Wikipedia corpus.\nPython code (for both the PROPS training algorithm as well as experiment\nreproducibility) is available at\nhttps://github.com/cylance/perturbed-sequence-model.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:02:11 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Wojnowicz", "Michael Thomas", ""], ["Zhao", "Xuan", ""]]}, {"id": "1903.02020", "submitter": "Prasoon Goyal", "authors": "Prasoon Goyal, Scott Niekum, Raymond J. Mooney", "title": "Using Natural Language for Reward Shaping in Reinforcement Learning", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reinforcement learning (RL) approaches have shown strong performance\nin complex domains such as Atari games, but are often highly sample\ninefficient. A common approach to reduce interaction time with the environment\nis to use reward shaping, which involves carefully designing reward functions\nthat provide the agent intermediate rewards for progress towards the goal.\nHowever, designing appropriate shaping rewards is known to be difficult as well\nas time-consuming. In this work, we address this problem by using natural\nlanguage instructions to perform reward shaping. We propose the LanguagE-Action\nReward Network (LEARN), a framework that maps free-form natural language\ninstructions to intermediate rewards based on actions taken by the agent. These\nintermediate language-based rewards can seamlessly be integrated into any\nstandard reinforcement learning algorithm. We experiment with Montezuma's\nRevenge from the Atari Learning Environment, a popular benchmark in RL. Our\nexperiments on a diverse set of 15 tasks demonstrate that, for the same number\nof interactions with the environment, language-based rewards lead to successful\ncompletion of the task 60% more often on average, compared to learning without\nlanguage.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:20:35 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 04:58:07 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Goyal", "Prasoon", ""], ["Niekum", "Scott", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1903.02048", "submitter": "Xiaowei Xu", "authors": "Xiaowei Xu", "title": "On the Quantization of Cellular Neural Networks for Cyber-Physical\n  Systems", "comments": "14 pages,10 figures", "journal-ref": "TC-CCPS Newsletter, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPSs) have been pervasive including smart grid,\nautonomous automobile systems, medical monitoring, process control systems,\nrobotics systems, and automatic pilot avionics. As usually implemented on\nembedded devices, CPS is typically constrained by computation capacity and\nenergy consumption. In some CPS applications such as telemedicine and advanced\ndriving assistance system (ADAS), data processing on the embedded devices is\npreferred due to security/safety and real-time requirement. Therefore, high\nefficiency is highly desirable for such CPS applications. In this paper we\npresent CeNN quantization for high-efficient processing for CPS applications,\nparticularly telemedicine and ADAS applications. We systematically put forward\npowers-of-two based incremental quantization of CeNNs for efficient hardware\nimplementation. The incremental quantization contains iterative procedures\nincluding parameter partition, parameter quantization, and re-training. We\npropose five different strategies including random strategy, pruning inspired\nstrategy, weighted pruning inspired strategy, nearest neighbor strategy, and\nweighted nearest neighbor strategy. Experimental results show that our approach\ncan achieve a speedup up to 7.8x with no performance loss compared with the\nstate-of-the-art FPGA solutions for CeNNs.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 20:47:33 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Xu", "Xiaowei", ""]]}, {"id": "1903.02050", "submitter": "Yukun Ding", "authors": "Yukun Ding, Jinglan Liu, Jinjun Xiong, Yiyu Shi", "title": "Revisiting the Evaluation of Uncertainty Estimation and Its Application\n  to Explore Model Complexity-Uncertainty Trade-Off", "comments": "CVPR 2020 - Fair, Data Efficient and Trusted Computer Vision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately estimating uncertainties in neural network predictions is of great\nimportance in building trusted DNNs-based models, and there is an increasing\ninterest in providing accurate uncertainty estimation on many tasks, such as\nsecurity cameras and autonomous driving vehicles. In this paper, we focus on\nthe two main use cases of uncertainty estimation, i.e. selective prediction and\nconfidence calibration. We first reveal potential issues of commonly used\nquality metrics for uncertainty estimation in both use cases, and propose our\nnew metrics to mitigate them. We then apply these new metrics to explore the\ntrade-off between model complexity and uncertainty estimation quality, a\ncritically missing work in the literature. Our empirical experiment results\nvalidate the superiority of the proposed metrics, and some interesting trends\nabout the complexity-uncertainty trade-off are observed.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 21:02:44 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 15:50:52 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 00:06:45 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ding", "Yukun", ""], ["Liu", "Jinglan", ""], ["Xiong", "Jinjun", ""], ["Shi", "Yiyu", ""]]}, {"id": "1903.02054", "submitter": "Karthikeyan Shanmugam", "authors": "Dmitriy Katz, Karthikeyan Shanmugam, Chandler Squires, Caroline Uhler", "title": "Size of Interventional Markov Equivalence Classes in Random DAG Models", "comments": "19 pages, 5 figures. Accepted to AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graph (DAG) models are popular for capturing causal\nrelationships. From observational and interventional data, a DAG model can only\nbe determined up to its \\emph{interventional Markov equivalence class} (I-MEC).\nWe investigate the size of MECs for random DAG models generated by uniformly\nsampling and ordering an Erd\\H{o}s-R\\'{e}nyi graph. For constant density, we\nshow that the expected $\\log$ observational MEC size asymptotically (in the\nnumber of vertices) approaches a constant. We characterize I-MEC size in a\nsimilar fashion in the above settings with high precision. We show that the\nasymptotic expected number of interventions required to fully identify a DAG is\na constant. These results are obtained by exploiting Meek rules and coupling\narguments to provide sharp upper and lower bounds on the asymptotic quantities,\nwhich are then calculated numerically up to high precision. Our results have\nimportant consequences for experimental design of interventions and the\ndevelopment of algorithms for causal inference.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 21:09:37 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Katz", "Dmitriy", ""], ["Shanmugam", "Karthikeyan", ""], ["Squires", "Chandler", ""], ["Uhler", "Caroline", ""]]}, {"id": "1903.02079", "submitter": "Nazeeh Ghatasheh", "authors": "Nazeeh Ghatasheh, Hossam Faris, Ibrahim Aljarah, Rizik M. H. Al-Sayyed", "title": "Optimizing Software Effort Estimation Models Using Firefly Algorithm", "comments": "9 pages", "journal-ref": "Journal of Software Engineering and Applications, 8, 133-142\n  (2018)", "doi": "10.4236/jsea.2015.83014", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software development effort estimation is considered a fundamental task for\nsoftware development life cycle as well as for managing project cost, time and\nquality. Therefore, accurate estimation is a substantial factor in projects\nsuccess and reducing the risks. In recent years, software effort estimation has\nreceived a considerable amount of attention from researchers and became a\nchallenge for software industry. In the last two decades, many researchers and\npractitioners proposed statistical and machine learning-based models for\nsoftware effort estimation. In this work, Firefly Algorithm is proposed as a\nmetaheuristic optimization method for optimizing the parameters of three\nCOCOMO-based models. These models include the basic COCOMO model and other two\nmodels proposed in the literature as extensions of the basic COCOMO model. The\ndeveloped estimation models are evaluated using different evaluation metrics.\nExperimental results show high accuracy and significant error minimization of\nFirefly Algorithm over other metaheuristic optimization algorithms including\nGenetic Algorithms and Particle Swarm Optimization.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 23:34:43 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Ghatasheh", "Nazeeh", ""], ["Faris", "Hossam", ""], ["Aljarah", "Ibrahim", ""], ["Al-Sayyed", "Rizik M. H.", ""]]}, {"id": "1903.02080", "submitter": "Senthil Yogamani", "authors": "Sambit Mohapatra, Heinrich Gotzig, Senthil Yogamani, Stefan Milz and\n  Raoul Zollner", "title": "Exploring Deep Spiking Neural Networks for Automated Driving\n  Applications", "comments": "Accepted for Oral Presentation at VISAPP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become the standard model for various computer vision\ntasks in automated driving including semantic segmentation, moving object\ndetection, depth estimation, visual odometry, etc. The main flavors of neural\nnetworks which are used commonly are convolutional (CNN) and recurrent (RNN).\nIn spite of rapid progress in embedded processors, power consumption and cost\nis still a bottleneck. Spiking Neural Networks (SNNs) are gradually progressing\nto achieve low-power event-driven hardware architecture which has a potential\nfor high efficiency. In this paper, we explore the role of deep spiking neural\nnetworks (SNN) for automated driving applications. We provide an overview of\nprogress on SNN and argue how it can be a good fit for automated driving\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 18:40:42 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Mohapatra", "Sambit", ""], ["Gotzig", "Heinrich", ""], ["Yogamani", "Senthil", ""], ["Milz", "Stefan", ""], ["Zollner", "Raoul", ""]]}, {"id": "1903.02081", "submitter": "Samira Vafay Eslahi", "authors": "Samira Vafay Eslahi, Nader Jafarnia Dabanloo, Keivan Maghooli", "title": "A GA-based feature selection of the EEG signals by classification\n  evaluation: Application in BCI systems", "comments": "12 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In electroencephalogram (EEG) signal processing, finding the appropriate\ninformation from a dataset has been a big challenge for successful signal\nclassification. The feature selection methods make it possible to solve this\nproblem; however, the method selection is still under investigation to find out\nwhich feature can perform the best to extract the most proper features of the\nsignal to improve the classification performance. In this study, we use the\ngenetic algorithm (GA), a heuristic searching algorithm, to find the optimum\ncombination of the feature extraction methods and the classifiers, in the\nbrain-computer interface (BCI) applications. A BCI system can be practical if\nand only if it performs with high accuracy and high speed alongside each other.\nIn the proposed method, GA performs as a searching engine to find the best\ncombination of the features and classifications. The features used here are\nKatz, Higuchi, Petrosian, Sevcik, and box-counting dimension (BCD) feature\nextraction methods. These features are applied to the wavelet subbands and are\nclassified with four classifiers such as adaptive neuro-fuzzy inference system\n(ANFIS), fuzzy k-nearest neighbors (FKNN), support vector machine (SVM) and\nlinear discriminant analysis (LDA). Due to the huge number of features, the GA\noptimization is used to find the features with the optimum fitness value (FV).\nResults reveal that Katz fractal feature estimation method with LDA\nclassification has the best FV. Consequently, due to the low computation time\nof the first Daubechies wavelet transformation in comparison to the original\nsignal, the final selected methods contain the fractal features of the first\ncoefficient of the detail subbands.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 05:31:08 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Eslahi", "Samira Vafay", ""], ["Dabanloo", "Nader Jafarnia", ""], ["Maghooli", "Keivan", ""]]}, {"id": "1903.02082", "submitter": "Yifeng Zhang", "authors": "Yifeng Zhang, Ka-Ho Chow, S.-H. Gary Chan", "title": "DA-LSTM: A Long Short-Term Memory with Depth Adaptive to Non-uniform\n  Information Flow in Sequential Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much sequential data exhibits highly non-uniform information distribution.\nThis cannot be correctly modeled by traditional Long Short-Term Memory (LSTM).\nTo address that, recent works have extended LSTM by adding more activations\nbetween adjacent inputs. However, the approaches often use a fixed depth, which\nis at the step of the most information content. This one-size-fits-all\nworst-case approach is not satisfactory, because when little information is\ndistributed to some steps, shallow structures can achieve faster convergence\nand consume less computation resource. In this paper, we develop a\nDepth-Adaptive Long Short-Term Memory (DA-LSTM) architecture, which can\ndynamically adjust the structure depending on information distribution without\nprior knowledge. Experimental results on real-world datasets show that DA-LSTM\ncosts much less computation resource and substantially reduce convergence time\nby $41.78\\%$ and $46.01 \\%$, compared with Stacked LSTM and Deep Transition\nLSTM, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 14:21:12 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Zhang", "Yifeng", ""], ["Chow", "Ka-Ho", ""], ["Chan", "S. -H. Gary", ""]]}, {"id": "1903.02083", "submitter": "Brian Crafton Mr.", "authors": "Brian Crafton, Abhinav Parihar, Evan Gebhardt, Arijit Raychowdhury", "title": "Direct Feedback Alignment with Sparse Connections for Local Learning", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep neural networks (DNNs) owe their success to training\nalgorithms that use backpropagation and gradient-descent. Backpropagation,\nwhile highly effective on von Neumann architectures, becomes inefficient when\nscaling to large networks. Commonly referred to as the weight transport\nproblem, each neuron's dependence on the weights and errors located deeper in\nthe network require exhaustive data movement which presents a key problem in\nenhancing the performance and energy-efficiency of machine-learning hardware.\nIn this work, we propose a bio-plausible alternative to backpropagation drawing\nfrom advances in feedback alignment algorithms in which the error computation\nat a single synapse reduces to the product of three scalar values. Using a\nsparse feedback matrix, we show that a neuron needs only a fraction of the\ninformation previously used by the feedback alignment algorithms. Consequently,\nmemory and compute can be partitioned and distributed whichever way produces\nthe most efficient forward pass so long as a single error can be delivered to\neach neuron. Our results show orders of magnitude improvement in data movement\nand $2\\times$ improvement in multiply-and-accumulate operations over\nbackpropagation. Like previous work, we observe that any variant of feedback\nalignment suffers significant losses in classification accuracy on deep\nconvolutional neural networks. By transferring trained convolutional layers and\ntraining the fully connected layers using direct feedback alignment, we\ndemonstrate that direct feedback alignment can obtain results competitive with\nbackpropagation. Furthermore, we observe that using an extremely sparse\nfeedback matrix, rather than a dense one, results in a small accuracy drop\nwhile yielding hardware advantages. All the code and results are available\nunder https://github.com/bcrafton/ssdfa.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 16:33:08 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 14:13:29 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Crafton", "Brian", ""], ["Parihar", "Abhinav", ""], ["Gebhardt", "Evan", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "1903.02088", "submitter": "Lucy Vasserman", "authors": "Daniel Borkan, Lucas Dixon, John Li, Jeffrey Sorensen, Nithum Thain,\n  Lucy Vasserman", "title": "Limitations of Pinned AUC for Measuring Unintended Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report examines the Pinned AUC metric introduced and highlights some of\nits limitations. Pinned AUC provides a threshold-agnostic measure of unintended\nbias in a classification model, inspired by the ROC-AUC metric. However, as we\nhighlight in this report, there are ways that the metric can obscure different\nkinds of unintended biases when the underlying class distributions on which\nbias is being measured are not carefully controlled.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 22:18:36 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Borkan", "Daniel", ""], ["Dixon", "Lucas", ""], ["Li", "John", ""], ["Sorensen", "Jeffrey", ""], ["Thain", "Nithum", ""], ["Vasserman", "Lucy", ""]]}, {"id": "1903.02129", "submitter": "Yura Kim", "authors": "Yura Kim, Elizaveta Levina", "title": "Graph-aware Modeling of Brain Connectivity Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional connections in the brain are frequently represented by weighted\nnetworks, with nodes representing locations in the brain, and edges\nrepresenting the strength of connectivity between these locations. One\nchallenge in analyzing such data is that inference at the individual edge level\nis not particularly biologically meaningful; interpretation is more useful at\nthe level of so-called functional regions, or groups of nodes and connections\nbetween them; this is often called \"graph-aware\" inference in the neuroimaging\nliterature. However, pooling over functional regions leads to significant loss\nof information and lower accuracy. Another challenge is correlation among edge\nweights within a subject, which makes inference based on independence\nassumptions unreliable. We address both these challenges with a linear mixed\neffects model, which accounts for functional regions and for edge dependence,\nwhile still modeling individual edge weights to avoid loss of information. The\nmodel allows for comparing two populations, such as patients and healthy\ncontrols, both at the functional regions level and at individual edge level,\nleading to biologically meaningful interpretations. We fit this model to a\nresting state fMRI data on schizophrenics and healthy controls, obtaining\ninterpretable results consistent with the schizophrenia literature.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 00:59:28 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 19:02:22 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Kim", "Yura", ""], ["Levina", "Elizaveta", ""]]}, {"id": "1903.02140", "submitter": "Hui Jiang", "authors": "Hui Jiang", "title": "Why Learning of Large-Scale Neural Networks Behaves Like Convex\n  Optimization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present some theoretical work to explain why simple\ngradient descent methods are so successful in solving non-convex optimization\nproblems in learning large-scale neural networks (NN). After introducing a\nmathematical tool called canonical space, we have proved that the objective\nfunctions in learning NNs are convex in the canonical model space. We further\nelucidate that the gradients between the original NN model space and the\ncanonical space are related by a pointwise linear transformation, which is\nrepresented by the so-called disparity matrix. Furthermore, we have proved that\ngradient descent methods surely converge to a global minimum of zero loss\nprovided that the disparity matrices maintain full rank. If this full-rank\ncondition holds, the learning of NNs behaves in the same way as normal convex\noptimization. At last, we have shown that the chance to have singular disparity\nmatrices is extremely slim in large NNs. In particular, when over-parameterized\nNNs are randomly initialized, the gradient decent algorithms converge to a\nglobal minimum of zero loss in probability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 02:21:37 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Jiang", "Hui", ""]]}, {"id": "1903.02152", "submitter": "Jiangchao Yao", "authors": "Jiangchao Yao, Ya Zhang, Ivor W. Tsang and Jun Sun", "title": "Safeguarded Dynamic Label Regression for Generalized Noisy Supervision", "comments": "Submitted to Transactions on Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with noisy labels, which aims to reduce expensive labors on accurate\nannotations, has become imperative in the Big Data era. Previous noise\ntransition based method has achieved promising results and presented a\ntheoretical guarantee on performance in the case of class-conditional noise.\nHowever, this type of approaches critically depend on an accurate\npre-estimation of the noise transition, which is usually impractical.\nSubsequent improvement adapts the pre-estimation along with the training\nprogress via a Softmax layer. However, the parameters in the Softmax layer are\nhighly tweaked for the fragile performance due to the ill-posed stochastic\napproximation. To address these issues, we propose a Latent Class-Conditional\nNoise model (LCCN) that naturally embeds the noise transition under a Bayesian\nframework. By projecting the noise transition into a Dirichlet-distributed\nspace, the learning is constrained on a simplex based on the whole dataset,\ninstead of some ad-hoc parametric space. We then deduce a dynamic label\nregression method for LCCN to iteratively infer the latent labels, to\nstochastically train the classifier and to model the noise. Our approach\nsafeguards the bounded update of the noise transition, which avoids previous\narbitrarily tuning via a batch of samples. We further generalize LCCN for\nopen-set noisy labels and the semi-supervised setting. We perform extensive\nexperiments with the controllable noise data sets, CIFAR-10 and CIFAR-100, and\nthe agnostic noise data sets, Clothing1M and WebVision17. The experimental\nresults have demonstrated that the proposed model outperforms several\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:20:09 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Yao", "Jiangchao", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor W.", ""], ["Sun", "Jun", ""]]}, {"id": "1903.02154", "submitter": "Qingcan Wang", "authors": "Weinan E, Chao Ma, Qingcan Wang", "title": "A Priori Estimates of the Population Risk for Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal a priori estimates are derived for the population risk, also known as\nthe generalization error, of a regularized residual network model. An important\npart of the regularized model is the usage of a new path norm, called the\nweighted path norm, as the regularization term. The weighted path norm treats\nthe skip connections and the nonlinearities differently so that paths with more\nnonlinearities are regularized by larger weights. The error estimates are a\npriori in the sense that the estimates depend only on the target function, not\non the parameters obtained in the training process. The estimates are optimal,\nin a high dimensional setting, in the sense that both the bound for the\napproximation and estimation errors are comparable to the Monte Carlo error\nrates. A crucial step in the proof is to establish an optimal bound for the\nRademacher complexity of the residual networks. Comparisons are made with\nexisting norm-based generalization error bounds.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:35:30 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 00:30:40 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wang", "Qingcan", ""]]}, {"id": "1903.02164", "submitter": "Yuchen Li", "authors": "Ahmed Ayyad, Yuchen Li, Nassir Navab, Shadi Albarqouni, Mohamed\n  Elhoseiny", "title": "Semi-Supervised Few-Shot Learning with Prototypical Random Walks", "comments": "Accepted by AAAI 2021 Workshop (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent progress has shown that few-shot learning can be improved with access\nto unlabelled data, known as semi-supervised few-shot learning(SS-FSL). We\nintroduce an SS-FSL approach, dubbed as Prototypical Random Walk\nNetworks(PRWN), built on top of Prototypical Networks (PN). We develop a random\nwalk semi-supervised loss that enables the network to learn representations\nthat are compact and well-separated. Our work is related to the very recent\ndevelopment of graph-based approaches for few-shot learning. However, we show\nthat compact and well-separated class representations can be achieved by\nmodeling our prototypical random walk notion without needing additional\ngraph-NN parameters or requiring a transductive setting where a collective test\nset is provided. Our model outperforms baselines in most benchmarks with\nsignificant improvements in some cases. Our model, trained with 40$\\%$ of the\ndata as labeled, compares competitively against fully supervised prototypical\nnetworks, trained on 100$\\%$ of the labels, even outperforming it in the 1-shot\nmini-Imagenet case with 50.89$\\%$ to 49.4$\\%$ accuracy. We also show that our\nloss is resistant to distractors, unlabeled data that does not belong to any of\nthe training classes, and hence reflecting robustness to labeled/unlabeled\nclass distribution mismatch. Associated GitHub page can be found at\nhttps://prototypical-random-walk.github.io.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:54:40 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 20:33:17 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 06:19:56 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Ayyad", "Ahmed", ""], ["Li", "Yuchen", ""], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""], ["Elhoseiny", "Mohamed", ""]]}, {"id": "1903.02173", "submitter": "Gan Sun", "authors": "Gan Sun, Yang Cong, Qianqian Wang, Bineng Zhong, Yun Fu", "title": "Representative Task Self-selection for Flexible Clustered Lifelong\n  Learning", "comments": "15 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the lifelong machine learning paradigm whose objective is to learn a\nsequence of tasks depending on previous experiences, e.g., knowledge library or\ndeep network weights. However, the knowledge libraries or deep networks for\nmost recent lifelong learning models are with prescribed size, and can\ndegenerate the performance for both learned tasks and coming ones when facing\nwith a new task environment (cluster). To address this challenge, we propose a\nnovel incremental clustered lifelong learning framework with two knowledge\nlibraries: feature learning library and model knowledge library, called\nFlexible Clustered Lifelong Learning (FCL3). Specifically, the feature learning\nlibrary modeled by an autoencoder architecture maintains a set of\nrepresentation common across all the observed tasks, and the model knowledge\nlibrary can be self-selected by identifying and adding new representative\nmodels (clusters). When a new task arrives, our proposed FCL3model firstly\ntransfers knowledge from these libraries to encode the new task,\ni.e.,effectively and selectively soft-assigning this new task to multiple\nrepresentative models over feature learning library. Then, 1) the new task with\na higher outlier probability will be judged as a new representative, and used\nto redefine both feature learning library and representative models over time;\nor 2) the new task with lower outlier probability will only refine the feature\nlearning library. For model optimization, we cast this lifelong learning\nproblem as an alternating direction minimization problem as a new task comes.\nFinally, we evaluate the proposed framework by analyzing several multi-task\ndatasets, and the experimental results demonstrate that our FCL3 model can\nachieve better performance than most lifelong learning frameworks, even batch\nclustered multi-task learning models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:49:55 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 17:12:27 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Sun", "Gan", ""], ["Cong", "Yang", ""], ["Wang", "Qianqian", ""], ["Zhong", "Bineng", ""], ["Fu", "Yun", ""]]}, {"id": "1903.02183", "submitter": "Shumpei Kubosawa", "authors": "Shumpei Kubosawa, Takashi Onishi and Yoshimasa Tsuruoka", "title": "Synthesizing Chemical Plant Operation Procedures using Knowledge,\n  Dynamic Simulation and Deep Reinforcement Learning", "comments": "Proceedings of the SICE Annual Conference 2018 (pp.1376-1379)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical plants are complex and dynamical systems consisting of many\ncomponents for manipulation and sensing, whose state transitions depend on\nvarious factors such as time, disturbance, and operation procedures. For the\npurpose of supporting human operators of chemical plants, we are developing an\nAI system that can semi-automatically synthesize operation procedures for\nefficient and stable operation. Our system can provide not only appropriate\noperation procedures but also reasons why the procedures are considered to be\nvalid. This is achieved by integrating automated reasoning and deep\nreinforcement learning technologies with a chemical plant simulator and\nexternal knowledge. Our preliminary experimental results demonstrate that it\ncan synthesize a procedure that achieves a much faster recovery from a\nmalfunction compared to standard PID control.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 05:44:15 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Kubosawa", "Shumpei", ""], ["Onishi", "Takashi", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1903.02228", "submitter": "Nicholas Murphy", "authors": "Nicholas Murphy and Tim Gebbie", "title": "Learning the dynamics of technical trading strategies", "comments": "35 pages, 7 figures", "journal-ref": "Quantitative Finance (2021)", "doi": "10.1080/14697688.2020.1869292", "report-no": null, "categories": "q-fin.CP q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use an adversarial expert based online learning algorithm to learn the\noptimal parameters required to maximise wealth trading zero-cost portfolio\nstrategies. The learning algorithm is used to determine the relative population\ndynamics of technical trading strategies that can survive historical\nback-testing as well as form an overall aggregated portfolio trading strategy\nfrom the set of underlying trading strategies implemented on daily and intraday\nJohannesburg Stock Exchange data. The resulting population time-series are\ninvestigated using unsupervised learning for dimensionality reduction and\nvisualisation. A key contribution is that the overall aggregated trading\nstrategies are tested for statistical arbitrage using a novel hypothesis test\nproposed by Jarrow et al. (2012) on both daily sampled and intraday\ntime-scales. The (low frequency) daily sampled strategies fail the arbitrage\ntests after costs, while the (high frequency) intraday sampled strategies are\nnot falsified as statistical arbitrages after costs. The estimates of trading\nstrategy success, cost of trading and slippage are considered along with an\nonline benchmark portfolio algorithm for performance comparison. In addition,\nthe algorithms generalisation error is analysed by recovering a probability of\nback-test overfitting estimate using a nonparametric procedure introduced by\nBailey et al. (2016). The work aims to explore and better understand the\ninterplay between different technical trading strategies from a data-informed\nperspective.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 08:04:26 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 12:43:46 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2019 16:07:21 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Murphy", "Nicholas", ""], ["Gebbie", "Tim", ""]]}, {"id": "1903.02237", "submitter": "Qi Meng", "authors": "Mingyang Yi, Qi Meng, Wei Chen, Zhi-ming Ma and Tie-Yan Liu", "title": "Positively Scale-Invariant Flatness of ReLU Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was empirically confirmed by Keskar et al.\\cite{SharpMinima} that flatter\nminima generalize better. However, for the popular ReLU network, sharp minimum\ncan also generalize well \\cite{SharpMinimacan}. The conclusion demonstrates\nthat the existing definitions of flatness fail to account for the complex\ngeometry of ReLU neural networks because they can't cover the Positively\nScale-Invariant (PSI) property of ReLU network. In this paper, we formalize the\nPSI causes problem of existing definitions of flatness and propose a new\ndescription of flatness - \\emph{PSI-flatness}. PSI-flatness is defined on the\nvalues of basis paths \\cite{GSGD} instead of weights. Values of basis paths\nhave been shown to be the PSI-variables and can sufficiently represent the ReLU\nneural networks which ensure the PSI property of PSI-flatness. Then we study\nthe relation between PSI-flatness and generalization theoretically and\nempirically. First, we formulate a generalization bound based on PSI-flatness\nwhich shows generalization error decreasing with the ratio between the largest\nbasis path value and the smallest basis path value. That is to say, the minimum\nwith balanced values of basis paths will more likely to be flatter and\ngeneralize better. Finally. we visualize the PSI-flatness of loss surface\naround two learned models which indicates the minimum with smaller PSI-flatness\ncan indeed generalize better.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 08:21:09 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Yi", "Mingyang", ""], ["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Ma", "Zhi-ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1903.02250", "submitter": "Jack Umenberger", "authors": "Jack Umenberger, Thomas B. Sch\\\"on", "title": "Nonlinear input design as optimal control of a Hamiltonian system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an input design method for a general class of parametric\nprobabilistic models, including nonlinear dynamical systems with process noise.\nThe goal of the procedure is to select inputs such that the parameter posterior\ndistribution concentrates about the true value of the parameters; however,\nexact computation of the posterior is intractable. By representing (samples\nfrom) the posterior as trajectories from a certain Hamiltonian system, we\ntransform the input design task into an optimal control problem. The method is\nillustrated via numerical examples, including MRI pulse sequence design.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 09:02:58 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Umenberger", "Jack", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1903.02271", "submitter": "Michael Tschannen", "authors": "Mario Lucic, Michael Tschannen, Marvin Ritter, Xiaohua Zhai, Olivier\n  Bachem, Sylvain Gelly", "title": "High-Fidelity Image Generation With Fewer Labels", "comments": "Mario Lucic, Michael Tschannen, and Marvin Ritter contributed equally\n  to this work. ICML 2019 camera-ready version. Code available at\n  https://github.com/google/compare_gan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are becoming a cornerstone of modern machine learning.\nRecent work on conditional generative adversarial networks has shown that\nlearning complex, high-dimensional distributions over natural images is within\nreach. While the latest models are able to generate high-fidelity, diverse\nnatural images at high resolution, they rely on a vast quantity of labeled\ndata. In this work we demonstrate how one can benefit from recent work on self-\nand semi-supervised learning to outperform the state of the art on both\nunsupervised ImageNet synthesis, as well as in the conditional setting. In\nparticular, the proposed approach is able to match the sample quality (as\nmeasured by FID) of the current state-of-the-art conditional model BigGAN on\nImageNet using only 10% of the labels and outperform it using 20% of the\nlabels.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 09:52:49 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 15:27:42 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Lucic", "Mario", ""], ["Tschannen", "Michael", ""], ["Ritter", "Marvin", ""], ["Zhai", "Xiaohua", ""], ["Bachem", "Olivier", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1903.02278", "submitter": "Diviyan Kalainathan", "authors": "Diviyan Kalainathan, Olivier Goudet", "title": "Causal Discovery Toolbox: Uncover causal relationships in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents a new open source Python framework for causal discovery\nfrom observational data and domain background knowledge, aimed at causal graph\nand causal mechanism modeling. The 'cdt' package implements the end-to-end\napproach, recovering the direct dependencies (the skeleton of the causal graph)\nand the causal relationships between variables. It includes algorithms from the\n'Bnlearn' and 'Pcalg' packages, together with algorithms for pairwise causal\ndiscovery such as ANM. 'cdt' is available under the MIT License at\nhttps://github.com/Diviyan-Kalainathan/CausalDiscoveryToolbox.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 10:03:20 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Kalainathan", "Diviyan", ""], ["Goudet", "Olivier", ""]]}, {"id": "1903.02313", "submitter": "Konstantinos Nikolaidis", "authors": "Konstantinos Nikolaidis, Stein Kristiansen, Vera Goebel, Thomas\n  Plagemann", "title": "Learning from Higher-Layer Feature Visualizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the goal to enable sleep apnea monitoring and machine\nlearning-based detection at home with small mobile devices, we investigate\nwhether interpretation-based indirect knowledge transfer can be used to create\nclassifiers with acceptable performance. Interpretation-based indirect\nknowledge transfer means that a classifier (student) learns from a synthetic\ndataset based on the knowledge representation from an already trained Deep\nNetwork (teacher). We use activation maximization to generate visualizations\nand create a synthetic dataset to train the student classifier. This approach\nhas the advantage that student classifiers can be trained without access to the\noriginal training data. With experiments we investigate the feasibility of\ninterpretation-based indirect knowledge transfer and its limitations. The\nstudent achieves an accuracy of 97.8% on MNIST (teacher accuracy: 99.3%) with a\nsimilar smaller architecture to that of the teacher. The student classifier\nachieves an accuracy of 86.1% and 89.5% for a subset of the Apnea-ECG dataset\n(teacher: 89.5% and 91.1%, respectively).\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 11:01:17 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Nikolaidis", "Konstantinos", ""], ["Kristiansen", "Stein", ""], ["Goebel", "Vera", ""], ["Plagemann", "Thomas", ""]]}, {"id": "1903.02318", "submitter": "Urtats Etxegarai Susaeta", "authors": "U. Etxegarai, E. Portillo, J. Irazusta, L. A. Koefoed, N. Kasabov", "title": "A heuristic approach for lactate threshold estimation for training\n  decision-making: An accessible and easy to use solution for recreational\n  runners", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": "10.1016/j.ejor.2019.08.023", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a heuristic as operational tool to estimate the lactate\nthreshold and to facilitate its integration into the training process of\nrecreational runners is proposed. To do so, we formalize the principles for the\nlactate threshold estimation from empirical data and an iterative methodology\nthat enables experience based learning. This strategy arises as a robust and\nadaptive approach to solve data analysis problems. We compare the results of\nthe heuristic with the most commonly used protocol by making a first\nquantitative error analysis to show its reliability. Additionally, we provide a\ncomputational algorithm so that this quantitative analysis can be easily\nperformed in other lactate threshold protocols. With this work, we have shown\nthat a heuristic %60 of 'endurance running speed reserve', serves for the same\npurpose of the most commonly used protocol in recreational runners, but\nimproving its operational limitations of accessibility and consistent use.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 11:09:58 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Etxegarai", "U.", ""], ["Portillo", "E.", ""], ["Irazusta", "J.", ""], ["Koefoed", "L. A.", ""], ["Kasabov", "N.", ""]]}, {"id": "1903.02334", "submitter": "Saeed Saremi", "authors": "Saeed Saremi, Aapo Hyvarinen", "title": "Neural Empirical Bayes", "comments": "23 pages, 10 figures", "journal-ref": "Journal of Machine Learning Research 20(181), 1-23, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We unify $\\textit{kernel density estimation}$ and $\\textit{empirical Bayes}$\nand address a set of problems in unsupervised learning with a geometric\ninterpretation of those methods, rooted in the $\\textit{concentration of\nmeasure}$ phenomenon. Kernel density is viewed symbolically as\n$X\\rightharpoonup Y$ where the random variable $X$ is smoothed to $Y=\nX+N(0,\\sigma^2 I_d)$, and empirical Bayes is the machinery to denoise in a\nleast-squares sense, which we express as $X \\leftharpoondown Y$. A learning\nobjective is derived by combining these two, symbolically captured by $X\n\\rightleftharpoons Y$. Crucially, instead of using the original nonparametric\nestimators, we parametrize $\\textit{the energy function}$ with a neural network\ndenoted by $\\phi$; at optimality, $\\nabla \\phi \\approx -\\nabla \\log f$ where\n$f$ is the density of $Y$. The optimization problem is abstracted as\ninteractions of high-dimensional spheres which emerge due to the concentration\nof isotropic gaussians. We introduce two algorithmic frameworks based on this\nmachinery: (i) a \"walk-jump\" sampling scheme that combines Langevin MCMC\n(walks) and empirical Bayes (jumps), and (ii) a probabilistic framework for\n$\\textit{associative memory}$, called NEBULA, defined \\`{a} la Hopfield by the\n$\\textit{gradient flow}$ of the learned energy to a set of attractors. We\nfinish the paper by reporting the emergence of very rich \"creative memories\" as\nattractors of NEBULA for highly-overlapping spheres.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 12:04:44 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 03:12:26 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Saremi", "Saeed", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1903.02380", "submitter": "Roman Werpachowski", "authors": "Roman Werpachowski, Andr\\'as Gy\\\"orgy and Csaba Szepesv\\'ari", "title": "Detecting Overfitting via Adversarial Examples", "comments": "17 pages", "journal-ref": "Part of: Advances in Neural Information Processing Systems 32\n  (NIPS 2019) pre-proceedings", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repeated community-wide reuse of test sets in popular benchmark problems\nraises doubts about the credibility of reported test-error rates. Verifying\nwhether a learned model is overfitted to a test set is challenging as\nindependent test sets drawn from the same data distribution are usually\nunavailable, while other test sets may introduce a distribution shift. We\npropose a new hypothesis test that uses only the original test data to detect\noverfitting. It utilizes a new unbiased error estimate that is based on\nadversarial examples generated from the test data and importance weighting.\nOverfitting is detected if this error estimate is sufficiently different from\nthe original test error rate. We develop a specialized variant of our test for\nmulticlass image classification, and apply it to testing overfitting of recent\nmodels to the popular ImageNet benchmark. Our method correctly indicates\noverfitting of the trained model to the training set, but is not able to detect\nany overfitting to the test set, in line with other recent work on this topic.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 13:49:18 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 11:16:01 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Werpachowski", "Roman", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1903.02407", "submitter": "Li Ant", "authors": "Liat Antwarg, Ronnie Mindlin Miller, Bracha Shapira, Lior Rokach", "title": "Explaining Anomalies Detected by Autoencoders Using SHAP", "comments": "Added more evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection algorithms are often thought to be limited because they\ndon't facilitate the process of validating results performed by domain experts.\nIn Contrast, deep learning algorithms for anomaly detection, such as\nautoencoders, point out the outliers, saving experts the time-consuming task of\nexamining normal cases in order to find anomalies. Most outlier detection\nalgorithms output a score for each instance in the database. The top-k most\nintense outliers are returned to the user for further inspection; however the\nmanual validation of results becomes challenging without additional clues. An\nexplanation of why an instance is anomalous enables the experts to focus their\ninvestigation on most important anomalies and may increase their trust in the\nalgorithm.\n  Recently, a game theory-based framework known as SHapley Additive\nexPlanations (SHAP) has been shown to be effective in explaining various\nsupervised learning models. In this research, we extend SHAP to explain\nanomalies detected by an autoencoder, an unsupervised model. The proposed\nmethod extracts and visually depicts both the features that most contributed to\nthe anomaly and those that offset it. A preliminary experimental study using\nreal world data demonstrates the usefulness of the proposed method in assisting\nthe domain experts to understand the anomaly and filtering out the\nuninteresting anomalies, aiming at minimizing the false positive rate of\ndetected anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 14:29:27 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 20:32:25 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Antwarg", "Liat", ""], ["Miller", "Ronnie Mindlin", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1903.02428", "submitter": "Matthias Fey", "authors": "Matthias Fey, Jan Eric Lenssen", "title": "Fast Graph Representation Learning with PyTorch Geometric", "comments": "ICLR 2019 (RLGM Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PyTorch Geometric, a library for deep learning on irregularly\nstructured input data such as graphs, point clouds and manifolds, built upon\nPyTorch. In addition to general graph data structures and processing methods,\nit contains a variety of recently published methods from the domains of\nrelational learning and 3D data processing. PyTorch Geometric achieves high\ndata throughput by leveraging sparse GPU acceleration, by providing dedicated\nCUDA kernels and by introducing efficient mini-batch handling for input\nexamples of different size. In this work, we present the library in detail and\nperform a comprehensive comparative study of the implemented methods in\nhomogeneous evaluation scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 14:50:02 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 17:07:42 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 10:06:09 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Fey", "Matthias", ""], ["Lenssen", "Jan Eric", ""]]}, {"id": "1903.02456", "submitter": "Stefan Bauer", "authors": "Anant Raj and Luigi Gresele and Michel Besserve and Bernhard\n  Sch\\\"olkopf and Stefan Bauer", "title": "Orthogonal Structure Search for Efficient Causal Discovery from\n  Observational Data", "comments": "first author uploaded a new version as \"Causal Feature Selection via\n  Orthogonal Search\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of inferring the direct causal parents of a response variable\namong a large set of explanatory variables is of high practical importance in\nmany disciplines. Recent work exploits stability of regression coefficients or\ninvariance properties of models across different experimental conditions for\nreconstructing the full causal graph. These approaches generally do not scale\nwell with the number of the explanatory variables and are difficult to extend\nto nonlinear relationships. Contrary to existing work, we propose an approach\nwhich even works for observational data alone, while still offering theoretical\nguarantees including the case of partially nonlinear relationships. Our\nalgorithm requires only one estimation for each variable and in our experiments\nwe apply our causal discovery algorithm even to large graphs, demonstrating\nsignificant improvements compared to well established approaches.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 15:51:10 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 13:53:21 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Raj", "Anant", ""], ["Gresele", "Luigi", ""], ["Besserve", "Michel", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "1903.02482", "submitter": "Yuan Zhou", "authors": "Yuan Zhou, Bradley J. Gram-Hansen, Tobias Kohn, Tom Rainforth,\n  Hongseok Yang, Frank Wood", "title": "LF-PPL: A Low-Level First Order Probabilistic Programming Language for\n  Non-Differentiable Models", "comments": "Published in the proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new Low-level, First-order Probabilistic Programming Language\n(LF-PPL) suited for models containing a mix of continuous, discrete, and/or\npiecewise-continuous variables. The key success of this language and its\ncompilation scheme is in its ability to automatically distinguish parameters\nthe density function is discontinuous with respect to, while further providing\nruntime checks for boundary crossings. This enables the introduction of new\ninference engines that are able to exploit gradient information, while\nremaining efficient for models which are not everywhere differentiable. We\ndemonstrate this ability by incorporating a discontinuous Hamiltonian Monte\nCarlo (DHMC) inference engine that is able to deliver automated and efficient\ninference for non-differentiable models. Our system is backed up by a\nmathematical formalism that ensures that any model expressed in this language\nhas a density with measure zero discontinuities to maintain the validity of the\ninference engine.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 16:29:20 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Zhou", "Yuan", ""], ["Gram-Hansen", "Bradley J.", ""], ["Kohn", "Tobias", ""], ["Rainforth", "Tom", ""], ["Yang", "Hongseok", ""], ["Wood", "Frank", ""]]}, {"id": "1903.02521", "submitter": "Aritra Chowdhury", "authors": "Aritra Chowdhury, Malik Magdin-Ismail, Bulent Yener", "title": "Quantifying error contributions of computational steps, algorithms and\n  hyperparameter choices in image classification pipelines", "comments": "arXiv admin note: substantial text overlap with arXiv:1903.00405", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science relies on pipelines that are organized in the form of\ninterdependent computational steps. Each step consists of various candidate\nalgorithms that maybe used for performing a particular function. Each algorithm\nconsists of several hyperparameters. Algorithms and hyperparameters must be\noptimized as a whole to produce the best performance. Typical machine learning\npipelines typically consist of complex algorithms in each of the steps. Not\nonly is the selection process combinatorial, but it is also important to\ninterpret and understand the pipelines. We propose a method to quantify the\nimportance of different layers in the pipeline, by computing an error\ncontribution relative to an agnostic choice of algorithms in that layer. We\ndemonstrate our methodology on image classification pipelines. The agnostic\nmethodology quantifies the error contributions from the computational steps,\nalgorithms and hyperparameters in the image classification pipeline. We show\nthat algorithm selection and hyper-parameter optimization methods can be used\nto quantify the error contribution and that random search is able to quantify\nthe contribution more accurately than Bayesian optimization. This methodology\ncan be used by domain experts to understand machine learning and data analysis\npipelines in terms of their individual components, which can help in\nprioritizing different components of the pipeline.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:16:58 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Chowdhury", "Aritra", ""], ["Magdin-Ismail", "Malik", ""], ["Yener", "Bulent", ""]]}, {"id": "1903.02540", "submitter": "Gerasimos Spanakis", "authors": "Matteo Maggiolo and Gerasimos Spanakis", "title": "Autoregressive Convolutional Recurrent Neural Network for Univariate and\n  Multivariate Time Series Prediction", "comments": "ESAN2019 accepted paper, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series forecasting (univariate and multivariate) is a problem of high\ncomplexity due the different patterns that have to be detected in the input,\nranging from high to low frequencies ones. In this paper we propose a new model\nfor timeseries prediction that utilizes convolutional layers for feature\nextraction, a recurrent encoder and a linear autoregressive component. We\nmotivate the model and we test and compare it against a baseline of widely used\nexisting architectures for univariate and multivariate timeseries. The proposed\nmodel appears to outperform the baselines in almost every case of the\nmultivariate timeseries datasets, in some cases even with 50% improvement which\nshows the strengths of such a hybrid architecture in complex timeseries.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:37:05 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Maggiolo", "Matteo", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1903.02541", "submitter": "Ryan Murphy", "authors": "Ryan L. Murphy and Balasubramaniam Srinivasan and Vinayak Rao and\n  Bruno Ribeiro", "title": "Relational Pooling for Graph Representations", "comments": "ICML 2019 Camera-Ready. Added to molecular experiments and balanced\n  the classes of the validation folds for the synthetic-graph experiments.\n  Clarified some discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work generalizes graph neural networks (GNNs) beyond those based on the\nWeisfeiler-Lehman (WL) algorithm, graph Laplacians, and diffusions. Our\napproach, denoted Relational Pooling (RP), draws from the theory of finite\npartial exchangeability to provide a framework with maximal representation\npower for graphs. RP can work with existing graph representation models and,\nsomewhat counterintuitively, can make them even more powerful than the original\nWL isomorphism test. Additionally, RP allows architectures like Recurrent\nNeural Networks and Convolutional Neural Networks to be used in a theoretically\nsound approach for graph classification. We demonstrate improved performance of\nRP-based graph representations over state-of-the-art methods on a number of\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:37:26 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 18:03:34 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Murphy", "Ryan L.", ""], ["Srinivasan", "Balasubramaniam", ""], ["Rao", "Vinayak", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "1903.02585", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah", "title": "GanDef: A GAN based Adversarial Training Defense for Neural Network\n  Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models, especially neural network (NN) classifiers, are\nwidely used in many applications including natural language processing,\ncomputer vision and cybersecurity. They provide high accuracy under the\nassumption of attack-free scenarios. However, this assumption has been defied\nby the introduction of adversarial examples -- carefully perturbed samples of\ninput that are usually misclassified. Many researchers have tried to develop a\ndefense against adversarial examples; however, we are still far from achieving\nthat goal. In this paper, we design a Generative Adversarial Net (GAN) based\nadversarial training defense, dubbed GanDef, which utilizes a competition game\nto regulate the feature selection during the training. We analytically show\nthat GanDef can train a classifier so it can defend against adversarial\nexamples. Through extensive evaluation on different white-box adversarial\nexamples, the classifier trained by GanDef shows the same level of test\naccuracy as those trained by state-of-the-art adversarial training defenses.\nMore importantly, GanDef-Comb, a variant of GanDef, could utilize the\ndiscriminator to achieve a dynamic trade-off between correctly classifying\noriginal and adversarial examples. As a result, it achieves the highest overall\ntest accuracy when the ratio of adversarial examples exceeds 41.7%.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:09:47 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""]]}, {"id": "1903.02606", "submitter": "Mingwei Wei", "authors": "Mingwei Wei, James Stokes, David J Schwab", "title": "Mean-field Analysis of Batch Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BatchNorm) is an extremely useful component of modern\nneural network architectures, enabling optimization using higher learning rates\nand achieving faster convergence. In this paper, we use mean-field theory to\nanalytically quantify the impact of BatchNorm on the geometry of the loss\nlandscape for multi-layer networks consisting of fully-connected and\nconvolutional layers. We show that it has a flattening effect on the loss\nlandscape, as quantified by the maximum eigenvalue of the Fisher Information\nMatrix. These findings are then used to justify the use of larger learning\nrates for networks that use BatchNorm, and we provide quantitative\ncharacterization of the maximal allowable learning rate to ensure convergence.\nExperiments support our theoretically predicted maximum learning rate, and\nfurthermore suggest that networks with smaller values of the BatchNorm\nparameter achieve lower loss after the same number of epochs of training.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 20:50:29 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Wei", "Mingwei", ""], ["Stokes", "James", ""], ["Schwab", "David J", ""]]}, {"id": "1903.02610", "submitter": "Gabriel Loaiza-Ganem", "authors": "Gabriel Loaiza-Ganem, Sean M. Perkins, Karen E. Schroeder, Mark M.\n  Churchland, John P. Cunningham", "title": "Deep Random Splines for Point Process Intensity Estimation of Neural\n  Population Data", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are the leading class of distributions on random\nfunctions, but they suffer from well known issues including difficulty scaling\nand inflexibility with respect to certain shape constraints (such as\nnonnegativity). Here we propose Deep Random Splines, a flexible class of random\nfunctions obtained by transforming Gaussian noise through a deep neural network\nwhose output are the parameters of a spline. Unlike Gaussian processes, Deep\nRandom Splines allow us to readily enforce shape constraints while inheriting\nthe richness and tractability of deep generative models. We also present an\nobservational model for point process data which uses Deep Random Splines to\nmodel the intensity function of each point process and apply it to neural\npopulation data to obtain a low-dimensional representation of spiking activity.\nInference is performed via a variational autoencoder that uses a novel\nrecurrent encoder architecture that can handle multiple point processes as\ninput. We use a newly collected dataset where a primate completes a pedaling\ntask, and observe better dimensionality reduction with our model than with\ncompeting alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 21:01:03 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 00:28:06 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 19:39:54 GMT"}, {"version": "v4", "created": "Thu, 10 Oct 2019 01:20:17 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 03:46:59 GMT"}, {"version": "v6", "created": "Sun, 29 Dec 2019 23:52:01 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Loaiza-Ganem", "Gabriel", ""], ["Perkins", "Sean M.", ""], ["Schroeder", "Karen E.", ""], ["Churchland", "Mark M.", ""], ["Cunningham", "John P.", ""]]}, {"id": "1903.02640", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Kamiya Motwani, Evren Korpeoglu, Sushant Kumar,\n  Kannan Achan", "title": "Generative Graph Convolutional Network for Growing Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682360", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling generative process of growing graphs has wide applications in social\nnetworks and recommendation systems, where cold start problem leads to new\nnodes isolated from existing graph. Despite the emerging literature in learning\ngraph representation and graph generation, most of them can not handle isolated\nnew nodes without nontrivial modifications. The challenge arises due to the\nfact that learning to generate representations for nodes in observed graph\nrelies heavily on topological features, whereas for new nodes only node\nattributes are available. Here we propose a unified generative graph\nconvolutional network that learns node representations for all nodes adaptively\nin a generative model framework, by sampling graph generation sequences\nconstructed from observed graph data. We optimize over a variational lower\nbound that consists of a graph reconstruction term and an adaptive\nKullback-Leibler divergence regularization term. We demonstrate the superior\nperformance of our approach on several benchmark citation network datasets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 22:36:57 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Motwani", "Kamiya", ""], ["Korpeoglu", "Evren", ""], ["Kumar", "Sushant", ""], ["Achan", "Kannan", ""]]}, {"id": "1903.02647", "submitter": "Nicholas Ketz", "authors": "Nicholas Ketz, Soheil Kolouri, Praveen Pilly", "title": "Continual Learning Using World Models for Pseudo-Rehearsal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utility of learning a dynamics/world model of the environment in\nreinforcement learning has been shown in a many ways. When using neural\nnetworks, however, these models suffer catastrophic forgetting when learned in\na lifelong or continual fashion. Current solutions to the continual learning\nproblem require experience to be segmented and labeled as discrete tasks,\nhowever, in continuous experience it is generally unclear what a sufficient\nsegmentation of tasks would be. Here we propose a method to continually learn\nthese internal world models through the interleaving of internally generated\nepisodes of past experiences (i.e., pseudo-rehearsal). We show this method can\nsequentially learn unsupervised temporal prediction, without task labels, in a\ndisparate set of Atari games. Empirically, this interleaving of the internally\ngenerated rollouts with the external environment's observations leads to a\nconsistent reduction in temporal prediction loss compared to non-interleaved\nlearning and is preserved over repeated random exposures to various tasks.\nSimilarly, using a network distillation approach, we show that modern policy\ngradient based reinforcement learning algorithms can use this internal model to\ncontinually learn to optimize reward based on the world model's representation\nof the environment.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 22:58:36 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 17:35:52 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Ketz", "Nicholas", ""], ["Kolouri", "Soheil", ""], ["Pilly", "Praveen", ""]]}, {"id": "1903.02650", "submitter": "Jessica Hoffmann", "authors": "Jessica Hoffmann, Constantine Caramanis", "title": "Learning Graphs from Noisy Epidemic Cascades", "comments": "32 pages, 3 figures. Accepted at SIGMETRICS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the weighted edges of a graph by\nobserving the noisy times of infection for multiple epidemic cascades on this\ngraph. Past work has considered this problem when the cascade information,\ni.e., infection times, are known exactly. Though the noisy setting is well\nmotivated by many epidemic processes (e.g., most human epidemics), to the best\nof our knowledge, very little is known about when it is solvable. Previous work\non the no-noise setting critically uses the ordering information. If noise can\nreverse this -- a node's reported (noisy) infection time comes after the\nreported infection time of some node it infected -- then we are unable to see\nhow previous results can be extended.\n  We therefore tackle two versions of the noisy setting: the limited-noise\nsetting, where we know noisy times of infections, and the extreme-noise\nsetting, in which we only know whether or not a node was infected. We provide a\npolynomial time algorithm for recovering the structure of bidirectional trees\nin the extreme-noise setting, and show our algorithm almost matches lower\nbounds established in the no-noise setting, and hence is optimal up to\nlog-factors. We extend our results for general degree-bounded graphs, where\nagain we show that our (poly-time) algorithm can recover the structure of the\ngraph with optimal sample complexity. We also provide the first efficient\nalgorithm to learn the weights of the bidirectional tree in the limited-noise\nsetting. Finally, we give a polynomial time algorithm for learning the weights\nof general bounded-degree graphs in the limited-noise setting. This algorithm\nextends to general graphs (at the price of exponential running time), proving\nthe problem is solvable in the general case. All our algorithms work for any\nnoise distribution, without any restriction on the variance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 23:07:12 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 16:59:13 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Hoffmann", "Jessica", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1903.02656", "submitter": "Sharon Qian", "authors": "Sharon Qian, Yaron Singer", "title": "Fast Parallel Algorithms for Statistical Subset Selection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new framework for designing fast parallel\nalgorithms for fundamental statistical subset selection tasks that include\nfeature selection and experimental design. Such tasks are known to be weakly\nsubmodular and are amenable to optimization via the standard greedy algorithm.\nDespite its desirable approximation guarantees, the greedy algorithm is\ninherently sequential and in the worst case, its parallel runtime is linear in\nthe size of the data. Recently, there has been a surge of interest in a\nparallel optimization technique called adaptive sampling which produces\nsolutions with desirable approximation guarantees for submodular maximization\nin exponentially faster parallel runtime. Unfortunately, we show that for\ngeneral weakly submodular functions such accelerations are impossible. The\nmajor contribution in this paper is a novel relaxation of submodularity which\nwe call differential submodularity. We first prove that differential\nsubmodularity characterizes objectives like feature selection and experimental\ndesign. We then design an adaptive sampling algorithm for differentially\nsubmodular functions whose parallel runtime is logarithmic in the size of the\ndata and achieves strong approximation guarantees. Through experiments, we show\nthe algorithm's performance is competitive with state-of-the-art methods and\nobtains dramatic speedups for feature selection and experimental design\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 23:26:38 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 22:15:33 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 17:37:57 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Qian", "Sharon", ""], ["Singer", "Yaron", ""]]}, {"id": "1903.02658", "submitter": "Minyue Fu Prof", "authors": "Zhaorong Zhang and Minyue Fu", "title": "On Convergence Rate of the Gaussian Belief Propagation Algorithm for\n  Markov Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Belief Propagation (BP) algorithm is one of the most important\ndistributed algorithms in signal processing and statistical learning involving\nMarkov networks. It is well known that the algorithm correctly computes\nmarginal density functions from a high dimensional joint density function over\na Markov network in a finite number of iterations when the underlying Gaussian\ngraph is acyclic. It is also known more recently that the algorithm produces\ncorrect marginal means asymptotically for cyclic Gaussian graphs under the\ncondition of walk summability. This paper extends this convergence result\nfurther by showing that the convergence is exponential under the walk\nsummability condition, and provides a simple bound for the convergence rate.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 23:45:49 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Zhang", "Zhaorong", ""], ["Fu", "Minyue", ""]]}, {"id": "1903.02675", "submitter": "Yair Carmon", "authors": "Yair Carmon, John C. Duchi, Aaron Sidford and Kevin Tian", "title": "A Rank-1 Sketch for Matrix Multiplicative Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a simple randomized sketch of the matrix multiplicative weight\n(MMW) update enjoys (in expectation) the same regret bounds as MMW, up to a\nsmall constant factor. Unlike MMW, where every step requires full matrix\nexponentiation, our steps require only a single product of the form $e^A b$,\nwhich the Lanczos method approximates efficiently. Our key technique is to view\nthe sketch as a $\\textit{randomized mirror projection}$, and perform mirror\ndescent analysis on the $\\textit{expected projection}$. Our sketch solves the\nonline eigenvector problem, improving the best known complexity bounds by\n$\\Omega(\\log^5 n)$. We also apply this sketch to semidefinite programming in\nsaddle-point form, yielding a simple primal-dual scheme with guarantees\nmatching the best in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 01:05:27 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 03:16:37 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Carmon", "Yair", ""], ["Duchi", "John C.", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""]]}, {"id": "1903.02695", "submitter": "Chris Von Csefalvay", "authors": "Chris von Csefalvay", "title": "Novel quantitative indicators of digital ophthalmoscopy image quality", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of smartphone indirect ophthalmoscopy, teleophthalmology -\nthe use of specialist ophthalmology assets at a distance from the patient - has\nexperienced a breakthrough, promising enormous benefits especially for\nhealthcare in distant, inaccessible or opthalmologically underserved areas,\nwhere specialists are either unavailable or too few in number. However,\naccurate teleophthalmology requires high-quality ophthalmoscopic imagery. This\npaper considers three feature families - statistical metrics, gradient-based\nmetrics and wavelet transform coefficient derived indicators - as possible\nmetrics to identify unsharp or blurry images. By using standard machine\nlearning techniques, the suitability of these features for image quality\nassessment is confirmed, albeit on a rather small data set. With the increased\navailability and decreasing cost of digital ophthalmoscopy on one hand and the\nincreased prevalence of diabetic retinopathy worldwide on the other, creating\ntools that can determine whether an image is likely to be diagnostically\nsuitable can play a significant role in accelerating and streamlining the\nteleophthalmology process. This paper highlights the need for more research in\nthis area, including the compilation of a diverse database of ophthalmoscopic\nimagery, annotated with quality markers, to train the Point of Acquisition\nerror detection algorithms of the future.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 02:21:41 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["von Csefalvay", "Chris", ""]]}, {"id": "1903.02706", "submitter": "Amir Karami", "authors": "Amir Karami, Vishal Shah, Reza Vaezi, Amit Bansal", "title": "Twitter Speaks: A Case of National Disaster Situational Awareness", "comments": "17 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have been faced with a series of natural disasters\ncausing a tremendous amount of financial, environmental, and human losses. The\nunpredictable nature of natural disasters' behavior makes it hard to have a\ncomprehensive situational awareness (SA) to support disaster management. Using\nopinion surveys is a traditional approach to analyze public concerns during\nnatural disasters; however, this approach is limited, expensive, and\ntime-consuming. Luckily the advent of social media has provided scholars with\nan alternative means of analyzing public concerns. Social media enable users\n(people) to freely communicate their opinions and disperse information\nregarding current events including natural disasters. This research emphasizes\nthe value of social media analysis and proposes an analytical framework:\nTwitter Situational Awareness (TwiSA). This framework uses text mining methods\nincluding sentiment analysis and topic modeling to create a better SA for\ndisaster preparedness, response, and recovery. TwiSA has also effectively\ndeployed on a large number of tweets and tracks the negative concerns of people\nduring the 2015 South Carolina flood.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 03:02:00 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Karami", "Amir", ""], ["Shah", "Vishal", ""], ["Vaezi", "Reza", ""], ["Bansal", "Amit", ""]]}, {"id": "1903.02709", "submitter": "Christopher Beckham", "authors": "Christopher Beckham, Sina Honari, Vikas Verma, Alex Lamb, Farnoosh\n  Ghadiri, R Devon Hjelm, Yoshua Bengio, Christopher Pal", "title": "On Adversarial Mixup Resynthesis", "comments": "'Camera-ready draft'", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore new approaches to combining information encoded\nwithin the learned representations of auto-encoders. We explore models that are\ncapable of combining the attributes of multiple inputs such that a\nresynthesised output is trained to fool an adversarial discriminator for real\nversus synthesised data. Furthermore, we explore the use of such an\narchitecture in the context of semi-supervised learning, where we learn a\nmixing function whose objective is to produce interpolations of hidden states,\nor masked combinations of latent representations that are consistent with a\nconditioned class label. We show quantitative and qualitative evidence that\nsuch a formulation is an interesting avenue of research.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 03:28:25 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 14:05:21 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 13:35:09 GMT"}, {"version": "v4", "created": "Wed, 23 Oct 2019 21:13:36 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Beckham", "Christopher", ""], ["Honari", "Sina", ""], ["Verma", "Vikas", ""], ["Lamb", "Alex", ""], ["Ghadiri", "Farnoosh", ""], ["Hjelm", "R Devon", ""], ["Bengio", "Yoshua", ""], ["Pal", "Christopher", ""]]}, {"id": "1903.02750", "submitter": "Soma Yokoi", "authors": "Soma Yokoi and Takuma Otsuka and Issei Sato", "title": "On Transformations in Stochastic Gradient MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient Langevin dynamics (SGLD) is a computationally efficient\nsampler for Bayesian posterior inference given a large scale dataset. Although\nSGLD is designed for unbounded random variables, many practical models\nincorporate variables with boundaries such as non-negative ones or those in a\nfinite interval. To bridge this gap, we consider mapping unbounded samples into\nthe target interval. This paper reveals that several mapping approaches\ncommonly used in the literature produces erroneous samples from theoretical and\nempirical perspectives. We show that the change of random variable using an\ninvertible Lipschitz mapping function overcomes the pitfall as well as attains\nthe weak convergence. Experiments demonstrate its efficacy for widely-used\nmodels with bounded latent variables including Bayesian non-negative matrix\nfactorization and binary neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 06:57:54 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 05:46:55 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Yokoi", "Soma", ""], ["Otsuka", "Takuma", ""], ["Sato", "Issei", ""]]}, {"id": "1903.02785", "submitter": "Menglei Hu", "authors": "Menglei Hu and Songcan Chen", "title": "Doubly Aligned Incomplete Multi-view Clustering", "comments": "8 pages, IJCAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, multi-view clustering has attracted more and more attention. To\ndate, almost all the previous studies assume that views are complete. However,\nin reality, it is often the case that each view may contain some missing\ninstances. Such incompleteness makes it impossible to directly use traditional\nmulti-view clustering methods. In this paper, we propose a Doubly Aligned\nIncomplete Multi-view Clustering algorithm (DAIMC) based on weighted\nsemi-nonnegative matrix factorization (semi-NMF). Specifically, on the one\nhand, DAIMC utilizes the given instance alignment information to learn a common\nlatent feature matrix for all the views. On the other hand, DAIMC establishes a\nconsensus basis matrix with the help of $L_{2,1}$-Norm regularized regression\nfor reducing the influence of missing instances. Consequently, compared with\nexisting methods, besides inheriting the strength of semi-NMF with ability to\nhandle negative entries, DAIMC has two unique advantages: 1) solving the\nincomplete view problem by introducing a respective weight matrix for each\nview, making it able to easily adapt to the case with more than two views; 2)\nreducing the influence of view incompleteness on clustering by enforcing the\nbasis matrices of individual views being aligned with the help of regression.\nExperiments on four real-world datasets demonstrate its advantages.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:25:25 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Hu", "Menglei", ""], ["Chen", "Songcan", ""]]}, {"id": "1903.02787", "submitter": "Feng Li", "authors": "Yanfei Kang, Rob J Hyndman, Feng Li", "title": "GRATIS: GeneRAting TIme Series with diverse and controllable\n  characteristics", "comments": null, "journal-ref": "Statistical Analysis and Data Mining 2020", "doi": "10.1002/sam.11461", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of time series data in recent years has brought a flourish of\nnew time series analysis methods, for forecasting, clustering, classification\nand other tasks. The evaluation of these new methods requires either collecting\nor simulating a diverse set of time series benchmarking data to enable reliable\ncomparisons against alternative approaches. We propose GeneRAting TIme Series\nwith diverse and controllable characteristics, named GRATIS, with the use of\nmixture autoregressive (MAR) models. We simulate sets of time series using MAR\nmodels and investigate the diversity and coverage of the generated time series\nin a time series feature space. By tuning the parameters of the MAR models,\nGRATIS is also able to efficiently generate new time series with controllable\nfeatures. In general, as a costless surrogate to the traditional data\ncollection approach, GRATIS can be used as an evaluation tool for tasks such as\ntime series forecasting and classification. We illustrate the usefulness of our\ntime series generation process through a time series forecasting application.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:29:31 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 13:07:19 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kang", "Yanfei", ""], ["Hyndman", "Rob J", ""], ["Li", "Feng", ""]]}, {"id": "1903.02788", "submitter": "Thomas Unterthiner", "authors": "Kristina Preuer, G\\\"unter Klambauer, Friedrich Rippmann, Sepp\n  Hochreiter, Thomas Unterthiner", "title": "Interpretable Deep Learning in Drug Discovery", "comments": "Code available at\n  https://github.com/bioinf-jku/interpretable_ml_drug_discovery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without any means of interpretation, neural networks that predict molecular\nproperties and bioactivities are merely black boxes. We will unravel these\nblack boxes and will demonstrate approaches to understand the learned\nrepresentations which are hidden inside these models. We show how single\nneurons can be interpreted as classifiers which determine the presence or\nabsence of pharmacophore- or toxicophore-like structures, thereby generating\nnew insights and relevant knowledge for chemistry, pharmacology and\nbiochemistry. We further discuss how these novel pharmacophores/toxicophores\ncan be determined from the network by identifying the most relevant components\nof a compound for the prediction of the network. Additionally, we propose a\nmethod which can be used to extract new pharmacophores from a model and will\nshow that these extracted structures are consistent with literature findings.\nWe envision that having access to such interpretable knowledge is a crucial aid\nin the development and design of new pharmaceutically active molecules, and\nhelps to investigate and understand failures and successes of current methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:39:08 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 15:34:48 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Preuer", "Kristina", ""], ["Klambauer", "G\u00fcnter", ""], ["Rippmann", "Friedrich", ""], ["Hochreiter", "Sepp", ""], ["Unterthiner", "Thomas", ""]]}, {"id": "1903.02791", "submitter": "Niklas Christoffer Petersen", "authors": "Niklas Christoffer Petersen and Filipe Rodrigues and Francisco Camara\n  Pereira", "title": "Multi-output Bus Travel Time Prediction with Convolutional LSTM Neural\n  Network", "comments": null, "journal-ref": "Expert Systems with Applications, Volume 120, 15 April 2019, Pages\n  426-435", "doi": "10.1016/j.eswa.2018.11.028", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and reliable travel time predictions in public transport networks\nare essential for delivering an attractive service that is able to compete with\nother modes of transport in urban areas. The traditional application of this\ninformation, where arrival and departure predictions are displayed on digital\nboards, is highly visible in the city landscape of most modern metropolises.\nMore recently, the same information has become critical as input for\nsmart-phone trip planners in order to alert passengers about unreachable\nconnections, alternative route choices and prolonged travel times. More\nsophisticated Intelligent Transport Systems (ITS) include the predictions of\nconnection assurance, i.e. to hold back services in case a connecting service\nis delayed. In order to operate such systems, and to ensure the confidence of\npassengers in the systems, the information provided must be accurate and\nreliable. Traditional methods have trouble with this as congestion, and thus\ntravel time variability, increases in cities, consequently making travel time\npredictions in urban areas a non-trivial task. This paper presents a system for\nbus travel time prediction that leverages the non-static spatio-temporal\ncorrelations present in urban bus networks, allowing the discovery of complex\npatterns not captured by traditional methods. The underlying model is a\nmulti-output, multi-time-step, deep neural network that uses a combination of\nconvolutional and long short-term memory (LSTM) layers. The method is\nempirically evaluated and compared to other popular approaches for link travel\ntime prediction and currently available services, including the currently\ndeployed model in Copenhagen, Denmark. We find that the proposed model\nsignificantly outperforms all the other methods we compare with, and is able to\ndetect small irregular peaks in bus travel times very quickly.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:47:11 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Petersen", "Niklas Christoffer", ""], ["Rodrigues", "Filipe", ""], ["Pereira", "Francisco Camara", ""]]}, {"id": "1903.02837", "submitter": "Borja Balle", "authors": "Borja Balle, James Bell, Adria Gascon, Kobbi Nissim", "title": "The Privacy Blanket of the Shuffle Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies differential privacy in the context of the recently\nproposed shuffle model. Unlike in the local model, where the server collecting\nprivatized data from users can track back an input to a specific user, in the\nshuffle model users submit their privatized inputs to a server anonymously.\nThis setup yields a trust model which sits in between the classical curator and\nlocal models for differential privacy. The shuffle model is the core idea in\nthe Encode, Shuffle, Analyze (ESA) model introduced by Bittau et al. (SOPS\n2017). Recent work by Cheu et al. (EUROCRYPT 2019) analyzes the differential\nprivacy properties of the shuffle model and shows that in some cases shuffled\nprotocols provide strictly better accuracy than local protocols. Additionally,\nErlingsson et al. (SODA 2019) provide a privacy amplification bound quantifying\nthe level of curator differential privacy achieved by the shuffle model in\nterms of the local differential privacy of the randomizer used by each user. In\nthis context, we make three contributions. First, we provide an optimal single\nmessage protocol for summation of real numbers in the shuffle model. Our\nprotocol is very simple and has better accuracy and communication than the\nprotocols for this same problem proposed by Cheu et al. Optimality of this\nprotocol follows from our second contribution, a new lower bound for the\naccuracy of private protocols for summation of real numbers in the shuffle\nmodel. The third contribution is a new amplification bound for analyzing the\nprivacy of protocols in the shuffle model in terms of the privacy provided by\nthe corresponding local randomizer. Our amplification bound generalizes the\nresults by Erlingsson et al. to a wider range of parameters, and provides a\nwhole family of methods to analyze privacy amplification in the shuffle model.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 11:12:39 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 10:18:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Balle", "Borja", ""], ["Bell", "James", ""], ["Gascon", "Adria", ""], ["Nissim", "Kobbi", ""]]}, {"id": "1903.02891", "submitter": "Felix Sattler", "authors": "Felix Sattler, Simon Wiedemann, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Robust and Communication-Efficient Federated Learning from Non-IID Data", "comments": "17 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning allows multiple parties to jointly train a deep learning\nmodel on their combined data, without any of the participants having to reveal\ntheir local data to a centralized server. This form of privacy-preserving\ncollaborative learning however comes at the cost of a significant communication\noverhead during training. To address this problem, several compression methods\nhave been proposed in the distributed training literature that can reduce the\namount of required communication by up to three orders of magnitude. These\nexisting methods however are only of limited utility in the Federated Learning\nsetting, as they either only compress the upstream communication from the\nclients to the server (leaving the downstream communication uncompressed) or\nonly perform well under idealized conditions such as iid distribution of the\nclient data, which typically can not be found in Federated Learning. In this\nwork, we propose Sparse Ternary Compression (STC), a new compression framework\nthat is specifically designed to meet the requirements of the Federated\nLearning environment. Our experiments on four different learning tasks\ndemonstrate that STC distinctively outperforms Federated Averaging in common\nFederated Learning scenarios where clients either a) hold non-iid data, b) use\nsmall batch sizes during training, or where c) the number of clients is large\nand the participation rate in every communication round is low. We furthermore\nshow that even if the clients hold iid data and use medium sized batches for\ntraining, STC still behaves pareto-superior to Federated Averaging in the sense\nthat it achieves fixed target accuracies on our benchmarks within both fewer\ntraining iterations and a smaller communication budget.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 13:10:30 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Sattler", "Felix", ""], ["Wiedemann", "Simon", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1903.02893", "submitter": "Vivek Bakaraju", "authors": "Vivek Bakaraju, Kishore Reddy Konda", "title": "Only sparsity based loss function for learning representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the emergence of sparse representations in neural networks. We show\nthat in unsupervised models with regularization, the emergence of sparsity is\nthe result of the input data samples being distributed along highly non-linear\nor discontinuous manifold. We also derive a similar argument for\ndiscriminatively trained networks and present experiments to support this\nhypothesis. Based on our study of sparsity, we introduce a new loss function\nwhich can be used as regularization term for models like autoencoders and MLPs.\nFurther, the same loss function can also be used as a cost function for an\nunsupervised single-layered neural network model for learning efficient\nrepresentations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 13:11:39 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Bakaraju", "Vivek", ""], ["Konda", "Kishore Reddy", ""]]}, {"id": "1903.02926", "submitter": "Dario Pasquini", "authors": "Dario Pasquini, Marco Mingione and Massimo Bernaschi", "title": "Adversarial Out-domain Examples for Generative Models", "comments": "accepted in proceedings of the Workshop on Machine Learning for\n  Cyber-Crime Investigation and Cybersecurity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are rapidly becoming a common tool for researchers and\ndevelopers. However, as exhaustively shown for the family of discriminative\nmodels, the test-time inference of deep neural networks cannot be fully\ncontrolled and erroneous behaviors can be induced by an attacker. In the\npresent work, we show how a malicious user can force a pre-trained generator to\nreproduce arbitrary data instances by feeding it suitable adversarial inputs.\nMoreover, we show that these adversarial latent vectors can be shaped so as to\nbe statistically indistinguishable from the set of genuine inputs. The proposed\nattack technique is evaluated with respect to various GAN images generators\nusing different architectures, training processes and for both conditional and\nnot-conditional setups.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 14:13:59 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 20:01:02 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Pasquini", "Dario", ""], ["Mingione", "Marco", ""], ["Bernaschi", "Massimo", ""]]}, {"id": "1903.02948", "submitter": "Sandesh Ghimire", "authors": "Sandesh Ghimire, Prashnna Kumar Gyawali, Jwala Dhamala, John L Sapp,\n  Milan Horacek and Linwei Wang", "title": "Improving Generalization of Deep Networks for Inverse Reconstruction of\n  Image Sequences", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.05713", "journal-ref": "International Conference on Information Processing and Medical\n  Imaging 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning networks have shown state-of-the-art performance in many image\nreconstruction problems. However, it is not well understood what properties of\nrepresentation and learning may improve the generalization ability of the\nnetwork. In this paper, we propose that the generalization ability of an\nencoder-decoder network for inverse reconstruction can be improved in two\nmeans. First, drawing from analytical learning theory, we theoretically show\nthat a stochastic latent space will improve the ability of a network to\ngeneralize to test data outside the training distribution. Second, following\nthe information bottleneck principle, we show that a latent representation\nminimally informative of the input data will help a network generalize to\nunseen input variations that are irrelevant to the output reconstruction.\nTherefore, we present a sequence image reconstruction network optimized by a\nvariational approximation of the information bottleneck principle with\nstochastic latent space. In the application setting of reconstructing the\nsequence of cardiac transmembrane potential from bodysurface potential, we\nassess the two types of generalization abilities of the presented network\nagainst its deterministic counterpart. The results demonstrate that the\ngeneralization ability of an inverse reconstruction network can be improved by\nstochasticity as well as the information bottleneck.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 23:26:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ghimire", "Sandesh", ""], ["Gyawali", "Prashnna Kumar", ""], ["Dhamala", "Jwala", ""], ["Sapp", "John L", ""], ["Horacek", "Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "1903.02958", "submitter": "Tim R. Davidson", "authors": "Luca Falorsi, Pim de Haan, Tim R. Davidson, Patrick Forr\\'e", "title": "Reparameterizing Distributions on Lie Groups", "comments": "AISTATS (2019), code available at https://github.com/pimdh/relie", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG math.PR math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reparameterizable densities are an important way to learn probability\ndistributions in a deep learning setting. For many distributions it is possible\nto create low-variance gradient estimators by utilizing a `reparameterization\ntrick'. Due to the absence of a general reparameterization trick, much research\nhas recently been devoted to extend the number of reparameterizable\ndistributional families. Unfortunately, this research has primarily focused on\ndistributions defined in Euclidean space, ruling out the usage of one of the\nmost influential class of spaces with non-trivial topologies: Lie groups. In\nthis work we define a general framework to create reparameterizable densities\non arbitrary Lie groups, and provide a detailed practitioners guide to further\nthe ease of usage. We demonstrate how to create complex and multimodal\ndistributions on the well known oriented group of 3D rotations,\n$\\operatorname{SO}(3)$, using normalizing flows. Our experiments on applying\nsuch distributions in a Bayesian setting for pose estimation on objects with\ndiscrete and continuous symmetries, showcase their necessity in achieving\nrealistic uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 14:49:30 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Falorsi", "Luca", ""], ["de Haan", "Pim", ""], ["Davidson", "Tim R.", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "1903.02984", "submitter": "Da Tang", "authors": "Da Tang, Rajesh Ranganath", "title": "The Variational Predictive Natural Gradient", "comments": "International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference transforms posterior inference into parametric\noptimization thereby enabling the use of latent variable models where otherwise\nimpractical. However, variational inference can be finicky when different\nvariational parameters control variables that are strongly correlated under the\nmodel. Traditional natural gradients based on the variational approximation\nfail to correct for correlations when the approximation is not the true\nposterior. To address this, we construct a new natural gradient called the\nVariational Predictive Natural Gradient (VPNG). Unlike traditional natural\ngradients for variational inference, this natural gradient accounts for the\nrelationship between model parameters and variational parameters. We\ndemonstrate the insight with a simple example as well as the empirical value on\na classification task, a deep generative model of images, and probabilistic\nmatrix factorization for recommendation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 15:22:23 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 00:59:41 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 22:56:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Tang", "Da", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1903.02993", "submitter": "Jack Parker-Holder", "authors": "Krzysztof Choromanski, Aldo Pacchiano, Jack Parker-Holder, Yunhao\n  Tang, Deepali Jain, Yuxiang Yang, Atil Iscen, Jasmine Hsu and Vikas Sindhwani", "title": "Provably Robust Blackbox Optimization for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in derivative-free optimization (DFO) and \"evolutionary strategies\"\n(ES) has recently surged in the Reinforcement Learning (RL) community, with\ngrowing evidence that they can match state of the art methods for policy\noptimization problems in Robotics. However, it is well known that DFO methods\nsuffer from prohibitively high sampling complexity. They can also be very\nsensitive to noisy rewards and stochastic dynamics. In this paper, we propose a\nnew class of algorithms, called Robust Blackbox Optimization (RBO). Remarkably,\neven if up to $23\\%$ of all the measurements are arbitrarily corrupted, RBO can\nprovably recover gradients to high accuracy. RBO relies on learning gradient\nflows using robust regression methods to enable off-policy updates. On several\nMuJoCo robot control tasks, when all other RL approaches collapse in the\npresence of adversarial noise, RBO is able to train policies effectively. We\nalso show that RBO can be applied to legged locomotion tasks including path\ntracking for quadruped robots.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 15:29:05 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 12:30:07 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Pacchiano", "Aldo", ""], ["Parker-Holder", "Jack", ""], ["Tang", "Yunhao", ""], ["Jain", "Deepali", ""], ["Yang", "Yuxiang", ""], ["Iscen", "Atil", ""], ["Hsu", "Jasmine", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1903.03008", "submitter": "Tahar Kechadi M", "authors": "Lamine M. Aouad, Nhien-An Le-Khac, Tahar M. Kechadi", "title": "Performance study of distributed Apriori-like frequent itemsets mining", "comments": null, "journal-ref": "Knowledge and Information Systems April 2010, Volume 23, Issue 1", "doi": "10.1007/s10115-009-0205-3", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we focus on distributed Apriori-based frequent itemsets\nmining. We present a new distributed approach which takes into account inherent\ncharacteristics of this algorithm. We study the distribution aspect of this\nalgorithm and give a comparison of the proposed approach with a classical\nApriori-like distributed algorithm, using both analytical and experimental\nstudies. We find that under a wide range of conditions and datasets, the\nperformance of a distributed Apriori-like algorithm is not related to global\nstrategies of pruning since the performance of the local Apriori generation is\nusually characterized by relatively high success rates of candidate sets\nfrequency at low levels which switch to very low rates at some stage, and often\ndrops to zero. This means that the intermediate communication steps and remote\nsupport counts computation and collection in classical distributed schemes are\ncomputationally inefficient locally, and then constrains the global\nperformance. Our performance evaluation is done on a large cluster of\nworkstations using the Condor system and its workflow manager DAGMan. The\nresults show that the presented approach greatly enhances the performance and\nachieves good scalability compared to a typical distributed Apriori founded\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:47:35 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Aouad", "Lamine M.", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "Tahar M.", ""]]}, {"id": "1903.03040", "submitter": "Kjetil Olsen Lye", "authors": "Kjetil O. Lye, Siddhartha Mishra, Deep Ray", "title": "Deep learning observables in computational fluid dynamics", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109339", "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many large scale problems in computational fluid dynamics such as uncertainty\nquantification, Bayesian inversion, data assimilation and PDE constrained\noptimization are considered very challenging computationally as they require a\nlarge number of expensive (forward) numerical solutions of the corresponding\nPDEs. We propose a machine learning algorithm, based on deep artificial neural\nnetworks, that predicts the underlying \\emph{input parameters to observable}\nmap from a few training samples (computed realizations of this map). By a\njudicious combination of theoretical arguments and empirical observations, we\nfind suitable network architectures and training hyperparameters that result in\nrobust and efficient neural network approximations of the parameters to\nobservable map. Numerical experiments are presented to demonstrate low\nprediction errors for the trained network networks, even when the network has\nbeen trained with a few samples, at a computational cost which is several\norders of magnitude lower than the underlying PDE solver.\n  Moreover, we combine the proposed deep learning algorithm with Monte Carlo\n(MC) and Quasi-Monte Carlo (QMC) methods to efficiently compute uncertainty\npropagation for nonlinear PDEs. Under the assumption that the underlying neural\nnetworks generalize well, we prove that the deep learning MC and QMC algorithms\nare guaranteed to be faster than the baseline (quasi-) Monte Carlo methods.\nNumerical experiments demonstrating one to two orders of magnitude speed up\nover baseline QMC and MC algorithms, for the intricate problem of computing\nprobability distributions of the observable, are also presented.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 16:57:52 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 09:31:28 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lye", "Kjetil O.", ""], ["Mishra", "Siddhartha", ""], ["Ray", "Deep", ""]]}, {"id": "1903.03046", "submitter": "Xitong Gao", "authors": "Yiren Zhao, Xitong Gao, Daniel Bates, Robert Mullins, Cheng-Zhong Xu", "title": "Focused Quantization for Sparse CNNs", "comments": "To appear in NeurIPS 2019, this is the same paper adapted for viewing\n  on arXiv. TL;DR: Better size/accuracy trade-off of compressed sparse models\n  with focused quantization. 11 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep convolutional neural networks (CNNs) are powerful tools for a wide range\nof vision tasks, but the enormous amount of memory and compute resources\nrequired by CNNs pose a challenge in deploying them on constrained devices.\nExisting compression techniques, while excelling at reducing model sizes,\nstruggle to be computationally friendly. In this paper, we attend to the\nstatistical properties of sparse CNNs and present focused quantization, a novel\nquantization strategy based on power-of-two values, which exploits the weight\ndistributions after fine-grained pruning. The proposed method dynamically\ndiscovers the most effective numerical representation for weights in layers\nwith varying sparsities, significantly reducing model sizes. Multiplications in\nquantized CNNs are replaced with much cheaper bit-shift operations for\nefficient inference. Coupled with lossless encoding, we built a compression\npipeline that provides CNNs with high compression ratios (CR), low computation\ncost and minimal loss in accuracy. In ResNet-50, we achieved a 18.08x CR with\nonly 0.24% loss in top-5 accuracy, outperforming existing compression methods.\nWe fully compressed a ResNet-18 and found that it is not only higher in CR and\ntop-5 accuracy, but also more hardware efficient as it requires fewer logic\ngates to implement when compared to other state-of-the-art quantization methods\nassuming the same throughput.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 17:06:07 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 07:26:05 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 03:44:03 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhao", "Yiren", ""], ["Gao", "Xitong", ""], ["Bates", "Daniel", ""], ["Mullins", "Robert", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "1903.03058", "submitter": "Wen Tang", "authors": "Wen Tang, Ashkan Panahi, Hamid Krim, Liyi Dai", "title": "Analysis Dictionary Learning: An Efficient and Discriminative Solution", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminative Dictionary Learning (DL) methods have been widely advocated\nfor image classification problems. To further sharpen their discriminative\ncapabilities, most state-of-the-art DL methods have additional constraints\nincluded in the learning stages. These various constraints, however, lead to\nadditional computational complexity. We hence propose an efficient\nDiscriminative Convolutional Analysis Dictionary Learning (DCADL) method, as a\nlower cost Discriminative DL framework, to both characterize the image\nstructures and refine the interclass structure representations. The proposed\nDCADL jointly learns a convolutional analysis dictionary and a universal\nclassifier, while greatly reducing the time complexity in both training and\ntesting phases, and achieving a competitive accuracy, thus demonstrating great\nperformance in many experiments with standard databases.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 17:32:32 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Tang", "Wen", ""], ["Panahi", "Ashkan", ""], ["Krim", "Hamid", ""], ["Dai", "Liyi", ""]]}, {"id": "1903.03064", "submitter": "Ekaterina Abramova", "authors": "Ekaterina Abramova, Luke Dickens, Daniel Kuhn and Aldo Faisal", "title": "RLOC: Neurobiologically Inspired Hierarchical Reinforcement Learning\n  Algorithm for Continuous Control of Nonlinear Dynamical Systems", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear optimal control problems are often solved with numerical methods\nthat require knowledge of system's dynamics which may be difficult to infer,\nand that carry a large computational cost associated with iterative\ncalculations. We present a novel neurobiologically inspired hierarchical\nlearning framework, Reinforcement Learning Optimal Control, which operates on\ntwo levels of abstraction and utilises a reduced number of controllers to solve\nnonlinear systems with unknown dynamics in continuous state and action spaces.\nOur approach is inspired by research at two levels of abstraction: first, at\nthe level of limb coordination human behaviour is explained by linear optimal\nfeedback control theory. Second, in cognitive tasks involving learning symbolic\nlevel action selection, humans learn such problems using model-free and\nmodel-based reinforcement learning algorithms. We propose that combining these\ntwo levels of abstraction leads to a fast global solution of nonlinear control\nproblems using reduced number of controllers. Our framework learns the local\ntask dynamics from naive experience and forms locally optimal infinite horizon\nLinear Quadratic Regulators which produce continuous low-level control. A\ntop-level reinforcement learner uses the controllers as actions and learns how\nto best combine them in state space while maximising a long-term reward. A\nsingle optimal control objective function drives high-level symbolic learning\nby providing training signals on desirability of each selected controller. We\nshow that a small number of locally optimal linear controllers are able to\nsolve global nonlinear control problems with unknown dynamics when combined\nwith a reinforcement learner in this hierarchical framework. Our algorithm\ncompetes in terms of computational cost and solution quality with sophisticated\ncontrol algorithms and we illustrate this with solutions to benchmark problems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 17:37:53 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Abramova", "Ekaterina", ""], ["Dickens", "Luke", ""], ["Kuhn", "Daniel", ""], ["Faisal", "Aldo", ""]]}, {"id": "1903.03082", "submitter": "Fabio Gonzalez", "authors": "Fabio A. Gonz\\'alez and Juan C. Caicedo", "title": "Quantum Latent Semantic Analysis", "comments": "ICTIR2011 International Conference on the Theory of Information\n  Retrieval", "journal-ref": null, "doi": "10.1007/978-3-642-23318-0_7", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to explore latent topic analysis (LTA), in the\ncontext of quantum information retrieval. LTA is a valuable technique for\ndocument analysis and representation, which has been extensively used in\ninformation retrieval and machine learning. Different LTA techniques have been\nproposed, some based on geometrical modeling (such as latent semantic analysis,\nLSA) and others based on a strong statistical foundation. However, these two\ndifferent approaches are not usually mixed. Quantum information retrieval has\nthe remarkable virtue of combining both geometry and probability in a common\nprincipled framework. We built on this quantum framework to propose a new LTA\nmethod, which has a clear geometrical motivation but also supports a\nwell-founded probabilistic interpretation. An initial exploratory\nexperimentation was performed on three standard data sets. The results show\nthat the proposed method outperforms LSA on two of the three datasets. These\nresults suggests that the quantum-motivated representation is an alternative\nfor geometrical latent topic modeling worthy of further exploration.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:19:55 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Gonz\u00e1lez", "Fabio A.", ""], ["Caicedo", "Juan C.", ""]]}, {"id": "1903.03088", "submitter": "Matthew MacKay", "authors": "Matthew MacKay, Paul Vicol, Jon Lorraine, David Duvenaud, Roger Grosse", "title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using\n  Structured Best-Response Functions", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization can be formulated as a bilevel optimization\nproblem, where the optimal parameters on the training set depend on the\nhyperparameters. We aim to adapt regularization hyperparameters for neural\nnetworks by fitting compact approximations to the best-response function, which\nmaps hyperparameters to optimal weights and biases. We show how to construct\nscalable best-response approximations for neural networks by modeling the\nbest-response as a single network whose hidden units are gated conditionally on\nthe regularizer. We justify this approximation by showing the exact\nbest-response for a shallow linear network with L2-regularized Jacobian can be\nrepresented by a similar gating mechanism. We fit this model using a\ngradient-based hyperparameter optimization algorithm which alternates between\napproximating the best-response around the current hyperparameters and\noptimizing the hyperparameters using the approximate best-response function.\nUnlike other gradient-based approaches, we do not require differentiating the\ntraining loss with respect to the hyperparameters, allowing us to tune discrete\nhyperparameters, data augmentation hyperparameters, and dropout probabilities.\nBecause the hyperparameters are adapted online, our approach discovers\nhyperparameter schedules that can outperform fixed hyperparameter values.\nEmpirically, our approach outperforms competing hyperparameter optimization\nmethods on large-scale deep learning problems. We call our networks, which\nupdate their own hyperparameters online during training, Self-Tuning Networks\n(STNs).\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:26:46 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["MacKay", "Matthew", ""], ["Vicol", "Paul", ""], ["Lorraine", "Jon", ""], ["Duvenaud", "David", ""], ["Grosse", "Roger", ""]]}, {"id": "1903.03096", "submitter": "Pascal Lamblin", "authors": "Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku\n  Evci, Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine\n  Manzagol, Hugo Larochelle", "title": "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few\n  Examples", "comments": "Code available at https://github.com/google-research/meta-dataset", "journal-ref": "International Conference on Learning Representations (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification refers to learning a classifier for new classes given\nonly a few examples. While a plethora of models have emerged to tackle it, we\nfind the procedure and datasets that are used to assess their progress lacking.\nTo address this limitation, we propose Meta-Dataset: a new benchmark for\ntraining and evaluating models that is large-scale, consists of diverse\ndatasets, and presents more realistic tasks. We experiment with popular\nbaselines and meta-learners on Meta-Dataset, along with a competitive method\nthat we propose. We analyze performance as a function of various\ncharacteristics of test tasks and examine the models' ability to leverage\ndiverse training sources for improving their generalization. We also propose a\nnew set of baselines for quantifying the benefit of meta-learning in\nMeta-Dataset. Our extensive experimentation has uncovered important research\nchallenges and we hope to inspire work in these directions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:48:55 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 16:04:30 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 22:22:53 GMT"}, {"version": "v4", "created": "Wed, 8 Apr 2020 15:58:20 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Triantafillou", "Eleni", ""], ["Zhu", "Tyler", ""], ["Dumoulin", "Vincent", ""], ["Lamblin", "Pascal", ""], ["Evci", "Utku", ""], ["Xu", "Kelvin", ""], ["Goroshin", "Ross", ""], ["Gelada", "Carles", ""], ["Swersky", "Kevin", ""], ["Manzagol", "Pierre-Antoine", ""], ["Larochelle", "Hugo", ""]]}, {"id": "1903.03104", "submitter": "James Bagrow", "authors": "Abigail Hotaling and James P. Bagrow", "title": "Accurate inference of crowdsourcing properties when using efficient\n  allocation strategies", "comments": "21 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allocation strategies improve the efficiency of crowdsourcing by decreasing\nthe work needed to complete individual tasks accurately. However, these\nalgorithms introduce bias by preferentially allocating workers onto easy tasks,\nleading to sets of completed tasks that are no longer representative of all\ntasks. This bias challenges inference of problem-wide properties such as\ntypical task difficulty or crowd properties such as worker completion times,\nimportant information that goes beyond the crowd responses themselves. Here we\nstudy inference about problem properties when using an allocation algorithm to\nimprove crowd efficiency. We introduce Decision-Explicit Probability Sampling\n(DEPS), a method to perform inference of problem properties while accounting\nfor the potential bias introduced by an allocation strategy. Experiments on\nreal and synthetic crowdsourcing data show that DEPS outperforms baseline\ninference methods while still leveraging the efficiency gains of the allocation\nmethod. The ability to perform accurate inference of general properties when\nusing non-representative data allows crowdsourcers to extract more knowledge\nout of a given crowdsourced dataset.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:58:34 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Hotaling", "Abigail", ""], ["Bagrow", "James P.", ""]]}, {"id": "1903.03107", "submitter": "Hyeong-Seok Choi", "authors": "Hyeong-Seok Choi, Jang-Hyun Kim, Jaesung Huh, Adrian Kim, Jung-Woo Ha,\n  and Kyogu Lee", "title": "Phase-aware Speech Enhancement with Deep Complex U-Net", "comments": "Significant error was found in data processing step, therefore will\n  be retracted from International Conference on Learning Representations (ICLR)\n  2019. It is not recommended to read current version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning-based models for speech enhancement have mainly focused on\nestimating the magnitude of spectrogram while reusing the phase from noisy\nspeech for reconstruction. This is due to the difficulty of estimating the\nphase of clean speech. To improve speech enhancement performance, we tackle the\nphase estimation problem in three ways. First, we propose Deep Complex U-Net,\nan advanced U-Net structured model incorporating well-defined complex-valued\nbuilding blocks to deal with complex-valued spectrograms. Second, we propose a\npolar coordinate-wise complex-valued masking method to reflect the distribution\nof complex ideal ratio masks. Third, we define a novel loss function, weighted\nsource-to-distortion ratio (wSDR) loss, which is designed to directly correlate\nwith a quantitative evaluation measure. Our model was evaluated on a mixture of\nthe Voice Bank corpus and DEMAND database, which has been widely used by many\ndeep learning models for speech enhancement. Ablation experiments were\nconducted on the mixed dataset showing that all three proposed approaches are\nempirically valid. Experimental results show that the proposed method achieves\nstate-of-the-art performance in all metrics, outperforming previous approaches\nby a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 10:41:37 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 08:11:35 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Choi", "Hyeong-Seok", ""], ["Kim", "Jang-Hyun", ""], ["Huh", "Jaesung", ""], ["Kim", "Adrian", ""], ["Ha", "Jung-Woo", ""], ["Lee", "Kyogu", ""]]}, {"id": "1903.03178", "submitter": "Arindam Paul", "authors": "Arindam Paul, Dipendra Jha, Reda Al-Bahrani, Wei-keng Liao, Alok\n  Choudhary, Ankit Agrawal", "title": "Transfer Learning Using Ensemble Neural Networks for Organic Solar Cell\n  Screening", "comments": "8 pages, 11 figures, International Joint Conference on Neural\n  Networks", "journal-ref": "International Joint Conference on Neural Networks, Budapest\n  Hungary, 14-19 July 2019", "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organic Solar Cells are a promising technology for solving the clean energy\ncrisis in the world. However, generating candidate chemical compounds for solar\ncells is a time-consuming process requiring thousands of hours of laboratory\nanalysis. For a solar cell, the most important property is the power conversion\nefficiency which is dependent on the highest occupied molecular orbitals (HOMO)\nvalues of the donor molecules. Recently, machine learning techniques have\nproved to be very useful in building predictive models for HOMO values of donor\nstructures of Organic Photovoltaic Cells (OPVs). Since experimental datasets\nare limited in size, current machine learning models are trained on data\nderived from calculations based on density functional theory (DFT). Molecular\nline notations such as SMILES or InChI are popular input representations for\ndescribing the molecular structure of donor molecules. The two types of line\nrepresentations encode different information, such as SMILES defines the bond\ntypes while InChi defines protonation. In this work, we present an ensemble\ndeep neural network architecture, called SINet, which harnesses both the SMILES\nand InChI molecular representations to predict HOMO values and leverage the\npotential of transfer learning from a sizeable DFT-computed dataset- Harvard\nCEP to build more robust predictive models for relatively smaller HOPV\ndatasets. Harvard CEP dataset contains molecular structures and properties for\n2.3 million candidate donor structures for OPV while HOPV contains DFT-computed\nand experimental values of 350 and 243 molecules respectively. Our results\ndemonstrate significant performance improvement from the use of transfer\nlearning and leveraging both molecular representations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:45:15 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 20:31:27 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 21:16:27 GMT"}, {"version": "v4", "created": "Sun, 28 Jul 2019 22:25:12 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Paul", "Arindam", ""], ["Jha", "Dipendra", ""], ["Al-Bahrani", "Reda", ""], ["Liao", "Wei-keng", ""], ["Choudhary", "Alok", ""], ["Agrawal", "Ankit", ""]]}, {"id": "1903.03202", "submitter": "Xiao Qiao", "authors": "Alexander James, Yaser S. Abu-Mostafa, Xiao Qiao", "title": "Nowcasting Recessions using the SVM Machine Learning Algorithm", "comments": "My company policy about sharing research papers has been changed. As\n  a result, I would like to withdraw the paper, with the full understanding\n  that previous version will remain accessible. Thank you very much", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG econ.GN q-fin.EC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel application of Support Vector Machines (SVM), an\nimportant Machine Learning algorithm, to determine the beginning and end of\nrecessions in real time. Nowcasting, \"forecasting\" a condition about the\npresent time because the full information about it is not available until\nlater, is key for recessions, which are only determined months after the fact.\nWe show that SVM has excellent predictive performance for this task, and we\nprovide implementation details to facilitate its use in similar problems in\neconomics and finance.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 15:04:35 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 14:53:06 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["James", "Alexander", ""], ["Abu-Mostafa", "Yaser S.", ""], ["Qiao", "Xiao", ""]]}, {"id": "1903.03232", "submitter": "Umar Asif", "authors": "Umar Asif, Subhrajit Roy, Jianbin Tang and Stefan Harrer", "title": "SeizureNet: Multi-Spectral Deep Feature Learning for Seizure Type\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic classification of epileptic seizure types in electroencephalograms\n(EEGs) data can enable more precise diagnosis and efficient management of the\ndisease. This task is challenging due to factors such as low signal-to-noise\nratios, signal artefacts, high variance in seizure semiology among epileptic\npatients, and limited availability of clinical data. To overcome these\nchallenges, in this paper, we present SeizureNet, a deep learning framework\nwhich learns multi-spectral feature embeddings using an ensemble architecture\nfor cross-patient seizure type classification. We used the recently released\nTUH EEG Seizure Corpus (V1.4.0 and V1.5.2) to evaluate the performance of\nSeizureNet. Experiments show that SeizureNet can reach a weighted F1 score of\nup to 0.94 for seizure-wise cross validation and 0.59 for patient-wise cross\nvalidation for scalp EEG based multi-class seizure type classification. We also\nshow that the high-level feature embeddings learnt by SeizureNet considerably\nimprove the accuracy of smaller networks through knowledge distillation for\napplications with low-memory constraints.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 00:49:31 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 03:17:25 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 07:48:25 GMT"}, {"version": "v4", "created": "Thu, 2 Apr 2020 06:32:59 GMT"}, {"version": "v5", "created": "Sun, 23 Aug 2020 05:08:41 GMT"}, {"version": "v6", "created": "Wed, 30 Sep 2020 03:09:00 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Asif", "Umar", ""], ["Roy", "Subhrajit", ""], ["Tang", "Jianbin", ""], ["Harrer", "Stefan", ""]]}, {"id": "1903.03234", "submitter": "Srinivasan Sivanandan", "authors": "Vaibhav Saxena, Srinivasan Sivanandan, Pulkit Mathur", "title": "Dyna-AIL : Adversarial Imitation Learning by Planning", "comments": "8 pages, 6 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial methods for imitation learning have been shown to perform well on\nvarious control tasks. However, they require a large number of environment\ninteractions for convergence. In this paper, we propose an end-to-end\ndifferentiable adversarial imitation learning algorithm in a Dyna-like\nframework for switching between model-based planning and model-free learning\nfrom expert data. Our results on both discrete and continuous environments show\nthat our approach of using model-based planning along with model-free learning\nconverges to an optimal policy with fewer number of environment interactions in\ncomparison to the state-of-the-art learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 00:54:49 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Saxena", "Vaibhav", ""], ["Sivanandan", "Srinivasan", ""], ["Mathur", "Pulkit", ""]]}, {"id": "1903.03237", "submitter": "Kazuyoshi Yoshii", "authors": "Kouhei Sekiguchi, Aditya Arie Nugraha, Yoshiaki Bando, Kazuyoshi\n  Yoshii", "title": "Fast Multichannel Source Separation Based on Jointly Diagonalizable\n  Spatial Covariance Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a versatile method that accelerates multichannel source\nseparation methods based on full-rank spatial modeling. A popular approach to\nmultichannel source separation is to integrate a spatial model with a source\nmodel for estimating the spatial covariance matrices (SCMs) and power spectral\ndensities (PSDs) of each sound source in the time-frequency domain. One of the\nmost successful examples of this approach is multichannel nonnegative matrix\nfactorization (MNMF) based on a full-rank spatial model and a low-rank source\nmodel. MNMF, however, is computationally expensive and often works poorly due\nto the difficulty of estimating the unconstrained full-rank SCMs. Instead of\nrestricting the SCMs to rank-1 matrices with the severe loss of the spatial\nmodeling ability as in independent low-rank matrix analysis (ILRMA), we\nrestrict the SCMs of each frequency bin to jointly-diagonalizable but still\nfull-rank matrices. For such a fast version of MNMF, we propose a\ncomputationally-efficient and convergence-guaranteed algorithm that is similar\nin form to that of ILRMA. Similarly, we propose a fast version of a\nstate-of-the-art speech enhancement method based on a deep speech model and a\nlow-rank noise model. Experimental results showed that the fast versions of\nMNMF and the deep speech enhancement method were several times faster and\nperformed even better than the original versions of those methods,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 01:17:23 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Sekiguchi", "Kouhei", ""], ["Nugraha", "Aditya Arie", ""], ["Bando", "Yoshiaki", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1903.03252", "submitter": "Alex Kearney", "authors": "Alex Kearney, Vivek Veeriah, Jaden Travnik, Patrick M. Pilarski,\n  Richard S. Sutton", "title": "Learning Feature Relevance Through Step Size Adaptation in\n  Temporal-Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a long history of using meta learning as representation learning,\nspecifically for determining the relevance of inputs. In this paper, we examine\nan instance of meta-learning in which feature relevance is learned by adapting\nstep size parameters of stochastic gradient descent---building on a variety of\nprior work in stochastic approximation, machine learning, and artificial neural\nnetworks. In particular, we focus on stochastic meta-descent introduced in the\nIncremental Delta-Bar-Delta (IDBD) algorithm for setting individual step sizes\nfor each feature of a linear function approximator. Using IDBD, a feature with\nlarge or small step sizes will have a large or small impact on generalization\nfrom training examples. As a main contribution of this work, we extend IDBD to\ntemporal-difference (TD) learning---a form of learning which is effective in\nsequential, non i.i.d. problems. We derive a variety of IDBD generalizations\nfor TD learning, demonstrating that they are able to distinguish which features\nare relevant and which are not. We demonstrate that TD IDBD is effective at\nlearning feature relevance in both an idealized gridworld and a real-world\nrobotic prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 02:29:22 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Kearney", "Alex", ""], ["Veeriah", "Vivek", ""], ["Travnik", "Jaden", ""], ["Pilarski", "Patrick M.", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1903.03253", "submitter": "Yaqing Wang", "authors": "Yaqing Wang, James T. Kwok, and Lionel M. Ni", "title": "General Convolutional Sparse Coding with Unknown Noise", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2020.2980980", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional sparse coding (CSC) can learn representative shift-invariant\npatterns from multiple kinds of data. However, existing CSC methods can only\nmodel noises from Gaussian distribution, which is restrictive and unrealistic.\nIn this paper, we propose a general CSC model capable of dealing with\ncomplicated unknown noise. The noise is now modeled by Gaussian mixture model,\nwhich can approximate any continuous probability density function. We use the\nexpectation-maximization algorithm to solve the problem and design an efficient\nmethod for the weighted CSC problem in maximization step. The crux is to speed\nup the convolution in the frequency domain while keeping the other computation\ninvolving weight matrix in the spatial domain. Besides, we simultaneously\nupdate the dictionary and codes by nonconvex accelerated proximal gradient\nalgorithm without bringing in extra alternating loops. The resultant method\nobtains comparable time and space complexity compared with existing CSC\nmethods. Extensive experiments on synthetic and real noisy biomedical data sets\nvalidate that our method can model noise effectively and obtain high-quality\nfilters and representation.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 02:32:43 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Wang", "Yaqing", ""], ["Kwok", "James T.", ""], ["Ni", "Lionel M.", ""]]}, {"id": "1903.03269", "submitter": "Kazuyoshi Yoshii", "authors": "Aditya Arie Nugraha, Kouhei Sekiguchi, Kazuyoshi Yoshii", "title": "A Deep Generative Model of Speech Complex Spectrograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach to the joint modeling of the short-time\nFourier transform magnitude and phase spectrograms with a deep generative\nmodel. We assume that the magnitude follows a Gaussian distribution and the\nphase follows a von Mises distribution. To improve the consistency of the phase\nvalues in the time-frequency domain, we also apply the von Mises distribution\nto the phase derivatives, i.e., the group delay and the instantaneous\nfrequency. Based on these assumptions, we explore and compare several\ncombinations of loss functions for training our models. Built upon the\nvariational autoencoder framework, our model consists of three convolutional\nneural networks acting as an encoder, a magnitude decoder, and a phase decoder.\nIn addition to the latent variables, we propose to also condition the phase\nestimation on the estimated magnitude. Evaluated for a time-domain speech\nreconstruction task, our models could generate speech with a high perceptual\nquality and a high intelligibility.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 03:57:30 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Nugraha", "Aditya Arie", ""], ["Sekiguchi", "Kouhei", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1903.03279", "submitter": "Yu Inatsu", "authors": "Yu Inatsu, Daisuke Sugita, Kazuaki Toyoura, Ichiro Takeuchi", "title": "Active learning for enumerating local minima based on Gaussian process\n  derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study active learning (AL) based on Gaussian Processes (GPs) for\nefficiently enumerating all of the local minimum solutions of a black-box\nfunction. This problem is challenging due to the fact that local solutions are\ncharacterized by their zero gradient and positive-definite Hessian properties,\nbut those derivatives cannot be directly observed. We propose a new AL method\nin which the input points are sequentially selected such that the confidence\nintervals of the GP derivatives are effectively updated for enumerating local\nminimum solutions. We theoretically analyze the proposed method and demonstrate\nits usefulness through numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 04:35:02 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Inatsu", "Yu", ""], ["Sugita", "Daisuke", ""], ["Toyoura", "Kazuaki", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1903.03300", "submitter": "Dominique Gay", "authors": "Dominique Gay and Vincent Lemaire", "title": "Should we Reload Time Series Classification Performance Evaluation ? (a\n  position paper)", "comments": "8 pages", "journal-ref": "3rd ECML/PKDD Workshop on Advanced Analytics and Learning on\n  Temporal Data (AALTD 2018)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the introduction and the public availability of the \\textsc{ucr} time\nseries benchmark data sets, numerous Time Series Classification (TSC) methods\nhas been designed, evaluated and compared to each others. We suggest a critical\nview of TSC performance evaluation protocols put in place in recent TSC\nliterature. The main goal of this `position' paper is to stimulate discussion\nand reflexion about performance evaluation in TSC literature.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 06:26:59 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Gay", "Dominique", ""], ["Lemaire", "Vincent", ""]]}, {"id": "1903.03315", "submitter": "Huyan Huang", "authors": "Huyan Huang and Yipeng Liu and Ce Zhu", "title": "Provable Tensor Ring Completion", "comments": null, "journal-ref": "Signal Processing, vol. 171, p. 107486, 2020", "doi": "10.1016/j.sigpro.2020.107486", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion recovers a multi-dimensional array from a limited number of\nmeasurements. Using the recently proposed tensor ring (TR) decomposition, in\nthis paper we show that a d-order tensor of dimensional size n and TR rank r\ncan be exactly recovered with high probability by solving a convex optimization\nprogram, given n^{d/2} r^2 ln^7(n^{d/2})samples. The proposed TR incoherence\ncondition under which the result holds is similar to the matrix incoherence\ncondition. The experiments on synthetic data verify the recovery guarantee for\nTR completion. Moreover, the experiments on real-world data show that our\nmethod improves the recovery performance compared with the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 08:04:25 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 12:32:52 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 05:35:21 GMT"}, {"version": "v4", "created": "Sun, 17 Mar 2019 13:15:43 GMT"}, {"version": "v5", "created": "Thu, 21 Mar 2019 02:20:01 GMT"}, {"version": "v6", "created": "Thu, 9 Jan 2020 03:14:22 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Huang", "Huyan", ""], ["Liu", "Yipeng", ""], ["Zhu", "Ce", ""]]}, {"id": "1903.03324", "submitter": "Mikel Elkano", "authors": "Mikel Elkano and Humberto Bustince and Mikel Galar", "title": "Do we still need fuzzy classifiers for Small Data in the Era of Big\n  Data?", "comments": "To appear in 2019 IEEE International Conference on Fuzzy Systems\n  (FUZZ-IEEE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Era of Big Data has forced researchers to explore new distributed\nsolutions for building fuzzy classifiers, which often introduce approximation\nerrors or make strong assumptions to reduce computational and memory\nrequirements. As a result, Big Data classifiers might be expected to be\ninferior to those designed for standard classification tasks (Small Data) in\nterms of accuracy and model complexity. To our knowledge, however, there is no\nempirical evidence to confirm such a conjecture yet. Here, we investigate the\nextent to which state-of-the-art fuzzy classifiers for Big Data sacrifice\nperformance in favor of scalability. To this end, we carry out an empirical\nstudy that compares these classifiers with some of the best performing\nalgorithms for Small Data. Assuming the latter were generally designed for\nmaximizing performance without considering scalability issues, the results of\nthis study provide some intuition around the tradeoff between performance and\nscalability achieved by current Big Data solutions. Our findings show that,\nalthough slightly inferior, Big Data classifiers are gradually catching up with\nstate-of-the-art classifiers for Small data, suggesting that a unified learning\nalgorithm for Big and Small Data might be possible.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 08:46:27 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Elkano", "Mikel", ""], ["Bustince", "Humberto", ""], ["Galar", "Mikel", ""]]}, {"id": "1903.03332", "submitter": "Sourav Medya", "authors": "Sahil Manchanda and Akash Mittal and Anuj Dhawan and Sourav Medya and\n  Sayan Ranu and Ambuj Singh", "title": "Learning Heuristics over Large Graphs via Deep Reinforcement Learning", "comments": "To appear in NeurIPS 2020\n  https://papers.nips.cc/paper/2020/hash/e7532dbeff7ef901f2e70daacb3f452d-Abstract.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increased interest in discovering heuristics for\ncombinatorial problems on graphs through machine learning. While existing\ntechniques have primarily focused on obtaining high-quality solutions,\nscalability to billion-sized graphs has not been adequately addressed. In\naddition, the impact of budget-constraint, which is necessary for many\npractical scenarios, remains to be studied. In this paper, we propose a\nframework called GCOMB to bridge these gaps. GCOMB trains a Graph Convolutional\nNetwork (GCN) using a novel probabilistic greedy mechanism to predict the\nquality of a node. To further facilitate the combinatorial nature of the\nproblem, GCOMB utilizes a Q-learning framework, which is made efficient through\nimportance sampling. We perform extensive experiments on real graphs to\nbenchmark the efficiency and efficacy of GCOMB. Our results establish that\nGCOMB is 100 times faster and marginally better in quality than\nstate-of-the-art algorithms for learning combinatorial algorithms.\nAdditionally, a case-study on the practical combinatorial problem of Influence\nMaximization (IM) shows GCOMB is 150 times faster than the specialized IM\nalgorithm IMM with similar quality.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 09:23:08 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 03:31:07 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 08:01:08 GMT"}, {"version": "v4", "created": "Wed, 2 Dec 2020 12:17:04 GMT"}, {"version": "v5", "created": "Thu, 3 Dec 2020 05:51:59 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Manchanda", "Sahil", ""], ["Mittal", "Akash", ""], ["Dhawan", "Anuj", ""], ["Medya", "Sourav", ""], ["Ranu", "Sayan", ""], ["Singh", "Ambuj", ""]]}, {"id": "1903.03348", "submitter": "Wei Shao Dr", "authors": "Wei Shao, Flora D. Salim, Jeffrey Chan, Sean Morrison and Fabio\n  Zambetta", "title": "Approximating Optimisation Solutions for Travelling Officer Problem with\n  Customised Deep Learning Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been extended to a number of new domains with critical\nsuccess, though some traditional orienteering problems such as the Travelling\nSalesman Problem (TSP) and its variants are not commonly solved using such\ntechniques. Deep neural networks (DNNs) are a potentially promising and\nunder-explored solution to solve these problems due to their powerful function\napproximation abilities, and their fast feed-forward computation. In this\npaper, we outline a method for converting an orienteering problem into a\nclassification problem, and design a customised multi-layer deep learning\nnetwork to approximate traditional optimisation solutions to this problem. We\ntest the performance of the network on a real-world parking violation dataset,\nand conduct a generic study that empirically shows the critical architectural\ncomponents that affect network performance for this problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 10:04:27 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Shao", "Wei", ""], ["Salim", "Flora D.", ""], ["Chan", "Jeffrey", ""], ["Morrison", "Sean", ""], ["Zambetta", "Fabio", ""]]}, {"id": "1903.03364", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Large-Margin Multiple Kernel Learning for Discriminative Features\n  Selection and Representation Learning", "comments": "8 Pages, 2 figures, IJCNN 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple kernel learning (MKL) algorithms combine different base kernels to\nobtain a more efficient representation in the feature space. Focusing on\ndiscriminative tasks, MKL has been used successfully for feature selection and\nfinding the significant modalities of the data. In such applications, each base\nkernel represents one dimension of the data or is derived from one specific\ndescriptor. Therefore, MKL finds an optimal weighting scheme for the given\nkernels to increase the classification accuracy. Nevertheless, the majority of\nthe works in this area focus on only binary classification problems or aim for\nlinear separation of the classes in the kernel space, which are not realistic\nassumptions for many real-world problems. In this paper, we propose a novel\nmulti-class MKL framework which improves the state-of-the-art by enhancing the\nlocal separation of the classes in the feature space. Besides, by using a\nsparsity term, our large-margin multiple kernel algorithm (LMMK) performs\ndiscriminative feature selection by aiming to employ a small subset of the base\nkernels. Based on our empirical evaluations on different real-world datasets,\nLMMK provides a competitive classification accuracy compared with the\nstate-of-the-art algorithms in MKL. Additionally, it learns a sparse set of\nnon-zero kernel weights which leads to a more interpretable feature selection\nand representation learning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 10:51:03 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 23:00:12 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.03386", "submitter": "Vikram Venkatraghavan", "authors": "Vikram Venkatraghavan and Florian Dubost and Esther E. Bron and Wiro\n  J. Niessen and Marleen de Bruijne and Stefan Klein", "title": "Event-Based Modeling with High-Dimensional Imaging Biomarkers for\n  Estimating Spatial Progression of Dementia", "comments": "IPMI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Event-based models (EBM) are a class of disease progression models that can\nbe used to estimate temporal ordering of neuropathological changes from\ncross-sectional data. Current EBMs only handle scalar biomarkers, such as\nregional volumes, as inputs. However, regional aggregates are a crude summary\nof the underlying high-resolution images, potentially limiting the accuracy of\nEBM. Therefore, we propose a novel method that exploits high-dimensional\nvoxel-wise imaging biomarkers: n-dimensional discriminative EBM (nDEBM). nDEBM\nis based on an insight that mixture modeling, which is a key element of\nconventional EBMs, can be replaced by a more scalable semi-supervised support\nvector machine (SVM) approach. This SVM is used to estimate the degree of\nabnormality of each region which is then used to obtain subject-specific\ndisease progression patterns. These patterns are in turn used for estimating\nthe mean ordering by fitting a generalized Mallows model. In order to validate\nthe biomarker ordering obtained using nDEBM, we also present a framework for\nSimulation of Imaging Biomarkers' Temporal Evolution (SImBioTE) that mimics\nneurodegeneration in brain regions. SImBioTE trains variational auto-encoders\n(VAE) in different brain regions independently to simulate images at varying\nstages of disease progression. We also validate nDEBM clinically using data\nfrom the Alzheimer's Disease Neuroimaging Initiative (ADNI). In both\nexperiments, nDEBM using high-dimensional features gave better performance than\nstate-of-the-art EBM methods using regional volume biomarkers. This suggests\nthat nDEBM is a promising approach for disease progression modeling.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 12:05:58 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Venkatraghavan", "Vikram", ""], ["Dubost", "Florian", ""], ["Bron", "Esther E.", ""], ["Niessen", "Wiro J.", ""], ["de Bruijne", "Marleen", ""], ["Klein", "Stefan", ""]]}, {"id": "1903.03425", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "The Ethics of AI Ethics -- An Evaluation of Guidelines", "comments": "16 pages, 1 table", "journal-ref": "Minds & Machines, 2020", "doi": "10.1007/s11023-020-09517-8", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current advances in research, development and application of artificial\nintelligence (AI) systems have yielded a far-reaching discourse on AI ethics.\nIn consequence, a number of ethics guidelines have been released in recent\nyears. These guidelines comprise normative principles and recommendations aimed\nto harness the \"disruptive\" potentials of new AI technologies. Designed as a\ncomprehensive evaluation, this paper analyzes and compares these guidelines\nhighlighting overlaps but also omissions. As a result, I give a detailed\noverview of the field of AI ethics. Finally, I also examine to what extent the\nrespective ethical principles and values are implemented in the practice of\nresearch, development and application of AI systems - and how the effectiveness\nin the demands of AI ethics can be improved.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 15:50:35 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 08:44:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "1903.03441", "submitter": "Tim Adler", "authors": "Tim J. Adler, Lynton Ardizzone, Anant Vemuri, Leonardo Ayala, Janek\n  Gr\\\"ohl, Thomas Kirchner, Sebastian Wirkert, Jakob Kruse, Carsten Rother,\n  Ullrich K\\\"othe and Lena Maier-Hein", "title": "Uncertainty-aware performance assessment of optical imaging modalities\n  with invertible neural networks", "comments": "Accepted at IPCAI 2019", "journal-ref": null, "doi": "10.1007/s11548-019-01939-9", "report-no": null, "categories": "physics.med-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Optical imaging is evolving as a key technique for advanced sensing\nin the operating room. Recent research has shown that machine learning\nalgorithms can be used to address the inverse problem of converting pixel-wise\nmultispectral reflectance measurements to underlying tissue parameters, such as\noxygenation. Assessment of the specific hardware used in conjunction with such\nalgorithms, however, has not properly addressed the possibility that the\nproblem may be ill-posed.\n  Methods: We present a novel approach to the assessment of optical imaging\nmodalities, which is sensitive to the different types of uncertainties that may\noccur when inferring tissue parameters. Based on the concept of invertible\nneural networks, our framework goes beyond point estimates and maps each\nmultispectral measurement to a full posterior probability distribution which is\ncapable of representing ambiguity in the solution via multiple modes.\nPerformance metrics for a hardware setup can then be computed from the\ncharacteristics of the posteriors.\n  Results: Application of the assessment framework to the specific use case of\ncamera selection for physiological parameter estimation yields the following\ninsights: (1) Estimation of tissue oxygenation from multispectral images is a\nwell-posed problem, while (2) blood volume fraction may not be recovered\nwithout ambiguity. (3) In general, ambiguity may be reduced by increasing the\nnumber of spectral bands in the camera.\n  Conclusion: Our method could help to optimize optical camera design in an\napplication-specific manner.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:39:15 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Adler", "Tim J.", ""], ["Ardizzone", "Lynton", ""], ["Vemuri", "Anant", ""], ["Ayala", "Leonardo", ""], ["Gr\u00f6hl", "Janek", ""], ["Kirchner", "Thomas", ""], ["Wirkert", "Sebastian", ""], ["Kruse", "Jakob", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""], ["Maier-Hein", "Lena", ""]]}, {"id": "1903.03447", "submitter": "Malik Tiomoko", "authors": "Malik Tiomoko and Romain Couillet", "title": "Random Matrix-Improved Estimation of the Wasserstein Distance between\n  two Centered Gaussian Distributions", "comments": "Submitted to European Signal Processing Conference (EUSIPCO'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a method to consistently estimate functionals\n$\\frac1p\\sum_{i=1}^pf(\\lambda_i(C_1C_2))$ of the eigenvalues of the product of\ntwo covariance matrices $C_1,C_2\\in\\mathbb{R}^{p\\times p}$ based on the\nempirical estimates $\\lambda_i(\\hat C_1\\hat C_2)$ ($\\hat\nC_a=\\frac1{n_a}\\sum_{i=1}^{n_a} x_i^{(a)}x_i^{(a){{\\sf T}}}$), when the size\n$p$ and number $n_a$ of the (zero mean) samples $x_i^{(a)}$ are similar. As a\ncorollary, a consistent estimate of the Wasserstein distance (related to the\ncase $f(t)=\\sqrt{t}$) between centered Gaussian distributions is derived.\n  The new estimate is shown to largely outperform the classical sample\ncovariance-based `plug-in' estimator. Based on this finding, a practical\napplication to covariance estimation is then devised which demonstrates\npotentially significant performance gains with respect to state-of-the-art\nalternatives.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:54:14 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Tiomoko", "Malik", ""], ["Couillet", "Romain", ""]]}, {"id": "1903.03448", "submitter": "Fredrik D. Johansson", "authors": "Fredrik D. Johansson, David Sontag, Rajesh Ranganath", "title": "Support and Invertibility in Domain-Invariant Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning domain-invariant representations has become a popular approach to\nunsupervised domain adaptation and is often justified by invoking a particular\nsuite of theoretical results. We argue that there are two significant flaws in\nsuch arguments. First, the results in question hold only for a fixed\nrepresentation and do not account for information lost in non-invertible\ntransformations. Second, domain invariance is often a far too strict\nrequirement and does not always lead to consistent estimation, even under\nstrong and favorable assumptions. In this work, we give generalization bounds\nfor unsupervised domain adaptation that hold for any representation function by\nacknowledging the cost of non-invertibility. In addition, we show that\npenalizing distance between densities is often wasteful and propose a bound\nbased on measuring the extent to which the support of the source domain covers\nthe target domain. We perform experiments on well-known benchmarks that\nillustrate the short-comings of current standard practice.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:56:24 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 15:39:57 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 12:48:05 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 22:58:51 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Johansson", "Fredrik D.", ""], ["Sontag", "David", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1903.03488", "submitter": "Eran Malach", "authors": "Eran Malach, Shai Shalev-Shwartz", "title": "Is Deeper Better only when Shallow is Good?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the power of depth in feed-forward neural networks is an\nongoing challenge in the field of deep learning theory. While current works\naccount for the importance of depth for the expressive power of\nneural-networks, it remains an open question whether these benefits are\nexploited during a gradient-based optimization process. In this work we explore\nthe relation between expressivity properties of deep networks and the ability\nto train them efficiently using gradient-based algorithms. We give a depth\nseparation argument for distributions with fractal structure, showing that they\ncan be expressed efficiently by deep networks, but not with shallow ones. These\ndistributions have a natural coarse-to-fine structure, and we show that the\nbalance between the coarse and fine details has a crucial effect on whether the\noptimization process is likely to succeed. We prove that when the distribution\nis concentrated on the fine details, gradient-based algorithms are likely to\nfail. Using this result we prove that, at least in some distributions, the\nsuccess of learning deep networks depends on whether the distribution can be\nwell approximated by shallower networks, and we conjecture that this property\nholds in general.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 15:14:30 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1903.03536", "submitter": "Martin Wistuba", "authors": "Martin Wistuba, Tejaswini Pedapati", "title": "Inductive Transfer for Neural Architecture Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advent of automated neural network architecture search led to\nseveral methods that outperform state-of-the-art human-designed architectures.\nHowever, these approaches are computationally expensive, in extreme cases\nconsuming GPU years. We propose two novel methods which aim to expedite this\noptimization problem by transferring knowledge acquired from previous tasks to\nnew ones. First, we propose a novel neural architecture selection method which\nemploys this knowledge to identify strong and weak characteristics of neural\narchitectures across datasets. Thus, these characteristics do not need to be\nrediscovered in every search, a strong weakness of current state-of-the-art\nsearches. Second, we propose a method for learning curve extrapolation to\ndetermine if a training process can be terminated early. In contrast to\nexisting work, we propose to learn from learning curves of architectures\ntrained on other datasets to improve the prediction accuracy for novel\ndatasets. On five different image classification benchmarks, we empirically\ndemonstrate that both of our orthogonal contributions independently lead to an\nacceleration, without any significant loss in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 16:27:32 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Wistuba", "Martin", ""], ["Pedapati", "Tejaswini", ""]]}, {"id": "1903.03571", "submitter": "David Burt", "authors": "David R. Burt, Carl E. Rasmussen, Mark van der Wilk", "title": "Rates of Convergence for Sparse Variational Gaussian Process Regression", "comments": "International Conference on Machine Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excellent variational approximations to Gaussian process posteriors have been\ndeveloped which avoid the $\\mathcal{O}\\left(N^3\\right)$ scaling with dataset\nsize $N$. They reduce the computational cost to $\\mathcal{O}\\left(NM^2\\right)$,\nwith $M\\ll N$ being the number of inducing variables, which summarise the\nprocess. While the computational cost seems to be linear in $N$, the true\ncomplexity of the algorithm depends on how $M$ must increase to ensure a\ncertain quality of approximation. We address this by characterising the\nbehavior of an upper bound on the KL divergence to the posterior. We show that\nwith high probability the KL divergence can be made arbitrarily small by\ngrowing $M$ more slowly than $N$. A particular case of interest is that for\nregression with normally distributed inputs in D-dimensions with the popular\nSquared Exponential kernel, $M=\\mathcal{O}(\\log^D N)$ is sufficient. Our\nresults show that as datasets grow, Gaussian process posteriors can truly be\napproximated cheaply, and provide a concrete rule for how to increase $M$ in\ncontinual learning scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 17:26:52 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 14:14:58 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 18:39:56 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Burt", "David R.", ""], ["Rasmussen", "Carl E.", ""], ["van der Wilk", "Mark", ""]]}, {"id": "1903.03605", "submitter": "Meena Jagadeesan", "authors": "Meena Jagadeesan", "title": "Understanding Sparse JL for Feature Hashing", "comments": "Appeared at NeurIPS 2019; this is the full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature hashing and other random projection schemes are commonly used to\nreduce the dimensionality of feature vectors. The goal is to efficiently\nproject a high-dimensional feature vector living in $\\mathbb{R}^n$ into a much\nlower-dimensional space $\\mathbb{R}^m$, while approximately preserving\nEuclidean norm. These schemes can be constructed using sparse random\nprojections, for example using a sparse Johnson-Lindenstrauss (JL) transform. A\nline of work introduced by Weinberger et. al (ICML '09) analyzes the accuracy\nof sparse JL with sparsity 1 on feature vectors with small\n$\\ell_\\infty$-to-$\\ell_2$ norm ratio. Recently, Freksen, Kamma, and Larsen\n(NeurIPS '18) closed this line of work by proving a tight tradeoff between\n$\\ell_\\infty$-to-$\\ell_2$ norm ratio and accuracy for sparse JL with sparsity\n$1$.\n  In this paper, we demonstrate the benefits of using sparsity $s$ greater than\n$1$ in sparse JL on feature vectors. Our main result is a tight tradeoff\nbetween $\\ell_\\infty$-to-$\\ell_2$ norm ratio and accuracy for a general\nsparsity $s$, that significantly generalizes the result of Freksen et. al. Our\nresult theoretically demonstrates that sparse JL with $s > 1$ can have\nsignificantly better norm-preservation properties on feature vectors than\nsparse JL with $s = 1$; we also empirically demonstrate this finding.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 18:50:42 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 17:51:43 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Jagadeesan", "Meena", ""]]}, {"id": "1903.03614", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Gradient Descent based Optimization Algorithms for Deep Learning Models\n  Training", "comments": "arXiv admin note: text overlap with arXiv:1805.07500", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at providing an introduction to the gradient descent\nbased optimization algorithms for learning deep neural network models. Deep\nlearning models involving multiple nonlinear projection layers are very\nchallenging to train. Nowadays, most of the deep learning model training still\nrelies on the back propagation algorithm actually. In back propagation, the\nmodel variables will be updated iteratively until convergence with gradient\ndescent based optimization algorithms. Besides the conventional vanilla\ngradient descent algorithm, many gradient descent variants have also been\nproposed in recent years to improve the learning performance, including\nMomentum, Adagrad, Adam, Gadam, etc., which will all be introduced in this\npaper respectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 12:59:47 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1903.03630", "submitter": "Masatoshi Uehara", "authors": "Masatoshi Uehara, Takeru Matsuda, Jae Kwang Kim", "title": "Imputation estimators for unnormalized models with missing data", "comments": "To appear (AISTATS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several statistical models are given in the form of unnormalized densities,\nand calculation of the normalization constant is intractable. We propose\nestimation methods for such unnormalized models with missing data. The key\nconcept is to combine imputation techniques with estimators for unnormalized\nmodels including noise contrastive estimation and score matching. In addition,\nwe derive asymptotic distributions of the proposed estimators and construct\nconfidence intervals. Simulation results with truncated Gaussian graphical\nmodels and the application to real data of wind direction reveal that the\nproposed methods effectively enable statistical inference with unnormalized\nmodels from missing data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 19:01:45 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 21:51:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Uehara", "Masatoshi", ""], ["Matsuda", "Takeru", ""], ["Kim", "Jae Kwang", ""]]}, {"id": "1903.03642", "submitter": "Xiaobai Ma Mr.", "authors": "Xiaobai Ma, Katherine Driggs-Campbell, and Mykel J. Kochenderfer", "title": "Improved Robustness and Safety for Autonomous Vehicle Control with\n  Adversarial Reinforcement Learning", "comments": "intelligent vehicles symposium 2018", "journal-ref": "Intelligent Vehicles Symposium (IV), 2018 IEEE", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To improve efficiency and reduce failures in autonomous vehicles, research\nhas focused on developing robust and safe learning methods that take into\naccount disturbances in the environment. Existing literature in robust\nreinforcement learning poses the learning problem as a two player game between\nthe autonomous system and disturbances. This paper examines two different\nalgorithms to solve the game, Robust Adversarial Reinforcement Learning and\nNeural Fictitious Self Play, and compares performance on an autonomous driving\nscenario. We extend the game formulation to a semi-competitive setting and\ndemonstrate that the resulting adversary better captures meaningful\ndisturbances that lead to better overall performance. The resulting robust\npolicy exhibits improved driving efficiency while effectively reducing\ncollision rates compared to baseline control policies produced by traditional\nreinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 19:44:29 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ma", "Xiaobai", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.03694", "submitter": "Weiran Wang", "authors": "Weiran Wang", "title": "Everything old is new again: A multi-view learning approach to learning\n  using privileged information and distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adopt a multi-view approach for analyzing two knowledge transfer\nsettings---learning using privileged information (LUPI) and distillation---in a\ncommon framework. Under reasonable assumptions about the complexities of\nhypothesis spaces, and being optimistic about the expected loss achievable by\nthe student (in distillation) and a transformed teacher predictor (in LUPI), we\nshow that encouraging agreement between the teacher and the student leads to\nreduced search space. As a result, improved convergence rate can be obtained\nwith regularized empirical risk minimization.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 23:04:11 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Weiran", ""]]}, {"id": "1903.03698", "submitter": "Vitchyr H. Pong", "authors": "Vitchyr H. Pong, Murtaza Dalal, Steven Lin, Ashvin Nair, Shikhar Bahl,\n  Sergey Levine", "title": "Skew-Fit: State-Covering Self-Supervised Reinforcement Learning", "comments": "ICML 2020. 8 pages, 8 figures; 9 pages appendix (6 additional\n  figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents that must exhibit flexible and broad capabilities will need\nto be equipped with large repertoires of skills. Defining each skill with a\nmanually-designed reward function limits this repertoire and imposes a manual\nengineering burden. Self-supervised agents that set their own goals can\nautomate this process, but designing appropriate goal setting objectives can be\ndifficult, and often involves heuristic design decisions. In this paper, we\npropose a formal exploration objective for goal-reaching policies that\nmaximizes state coverage. We show that this objective is equivalent to\nmaximizing goal reaching performance together with the entropy of the goal\ndistribution, where goals correspond to full state observations. To instantiate\nthis principle, we present an algorithm called Skew-Fit for learning a\nmaximum-entropy goal distributions. We prove that, under regularity conditions,\nSkew-Fit converges to a uniform distribution over the set of valid states, even\nwhen we do not know this set beforehand. Our experiments show that combining\nSkew-Fit for learning goal distributions with existing goal-reaching methods\noutperforms a variety of prior methods on open-sourced visual goal-reaching\ntasks. Moreover, we demonstrate that Skew-Fit enables a real-world robot to\nlearn to open a door, entirely from scratch, from pixels, and without any\nmanually-designed reward function.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 23:32:17 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:30:20 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 20:24:12 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 04:07:27 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Pong", "Vitchyr H.", ""], ["Dalal", "Murtaza", ""], ["Lin", "Steven", ""], ["Nair", "Ashvin", ""], ["Bahl", "Shikhar", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.03704", "submitter": "Pavel Sountsov", "authors": "Matthew Hoffman, Pavel Sountsov, Joshua V. Dillon, Ian Langmore,\n  Dustin Tran, Srinivas Vasudevan", "title": "NeuTra-lizing Bad Geometry in Hamiltonian Monte Carlo Using Neural\n  Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hamiltonian Monte Carlo is a powerful algorithm for sampling from\ndifficult-to-normalize posterior distributions. However, when the geometry of\nthe posterior is unfavorable, it may take many expensive evaluations of the\ntarget distribution and its gradient to converge and mix. We propose neural\ntransport (NeuTra) HMC, a technique for learning to correct this sort of\nunfavorable geometry using inverse autoregressive flows (IAF), a powerful\nneural variational inference technique. The IAF is trained to minimize the KL\ndivergence from an isotropic Gaussian to the warped posterior, and then HMC\nsampling is performed in the warped space. We evaluate NeuTra HMC on a variety\nof synthetic and real problems, and find that it significantly outperforms\nvanilla HMC both in time to reach the stationary distribution and asymptotic\neffective-sample-size rates.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 00:23:26 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Hoffman", "Matthew", ""], ["Sountsov", "Pavel", ""], ["Dillon", "Joshua V.", ""], ["Langmore", "Ian", ""], ["Tran", "Dustin", ""], ["Vasudevan", "Srinivas", ""]]}, {"id": "1903.03705", "submitter": "Urvashi Oswal", "authors": "Urvashi Oswal, Aniruddha Bhargava, and Robert Nowak", "title": "Linear Bandits with Feature Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new form of the linear bandit problem in which the\nalgorithm receives the usual stochastic rewards as well as stochastic feedback\nabout which features are relevant to the rewards, the latter feedback being the\nnovel aspect. The focus of this paper is the development of new theory and\nalgorithms for linear bandits with feature feedback. We show that linear\nbandits with feature feedback can achieve regret over time horizon $T$ that\nscales like $k\\sqrt{T}$, without prior knowledge of which features are relevant\nnor the number $k$ of relevant features. In comparison, the regret of\ntraditional linear bandits is $d\\sqrt{T}$, where $d$ is the total number of\n(relevant and irrelevant) features, so the improvement can be dramatic if $k\\ll\nd$. The computational complexity of the new algorithm is proportional to $k$\nrather than $d$, making it much more suitable for real-world applications\ncompared to traditional linear bandits. We demonstrate the performance of the\nnew algorithm with synthetic and real human-labeled data.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 00:32:28 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 00:46:49 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Oswal", "Urvashi", ""], ["Bhargava", "Aniruddha", ""], ["Nowak", "Robert", ""]]}, {"id": "1903.03711", "submitter": "Toshiaki Koike-Akino", "authors": "Ye Wang, Toshiaki Koike-Akino", "title": "Learning to Modulate for Non-coherent MIMO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep learning trend has recently impacted a variety of fields, including\ncommunication systems, where various approaches have explored the application\nof neural networks in place of traditional designs. Neural networks flexibly\nallow for data/simulation-driven optimization, but are often employed as black\nboxes detached from direct application of domain knowledge. Our work considers\nlearning-based approaches addressing modulation and signal detection design for\nthe non-coherent MIMO channel. We demonstrate that simulation-driven\noptimization can be performed while entirely avoiding neural networks, yet\nstill perform comparably. Additionally, we show the feasibility of MIMO\ncommunications over extremely short coherence windows (i.e., channel\ncoefficient stability period), with as few as two time slots.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 00:50:17 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""]]}, {"id": "1903.03712", "submitter": "Qiuhua Huang", "authors": "Qiuhua Huang, Renke Huang, Weituo Hao, Jie Tan, Rui Fan, Zhenyu Huang", "title": "Adaptive Power System Emergency Control using Deep Reinforcement\n  Learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Power system emergency control is generally regarded as the last safety net\nfor grid security and resiliency. Existing emergency control schemes are\nusually designed off-line based on either the conceived \"worst\" case scenario\nor a few typical operation scenarios. These schemes are facing significant\nadaptiveness and robustness issues as increasing uncertainties and variations\noccur in modern electrical grids. To address these challenges, for the first\ntime, this paper developed novel adaptive emergency control schemes using deep\nreinforcement learning (DRL), by leveraging the high-dimensional feature\nextraction and non-linear generalization capabilities of DRL for complex power\nsystems. Furthermore, an open-source platform named RLGC has been designed for\nthe first time to assist the development and benchmarking of DRL algorithms for\npower system control. Details of the platform and DRL-based emergency control\nschemes for generator dynamic braking and under-voltage load shedding are\npresented. Extensive case studies performed in both two-area four-machine\nsystem and IEEE 39-Bus system have demonstrated the excellent performance and\nrobustness of the proposed schemes.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 00:59:40 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 15:50:19 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Huang", "Qiuhua", ""], ["Huang", "Renke", ""], ["Hao", "Weituo", ""], ["Tan", "Jie", ""], ["Fan", "Rui", ""], ["Huang", "Zhenyu", ""]]}, {"id": "1903.03713", "submitter": "Toshiaki Koike-Akino", "authors": "Toshiki Matsumine, Toshiaki Koike-Akino, Ye Wang", "title": "Deep Learning-Based Constellation Optimization for Physical Network\n  Coding in Two-Way Relay Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a new application of deep learning (DL) for optimizing\nconstellations in two-way relaying with physical-layer network coding (PNC),\nwhere deep neural network (DNN)-based modulation and demodulation are employed\nat each terminal and relay node. We train DNNs such that the cross entropy loss\nis directly minimized, and thus it maximizes the likelihood, rather than\nconsidering the Euclidean distance of the constellations. The proposed scheme\ncan be extended to higher level constellations with slight modification of the\nDNN structure. Simulation results demonstrate a significant performance gain in\nterms of the achievable sum rate over conventional relaying schemes.\nFurthermore, since our DNN demodulator directly outputs bit-wise probabilities,\nit is straightforward to concatenate with soft-decision channel decoding.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 01:05:27 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Matsumine", "Toshiki", ""], ["Koike-Akino", "Toshiaki", ""], ["Wang", "Ye", ""]]}, {"id": "1903.03714", "submitter": "Xiang Ren", "authors": "Weizhi Ma, Min Zhang, Yue Cao, Woojeong, Jin, Chenyang Wang, Yiqun\n  Liu, Shaoping Ma, Xiang Ren", "title": "Jointly Learning Explainable Rules for Recommendation with Knowledge\n  Graph", "comments": "10 pages, plus 1-page references; accepted at The Web Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability and effectiveness are two key aspects for building recommender\nsystems. Prior efforts mostly focus on incorporating side information to\nachieve better recommendation performance. However, these methods have some\nweaknesses: (1) prediction of neural network-based embedding methods are hard\nto explain and debug; (2) symbolic, graph-based approaches (e.g., meta\npath-based models) require manual efforts and domain knowledge to define\npatterns and rules, and ignore the item association types (e.g. substitutable\nand complementary). In this paper, we propose a novel joint learning framework\nto integrate \\textit{induction of explainable rules from knowledge graph} with\n\\textit{construction of a rule-guided neural recommendation model}. The\nframework encourages two modules to complement each other in generating\neffective and explainable recommendation: 1) inductive rules, mined from\nitem-centric knowledge graphs, summarize common multi-hop relational patterns\nfor inferring different item associations and provide human-readable\nexplanation for model prediction; 2) recommendation module can be augmented by\ninduced rules and thus have better generalization ability dealing with the\ncold-start issue. Extensive experiments\\footnote{Code and data can be found at:\n\\url{https://github.com/THUIR/RuleRec}} show that our proposed method has\nachieved significant improvements in item recommendation over baselines on\nreal-world datasets. Our model demonstrates robust performance over \"noisy\"\nitem knowledge graphs, generated by linking item names to related entities.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 01:06:04 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ma", "Weizhi", ""], ["Zhang", "Min", ""], ["Cao", "Yue", ""], ["Woojeong", "", ""], ["Jin", "", ""], ["Wang", "Chenyang", ""], ["Liu", "Yiqun", ""], ["Ma", "Shaoping", ""], ["Ren", "Xiang", ""]]}, {"id": "1903.03730", "submitter": "Sandesh Adhikary", "authors": "Sandesh Adhikary, Siddarth Srinivasan, Byron Boots", "title": "Learning Quantum Graphical Models using Constrained Gradient Descent on\n  the Stiefel Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum graphical models (QGMs) extend the classical framework for reasoning\nabout uncertainty by incorporating the quantum mechanical view of probability.\nPrior work on QGMs has focused on hidden quantum Markov models (HQMMs), which\ncan be formulated using quantum analogues of the sum rule and Bayes rule used\nin classical graphical models. Despite the focus on developing the QGM\nframework, there has been little progress in learning these models from data.\nThe existing state-of-the-art approach randomly initializes parameters and\niteratively finds unitary transformations that increase the likelihood of the\ndata. While this algorithm demonstrated theoretical strengths of HQMMs over\nHMMs, it is slow and can only handle a small number of hidden states. In this\npaper, we tackle the learning problem by solving a constrained optimization\nproblem on the Stiefel manifold using a well-known retraction-based algorithm.\nWe demonstrate that this approach is not only faster and yields better\nsolutions on several datasets, but also scales to larger models that were\nprohibitively slow to train via the earlier method.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 03:48:18 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Adhikary", "Sandesh", ""], ["Srinivasan", "Siddarth", ""], ["Boots", "Byron", ""]]}, {"id": "1903.03746", "submitter": "Gal Kaplun", "authors": "Dimitris Kalimeris and Gal Kaplun and Yaron Singer", "title": "Robust Influence Maximization for Hyperparametric Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of robust influence maximization in the\nindependent cascade model under a hyperparametric assumption. In social\nnetworks users influence and are influenced by individuals with similar\ncharacteristics and as such, they are associated with some features. A recent\nsurging research direction in influence maximization focuses on the case where\nthe edge probabilities on the graph are not arbitrary but are generated as a\nfunction of the features of the users and a global hyperparameter. We propose a\nmodel where the objective is to maximize the worst-case number of influenced\nusers for any possible value of that hyperparameter. We provide theoretical\nresults showing that proper robust solution in our model is NP-hard and an\nalgorithm that achieves improper robust optimization. We make-use of sampling\nbased techniques and of the renowned multiplicative weight updates algorithm.\nAdditionally, we validate our method empirically and prove that it outperforms\nthe state-of-the-art robust influence maximization techniques.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 06:23:11 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 00:32:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kalimeris", "Dimitris", ""], ["Kaplun", "Gal", ""], ["Singer", "Yaron", ""]]}, {"id": "1903.03756", "submitter": "Yuan Tang", "authors": "Ying Tang", "title": "Two-Hop Walks Indicate PageRank Order", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that pairwise PageRank orders emerge from two-hop walks. The\nmain tool used here refers to a specially designed sign-mirror function and a\nparameter curve, whose low-order derivative information implies pairwise\nPageRank orders with high probability. We study the pairwise correct rate by\nplacing the Google matrix $\\textbf{G}$ in a probabilistic framework, where\n$\\textbf{G}$ may be equipped with different random ensembles for\nmodel-generated or real-world networks with sparse, small-world, scale-free\nfeatures, the proof of which is mixed by mathematical and numerical evidence.\nWe believe that the underlying spectral distribution of aforementioned networks\nis responsible for the high pairwise correct rate. Moreover, the perspective of\nthis paper naturally leads to an $O(1)$ algorithm for any single pairwise\nPageRank comparison if assuming both $\\textbf{A}=\\textbf{G}-\\textbf{I}_n$,\nwhere $\\textbf{I}_n$ denotes the identity matrix of order $n$, and\n$\\textbf{A}^2$ are ready on hand (e.g., constructed offline in an incremental\nmanner), based on which it is easy to extract the top $k$ list in $O(kn)$, thus\nmaking it possible for PageRank algorithm to deal with super large-scale\ndatasets in real time.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 07:54:10 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Tang", "Ying", ""]]}, {"id": "1903.03759", "submitter": "Zheqi Zhu", "authors": "Zheqi Zhu, Pingyi Fan", "title": "Machine Learning Based Prediction and Classification of Computational\n  Jobs in Cloud Computing Centers", "comments": null, "journal-ref": null, "doi": "10.1109/IWCMC.2019.8766558", "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of the data volume and the fast increasing of the\ncomputational model complexity in the scenario of cloud computing, it becomes\nan important topic that how to handle users' requests by scheduling\ncomputational jobs and assigning the resources in data center.\n  In order to have a better perception of the computing jobs and their requests\nof resources, we analyze its characteristics and focus on the prediction and\nclassification of the computing jobs with some machine learning approaches.\nSpecifically, we apply LSTM neural network to predict the arrival of the jobs\nand the aggregated requests for computing resources. Then we evaluate it on\nGoogle Cluster dataset and it shows that the accuracy has been improved\ncompared to the current existing methods. Additionally, to have a better\nunderstanding of the computing jobs, we use an unsupervised hierarchical\nclustering algorithm, BIRCH, to make classification and get some\ninterpretability of our results in the computing centers.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 08:02:18 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zhu", "Zheqi", ""], ["Fan", "Pingyi", ""]]}, {"id": "1903.03763", "submitter": "Pan Li", "authors": "Pan Li, Baihong Jin, Ruoxuan Xiong, Dai Wang, Alberto\n  Sangiovanni-Vincentelli, Baosen Zhang", "title": "A tractable ellipsoidal approximation for voltage regulation problems", "comments": "accepted by ACC2019 http://acc2019.a2c2.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning approach to the solution of chance constrained\noptimizations in the context of voltage regulation problems in power system\noperation. The novelty of our approach resides in approximating the feasible\nregion of uncertainty with an ellipsoid. We formulate this problem using a\nlearning model similar to Support Vector Machines (SVM) and propose a sampling\nalgorithm that efficiently trains the model. We demonstrate our approach on a\nvoltage regulation problem using standard IEEE distribution test feeders.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 08:32:32 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Li", "Pan", ""], ["Jin", "Baihong", ""], ["Xiong", "Ruoxuan", ""], ["Wang", "Dai", ""], ["Sangiovanni-Vincentelli", "Alberto", ""], ["Zhang", "Baosen", ""]]}, {"id": "1903.03784", "submitter": "Jiri Hron", "authors": "Mark Rowland and Jiri Hron and Yunhao Tang and Krzysztof Choromanski\n  and Tamas Sarlos and Adrian Weller", "title": "Orthogonal Estimation of Wasserstein Distances", "comments": "Published at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein distances are increasingly used in a wide variety of applications\nin machine learning. Sliced Wasserstein distances form an important subclass\nwhich may be estimated efficiently through one-dimensional sorting operations.\nIn this paper, we propose a new variant of sliced Wasserstein distance, study\nthe use of orthogonal coupling in Monte Carlo estimation of Wasserstein\ndistances and draw connections with stratified sampling, and evaluate our\napproaches experimentally in a range of large-scale experiments in generative\nmodelling and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 11:26:51 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 09:19:02 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Rowland", "Mark", ""], ["Hron", "Jiri", ""], ["Tang", "Yunhao", ""], ["Choromanski", "Krzysztof", ""], ["Sarlos", "Tamas", ""], ["Weller", "Adrian", ""]]}, {"id": "1903.03812", "submitter": "Kamanchi Chandramouli", "authors": "Chandramouli Kamanchi, Raghuram Bharadwaj Diddigi, Shalabh Bhatnagar", "title": "Successive Over Relaxation Q-Learning", "comments": null, "journal-ref": "IEEE Control Systems Letters 2019", "doi": "10.1109/LCSYS.2019.2921158", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a discounted reward Markov Decision Process (MDP), the objective is to\nfind the optimal value function, i.e., the value function corresponding to an\noptimal policy. This problem reduces to solving a functional equation known as\nthe Bellman equation and a fixed point iteration scheme known as the value\niteration is utilized to obtain the solution. In literature, a successive\nover-relaxation based value iteration scheme is proposed to speed-up the\ncomputation of the optimal value function. The speed-up is achieved by\nconstructing a modified Bellman equation that ensures faster convergence to the\noptimal value function. However, in many practical applications, the model\ninformation is not known and we resort to Reinforcement Learning (RL)\nalgorithms to obtain optimal policy and value function. One such popular\nalgorithm is Q-learning. In this paper, we propose Successive Over-Relaxation\n(SOR) Q-learning. We first derive a modified fixed point iteration for SOR\nQ-values and utilize stochastic approximation to derive a learning algorithm to\ncompute the optimal value function and an optimal policy. We then prove the\nalmost sure convergence of the SOR Q-learning to SOR Q-values. Finally, through\nnumerical experiments, we show that SOR Q-learning is faster compared to the\nstandard Q-learning algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 15:03:18 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 18:38:53 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 18:49:22 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kamanchi", "Chandramouli", ""], ["Diddigi", "Raghuram Bharadwaj", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1903.03825", "submitter": "Vikas Verma", "authors": "Vikas Verma, Kenji Kawaguchi, Alex Lamb, Juho Kannala, Yoshua Bengio,\n  David Lopez-Paz", "title": "Interpolation Consistency Training for Semi-Supervised Learning", "comments": "Extended version of IJCAI 2019 paper. Semi-supervised Learning, Deep\n  Learning, Neural Networks. All the previous results are unchanged; we added\n  new theoretical and empirical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Interpolation Consistency Training (ICT), a simple and\ncomputation efficient algorithm for training Deep Neural Networks in the\nsemi-supervised learning paradigm. ICT encourages the prediction at an\ninterpolation of unlabeled points to be consistent with the interpolation of\nthe predictions at those points. In classification problems, ICT moves the\ndecision boundary to low-density regions of the data distribution. Our\nexperiments show that ICT achieves state-of-the-art performance when applied to\nstandard neural network architectures on the CIFAR-10 and SVHN benchmark\ndatasets. Our theoretical analysis shows that ICT corresponds to a certain type\nof data-adaptive regularization with unlabeled points which reduces overfitting\nto labeled points under high confidence values.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 16:39:22 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 17:46:54 GMT"}, {"version": "v3", "created": "Sun, 19 May 2019 05:00:06 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 15:31:56 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Verma", "Vikas", ""], ["Kawaguchi", "Kenji", ""], ["Lamb", "Alex", ""], ["Kannala", "Juho", ""], ["Bengio", "Yoshua", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1903.03850", "submitter": "Ashkan Panahi", "authors": "Ashkan Panahi, Arman Rahbar, Morteza Haghir Chehreghani, Devdatt\n  Dubhashi", "title": "Stochastic Proximal Algorithms with SON Regularization: Towards\n  Efficient Optimal Transport for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new regularizer for optimal transport (OT) which is tailored to\nbetter preserve the class structure of the subjected process. Accordingly, we\nprovide the first theoretical guarantees for an OT scheme that respects class\nstructure. We derive an accelerated proximal algorithm with a closed form\nprojection and proximal operator scheme thereby affording a highly scalable\nalgorithm for computing optimal transport plans. We provide a novel argument\nfor the uniqueness of the optimum even in the absence of strong convexity.Our\nexperiments show that the new regularizer does not only result in a better\npreservation of the class structure but also in additional robustness relative\nto previous regularizers.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 18:54:21 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 11:34:03 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Panahi", "Ashkan", ""], ["Rahbar", "Arman", ""], ["Chehreghani", "Morteza Haghir", ""], ["Dubhashi", "Devdatt", ""]]}, {"id": "1903.03867", "submitter": "Raed Al Kontar", "authors": "Xubo Yue, Raed Kontar", "title": "Variational Inference of Joint Models using Multivariate Gaussian\n  Convolution Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a non-parametric prognostic framework for individualized event\nprediction based on joint modeling of both longitudinal and time-to-event data.\nOur approach exploits a multivariate Gaussian convolution process (MGCP) to\nmodel the evolution of longitudinal signals and a Cox model to map\ntime-to-event data with longitudinal data modeled through the MGCP. Taking\nadvantage of the unique structure imposed by convolved processes, we provide a\nvariational inference framework to simultaneously estimate parameters in the\njoint MGCP-Cox model. This significantly reduces computational complexity and\nsafeguards against model overfitting. Experiments on synthetic and real world\ndata show that the proposed framework outperforms state-of-the art approaches\nbuilt on two-stage inference and strong parametric assumptions.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 20:41:13 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Yue", "Xubo", ""], ["Kontar", "Raed", ""]]}, {"id": "1903.03871", "submitter": "Raed Al Kontar", "authors": "Seokhyun Chung, Raed Kontar", "title": "Functional Principal Component Analysis for Extrapolating Multi-stream\n  Longitudinal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advance of modern sensor technologies enables collection of multi-stream\nlongitudinal data where multiple signals from different units are collected in\nreal-time. In this article, we present a non-parametric approach to predict the\nevolution of multi-stream longitudinal data for an in-service unit through\nborrowing strength from other historical units. Our approach first decomposes\neach stream into a linear combination of eigenfunctions and their corresponding\nfunctional principal component (FPC) scores. A Gaussian process prior for the\nFPC scores is then established based on a functional semi-metric that measures\nsimilarities between streams of historical units and the in-service unit.\nFinally, an empirical Bayesian updating strategy is derived to update the\nestablished prior using real-time stream data obtained from the in-service\nunit. Experiments on synthetic and real world data show that the proposed\nframework outperforms state-of-the-art approaches and can effectively account\nfor heterogeneity as well as achieve high predictive accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 21:22:54 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Chung", "Seokhyun", ""], ["Kontar", "Raed", ""]]}, {"id": "1903.03878", "submitter": "Kuan Fang", "authors": "Kuan Fang, Alexander Toshev, Li Fei-Fei, Silvio Savarese", "title": "Scene Memory Transformer for Embodied Agents in Long-Horizon Tasks", "comments": "CVPR 2019 paper with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many robotic applications require the agent to perform long-horizon tasks in\npartially observable environments. In such applications, decision making at any\nstep can depend on observations received far in the past. Hence, being able to\nproperly memorize and utilize the long-term history is crucial. In this work,\nwe propose a novel memory-based policy, named Scene Memory Transformer (SMT).\nThe proposed policy embeds and adds each observation to a memory and uses the\nattention mechanism to exploit spatio-temporal dependencies. This model is\ngeneric and can be efficiently trained with reinforcement learning over long\nepisodes. On a range of visual navigation tasks, SMT demonstrates superior\nperformance to existing reactive and memory-based policies by a margin.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 22:03:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fang", "Kuan", ""], ["Toshev", "Alexander", ""], ["Fei-Fei", "Li", ""], ["Savarese", "Silvio", ""]]}, {"id": "1903.03891", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Felix H\\\"ulsmann, Mario Botsch, Barbara Hammer", "title": "Non-Negative Kernel Sparse Coding for the Classification of Motion Data", "comments": "8 pages, ICANN 2016 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the decomposition of motion data into a sparse linear\ncombination of base functions which enable efficient data processing. We\ncombine two prominent frameworks: dynamic time warping (DTW), which offers\nparticularly successful pairwise motion data comparison, and sparse coding\n(SC), which enables an automatic decomposition of vectorial data into a sparse\nlinear combination of base vectors. We enhance SC as follows: an efficient\nkernelization which extends its application domain to general similarity data\nsuch as offered by DTW, and its restriction to non-negative linear\nrepresentations of signals and base vectors in order to guarantee a meaningful\ndictionary. Empirical evaluations on motion capture benchmarks show the\neffectiveness of our framework regarding interpretation and discrimination\nconcerns.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 00:45:05 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 10:00:39 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Hosseini", "Babak", ""], ["H\u00fclsmann", "Felix", ""], ["Botsch", "Mario", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.03894", "submitter": "Rex Ying", "authors": "Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, Jure Leskovec", "title": "GNNExplainer: Generating Explanations for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are a powerful tool for machine learning on\ngraphs.GNNs combine node feature information with the graph structure by\nrecursively passing neural messages along edges of the input graph. However,\nincorporating both graph structure and feature information leads to complex\nmodels, and explaining predictions made by GNNs remains unsolved. Here we\npropose GNNExplainer, the first general, model-agnostic approach for providing\ninterpretable explanations for predictions of any GNN-based model on any\ngraph-based machine learning task. Given an instance, GNNExplainer identifies a\ncompact subgraph structure and a small subset of node features that have a\ncrucial role in GNN's prediction. Further, GNNExplainer can generate consistent\nand concise explanations for an entire class of instances. We formulate\nGNNExplainer as an optimization task that maximizes the mutual information\nbetween a GNN's prediction and distribution of possible subgraph structures.\nExperiments on synthetic and real-world graphs show that our approach can\nidentify important graph structures as well as node features, and outperforms\nbaselines by 17.1% on average. GNNExplainer provides a variety of benefits,\nfrom the ability to visualize semantically relevant structures to\ninterpretability, to giving insights into errors of faulty GNNs.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 00:56:26 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 22:53:52 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 19:08:14 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 22:36:57 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Ying", "Rex", ""], ["Bourgeois", "Dylan", ""], ["You", "Jiaxuan", ""], ["Zitnik", "Marinka", ""], ["Leskovec", "Jure", ""]]}, {"id": "1903.03905", "submitter": "Ousmane Dia", "authors": "Ousmane Amadou Dia, Elnaz Barshan, Reza Babanezhad", "title": "Semantics Preserving Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While progress has been made in crafting visually imperceptible adversarial\nexamples, constructing semantically meaningful ones remains a challenge. In\nthis paper, we propose a framework to generate semantics preserving adversarial\nexamples. First, we present a manifold learning method to capture the semantics\nof the inputs. The motivating principle is to learn the low-dimensional\ngeometric summaries of the inputs via statistical inference. Then, we perturb\nthe elements of the learned manifold using the Gram-Schmidt process to induce\nthe perturbed elements to remain in the manifold. To produce adversarial\nexamples, we propose an efficient algorithm whereby we leverage the semantics\nof the inputs as a source of knowledge upon which we impose adversarial\nconstraints. We apply our approach on toy data, images and text, and show its\neffectiveness in producing semantics preserving adversarial examples which\nevade existing defenses against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 02:48:46 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 02:09:39 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 03:25:33 GMT"}, {"version": "v4", "created": "Sun, 26 May 2019 00:04:52 GMT"}, {"version": "v5", "created": "Sat, 21 Dec 2019 13:02:43 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dia", "Ousmane Amadou", ""], ["Barshan", "Elnaz", ""], ["Babanezhad", "Reza", ""]]}, {"id": "1903.03906", "submitter": "Xuhui Fan", "authors": "Xuhui Fan and Bin Li and Scott Anthony Sisson", "title": "Rectangular Bounding Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic partition models divide a multi-dimensional space into a number of\nrectangular regions, such that the data within each region exhibit certain\ntypes of homogeneity. Due to the nature of their partition strategy, existing\npartition models may create many unnecessary divisions in sparse regions when\ntrying to describe data in dense regions. To avoid this problem we introduce a\nnew parsimonious partition model -- the Rectangular Bounding Process (RBP) --\nto efficiently partition multi-dimensional spaces, by employing a bounding\nstrategy to enclose data points within rectangular bounding boxes. Unlike\nexisting approaches, the RBP possesses several attractive theoretical\nproperties that make it a powerful nonparametric partition prior on a\nhypercube. In particular, the RBP is self-consistent and as such can be\ndirectly extended from a finite hypercube to infinite (unbounded) space. We\napply the RBP to regression trees and relational models as a flexible partition\nprior. The experimental results validate the merit of the RBP {in rich yet\nparsimonious expressiveness} compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 02:52:32 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.03910", "submitter": "Ashkan Rezaei", "authors": "Ashkan Rezaei, Rizal Fathony, Omid Memarrast, Brian Ziebart", "title": "Fairness for Robust Log Loss Classification", "comments": null, "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence\n  (2020), Vol 34 No 04: AAAI-20 Technical Tracks 4", "doi": "10.1609/aaai.v34i04.6002", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing classification methods with high accuracy that also avoid unfair\ntreatment of different groups has become increasingly important for data-driven\ndecision making in social applications. Many existing methods enforce fairness\nconstraints on a selected classifier (e.g., logistic regression) by directly\nforming constrained optimizations. We instead re-derive a new classifier from\nthe first principles of distributional robustness that incorporates fairness\ncriteria into a worst-case logarithmic loss minimization. This construction\ntakes the form of a minimax game and produces a parametric exponential family\nconditional distribution that resembles truncated logistic regression. We\npresent the theoretical benefits of our approach in terms of its convexity and\nasymptotic convergence. We then demonstrate the practical advantages of our\napproach on three benchmark fairness datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 03:18:33 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 07:34:33 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 19:22:37 GMT"}, {"version": "v4", "created": "Wed, 14 Oct 2020 04:36:21 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Rezaei", "Ashkan", ""], ["Fathony", "Rizal", ""], ["Memarrast", "Omid", ""], ["Ziebart", "Brian", ""]]}, {"id": "1903.03936", "submitter": "Cong Xie", "authors": "Cong Xie, Sanmi Koyejo, Indranil Gupta", "title": "Fall of Empires: Breaking Byzantine-tolerant SGD by Inner Product\n  Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, new defense techniques have been developed to tolerate Byzantine\nfailures for distributed machine learning. The Byzantine model captures workers\nthat behave arbitrarily, including malicious and compromised workers. In this\npaper, we break two prevailing Byzantine-tolerant techniques. Specifically we\nshow robust aggregation methods for synchronous SGD -- coordinate-wise median\nand Krum -- can be broken using new attack strategies based on inner product\nmanipulation. We prove our results theoretically, as well as show empirical\nvalidation.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 06:26:01 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Sanmi", ""], ["Gupta", "Indranil", ""]]}, {"id": "1903.03986", "submitter": "Edwin Bonilla", "authors": "Astrid Dahl, Edwin V. Bonilla", "title": "Scalable Grouped Gaussian Processes via Direct Cholesky Functional\n  Representations", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-task regression models where observations are assumed to be\na linear combination of several latent node and weight functions, all drawn\nfrom Gaussian process (GP) priors that allow nonzero covariance between grouped\nlatent functions. We show that when these grouped functions are conditionally\nindependent given a group-dependent pivot, it is possible to parameterize the\nprior through sparse Cholesky factors directly, hence avoiding their\ncomputation during inference. Furthermore, we establish that kernels that are\nmultiplicatively separable over input points give rise to such sparse\nparameterizations naturally without any additional assumptions. Finally, we\nextend the use of these sparse structures to approximate posteriors within\nvariational inference, further improving scalability on the number of\nfunctions. We test our approach on multi-task datasets concerning distributed\nsolar forecasting and show that it outperforms several multi-task GP baselines\nand that our sparse specifications achieve the same or better accuracy than\nnon-sparse counterparts.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 13:20:16 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 06:06:13 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Dahl", "Astrid", ""], ["Bonilla", "Edwin V.", ""]]}, {"id": "1903.03989", "submitter": "Weiqi Ji", "authors": "Weiqi Ji, Zhuyin Ren and Chung K. Law", "title": "Uncertainty Propagation in Deep Neural Network Using Active Subspace", "comments": "Add link to github repo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inputs of deep neural network (DNN) from real-world data usually come\nwith uncertainties. Yet, it is challenging to propagate the uncertainty in the\ninput features to the DNN predictions at a low computational cost. This work\nemploys a gradient-based subspace method and response surface technique to\naccelerate the uncertainty propagation in DNN. Specifically, the active\nsubspace method is employed to identify the most important subspace in the\ninput features using the gradient of the DNN output to the inputs. Then the\nresponse surface within that low-dimensional subspace can be efficiently built,\nand the uncertainty of the prediction can be acquired by evaluating the\ncomputationally cheap response surface instead of the DNN models. In addition,\nthe subspace can help explain the adversarial examples. The approach is\ndemonstrated in MNIST datasets with a convolutional neural network. Code is\navailable at: https://github.com/jiweiqi/nnsubspace.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 13:38:43 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 22:34:28 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ji", "Weiqi", ""], ["Ren", "Zhuyin", ""], ["Law", "Chung K.", ""]]}, {"id": "1903.04003", "submitter": "Yiming Li", "authors": "Yiming Li, Jiawang Bai, Jiawei Li, Xue Yang, Yong Jiang, Chun Li,\n  Shutao Xia", "title": "Multinomial Random Forest: Toward Consistency and Privacy-Preservation", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the impressive performance of random forests (RF), its theoretical\nproperties have not been thoroughly understood. In this paper, we propose a\nnovel RF framework, dubbed multinomial random forest (MRF), to analyze the\n\\emph{consistency} and \\emph{privacy-preservation}. Instead of deterministic\ngreedy split rule or with simple randomness, the MRF adopts two impurity-based\nmultinomial distributions to randomly select a split feature and a split value\nrespectively. Theoretically, we prove the consistency of the proposed MRF and\nanalyze its privacy-preservation within the framework of differential privacy.\nWe also demonstrate with multiple datasets that its performance is on par with\nthe standard RF. To the best of our knowledge, MRF is the first consistent RF\nvariant that has comparable performance to the standard RF.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 14:47:16 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 15:00:22 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 13:35:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Yiming", ""], ["Bai", "Jiawang", ""], ["Li", "Jiawei", ""], ["Yang", "Xue", ""], ["Jiang", "Yong", ""], ["Li", "Chun", ""], ["Xia", "Shutao", ""]]}, {"id": "1903.04012", "submitter": "David Kirkpatrick", "authors": "David Kirkpatrick, Hans U. Simon, Sandra Zilles", "title": "Optimal Collusion-Free Teaching", "comments": "26 pages and 6 figures. This is an expanded version of a similarly\n  titled paper to appear in Proceedings of Machine Learning Research (ALT\n  2019), vol. 98, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal models of learning from teachers need to respect certain criteria to\navoid collusion. The most commonly accepted notion of collusion-freeness was\nproposed by Goldman and Mathias (1996), and various teaching models obeying\ntheir criterion have been studied. For each model $M$ and each concept class\n$\\mathcal{C}$, a parameter $M$-$\\mathrm{TD}(\\mathcal{C})$ refers to the\nteaching dimension of concept class $\\mathcal{C}$ in model $M$---defined to be\nthe number of examples required for teaching a concept, in the worst case over\nall concepts in $\\mathcal{C}$.\n  This paper introduces a new model of teaching, called no-clash teaching,\ntogether with the corresponding parameter $\\mathrm{NCTD}(\\mathcal{C})$.\nNo-clash teaching is provably optimal in the strong sense that, given any\nconcept class $\\mathcal{C}$ and any model $M$ obeying Goldman and Mathias's\ncollusion-freeness criterion, one obtains $\\mathrm{NCTD}(\\mathcal{C})\\le\nM$-$\\mathrm{TD}(\\mathcal{C})$. We also study a corresponding notion\n$\\mathrm{NCTD}^+$ for the case of learning from positive data only, establish\nuseful bounds on $\\mathrm{NCTD}$ and $\\mathrm{NCTD}^+$, and discuss relations\nof these parameters to the VC-dimension and to sample compression.\n  In addition to formulating an optimal model of collusion-free teaching, our\nmain results are on the computational complexity of deciding whether\n$\\mathrm{NCTD}^+(\\mathcal{C})=k$ (or $\\mathrm{NCTD}(\\mathcal{C})=k$) for given\n$\\mathcal{C}$ and $k$. We show some such decision problems to be equivalent to\nthe existence question for certain constrained matchings in bipartite graphs.\nOur NP-hardness results for the latter are of independent interest in the study\nof constrained graph matchings.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 15:23:05 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kirkpatrick", "David", ""], ["Simon", "Hans U.", ""], ["Zilles", "Sandra", ""]]}, {"id": "1903.04016", "submitter": "Yu Chen", "authors": "Yu Chen and Telmo Silva Filho and Ricardo B. C. Prud\\^encio and Tom\n  Diethe and Peter Flach", "title": "$\\beta^3$-IRT: A New Item Response Model and its Applications", "comments": null, "journal-ref": "AISTATS 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item Response Theory (IRT) aims to assess latent abilities of respondents\nbased on the correctness of their answers in aptitude test items with different\ndifficulty levels. In this paper, we propose the $\\beta^3$-IRT model, which\nmodels continuous responses and can generate a much enriched family of Item\nCharacteristic Curve (ICC). In experiments we applied the proposed model to\ndata from an online exam platform, and show our model outperforms a more\nstandard 2PL-ND model on all datasets. Furthermore, we show how to apply\n$\\beta^3$-IRT to assess the ability of machine learning classifiers. This novel\napplication results in a new metric for evaluating the quality of the\nclassifier's probability estimates, based on the inferred difficulty and\ndiscrimination of data instances.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 16:06:50 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 11:09:51 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 16:07:12 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Yu", ""], ["Filho", "Telmo Silva", ""], ["Prud\u00eancio", "Ricardo B. C.", ""], ["Diethe", "Tom", ""], ["Flach", "Peter", ""]]}, {"id": "1903.04042", "submitter": "Ga\\\"el Beck", "authors": "Andriantsiory Dina Faneva, Mustapha Lebbah, Hanane Azzag, Ga\\\"el Beck", "title": "Algorithms for an Efficient Tensor Biclustering", "comments": "Algorithms available on Clustering4Ever github,\n  https://github.com/Clustering4Ever/Clustering4Ever", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a data set collected by (individuals-features) pairs in different\ntimes. It can be represented as a tensor of three dimensions (Individuals,\nfeatures and times). The tensor biclustering problem computes a subset of\nindividuals and a subset of features whose signal trajectories over time lie in\na low-dimensional subspace, modeling similarity among the signal trajectories\nwhile allowing different scalings across different individuals or different\nfeatures. This approach are based on spectral decomposition in order to build\nthe desired biclusters. We evaluate the quality of the results from each\nalgorithms with both synthetic and real data set.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 18:56:14 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Faneva", "Andriantsiory Dina", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""], ["Beck", "Ga\u00ebl", ""]]}, {"id": "1903.04056", "submitter": "Eric Kightley", "authors": "Eric Kightley and Stephen Becker", "title": "One-Pass Sparsified Gaussian Mixtures", "comments": "submitted to IEEE DSW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a one-pass sparsified Gaussian mixture model (SGMM). Given $N$\ndata points in $P$ dimensions, $X$, the model fits $K$ Gaussian distributions\nto $X$ and (softly) classifies each point to these clusters. After paying an\nup-front cost of $\\mathcal{O}(NP\\log P)$ to precondition the data, we subsample\n$Q$ entries of each data point and discard the full $P$-dimensional data. SGMM\noperates in $\\mathcal{O}(KNQ)$ time per iteration for diagonal or spherical\ncovariances, independent of $P$, while estimating the model parameters in the\nfull $P$-dimensional space, making it one-pass and hence suitable for streaming\ndata. We derive the maximum likelihood estimators for the parameters in the\nsparsified regime, demonstrate clustering on synthetic and real data, and show\nthat SGMM is faster than GMM while preserving accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 20:40:02 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 22:14:30 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Kightley", "Eric", ""], ["Becker", "Stephen", ""]]}, {"id": "1903.04057", "submitter": "Gilles Louppe", "authors": "Joeri Hermans, Volodimir Begy, Gilles Louppe", "title": "Likelihood-free MCMC with Amortized Approximate Ratio Estimators", "comments": "v5: Camera-ready version presented at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior inference with an intractable likelihood is becoming an\nincreasingly common task in scientific domains which rely on sophisticated\ncomputer simulations. Typically, these forward models do not admit tractable\ndensities forcing practitioners to make use of approximations. This work\nintroduces a novel approach to address the intractability of the likelihood and\nthe marginal model. We achieve this by learning a flexible amortized estimator\nwhich approximates the likelihood-to-evidence ratio. We demonstrate that the\nlearned ratio estimator can be embedded in MCMC samplers to approximate\nlikelihood-ratios between consecutive states in the Markov chain, allowing us\nto draw samples from the intractable posterior. Techniques are presented to\nimprove the numerical stability and to measure the quality of an approximation.\nThe accuracy of our approach is demonstrated on a variety of benchmarks against\nwell-established techniques. Scientific applications in physics show its\napplicability.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 20:51:02 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 13:06:38 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 08:29:11 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 16:57:52 GMT"}, {"version": "v5", "created": "Fri, 26 Jun 2020 08:15:43 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Hermans", "Joeri", ""], ["Begy", "Volodimir", ""], ["Louppe", "Gilles", ""]]}, {"id": "1903.04064", "submitter": "Chen-Yu Lee", "authors": "Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, Daniel Ulbricht", "title": "Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation", "comments": "Accepted at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we connect two distinct concepts for unsupervised domain\nadaptation: feature distribution alignment between domains by utilizing the\ntask-specific decision boundary and the Wasserstein metric. Our proposed sliced\nWasserstein discrepancy (SWD) is designed to capture the natural notion of\ndissimilarity between the outputs of task-specific classifiers. It provides a\ngeometrically meaningful guidance to detect target samples that are far from\nthe support of the source and enables efficient distribution alignment in an\nend-to-end trainable fashion. In the experiments, we validate the effectiveness\nand genericness of our method on digit and sign recognition, image\nclassification, semantic segmentation, and object detection.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 21:56:45 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Lee", "Chen-Yu", ""], ["Batra", "Tanmay", ""], ["Baig", "Mohammad Haris", ""], ["Ulbricht", "Daniel", ""]]}, {"id": "1903.04100", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Jeremias Sulam, Daniel P. Robinson, Ren\\'e Vidal", "title": "Conformal Symplectic and Relativistic Optimization", "comments": "A short version of this paper appeared at NeurIPS 2020 (spotlight).\n  This lengthier version matches the published paper at JSTAT, which contains\n  additional results", "journal-ref": "J. Stat. Mech. (2020) 124008", "doi": "10.1088/1742-5468/abcaee", "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguably, the two most popular accelerated or momentum-based optimization\nmethods in machine learning are Nesterov's accelerated gradient and Polyaks's\nheavy ball, both corresponding to different discretizations of a particular\nsecond order differential equation with friction. Such connections with\ncontinuous-time dynamical systems have been instrumental in demystifying\nacceleration phenomena in optimization. Here we study structure-preserving\ndiscretizations for a certain class of dissipative (conformal) Hamiltonian\nsystems, allowing us to analyze the symplectic structure of both Nesterov and\nheavy ball, besides providing several new insights into these methods.\nMoreover, we propose a new algorithm based on a dissipative relativistic system\nthat normalizes the momentum and may result in more stable/faster optimization.\nImportantly, such a method generalizes both Nesterov and heavy ball, each being\nrecovered as distinct limiting cases, and has potential advantages at no\nadditional cost.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 02:13:03 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 03:08:51 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 18:54:40 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 23:36:45 GMT"}, {"version": "v5", "created": "Wed, 14 Oct 2020 13:57:01 GMT"}, {"version": "v6", "created": "Tue, 27 Oct 2020 22:53:50 GMT"}, {"version": "v7", "created": "Thu, 24 Dec 2020 12:51:35 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Sulam", "Jeremias", ""], ["Robinson", "Daniel P.", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1903.04110", "submitter": "Xiaoxiao Guo", "authors": "Xiaoxiao Guo, Shiyu Chang, Mo Yu, Gerald Tesauro, Murray Campbell", "title": "Hybrid Reinforcement Learning with Expert State Sequences", "comments": "AAAI 2019; https://github.com/XiaoxiaoGuo/tensor4rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing imitation learning approaches often require that the complete\ndemonstration data, including sequences of actions and states, are available.\nIn this paper, we consider a more realistic and difficult scenario where a\nreinforcement learning agent only has access to the state sequences of an\nexpert, while the expert actions are unobserved. We propose a novel\ntensor-based model to infer the unobserved actions of the expert state\nsequences. The policy of the agent is then optimized via a hybrid objective\ncombining reinforcement learning and imitation learning. We evaluated our\nhybrid approach on an illustrative domain and Atari games. The empirical\nresults show that (1) the agents are able to leverage state expert sequences to\nlearn faster than pure reinforcement learning baselines, (2) our tensor-based\naction inference model is advantageous compared to standard deep neural\nnetworks in inferring expert actions, and (3) the hybrid policy optimization\nobjective is robust against noise in expert state sequences.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 03:28:13 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Guo", "Xiaoxiao", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""], ["Tesauro", "Gerald", ""], ["Campbell", "Murray", ""]]}, {"id": "1903.04124", "submitter": "Jinxi Guo", "authors": "Xin Chen, Wei Chu, Jinxi Guo, Ning Xu", "title": "Singing voice conversion with non-parallel data", "comments": "Accepted to MIPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singing voice conversion is a task to convert a song sang by a source singer\nto the voice of a target singer. In this paper, we propose using a parallel\ndata free, many-to-one voice conversion technique on singing voices. A phonetic\nposterior feature is first generated by decoding singing voices through a\nrobust Automatic Speech Recognition Engine (ASR). Then, a trained Recurrent\nNeural Network (RNN) with a Deep Bidirectional Long Short Term Memory (DBLSTM)\nstructure is used to model the mapping from person-independent content to the\nacoustic features of the target person. F0 and aperiodic are obtained through\nthe original singing voice, and used with acoustic features to reconstruct the\ntarget singing voice through a vocoder. In the obtained singing voice, the\ntargeted and sourced singers sound similar. To our knowledge, this is the first\nstudy that uses non parallel data to train a singing voice conversion system.\nSubjective evaluations demonstrate that the proposed method effectively\nconverts singing voices.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 04:52:36 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Chen", "Xin", ""], ["Chu", "Wei", ""], ["Guo", "Jinxi", ""], ["Xu", "Ning", ""]]}, {"id": "1903.04154", "submitter": "Ke Sun", "authors": "Ke Sun, Piotr Koniusz, Zhen Wang", "title": "Fisher-Bures Adversary Graph Convolutional Networks", "comments": "Published in UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a graph convolutional network, we assume that the graph $G$ is generated\nwrt some observation noise. During learning, we make small random perturbations\n$\\Delta{}G$ of the graph and try to improve generalization. Based on quantum\ninformation geometry, $\\Delta{}G$ can be characterized by the\neigendecomposition of the graph Laplacian matrix. We try to minimize the loss\nwrt the perturbed $G+\\Delta{G}$ while making $\\Delta{G}$ to be effective in\nterms of the Fisher information of the neural network. Our proposed model can\nconsistently improve graph convolutional networks on semi-supervised node\nclassification tasks with reasonable computational overhead. We present three\ndifferent geometries on the manifold of graphs: the intrinsic geometry measures\nthe information theoretic dynamics of a graph; the extrinsic geometry\ncharacterizes how such dynamics can affect externally a graph neural network;\nthe embedding geometry is for measuring node embeddings. These new analytical\ntools are useful in developing a good understanding of graph neural networks\nand fostering new techniques.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 07:47:33 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 23:48:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sun", "Ke", ""], ["Koniusz", "Piotr", ""], ["Wang", "Zhen", ""]]}, {"id": "1903.04191", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw, Silas N. {\\O}rting, Jens Petersen, Kim S. Pedersen,\n  Marleen de Bruijne", "title": "A cross-center smoothness prior for variational Bayesian brain tissue\n  segmentation", "comments": "12 pages, 2 figures, 1 table. Accepted to the International\n  Conference on Information Processing in Medical Imaging (2019)", "journal-ref": "International Conference on Information Processing in Medical\n  Imaging (IPMI), Hong Kong, 2019, pp. 360-371", "doi": "10.1007/978-3-030-20351-1_27", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose one is faced with the challenge of tissue segmentation in MR images,\nwithout annotators at their center to provide labeled training data. One option\nis to go to another medical center for a trained classifier. Sadly, tissue\nclassifiers do not generalize well across centers due to voxel intensity shifts\ncaused by center-specific acquisition protocols. However, certain aspects of\nsegmentations, such as spatial smoothness, remain relatively consistent and can\nbe learned separately. Here we present a smoothness prior that is fit to\nsegmentations produced at another medical center. This informative prior is\npresented to an unsupervised Bayesian model. The model clusters the voxel\nintensities, such that it produces segmentations that are similarly smooth to\nthose of the other medical center. In addition, the unsupervised Bayesian model\nis extended to a semi-supervised variant, which needs no visual interpretation\nof clusters into tissues.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:54:07 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kouw", "Wouter M.", ""], ["\u00d8rting", "Silas N.", ""], ["Petersen", "Jens", ""], ["Pedersen", "Kim S.", ""], ["de Bruijne", "Marleen", ""]]}, {"id": "1903.04192", "submitter": "Xinyu Peng", "authors": "Xinyu Peng, Li Li, Fei-Yue Wang", "title": "Accelerating Minibatch Stochastic Gradient Descent using Typicality\n  Sampling", "comments": "10 pages, 4 figures, for journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning, especially deep neural networks, has been rapidly developed\nin fields including computer vision, speech recognition and reinforcement\nlearning. Although Mini-batch SGD is one of the most popular stochastic\noptimization methods in training deep networks, it shows a slow convergence\nrate due to the large noise in gradient approximation. In this paper, we\nattempt to remedy this problem by building more efficient batch selection\nmethod based on typicality sampling, which reduces the error of gradient\nestimation in conventional Minibatch SGD. We analyze the convergence rate of\nthe resulting typical batch SGD algorithm and compare convergence properties\nbetween Minibatch SGD and the algorithm. Experimental results demonstrate that\nour batch selection scheme works well and more complex Minibatch SGD variants\ncan benefit from the proposed batch selection strategy.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:57:18 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Peng", "Xinyu", ""], ["Li", "Li", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "1903.04209", "submitter": "Andreas Joseph Mr.", "authors": "Andreas Joseph", "title": "Parametric inference with universal function approximators", "comments": "38 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Universal function approximators, such as artificial neural networks, can\nlearn a large variety of target functions arbitrarily well given sufficient\ntraining data. This flexibility comes at the cost of the ability to perform\nparametric inference. We address this gap by proposing a generic framework\nbased on the Shapley-Taylor decomposition of a model. A surrogate parametric\nregression analysis is performed in the space spanned by the Shapley value\nexpansion of a model. This allows for the testing of standard hypotheses of\ninterest. At the same time, the proposed approach provides novel insights into\nstatistical learning processes themselves derived from the consistency and bias\nproperties of the nonparametric estimators. We apply the framework to the\nestimation of heterogeneous treatment effects in simulated and real-world\nrandomised experiments. We introduce an explicit treatment function based on\nhigher-order Shapley-Taylor indices. This can be used to identify potentially\ncomplex treatment channels and help the generalisation of findings from\nexperimental settings. More generally, the presented approach allows for a\nstandardised use and communication of results from machine learning models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 10:37:05 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 18:02:56 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 13:40:22 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 20:18:27 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Joseph", "Andreas", ""]]}, {"id": "1903.04233", "submitter": "Anees Kazi", "authors": "Anees Kazi, Shayan shekarforoush, S.Arvind krishna, Hendrik Burwinkel,\n  Gerome Vivar, Karsten Kortuem, Seyed-Ahmad Ahmadi, Shadi Albarqouni, Nassir\n  Navab", "title": "InceptionGCN: Receptive Field Aware Graph Convolutional Network for\n  Disease Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric deep learning provides a principled and versatile manner for the\nintegration of imaging and non-imaging modalities in the medical domain. Graph\nConvolutional Networks (GCNs) in particular have been explored on a wide\nvariety of problems such as disease prediction, segmentation, and matrix\ncompletion by leveraging large, multimodal datasets. In this paper, we\nintroduce a new spectral domain architecture for deep learning on graphs for\ndisease prediction. The novelty lies in defining geometric 'inception modules'\nwhich are capable of capturing intra- and inter-graph structural heterogeneity\nduring convolutions. We design filters with different kernel sizes to build our\narchitecture. We show our disease prediction results on two publicly available\ndatasets. Further, we provide insights on the behaviour of regular GCNs and our\nproposed model under varying input scenarios on simulated data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 11:55:54 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kazi", "Anees", ""], ["shekarforoush", "Shayan", ""], ["krishna", "S. Arvind", ""], ["Burwinkel", "Hendrik", ""], ["Vivar", "Gerome", ""], ["Kortuem", "Karsten", ""], ["Ahmadi", "Seyed-Ahmad", ""], ["Albarqouni", "Shadi", ""], ["Navab", "Nassir", ""]]}, {"id": "1903.04235", "submitter": "Zhao Kang", "authors": "Zhao Kang, Yiwei Lu, Yuanzhang Su, Changsheng Li, Zenglin Xu", "title": "Similarity Learning via Kernel Preserving Embedding", "comments": "Published in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data similarity is a key concept in many data-driven applications. Many\nalgorithms are sensitive to similarity measures. To tackle this fundamental\nproblem, automatically learning of similarity information from data via\nself-expression has been developed and successfully applied in various models,\nsuch as low-rank representation, sparse subspace learning, semi-supervised\nlearning. However, it just tries to reconstruct the original data and some\nvaluable information, e.g., the manifold structure, is largely ignored. In this\npaper, we argue that it is beneficial to preserve the overall relations when we\nextract similarity information. Specifically, we propose a novel similarity\nlearning framework by minimizing the reconstruction error of kernel matrices,\nrather than the reconstruction error of original data adopted by existing work.\nTaking the clustering task as an example to evaluate our method, we observe\nconsiderable improvements compared to other state-of-the-art methods. More\nimportantly, our proposed framework is very general and provides a novel and\nfundamental building block for many other similarity-based tasks. Besides, our\nproposed kernel preserving opens up a large number of possibilities to embed\nhigh-dimensional data into low-dimensional space.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 11:58:40 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kang", "Zhao", ""], ["Lu", "Yiwei", ""], ["Su", "Yuanzhang", ""], ["Li", "Changsheng", ""], ["Xu", "Zenglin", ""]]}, {"id": "1903.04254", "submitter": "Abhinandan Krishnan", "authors": "Abhinandan Krishnan, Abilash Amarthaluri", "title": "Large Scale Product Categorization using Structured and Unstructured\n  Attributes", "comments": "Submitted to KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product categorization using text data for eCommerce is a very challenging\nextreme classification problem with several thousands of classes and several\nmillions of products to classify. Even though multi-class text classification\nis a well studied problem both in academia and industry, most approaches either\ndeal with treating product content as a single pile of text, or only consider a\nfew product attributes for modelling purposes. Given the variety of products\nsold on popular eCommerce platforms, it is hard to consider all available\nproduct attributes as part of the modeling exercise, considering that products\npossess their own unique set of attributes based on category. In this paper, we\ncompare hierarchical models to flat models and show that in specific cases,\nflat models perform better. We explore two Deep Learning based models that\nextract features from individual pieces of unstructured data from each product\nand then combine them to create a product signature. We also propose a novel\nidea of using structured attributes and their values together in an\nunstructured fashion along with convolutional filters such that the ordering of\nthe attributes and the differing attributes by product categories no longer\nbecomes a modelling challenge. This approach is also more robust to the\npresence of faulty product attribute names and values and can elegantly\ngeneralize to use both closed list and open list attributes.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 23:41:10 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Krishnan", "Abhinandan", ""], ["Amarthaluri", "Abilash", ""]]}, {"id": "1903.04263", "submitter": "Shubhra-Kanti Karmaker-Santu", "authors": "Shubhra Kanti Karmaker Santu, Parikshit Sondhi, ChengXiang Zhai", "title": "On Application of Learning to Rank for E-Commerce Search", "comments": null, "journal-ref": null, "doi": "10.1145/3077136.3080838", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-Commerce (E-Com) search is an emerging important new application of\ninformation retrieval. Learning to Rank (LETOR) is a general effective strategy\nfor optimizing search engines, and is thus also a key technology for E-Com\nsearch. While the use of LETOR for web search has been well studied, its use\nfor E-Com search has not yet been well explored. In this paper, we discuss the\npractical challenges in applying learning to rank methods to E-Com search,\nincluding the challenges in feature representation, obtaining reliable\nrelevance judgments, and optimally exploiting multiple user feedback signals\nsuch as click rates, add-to-cart ratios, order rates, and revenue. We study\nthese new challenges using experiments on industry data sets and report several\ninteresting findings that can provide guidance on how to optimally apply LETOR\nto E-Com search: First, popularity-based features defined solely on product\nitems are very useful and LETOR methods were able to effectively optimize their\ncombination with relevance-based features. Second, query attribute sparsity\nraises challenges for LETOR, and selecting features to reduce/avoid sparsity is\nbeneficial. Third, while crowdsourcing is often useful for obtaining relevance\njudgments for Web search, it does not work as well for E-Com search due to\ndifficulty in eliciting sufficiently fine grained relevance judgments. Finally,\namong the multiple feedback signals, the order rate is found to be the most\nrobust training objective, followed by click rate, while add-to-cart ratio\nseems least robust, suggesting that an effective practical strategy may be to\ninitially use click rates for training and gradually shift to using order rates\nas they become available.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 22:10:14 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Santu", "Shubhra Kanti Karmaker", ""], ["Sondhi", "Parikshit", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "1903.04268", "submitter": "Yunhao Tang", "authors": "Krzysztof Choromanski, Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang", "title": "From Complexity to Simplicity: Adaptive ES-Active Subspaces for Blackbox\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm ASEBO for optimizing high-dimensional blackbox\nfunctions. ASEBO adapts to the geometry of the function and learns optimal sets\nof sensing directions, which are used to probe it, on-the-fly. It addresses the\nexploration-exploitation trade-off of blackbox optimization with expensive\nblackbox queries by continuously learning the bias of the lower-dimensional\nmodel used to approximate gradients of smoothings of the function via\ncompressed sensing and contextual bandits methods. To obtain this model, it\nleverages techniques from the emerging theory of active subspaces in the novel\nES blackbox optimization context. As a result, ASEBO learns the dynamically\nchanging intrinsic dimensionality of the gradient space and adapts to the\nhardness of different stages of the optimization without external supervision.\nConsequently, it leads to more sample-efficient blackbox optimization than\nstate-of-the-art algorithms. We provide theoretical results and test ASEBO\nadvantages over other methods empirically by evaluating it on the set of\nreinforcement learning policy optimization tasks as well as functions from the\nrecently open-sourced Nevergrad library.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 16:04:13 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 15:23:27 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 22:25:10 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Pacchiano", "Aldo", ""], ["Parker-Holder", "Jack", ""], ["Tang", "Yunhao", ""]]}, {"id": "1903.04276", "submitter": "Leonidas Akritidis Mr", "authors": "Leonidas Akritidis, Athanasios Fevgas, Panayiotis Bozanis, Christos\n  Makris", "title": "A Clustering-Based Combinatorial Approach to Unsupervised Matching of\n  Product Titles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constant growth of the e-commerce industry has rendered the problem of\nproduct retrieval particularly important. As more enterprises move their\nactivities on the Web, the volume and the diversity of the product-related\ninformation increase quickly. These factors make it difficult for the users to\nidentify and compare the features of their desired products. Recent studies\nproved that the standard similarity metrics cannot effectively identify\nidentical products, since similar titles often refer to different products and\nvice-versa. Other studies employed external data sources (search engines) to\nenrich the titles; these solutions are rather impractical mainly because the\nexternal data fetching is slow. In this paper we introduce UPM, an unsupervised\nalgorithm for matching products by their titles. UPM is independent of any\nexternal sources, since it analyzes the titles and extracts combinations of\nwords out of them. These combinations are evaluated according to several\ncriteria, and the most appropriate of them constitutes the cluster where a\nproduct is classified into. UPM is also parameter-free, it avoids product\npairwise comparisons, and includes a post-processing verification stage which\ncorrects the erroneous matches. The experimental evaluation of UPM demonstrated\nits superiority against the state-of-the-art approaches in terms of both\nefficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 02:22:48 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Akritidis", "Leonidas", ""], ["Fevgas", "Athanasios", ""], ["Bozanis", "Panayiotis", ""], ["Makris", "Christos", ""]]}, {"id": "1903.04277", "submitter": "Xinlei Yi", "authors": "Xinlei Yi, Xiuxian Li, Lihua Xie, and Karl H. Johansson", "title": "Distributed Online Convex Optimization with Time-Varying Coupled\n  Inequality Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers distributed online optimization with time-varying\ncoupled inequality constraints. The global objective function is composed of\nlocal convex cost and regularization functions and the coupled constraint\nfunction is the sum of local convex functions. A distributed online primal-dual\ndynamic mirror descent algorithm is proposed to solve this problem, where the\nlocal cost, regularization, and constraint functions are held privately and\nrevealed only after each time slot. Without assuming Slater's condition, we\nfirst derive regret and constraint violation bounds for the algorithm and show\nhow they depend on the stepsize sequences, the accumulated dynamic variation of\nthe comparator sequence, the number of agents, and the network connectivity. As\na result, under some natural decreasing stepsize sequences, we prove that the\nalgorithm achieves sublinear dynamic regret and constraint violation if the\naccumulated dynamic variation of the optimal sequence also grows sublinearly.\nWe also prove that the algorithm achieves sublinear static regret and\nconstraint violation under mild conditions. Assuming Slater's condition, we\nshow that the algorithm achieves smaller bounds on the constraint violation. In\naddition, smaller bounds on the static regret are achieved when the objective\nfunction is strongly convex. Finally, numerical simulations are provided to\nillustrate the effectiveness of the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 20:29:00 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 10:09:40 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Yi", "Xinlei", ""], ["Li", "Xiuxian", ""], ["Xie", "Lihua", ""], ["Johansson", "Karl H.", ""]]}, {"id": "1903.04297", "submitter": "Shuai Ma", "authors": "Hongmei Wang, Zhenzhen Wu, Shuai Ma, Songtao Lu, Han Zhang, Guoru\n  Ding, and Shiyin Li", "title": "Deep Learning for Signal Demodulation in Physical Layer Wireless\n  Communications: Prototype Platform, Open Dataset, and Analytics", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2903130", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate deep learning (DL)-enabled signal demodulation\nmethods and establish the first open dataset of real modulated signals for\nwireless communication systems. Specifically, we propose a flexible\ncommunication prototype platform for measuring real modulation dataset. Then,\nbased on the measured dataset, two DL-based demodulators, called deep belief\nnetwork (DBN)-support vector machine (SVM) demodulator and adaptive boosting\n(AdaBoost) based demodulator, are proposed. The proposed DBN-SVM based\ndemodulator exploits the advantages of both DBN and SVM, i.e., the advantage of\nDBN as a feature extractor and SVM as a feature classifier. In DBN-SVM based\ndemodulator, the received signals are normalized before being fed to the DBN\nnetwork. Furthermore, an AdaBoost based demodulator is developed, which employs\nthe $k$-Nearest Neighbor (KNN) as a weak classifier to form a strong combined\nclassifier. Finally, experimental results indicate that the proposed DBN-SVM\nbased demodulator and AdaBoost based demodulator are superior to the single\nclassification method using DBN, SVM, and maximum likelihood (MLD) based\ndemodulator.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 12:47:57 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Hongmei", ""], ["Wu", "Zhenzhen", ""], ["Ma", "Shuai", ""], ["Lu", "Songtao", ""], ["Zhang", "Han", ""], ["Ding", "Guoru", ""], ["Li", "Shiyin", ""]]}, {"id": "1903.04337", "submitter": "Daniel Wesierski", "authors": "Lukasz Czekaj, Wojciech Ziembla, Pawel Jezierski, Pawel Swiniarski,\n  Anna Kolodziejak, Pawel Ogniewski, Pawel Niedbalski, Anna Jezierska, Daniel\n  Wesierski", "title": "Labeler-hot Detection of EEG Epileptic Transients", "comments": "5 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventing early progression of epilepsy and so the severity of seizures\nrequires an effective diagnosis. Epileptic transients indicate the ability to\ndevelop seizures but humans overlook such brief events in an\nelectroencephalogram (EEG) what compromises patient treatment. Traditionally,\ntraining of the EEG event detection algorithms has relied on ground truth\nlabels, obtained from the consensus of the majority of labelers. In this work,\nwe go beyond labeler consensus on EEG data. Our event descriptor integrates EEG\nsignal features with one-hot encoded labeler category that is a key to improved\ngeneralization performance. Notably, boosted decision trees take advantage of\nsingly-labeled but more varied training sets. Our quantitative experiments show\nthe proposed labeler-hot epileptic event detector consistently outperforms a\nconsensus-trained detector and maintains confidence bounds of the detection.\nThe results on our infant EEG recordings suggest datasets can gain higher event\nvariety faster and thus better performance by shifting available human effort\nfrom consensus-oriented to separate labeling when labels include both, the\nevent and the labeler category.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:48:49 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 12:01:55 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 08:59:41 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Czekaj", "Lukasz", ""], ["Ziembla", "Wojciech", ""], ["Jezierski", "Pawel", ""], ["Swiniarski", "Pawel", ""], ["Kolodziejak", "Anna", ""], ["Ogniewski", "Pawel", ""], ["Niedbalski", "Pawel", ""], ["Jezierska", "Anna", ""], ["Wesierski", "Daniel", ""]]}, {"id": "1903.04360", "submitter": "Yiming Xu", "authors": "Yiming Xu, Dnyanesh Rajpathak, Ian Gibbs, Diego Klabjan", "title": "Automatic Ontology Learning from Domain-Specific Short Unstructured Text\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology learning is a critical task in industry, dealing with identifying\nand extracting concepts captured in text data such that these concepts can be\nused in different tasks, e.g. information retrieval. Ontology learning is\nnon-trivial due to several reasons with limited amount of prior research work\nthat automatically learns a domain specific ontology from data. In our work, we\npropose a two-stage classification system to automatically learn an ontology\nfrom unstructured text data. We first collect candidate concepts, which are\nclassified into concepts and irrelevant collocates by our first classifier. The\nconcepts from the first classifier are further classified by the second\nclassifier into different concept types. The proposed system is deployed as a\nprototype at a company and its performance is validated by using complaint and\nrepair verbatim data collected in automotive industry from different data\nsources.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:48:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Xu", "Yiming", ""], ["Rajpathak", "Dnyanesh", ""], ["Gibbs", "Ian", ""], ["Klabjan", "Diego", ""]]}, {"id": "1903.04377", "submitter": "Bahareh Pourbabaee", "authors": "Bahareh Pourbabaee, Matthew Howe-Patterson, Matthew Patterson,\n  Frederic Benard", "title": "SleepNet: Automated Sleep Analysis via Dense Convolutional Neural\n  Network Using Physiological Time Series", "comments": "20 pages, 4 figures, Accepted to be published by Physiological\n  Measurement Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a dense recurrent convolutional neural network (DRCNN) was\nconstructed to detect sleep disorders including arousal, apnea and hypopnea\nusing Polysomnography (PSG) measurement channels provided in the 2018 Physionet\nchallenge database. Our model structure is composed of multiple dense\nconvolutional units (DCU) followed by a bidirectional long-short term memory\n(LSTM) layer followed by a softmax output layer. The sleep events including\nsleep stages, arousal regions and multiple types of apnea and hypopnea are\nmanually annotated by experts which enables us to train our proposed network\nusing a multi-task learning mechanism. Three binary cross-entropy loss\nfunctions corresponding to sleep/wake, target arousal and apnea-hypopnea/normal\ndetection tasks are summed up to generate our overall network loss function\nthat is optimized using the Adam method. Our model performance was evaluated\nusing two metrics: the area under the precision-recall curve (AUPRC) and the\narea under the receiver operating characteristic curve (AUROC). To measure our\nmodel generalization, 4-fold cross-validation was also performed. For training,\nour model was applied to full night recording data. Finally, the average AUPRC\nand AUROC values associated with the arousal detection task were 0.505 and\n0.922, respectively on our testing dataset. An ensemble of four models trained\non different data folds improved the AUPRC and AUROC to 0.543 and 0.931,\nrespectively. Our proposed algorithm achieved the first place in the official\nstage of the 2018 Physionet challenge for detecting sleep arousals with AUPRC\nof 0.54 on the blind testing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 15:41:55 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 16:17:16 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Pourbabaee", "Bahareh", ""], ["Howe-Patterson", "Matthew", ""], ["Patterson", "Matthew", ""], ["Benard", "Frederic", ""]]}, {"id": "1903.04388", "submitter": "Daniel Elton", "authors": "Daniel C. Elton, Zois Boukouvalas, Mark D. Fuge, Peter W. Chung", "title": "Deep learning for molecular design - a review of the state of the art", "comments": "24 pages, new title, published in RSC MSDE", "journal-ref": "Molecular Systems Design & Engineering, 2019", "doi": "10.1039/C9ME00039A", "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the space of only a few years, deep generative modeling has revolutionized\nhow we think of artificial creativity, yielding autonomous systems which\nproduce original images, music, and text. Inspired by these successes,\nresearchers are now applying deep generative modeling techniques to the\ngeneration and optimization of molecules - in our review we found 45 papers on\nthe subject published in the past two years. These works point to a future\nwhere such systems will be used to generate lead molecules, greatly reducing\nresources spent downstream synthesizing and characterizing bad leads in the\nlab. In this review we survey the increasingly complex landscape of models and\nrepresentation schemes that have been proposed. The four classes of techniques\nwe describe are recursive neural networks, autoencoders, generative adversarial\nnetworks, and reinforcement learning. After first discussing some of the\nmathematical fundamentals of each technique, we draw high level connections and\ncomparisons with other techniques and expose the pros and cons of each. Several\nimportant high level themes emerge as a result of this work, including the\nshift away from the SMILES string representation of molecules towards more\nsophisticated representations such as graph grammars and 3D representations,\nthe importance of reward function design, the need for better standards for\nbenchmarking and testing, and the benefits of adversarial training and\nreinforcement learning over maximum likelihood based training.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 15:51:47 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 14:02:24 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 21:00:25 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Elton", "Daniel C.", ""], ["Boukouvalas", "Zois", ""], ["Fuge", "Mark D.", ""], ["Chung", "Peter W.", ""]]}, {"id": "1903.04416", "submitter": "Xiaohui Chen", "authors": "Xiaohui Chen, Yun Yang", "title": "Diffusion $K$-means clustering on manifolds: provable exact recovery via\n  semidefinite relaxations", "comments": "accepted to Applied and Computational Harmonic Analysis", "journal-ref": null, "doi": "10.1016/j.acha.2020.03.002", "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the {\\it diffusion $K$-means} clustering method on Riemannian\nsubmanifolds, which maximizes the within-cluster connectedness based on the\ndiffusion distance. The diffusion $K$-means constructs a random walk on the\nsimilarity graph with vertices as data points randomly sampled on the manifolds\nand edges as similarities given by a kernel that captures the local geometry of\nmanifolds. The diffusion $K$-means is a multi-scale clustering tool that is\nsuitable for data with non-linear and non-Euclidean geometric features in mixed\ndimensions. Given the number of clusters, we propose a polynomial-time convex\nrelaxation algorithm via the semidefinite programming (SDP) to solve the\ndiffusion $K$-means. In addition, we also propose a nuclear norm regularized\nSDP that is adaptive to the number of clusters. In both cases, we show that\nexact recovery of the SDPs for diffusion $K$-means can be achieved under\nsuitable between-cluster separability and within-cluster connectedness of the\nsubmanifolds, which together quantify the hardness of the manifold clustering\nproblem. We further propose the {\\it localized diffusion $K$-means} by using\nthe local adaptive bandwidth estimated from the nearest neighbors. We show that\nexact recovery of the localized diffusion $K$-means is fully adaptive to the\nlocal probability density and geometric structures of the underlying\nsubmanifolds.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:29:27 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 01:01:56 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 03:27:37 GMT"}, {"version": "v4", "created": "Mon, 16 Mar 2020 16:49:41 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chen", "Xiaohui", ""], ["Yang", "Yun", ""]]}, {"id": "1903.04440", "submitter": "Konstantinos Spiliopoulos", "authors": "Justin Sirignano and Konstantinos Spiliopoulos", "title": "Mean Field Analysis of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze multi-layer neural networks in the asymptotic regime of\nsimultaneously (A) large network sizes and (B) large numbers of stochastic\ngradient descent training iterations. We rigorously establish the limiting\nbehavior of the multi-layer neural network output. The limit procedure is valid\nfor any number of hidden layers and it naturally also describes the limiting\nbehavior of the training loss. The ideas that we explore are to (a) take the\nlimits of each hidden layer sequentially and (b) characterize the evolution of\nparameters in terms of their initialization. The limit satisfies a system of\ndeterministic integro-differential equations. The proof uses methods from weak\nconvergence and stochastic analysis. We show that, under suitable assumptions\non the activation functions and the behavior for large times, the limit neural\nnetwork recovers a global minimum (with zero loss for the objective function).\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:02:10 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 02:30:59 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 22:03:14 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 02:24:54 GMT"}, {"version": "v5", "created": "Fri, 2 Apr 2021 19:19:18 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Sirignano", "Justin", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1903.04455", "submitter": "Jonathan Donier", "authors": "Jonathan Donier", "title": "Scaling up deep neural networks: a capacity allocation perspective", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent work on capacity allocation, we formulate the conjecture\nthat the shattering problem in deep neural networks can only be avoided if the\ncapacity propagation through layers has a non-degenerate continuous limit when\nthe number of layers tends to infinity. This allows us to study a number of\ncommonly used architectures and determine which scaling relations should be\nenforced in practice as the number of layers grows large. In particular, we\nrecover the conditions of Xavier initialization in the multi-channel case, and\nwe find that weights and biases should be scaled down as the inverse square\nroot of the number of layers for deep residual networks and as the inverse\nsquare root of the desired memory length for recurrent networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:24:57 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 10:29:24 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Donier", "Jonathan", ""]]}, {"id": "1903.04476", "submitter": "Siavash Golkar", "authors": "Siavash Golkar, Michael Kagan, Kyunghyun Cho", "title": "Continual Learning via Neural Pruning", "comments": "12 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Continual Learning via Neural Pruning (CLNP), a new method aimed\nat lifelong learning in fixed capacity models based on neuronal model\nsparsification. In this method, subsequent tasks are trained using the inactive\nneurons and filters of the sparsified network and cause zero deterioration to\nthe performance of previous tasks. In order to deal with the possible\ncompromise between model sparsity and performance, we formalize and incorporate\nthe concept of graceful forgetting: the idea that it is preferable to suffer a\nsmall amount of forgetting in a controlled manner if it helps regain network\ncapacity and prevents uncontrolled loss of performance during the training of\nfuture tasks. CLNP also provides simple continual learning diagnostic tools in\nterms of the number of free neurons left for the training of future tasks as\nwell as the number of neurons that are being reused. In particular, we see in\nexperiments that CLNP verifies and automatically takes advantage of the fact\nthat the features of earlier layers are more transferable. We show empirically\nthat CLNP leads to significantly improved results over current weight\nelasticity based methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:53:34 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Golkar", "Siavash", ""], ["Kagan", "Michael", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1903.04478", "submitter": "Ali Taylan Cemgil", "authors": "Ali Taylan Cemgil, Mehmet Burak Kurutmaz, Sinan Yildirim, Melih\n  Barsbey, Umut Simsekli", "title": "Bayesian Allocation Model: Inference by Sequential Monte Carlo for\n  Nonnegative Tensor Factorizations and Topic Models using Polya Urns", "comments": "70 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dynamic generative model, Bayesian allocation model (BAM),\nwhich establishes explicit connections between nonnegative tensor factorization\n(NTF), graphical models of discrete probability distributions and their\nBayesian extensions, and the topic models such as the latent Dirichlet\nallocation. BAM is based on a Poisson process, whose events are marked by using\na Bayesian network, where the conditional probability tables of this network\nare then integrated out analytically. We show that the resulting marginal\nprocess turns out to be a Polya urn, an integer valued self-reinforcing\nprocess. This urn processes, which we name a Polya-Bayes process, obey certain\nconditional independence properties that provide further insight about the\nnature of NTF. These insights also let us develop space efficient simulation\nalgorithms that respect the potential sparsity of data: we propose a class of\nsequential importance sampling algorithms for computing NTF and approximating\ntheir marginal likelihood, which would be useful for model selection. The\nresulting methods can also be viewed as a model scoring method for topic models\nand discrete Bayesian networks with hidden variables. The new algorithms have\nfavourable properties in the sparse data regime when contrasted with\nvariational algorithms that become more accurate when the total sum of the\nelements of the observed tensor goes to infinity. We illustrate the performance\non several examples and numerically study the behaviour of the algorithms for\nvarious data regimes.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:54:59 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Cemgil", "Ali Taylan", ""], ["Kurutmaz", "Mehmet Burak", ""], ["Yildirim", "Sinan", ""], ["Barsbey", "Melih", ""], ["Simsekli", "Umut", ""]]}, {"id": "1903.04479", "submitter": "Benjamin Guedj", "authors": "St\\'ephane Chr\\'etien and Benjamin Guedj", "title": "Revisiting clustering as matrix factorisation on the Stiefel manifold", "comments": "Accepted at the LOD 2020 Conference -- The Sixth International\n  Conference on Machine Learning, Optimization, and Data Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studies clustering for possibly high dimensional data (e.g.\nimages, time series, gene expression data, and many other settings), and\nrephrase it as low rank matrix estimation in the PAC-Bayesian framework. Our\napproach leverages the well known Burer-Monteiro factorisation strategy from\nlarge scale optimisation, in the context of low rank estimation. Moreover, our\nBurer-Monteiro factors are shown to lie on a Stiefel manifold. We propose a new\ngeneralized Bayesian estimator for this problem and prove novel prediction\nbounds for clustering. We also devise a componentwise Langevin sampler on the\nStiefel manifold to compute this estimator.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:56:13 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:15:01 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Chr\u00e9tien", "St\u00e9phane", ""], ["Guedj", "Benjamin", ""]]}, {"id": "1903.04486", "submitter": "Iman Niazazari", "authors": "Iman Niazazari, Reza Jalilzadeh Hamidi, Hanif Livani, and Reza\n  Arghandeh", "title": "Cause Identification of Electromagnetic Transient Events using\n  Spatiotemporal Feature Learning", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a spatiotemporal unsupervised feature learning method for\ncause identification of electromagnetic transient events (EMTE) in power grids.\nThe proposed method is formulated based on the availability of\ntime-synchronized high-frequency measurement, and using the convolutional\nneural network (CNN) as the spatiotemporal feature representation along with\nsoftmax function. Despite the existing threshold-based, or energy-based events\nanalysis methods, such as support vector machine (SVM), autoencoder, and\ntapered multi-layer perception (t-MLP) neural network, the proposed feature\nlearning is carried out with respect to both time and space. The effectiveness\nof the proposed feature learning and the subsequent cause identification is\nvalidated through the EMTP simulation of different events such as line\nenergization, capacitor bank energization, lightning, fault, and high-impedance\nfault in the IEEE 30-bus, and the real-time digital simulation (RTDS) of the\nWSCC 9-bus system.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 01:00:17 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Niazazari", "Iman", ""], ["Hamidi", "Reza Jalilzadeh", ""], ["Livani", "Hanif", ""], ["Arghandeh", "Reza", ""]]}, {"id": "1903.04488", "submitter": "Enayat Ullah", "authors": "Nikita Ivkin, Daniel Rothchild, Enayat Ullah, Vladimir Braverman, Ion\n  Stoica, Raman Arora", "title": "Communication-efficient distributed SGD with Sketching", "comments": "19 pages, 6 figures, published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale distributed training of neural networks is often limited by\nnetwork bandwidth, wherein the communication time overwhelms the local\ncomputation time. Motivated by the success of sketching methods in\nsub-linear/streaming algorithms, we introduce Sketched SGD, an algorithm for\ncarrying out distributed SGD by communicating sketches instead of full\ngradients. We show that Sketched SGD has favorable convergence rates on several\nclasses of functions. When considering all communication -- both of gradients\nand of updated model weights -- Sketched SGD reduces the amount of\ncommunication required compared to other gradient compression methods from\n$\\mathcal{O}(d)$ or $\\mathcal{O}(W)$ to $\\mathcal{O}(\\log d)$, where $d$ is the\nnumber of model parameters and $W$ is the number of workers participating in\ntraining. We run experiments on a transformer model, an LSTM, and a residual\nnetwork, demonstrating up to a 40x reduction in total communication cost with\nno loss in final model performance. We also show experimentally that Sketched\nSGD scales to at least 256 workers without increasing communication cost or\ndegrading model performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 17:59:48 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 21:49:03 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 15:59:50 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Ivkin", "Nikita", ""], ["Rothchild", "Daniel", ""], ["Ullah", "Enayat", ""], ["Braverman", "Vladimir", ""], ["Stoica", "Ion", ""], ["Arora", "Raman", ""]]}, {"id": "1903.04489", "submitter": "Baogui Xin", "authors": "Wei Peng, Baogui Xin", "title": "SPMF: A Social Trust and Preference Segmentation-based Matrix\n  Factorization Recommendation Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional social recommendation algorithm ignores the following fact:\nthe preferences of users with trust relationships are not necessarily similar,\nand the consideration of user preference similarity should be limited to\nspecific areas. A social trust and preference segmentation-based matrix\nfactorization (SPMF) recommendation system is proposed to solve the\nabove-mentioned problems. Experimental results based on the Ciao and Epinions\ndatasets show that the accuracy of the SPMF algorithm is significantly higher\nthan that of some state-of-the-art recommendation algorithms. The proposed SPMF\nalgorithm is a more accurate and effective recommendation algorithm based on\ndistinguishing the difference of trust relations and preference domain, which\ncan support commercial activities such as product marketing.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:18:43 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Peng", "Wei", ""], ["Xin", "Baogui", ""]]}, {"id": "1903.04527", "submitter": "Zhaojian Li", "authors": "Tianshu Chu, Jie Wang, Lara Codec\\`a, Zhaojian Li", "title": "Multi-Agent Deep Reinforcement Learning for Large-scale Traffic Signal\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a promising data-driven approach for adaptive\ntraffic signal control (ATSC) in complex urban traffic networks, and deep\nneural networks further enhance its learning power. However, centralized RL is\ninfeasible for large-scale ATSC due to the extremely high dimension of the\njoint action space. Multi-agent RL (MARL) overcomes the scalability issue by\ndistributing the global control to each local RL agent, but it introduces new\nchallenges: now the environment becomes partially observable from the viewpoint\nof each local agent due to limited communication among agents. Most existing\nstudies in MARL focus on designing efficient communication and coordination\namong traditional Q-learning agents. This paper presents, for the first time, a\nfully scalable and decentralized MARL algorithm for the state-of-the-art deep\nRL agent: advantage actor critic (A2C), within the context of ATSC. In\nparticular, two methods are proposed to stabilize the learning procedure, by\nimproving the observability and reducing the learning difficulty of each local\nagent. The proposed multi-agent A2C is compared against independent A2C and\nindependent Q-learning algorithms, in both a large synthetic traffic grid and a\nlarge real-world traffic network of Monaco city, under simulated peak-hour\ntraffic dynamics. Results demonstrate its optimality, robustness, and sample\nefficiency over other state-of-the-art decentralized MARL algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 18:28:58 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Chu", "Tianshu", ""], ["Wang", "Jie", ""], ["Codec\u00e0", "Lara", ""], ["Li", "Zhaojian", ""]]}, {"id": "1903.04556", "submitter": "Diego Mesquita", "authors": "Diego Mesquita, Paul Blomstedt, Samuel Kaski", "title": "Embarrassingly parallel MCMC using deep invertible transformations", "comments": "Accepted to UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While MCMC methods have become a main work-horse for Bayesian inference,\nscaling them to large distributed datasets is still a challenge. Embarrassingly\nparallel MCMC strategies take a divide-and-conquer stance to achieve this by\nwriting the target posterior as a product of subposteriors, running MCMC for\neach of them in parallel and subsequently combining the results. The challenge\nthen lies in devising efficient aggregation strategies. Current strategies\ntrade-off between approximation quality, and costs of communication and\ncomputation. In this work, we introduce a novel method that addresses these\nissues simultaneously. Our key insight is to introduce a deep invertible\ntransformation to approximate each of the subposteriors. These approximations\ncan be made accurate even for complex distributions and serve as intermediate\nrepresentations, keeping the total communication cost limited. Moreover, they\nenable us to sample from the product of the subposteriors using an efficient\nand stable importance sampling scheme. We demonstrate the approach outperforms\navailable state-of-the-art methods in a range of challenging scenarios,\nincluding high-dimensional and heterogeneous subposteriors.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:23:22 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 08:27:24 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mesquita", "Diego", ""], ["Blomstedt", "Paul", ""], ["Kaski", "Samuel", ""]]}, {"id": "1903.04561", "submitter": "Nithum Thain", "authors": "Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, Lucy\n  Vasserman", "title": "Nuanced Metrics for Measuring Unintended Bias with Real Data for Text\n  Classification", "comments": "Updated to fix typo in Equation 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unintended bias in Machine Learning can manifest as systemic differences in\nperformance for different demographic groups, potentially compounding existing\nchallenges to fairness in society at large. In this paper, we introduce a suite\nof threshold-agnostic metrics that provide a nuanced view of this unintended\nbias, by considering the various ways that a classifier's score distribution\ncan vary across designated groups. We also introduce a large new test set of\nonline comments with crowd-sourced annotations for identity references. We use\nthis to show how our metrics can be used to find new and potentially subtle\nunintended bias in existing public models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:45:54 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 14:39:41 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Borkan", "Daniel", ""], ["Dixon", "Lucas", ""], ["Sorensen", "Jeffrey", ""], ["Thain", "Nithum", ""], ["Vasserman", "Lucy", ""]]}, {"id": "1903.04566", "submitter": "Mohammad Rostami", "authors": "Mohammad Rostami, Soheil Kolouri, Praveen K. Pilly", "title": "Complementary Learning for Overcoming Catastrophic Forgetting Using\n  Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite huge success, deep networks are unable to learn effectively in\nsequential multitask learning settings as they forget the past learned tasks\nafter learning new tasks. Inspired from complementary learning systems theory,\nwe address this challenge by learning a generative model that couples the\ncurrent task to the past learned tasks through a discriminative embedding\nspace. We learn an abstract level generative distribution in the embedding that\nallows the generation of data points to represent the experience. We sample\nfrom this distribution and utilize experience replay to avoid forgetting and\nsimultaneously accumulate new knowledge to the abstract distribution in order\nto couple the current task with past experience. We demonstrate theoretically\nand empirically that our framework learns a distribution in the embedding that\nis shared across all task and as a result tackles catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:50:38 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 18:28:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Rostami", "Mohammad", ""], ["Kolouri", "Soheil", ""], ["Pilly", "Praveen K.", ""]]}, {"id": "1903.04571", "submitter": "Guy Shtar", "authors": "Guy Shtar, Lior Rokach, Bracha Shapira", "title": "Detecting drug-drug interactions using artificial neural networks and\n  classic graph similarity measures", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0219796", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug-drug interactions are preventable causes of medical injuries and often\nresult in doctor and emergency room visits. Computational techniques can be\nused to predict potential drug-drug interactions. We approach the drug-drug\ninteraction prediction problem as a link prediction problem and present two\nnovel methods for drug-drug interaction prediction based on artificial neural\nnetworks and factor propagation over graph nodes: adjacency matrix\nfactorization (AMF) and adjacency matrix factorization with propagation (AMFP).\nWe conduct a retrospective analysis by training our models on a previous\nrelease of the DrugBank database with 1,141 drugs and 45,296 drug-drug\ninteractions and evaluate the results on a later version of DrugBank with 1,440\ndrugs and 248,146 drug-drug interactions. Additionally, we perform a holdout\nanalysis using DrugBank. We report an area under the receiver operating\ncharacteristic curve score of 0.807 and 0.990 for the retrospective and holdout\nanalyses respectively. Finally, we create an ensemble-based classifier using\nAMF, AMFP, and existing link prediction methods and obtain an area under the\nreceiver operating characteristic curve of 0.814 and 0.991 for the\nretrospective and the holdout analyses. We demonstrate that AMF and AMFP\nprovide state of the art results compared to existing methods and that the\nensemble-based classifier improves the performance by combining various\npredictors. These results suggest that AMF, AMFP, and the proposed\nensemble-based classifier can provide important information during drug\ndevelopment and regarding drug prescription given only partial or noisy data.\nThese methods can also be used to solve other link prediction problems. Drug\nembeddings (compressed representations) created when training our models using\nthe interaction network have been made public.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:59:29 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 09:31:26 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Shtar", "Guy", ""], ["Rokach", "Lior", ""], ["Shapira", "Bracha", ""]]}, {"id": "1903.04598", "submitter": "Henrique Lemos", "authors": "Henrique Lemos and Marcelo Prates and Pedro Avelar and Luis Lamb", "title": "Graph Colouring Meets Deep Learning: Effective Graph Neural Network\n  Models for Combinatorial Problems", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has consistently defied state-of-the-art techniques in many\nfields over the last decade. However, we are just beginning to understand the\ncapabilities of neural learning in symbolic domains. Deep learning\narchitectures that employ parameter sharing over graphs can produce models\nwhich can be trained on complex properties of relational data. These include\nhighly relevant NP-Complete problems, such as SAT and TSP. In this work, we\nshowcase how Graph Neural Networks (GNN) can be engineered -- with a very\nsimple architecture -- to solve the fundamental combinatorial problem of graph\ncolouring. Our results show that the model, which achieves high accuracy upon\ntraining on random instances, is able to generalise to graph distributions\ndifferent from those seen at training time. Further, it performs better than\nthe Neurosat, Tabucol and greedy baselines for some distributions. In addition,\nwe show how vertex embeddings can be clustered in multidimensional spaces to\nyield constructive solutions even though our model is only trained as a binary\nclassifier. In summary, our results contribute to shorten the gap in our\nunderstanding of the algorithms learned by GNNs, as well as hoarding empirical\nevidence for their capability on hard combinatorial problems. Our results thus\ncontribute to the standing challenge of integrating robust learning and\nsymbolic reasoning in Deep Learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 20:46:47 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 19:00:53 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lemos", "Henrique", ""], ["Prates", "Marcelo", ""], ["Avelar", "Pedro", ""], ["Lamb", "Luis", ""]]}, {"id": "1903.04610", "submitter": "Murat Ozbayoglu", "authors": "Omer Berat Sezer, Ahmet Murat Ozbayoglu", "title": "Financial Trading Model with Stock Bar Chart Image Time Series with Deep\n  Convolutional Neural Networks", "comments": "accepted to be published in Intelligent Automation and Soft Computing\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though computational intelligence techniques have been extensively\nutilized in financial trading systems, almost all developed models use the time\nseries data for price prediction or identifying buy-sell points. However, in\nthis study we decided to use 2-D stock bar chart images directly without\nintroducing any additional time series associated with the underlying stock. We\npropose a novel algorithmic trading model CNN-BI (Convolutional Neural Network\nwith Bar Images) using a 2-D Convolutional Neural Network. We generated 2-D\nimages of sliding windows of 30-day bar charts for Dow 30 stocks and trained a\ndeep Convolutional Neural Network (CNN) model for our algorithmic trading\nmodel. We tested our model separately between 2007-2012 and 2012-2017 for\nrepresenting different market conditions. The results indicate that the model\nwas able to outperform Buy and Hold strategy, especially in trendless or bear\nmarkets. Since this is a preliminary study and probably one of the first\nattempts using such an unconventional approach, there is always potential for\nimprovement. Overall, the results are promising and the model might be\nintegrated as part of an ensemble trading model combined with different\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 21:17:20 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Sezer", "Omer Berat", ""], ["Ozbayoglu", "Ahmet Murat", ""]]}, {"id": "1903.04613", "submitter": "Rakshit Agrawal", "authors": "Rakshit Agrawal, Luca de Alfaro", "title": "Learning Edge Properties in Graphs from Path Aggregations", "comments": "To be published in The Proceedings of the 2019 World Wide Web\n  Conference (WWW'19)", "journal-ref": null, "doi": "10.1145/3308558.3313695", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph edges, along with their labels, can represent information of\nfundamental importance, such as links between web pages, friendship between\nusers, the rating given by users to other users or items, and much more. We\nintroduce LEAP, a trainable, general framework for predicting the presence and\nproperties of edges on the basis of the local structure, topology, and labels\nof the graph. The LEAP framework is based on the exploration and\nmachine-learning aggregation of the paths connecting nodes in a graph. We\nprovide several methods for performing the aggregation phase by training path\naggregators, and we demonstrate the flexibility and generality of the framework\nby applying it to the prediction of links and user ratings in social networks.\n  We validate the LEAP framework on two problems: link prediction, and user\nrating prediction. On eight large datasets, among which the arXiv collaboration\nnetwork, the Yeast protein-protein interaction, and the US airlines routes\nnetwork, we show that the link prediction performance of LEAP is at least as\ngood as the current state of the art methods, such as SEAL and WLNM. Next, we\nconsider the problem of predicting user ratings on other users: this problem is\nknown as the edge-weight prediction problem in weighted signed networks (WSN).\nOn Bitcoin networks, and Wikipedia RfA, we show that LEAP performs consistently\nbetter than the Fairness & Goodness based regression models, varying the amount\nof training edges between 10 to 90%. These examples demonstrate that LEAP, in\nspite of its generality, can match or best the performance of approaches that\nhave been especially crafted to solve very specific edge prediction problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 21:31:04 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Agrawal", "Rakshit", ""], ["de Alfaro", "Luca", ""]]}, {"id": "1903.04631", "submitter": "Asad Haris", "authors": "Asad Haris, Noah Simon, Ali Shojaie", "title": "Wavelet regression and additive models for irregularly spaced data", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2018, 8987-8997", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for nonparametric regression using wavelet basis\nfunctions. Our proposal, $\\texttt{waveMesh}$, can be applied to non-equispaced\ndata with sample size not necessarily a power of 2. We develop an efficient\nproximal gradient descent algorithm for computing the estimator and establish\nadaptive minimax convergence rates. The main appeal of our approach is that it\nnaturally extends to additive and sparse additive models for a potentially\nlarge number of covariates. We prove minimax optimal convergence rates under a\nweak compatibility condition for sparse additive models. The compatibility\ncondition holds when we have a small number of covariates. Additionally, we\nestablish convergence rates for when the condition is not met. We complement\nour theoretical results with empirical studies comparing $\\texttt{waveMesh}$ to\nexisting methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 22:14:40 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Haris", "Asad", ""], ["Simon", "Noah", ""], ["Shojaie", "Ali", ""]]}, {"id": "1903.04641", "submitter": "Asad Haris", "authors": "Asad Haris, Noah Simon, Ali Shojaie", "title": "Generalized Sparse Additive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework for estimation and analysis of generalized\nadditive models in high dimensions. The framework defines a large class of\npenalized regression estimators, encompassing many existing methods. An\nefficient computational algorithm for this class is presented that easily\nscales to thousands of observations and features. We prove minimax optimal\nconvergence bounds for this class under a weak compatibility condition. In\naddition, we characterize the rate of convergence when this compatibility\ncondition is not met. Finally, we also show that the optimal penalty parameters\nfor structure and sparsity penalties in our framework are linked, allowing\ncross-validation to be conducted over only a single tuning parameter. We\ncomplement our theoretical results with empirical studies comparing some\nexisting methods within this framework.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 22:50:29 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Haris", "Asad", ""], ["Simon", "Noah", ""], ["Shojaie", "Ali", ""]]}, {"id": "1903.04656", "submitter": "Marius Arvinte", "authors": "Marius Arvinte, Ahmed H. Tewfik, Sriram Vishwanath", "title": "Deep Log-Likelihood Ratio Quantization", "comments": "Accepted for publication at EUSIPCO 2019. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, a deep learning-based method for log-likelihood ratio (LLR)\nlossy compression and quantization is proposed, with emphasis on a single-input\nsingle-output uncorrelated fading communication setting. A deep autoencoder\nnetwork is trained to compress, quantize and reconstruct the bit log-likelihood\nratios corresponding to a single transmitted symbol. Specifically, the encoder\nmaps to a latent space with dimension equal to the number of sufficient\nstatistics required to recover the inputs - equal to three in this case - while\nthe decoder aims to reconstruct a noisy version of the latent representation\nwith the purpose of modeling quantization effects in a differentiable way.\nSimulation results show that, when applied to a standard rate-1/2 low-density\nparity-check (LDPC) code, a finite precision compression factor of nearly three\ntimes is achieved when storing an entire codeword, with an incurred loss of\nperformance lower than 0.1 dB compared to straightforward scalar quantization\nof the log-likelihood ratios.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 23:40:05 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 15:17:44 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 23:24:12 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Arvinte", "Marius", ""], ["Tewfik", "Ahmed H.", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1903.04703", "submitter": "Jian Wu", "authors": "Jian Wu, Saul Toscano-Palmerin, Peter I. Frazier and Andrew Gordon\n  Wilson", "title": "Practical Multi-fidelity Bayesian Optimization for Hyperparameter Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is popular for optimizing time-consuming black-box\nobjectives. Nonetheless, for hyperparameter tuning in deep neural networks, the\ntime required to evaluate the validation error for even a few hyperparameter\nsettings remains a bottleneck. Multi-fidelity optimization promises relief\nusing cheaper proxies to such objectives --- for example, validation error for\na network trained using a subset of the training points or fewer iterations\nthan required for convergence. We propose a highly flexible and practical\napproach to multi-fidelity Bayesian optimization, focused on efficiently\noptimizing hyperparameters for iteratively trained supervised learning models.\nWe introduce a new acquisition function, the trace-aware knowledge-gradient,\nwhich efficiently leverages both multiple continuous fidelity controls and\ntrace observations --- values of the objective at a sequence of fidelities,\navailable when varying fidelity using training iterations. We provide a\nprovably convergent method for optimizing our acquisition function and show it\noutperforms state-of-the-art alternatives for hyperparameter tuning of deep\nneural networks and large-scale kernel learning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 02:14:04 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Wu", "Jian", ""], ["Toscano-Palmerin", "Saul", ""], ["Frazier", "Peter I.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1903.04717", "submitter": "Scott Coull", "authors": "Scott E. Coull and Christopher Gardner", "title": "Activation Analysis of a Byte-Based Deep Neural Network for Malware\n  Classification", "comments": "2nd Deep Learning and Security Workshop (DLS 2019)", "journal-ref": "2nd Deep Learning and Security Workshop (DLS 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering is one of the most costly aspects of developing effective\nmachine learning models, and that cost is even greater in specialized problem\ndomains, like malware classification, where expert skills are necessary to\nidentify useful features. Recent work, however, has shown that deep learning\nmodels can be used to automatically learn feature representations directly from\nthe raw, unstructured bytes of the binaries themselves. In this paper, we\nexplore what these models are learning about malware. To do so, we examine the\nlearned features at multiple levels of resolution, from individual byte\nembeddings to end-to-end analysis of the model. At each step, we connect these\nbyte-oriented activations to their original semantics through parsing and\ndisassembly of the binary to arrive at human-understandable features. Through\nour results, we identify several interesting features learned by the model and\ntheir connection to manually-derived features typically used by traditional\nmachine learning models. Additionally, we explore the impact of training data\nvolume and regularization on the quality of the learned features and the\nefficacy of the classifiers, revealing the somewhat paradoxical insight that\nbetter generalization does not necessarily result in better performance for\nbyte-based malware classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 04:00:42 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 02:57:07 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Coull", "Scott E.", ""], ["Gardner", "Christopher", ""]]}, {"id": "1903.04735", "submitter": "Huyan Huang", "authors": "Huyan Huang, Yipeng Liu, Ce Zhu", "title": "Low-rank Tensor Grid for Image Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion estimates missing components by exploiting the low-rank\nstructure of multi-way data. The recently proposed methods based on tensor\ntrain (TT) and tensor ring (TR) show better performance in image recovery than\nclassical ones. Compared with TT and TR, the projected entangled pair state\n(PEPS), which is also called tensor grid (TG), allows more interactions between\ndifferent dimensions, and may lead to more compact representation. In this\npaper, we propose to perform image completion based on low-rank tensor grid. A\ntwo-stage density matrix renormalization group algorithm is used for\ninitialization of TG decomposition, which consists of multiple TT\ndecompositions. The latent TG factors can be alternatively obtained by solving\nalternating least squares problems. To further improve the computational\nefficiency, a multi-linear matrix factorization for low rank TG completion is\ndeveloped by using parallel matrix factorization. Experimental results on\nsynthetic data and real-world images show the proposed methods outperform the\nexisting ones in terms of recovery accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 05:36:37 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 02:41:09 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 07:58:20 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Huang", "Huyan", ""], ["Liu", "Yipeng", ""], ["Zhu", "Ce", ""]]}, {"id": "1903.04774", "submitter": "Patrick Schlachter", "authors": "Patrick Schlachter, Yiwen Liao and Bin Yang", "title": "Open-Set Recognition Using Intra-Class Splitting", "comments": "IEEE European Signal Processing Conference 2019 (EUSIPCO 2019)", "journal-ref": null, "doi": "10.23919/EUSIPCO.2019.8902738", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to use deep neural networks as end-to-end\nopen-set classifiers. It is based on intra-class data splitting. In open-set\nrecognition, only samples from a limited number of known classes are available\nfor training. During inference, an open-set classifier must reject samples from\nunknown classes while correctly classifying samples from known classes. The\nproposed method splits given data into typical and atypical normal subsets by\nusing a closed-set classifier. This enables to model the abnormal classes by\natypical normal samples. Accordingly, the open-set recognition problem is\nreformulated into a traditional classification problem. In addition, a\nclosed-set regularization is proposed to guarantee a high closed-set\nclassification performance. Intensive experiments on five well-known image\ndatasets showed the effectiveness of the proposed method which outperformed the\nbaselines and achieved a distinct improvement over the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 08:24:15 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 14:07:31 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 13:50:35 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Schlachter", "Patrick", ""], ["Liao", "Yiwen", ""], ["Yang", "Bin", ""]]}, {"id": "1903.04797", "submitter": "Christian A. Naesseth", "authors": "Christian A. Naesseth and Fredrik Lindsten and Thomas B. Sch\\\"on", "title": "Elements of Sequential Monte Carlo", "comments": "Under review at Foundations and Trends in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core problem in statistics and probabilistic machine learning is to compute\nprobability distributions and expectations. This is the fundamental problem of\nBayesian statistics and machine learning, which frames all inference as\nexpectations with respect to the posterior distribution. The key challenge is\nto approximate these intractable expectations. In this tutorial, we review\nsequential Monte Carlo (SMC), a random-sampling-based class of methods for\napproximate inference. First, we explain the basics of SMC, discuss practical\nissues, and review theoretical results. We then examine two of the main user\ndesign choices: the proposal distributions and the so called intermediate\ntarget distributions. We review recent results on how variational inference and\namortization can be used to learn efficient proposals and target distributions.\nNext, we discuss the SMC estimate of the normalizing constant, how this can be\nused for pseudo-marginal inference and inference evaluation. Throughout the\ntutorial we illustrate the use of SMC on various models commonly used in\nmachine learning, such as stochastic recurrent neural networks, probabilistic\ngraphical models, and probabilistic programs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 09:28:05 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Naesseth", "Christian A.", ""], ["Lindsten", "Fredrik", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1903.04820", "submitter": "Parviz Asghari", "authors": "Parviz Asghari, Elnaz Soelimani, Ehsan Nazerfard", "title": "Online Human Activity Recognition Employing Hierarchical Hidden Markov\n  Models", "comments": "9 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years there has been a growing interest in Human Activity\nRecognition~(HAR) topic. Sensor-based HAR approaches, in particular, has been\ngaining more popularity owing to their privacy preserving nature. Furthermore,\ndue to the widespread accessibility of the internet, a broad range of\nstreaming-based applications such as online HAR, has emerged over the past\ndecades. However, proposing sufficiently robust online activity recognition\napproach in smart environment setting is still considered as a remarkable\nchallenge. This paper presents a novel online application of Hierarchical\nHidden Markov Model in order to detect the current activity on the live\nstreaming of sensor events. Our method consists of two phases. In the first\nphase, data stream is segmented based on the beginning and ending of the\nactivity patterns. Also, on-going activity is reported with every receiving\nobservation. This phase is implemented using Hierarchical Hidden Markov models.\nThe second phase is devoted to the correction of the provided label for the\nsegmented data stream based on statistical features. The proposed model can\nalso discover the activities that happen during another activity - so-called\ninterrupted activities. After detecting the activity pane, the predicted label\nwill be corrected utilizing statistical features such as time of day at which\nthe activity happened and the duration of the activity. We validated our\nproposed method by testing it against two different smart home datasets and\ndemonstrated its effectiveness, which is competing with the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 10:22:33 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Asghari", "Parviz", ""], ["Soelimani", "Elnaz", ""], ["Nazerfard", "Ehsan", ""]]}, {"id": "1903.04829", "submitter": "Alexander Marx", "authors": "Alexander Marx and Jilles Vreeken", "title": "Testing Conditional Independence on Discrete Data using Stochastic\n  Complexity", "comments": "18 pages, accepted at AISTATS'19, the proposed test was released in\n  the R package SCCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing for conditional independence is a core aspect of constraint-based\ncausal discovery. Although commonly used tests are perfect in theory, they\noften fail to reject independence in practice, especially when conditioning on\nmultiple variables.\n  We focus on discrete data and propose a new test based on the notion of\nalgorithmic independence that we instantiate using stochastic complexity.\nAmongst others, we show that our proposed test, SCI, is an asymptotically\nunbiased as well as $L_2$ consistent estimator for conditional mutual\ninformation (CMI). Further, we show that SCI can be reformulated to find a\nsensible threshold for CMI that works well on limited samples. Empirical\nevaluation shows that SCI has a lower type II error than commonly used tests.\nAs a result, we obtain a higher recall when we use SCI in causal discovery\nalgorithms, without compromising the precision.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 10:40:42 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Marx", "Alexander", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1903.04841", "submitter": "Thierry Roncalli", "authors": "Joan Gonzalvez, Edmond Lezmi, Thierry Roncalli, Jiali Xu", "title": "Financial Applications of Gaussian Processes and Bayesian Optimization", "comments": "42 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last five years, the financial industry has been impacted by the\nemergence of digitalization and machine learning. In this article, we explore\ntwo methods that have undergone rapid development in recent years: Gaussian\nprocesses and Bayesian optimization. Gaussian processes can be seen as a\ngeneralization of Gaussian random vectors and are associated with the\ndevelopment of kernel methods. Bayesian optimization is an approach for\nperforming derivative-free global optimization in a small dimension, and uses\nGaussian processes to locate the global maximum of a black-box function. The\nfirst part of the article reviews these two tools and shows how they are\nconnected. In particular, we focus on the Gaussian process regression, which is\nthe core of Bayesian machine learning, and the issue of hyperparameter\nselection. The second part is dedicated to two financial applications. We first\nconsider the modeling of the term structure of interest rates. More precisely,\nwe test the fitting method and compare the GP prediction and the random walk\nmodel. The second application is the construction of trend-following\nstrategies, in particular the online estimation of trend and covariance\nwindows.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 11:12:58 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Gonzalvez", "Joan", ""], ["Lezmi", "Edmond", ""], ["Roncalli", "Thierry", ""], ["Xu", "Jiali", ""]]}, {"id": "1903.04860", "submitter": "Jaeyoon Yoo", "authors": "Jaeyoon Yoo, Changhwa Park, Yongjun Hong, Sungroh Yoon", "title": "Learning Condensed and Aligned Features for Unsupervised Domain\n  Adaptation Using Label Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation aiming to learn a specific task for one domain\nusing another domain data has emerged to address the labeling issue in\nsupervised learning, especially because it is difficult to obtain massive\namounts of labeled data in practice. The existing methods have succeeded by\nreducing the difference between the embedded features of both domains, but the\nperformance is still unsatisfactory compared to the supervised learning scheme.\nThis is attributable to the embedded features that lay around each other but do\nnot align perfectly and establish clearly separable clusters. We propose a\nnovel domain adaptation method based on label propagation and cycle consistency\nto let the clusters of the features from the two domains overlap exactly and\nbecome clear for high accuracy. Specifically, we introduce cycle consistency to\nenforce the relationship between each cluster and exploit label propagation to\nachieve the association between the data from the perspective of the manifold\nstructure instead of a one-to-one relation. Hence, we successfully formed\naligned and discriminative clusters. We present the empirical results of our\nmethod for various domain adaptation scenarios and visualize the embedded\nfeatures to prove that our method is critical for better domain adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 12:06:57 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Yoo", "Jaeyoon", ""], ["Park", "Changhwa", ""], ["Hong", "Yongjun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1903.04887", "submitter": "Honghao Wei", "authors": "Honghao Wei, Xiaohan Kang, Weina Wang, Lei Ying", "title": "QuickStop: A Markov Optimal Stopping Approach for Quickest\n  Misinformation Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper combines data-driven and model-driven methods for real-time\nmisinformation detection. Our algorithm, named QuickStop, is an optimal\nstopping algorithm based on a probabilistic information spreading model\nobtained from labeled data. The algorithm consists of an offline machine\nlearning algorithm for learning the probabilistic information spreading model\nand an online optimal stopping algorithm to detect misinformation. The online\ndetection algorithm has both low computational and memory complexities. Our\nnumerical evaluations with a real-world dataset show that QuickStop outperforms\nexisting misinformation detection algorithms in terms of both accuracy and\ndetection time (number of observations needed for detection). Our evaluations\nwith synthetic data further show that QuickStop is robust to (offline) learning\nerrors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 22:23:33 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 20:29:36 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Wei", "Honghao", ""], ["Kang", "Xiaohan", ""], ["Wang", "Weina", ""], ["Ying", "Lei", ""]]}, {"id": "1903.04925", "submitter": "Angana Chakraborty", "authors": "Angana Chakraborty and Sanghamitra Bandyopadhyay", "title": "conLSH: Context based Locality Sensitive Hashing for Mapping of noisy\n  SMRT Reads", "comments": "arXiv admin note: text overlap with arXiv:1705.03933", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single Molecule Real-Time (SMRT) sequencing is a recent advancement of Next\nGen technology developed by Pacific Bio (PacBio). It comes with an explosion of\nlong and noisy reads demanding cutting edge research to get most out of it. To\ndeal with the high error probability of SMRT data, a novel contextual Locality\nSensitive Hashing (conLSH) based algorithm is proposed in this article, which\ncan effectively align the noisy SMRT reads to the reference genome. Here,\nsequences are hashed together based not only on their closeness, but also on\nsimilarity of context. The algorithm has $\\mathcal{O}(n^{\\rho+1})$ space\nrequirement, where $n$ is the number of sequences in the corpus and $\\rho$ is a\nconstant. The indexing time and querying time are bounded by $\\mathcal{O}(\n\\frac{n^{\\rho+1} \\cdot \\ln n}{\\ln \\frac{1}{P_2}})$ and $\\mathcal{O}(n^\\rho)$\nrespectively, where $P_2 > 0$, is a probability value. This algorithm is\nparticularly useful for retrieving similar sequences, a widely used task in\nbiology. The proposed conLSH based aligner is compared with rHAT, popularly\nused for aligning SMRT reads, and is found to comprehensively beat it in speed\nas well as in memory requirements. In particular, it takes approximately\n$24.2\\%$ less processing time, while saving about $70.3\\%$ in peak memory\nrequirement for H.sapiens PacBio dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:49:01 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Chakraborty", "Angana", ""], ["Bandyopadhyay", "Sanghamitra", ""]]}, {"id": "1903.04933", "submitter": "Sander Dieleman", "authors": "Jeffrey De Fauw, Sander Dieleman, Karen Simonyan", "title": "Hierarchical Autoregressive Image Models with Auxiliary Decoders", "comments": "Updated: added human evaluation results, incorporated review feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive generative models of images tend to be biased towards\ncapturing local structure, and as a result they often produce samples which are\nlacking in terms of large-scale coherence. To address this, we propose two\nmethods to learn discrete representations of images which abstract away local\ndetail. We show that autoregressive models conditioned on these representations\ncan produce high-fidelity reconstructions of images, and that we can train\nautoregressive priors on these representations that produce samples with\nlarge-scale coherence. We can recursively apply the learning procedure,\nyielding a hierarchy of progressively more abstract image representations. We\ntrain hierarchical class-conditional autoregressive models on the ImageNet\ndataset and demonstrate that they are able to generate realistic images at\nresolutions of 128$\\times$128 and 256$\\times$256 pixels. We also perform a\nhuman evaluation study comparing our models with both adversarial and\nlikelihood-based state-of-the-art generative models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 22:13:52 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 17:55:59 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["De Fauw", "Jeffrey", ""], ["Dieleman", "Sander", ""], ["Simonyan", "Karen", ""]]}, {"id": "1903.04959", "submitter": "Haotian Fu", "authors": "Haotian Fu, Hongyao Tang, Jianye Hao, Zihan Lei, Yingfeng Chen,\n  Changjie Fan", "title": "Deep Multi-Agent Reinforcement Learning with Discrete-Continuous Hybrid\n  Action Spaces", "comments": null, "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has been applied to address a variety of\ncooperative multi-agent problems with either discrete action spaces or\ncontinuous action spaces. However, to the best of our knowledge, no previous\nwork has ever succeeded in applying DRL to multi-agent problems with\ndiscrete-continuous hybrid (or parameterized) action spaces which is very\ncommon in practice. Our work fills this gap by proposing two novel algorithms:\nDeep Multi-Agent Parameterized Q-Networks (Deep MAPQN) and Deep Multi-Agent\nHierarchical Hybrid Q-Networks (Deep MAHHQN). We follow the centralized\ntraining but decentralized execution paradigm: different levels of\ncommunication between different agents are used to facilitate the training\nprocess, while each agent executes its policy independently based on local\nobservations during execution. Our empirical results on several challenging\ntasks (simulated RoboCup Soccer and game Ghost Story) show that both Deep MAPQN\nand Deep MAHHQN are effective and significantly outperform existing independent\ndeep parameterized Q-learning method.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:40:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fu", "Haotian", ""], ["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Lei", "Zihan", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""]]}, {"id": "1903.04991", "submitter": "Andrzej Banburski", "authors": "Andrzej Banburski, Qianli Liao, Brando Miranda, Lorenzo Rosasco,\n  Fernanda De La Torre, Jack Hidary and Tomaso Poggio", "title": "Theory III: Dynamics and Generalization in Deep Networks", "comments": "47 pages, 11 figures. This replaces previous versions of Theory III,\n  that appeared on Arxiv [arXiv:1806.11379, arXiv:1801.00173] or on the CBMM\n  site. v5: Changes throughout the paper to the presentation and tightening\n  some of the statements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key to generalization is controlling the complexity of the network.\nHowever, there is no obvious control of complexity -- such as an explicit\nregularization term -- in the training of deep networks for classification. We\nwill show that a classical form of norm control -- but kind of hidden -- is\npresent in deep networks trained with gradient descent techniques on\nexponential-type losses. In particular, gradient descent induces a dynamics of\nthe normalized weights which converge for $t \\to \\infty$ to an equilibrium\nwhich corresponds to a minimum norm (or maximum margin) solution. For\nsufficiently large but finite $\\rho$ -- and thus finite $t$ -- the dynamics\nconverges to one of several margin maximizers, with the margin monotonically\nincreasing towards a limit stationary point of the flow. In the usual case of\nstochastic gradient descent, most of the stationary points are likely to be\nconvex minima corresponding to a constrained minimizer -- the network with\nnormalized weights-- which corresponds to vanishing regularization. The\nsolution has zero generalization gap, for fixed architecture, asymptotically\nfor $N \\to \\infty$, where $N$ is the number of training examples. Our approach\nextends some of the original results of Srebro from linear networks to deep\nnetworks and provides a new perspective on the implicit bias of gradient\ndescent. We believe that the elusive complexity control we describe is\nresponsible for the puzzling empirical finding of good predictive performance\nby deep networks, despite overparametrization.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 15:24:26 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 22:38:08 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 02:02:40 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 22:59:20 GMT"}, {"version": "v5", "created": "Sat, 11 Apr 2020 00:21:50 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Banburski", "Andrzej", ""], ["Liao", "Qianli", ""], ["Miranda", "Brando", ""], ["Rosasco", "Lorenzo", ""], ["De La Torre", "Fernanda", ""], ["Hidary", "Jack", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1903.05006", "submitter": "Zengde Deng", "authors": "Zengde Deng, Anthony Man-Cho So", "title": "An Efficient Augmented Lagrangian Based Method for Constrained Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection is one of the most important tasks in statistics and\nmachine learning. To incorporate more prior information about the regression\ncoefficients, the constrained Lasso model has been proposed in the literature.\nIn this paper, we present an inexact augmented Lagrangian method to solve the\nLasso problem with linear equality constraints. By fully exploiting\nsecond-order sparsity of the problem, we are able to greatly reduce the\ncomputational cost and obtain highly efficient implementations. Furthermore,\nnumerical results on both synthetic data and real data show that our algorithm\nis superior to existing first-order methods in terms of both running time and\nsolution accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 15:51:20 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Deng", "Zengde", ""], ["So", "Anthony Man-Cho", ""]]}, {"id": "1903.05054", "submitter": "Yang Tang", "authors": "Michael P. B. Gallaugher and Yang Tang and Paul D. McNicholas", "title": "Flexible Clustering with a Sparse Mixture of Generalized Hyperbolic\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robust clustering of high-dimensional data is an important topic because, in\nmany practical situations, real data sets are heavy-tailed and/or asymmetric.\nMoreover, traditional model-based clustering often fails for high dimensional\ndata due to the number of free covariance parameters. A parametrization of the\ncomponent scale matrices for the mixture of generalized hyperbolic\ndistributions is proposed by including a penalty term in the likelihood\nconstraining the parameters resulting in a flexible model for high dimensional\ndata and a meaningful interpretation. An analytically feasible EM algorithm is\ndeveloped by placing a gamma-Lasso penalty constraining the concentration\nmatrix. The proposed methodology is investigated through simulation studies and\ntwo real data sets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 17:02:40 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Gallaugher", "Michael P. B.", ""], ["Tang", "Yang", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1903.05063", "submitter": "Michael Lingzhi Li", "authors": "Michael Lingzhi Li, Elliott Wolf, Daniel Wintz", "title": "Duration-of-Stay Storage Assignment under Uncertainty", "comments": "15 pages, 4 figures. Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing storage assignment is a central problem in warehousing. Past\nliterature has shown the superiority of the Duration-of-Stay (DoS) method in\nassigning pallets, but the methodology requires perfect prior knowledge of DoS\nfor each pallet, which is unknown and uncertain under realistic conditions. The\ndynamic nature of a warehouse further complicates the validity of synthetic\ndata testing that is often conducted for algorithms. In this paper, in\ncollaboration with a large cold storage company, we release the first publicly\navailable set of warehousing records to facilitate research into this central\nproblem. We introduce a new framework for storage assignment that accounts for\nuncertainty in warehouses. Then, by utilizing a combination of convolutional\nand recurrent neural network models, ParallelNet, we show that it is able to\npredict future shipments well: it achieves up to 29% decrease in MAPE compared\nto CNN-LSTM on unseen future shipments, and suffers less performance decay over\ntime. The framework is then integrated into a first-of-its-kind Storage\nAssignment system, which is being piloted in warehouses across the country,\nwith initial results showing up to 19% in labor savings.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 17:12:07 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 19:27:10 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 01:38:44 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Michael Lingzhi", ""], ["Wolf", "Elliott", ""], ["Wintz", "Daniel", ""]]}, {"id": "1903.05071", "submitter": "Jacob Reinier Maat", "authors": "Jacob Reinier Maat, Nikos Gianniotis, Pavlos Protopapas", "title": "Efficient Optimization of Echo State Networks for Time Series Datasets", "comments": null, "journal-ref": "2018 International Joint Conference on Neural Networks (IJCNN),\n  pp. 1-7. IEEE, 2018", "doi": "10.1109/IJCNN.2018.8489094", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo State Networks (ESNs) are recurrent neural networks that only train\ntheir output layer, thereby precluding the need to backpropagate gradients\nthrough time, which leads to significant computational gains. Nevertheless, a\ncommon issue in ESNs is determining its hyperparameters, which are crucial in\ninstantiating a well performing reservoir, but are often set manually or using\nheuristics. In this work we optimize the ESN hyperparameters using Bayesian\noptimization which, given a limited budget of function evaluations, outperforms\na grid search strategy. In the context of large volumes of time series data,\nsuch as light curves in the field of astronomy, we can further reduce the\noptimization cost of ESNs. In particular, we wish to avoid tuning\nhyperparameters per individual time series as this is costly; instead, we want\nto find ESNs with hyperparameters that perform well not just on individual time\nseries but rather on groups of similar time series without sacrificing\npredictive performance significantly. This naturally leads to a notion of\nclusters, where each cluster is represented by an ESN tuned to model a group of\ntime series of similar temporal behavior. We demonstrate this approach both on\nsynthetic datasets and real world light curves from the MACHO survey. We show\nthat our approach results in a significant reduction in the number of ESN\nmodels required to model a whole dataset, while retaining predictive\nperformance for the series in each cluster.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 17:27:19 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Maat", "Jacob Reinier", ""], ["Gianniotis", "Nikos", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "1903.05083", "submitter": "Rustem Takhanov", "authors": "Rustem Takhanov", "title": "Dimension reduction as an optimization problem over a set of generalized\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical dimension reduction problem can be loosely formulated as a problem\nof finding a $k$-dimensional affine subspace of ${\\mathbb R}^n$ onto which data\npoints ${\\mathbf x}_1,\\cdots, {\\mathbf x}_N$ can be projected without loss of\nvaluable information. We reformulate this problem in the language of tempered\ndistributions, i.e. as a problem of approximating an empirical probability\ndensity function $p_{\\rm{emp}}({\\mathbf x}) = \\frac{1}{N} \\sum_{i=1}^N \\delta^n\n(\\bold{x} - \\bold{x}_i)$, where $\\delta^n$ is an $n$-dimensional Dirac delta\nfunction, by another tempered distribution $q({\\mathbf x})$ whose density is\nsupported in some $k$-dimensional subspace. Thus, our problem is reduced to the\nminimization of a certain loss function $I(q)$ measuring the distance from $q$\nto $p_{\\rm{emp}}$ over a pertinent set of generalized functions, denoted\n$\\mathcal{G}_k$.\n  Another classical problem of data analysis is the sufficient dimension\nreduction problem. We show that it can be reduced to the following problem:\ngiven a function $f: {\\mathbb R}^n\\rightarrow {\\mathbb R}$ and a probability\ndensity function $p({\\mathbf x})$, find a function of the form $g({\\mathbf\nw}^T_1{\\mathbf x}, \\cdots, {\\mathbf w}^T_k{\\mathbf x})$ that minimizes the loss\n${\\mathbb E}_{{\\mathbf x}\\sim p} |f({\\mathbf x})-g({\\mathbf w}^T_1{\\mathbf x},\n\\cdots, {\\mathbf w}^T_k{\\mathbf x})|^2$.\n  We first show that search spaces of the latter two problems are in one-to-one\ncorrespondence which is defined by the Fourier transform. We introduce a\nnonnegative penalty function $R(f)$ and a set of ordinary functions\n$\\Omega_\\epsilon = \\{f| R(f)\\leq \\epsilon\\}$ in such a way that\n$\\Omega_\\epsilon$ `approximates' the space $\\mathcal{G}_k$ when $\\epsilon\n\\rightarrow 0$. Then we present an algorithm for minimization of $I(f)+\\lambda\nR(f)$, based on the idea of two-step iterative computation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:25:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Takhanov", "Rustem", ""]]}, {"id": "1903.05084", "submitter": "Julian Theis", "authors": "Julian Theis and Houshang Darabi", "title": "Decay Replay Mining to Predict Next Process Events", "comments": "Revised manuscript. Github repository added", "journal-ref": "IEEE Access, vol. 7, pp. 119787-119803, 2019", "doi": "10.1109/ACCESS.2019.2937085", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex processes, various events can happen in different sequences. The\nprediction of the next event given an a-priori process state is of importance\nin such processes. Recent methods have proposed deep learning techniques such\nas recurrent neural networks, developed on raw event logs, to predict the next\nevent from a process state. However, such deep learning models by themselves\nlack a clear representation of the process states. At the same time, recent\nmethods have neglected the time feature of event instances. In this paper, we\ntake advantage of Petri nets as a powerful tool in modeling complex process\nbehaviors considering time as an elemental variable. We propose an approach\nwhich starts from a Petri net process model constructed by a process mining\nalgorithm. We enhance the Petri net model with time decay functions to create\ncontinuous process state samples. Finally, we use these samples in combination\nwith discrete token movement counters and Petri net markings to train a deep\nlearning model that predicts the next event. We demonstrate significant\nperformance improvements and outperform the state-of-the-art methods on nine\nreal-world benchmark event logs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:53:10 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 15:04:55 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 20:54:32 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Theis", "Julian", ""], ["Darabi", "Houshang", ""]]}, {"id": "1903.05133", "submitter": "Fan Zhou", "authors": "Fan Zhou and Guojing Cong", "title": "A Distributed Hierarchical SGD Algorithm with Sparse Global Reduction", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing communication in training large-scale machine learning applications\non distributed platform is still a big challenge. To address this issue, we\npropose a distributed hierarchical averaging stochastic gradient descent\n(Hier-AVG) algorithm with infrequent global reduction by introducing local\nreduction. As a general type of parallel SGD, Hier-AVG can reproduce several\npopular synchronous parallel SGD variants by adjusting its parameters. We show\nthat Hier-AVG with infrequent global reduction can still achieve standard\nconvergence rate for non-convex optimization problems. In addition, we show\nthat more frequent local averaging with more participants involved can lead to\nfaster training convergence. By comparing Hier-AVG with another popular\ndistributed training algorithm K-AVG, we show that through deploying local\naveraging with fewer number of global averaging, Hier-AVG can still achieve\ncomparable training speed while frequently get better test accuracy. This\nindicates that local averaging can serve as an alternative remedy to\neffectively reduce communication overhead when the number of learners is large.\nExperimental results of Hier-AVG with several state-of-the-art deep neural nets\non CIFAR-10 and IMAGENET-1K are presented to validate our analysis and show its\nsuperiority.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 18:34:49 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 06:18:49 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Fan", ""], ["Cong", "Guojing", ""]]}, {"id": "1903.05153", "submitter": "Vijil Chenthamarakshan", "authors": "Tian Gao, Jie Chen, Vijil Chenthamarakshan, Michael Witbrock", "title": "A Sequential Set Generation Method for Predicting Set-Valued Outputs", "comments": "Published at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a general machine learning setting where the output is a set of\nlabels or sequences. This output set is unordered and its size varies with the\ninput. Whereas multi-label classification methods seem a natural first resort,\nthey are not readily applicable to set-valued outputs because of the growth\nrate of the output space; and because conventional sequence generation doesn't\nreflect sets' order-free nature. In this paper, we propose a unified\nframework--sequential set generation (SSG)--that can handle output sets of\nlabels and sequences. SSG is a meta-algorithm that leverages any probabilistic\nlearning method for label or sequence prediction, but employs a proper\nregularization such that a new label or sequence is generated repeatedly until\nthe full set is produced. Though SSG is sequential in nature, it does not\npenalize the ordering of the appearance of the set elements and can be applied\nto a variety of set output problems, such as a set of classification labels or\nsequences. We perform experiments with both benchmark and synthetic data sets\nand demonstrate SSG's strong performance over baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:06:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Gao", "Tian", ""], ["Chen", "Jie", ""], ["Chenthamarakshan", "Vijil", ""], ["Witbrock", "Michael", ""]]}, {"id": "1903.05157", "submitter": "Adith Boloor", "authors": "Adith Boloor, Xin He, Christopher Gill, Yevgeniy Vorobeychik, Xuan\n  Zhang", "title": "Simple Physical Adversarial Examples against End-to-End Autonomous\n  Driving Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning, especially techniques such as deep\nneural networks, are promoting a range of high-stakes applications, including\nautonomous driving, which often relies on deep learning for perception. While\ndeep learning for perception has been shown to be vulnerable to a host of\nsubtle adversarial manipulations of images, end-to-end demonstrations of\nsuccessful attacks, which manipulate the physical environment and result in\nphysical consequences, are scarce. Moreover, attacks typically involve\ncarefully constructed adversarial examples at the level of pixels. We\ndemonstrate the first end-to-end attacks on autonomous driving in simulation,\nusing simple physically realizable attacks: the painting of black lines on the\nroad. These attacks target deep neural network models for end-to-end autonomous\ndriving control. A systematic investigation shows that such attacks are\nsurprisingly easy to engineer, and we describe scenarios (e.g., right turns) in\nwhich they are highly effective, and others that are less vulnerable (e.g.,\ndriving straight). Further, we use network deconvolution to demonstrate that\nthe attacks succeed by inducing activation patterns similar to entirely\ndifferent scenarios used in training.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:13:12 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Boloor", "Adith", ""], ["He", "Xin", ""], ["Gill", "Christopher", ""], ["Vorobeychik", "Yevgeniy", ""], ["Zhang", "Xuan", ""]]}, {"id": "1903.05168", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe and Jakob Foerster and Y-Lan Boureau and Joelle Pineau and\n  Yann Dauphin", "title": "On the Pitfalls of Measuring Emergent Communication", "comments": "AAMAS 2019. 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do we know if communication is emerging in a multi-agent system? The vast\nmajority of recent papers on emergent communication show that adding a\ncommunication channel leads to an increase in reward or task success. This is a\nuseful indicator, but provides only a coarse measure of the agent's learned\ncommunication abilities. As we move towards more complex environments, it\nbecomes imperative to have a set of finer tools that allow qualitative and\nquantitative insights into the emergence of communication. This may be\nespecially useful to allow humans to monitor agents' behaviour, whether for\nfault detection, assessing performance, or even building trust. In this paper,\nwe examine a few intuitive existing metrics for measuring communication, and\nshow that they can be misleading. Specifically, by training deep reinforcement\nlearning agents to play simple matrix games augmented with a communication\nchannel, we find a scenario where agents appear to communicate (their messages\nprovide information about their subsequent action), and yet the messages do not\nimpact the environment or other agent in any way. We explain this phenomenon\nusing ablation studies and by visualizing the representations of the learned\npolicies. We also survey some commonly used metrics for measuring emergent\ncommunication, and provide recommendations as to when these metrics should be\nused.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:33:49 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Lowe", "Ryan", ""], ["Foerster", "Jakob", ""], ["Boureau", "Y-Lan", ""], ["Pineau", "Joelle", ""], ["Dauphin", "Yann", ""]]}, {"id": "1903.05174", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Richness of Deep Echo State Network Dynamics", "comments": "Preprint of the paper accepted at IWANN 2019", "journal-ref": null, "doi": "10.1007/978-3-030-20521-8_40", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir Computing (RC) is a popular methodology for the efficient design of\nRecurrent Neural Networks (RNNs). Recently, the advantages of the RC approach\nhave been extended to the context of multi-layered RNNs, with the introduction\nof the Deep Echo State Network (DeepESN) model. In this paper, we study the\nquality of state dynamics in progressively higher layers of DeepESNs, using\ntools from the areas of information theory and numerical analysis. Our\nexperimental results on RC benchmark datasets reveal the fundamental role\nplayed by the strength of inter-reservoir connections to increasingly enrich\nthe representations developed in higher layers. Our analysis also gives\ninteresting insights into the possibility of effective exploitation of training\nalgorithms based on stochastic gradient descent in the RC field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:39:36 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:49:55 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1903.05176", "submitter": "Liam Li", "authors": "Liam Li, Evan Sparks, Kevin Jamieson, Ameet Talwalkar", "title": "Exploiting Reuse in Pipeline-Aware Hyperparameter Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter tuning of multi-stage pipelines introduces a significant\ncomputational burden. Motivated by the observation that work can be reused\nacross pipelines if the intermediate computations are the same, we propose a\npipeline-aware approach to hyperparameter tuning. Our approach optimizes both\nthe design and execution of pipelines to maximize reuse. We design pipelines\namenable for reuse by (i) introducing a novel hybrid hyperparameter tuning\nmethod called gridded random search, and (ii) reducing the average training\ntime in pipelines by adapting early-stopping hyperparameter tuning approaches.\nWe then realize the potential for reuse during execution by introducing a novel\ncaching problem for ML workloads which we pose as a mixed integer linear\nprogram (ILP), and subsequently evaluating various caching heuristics relative\nto the optimal solution of the ILP. We conduct experiments on simulated and\nreal-world machine learning pipelines to show that a pipeline-aware approach to\nhyperparameter tuning can offer over an order-of-magnitude speedup over\nindependently evaluating pipeline configurations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:40:28 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Li", "Liam", ""], ["Sparks", "Evan", ""], ["Jamieson", "Kevin", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1903.05179", "submitter": "Zhengze Zhou", "authors": "Zhengze Zhou, Giles Hooker", "title": "Unbiased Measurement of Feature Importance in Tree-Based Methods", "comments": "add Section 3.4 to compare with other methods for dealing with\n  similar bias; add more simulation results in Section 5; add link to Github\n  repository for code access", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modification that corrects for split-improvement variable\nimportance measures in Random Forests and other tree-based methods. These\nmethods have been shown to be biased towards increasing the importance of\nfeatures with more potential splits. We show that by appropriately\nincorporating split-improvement as measured on out of sample data, this bias\ncan be corrected yielding better summaries and screening tools.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:52:53 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 19:09:03 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Zhou", "Zhengze", ""], ["Hooker", "Giles", ""]]}, {"id": "1903.05196", "submitter": "Karl Mason", "authors": "Karl Mason, Santiago Grijalva", "title": "A Review of Reinforcement Learning for Autonomous Building Energy\n  Management", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of building energy management has received a significant amount of\ninterest in recent years. This area is concerned with combining advancements in\nsensor technologies, communications and advanced control algorithms to optimize\nenergy utilization. Reinforcement learning is one of the most prominent machine\nlearning algorithms used for control problems and has had many successful\napplications in the area of building energy management. This research gives a\ncomprehensive review of the literature relating to the application of\nreinforcement learning to developing autonomous building energy management\nsystems. The main direction for future research and challenges in reinforcement\nlearning are also outlined.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:38:54 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 17:06:11 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Mason", "Karl", ""], ["Grijalva", "Santiago", ""]]}, {"id": "1903.05202", "submitter": "Tom Diethe", "authors": "Tom Diethe, Tom Borchert, Eno Thereska, Borja Balle, Neil Lawrence", "title": "Continual Learning in Practice", "comments": "Presented at the NeurIPS 2018 workshop on Continual Learning\n  https://sites.google.com/view/continual2018/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a reference architecture for self-maintaining systems\nthat can learn continually, as data arrives. In environments where data\nevolves, we need architectures that manage Machine Learning (ML) models in\nproduction, adapt to shifting data distributions, cope with outliers, retrain\nwhen necessary, and adapt to new tasks. This represents continual AutoML or\nAutomatically Adaptive Machine Learning. We describe the challenges and\nproposes a reference architecture.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:41:36 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 14:44:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Diethe", "Tom", ""], ["Borchert", "Tom", ""], ["Thereska", "Eno", ""], ["Balle", "Borja", ""], ["Lawrence", "Neil", ""]]}, {"id": "1903.05216", "submitter": "Daan Wout", "authors": "Daan Wout, Jan Scholten, Carlos Celemin, Jens Kober", "title": "Learning Gaussian Policies from Corrective Human Feedback", "comments": "Submitted to the Uncertainty in Artificial Intelligence (UAI)\n  Conference of 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from human feedback is a viable alternative to control design that\ndoes not require modelling or control expertise. Particularly, learning from\ncorrective advice garners advantages over evaluative feedback as it is a more\nintuitive and scalable format. The current state-of-the-art in this field,\nCOACH, has proven to be a effective approach for confined problems. However, it\nparameterizes the policy with Radial Basis Function networks, which require\nmeticulous feature space engineering for higher order systems. We introduce\nGaussian Process Coach (GPC), where feature space engineering is avoided by\nemploying Gaussian Processes. In addition, we use the available policy\nuncertainty to 1) inquire feedback samples of maximal utility and 2) to adapt\nthe learning rate to the teacher's learning phase. We demonstrate that the\nnovel algorithm outperforms the current state-of-the-art in final performance,\nconvergence rate and robustness to erroneous feedback in OpenAI Gym continuous\ncontrol benchmarks, both for simulated and real human teachers.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 21:10:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wout", "Daan", ""], ["Scholten", "Jan", ""], ["Celemin", "Carlos", ""], ["Kober", "Jens", ""]]}, {"id": "1903.05219", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Confident Kernel Sparse Coding and Dictionary Learning", "comments": "10 pages, ICDM 2018 conference", "journal-ref": null, "doi": "10.1109/ICDM.2018.00130", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, kernel-based sparse coding (K-SRC) has received particular\nattention due to its efficient representation of nonlinear data structures in\nthe feature space. Nevertheless, the existing K-SRC methods suffer from the\nlack of consistency between their training and test optimization frameworks. In\nthis work, we propose a novel confident K-SRC and dictionary learning algorithm\n(CKSC) which focuses on the discriminative reconstruction of the data based on\nits representation in the kernel space. CKSC focuses on reconstructing each\ndata sample via weighted contributions which are confident in its corresponding\nclass of data. We employ novel discriminative terms to apply this scheme to\nboth training and test frameworks in our algorithm. This specific design\nincreases the consistency of these optimization frameworks and improves the\ndiscriminative performance in the recall phase. In addition, CKSC directly\nemploys the supervised information in its dictionary learning framework to\nenhance the discriminative structure of the dictionary. For empirical\nevaluations, we implement our CKSC algorithm on multivariate time-series\nbenchmarks such as DynTex++ and UTKinect. Our claims regarding the superior\nperformance of the proposed algorithm are justified throughout comparing its\nclassification results to the state-of-the-art K-SRC algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 21:15:51 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.05239", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Non-Negative Local Sparse Coding for Subspace Clustering", "comments": "15 pages, IDA 2018 conference", "journal-ref": null, "doi": "10.1007/978-3-030-01768-2_12", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace sparse coding (SSC) algorithms have proven to be beneficial to\nclustering problems. They provide an alternative data representation in which\nthe underlying structure of the clusters can be better captured. However, most\nof the research in this area is mainly focused on enhancing the sparse coding\npart of the problem. In contrast, we introduce a novel objective term in our\nproposed SSC framework which focuses on the separability of data points in the\ncoding space. We also provide mathematical insights into how this\nlocal-separability term improves the clustering result of the SSC framework.\nOur proposed non-linear local SSC algorithm (NLSSC) also benefits from the\nefficient choice of its sparsity terms and constraints. The NLSSC algorithm is\nalso formulated in the kernel-based framework (NLKSSC) which can represent the\nnonlinear structure of data. In addition, we address the possibility of having\nredundancies in sparse coding results and its negative effect on graph-based\nclustering problems. We introduce the link-restore post-processing step to\nimprove the representation graph of non-negative SSC algorithms such as ours.\nEmpirical evaluations on well-known clustering benchmarks show that our\nproposed NLSSC framework results in better clusterings compared to the\nstate-of-the-art baselines and demonstrate the effectiveness of the\nlink-restore post-processing in improving the clustering accuracy via\ncorrecting the broken links of the representation graph.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 22:20:10 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.05257", "submitter": "Hassan Muhammad", "authors": "Hassan Muhammad, Carlie S. Sigel, Gabriele Campanella, Thomas Boerner,\n  Linda M. Pak, Stefan B\\\"uttner, Jan N.M. IJzermans, Bas Groot Koerkamp,\n  Michael Doukas, William R. Jarnagin, Amber Simpson, Thomas J. Fuchs", "title": "Towards Unsupervised Cancer Subtyping: Predicting Prognosis Using A\n  Histologic Visual Dictionary", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike common cancers, such as those of the prostate and breast, tumor\ngrading in rare cancers is difficult and largely undefined because of small\nsample sizes, the sheer volume of time needed to undertake on such a task, and\nthe inherent difficulty of extracting human-observed patterns. One of the most\nchallenging examples is intrahepatic cholangiocarcinoma (ICC), a primary liver\ncancer arising from the biliary system, for which there is well-recognized\ntumor heterogeneity and no grading paradigm or prognostic biomarkers. In this\npaper, we propose a new unsupervised deep convolutional autoencoder-based\nclustering model that groups together cellular and structural morphologies of\ntumor in 246 ICC digitized whole slides, based on visual similarity. From this\nvisual dictionary of histologic patterns, we use the clusters as covariates to\ntrain Cox-proportional hazard survival models. In univariate analysis, three\nclusters were significantly associated with recurrence-free survival.\nCombinations of these clusters were significant in multivariate analysis. In a\nmultivariate analysis of all clusters, five showed significance to\nrecurrence-free survival, however the overall model was not measured to be\nsignificant. Finally, a pathologist assigned clinical terminology to the\nsignificant clusters in the visual dictionary and found evidence supporting the\nhypothesis that collagen-enriched fibrosis plays a role in disease severity.\nThese results offer insight into the future of cancer subtyping and show that\ncomputational pathology can contribute to disease prognostication, especially\nin rare cancers.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 23:24:23 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Muhammad", "Hassan", ""], ["Sigel", "Carlie S.", ""], ["Campanella", "Gabriele", ""], ["Boerner", "Thomas", ""], ["Pak", "Linda M.", ""], ["B\u00fcttner", "Stefan", ""], ["IJzermans", "Jan N. M.", ""], ["Koerkamp", "Bas Groot", ""], ["Doukas", "Michael", ""], ["Jarnagin", "William R.", ""], ["Simpson", "Amber", ""], ["Fuchs", "Thomas J.", ""]]}, {"id": "1903.05263", "submitter": "Hugo Jair  Escalante", "authors": "Hugo Jair Escalante, Wei-Wei Tu, Isabelle Guyon, Daniel L. Silver,\n  Evelyne Viegas, Yuqiang Chen, Wenyuan Dai, Qiang Yang", "title": "AutoML @ NeurIPS 2018 challenge: Design and Results", "comments": "Preprint submitted to NeurIPS2018 Volume of Springer Series on\n  Challenges in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We organized a competition on Autonomous Lifelong Machine Learning with Drift\nthat was part of the competition program of NeurIPS 2018. This data driven\ncompetition asked participants to develop computer programs capable of solving\nsupervised learning problems where the i.i.d. assumption did not hold. Large\ndata sets were arranged in a lifelong learning and evaluation scenario and\nCodaLab was used as the challenge platform. The challenge attracted more than\n300 participants in its two month duration. This chapter describes the design\nof the challenge and summarizes its main results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 23:43:59 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 03:02:38 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Escalante", "Hugo Jair", ""], ["Tu", "Wei-Wei", ""], ["Guyon", "Isabelle", ""], ["Silver", "Daniel L.", ""], ["Viegas", "Evelyne", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Yang", "Qiang", ""]]}, {"id": "1903.05271", "submitter": "Minsung Hyun", "authors": "Junyoung Choi, Minsung Hyun, Nojun Kwak", "title": "Task-oriented Design through Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new low-cost machine-learning-based methodology which assists\ndesigners in reducing the gap between the problem and the solution in the\ndesign process. Our work applies reinforcement learning (RL) to find the\noptimal task-oriented design solution through the construction of the design\naction for each task. For this task-oriented design, the 3D design process in\nproduct design is assigned to an action space in Deep RL, and the desired 3D\nmodel is obtained by training each design action according to the task. By\nshowing that this method achieves satisfactory design even when applied to a\ntask pursuing multiple goals, we suggest the direction of how machine learning\ncan contribute to the design process. Also, we have validated with product\ndesigners that this methodology can assist the creative part in the process of\ndesign.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 00:49:01 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Choi", "Junyoung", ""], ["Hyun", "Minsung", ""], ["Kwak", "Nojun", ""]]}, {"id": "1903.05284", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Mingzhang Yin, Mingyuan Zhou", "title": "Augment-Reinforce-Merge Policy Gradient for Binary Stochastic Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high variance of policy gradients, on-policy optimization\nalgorithms are plagued with low sample efficiency. In this work, we propose\nAugment-Reinforce-Merge (ARM) policy gradient estimator as an unbiased\nlow-variance alternative to previous baseline estimators on tasks with binary\naction space, inspired by the recent ARM gradient estimator for discrete random\nvariable models. We show that the ARM policy gradient estimator achieves\nvariance reduction with theoretical guarantees, and leads to significantly more\nstable and faster convergence of policies parameterized by neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 01:43:50 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Tang", "Yunhao", ""], ["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1903.05312", "submitter": "Masato Ishii", "authors": "Masato Ishii, Takashi Takenouchi, and Masashi Sugiyama", "title": "Zero-shot Domain Adaptation Based on Attribute Information", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel domain adaptation method that can be\napplied without target data. We consider the situation where domain shift is\ncaused by a prior change of a specific factor and assume that we know how the\nprior changes between source and target domains. We call this factor an\nattribute, and reformulate the domain adaptation problem to utilize the\nattribute prior instead of target data. In our method, the source data are\nreweighted with the sample-wise weight estimated by the attribute prior and the\ndata themselves so that they are useful in the target domain. We theoretically\nreveal that our method provides more precise estimation of sample-wise\ntransferability than a straightforward attribute-based reweighting approach.\nExperimental results with both toy datasets and benchmark datasets show that\nour method can perform well, though it does not use any target data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 04:50:56 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Ishii", "Masato", ""], ["Takenouchi", "Takashi", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1903.05347", "submitter": "Robi Bhattacharjee", "authors": "Robi Bhattacharjee and Sanjoy Dasgupta", "title": "What relations are reliably embeddable in Euclidean space?", "comments": "Published at ALT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of embedding a relation, represented as a directed\ngraph, into Euclidean space. For three types of embeddings motivated by the\nrecent literature on knowledge graphs, we obtain characterizations of which\nrelations they are able to capture, as well as bounds on the minimal\ndimensionality and precision needed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 07:54:58 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 23:19:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bhattacharjee", "Robi", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "1903.05379", "submitter": "Daniele Ancora", "authors": "Daniele Ancora and Luca Leuzzi", "title": "Transmission Matrix Inference via Pseudolikelihood Decimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG eess.IV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges in the field of biomedical imaging is the\ncomprehension and the exploitation of the photon scattering through disordered\nmedia. Many studies have pursued the solution to this puzzle, achieving\nlight-focusing control or reconstructing images in complex media. In the\npresent work, we investigate how statistical inference helps the calculation of\nthe transmission matrix in a complex scrambling environment, enabling its usage\nlike a normal optical element. We convert a linear input-output transmission\nproblem into a statistical formulation based on pseudolikelihood maximization,\nlearning the coupling matrix via random sampling of intensity realizations. Our\naim is to uncover insights from the scattering problem, encouraging the\ndevelopment of novel imaging techniques for better medical investigations,\nborrowing a number of statistical tools from spin-glass theory.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:43:22 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ancora", "Daniele", ""], ["Leuzzi", "Luca", ""]]}, {"id": "1903.05382", "submitter": "Lior Rokach", "authors": "Eran Fainman, Bracha Shapira, Lior Rokach, Yisroel Mirsky", "title": "Online Budgeted Learning for Classifier Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world machine learning applications, there is a cost associated with\nsampling of different features. Budgeted learning can be used to select which\nfeature-values to acquire from each instance in a dataset, such that the best\nmodel is induced under a given constraint. However, this approach is not\npossible in the domain of online learning since one may not retroactively\nacquire feature-values from past instances. In online learning, the challenge\nis to find the optimum set of features to be acquired from each instance upon\narrival from a data stream. In this paper we introduce the issue of online\nbudgeted learning and describe a general framework for addressing this\nchallenge. We propose two types of feature value acquisition policies based on\nthe multi-armed bandit problem: random and adaptive. Adaptive policies perform\nonline adjustments according to new information coming from a data stream,\nwhile random policies are not sensitive to the information that arrives from\nthe data stream. Our comparative study on five real-world datasets indicates\nthat adaptive policies outperform random policies for most budget limitations\nand datasets. Furthermore, we found that in some cases adaptive policies\nachieve near-optimal results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:51:33 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Fainman", "Eran", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""], ["Mirsky", "Yisroel", ""]]}, {"id": "1903.05457", "submitter": "Karim Abou-Moustafa", "authors": "Karim Abou-Moustafa and Csaba Szepesvari", "title": "An Exponential Efron-Stein Inequality for Lq Stable Learning Rules", "comments": "Additional text and appendices that were not included in the PMLR\n  (ALT'19) proceedings are now included in this version", "journal-ref": "PMLR Vol. 98, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is accumulating evidence in the literature that stability of learning\nalgorithms is a key characteristic that permits a learning algorithm to\ngeneralize. Despite various insightful results in this direction, there seems\nto be an overlooked dichotomy in the type of stability-based generalization\nbounds we have in the literature. On one hand, the literature seems to suggest\nthat exponential generalization bounds for the estimated risk, which are\noptimal, can be only obtained through stringent, distribution independent and\ncomputationally intractable notions of stability such as uniform stability. On\nthe other hand, it seems that weaker notions of stability such as hypothesis\nstability, although it is distribution dependent and more amenable to\ncomputation, can only yield polynomial generalization bounds for the estimated\nrisk, which are suboptimal.\n  In this paper, we address the gap between these two regimes of results. In\nparticular, the main question we address here is \\emph{whether it is possible\nto derive exponential generalization bounds for the estimated risk using a\nnotion of stability that is computationally tractable and distribution\ndependent, but weaker than uniform stability. Using recent advances in\nconcentration inequalities, and using a notion of stability that is weaker than\nuniform stability but distribution dependent and amenable to computation, we\nderive an exponential tail bound for the concentration of the estimated risk of\na hypothesis returned by a general learning rule, where the estimated risk is\nexpressed in terms of either the resubstitution estimate (empirical error), or\nthe deleted (or, leave-one-out) estimate. As an illustration, we derive\nexponential tail bounds for ridge regression with unbounded responses, where we\nshow how stability changes with the tail behavior of the response variables.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 02:33:02 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 22:50:39 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Abou-Moustafa", "Karim", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1903.05480", "submitter": "Adam Foster", "authors": "Adam Foster, Martin Jankowiak, Eli Bingham, Paul Horsfall, Yee Whye\n  Teh, Tom Rainforth, Noah Goodman", "title": "Variational Bayesian Optimal Experimental Design", "comments": "Published as a conference paper at the Thirty-third Conference on\n  Neural Information Processing Systems, Vancouver 2019.\n  https://papers.nips.cc/paper/9553-variational-bayesian-optimal-experimental-design.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimal experimental design (BOED) is a principled framework for\nmaking efficient use of limited experimental resources. Unfortunately, its\napplicability is hampered by the difficulty of obtaining accurate estimates of\nthe expected information gain (EIG) of an experiment. To address this, we\nintroduce several classes of fast EIG estimators by building on ideas from\namortized variational inference. We show theoretically and empirically that\nthese estimators can provide significant gains in speed and accuracy over\nprevious approaches. We further demonstrate the practicality of our approach on\na number of end-to-end experiments.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 13:34:13 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:39:15 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 14:49:02 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Foster", "Adam", ""], ["Jankowiak", "Martin", ""], ["Bingham", "Eli", ""], ["Horsfall", "Paul", ""], ["Teh", "Yee Whye", ""], ["Rainforth", "Tom", ""], ["Goodman", "Noah", ""]]}, {"id": "1903.05499", "submitter": "Frank Schneider", "authors": "Frank Schneider, Lukas Balles and Philipp Hennig", "title": "DeepOBS: A Deep Learning Optimizer Benchmark Suite", "comments": "Accepted at ICLR 2019. 9 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because the choice and tuning of the optimizer affects the speed, and\nultimately the performance of deep learning, there is significant past and\nrecent research in this area. Yet, perhaps surprisingly, there is no generally\nagreed-upon protocol for the quantitative and reproducible evaluation of\noptimization strategies for deep learning. We suggest routines and benchmarks\nfor stochastic optimization, with special focus on the unique aspects of deep\nlearning, such as stochasticity, tunability and generalization. As the primary\ncontribution, we present DeepOBS, a Python package of deep learning\noptimization benchmarks. The package addresses key challenges in the\nquantitative assessment of stochastic optimizers, and automates most steps of\nbenchmarking. The library includes a wide and extensible set of ready-to-use\nrealistic optimization problems, such as training Residual Networks for image\nclassification on ImageNet or character-level language prediction models, as\nwell as popular classics like MNIST and CIFAR-10. The package also provides\nrealistic baseline results for the most popular optimizers on these test\nproblems, ensuring a fair comparison to the competition when benchmarking new\noptimizers, and without having to run costly experiments. It comes with output\nback-ends that directly produce LaTeX code for inclusion in academic\npublications. It supports TensorFlow and is available open source.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 14:05:31 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Schneider", "Frank", ""], ["Balles", "Lukas", ""], ["Hennig", "Philipp", ""]]}, {"id": "1903.05501", "submitter": "Hiroshi Kuwajima", "authors": "Hiroshi Kuwajima, Masayuki Tanaka, Masatoshi Okutomi", "title": "Improving Transparency of Deep Neural Inference Process", "comments": "11 pages, 14 figures, 1 table. This is a pre-print of an article\n  accepted in \"Progress in Artificial Intelligence\" on 26 Feb 2019. The final\n  authenticated version will be available online soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques are rapidly advanced recently, and becoming a\nnecessity component for widespread systems. However, the inference process of\ndeep learning is black-box, and not very suitable to safety-critical systems\nwhich must exhibit high transparency. In this paper, to address this black-box\nlimitation, we develop a simple analysis method which consists of 1) structural\nfeature analysis: lists of the features contributing to inference process, 2)\nlinguistic feature analysis: lists of the natural language labels describing\nthe visual attributes for each feature contributing to inference process, and\n3) consistency analysis: measuring consistency among input data, inference\n(label), and the result of our structural and linguistic feature analysis. Our\nanalysis is simplified to reflect the actual inference process for high\ntransparency, whereas it does not include any additional black-box mechanisms\nsuch as LSTM for highly human readable results. We conduct experiments and\ndiscuss the results of our analysis qualitatively and quantitatively, and come\nto believe that our work improves the transparency of neural networks.\nEvaluated through 12,800 human tasks, 75% workers answer that input data and\nresult of our feature analysis are consistent, and 70% workers answer that\ninference (label) and result of our feature analysis are consistent. In\naddition to the evaluation of the proposed analysis, we find that our analysis\nalso provide suggestions, or possible next actions such as expanding neural\nnetwork complexity or collecting training data to improve a neural network.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 14:11:44 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kuwajima", "Hiroshi", ""], ["Tanaka", "Masayuki", ""], ["Okutomi", "Masatoshi", ""]]}, {"id": "1903.05535", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni", "title": "Predicting class-imbalanced business risk using resampling,\n  regularization, and model ensembling algorithms", "comments": null, "journal-ref": "International Journal of Managing Information Technology (IJIMIT)\n  Vol. 11, No. 1, Februray 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at developing and improving the imbalanced business risk modeling via\njointly using proper evaluation criteria, resampling, cross-validation,\nclassifier regularization, and ensembling techniques. Area Under the Receiver\nOperating Characteristic Curve (AUC of ROC) is used for model comparison based\non 10-fold cross validation. Two undersampling strategies including random\nundersampling (RUS) and cluster centroid undersampling (CCUS), as well as two\noversampling methods including random oversampling (ROS) and Synthetic Minority\nOversampling Technique (SMOTE), are applied. Three highly interpretable\nclassifiers, including logistic regression without regularization (LR),\nL1-regularized LR (L1LR), and decision tree (DT) are implemented. Two\nensembling techniques, including Bagging and Boosting, are applied on the DT\nclassifier for further model improvement. The results show that, Boosting on DT\nby using the oversampled data containing 50% positives via SMOTE is the optimal\nmodel and it can achieve AUC, recall, and F1 score valued 0.8633, 0.9260, and\n0.8907, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 15:07:35 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""]]}, {"id": "1903.05587", "submitter": "Valerio Perrone", "authors": "Valerio Perrone, Marco Palma, Simon Hengchen, Alessandro Vatri, Jim Q.\n  Smith, Barbara McGillivray", "title": "GASC: Genre-Aware Semantic Change for Ancient Greek", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-4707", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word meaning changes over time, depending on linguistic and extra-linguistic\nfactors. Associating a word's correct meaning in its historical context is a\ncentral challenge in diachronic research, and is relevant to a range of NLP\ntasks, including information retrieval and semantic search in historical texts.\nBayesian models for semantic change have emerged as a powerful tool to address\nthis challenge, providing explicit and interpretable representations of\nsemantic change phenomena. However, while corpora typically come with rich\nmetadata, existing models are limited by their inability to exploit contextual\ninformation (such as text genre) beyond the document time-stamp. This is\nparticularly critical in the case of ancient languages, where lack of data and\nlong diachronic span make it harder to draw a clear distinction between\npolysemy (the fact that a word has several senses) and semantic change (the\nprocess of acquiring, losing, or changing senses), and current systems perform\npoorly on these languages. We develop GASC, a dynamic semantic change model\nthat leverages categorical metadata about the texts' genre to boost inference\nand uncover the evolution of meanings in Ancient Greek corpora. In a new\nevaluation framework, our model achieves improved predictive performance\ncompared to the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 17:32:51 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 12:48:56 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Perrone", "Valerio", ""], ["Palma", "Marco", ""], ["Hengchen", "Simon", ""], ["Vatri", "Alessandro", ""], ["Smith", "Jim Q.", ""], ["McGillivray", "Barbara", ""]]}, {"id": "1903.05594", "submitter": "Daniele Calandriello", "authors": "Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, Michal\n  Valko, Lorenzo Rosasco", "title": "Gaussian Process Optimization with Adaptive Sketching: Scalable and No\n  Regret", "comments": "Accepted at COLT 2019. Corrected typos and improved comparison with\n  existing methods", "journal-ref": "Proceedings of Machine Learning Research vol, 99, (COLT 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) are a well studied Bayesian approach for the\noptimization of black-box functions. Despite their effectiveness in simple\nproblems, GP-based algorithms hardly scale to high-dimensional functions, as\ntheir per-iteration time and space cost is at least quadratic in the number of\ndimensions $d$ and iterations $t$. Given a set of $A$ alternatives to choose\nfrom, the overall runtime $O(t^3A)$ is prohibitive. In this paper we introduce\nBKB (budgeted kernelized bandit), a new approximate GP algorithm for\noptimization under bandit feedback that achieves near-optimal regret (and hence\nnear-optimal convergence rate) with near-constant per-iteration complexity and\nremarkably no assumption on the input space or covariance of the GP.\n  We combine a kernelized linear bandit algorithm (GP-UCB) with randomized\nmatrix sketching based on leverage score sampling, and we prove that randomly\nsampling inducing points based on their posterior variance gives an accurate\nlow-rank approximation of the GP, preserving variance estimates and confidence\nintervals. As a consequence, BKB does not suffer from variance starvation, an\nimportant problem faced by many previous sparse GP approximations. Moreover, we\nshow that our procedure selects at most $\\tilde{O}(d_{eff})$ points, where\n$d_{eff}$ is the effective dimension of the explored space, which is typically\nmuch smaller than both $d$ and $t$. This greatly reduces the dimensionality of\nthe problem, thus leading to a $O(TAd_{eff}^2)$ runtime and $O(A d_{eff})$\nspace complexity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 16:50:40 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 16:20:21 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Calandriello", "Daniele", ""], ["Carratino", "Luigi", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1903.05631", "submitter": "Haoteng Yin", "authors": "Bing Yu, Haoteng Yin, Zhanxing Zhu", "title": "ST-UNet: A Spatio-Temporal U-Network for Graph-structured Time Series\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatio-temporal graph learning is becoming an increasingly important\nobject of graph study. Many application domains involve highly dynamic graphs\nwhere temporal information is crucial, e.g. traffic networks and financial\ntransaction graphs. Despite the constant progress made on learning structured\ndata, there is still a lack of effective means to extract dynamic complex\nfeatures from spatio-temporal structures. Particularly, conventional models\nsuch as convolutional networks or recurrent neural networks are incapable of\nrevealing the temporal patterns in short or long terms and exploring the\nspatial properties in local or global scope from spatio-temporal graphs\nsimultaneously. To tackle this problem, we design a novel multi-scale\narchitecture, Spatio-Temporal U-Net (ST-UNet), for graph-structured time series\nmodeling. In this U-shaped network, a paired sampling operation is proposed in\nspacetime domain accordingly: the pooling (ST-Pool) coarsens the input graph in\nspatial from its deterministic partition while abstracts multi-resolution\ntemporal dependencies through dilated recurrent skip connections; based on\nprevious settings in the downsampling, the unpooling (ST-Unpool) restores the\noriginal structure of spatio-temporal graphs and resumes regular intervals\nwithin graph sequences. Experiments on spatio-temporal prediction tasks\ndemonstrate that our model effectively captures comprehensive features in\nmultiple scales and achieves substantial improvements over mainstream methods\non several real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 17:57:12 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 15:51:25 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yu", "Bing", ""], ["Yin", "Haoteng", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1903.05662", "submitter": "Penghang Yin", "authors": "Penghang Yin, Jiancheng Lyu, Shuai Zhang, Stanley Osher, Yingyong Qi,\n  Jack Xin", "title": "Understanding Straight-Through Estimator in Training Activation\n  Quantized Neural Nets", "comments": "in International Conference on Learning Representations (ICLR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training activation quantized neural networks involves minimizing a piecewise\nconstant function whose gradient vanishes almost everywhere, which is\nundesirable for the standard back-propagation or chain rule. An empirical way\naround this issue is to use a straight-through estimator (STE) (Bengio et al.,\n2013) in the backward pass only, so that the \"gradient\" through the modified\nchain rule becomes non-trivial. Since this unusual \"gradient\" is certainly not\nthe gradient of loss function, the following question arises: why searching in\nits negative direction minimizes the training loss? In this paper, we provide\nthe theoretical justification of the concept of STE by answering this question.\nWe consider the problem of learning a two-linear-layer network with binarized\nReLU activation and Gaussian input data. We shall refer to the unusual\n\"gradient\" given by the STE-modifed chain rule as coarse gradient. The choice\nof STE is not unique. We prove that if the STE is properly chosen, the expected\ncoarse gradient correlates positively with the population gradient (not\navailable for the training), and its negation is a descent direction for\nminimizing the population loss. We further show the associated coarse gradient\ndescent algorithm converges to a critical point of the population loss\nminimization problem. Moreover, we show that a poor choice of STE leads to\ninstability of the training algorithm near certain local minima, which is\nverified with CIFAR-10 experiments.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 18:23:43 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 07:20:39 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 23:51:01 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 14:33:44 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Yin", "Penghang", ""], ["Lyu", "Jiancheng", ""], ["Zhang", "Shuai", ""], ["Osher", "Stanley", ""], ["Qi", "Yingyong", ""], ["Xin", "Jack", ""]]}, {"id": "1903.05675", "submitter": "Mahdieh Zabihimayvan", "authors": "Mahdieh Zabihimayvan, Derek Doran", "title": "Fuzzy Rough Set Feature Selection to Enhance Phishing Attack Detection", "comments": "Preprint of accepted paper in IEEE International Conference on Fuzzy\n  Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing as one of the most well-known cybercrime activities is a deception\nof online users to steal their personal or confidential information by\nimpersonating a legitimate website. Several machine learning-based strategies\nhave been proposed to detect phishing websites. These techniques are dependent\non the features extracted from the website samples. However, few studies have\nactually considered efficient feature selection for detecting phishing attacks.\nIn this work, we investigate an agreement on the definitive features which\nshould be used in phishing detection. We apply Fuzzy Rough Set (FRS) theory as\na tool to select most effective features from three benchmarked data sets. The\nselected features are fed into three often used classifiers for phishing\ndetection. To evaluate the FRS feature selection in developing a generalizable\nphishing detection, the classifiers are trained by a separate out-of-sample\ndata set of 14,000 website samples. The maximum F-measure gained by FRS feature\nselection is 95% using Random Forest classification. Also, there are 9\nuniversal features selected by FRS over all the three data sets. The F-measure\nvalue using this universal feature set is approximately 93% which is a\ncomparable result in contrast to the FRS performance. Since the universal\nfeature set contains no features from third-part services, this finding implies\nthat with no inquiry from external sources, we can gain a faster phishing\ndetection which is also robust toward zero-day attacks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 18:48:52 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Zabihimayvan", "Mahdieh", ""], ["Doran", "Derek", ""]]}, {"id": "1903.05700", "submitter": "Ethan Rudd", "authors": "Ethan M. Rudd, Felipe N. Ducau, Cody Wild, Konstantin Berlin, and\n  Richard Harang", "title": "ALOHA: Auxiliary Loss Optimization for Hypothesis Augmentation", "comments": "Pre-print of a manuscript submitted to Usenix Security Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware detection is a popular application of Machine Learning for\nInformation Security (ML-Sec), in which an ML classifier is trained to predict\nwhether a given file is malware or benignware. Parameters of this classifier\nare typically optimized such that outputs from the model over a set of input\nsamples most closely match the samples' true malicious/benign (1/0) target\nlabels. However, there are often a number of other sources of contextual\nmetadata for each malware sample, beyond an aggregate malicious/benign label,\nincluding multiple labeling sources and malware type information (e.g.,\nransomware, trojan, etc.), which we can feed to the classifier as auxiliary\nprediction targets. In this work, we fit deep neural networks to multiple\nadditional targets derived from metadata in a threat intelligence feed for\nPortable Executable (PE) malware and benignware, including a multi-source\nmalicious/benign loss, a count loss on multi-source detections, and a semantic\nmalware attribute tag loss. We find that incorporating multiple auxiliary loss\nterms yields a marked improvement in performance on the main detection task. We\nalso demonstrate that these gains likely stem from a more informed neural\nnetwork representation and are not due to a regularization artifact of\nmulti-target learning. Our auxiliary loss architecture yields a significant\nreduction in detection error rate (false negatives) of 42.6% at a false\npositive rate (FPR) of $10^{-3}$ when compared to a similar model with only one\ntarget, and a decrease of 53.8% at $10^{-5}$ FPR.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 19:56:04 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Rudd", "Ethan M.", ""], ["Ducau", "Felipe N.", ""], ["Wild", "Cody", ""], ["Berlin", "Konstantin", ""], ["Harang", "Richard", ""]]}, {"id": "1903.05726", "submitter": "Guanyang Wang", "authors": "Guanyang Wang", "title": "A Multi-armed Bandit MCMC, with applications in sampling from doubly\n  intractable posterior", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI physics.data-an stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) algorithms are widely used to sample from\ncomplicated distributions, especially to sample from the posterior distribution\nin Bayesian inference. However, MCMC is not directly applicable when facing the\ndoubly intractable problem. In this paper, we discussed and compared two\nexisting solutions -- Pseudo-marginal Monte Carlo and Exchange Algorithm. This\npaper also proposes a novel algorithm: Multi-armed Bandit MCMC (MABMC), which\nchooses between two (or more) randomized acceptance ratios in each step. MABMC\ncould be applied directly to incorporate Pseudo-marginal Monte Carlo and\nExchange algorithm, with higher average acceptance probability.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 21:38:48 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 20:39:01 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Wang", "Guanyang", ""]]}, {"id": "1903.05751", "submitter": "Kei Ota", "authors": "Kei Ota, Devesh K. Jha, Tomoaki Oiki, Mamoru Miura, Takashi Nammoto,\n  Daniel Nikovski, and Toshisada Mariyama", "title": "Trajectory Optimization for Unknown Constrained Systems using\n  Reinforcement Learning", "comments": "8 pages, 6 figures, Accepted to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a reinforcement learning-based algorithm for\ntrajectory optimization for constrained dynamical systems. This problem is\nmotivated by the fact that for most robotic systems, the dynamics may not\nalways be known. Generating smooth, dynamically feasible trajectories could be\ndifficult for such systems. Using sampling-based algorithms for motion planning\nmay result in trajectories that are prone to undesirable control jumps.\nHowever, they can usually provide a good reference trajectory which a\nmodel-free reinforcement learning algorithm can then exploit by limiting the\nsearch domain and quickly finding a dynamically smooth trajectory. We use this\nidea to train a reinforcement learning agent to learn a dynamically smooth\ntrajectory in a curriculum learning setting. Furthermore, for generalization,\nwe parameterize the policies with goal locations, so that the agent can be\ntrained for multiple goals simultaneously. We show result in both simulated\nenvironments as well as real experiments, for a $6$-DoF manipulator arm\noperated in position-controlled mode to validate the proposed idea. We compare\nthe proposed ideas against a PID controller which is used to track a designed\ntrajectory in configuration space. Our experiments show that our RL agent\ntrained with a reference path outperformed a model-free PID controller of the\ntype commonly used on many robotic platforms for trajectory tracking.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 23:07:29 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:24:14 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Ota", "Kei", ""], ["Jha", "Devesh K.", ""], ["Oiki", "Tomoaki", ""], ["Miura", "Mamoru", ""], ["Nammoto", "Takashi", ""], ["Nikovski", "Daniel", ""], ["Mariyama", "Toshisada", ""]]}, {"id": "1903.05769", "submitter": "Oguzhan Gencoglu", "authors": "Umair Akhtar Hasan Khan, Carolin St\\\"urenberg, Oguzhan Gencoglu, Kevin\n  Sandeman, Timo Heikkinen, Antti Rannikko, Tuomas Mirtti", "title": "Improving Prostate Cancer Detection with Breast Histopathology Images", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-030-23937-4_11", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have introduced significant advancements in the field of\nmachine learning-based analysis of digital pathology images including prostate\ntissue images. With the help of transfer learning, classification and\nsegmentation performance of neural network models have been further increased.\nHowever, due to the absence of large, extensively annotated, publicly available\nprostate histopathology datasets, several previous studies employ datasets from\nwell-studied computer vision tasks such as ImageNet dataset. In this work, we\npropose a transfer learning scheme from breast histopathology images to improve\nprostate cancer detection performance. We validate our approach on annotated\nprostate whole slide images by using a publicly available breast histopathology\ndataset as pre-training. We show that the proposed cross-cancer approach\noutperforms transfer learning from ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 00:09:14 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Khan", "Umair Akhtar Hasan", ""], ["St\u00fcrenberg", "Carolin", ""], ["Gencoglu", "Oguzhan", ""], ["Sandeman", "Kevin", ""], ["Heikkinen", "Timo", ""], ["Rannikko", "Antti", ""], ["Mirtti", "Tuomas", ""]]}, {"id": "1903.05779", "submitter": "Shengyang Sun", "authors": "Shengyang Sun, Guodong Zhang, Jiaxin Shi, Roger Grosse", "title": "Functional Variational Bayesian Neural Networks", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian neural networks (BNNs) perform variational inference\nover weights, but it is difficult to specify meaningful priors and approximate\nposteriors in a high-dimensional weight space. We introduce functional\nvariational Bayesian neural networks (fBNNs), which maximize an Evidence Lower\nBOund (ELBO) defined directly on stochastic processes, i.e. distributions over\nfunctions. We prove that the KL divergence between stochastic processes equals\nthe supremum of marginal KL divergences over all finite sets of inputs. Based\non this, we introduce a practical training objective which approximates the\nfunctional ELBO using finite measurement sets and the spectral Stein gradient\nestimator. With fBNNs, we can specify priors entailing rich structures,\nincluding Gaussian processes and implicit stochastic processes. Empirically, we\nfind fBNNs extrapolate well using various structured priors, provide reliable\nuncertainty estimates, and scale to large datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 01:05:24 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Sun", "Shengyang", ""], ["Zhang", "Guodong", ""], ["Shi", "Jiaxin", ""], ["Grosse", "Roger", ""]]}, {"id": "1903.05789", "submitter": "Bin Dai", "authors": "Bin Dai and David Wipf", "title": "Diagnosing and Enhancing VAE Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although variational autoencoders (VAEs) represent a widely influential deep\ngenerative model, many aspects of the underlying energy function remain poorly\nunderstood. In particular, it is commonly believed that Gaussian\nencoder/decoder assumptions reduce the effectiveness of VAEs in generating\nrealistic samples. In this regard, we rigorously analyze the VAE objective,\ndifferentiating situations where this belief is and is not actually true. We\nthen leverage the corresponding insights to develop a simple VAE enhancement\nthat requires no additional hyperparameters or sensitive tuning.\nQuantitatively, this proposal produces crisp samples and stable FID scores that\nare actually competitive with a variety of GAN models, all while retaining\ndesirable attributes of the original VAE architecture. A shorter version of\nthis work will appear in the ICLR 2019 conference proceedings (Dai and Wipf,\n2019). The code for our model is available at https://github.com/daib13/\nTwoStageVAE.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 02:11:17 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 10:53:11 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Dai", "Bin", ""], ["Wipf", "David", ""]]}, {"id": "1903.05803", "submitter": "Mohamad Kazem Shirani Faradonbeh", "authors": "Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, George Michailidis", "title": "On Applications of Bootstrap in Continuous Space Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decision making problems for continuous state and action spaces, linear\ndynamical models are widely employed. Specifically, policies for stochastic\nlinear systems subject to quadratic cost functions capture a large number of\napplications in reinforcement learning. Selected randomized policies have been\nstudied in the literature recently that address the trade-off between\nidentification and control. However, little is known about policies based on\nbootstrapping observed states and actions. In this work, we show that\nbootstrap-based policies achieve a square root scaling of regret with respect\nto time. We also obtain results on the accuracy of learning the model's\ndynamics. Corroborative numerical analysis that illustrates the technical\nresults is also provided.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 03:37:49 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2019 21:37:17 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Faradonbeh", "Mohamad Kazem Shirani", ""], ["Tewari", "Ambuj", ""], ["Michailidis", "George", ""]]}, {"id": "1903.05821", "submitter": "Sumit Kumar Jha", "authors": "Susmit Jha, Sunny Raj, Steven Lawrence Fernandes, Sumit Kumar Jha,\n  Somesh Jha, Gunjan Verma, Brian Jalaian, Ananthram Swami", "title": "Attribution-driven Causal Analysis for Detection of Adversarial Examples", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods have been developed to explain the decision of a machine\nlearning model on a given input. We use the Integrated Gradient method for\nfinding attributions to define the causal neighborhood of an input by\nincrementally masking high attribution features. We study the robustness of\nmachine learning models on benign and adversarial inputs in this neighborhood.\nOur study indicates that benign inputs are robust to the masking of high\nattribution features but adversarial inputs generated by the state-of-the-art\nadversarial attack methods such as DeepFool, FGSM, CW and PGD, are not robust\nto such masking. Further, our study demonstrates that this concentration of\nhigh-attribution features responsible for the incorrect decision is more\npronounced in physically realizable adversarial examples. This difference in\nattribution of benign and adversarial inputs can be used to detect adversarial\nexamples. Such a defense approach is independent of training data and attack\nmethod, and we demonstrate its effectiveness on digital and physically\nrealizable perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 05:50:00 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Jha", "Susmit", ""], ["Raj", "Sunny", ""], ["Fernandes", "Steven Lawrence", ""], ["Jha", "Sumit Kumar", ""], ["Jha", "Somesh", ""], ["Verma", "Gunjan", ""], ["Jalaian", "Brian", ""], ["Swami", "Ananthram", ""]]}, {"id": "1903.05844", "submitter": "Frederic Sala", "authors": "Paroma Varma, Frederic Sala, Ann He, Alexander Ratner, Christopher\n  R\\'e", "title": "Learning Dependency Structures for Weak Supervision Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling training data is a key bottleneck in the modern machine learning\npipeline. Recent weak supervision approaches combine labels from multiple noisy\nsources by estimating their accuracies without access to ground truth labels;\nhowever, estimating the dependencies among these sources is a critical\nchallenge. We focus on a robust PCA-based algorithm for learning these\ndependency structures, establish improved theoretical recovery rates, and\noutperform existing methods on various real-world tasks. Under certain\nconditions, we show that the amount of unlabeled data needed can scale\nsublinearly or even logarithmically with the number of sources $m$, improving\nover previous efforts that ignore the sparsity pattern in the dependency\nstructure and scale linearly in $m$. We provide an information-theoretic lower\nbound on the minimum sample complexity of the weak supervision setting. Our\nmethod outperforms weak supervision approaches that assume\nconditionally-independent sources by up to 4.64 F1 points and previous\nstructure learning approaches by up to 4.41 F1 points on real-world relation\nextraction and image classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 07:55:52 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Varma", "Paroma", ""], ["Sala", "Frederic", ""], ["He", "Ann", ""], ["Ratner", "Alexander", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1903.05895", "submitter": "Tri Dao", "authors": "Tri Dao, Albert Gu, Matthew Eichhorn, Atri Rudra, Christopher R\\'e", "title": "Learning Fast Algorithms for Linear Transforms Using Butterfly\n  Factorizations", "comments": "International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast linear transforms are ubiquitous in machine learning, including the\ndiscrete Fourier transform, discrete cosine transform, and other structured\ntransformations such as convolutions. All of these transforms can be\nrepresented by dense matrix-vector multiplication, yet each has a specialized\nand highly efficient (subquadratic) algorithm. We ask to what extent\nhand-crafting these algorithms and implementations is necessary, what\nstructural priors they encode, and how much knowledge is required to\nautomatically learn a fast algorithm for a provided structured transform.\nMotivated by a characterization of fast matrix-vector multiplication as\nproducts of sparse matrices, we introduce a parameterization of\ndivide-and-conquer methods that is capable of representing a large class of\ntransforms. This generic formulation can automatically learn an efficient\nalgorithm for many important transforms; for example, it recovers the $O(N \\log\nN)$ Cooley-Tukey FFT algorithm to machine precision, for dimensions $N$ up to\n$1024$. Furthermore, our method can be incorporated as a lightweight\nreplacement of generic matrices in machine learning pipelines to learn\nefficient and compressible transformations. On a standard task of compressing a\nsingle hidden-layer network, our method exceeds the classification accuracy of\nunconstrained matrices on CIFAR-10 by 3.9 points -- the first time a structured\napproach has done so -- with 4X faster inference speed and 40X fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 10:20:38 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 03:32:01 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Dao", "Tri", ""], ["Gu", "Albert", ""], ["Eichhorn", "Matthew", ""], ["Rudra", "Atri", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1903.05926", "submitter": "Ling Pan", "authors": "Ling Pan, Qingpeng Cai, Qi Meng, Wei Chen, Longbo Huang, Tie-Yan Liu", "title": "Reinforcement Learning with Dynamic Boltzmann Softmax Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value function estimation is an important task in reinforcement learning,\ni.e., prediction. The Boltzmann softmax operator is a natural value estimator\nand can provide several benefits. However, it does not satisfy the\nnon-expansion property, and its direct use may fail to converge even in value\niteration. In this paper, we propose to update the value function with dynamic\nBoltzmann softmax (DBS) operator, which has good convergence property in the\nsetting of planning and learning. Experimental results on GridWorld show that\nthe DBS operator enables better estimation of the value function, which\nrectifies the convergence issue of the softmax operator. Finally, we propose\nthe DBS-DQN algorithm by applying dynamic Boltzmann softmax updates in deep\nQ-network, which outperforms DQN substantially in 40 out of 49 Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 11:54:13 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 01:32:58 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 03:40:05 GMT"}, {"version": "v4", "created": "Sun, 8 Sep 2019 07:41:39 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pan", "Ling", ""], ["Cai", "Qingpeng", ""], ["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Huang", "Longbo", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1903.05962", "submitter": "Zhao Kang", "authors": "Zhao Kang, Liangjian Wen, Wenyu Chen, Zenglin Xu", "title": "Low-rank Kernel Learning for Graph-based Clustering", "comments": null, "journal-ref": "Knowledge-Based Systems, 2019", "doi": "10.1016/j.knosys.2018.09.009", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing the adjacency graph is fundamental to graph-based clustering.\nGraph learning in kernel space has shown impressive performance on a number of\nbenchmark data sets. However, its performance is largely determined by the\nchosen kernel matrix. To address this issue, the previous multiple kernel\nlearning algorithm has been applied to learn an optimal kernel from a group of\npredefined kernels. This approach might be sensitive to noise and limits the\nrepresentation ability of the consensus kernel. In contrast to existing\nmethods, we propose to learn a low-rank kernel matrix which exploits the\nsimilarity nature of the kernel matrix and seeks an optimal kernel from the\nneighborhood of candidate kernels. By formulating graph construction and kernel\nlearning in a unified framework, the graph and consensus kernel can be\niteratively enhanced by each other. Extensive experimental results validate the\nefficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 12:59:52 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Kang", "Zhao", ""], ["Wen", "Liangjian", ""], ["Chen", "Wenyu", ""], ["Xu", "Zenglin", ""]]}, {"id": "1903.05965", "submitter": "Yiming Li", "authors": "Jiawang Bai, Yiming Li, Jiawei Li, Yong Jiang, Shutao Xia", "title": "Rectified Decision Trees: Towards Interpretability, Compression and\n  Empirical Soundness", "comments": "This is an early draft of our journal submission 'Rectified Decision\n  Trees: Exploring the Landscape of Interpretable and Effective Machine\n  Learning'. Please refer to our new version (arXiv:2008.09413)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to obtain a model with good interpretability and performance has always\nbeen an important research topic. In this paper, we propose rectified decision\ntrees (ReDT), a knowledge distillation based decision trees rectification with\nhigh interpretability, small model size, and empirical soundness. Specifically,\nwe extend the impurity calculation and the pure ending condition of the\nclassical decision tree to propose a decision tree extension that allows the\nuse of soft labels generated by a well-trained teacher model in training and\nprediction process. It is worth noting that for the acquisition of soft labels,\nwe propose a new multiple cross-validation based method to reduce the effects\nof randomness and overfitting. These approaches ensure that ReDT retains\nexcellent interpretability and even achieves fewer nodes than the decision tree\nin the aspect of compression while having relatively good performance. Besides,\nin contrast to traditional knowledge distillation, back propagation of the\nstudent model is not necessarily required in ReDT, which is an attempt of a new\nknowledge distillation approach. Extensive experiments are conducted, which\ndemonstrates the superiority of ReDT in interpretability, compression, and\nempirical soundness.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 13:04:03 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 02:52:06 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bai", "Jiawang", ""], ["Li", "Yiming", ""], ["Li", "Jiawei", ""], ["Jiang", "Yong", ""], ["Xia", "Shutao", ""]]}, {"id": "1903.05980", "submitter": "Leonardo Gutierrez", "authors": "Leonardo Guti\\'errez-G\\'omez, Jean-Charles Delvenne", "title": "Unsupervised Network Embedding for Graph Visualization, Clustering and\n  Classification", "comments": "17 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main challenge in mining network-based data is finding effective ways to\nrepresent or encode graph structures so that it can be efficiently exploited by\nmachine learning algorithms. Several methods have focused in network\nrepresentation at node/edge or substructure level. However, many real life\nchallenges such as time-varying, multilayer, chemical compounds and brain\nnetworks involve analysis of a family of graphs instead of single one opening\nadditional challenges in graph comparison and representation. Traditional\napproaches for learning representations relies on hand-crafting specialized\nheuristics to extract meaningful information about the graphs, e.g statistical\nproperties, structural features, etc. as well as engineered graph distances to\nquantify dissimilarity between networks. In this work we provide an\nunsupervised approach to learn embedding representation for a collection of\ngraphs so that it can be used in numerous graph mining tasks. By using an\nunsupervised neural network approach on input graphs, we aim to capture the\nunderlying distribution of the data in order to discriminate between different\nclass of networks. Our method is assessed empirically on synthetic and real\nlife datasets and evaluated in three different tasks: graph clustering,\nvisualization and classification. Results reveal that our method outperforms\nwell known graph distances and graph-kernels in clustering and classification\ntasks, being highly efficient in runtime.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 08:15:05 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 07:46:36 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Guti\u00e9rrez-G\u00f3mez", "Leonardo", ""], ["Delvenne", "Jean-Charles", ""]]}, {"id": "1903.06007", "submitter": "Esteban Bautista", "authors": "Esteban Bautista and Patrice Abry and Paulo Gon\\c{c}alves", "title": "$L^\\gamma$-PageRank for Semi-Supervised Learning", "comments": "Submitted to Applied Network Science (special issue on machine\n  learning with graphs)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PageRank for Semi-Supervised Learning has shown to leverage data structures\nand limited tagged examples to yield meaningful classification. Despite\nsuccesses, classification performance can still be improved, particularly in\ncases of fuzzy graphs or unbalanced labeled data. To address such limitations,\na novel approach based on powers of the Laplacian matrix $L^\\gamma$ ($\\gamma >\n0$), referred to as $L^\\gamma$-PageRank, is proposed. Its theoretical study\nshows that it operates on signed graphs, where nodes belonging to one same\nclass are more likely to share positive edges while nodes from different\nclasses are more likely to be connected with negative edges. It is shown that\nby selecting an optimal $\\gamma$, classification performance can be\nsignificantly enhanced. A procedure for the automated estimation of the optimal\n$\\gamma$, from a unique observation of data, is devised and assessed.\nExperiments on several datasets demonstrate the effectiveness of both\n$L^\\gamma$-PageRank classification and the optimal $\\gamma$ estimation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:31:37 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Bautista", "Esteban", ""], ["Abry", "Patrice", ""], ["Gon\u00e7alves", "Paulo", ""]]}, {"id": "1903.06009", "submitter": "Issei Sato", "authors": "Issei Sato", "title": "On Learning from Ghost Imaging without Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational ghost imaging is an imaging technique in which an object is\nimaged from light collected using a single-pixel detector with no spatial\nresolution. Recently, ghost cytometry has been proposed for a high-speed\ncell-classification method that involves ghost imaging and machine learning in\nflow cytometry. Ghost cytometry skips the reconstruction of cell images from\nsignals and directly used signals for cell-classification because this\nreconstruction is what creates the bottleneck in the high-speed analysis. In\nthis paper, we provide theoretical analysis for learning from ghost imaging\nwithout imaging.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:04:51 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 01:09:45 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 02:32:27 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 13:59:59 GMT"}, {"version": "v5", "created": "Wed, 29 May 2019 14:55:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Sato", "Issei", ""]]}, {"id": "1903.06023", "submitter": "Rui Li", "authors": "Rui Li, Howard D. Bondell, Brian J. Reich", "title": "Deep Distribution Regression", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their flexibility and predictive performance, machine-learning based\nregression methods have become an important tool for predictive modeling and\nforecasting. However, most methods focus on estimating the conditional mean or\nspecific quantiles of the target quantity and do not provide the full\nconditional distribution, which contains uncertainty information that might be\ncrucial for decision making. In this article, we provide a general solution by\ntransforming a conditional distribution estimation problem into a constrained\nmulti-class classification problem, in which tools such as deep neural\nnetworks. We propose a novel joint binary cross-entropy loss function to\naccomplish this goal. We demonstrate its performance in various simulation\nstudies comparing to state-of-the-art competing methods. Additionally, our\nmethod shows improved accuracy in a probabilistic solar energy forecasting\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:19:39 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Li", "Rui", ""], ["Bondell", "Howard D.", ""], ["Reich", "Brian J.", ""]]}, {"id": "1903.06047", "submitter": "Matthew Gombolay", "authors": "Rohan Paleja and Matthew Gombolay", "title": "Inferring Personalized Bayesian Embeddings for Learning from\n  Heterogeneous Demonstration", "comments": "8 Pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For assistive robots and virtual agents to achieve ubiquity, machines will\nneed to anticipate the needs of their human counterparts. The field of Learning\nfrom Demonstration (LfD) has sought to enable machines to infer predictive\nmodels of human behavior for autonomous robot control. However, humans exhibit\nheterogeneity in decision-making, which traditional LfD approaches fail to\ncapture. To overcome this challenge, we propose a Bayesian LfD framework to\ninfer an integrated representation of all human task demonstrators by inferring\nhuman-specific embeddings, thereby distilling their unique characteristics. We\nvalidate our approach is able to outperform state-of-the-art techniques on both\nsynthetic and real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:32:55 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Paleja", "Rohan", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1903.06048", "submitter": "Animesh Karnewar", "authors": "Animesh Karnewar, Oliver Wang", "title": "MSG-GAN: Multi-Scale Gradients for Generative Adversarial Networks", "comments": "CVPR 2020 (Main Conference). Work sponsored by TomTom and Adobe. Code\n  repository: https://github.com/akanimax/msg-stylegan-tf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Generative Adversarial Networks (GANs) have seen huge successes in\nimage synthesis tasks, they are notoriously difficult to adapt to different\ndatasets, in part due to instability during training and sensitivity to\nhyperparameters. One commonly accepted reason for this instability is that\ngradients passing from the discriminator to the generator become uninformative\nwhen there isn't enough overlap in the supports of the real and fake\ndistributions. In this work, we propose the Multi-Scale Gradient Generative\nAdversarial Network (MSG-GAN), a simple but effective technique for addressing\nthis by allowing the flow of gradients from the discriminator to the generator\nat multiple scales. This technique provides a stable approach for high\nresolution image synthesis, and serves as an alternative to the commonly used\nprogressive growing technique. We show that MSG-GAN converges stably on a\nvariety of image datasets of different sizes, resolutions and domains, as well\nas different types of loss functions and architectures, all with the same set\nof fixed hyperparameters. When compared to state-of-the-art GANs, our approach\nmatches or exceeds the performance in most of the cases we tried.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:33:26 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 19:48:01 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 10:47:55 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 20:45:26 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Karnewar", "Animesh", ""], ["Wang", "Oliver", ""]]}, {"id": "1903.06059", "submitter": "Wouter Kool", "authors": "Wouter Kool, Herke van Hoof, Max Welling", "title": "Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for\n  Sampling Sequences Without Replacement", "comments": "ICML 2019 ; 13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known Gumbel-Max trick for sampling from a categorical distribution\ncan be extended to sample $k$ elements without replacement. We show how to\nimplicitly apply this 'Gumbel-Top-$k$' trick on a factorized distribution over\nsequences, allowing to draw exact samples without replacement using a\nStochastic Beam Search. Even for exponentially large domains, the number of\nmodel evaluations grows only linear in $k$ and the maximum sampled sequence\nlength. The algorithm creates a theoretical connection between sampling and\n(deterministic) beam search and can be used as a principled intermediate\nalternative. In a translation task, the proposed method compares favourably\nagainst alternatives to obtain diverse yet good quality translations. We show\nthat sequences sampled without replacement can be used to construct\nlow-variance estimators for expected sentence-level BLEU score and model\nentropy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:56:06 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 20:05:01 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Kool", "Wouter", ""], ["van Hoof", "Herke", ""], ["Welling", "Max", ""]]}, {"id": "1903.06070", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Nicholas Ketz, Xinyun Zou, Jeffrey Krichmar, Praveen\n  Pilly", "title": "Attention-Based Structural-Plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting/interference is a critical problem for lifelong\nlearning machines, which impedes the agents from maintaining their previously\nlearned knowledge while learning new tasks. Neural networks, in particular,\nsuffer plenty from the catastrophic forgetting phenomenon. Recently there has\nbeen several efforts towards overcoming catastrophic forgetting in neural\nnetworks. Here, we propose a biologically inspired method toward overcoming\ncatastrophic forgetting. Specifically, we define an attention-based selective\nplasticity of synapses based on the cholinergic neuromodulatory system in the\nbrain. We define synaptic importance parameters in addition to synaptic weights\nand then use Hebbian learning in parallel with backpropagation algorithm to\nlearn synaptic importances in an online and seamless manner. We test our\nproposed method on benchmark tasks including the Permuted MNIST and the Split\nMNIST problems and show competitive performance compared to the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 22:23:35 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Kolouri", "Soheil", ""], ["Ketz", "Nicholas", ""], ["Zou", "Xinyun", ""], ["Krichmar", "Jeffrey", ""], ["Pilly", "Praveen", ""]]}, {"id": "1903.06135", "submitter": "Naveen Goela", "authors": "Payam Delgosha and Naveen Goela", "title": "Deep Switch Networks for Generating Discrete Data and Language", "comments": "To be presented at the AISTATS-2019 conference, 12 pages,\n  double-column", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer switch networks are proposed as artificial generators of\nhigh-dimensional discrete data (e.g., binary vectors, categorical data, natural\nlanguage, network log files, and discrete-valued time series). Unlike\ndeconvolution networks which generate continuous-valued data and which consist\nof upsampling filters and reverse pooling layers, multilayer switch networks\nare composed of adaptive switches which model conditional distributions of\ndiscrete random variables. An interpretable, statistical framework is\nintroduced for training these nonlinear networks based on a maximum-likelihood\nobjective function. To learn network parameters, stochastic gradient descent is\napplied to the objective. This direct optimization is stable until convergence,\nand does not involve back-propagation over separate encoder and decoder\nnetworks, or adversarial training of dueling networks. While training remains\ntractable for moderately sized networks, Markov-chain Monte Carlo (MCMC)\napproximations of gradients are derived for deep networks which contain latent\nvariables. The statistical framework is evaluated on synthetic data,\nhigh-dimensional binary data of handwritten digits, and web-crawled natural\nlanguage data. Aspects of the model's framework such as interpretability,\ncomputational complexity, and generalization ability are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:28:44 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Delgosha", "Payam", ""], ["Goela", "Naveen", ""]]}, {"id": "1903.06151", "submitter": "Jan Scholten", "authors": "Jan Scholten, Daan Wout, Carlos Celemin and Jens Kober", "title": "Deep Reinforcement Learning with Feedback-based Exploration", "comments": "6 pages", "journal-ref": null, "doi": "10.1109/CDC40024.2019.9029503", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has enabled the control of increasingly complex\nand high-dimensional problems. However, the need of vast amounts of data before\nreasonable performance is attained prevents its widespread application. We\nemploy binary corrective feedback as a general and intuitive manner to\nincorporate human intuition and domain knowledge in model-free machine\nlearning. The uncertainty in the policy and the corrective feedback is combined\ndirectly in the action space as probabilistic conditional exploration. As a\nresult, the greatest part of the otherwise ignorant learning process can be\navoided. We demonstrate the proposed method, Predictive Probabilistic Merging\nof Policies (PPMP), in combination with DDPG. In experiments on continuous\ncontrol problems of the OpenAI Gym, we achieve drastic improvements in sample\nefficiency, final performance, and robustness to erroneous feedback, both for\nhuman and synthetic feedback. Additionally, we show solutions beyond the\ndemonstrated knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:52:46 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Scholten", "Jan", ""], ["Wout", "Daan", ""], ["Celemin", "Carlos", ""], ["Kober", "Jens", ""]]}, {"id": "1903.06164", "submitter": "Moonsu Han", "authors": "Moonsu Han, Minki Kang, Hyunwoo Jung, Sung Ju Hwang", "title": "Episodic Memory Reader: Learning What to Remember for Question Answering\n  from Streaming Data", "comments": "18 pages, 20 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel question answering (QA) task where the machine needs to\nread from large streaming data (long documents or videos) without knowing when\nthe questions will be given, which is difficult to solve with existing QA\nmethods due to their lack of scalability. To tackle this problem, we propose a\nnovel end-to-end deep network model for reading comprehension, which we refer\nto as Episodic Memory Reader (EMR) that sequentially reads the input contexts\ninto an external memory, while replacing memories that are less important for\nanswering \\emph{unseen} questions. Specifically, we train an RL agent to\nreplace a memory entry when the memory is full, in order to maximize its QA\naccuracy at a future timepoint, while encoding the external memory using either\nthe GRU or the Transformer architecture to learn representations that considers\nrelative importance between the memory entries. We validate our model on a\nsynthetic dataset (bAbI) as well as real-world large-scale textual QA\n(TriviaQA) and video QA (TVQA) datasets, on which it achieves significant\nimprovements over rule-based memory scheduling policies or an RL-based baseline\nthat independently learns the query-specific importance of each memory.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:00:56 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 07:46:25 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 06:58:01 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Han", "Moonsu", ""], ["Kang", "Minki", ""], ["Jung", "Hyunwoo", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1903.06187", "submitter": "Aditya Modi", "authors": "Aditya Modi, Ambuj Tewari", "title": "No-regret Exploration in Contextual Reinforcement Learning", "comments": "Accepted to UAI 2020. PMLR proceedings, volume 124", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recently proposed reinforcement learning (RL) framework of\nContextual Markov Decision Processes (CMDP), where the agent interacts with a\n(potentially adversarial) sequence of episodic tabular MDPs. In addition, a\ncontext vector determining the MDP parameters is available to the agent at the\nstart of each episode, thereby allowing it to learn a context-dependent\nnear-optimal policy. In this paper, we propose a no-regret online RL algorithm\nin the setting where the MDP parameters are obtained from the context using\ngeneralized linear mappings (GLMs). We propose and analyze optimistic and\nrandomized exploration methods which make (time and space) efficient online\nupdates. The GLM based model subsumes previous work in this area and also\nimproves previous known bounds in the special case where the contextual mapping\nis linear. In addition, we demonstrate a generic template to derive confidence\nsets using an online learning oracle and give a lower bound for the setting.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 18:02:09 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 21:30:26 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 20:02:00 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Modi", "Aditya", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1903.06209", "submitter": "Carl Trimbach", "authors": "Carl Trimbach, Michael Littman", "title": "Teaching with IMPACT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like many problems in AI in their general form, supervised learning is\ncomputationally intractable. We hypothesize that an important reason humans can\nlearn highly complex and varied concepts, in spite of the computational\ndifficulty, is that they benefit tremendously from experienced and insightful\nteachers. This paper proposes a new learning framework that provides a role for\na knowledgeable, benevolent teacher to guide the process of learning a target\nconcept in a series of \"curricular\" phases or rounds. In each round, the\nteacher's role is to act as a moderator, exposing the learner to a subset of\nthe available training data to move it closer to mastering the target concept.\nVia both theoretical and empirical evidence, we argue that this framework\nenables simple, efficient learners to acquire very complex concepts from\nexamples. In particular, we provide multiple examples of concept classes that\nare known to be unlearnable in the standard PAC setting along with provably\nefficient algorithms for learning them in our extended setting. A key focus of\nour work is the ability to learn complex concepts on top of simpler, previously\nlearned, concepts---a direction with the potential of creating more competent\nartificial agents.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 18:30:11 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Trimbach", "Carl", ""], ["Littman", "Michael", ""]]}, {"id": "1903.06236", "submitter": "Vladimir Macko", "authors": "Vladimir Macko, Charles Weill, Hanna Mazzawi, Javier Gonzalvo", "title": "Improving Neural Architecture Search Image Classifiers via Ensemble\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the best neural network architecture requires significant time,\nresources, and human expertise. These challenges are partially addressed by\nneural architecture search (NAS) which is able to find the best convolutional\nlayer or cell that is then used as a building block for the network. However,\nonce a good building block is found, manual design is still required to\nassemble the final architecture as a combination of multiple blocks under a\npredefined parameter budget constraint. A common solution is to stack these\nblocks into a single tower and adjust the width and depth to fill the parameter\nbudget. However, these single tower architectures may not be optimal. Instead,\nin this paper we present the AdaNAS algorithm, that uses ensemble techniques to\ncompose a neural network as an ensemble of smaller networks automatically.\nAdditionally, we introduce a novel technique based on knowledge distillation to\niteratively train the smaller networks using the previous ensemble as a\nteacher. Our experiments demonstrate that ensembles of networks improve\naccuracy upon a single neural network while keeping the same number of\nparameters. Our models achieve comparable results with the state-of-the-art on\nCIFAR-10 and sets a new state-of-the-art on CIFAR-100.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 20:17:33 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Macko", "Vladimir", ""], ["Weill", "Charles", ""], ["Mazzawi", "Hanna", ""], ["Gonzalvo", "Javier", ""]]}, {"id": "1903.06237", "submitter": "Amir Gholami", "authors": "Linjian Ma and Gabe Montague and Jiayu Ye and Zhewei Yao and Amir\n  Gholami and Kurt Keutzer and Michael W. Mahoney", "title": "Inefficiency of K-FAC for Large Batch Size Training", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic optimization, using large batch sizes during training can\nleverage parallel resources to produce faster wall-clock training times per\ntraining epoch. However, for both training loss and testing error, recent\nresults analyzing large batch Stochastic Gradient Descent (SGD) have found\nsharp diminishing returns, beyond a certain critical batch size. In the hopes\nof addressing this, it has been suggested that the Kronecker-Factored\nApproximate Curvature (\\mbox{K-FAC}) method allows for greater scalability to\nlarge batch sizes, for non-convex machine learning problems such as neural\nnetwork optimization, as well as greater robustness to variation in model\nhyperparameters. Here, we perform a detailed empirical analysis of large batch\nsize training %of these two hypotheses, for both \\mbox{K-FAC} and SGD,\nevaluating performance in terms of both wall-clock time and aggregate\ncomputational cost. Our main results are twofold: first, we find that both\n\\mbox{K-FAC} and SGD doesn't have ideal scalability behavior beyond a certain\nbatch size, and that \\mbox{K-FAC} does not exhibit improved large-batch\nscalability behavior, as compared to SGD; and second, we find that\n\\mbox{K-FAC}, in addition to requiring more hyperparameters to tune, suffers\nfrom similar hyperparameter sensitivity behavior as does SGD. We discuss\nextensive results using ResNet and AlexNet on \\mbox{CIFAR-10} and SVHN,\nrespectively, as well as more general implications of our findings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 20:21:35 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 21:59:03 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 19:28:00 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ma", "Linjian", ""], ["Montague", "Gabe", ""], ["Ye", "Jiayu", ""], ["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1903.06249", "submitter": "Saeed Masoudnia", "authors": "Omid Mersa, Farhood Etaati, Saeed Masoudnia and Babak N. Araabi", "title": "Learning Representations from Persian Handwriting for Offline Signature\n  Verification, a Deep Transfer Learning Approach", "comments": null, "journal-ref": "2019 4th International Conference on Pattern Recognition and Image\n  Analysis (IPRIA)", "doi": "10.1109/PRIA.2019.8785979", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline Signature Verification (OSV) is a challenging pattern recognition\ntask, especially when it is expected to generalize well on the skilled\nforgeries that are not available during the training. Its challenges also\ninclude small training sample and large intra-class variations. Considering the\nlimitations, we suggest a novel transfer learning approach from Persian\nhandwriting domain to multi-language OSV domain. We train two Residual CNNs on\nthe source domain separately based on two different tasks of word\nclassification and writer identification. Since identifying a person signature\nresembles identifying ones handwriting, it seems perfectly convenient to use\nhandwriting for the feature learning phase. The learned representation on the\nmore varied and plentiful handwriting dataset can compensate for the lack of\ntraining data in the original task, i.e. OSV, without sacrificing the\ngeneralizability. Our proposed OSV system includes two steps: learning\nrepresentation and verification of the input signature. For the first step, the\nsignature images are fed into the trained Residual CNNs. The output\nrepresentations are then used to train SVMs for the verification. We test our\nOSV system on three different signature datasets, including MCYT (a Spanish\nsignature dataset), UTSig (a Persian one) and GPDS-Synthetic (an artificial\ndataset). On UT-SIG, we achieved 9.80% Equal Error Rate (EER) which showed\nsubstantial improvement over the best EER in the literature, 17.45%. Our\nproposed method surpassed state-of-the-arts by 6% on GPDS-Synthetic, achieving\n6.81%. On MCYT, EER of 3.98% was obtained which is comparable to the best\npreviously reported results.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 08:13:55 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Mersa", "Omid", ""], ["Etaati", "Farhood", ""], ["Masoudnia", "Saeed", ""], ["Araabi", "Babak N.", ""]]}, {"id": "1903.06255", "submitter": "Saeed Masoudnia", "authors": "Taraneh Younesian, Saeed Masoudnia, Reshad Hosseini, Babak N. Araabi", "title": "Active Transfer Learning for Persian Offline Signature Verification", "comments": null, "journal-ref": "2019 4th International Conference on Pattern Recognition and Image\n  Analysis (IPRIA)", "doi": "10.1109/PRIA.2019.8786013", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline Signature Verification (OSV) remains a challenging pattern\nrecognition task, especially in the presence of skilled forgeries that are not\navailable during the training. This challenge is aggravated when there are\nsmall labeled training data available but with large intra-personal variations.\nIn this study, we address this issue by employing an active learning approach,\nwhich selects the most informative instances to label and therefore reduces the\nhuman labeling effort significantly. Our proposed OSV includes three steps:\nfeature learning, active learning, and final verification. We benefit from\ntransfer learning using a pre-trained CNN for feature learning. We also propose\nSVM-based active learning for each user to separate his genuine signatures from\nthe random forgeries. We finally used the SVMs to verify the authenticity of\nthe questioned signature. We examined our proposed active transfer learning\nmethod on UTSig: A Persian offline signature dataset. We achieved near 13%\nimprovement compared to the random selection of instances. Our results also\nshowed 1% improvement over the state-of-the-art method in which a fully\nsupervised setting with five more labeled instances per user was used.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 13:49:46 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Younesian", "Taraneh", ""], ["Masoudnia", "Saeed", ""], ["Hosseini", "Reshad", ""], ["Araabi", "Babak N.", ""]]}, {"id": "1903.06258", "submitter": "Alan JiaXiang Guo", "authors": "Yi Liang, Xin Zhao, Alan J.X. Guo, and Fei Zhu", "title": "Hyperspectral Image Classification with Deep Metric Learning and\n  Conditional Random Field", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2019.2939356", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the classification performance in the context of hyperspectral\nimage processing, many works have been developed based on two common\nstrategies, namely the spatial-spectral information integration and the\nutilization of neural networks. However, both strategies typically require more\ntraining data than the classical algorithms, aggregating the shortage of\nlabeled samples. In this letter, we propose a novel framework that organically\ncombines the spectrum-based deep metric learning model and the conditional\nrandom field algorithm. The deep metric learning model is supervised by the\ncenter loss to produce spectrum-based features that gather more tightly in\nEuclidean space within classes. The conditional random field with Gaussian edge\npotentials, which is firstly proposed for image segmentation tasks, is\nintroduced to give the pixel-wise classification over the hyperspectral image\nby utilizing both the geographical distances between pixels and the Euclidean\ndistances between the features produced by the deep metric learning model. The\nproposed framework is trained by spectral pixels at the deep metric learning\nstage and utilizes the half handcrafted spatial features at the conditional\nrandom field stage. This settlement alleviates the shortage of training data to\nsome extent. Experiments on two real hyperspectral images demonstrate the\nadvantages of the proposed method in terms of both classification accuracy and\ncomputation cost.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 09:26:03 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 02:30:41 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Liang", "Yi", ""], ["Zhao", "Xin", ""], ["Guo", "Alan J. X.", ""], ["Zhu", "Fei", ""]]}, {"id": "1903.06259", "submitter": "Adeel Mufti", "authors": "Adeel Mufti, Biagio Antonelli, Julius Monello", "title": "Conditional GANs For Painting Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We examined the use of modern Generative Adversarial Nets to generate novel\nimages of oil paintings using the Painter By Numbers dataset. We implemented\nSpectral Normalization GAN (SN-GAN) and Spectral Normalization GAN with\nGradient Penalty, and compared their outputs to a Deep Convolutional GAN.\nVisually, and quantitatively according to the Sliced Wasserstein Distance\nmetric, we determined that the SN-GAN produced paintings that were most\ncomparable to our training dataset. We then performed a series of experiments\nto add supervised conditioning to SN-GAN, the culmination of which is what we\nbelieve to be a novel architecture that can generate face paintings with\nuser-specified characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:47:56 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Mufti", "Adeel", ""], ["Antonelli", "Biagio", ""], ["Monello", "Julius", ""]]}, {"id": "1903.06260", "submitter": "Riddhish Bhalodia", "authors": "Tim Sodergren and Riddhish Bhalodia and Ross Whitaker and Joshua Cates\n  and Nassir Marrouche and Shireen Elhabian", "title": "Mixture Modeling of Global Shape Priors and Autoencoding Local Intensity\n  Priors for Left Atrium Segmentation", "comments": "Statistical Atlases and Computational Models of the Heart. Atrial\n  Segmentation and LV Quantification Challenges 2019", "journal-ref": "Statistical Atlases and Computational Models of the Heart. Atrial\n  Segmentation and LV Quantification Challenges, 2019, Springer International\n  Publishing, Cham 357--367,", "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Difficult image segmentation problems, for instance left atrium MRI, can be\naddressed by incorporating shape priors to find solutions that are consistent\nwith known objects. Nonetheless, a single multivariate Gaussian is not an\nadequate model in cases with significant nonlinear shape variation or where the\nprior distribution is multimodal. Nonparametric density estimation is more\ngeneral, but has a ravenous appetite for training samples and poses serious\nchallenges in optimization, especially in high dimensional spaces. Here, we\npropose a maximum-a-posteriori formulation that relies on a generative image\nmodel by incorporating both local intensity and global shape priors. We use\ndeep autoencoders to capture the complex intensity distribution while avoiding\nthe careful selection of hand-crafted features. We formulate the shape prior as\na mixture of Gaussians and learn the corresponding parameters in a\nhigh-dimensional shape space rather than pre-projecting onto a low-dimensional\nsubspace. In segmentation, we treat the identity of the mixture component as a\nlatent variable and marginalize it within a generalized\nexpectation-maximization framework. We present a conditional maximization-based\nscheme that alternates between a closed-form solution for component-specific\nshape parameters that provides a global update-based optimization strategy, and\nan intensity-based energy minimization that translates the global notion of a\nnonlinear shape prior into a set of local penalties. We demonstrate our\napproach on the left atrial segmentation from gadolinium-enhanced MRI, which is\nuseful in quantifying the atrial geometry in patients with atrial fibrillation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 23:24:08 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Sodergren", "Tim", ""], ["Bhalodia", "Riddhish", ""], ["Whitaker", "Ross", ""], ["Cates", "Joshua", ""], ["Marrouche", "Nassir", ""], ["Elhabian", "Shireen", ""]]}, {"id": "1903.06293", "submitter": "Ian Goodfellow", "authors": "Ian Goodfellow", "title": "A Research Agenda: Dynamic Models to Defend Against Correlated Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article I describe a research agenda for securing machine learning\nmodels against adversarial inputs at test time. This article does not present\nresults but instead shares some of my thoughts about where I think that the\nfield needs to go. Modern machine learning works very well on I.I.D. data: data\nfor which each example is drawn {\\em independently} and for which the\ndistribution generating each example is {\\em identical}. When these assumptions\nare relaxed, modern machine learning can perform very poorly. When machine\nlearning is used in contexts where security is a concern, it is desirable to\ndesign models that perform well even when the input is designed by a malicious\nadversary. So far most research in this direction has focused on an adversary\nwho violates the {\\em identical} assumption, and imposes some kind of\nrestricted worst-case distribution shift. I argue that machine learning\nsecurity researchers should also address the problem of relaxing the {\\em\nindependence} assumption and that current strategies designed for robustness to\ndistribution shift will not do so. I recommend {\\em dynamic models} that change\neach time they are run as a potential solution path to this problem, and show\nan example of a simple attack using correlated data that can be mitigated by a\nsimple dynamic defense. This is not intended as a real-world security measure,\nbut as a recommendation to explore this research direction and develop more\nrealistic defenses.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 23:07:48 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Goodfellow", "Ian", ""]]}, {"id": "1903.06336", "submitter": "Yitong Li", "authors": "Yitong Li, Michael Murias, Samantha Major, Geraldine Dawson, David E.\n  Carlson", "title": "On Target Shift in Adversarial Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrepancy between training and testing domains is a fundamental problem in\nthe generalization of machine learning techniques. Recently, several approaches\nhave been proposed to learn domain invariant feature representations through\nadversarial deep learning. However, label shift, where the percentage of data\nin each class is different between domains, has received less attention. Label\nshift naturally arises in many contexts, especially in behavioral studies where\nthe behaviors are freely chosen. In this work, we propose a method called\nDomain Adversarial nets for Target Shift (DATS) to address label shift while\nlearning a domain invariant representation. This is accomplished by using\ndistribution matching to estimate label proportions in a blind test set. We\nextend this framework to handle multiple domains by developing a scheme to\nupweight source domains most similar to the target domain. Empirical results\nshow that this framework performs well under large label shift in synthetic and\nreal experiments, demonstrating the practical importance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 02:48:32 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Li", "Yitong", ""], ["Murias", "Michael", ""], ["Major", "Samantha", ""], ["Dawson", "Geraldine", ""], ["Carlson", "David E.", ""]]}, {"id": "1903.06372", "submitter": "Ji Liu", "authors": "Wesley Suttle, Zhuoran Yang, Kaiqing Zhang, Zhaoran Wang, Tamer Basar,\n  Ji Liu", "title": "A Multi-Agent Off-Policy Actor-Critic Algorithm for Distributed\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends off-policy reinforcement learning to the multi-agent case\nin which a set of networked agents communicating with their neighbors according\nto a time-varying graph collaboratively evaluates and improves a target policy\nwhile following a distinct behavior policy. To this end, the paper develops a\nmulti-agent version of emphatic temporal difference learning for off-policy\npolicy evaluation, and proves convergence under linear function approximation.\nThe paper then leverages this result, in conjunction with a novel multi-agent\noff-policy policy gradient theorem and recent work in both multi-agent\non-policy and single-agent off-policy actor-critic methods, to develop and give\nconvergence guarantees for a new multi-agent off-policy actor-critic algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 05:44:12 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 00:41:14 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 21:46:13 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Suttle", "Wesley", ""], ["Yang", "Zhuoran", ""], ["Zhang", "Kaiqing", ""], ["Wang", "Zhaoran", ""], ["Basar", "Tamer", ""], ["Liu", "Ji", ""]]}, {"id": "1903.06412", "submitter": "Mikito Nanashima", "authors": "Mikito Nanashima", "title": "A Faster Algorithm Enumerating Relevant Features over Finite Fields", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of enumerating relevant features hidden in other\nirrelevant information for multi-labeled data, which is formalized as learning\njuntas.\n  A $k$-junta function is a function which depends on only $k$ coordinates of\nthe input. For relatively small $k$ w.r.t. the input size $n$, learning\n$k$-junta functions is one of fundamental problems both theoretically and\npractically in machine learning. For the last two decades, much effort has been\nmade to design efficient learning algorithms for Boolean junta functions, and\nsome novel techniques have been developed. However, in real world,\nmulti-labeled data seem to be obtained in much more often than binary-labeled\none. Thus, it is a natural question whether these techniques can be applied to\nmore general cases about the alphabet size.\n  In this paper, we expand the Fourier detection techniques for the binary\nalphabet to any finite field $\\mathbb{F}_q$, and give, roughly speaking, an\n$O(n^{0.8k})$-time learning algorithm for $k$-juntas over $\\mathbb{F}_q$. Note\nthat our algorithm is the first non-trivial (i.e., non-brute force) algorithm\nfor such a class even in the case where $q=3$ and we give an affirmative answer\nto the question posed by Mossel et al.\n  Our algorithm consists of two reductions: (1) from learning juntas to LDME\nwhich is a variant of the learning with errors (LWE) problems introduced by\nRegev, and (2) from LDME to the light bulb problem (LBP) introduced by\nL.Valiant. Since the reduced problem (i.e., LBP) is a kind of binary problem\nregardless of the alphabet size of the original problem (i.e., learning\njuntas), we can directly apply the techniques for the binary case in the\nprevious work.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 08:51:51 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 14:38:10 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Nanashima", "Mikito", ""]]}, {"id": "1903.06500", "submitter": "Rui Xia", "authors": "Rui Xia, Vincent Y. F. Tan, Louis Filstroff, C\\'edric F\\'evotte", "title": "A Ranking Model Motivated by Nonnegative Matrix Factorization with\n  Applications to Tennis Tournaments", "comments": "16 pages, 2 figures, 9 tables. Accepted and to be presented at the\n  European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (ECML/PKDD) 2019. Supplementary material,\n  code and datasets can be found in this URL\n  https://github.com/XiaRui1996/btl-nmf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel ranking model that combines the Bradley-Terry-Luce\nprobability model with a nonnegative matrix factorization framework to model\nand uncover the presence of latent variables that influence the performance of\ntop tennis players. We derive an efficient, provably convergent, and\nnumerically stable majorization-minimization-based algorithm to maximize the\nlikelihood of datasets under the proposed statistical model. The model is\ntested on datasets involving the outcomes of matches between 20 top male and\nfemale tennis players over 14 major tournaments for men (including the Grand\nSlams and the ATP Masters 1000) and 16 major tournaments for women over the\npast 10 years. Our model automatically infers that the surface of the court\n(e.g., clay or hard court) is a key determinant of the performances of male\nplayers, but less so for females. Top players on various surfaces over this\nlongitudinal period are also identified in an objective manner.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 12:48:33 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 03:56:27 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Xia", "Rui", ""], ["Tan", "Vincent Y. F.", ""], ["Filstroff", "Louis", ""], ["F\u00e9votte", "C\u00e9dric", ""]]}, {"id": "1903.06529", "submitter": "Nicolas Girard", "authors": "Nicolas Girard (UCA, TITANE), Guillaume Charpiat (TAU), Yuliya\n  Tarabalka (UCA, TITANE)", "title": "Noisy Supervision for Correcting Misaligned Cadaster Maps Without\n  Perfect Ground Truth Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning the best performance on a certain task is achieved by\nfully supervised methods when perfect ground truth labels are available.\nHowever, labels are often noisy, especially in remote sensing where manually\ncurated public datasets are rare. We study the multi-modal cadaster map\nalignment problem for which available annotations are mis-aligned polygons,\nresulting in noisy supervision. We subsequently set up a multiple-rounds\ntraining scheme which corrects the ground truth annotations at each round to\nbetter train the model at the next round. We show that it is possible to reduce\nthe noise of the dataset by iteratively training a better alignment model to\ncorrect the annotation alignment.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:38:39 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Girard", "Nicolas", "", "UCA, TITANE"], ["Charpiat", "Guillaume", "", "TAU"], ["Tarabalka", "Yuliya", "", "UCA, TITANE"]]}, {"id": "1903.06530", "submitter": "Seijoon Kim", "authors": "Seijoon Kim, Seongsik Park, Byunggook Na, Sungroh Yoon", "title": "Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object\n  Detection", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, deep neural networks (DNNs) have demonstrated\nremarkable performance in a variety of applications. As we try to solve more\nadvanced problems, increasing demands for computing and power resources has\nbecome inevitable. Spiking neural networks (SNNs) have attracted widespread\ninterest as the third-generation of neural networks due to their event-driven\nand low-powered nature. SNNs, however, are difficult to train, mainly owing to\ntheir complex dynamics of neurons and non-differentiable spike operations.\nFurthermore, their applications have been limited to relatively simple tasks\nsuch as image classification. In this study, we investigate the performance\ndegradation of SNNs in a more challenging regression problem (i.e., object\ndetection). Through our in-depth analysis, we introduce two novel methods:\nchannel-wise normalization and signed neuron with imbalanced threshold, both of\nwhich provide fast and accurate information transmission for deep SNNs.\nConsequently, we present a first spiked-based object detection model, called\nSpiking-YOLO. Our experiments show that Spiking-YOLO achieves remarkable\nresults that are comparable (up to 98%) to those of Tiny YOLO on non-trivial\ndatasets, PASCAL VOC and MS COCO. Furthermore, Spiking-YOLO on a neuromorphic\nchip consumes approximately 280 times less energy than Tiny YOLO and converges\n2.3 to 4 times faster than previous SNN conversion methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 08:34:47 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 16:00:31 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kim", "Seijoon", ""], ["Park", "Seongsik", ""], ["Na", "Byunggook", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1903.06536", "submitter": "Saeed Masoudnia", "authors": "Saeed Masoudnia, Omid Mersa, Babak N. Araabi, Abdol-Hossein Vahabie,\n  Mohammad Amin Sadeghi, and Majid Nili Ahmadabadi", "title": "Multi-Representational Learning for Offline Signature Verification using\n  Multi-Loss Snapshot Ensemble of CNNs", "comments": null, "journal-ref": "Expert Systems with Applications, 2019, 133, 317-330", "doi": "10.1016/j.eswa.2019.03.040", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline Signature Verification (OSV) is a challenging pattern recognition\ntask, especially in presence of skilled forgeries that are not available during\ntraining. This study aims to tackle its challenges and meet the substantial\nneed for generalization for OSV by examining different loss functions for\nConvolutional Neural Network (CNN). We adopt our new approach to OSV by asking\ntwo questions: 1. which classification loss provides more generalization for\nfeature learning in OSV? , and 2. How integration of different losses into a\nunified multi-loss function lead to an improved learning framework? These\nquestions are studied based on analysis of three loss functions, including\ncross entropy, Cauchy-Schwarz divergence, and hinge loss. According to\ncomplementary features of these losses, we combine them into a dynamic\nmulti-loss function and propose a novel ensemble framework for simultaneous use\nof them in CNN. Our proposed Multi-Loss Snapshot Ensemble (MLSE) consists of\nseveral sequential trials. In each trial, a dominant loss function is selected\nfrom the multi-loss set, and the remaining losses act as a regularizer.\nDifferent trials learn diverse representations for each input based on\nsignature identification task. This multi-representation set is then employed\nfor the verification task. An ensemble of SVMs is trained on these\nrepresentations, and their decisions are finally combined according to the\nselection of most generalizable SVM for each user. We conducted two sets of\nexperiments based on two different protocols of OSV, i.e., writer-dependent and\nwriter-independent on three signature datasets: GPDS-Synthetic, MCYT, and\nUT-SIG. Based on the writer-dependent OSV protocol, we achieved substantial\nimprovements over the best EERs in the literature. The results of the second\nset of experiments also confirmed the robustness to the arrival of new users\nenrolled in the OSV system.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:11:21 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Masoudnia", "Saeed", ""], ["Mersa", "Omid", ""], ["Araabi", "Babak N.", ""], ["Vahabie", "Abdol-Hossein", ""], ["Sadeghi", "Mohammad Amin", ""], ["Ahmadabadi", "Majid Nili", ""]]}, {"id": "1903.06538", "submitter": "Paresh Malalur", "authors": "Paresh Malalur and Tommi Jaakkola", "title": "Alignment Based Matching Networks for One-Shot Classification and\n  Open-Set Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning for object classification relies heavily on convolutional\nmodels. While effective, CNNs are rarely interpretable after the fact. An\nattention mechanism can be used to highlight the area of the image that the\nmodel focuses on thus offering a narrow view into the mechanism of\nclassification. We expand on this idea by forcing the method to explicitly\nalign images to be classified to reference images representing the classes. The\nmechanism of alignment is learned and therefore does not require that the\nreference objects are anything like those being classified. Beyond explanation,\nour exemplar based cross-alignment method enables classification with only a\nsingle example per category (one-shot). Our model cuts the 5-way, 1-shot error\nrate in Omniglot from 2.1% to 1.4% and in MiniImageNet from 53.5% to 46.5%\nwhile simultaneously providing point-wise alignment information providing some\nunderstanding on what the network is capturing. This method of alignment also\nenables the recognition of an unsupported class (open-set) in the one-shot\nsetting while maintaining an F1-score of above 0.5 for Omniglot even with 19\nother distracting classes while baselines completely fail to separate the\nopen-set class in the one-shot setting.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 02:50:27 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Malalur", "Paresh", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1903.06548", "submitter": "Philip Sellars", "authors": "Philip Sellars, Angelica Aviles-Rivero, and Carola-Bibiane Sch\\\"onlieb", "title": "Superpixel Contracted Graph-Based Learning for Hyperspectral Image\n  Classification", "comments": "11 pages", "journal-ref": null, "doi": "10.1109/TGRS.2019.2961599", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in hyperspectral image classification is obtaining high\nclassification accuracy when using a limited amount of labelled data. In this\npaper we present a novel graph-based framework, which aims to tackle this\nproblem in the presence of large scale data input. Our approach utilises a\nnovel superpixel method, specifically designed for hyperspectral data, to\ndefine meaningful local regions in an image, which with high probability share\nthe same classification label. We then extract spectral and spatial features\nfrom these regions and use these to produce a contracted weighted\ngraph-representation, where each node represents a region rather than a pixel.\nOur graph is then fed into a graph-based semi-supervised classifier which gives\nthe final classification. We show that using superpixels in a graph\nrepresentation is an effective tool for speeding up graphical classifiers\napplied to hyperspectral images. We demonstrate through exhaustive quantitative\nand qualitative results that our proposed method produces accurate\nclassifications when an incredibly small amount of labelled data is used. We\nshow that our approach mitigates the major drawbacks of existing approaches,\nresulting in our approach outperforming several comparative state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 13:23:43 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 09:22:46 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 15:11:25 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Sellars", "Philip", ""], ["Aviles-Rivero", "Angelica", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1903.06580", "submitter": "Rogelio Andrade Mancisidor", "authors": "Rogelio A Mancisidor, Michael Kampffmeyer, Kjersti Aas, Robert Jenssen", "title": "Learning Latent Representations of Bank Customers With The Variational\n  Autoencoder", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.02538", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning data representations that reflect the customers' creditworthiness\ncan improve marketing campaigns, customer relationship management, data and\nprocess management or the credit risk assessment in retail banks. In this\nresearch, we adopt the Variational Autoencoder (VAE), which has the ability to\nlearn latent representations that contain useful information. We show that it\nis possible to steer the latent representations in the latent space of the VAE\nusing the Weight of Evidence and forming a specific grouping of the data that\nreflects the customers' creditworthiness. Our proposed method learns a latent\nrepresentation of the data, which shows a well-defied clustering structure\ncapturing the customers' creditworthiness. These clusters are well suited for\nthe aforementioned banks' activities. Further, our methodology generalizes to\nnew customers, captures high-dimensional and complex financial data, and scales\nto large data sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:09:47 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Mancisidor", "Rogelio A", ""], ["Kampffmeyer", "Michael", ""], ["Aas", "Kjersti", ""], ["Jenssen", "Robert", ""]]}, {"id": "1903.06581", "submitter": "Duo Wang", "authors": "Duo Wang, Mateja Jamnik, Pietro Lio", "title": "Unsupervised and interpretable scene discovery with\n  Discrete-Attend-Infer-Repeat", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present Discrete Attend Infer Repeat (Discrete-AIR), a\nRecurrent Auto-Encoder with structured latent distributions containing discrete\ncategorical distributions, continuous attribute distributions, and factorised\nspatial attention. While inspired by the original AIR model andretaining AIR\nmodel's capability in identifying objects in an image, Discrete-AIR provides\ndirect interpretability of the latent codes. We show that for Multi-MNIST and a\nmultiple-objects version of dSprites dataset, the Discrete-AIR model needs just\none categorical latent variable, one attribute variable (for Multi-MNIST only),\ntogether with spatial attention variables, for efficient inference. We perform\nanalysis to show that the learnt categorical distributions effectively capture\nthe categories of objects in the scene for Multi-MNIST and for Multi-Sprites.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 16:30:27 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Wang", "Duo", ""], ["Jamnik", "Mateja", ""], ["Lio", "Pietro", ""]]}, {"id": "1903.06592", "submitter": "Samir Wadhwania", "authors": "Samir Wadhwania, Dong-Ki Kim, Shayegan Omidshafiei, and Jonathan P.\n  How", "title": "Policy Distillation and Value Matching in Multiagent Reinforcement\n  Learning", "comments": "Submitted as a conference paper to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent reinforcement learning algorithms (MARL) have been demonstrated on\ncomplex tasks that require the coordination of a team of multiple agents to\ncomplete. Existing works have focused on sharing information between agents via\ncentralized critics to stabilize learning or through communication to increase\nperformance, but do not generally look at how information can be shared between\nagents to address the curse of dimensionality in MARL. We posit that a\nmultiagent problem can be decomposed into a multi-task problem where each agent\nexplores a subset of the state space instead of exploring the entire state\nspace. This paper introduces a multiagent actor-critic algorithm and method for\ncombining knowledge from homogeneous agents through distillation and\nvalue-matching that outperforms policy distillation alone and allows further\nlearning in both discrete and continuous action spaces.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:13:02 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Wadhwania", "Samir", ""], ["Kim", "Dong-Ki", ""], ["Omidshafiei", "Shayegan", ""], ["How", "Jonathan P.", ""]]}, {"id": "1903.06594", "submitter": "Stefano Vigogna", "authors": "Zeljko Kereta, Stefano Vigogna, Valeriya Naumova, Lorenzo Rosasco,\n  Ernesto De Vito", "title": "Monte Carlo wavelets: a randomized approach to frame discretization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and study a family of continuous wavelets on general\ndomains, and a corresponding stochastic discretization that we call Monte Carlo\nwavelets. First, using tools from the theory of reproducing kernel Hilbert\nspaces and associated integral operators, we define a family of continuous\nwavelets by spectral calculus. Then, we propose a stochastic discretization\nbased on Monte Carlo estimates of integral operators. Using concentration of\nmeasure results, we establish the convergence of such a discretization and\nderive convergence rates under natural regularity assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:15:39 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 07:24:51 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kereta", "Zeljko", ""], ["Vigogna", "Stefano", ""], ["Naumova", "Valeriya", ""], ["Rosasco", "Lorenzo", ""], ["De Vito", "Ernesto", ""]]}, {"id": "1903.06602", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Deep Neural Network Ensembles for Time Series Classification", "comments": "Accepted at IJCNN 2019", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852316", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have revolutionized many fields such as computer vision\nand natural language processing. Inspired by this recent success, deep learning\nstarted to show promising results for Time Series Classification (TSC).\nHowever, neural networks are still behind the state-of-the-art TSC algorithms,\nthat are currently composed of ensembles of 37 non deep learning based\nclassifiers. We attribute this gap in performance due to the lack of neural\nnetwork ensembles for TSC. Therefore in this paper, we show how an ensemble of\n60 deep learning models can significantly improve upon the current\nstate-of-the-art performance of neural networks for TSC, when evaluated over\nthe UCR/UEA archive: the largest publicly available benchmark for time series\nanalysis. Finally, we show how our proposed Neural Network Ensemble (NNE) is\nthe first time series classifier to outperform COTE while reaching similar\nperformance to the current state-of-the-art ensemble HIVE-COTE.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:32:43 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 12:17:07 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1903.06603", "submitter": "Chen Liu", "authors": "Chen Liu, Ryota Tomioka, Volkan Cevher", "title": "On Certifying Non-uniform Bound against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the robustness certification problem of neural network\nmodels, which aims to find certified adversary-free regions as large as\npossible around data points. In contrast to the existing approaches that seek\nregions bounded uniformly along all input features, we consider non-uniform\nbounds and use it to study the decision boundary of neural network models. We\nformulate our target as an optimization problem with nonlinear constraints.\nThen, a framework applicable for general feedforward neural networks is\nproposed to bound the output logits so that the relaxed problem can be solved\nby the augmented Lagrangian method. Our experiments show the non-uniform bounds\nhave larger volumes than uniform ones and the geometric similarity of the\nnon-uniform bounds gives a quantitative, data-agnostic metric of input\nfeatures' robustness. Further, compared with normal models, the robust models\nhave even larger non-uniform bounds and better interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:33:44 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 22:32:54 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 11:17:43 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Liu", "Chen", ""], ["Tomioka", "Ryota", ""], ["Cevher", "Volkan", ""]]}, {"id": "1903.06631", "submitter": "Junzhe Zhang Mr", "authors": "Junzhe Zhang, Sai Ho Yeung, Yao Shu, Bingsheng He, Wei Wang", "title": "Efficient Memory Management for GPU-based Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPU (graphics processing unit) has been used for many data-intensive\napplications. Among them, deep learning systems are one of the most important\nconsumer systems for GPU nowadays. As deep learning applications impose deeper\nand larger models in order to achieve higher accuracy, memory management\nbecomes an important research topic for deep learning systems, given that GPU\nhas limited memory size. Many approaches have been proposed towards this issue,\ne.g., model compression and memory swapping. However, they either degrade the\nmodel accuracy or require a lot of manual intervention. In this paper, we\npropose two orthogonal approaches to reduce the memory cost from the system\nperspective. Our approaches are transparent to the models, and thus do not\naffect the model accuracy. They are achieved by exploiting the iterative nature\nof the training algorithm of deep learning to derive the lifetime and\nread/write order of all variables. With the lifetime semantics, we are able to\nimplement a memory pool with minimal fragments. However, the optimization\nproblem is NP-complete. We propose a heuristic algorithm that reduces up to\n13.3% of memory compared with Nvidia's default memory pool with equal time\ncomplexity. With the read/write semantics, the variables that are not in use\ncan be swapped out from GPU to CPU to reduce the memory footprint. We propose\nmultiple swapping strategies to automatically decide which variable to swap and\nwhen to swap out (in), which reduces the memory cost by up to 34.2% without\ncommunication overhead.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 08:33:04 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Zhang", "Junzhe", ""], ["Yeung", "Sai Ho", ""], ["Shu", "Yao", ""], ["He", "Bingsheng", ""], ["Wang", "Wei", ""]]}, {"id": "1903.06638", "submitter": "Panagiota Kiourti", "authors": "Panagiota Kiourti, Kacper Wardega, Susmit Jha, Wenchao Li", "title": "TrojDRL: Trojan Attacks on Deep Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has identified that classification models implemented as neural\nnetworks are vulnerable to data-poisoning and Trojan attacks at training time.\nIn this work, we show that these training-time vulnerabilities extend to deep\nreinforcement learning (DRL) agents and can be exploited by an adversary with\naccess to the training process. In particular, we focus on Trojan attacks that\naugment the function of reinforcement learning policies with hidden behaviors.\nWe demonstrate that such attacks can be implemented through minuscule data\npoisoning (as little as 0.025% of the training data) and in-band reward\nmodification that does not affect the reward on normal inputs. The policies\nlearned with our proposed attack approach perform imperceptibly similar to\nbenign policies but deteriorate drastically when the Trojan is triggered in\nboth targeted and untargeted settings. Furthermore, we show that existing\nTrojan defense mechanisms for classification tasks are not effective in the\nreinforcement learning setting.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 04:17:32 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Kiourti", "Panagiota", ""], ["Wardega", "Kacper", ""], ["Jha", "Susmit", ""], ["Li", "Wenchao", ""]]}, {"id": "1903.06661", "submitter": "Kar Wai Lim", "authors": "Quoc Phong Nguyen, Kar Wai Lim, Dinil Mon Divakaran, Kian Hsiang Low,\n  Mun Choon Chan", "title": "GEE: A Gradient-based Explainable Variational Autoencoder for Network\n  Anomaly Detection", "comments": "to appear in 2019 IEEE Conference on Communications and Network\n  Security (CNS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper looks into the problem of detecting network anomalies by analyzing\nNetFlow records. While many previous works have used statistical models and\nmachine learning techniques in a supervised way, such solutions have the\nlimitations that they require large amount of labeled data for training and are\nunlikely to detect zero-day attacks. Existing anomaly detection solutions also\ndo not provide an easy way to explain or identify attacks in the anomalous\ntraffic. To address these limitations, we develop and present GEE, a framework\nfor detecting and explaining anomalies in network traffic. GEE comprises of two\ncomponents: (i) Variational Autoencoder (VAE) - an unsupervised deep-learning\ntechnique for detecting anomalies, and (ii) a gradient-based fingerprinting\ntechnique for explaining anomalies. Evaluation of GEE on the recent UGR dataset\ndemonstrates that our approach is effective in detecting different anomalies as\nwell as identifying fingerprints that are good representations of these various\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 16:58:34 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Nguyen", "Quoc Phong", ""], ["Lim", "Kar Wai", ""], ["Divakaran", "Dinil Mon", ""], ["Low", "Kian Hsiang", ""], ["Chan", "Mun Choon", ""]]}, {"id": "1903.06668", "submitter": "Ekaterina Abramova", "authors": "Ekaterina Abramova and Derek Bunn", "title": "Estimating Dynamic Conditional Spread Densities to Optimise Daily\n  Storage Trading of Electricity", "comments": "59 pages, 37 figures, CEMA 2019, POM Special Issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG econ.EM q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates dynamic density functions, based upon skewed-t and\nsimilar representations, to model and forecast electricity price spreads\nbetween different hours of the day. This supports an optimal day ahead storage\nand discharge schedule, and thereby facilitates a bidding strategy for a\nmerchant arbitrage facility into the day-ahead auctions for wholesale\nelectricity. The four latent moments of the density functions are dynamic and\nconditional upon exogenous drivers, thereby permitting the mean, variance,\nskewness and kurtosis of the densities to respond hourly to such factors as\nweather and demand forecasts. The best specification for each spread is\nselected based on the Pinball Loss function, following the closed form\nanalytical solutions of the cumulative density functions. Those analytical\nproperties also allow the calculation of risk associated with the spread\narbitrages. From these spread densities, the optimal daily operation of a\nbattery storage facility is determined.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 20:33:21 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Abramova", "Ekaterina", ""], ["Bunn", "Derek", ""]]}, {"id": "1903.06675", "submitter": "Bal\\'azs Dobi", "authors": "Bal\\'azs Dobi and Andr\\'as Zempl\\'eni", "title": "Markov Chain-based Cost-Optimal Control Charts for Healthcare Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control charts have traditionally been used in industrial statistics, but are\nconstantly seeing new areas of application, especially in the age of Industry\n4.0. This paper introduces a new method, which is suitable for applications in\nthe healthcare sector, especially for monitoring a health-characteristic of a\npatient. We adapt a Markov chain-based approach and develop a method in which\nnot only the shift size (i.e. the degradation of the patient's health) can be\nrandom, but the effect of the repair (i.e. treatment) and time between\nsamplings (i.e. visits) too. This means that we do not use many often-present\nassumptions which are usually not applicable for medical treatments. The\naverage cost of the protocol, which is determined by the time between samplings\nand the control limit, can be estimated using the stationary distribution of\nthe Markov chain.\n  Furthermore, we incorporate the standard deviation of the cost into the\noptimisation procedure, which is often very important from a process control\nviewpoint. The sensitivity of the optimal parameters and the resulting average\ncost and cost standard deviation on different parameter values is investigated.\nWe demonstrate the usefulness of the approach for real-life data of patients\ntreated in Hungary: namely the monitoring of cholesterol level of patients with\ncardiovascular event risk. The results showed that the optimal parameters from\nour approach can be somewhat different from the original medical parameters.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 13:01:06 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Dobi", "Bal\u00e1zs", ""], ["Zempl\u00e9ni", "Andr\u00e1s", ""]]}, {"id": "1903.06694", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy, Karun Raju Vysyaraju, Willie Neiswanger,\n  Biswajit Paria, Christopher R. Collins, Jeff Schneider, Barnabas Poczos, Eric\n  P. Xing", "title": "Tuning Hyperparameters without Grad Students: Scalable and Robust\n  Bayesian Optimisation with Dragonfly", "comments": "Journal of Machine Learning Research 2020, Special Issue on Bayesian\n  Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimisation (BO) refers to a suite of techniques for global\noptimisation of expensive black box functions, which use introspective Bayesian\nmodels of the function to efficiently search for the optimum. While BO has been\napplied successfully in many applications, modern optimisation tasks usher in\nnew challenges where conventional methods fail spectacularly. In this work, we\npresent Dragonfly, an open source Python library for scalable and robust BO.\nDragonfly incorporates multiple recently developed methods that allow BO to be\napplied in challenging real world settings; these include better methods for\nhandling higher dimensional domains, methods for handling multi-fidelity\nevaluations when cheap approximations of an expensive function are available,\nmethods for optimising over structured combinatorial spaces, such as the space\nof neural network architectures, and methods for handling parallel evaluations.\nAdditionally, we develop new methodological improvements in BO for selecting\nthe Bayesian model, selecting the acquisition function, and optimising over\ncomplex domains with different variable types and additional constraints. We\ncompare Dragonfly to a suite of other packages and algorithms for global\noptimisation and demonstrate that when the above methods are integrated, they\nenable significant improvements in the performance of BO. The Dragonfly library\nis available at dragonfly.github.io.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 17:45:39 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 18:09:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Vysyaraju", "Karun Raju", ""], ["Neiswanger", "Willie", ""], ["Paria", "Biswajit", ""], ["Collins", "Christopher R.", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""], ["Xing", "Eric P.", ""]]}, {"id": "1903.06700", "submitter": "Sanjeev Raja", "authors": "Sanjeev Raja, Ernest Fokou\\'e", "title": "Multi-Stage Fault Warning for Large Electric Grids Using Anomaly\n  Detection and Machine Learning", "comments": "13 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the monitoring of a complex electric grid, it is of paramount importance\nto provide operators with early warnings of anomalies detected on the network,\nalong with a precise classification and diagnosis of the specific fault type.\nIn this paper, we propose a novel multi-stage early warning system prototype\nfor electric grid fault detection, classification, subgroup discovery, and\nvisualization. In the first stage, a computationally efficient anomaly\ndetection method based on quartiles detects the presence of a fault in real\ntime. In the second stage, the fault is classified into one of nine pre-defined\ndisaster scenarios. The time series data are first mapped to highly\ndiscriminative features by applying dimensionality reduction based on temporal\nautocorrelation. The features are then mapped through one of three\nclassification techniques: support vector machine, random forest, and\nartificial neural network. Finally in the third stage, intra-class clustering\nbased on dynamic time warping is used to characterize the fault with further\ngranularity. Results on the Bonneville Power Administration electric grid data\nshow that i) the proposed anomaly detector is both fast and accurate; ii)\ndimensionality reduction leads to dramatic improvement in classification\naccuracy and speed; iii) the random forest method offers the most accurate,\nconsistent, and robust fault classification; and iv) time series within a given\nclass naturally separate into five distinct clusters which correspond closely\nto the geographical distribution of electric grid buses.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 17:52:39 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Raja", "Sanjeev", ""], ["Fokou\u00e9", "Ernest", ""]]}, {"id": "1903.06701", "submitter": "Marco Canini", "authors": "Amedeo Sapio, Marco Canini, Chen-Yu Ho, Jacob Nelson, Panos Kalnis,\n  Changhoon Kim, Arvind Krishnamurthy, Masoud Moshref, Dan R. K. Ports, Peter\n  Richt\\'arik", "title": "Scaling Distributed Machine Learning with In-Network Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models in parallel is an increasingly important\nworkload. We accelerate distributed parallel training by designing a\ncommunication primitive that uses a programmable switch dataplane to execute a\nkey step of the training process. Our approach, SwitchML, reduces the volume of\nexchanged data by aggregating the model updates from multiple workers in the\nnetwork. We co-design the switch processing with the end-host protocols and ML\nframeworks to provide an efficient solution that speeds up training by up to\n5.5$\\times$ for a number of real-world benchmark models.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 15:10:21 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:26:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Sapio", "Amedeo", ""], ["Canini", "Marco", ""], ["Ho", "Chen-Yu", ""], ["Nelson", "Jacob", ""], ["Kalnis", "Panos", ""], ["Kim", "Changhoon", ""], ["Krishnamurthy", "Arvind", ""], ["Moshref", "Masoud", ""], ["Ports", "Dan R. K.", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1903.06727", "submitter": "Masoud Badiei Khuzani", "authors": "Masoud Badiei Khuzani, Varun Vasudevan, Hongyi Ren, Lei Xing", "title": "On Sample Complexity of Projection-Free Primal-Dual Methods for Learning\n  Mixture Policies in Markov Decision Processes", "comments": "Manuscript accepted to 58th CDC, 31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning policy of an infinite-horizon, discounted\ncost, Markov decision process (MDP) with a large number of states. We compute\nthe actions of a policy that is nearly as good as a policy chosen by a suitable\noracle from a given mixture policy class characterized by the convex hull of a\nset of known base policies. To learn the coefficients of the mixture model, we\nrecast the problem as an approximate linear programming (ALP) formulation for\nMDPs, where the feature vectors correspond to the occupation measures of the\nbase policies defined on the state-action space. We then propose a\nprojection-free stochastic primal-dual method with the Bregman divergence to\nsolve the characterized ALP. Furthermore, we analyze the probably approximately\ncorrect (PAC) sample complexity of the proposed stochastic algorithm, namely\nthe number of queries required to achieve near optimal objective value. We also\npropose a modification of our proposed algorithm with the polytope constraint\nsampling for the smoothed ALP, where the restriction to lower bounding\napproximations are relaxed. In addition, we apply the proposed algorithms to a\nqueuing problem, and compare their performance with a penalty function\nalgorithm. The numerical results illustrates that the primal-dual achieves\nbetter efficiency and low variance across different trials compared to the\npenalty function method.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:14:55 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 18:04:23 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 17:03:23 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Khuzani", "Masoud Badiei", ""], ["Vasudevan", "Varun", ""], ["Ren", "Hongyi", ""], ["Xing", "Lei", ""]]}, {"id": "1903.06733", "submitter": "Yeonjong Shin", "authors": "Lu Lu, Yeonjong Shin, Yanhui Su, George Em Karniadakis", "title": "Dying ReLU and Initialization: Theory and Numerical Examples", "comments": null, "journal-ref": null, "doi": "10.4208/cicp.OA-2020-0165", "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The dying ReLU refers to the problem when ReLU neurons become inactive and\nonly output 0 for any input. There are many empirical and heuristic\nexplanations of why ReLU neurons die. However, little is known about its\ntheoretical analysis. In this paper, we rigorously prove that a deep ReLU\nnetwork will eventually die in probability as the depth goes to infinite.\nSeveral methods have been proposed to alleviate the dying ReLU. Perhaps, one of\nthe simplest treatments is to modify the initialization procedure. One common\nway of initializing weights and biases uses symmetric probability\ndistributions, which suffers from the dying ReLU. We thus propose a new\ninitialization procedure, namely, a randomized asymmetric initialization. We\nprove that the new initialization can effectively prevent the dying ReLU. All\nparameters required for the new initialization are theoretically designed.\nNumerical examples are provided to demonstrate the effectiveness of the new\ninitialization procedure.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:23:55 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 23:15:23 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 19:19:02 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Lu", "Lu", ""], ["Shin", "Yeonjong", ""], ["Su", "Yanhui", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1903.06740", "submitter": "Navoneel Chakrabarty", "authors": "Navoneel Chakrabarty", "title": "A Data Mining Approach to Flight Arrival Delay Prediction for American\n  Airlines", "comments": "The 9th Annual Information Technology, Electromechanical and\n  Microelectronics Conference (IEMECON 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present scenario of domestic flights in USA, there have been numerous\ninstances of flight delays and cancellations. In the United States, the\nAmerican Airlines, Inc. have been one of the most entrusted and the world's\nlargest airline in terms of number of destinations served. But when it comes to\ndomestic flights, AA has not lived up to the expectations in terms of\npunctuality or on-time performance. Flight Delays also result in airline\ncompanies operating commercial flights to incur huge losses. So, they are\ntrying their best to prevent or avoid Flight Delays and Cancellations by taking\ncertain measures. This study aims at analyzing flight information of US\ndomestic flights operated by American Airlines, covering top 5 busiest airports\nof US and predicting possible arrival delay of the flight using Data Mining and\nMachine Learning Approaches. The Gradient Boosting Classifier Model is deployed\nby training and hyper-parameter tuning it, achieving a maximum accuracy of\n85.73%. Such an Intelligent System is very essential in foretelling\nflights'on-time performance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:37:03 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Chakrabarty", "Navoneel", ""]]}, {"id": "1903.06751", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Juho Kanniainen, Moncef Gabbouj, Alexandros Iosifidis", "title": "Data-driven Neural Architecture Learning For Financial Time-series\n  Forecasting", "comments": "Accepted in DISP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting based on financial time-series is a challenging task since most\nreal-world data exhibits nonstationary property and nonlinear dependencies. In\naddition, different data modalities often embed different nonlinear\nrelationships which are difficult to capture by human-designed models. To\ntackle the supervised learning task in financial time-series prediction, we\npropose the application of a recently formulated algorithm that adaptively\nlearns a mapping function, realized by a heterogeneous neural architecture\ncomposing of Generalized Operational Perceptron, given a set of labeled data.\nWith a modified objective function, the proposed algorithm can accommodate the\nfrequently observed imbalanced data distribution problem. Experiments on a\nlarge-scale Limit Order Book dataset demonstrate that the proposed algorithm\noutperforms related algorithms, including tensor-based methods which have\naccess to a broader set of input information.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 11:32:26 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1903.06753", "submitter": "Cheng Cheng", "authors": "Cheng Cheng, Beitong Zhou, Guijun Ma, Dongrui Wu and Ye Yuan", "title": "Wasserstein Distance based Deep Adversarial Transfer Learning for\n  Intelligent Fault Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand of artificial intelligent adoption for condition-based maintenance\nstrategy is astonishingly increased over the past few years. Intelligent fault\ndiagnosis is one critical topic of maintenance solution for mechanical systems.\nDeep learning models, such as convolutional neural networks (CNNs), have been\nsuccessfully applied to fault diagnosis tasks for mechanical systems and\nachieved promising results. However, for diverse working conditions in the\nindustry, deep learning suffers two difficulties: one is that the well-defined\n(source domain) and new (target domain) datasets are with different feature\ndistributions; another one is the fact that insufficient or no labelled data in\ntarget domain significantly reduce the accuracy of fault diagnosis. As a novel\nidea, deep transfer learning (DTL) is created to perform learning in the target\ndomain by leveraging information from the relevant source domain. Inspired by\nWasserstein distance of optimal transport, in this paper, we propose a novel\nDTL approach to intelligent fault diagnosis, namely Wasserstein Distance based\nDeep Transfer Learning (WD-DTL), to learn domain feature representations\n(generated by a CNN based feature extractor) and to minimize the distributions\nbetween the source and target domains through adversarial training. The\neffectiveness of the proposed WD-DTL is verified through 3 transfer scenarios\nand 16 transfer fault diagnosis experiments of both unsupervised and supervised\n(with insufficient labelled data) learning. We also provide a comprehensive\nanalysis of the network visualization of those transfer tasks.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 08:48:23 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Cheng", "Cheng", ""], ["Zhou", "Beitong", ""], ["Ma", "Guijun", ""], ["Wu", "Dongrui", ""], ["Yuan", "Ye", ""]]}, {"id": "1903.06754", "submitter": "Ruohan Zhang", "authors": "Ruohan Zhang, Calen Walshe, Zhuode Liu, Lin Guan, Karl S. Muller, Jake\n  A. Whritner, Luxin Zhang, Mary M. Hayhoe, Dana H. Ballard", "title": "Atari-HEAD: Atari Human Eye-Tracking and Demonstration Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale public datasets have been shown to benefit research in multiple\nareas of modern artificial intelligence. For decision-making research that\nrequires human data, high-quality datasets serve as important benchmarks to\nfacilitate the development of new methods by providing a common reproducible\nstandard. Many human decision-making tasks require visual attention to obtain\nhigh levels of performance. Therefore, measuring eye movements can provide a\nrich source of information about the strategies that humans use to solve\ndecision-making tasks. Here, we provide a large-scale, high-quality dataset of\nhuman actions with simultaneously recorded eye movements while humans play\nAtari video games. The dataset consists of 117 hours of gameplay data from a\ndiverse set of 20 games, with 8 million action demonstrations and 328 million\ngaze samples. We introduce a novel form of gameplay, in which the human plays\nin a semi-frame-by-frame manner. This leads to near-optimal game decisions and\ngame scores that are comparable or better than known human records. We\ndemonstrate the usefulness of the dataset through two simple applications:\npredicting human gaze and imitating human demonstrated actions. The quality of\nthe data leads to promising results in both tasks. Moreover, using a learned\nhuman gaze model to inform imitation learning leads to an 115\\% increase in\ngame performance. We interpret these results as highlighting the importance of\nincorporating human visual attention in models of decision making and\ndemonstrating the value of the current dataset to the research community. We\nhope that the scale and quality of this dataset can provide more opportunities\nto researchers in the areas of visual attention, imitation learning, and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:55:07 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 20:17:17 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhang", "Ruohan", ""], ["Walshe", "Calen", ""], ["Liu", "Zhuode", ""], ["Guan", "Lin", ""], ["Muller", "Karl S.", ""], ["Whritner", "Jake A.", ""], ["Zhang", "Luxin", ""], ["Hayhoe", "Mary M.", ""], ["Ballard", "Dana H.", ""]]}, {"id": "1903.06756", "submitter": "Ibrahim AlZuabi", "authors": "Ibrahim Mousa AlZuabi, Assef Jafar and Kadan Aljoumaa", "title": "Predicting customer's gender and age depending on mobile phone data", "comments": null, "journal-ref": null, "doi": "10.1186/s40537-019-0180-9", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of data driven solution, the customer demographic attributes, such\nas gender and age, play a core role that may enable companies to enhance the\noffers of their services and target the right customer in the right time and\nplace. In the marketing campaign, the companies want to target the real user of\nthe GSM (global system for mobile communications), not the line owner. Where\nsometimes they may not be the same. This work proposes a method that predicts\nusers' gender and age based on their behavior, services and contract\ninformation. We used call detail records (CDRs), customer relationship\nmanagement (CRM) and billing information as a data source to analyze telecom\ncustomer behavior, and applied different types of machine learning algorithms\nto provide marketing campaigns with more accurate information about customer\ndemographic attributes. This model is built using reliable data set of 18,000\nusers provided by SyriaTel Telecom Company, for training and testing. The model\napplied by using big data technology and achieved 85.6% accuracy in terms of\nuser gender prediction and 65.5% of user age prediction. The main contribution\nof this work is the improvement in the accuracy in terms of user gender\nprediction and user age prediction based on mobile phone data and end-to-end\nsolution that approaches customer data from multiple aspects in the telecom\ndomain.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 07:46:13 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["AlZuabi", "Ibrahim Mousa", ""], ["Jafar", "Assef", ""], ["Aljoumaa", "Kadan", ""]]}, {"id": "1903.06758", "submitter": "Changliu Liu", "authors": "Changliu Liu, Tomer Arnon, Christopher Lazarus, Christopher Strong,\n  Clark Barrett, Mykel J. Kochenderfer", "title": "Algorithms for Verifying Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used for nonlinear function approximation\nwith applications ranging from computer vision to control. Although these\nnetworks involve the composition of simple arithmetic operations, it can be\nvery challenging to verify whether a particular network satisfies certain\ninput-output properties. This article surveys methods that have emerged\nrecently for soundly verifying such properties. These methods borrow insights\nfrom reachability analysis, optimization, and search. We discuss fundamental\ndifferences and connections between existing algorithms. In addition, we\nprovide pedagogical implementations of existing methods and compare them on a\nset of benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 19:02:38 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 21:06:08 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Liu", "Changliu", ""], ["Arnon", "Tomer", ""], ["Lazarus", "Christopher", ""], ["Strong", "Christopher", ""], ["Barrett", "Clark", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.06781", "submitter": "Shay Deutsch Dr.", "authors": "Shay Deutsch, Andrea Bertozzi, and Stefano Soatto", "title": "Zero Shot Learning with the Isoperimetric Loss", "comments": "Accepted to AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the isoperimetric loss as a regularization criterion for\nlearning the map from a visual representation to a semantic embedding, to be\nused to transfer knowledge to unknown classes in a zero-shot learning setting.\nWe use a pre-trained deep neural network model as a visual representation of\nimage data, a Word2Vec embedding of class labels, and linear maps between the\nvisual and semantic embedding spaces. However, the spaces themselves are not\nlinear, and we postulate the sample embedding to be populated by noisy samples\nnear otherwise smooth manifolds. We exploit the graph structure defined by the\nsample points to regularize the estimates of the manifolds by inferring the\ngraph connectivity using a generalization of the isoperimetric inequalities\nfrom Riemannian geometry to graphs. Surprisingly, this regularization alone,\npaired with the simplest baseline model, outperforms the state-of-the-art among\nfully automated methods in zero-shot learning benchmarks such as AwA and CUB.\nThis improvement is achieved solely by learning the structure of the underlying\nspaces by imposing regularity.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 19:55:38 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 19:17:12 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Deutsch", "Shay", ""], ["Bertozzi", "Andrea", ""], ["Soatto", "Stefano", ""]]}, {"id": "1903.06787", "submitter": "Eren Balevi", "authors": "Eren Balevi, Jeffrey G. Andrews", "title": "Online Antenna Tuning in Heterogeneous Cellular Networks with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to jointly optimize antenna tilt angle, and vertical and horizontal\nhalf-power beamwidths of the macrocells in a heterogeneous cellular network\n(HetNet). The interactions between the cells, most notably due to their coupled\ninterference render this optimization prohibitively complex. Utilizing a single\nagent reinforcement learning (RL) algorithm for this optimization becomes quite\nsuboptimum despite its scalability, whereas multi-agent RL algorithms yield\nbetter solutions at the expense of scalability. Hence, we propose a compromise\nalgorithm between these two. Specifically, a multi-agent mean field RL\nalgorithm is first utilized in the offline phase so as to transfer information\nas features for the second (online) phase single agent RL algorithm, which\nemploys a deep neural network to learn users locations. This two-step approach\nis a practical solution for real deployments, which should automatically adapt\nto environmental changes in the network. Our results illustrate that the\nproposed algorithm approaches the performance of the multi-agent RL, which\nrequires millions of trials, with hundreds of online trials, assuming\nrelatively low environmental dynamics, and performs much better than a single\nagent RL. Furthermore, the proposed algorithm is compact and implementable, and\nempirically appears to provide a performance guarantee regardless of the amount\nof environmental dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 20:23:18 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 22:36:32 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Balevi", "Eren", ""], ["Andrews", "Jeffrey G.", ""]]}, {"id": "1903.06800", "submitter": "Alessandro Betti", "authors": "Lorenzo Gigoni, Alessandro Betti, Emanuele Crisostomi, Alessandro\n  Franco, Mauro Tucci, Fabrizio Bizzarri, Debora Mucci", "title": "Day-Ahead Hourly Forecasting of Power Generation from Photovoltaic\n  Plants", "comments": "Preprint of IEEE Transactions of Sustainable Energy, Vol. 9, Issue 2,\n  pp. 831 - 842 (2018)", "journal-ref": "IEEE Transactions of Sustainable Energy, Vol. 9, Issue 2, pp. 831\n  - 842 (2018)", "doi": "10.1109/TSTE.2017.2762435", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately forecast power generation from renewable sources is\nnowadays recognised as a fundamental skill to improve the operation of power\nsystems. Despite the general interest of the power community in this topic, it\nis not always simple to compare different forecasting methodologies, and infer\nthe impact of single components in providing accurate predictions. In this\npaper we extensively compare simple forecasting methodologies with more\nsophisticated ones over 32 photovoltaic plants of different size and technology\nover a whole year. Also, we try to evaluate the impact of weather conditions\nand weather forecasts on the prediction of PV power generation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 11:29:18 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Gigoni", "Lorenzo", ""], ["Betti", "Alessandro", ""], ["Crisostomi", "Emanuele", ""], ["Franco", "Alessandro", ""], ["Tucci", "Mauro", ""], ["Bizzarri", "Fabrizio", ""], ["Mucci", "Debora", ""]]}, {"id": "1903.06877", "submitter": "Qiuwei Li", "authors": "Kai Liu, Qiuwei Li, Hua Wang, Gongguo Tang", "title": "Spherical Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) is one of the most important methods to\nhandle high dimensional data. However, most of the studies on PCA aim to\nminimize the loss after projection, which usually measures the Euclidean\ndistance, though in some fields, angle distance is known to be more important\nand critical for analysis. In this paper, we propose a method by adding\nconstraints on factors to unify the Euclidean distance and angle distance.\nHowever, due to the nonconvexity of the objective and constraints, the\noptimized solution is not easy to obtain. We propose an alternating linearized\nminimization method to solve it with provable convergence rate and guarantee.\nExperiments on synthetic data and real-world datasets have validated the\neffectiveness of our method and demonstrated its advantages over state-of-art\nclustering methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 04:18:33 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Liu", "Kai", ""], ["Li", "Qiuwei", ""], ["Wang", "Hua", ""], ["Tang", "Gongguo", ""]]}, {"id": "1903.06928", "submitter": "Ali Al-Aradi", "authors": "Ali Al-Aradi and Sebastian Jaimungal", "title": "Active and Passive Portfolio Management with Latent Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a portfolio selection problem that combines active\n(outperformance) and passive (tracking) objectives using techniques from convex\nanalysis. We assume a general semimartingale market model where the assets'\ngrowth rate processes are driven by a latent factor. Using techniques from\nconvex analysis we obtain a closed-form solution for the optimal portfolio and\nprovide a theorem establishing its uniqueness. The motivation for incorporating\nlatent factors is to achieve improved growth rate estimation, an otherwise\nnotoriously difficult task. To this end, we focus on a model where growth rates\nare driven by an unobservable Markov chain. The solution in this case requires\na filtering step to obtain posterior probabilities for the state of the Markov\nchain from asset price information, which are subsequently used to find the\noptimal allocation. We show the optimal strategy is the posterior average of\nthe optimal strategies the investor would have held in each state assuming the\nMarkov chain remains in that state. Finally, we implement a number of\nhistorical backtests to demonstrate the performance of the optimal portfolio.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 14:10:44 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Al-Aradi", "Ali", ""], ["Jaimungal", "Sebastian", ""]]}, {"id": "1903.06996", "submitter": "Cong Xie", "authors": "Cong Xie, Sanmi Koyejo, Indranil Gupta", "title": "SLSGD: Secure and Efficient Distributed On-device Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed on-device learning with limited communication and\nsecurity requirements. We propose a new robust distributed optimization\nalgorithm with efficient communication and attack tolerance. The proposed\nalgorithm has provable convergence and robustness under non-IID settings.\nEmpirical results show that the proposed algorithm stabilizes the convergence\nand tolerates data poisoning on a small number of workers.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 22:25:20 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 16:53:40 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 20:12:18 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Sanmi", ""], ["Gupta", "Indranil", ""]]}, {"id": "1903.07020", "submitter": "Cong Xie", "authors": "Cong Xie, Sanmi Koyejo, Indranil Gupta", "title": "Zeno++: Robust Fully Asynchronous SGD", "comments": "ICML version with some additional remarks related to the acceptance\n  rate of Byzantine validation, and also with the full version of error bounds\n  in the theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Zeno++, a new robust asynchronous Stochastic Gradient\nDescent~(SGD) procedure which tolerates Byzantine failures of the workers. In\ncontrast to previous work, Zeno++ removes some unrealistic restrictions on\nworker-server communications, allowing for fully asynchronous updates from\nanonymous workers, arbitrarily stale worker updates, and the possibility of an\nunbounded number of Byzantine workers. The key idea is to estimate the descent\nof the loss value after the candidate gradient is applied, where large descent\nvalues indicate that the update results in optimization progress. We prove the\nconvergence of Zeno++ for non-convex problems under Byzantine failures.\nExperimental results show that Zeno++ outperforms existing approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 03:02:32 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 05:22:43 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 08:19:39 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 22:01:24 GMT"}, {"version": "v5", "created": "Sun, 9 May 2021 17:42:44 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Sanmi", ""], ["Gupta", "Indranil", ""]]}, {"id": "1903.07045", "submitter": "Ali Mirzaei", "authors": "Ali Mirzaei, Vahid Pourahmadi, Mehran Soltani, Hamid Sheikhzadeh", "title": "Deep Feature Selection using a Teacher-Student Network", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data in many machine learning applications leads to\ncomputational and analytical complexities. Feature selection provides an\neffective way for solving these problems by removing irrelevant and redundant\nfeatures, thus reducing model complexity and improving accuracy and\ngeneralization capability of the model. In this paper, we present a novel\nteacher-student feature selection (TSFS) method in which a 'teacher' (a deep\nneural network or a complicated dimension reduction method) is first employed\nto learn the best representation of data in low dimension. Then a 'student'\nnetwork (a simple neural network) is used to perform feature selection by\nminimizing the reconstruction error of low dimensional representation. Although\nthe teacher-student scheme is not new, to the best of our knowledge, it is the\nfirst time that this scheme is employed for feature selection. The proposed\nTSFS can be used for both supervised and unsupervised feature selection. This\nmethod is evaluated on different datasets and is compared with state-of-the-art\nexisting feature selection methods. The results show that TSFS performs better\nin terms of classification and clustering accuracies and reconstruction error.\nMoreover, experimental evaluations demonstrate a low degree of sensitivity to\nparameter selection in the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 09:07:41 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Mirzaei", "Ali", ""], ["Pourahmadi", "Vahid", ""], ["Soltani", "Mehran", ""], ["Sheikhzadeh", "Hamid", ""]]}, {"id": "1903.07050", "submitter": "Arunselvan Ramaswamy Dr.", "authors": "Arunselvan Ramaswamy", "title": "DSPG: Decentralized Simultaneous Perturbations Gradient Descent Scheme", "comments": "6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed descent-based methods are an essential toolset to solving\noptimization problems in multi-agent system scenarios. Here the agents seek to\noptimize a global objective function through mutual cooperation. Oftentimes,\ncooperation is achieved over a wireless communication network that is prone to\ndelays and errors. There are many scenarios wherein the objective function is\neither non-differentiable or merely observable. In this paper, we present a\ncross-entropy based distributed stochastic approximation algorithm (SA) that\nfinds a minimum of the objective, using only samples. We call this algorithm\nDecentralized Simultaneous Perturbation Stochastic Gradient, with Constant\nSensitivity Parameters (DSPG). This algorithm is a two fold improvement over\nthe classic Simultaneous Perturbation Stochastic Approximations (SPSA)\nalgorithm. Specifically, DSPG allows for (i) the use of old information from\nother agents and (ii) easy implementation through the use simple\nhyper-parameter choices. We analyze the biases and variances that arise due to\nthese two allowances. We show that the biases due to communication delays can\nbe countered by a careful choice of algorithm hyper-parameters. The variance of\nthe gradient estimator and its effect on the rate of convergence is studied. We\npresent numerical results supporting our theory. Finally, we discuss an\napplication to the stochastic consensus problem.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 09:51:18 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 10:31:43 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ramaswamy", "Arunselvan", ""]]}, {"id": "1903.07054", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Adversarial Attacks on Deep Neural Networks for Time Series\n  Classification", "comments": "Accepted at IJCNN 2019", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8851936", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series Classification (TSC) problems are encountered in many real life\ndata mining tasks ranging from medicine and security to human activity\nrecognition and food safety. With the recent success of deep neural networks in\nvarious domains such as computer vision and natural language processing,\nresearchers started adopting these techniques for solving time series data\nmining problems. However, to the best of our knowledge, no previous work has\nconsidered the vulnerability of deep learning models to adversarial time series\nexamples, which could potentially make them unreliable in situations where the\ndecision taken by the classifier is crucial such as in medicine and security.\nFor computer vision problems, such attacks have been shown to be very easy to\nperform by altering the image and adding an imperceptible amount of noise to\ntrick the network into wrongly classifying the input image. Following this line\nof work, we propose to leverage existing adversarial attack mechanisms to add a\nspecial noise to the input time series in order to decrease the network's\nconfidence when classifying instances at test time. Our results reveal that\ncurrent state-of-the-art deep learning time series classifiers are vulnerable\nto adversarial attacks which can have major consequences in multiple domains\nsuch as food safety and quality assurance.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 10:04:23 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 12:21:18 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1903.07058", "submitter": "Kai Tian", "authors": "Kai Tian, Shuigeng Zhou, Jianping Fan, Jihong Guan", "title": "Learning Competitive and Discriminative Reconstructions for Anomaly\n  Detection", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing methods for anomaly detection use only positive data to\nlearn the data distribution, thus they usually need a pre-defined threshold at\nthe detection stage to determine whether a test instance is an outlier.\nUnfortunately, a good threshold is vital for the performance and it is really\nhard to find an optimal one. In this paper, we take the discriminative\ninformation implied in unlabeled data into consideration and propose a new\nmethod for anomaly detection that can learn the labels of unlabelled data\ndirectly. Our proposed method has an end-to-end architecture with one encoder\nand two decoders that are trained to model inliers and outliers' data\ndistributions in a competitive way. This architecture works in a discriminative\nmanner without suffering from overfitting, and the training algorithm of our\nmodel is adopted from SGD, thus it is efficient and scalable even for\nlarge-scale datasets. Empirical studies on 7 datasets including KDD99, MNIST,\nCaltech-256, and ImageNet etc. show that our model outperforms the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 11:02:24 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Tian", "Kai", ""], ["Zhou", "Shuigeng", ""], ["Fan", "Jianping", ""], ["Guan", "Jihong", ""]]}, {"id": "1903.07082", "submitter": "Maryam Aziz", "authors": "Maryam Aziz, Emilie Kaufmann, Marie-Karelle Riviere", "title": "On Multi-Armed Bandit Designs for Dose-Finding Clinical Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding the optimal dosage in early stage clinical\ntrials through the multi-armed bandit lens. We advocate the use of the Thompson\nSampling principle, a flexible algorithm that can accommodate different types\nof monotonicity assumptions on the toxicity and efficacy of the doses. For the\nsimplest version of Thompson Sampling, based on a uniform prior distribution\nfor each dose, we provide finite-time upper bounds on the number of sub-optimal\ndose selections, which is unprecedented for dose-finding algorithms. Through a\nlarge simulation study, we then show that variants of Thompson Sampling based\non more sophisticated prior distributions outperform state-of-the-art dose\nidentification algorithms in different types of dose-finding studies that occur\nin phase I or phase I/II trials.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 13:28:27 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 18:53:17 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Aziz", "Maryam", ""], ["Kaufmann", "Emilie", ""], ["Riviere", "Marie-Karelle", ""]]}, {"id": "1903.07120", "submitter": "Huishuai Zhang", "authors": "Huishuai Zhang, Da Yu, Mingyang Yi, Wei Chen, Tie-Yan Liu", "title": "Convergence Theory of Learning Over-parameterized ResNet: A Full\n  Characterization", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ResNet structure has achieved great empirical success since its debut. Recent\nwork established the convergence of learning over-parameterized ResNet with a\nscaling factor $\\tau=1/L$ on the residual branch where $L$ is the network\ndepth. However, it is not clear how learning ResNet behaves for other values of\n$\\tau$. In this paper, we fully characterize the convergence theory of gradient\ndescent for learning over-parameterized ResNet with different values of $\\tau$.\nSpecifically, with hiding logarithmic factor and constant coefficients, we show\nthat for $\\tau\\le 1/\\sqrt{L}$ gradient descent is guaranteed to converge to the\nglobal minma, and especially when $\\tau\\le 1/L$ the convergence is irrelevant\nof the network depth. Conversely, we show that for $\\tau>L^{-\\frac{1}{2}+c}$,\nthe forward output grows at least with rate $L^c$ in expectation and then the\nlearning fails because of gradient explosion for large $L$. This means the\nbound $\\tau\\le 1/\\sqrt{L}$ is sharp for learning ResNet with arbitrary depth.\nTo the best of our knowledge, this is the first work that studies learning\nResNet with full range of $\\tau$.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 16:15:56 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 05:45:07 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 08:03:07 GMT"}, {"version": "v4", "created": "Fri, 12 Jul 2019 08:33:44 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Zhang", "Huishuai", ""], ["Yu", "Da", ""], ["Yi", "Mingyang", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1903.07167", "submitter": "Ripon Patgiri", "authors": "Ripon Patgiri, Sabuzima Nayak, Tanya Akutota, and Bishal Paul", "title": "Machine Learning: A Dark Side of Cancer Computing", "comments": "7 Pages, 21 Figures, 2 Tables, Proceedings of the 2018 International\n  Conference on Bioinformatics and Computational Biology, pp. 92-98, 2018", "journal-ref": "Proceedings of the 2018 International Conference on Bioinformatics\n  and Computational Biology, pp. 92-98, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer analysis and prediction is the utmost important research field for\nwell-being of humankind. The Cancer data are analyzed and predicted using\nmachine learning algorithms. Most of the researcher claims the accuracy of the\npredicted results within 99%. However, we show that machine learning algorithms\ncan easily predict with an accuracy of 100% on Wisconsin Diagnostic Breast\nCancer dataset. We show that the method of gaining accuracy is an unethical\napproach that we can easily mislead the algorithms. In this paper, we exploit\nthe weakness of Machine Learning algorithms. We perform extensive experiments\nfor the correctness of our results to exploit the weakness of machine learning\nalgorithms. The methods are rigorously evaluated to validate our claim. In\naddition, this paper focuses on correctness of accuracy. This paper report\nthree key outcomes of the experiments, namely, correctness of accuracies,\nsignificance of minimum accuracy, and correctness of machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 20:44:25 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Patgiri", "Ripon", ""], ["Nayak", "Sabuzima", ""], ["Akutota", "Tanya", ""], ["Paul", "Bishal", ""]]}, {"id": "1903.07173", "submitter": "Mostafa Mehdipour Ghazi", "authors": "Mostafa Mehdipour Ghazi, Mads Nielsen, Akshay Pai, M. Jorge Cardoso,\n  Marc Modat, Sebastien Ourselin, Lauge S{\\o}rensen", "title": "Training recurrent neural networks robust to incomplete data:\n  application to Alzheimer's disease progression modeling", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.05500", "journal-ref": "Medical Image Analysis, Volume 53, Pages 39-46, 2019", "doi": "10.1016/j.media.2019.01.004", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease progression modeling (DPM) using longitudinal data is a challenging\nmachine learning task. Existing DPM algorithms neglect temporal dependencies\namong measurements, make parametric assumptions about biomarker trajectories,\ndo not model multiple biomarkers jointly, and need an alignment of subjects'\ntrajectories. In this paper, recurrent neural networks (RNNs) are utilized to\naddress these issues. However, in many cases, longitudinal cohorts contain\nincomplete data, which hinders the application of standard RNNs and requires a\npre-processing step such as imputation of the missing values. Instead, we\npropose a generalized training rule for the most widely used RNN architecture,\nlong short-term memory (LSTM) networks, that can handle both missing predictor\nand target values. The proposed LSTM algorithm is applied to model the\nprogression of Alzheimer's disease (AD) using six volumetric magnetic resonance\nimaging (MRI) biomarkers, i.e., volumes of ventricles, hippocampus, whole\nbrain, fusiform, middle temporal gyrus, and entorhinal cortex, and it is\ncompared to standard LSTM networks with data imputation and a parametric,\nregression-based DPM method. The results show that the proposed algorithm\nachieves a significantly lower mean absolute error (MAE) than the alternatives\nwith p < 0.05 using Wilcoxon signed rank test in predicting values of almost\nall of the MRI biomarkers. Moreover, a linear discriminant analysis (LDA)\nclassifier applied to the predicted biomarker values produces a significantly\nlarger AUC of 0.90 vs. at most 0.84 with p < 0.001 using McNemar's test for\nclinical diagnosis of AD. Inspection of MAE curves as a function of the amount\nof missing data reveals that the proposed LSTM algorithm achieves the best\nperformance up until more than 74% missing values. Finally, it is illustrated\nhow the method can successfully be applied to data with varying time intervals.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 21:14:33 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Ghazi", "Mostafa Mehdipour", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""], ["Cardoso", "M. Jorge", ""], ["Modat", "Marc", ""], ["Ourselin", "Sebastien", ""], ["S\u00f8rensen", "Lauge", ""]]}, {"id": "1903.07181", "submitter": "Keith Dillon", "authors": "Keith Dillon", "title": "On the Computation and Applications of Large Dense Partial Correlation\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While sparse inverse covariance matrices are very popular for modeling\nnetwork connectivity, the value of the dense solution is often overlooked. In\nfact the L2-regularized solution has deep connections to a number of important\napplications to spectral graph theory, dimensionality reduction, and\nuncertainty quantification. We derive an approach to directly compute the\npartial correlations based on concepts from inverse problem theory. This\napproach also leads to new insights on open problems such as model selection\nand data preprocessing, as well as new approaches which relate the above\napplication areas.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 21:46:25 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Dillon", "Keith", ""]]}, {"id": "1903.07227", "submitter": "Cheng-Zhi Anna Huang", "authors": "Cheng-Zhi Anna Huang, Tim Cooijmans, Adam Roberts, Aaron Courville,\n  Douglas Eck", "title": "Counterpoint by Convolution", "comments": "Proceedings of the 18th International Society for Music Information\n  Retrieval Conference, ISMIR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models of music typically break up the task of composition\ninto a chronological process, composing a piece of music in a single pass from\nbeginning to end. On the contrary, human composers write music in a nonlinear\nfashion, scribbling motifs here and there, often revisiting choices previously\nmade. In order to better approximate this process, we train a convolutional\nneural network to complete partial musical scores, and explore the use of\nblocked Gibbs sampling as an analogue to rewriting. Neither the model nor the\ngenerative procedure are tied to a particular causal direction of composition.\nOur model is an instance of orderless NADE (Uria et al., 2014), which allows\nmore direct ancestral sampling. However, we find that Gibbs sampling greatly\nimproves sample quality, which we demonstrate to be due to some conditional\ndistributions being poorly modeled. Moreover, we show that even the cheap\napproximate blocked Gibbs procedure from Yao et al. (2014) yields better\nsamples than ancestral sampling, based on both log-likelihood and human\nevaluation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 02:04:23 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Huang", "Cheng-Zhi Anna", ""], ["Cooijmans", "Tim", ""], ["Roberts", "Adam", ""], ["Courville", "Aaron", ""], ["Eck", "Douglas", ""]]}, {"id": "1903.07258", "submitter": "Soummya Kar", "authors": "Brian Swenson, Soummya Kar, H. Vincent Poor, and Jose' M. F. Moura", "title": "Annealing for Distributed Global Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proves convergence to global optima for a class of distributed\nalgorithms for nonconvex optimization in network-based multi-agent settings.\nAgents are permitted to communicate over a time-varying undirected graph. Each\nagent is assumed to possess a local objective function (assumed to be smooth,\nbut possibly nonconvex). The paper considers algorithms for optimizing the sum\nfunction. A distributed algorithm of the consensus+innovations type is proposed\nwhich relies on first-order information at the agent level. Under appropriate\nconditions on network connectivity and the cost objective, convergence to the\nset of global optima is achieved by an annealing-type approach, with decaying\nGaussian noise independently added into each agent's update step. It is shown\nthat the proposed algorithm converges in probability to the set of global\nminima of the sum function.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 05:16:37 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Swenson", "Brian", ""], ["Kar", "Soummya", ""], ["Poor", "H. Vincent", ""], ["Moura", "Jose' M. F.", ""]]}, {"id": "1903.07266", "submitter": "Usman Khan", "authors": "Ran Xin, Anit Kumar Sahu, Usman A. Khan, and Soummya Kar", "title": "Distributed stochastic optimization with gradient tracking over\n  strongly-connected networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study distributed stochastic optimization to minimize a sum\nof smooth and strongly-convex local cost functions over a network of agents,\ncommunicating over a strongly-connected graph. Assuming that each agent has\naccess to a stochastic first-order oracle ($\\mathcal{SFO}$), we propose a novel\ndistributed method, called $\\mathcal{S}$-$\\mathcal{AB}$, where each agent uses\nan auxiliary variable to asymptotically track the gradient of the global cost\nin expectation. The $\\mathcal{S}$-$\\mathcal{AB}$ algorithm employs row- and\ncolumn-stochastic weights simultaneously to ensure both consensus and\noptimality. Since doubly-stochastic weights are not used,\n$\\mathcal{S}$-$\\mathcal{AB}$ is applicable to arbitrary strongly-connected\ngraphs. We show that under a sufficiently small constant step-size,\n$\\mathcal{S}$-$\\mathcal{AB}$ converges linearly (in expected mean-square sense)\nto a neighborhood of the global minimizer. We present numerical simulations\nbased on real-world data sets to illustrate the theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 06:29:08 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 22:23:17 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Xin", "Ran", ""], ["Sahu", "Anit Kumar", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "1903.07272", "submitter": "Omid Bazgir", "authors": "Omid Bazgir, Zeynab Mohammadi, Seyed Amir Hassan Habibi", "title": "Emotion Recognition with Machine Learning Using EEG Signals", "comments": null, "journal-ref": "2018 25th National and 3rd International Iranian Conference on\n  Biomedical Engineering (ICBME)(pp. 1-5). IEEE", "doi": "10.1109/ICBME.2018.8703559", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, an emotion recognition system is developed based on\nvalence/arousal model using electroencephalography (EEG) signals. EEG signals\nare decomposed into the gamma, beta, alpha and theta frequency bands using\ndiscrete wavelet transform (DWT), and spectral features are extracted from each\nfrequency band. Principle component analysis (PCA) is applied to the extracted\nfeatures by preserving the same dimensionality, as a transform, to make the\nfeatures mutually uncorrelated. Support vector machine (SVM), K-nearest\nneighbor (KNN) and artificial neural network (ANN) are used to classify\nemotional states. The cross-validated SVM with radial basis function (RBF)\nkernel using extracted features of 10 EEG channels, performs with 91.3%\naccuracy for arousal and 91.1% accuracy for valence, both in the beta frequency\nband. Our approach shows better performance compared to existing algorithms\napplied to the \"DEAP\" dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 06:49:05 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 04:22:53 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bazgir", "Omid", ""], ["Mohammadi", "Zeynab", ""], ["Habibi", "Seyed Amir Hassan", ""]]}, {"id": "1903.07273", "submitter": "Michael Biehl", "authors": "Michael Biehl, Fthi Abadi, Christina G\u007f\\\"opfert, and Barbara Hammer", "title": "Prototype-based classifiers in the presence of concept drift: A\n  modelling framework", "comments": "Accepted contribution to WSOM+ 2019, Barcelona/Spain, June 2019 13th\n  International Workshop on Self-Organizing Maps and Learning Vector\n  Quantization, Clustering and Data Visualization 11 pages", "journal-ref": null, "doi": "10.1007/978-3-030-19642-4", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modelling framework for the investigation of prototype-based\nclassifiers in non-stationary environments. Specifically, we study Learning\nVector Quantization (LVQ) systems trained from a stream of high-dimensional,\nclustered data.We consider standard winner-takes-all updates known as LVQ1.\nStatistical properties of the input data change on the time scale defined by\nthe training process. We apply analytical methods borrowed from statistical\nphysics which have been used earlier for the exact description of learning in\nstationary environments. The suggested framework facilitates the computation of\nlearning curves in the presence of virtual and real concept drift. Here we\nfocus on timedependent class bias in the training data. First results\ndemonstrate that, while basic LVQ algorithms are suitable for the training in\nnon-stationary environments, weight decay as an explicit mechanism of\nforgetting does not improve the performance under the considered drift\nprocesses.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 06:51:03 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Biehl", "Michael", ""], ["Abadi", "Fthi", ""], ["G\u007f\u00f6pfert", "Christina", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.07282", "submitter": "Kaitao Song", "authors": "Ping Yu, Kaitao Song, Jianfeng Lu", "title": "Generating Adversarial Examples With Conditional Generative Adversarial\n  Net", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have significant progress and successful\napplication in various fields, but they are found vulnerable to attack\ninstances, e.g., adversarial examples. State-of-art attack methods can generate\nattack images by adding small perturbation to the source image. These attack\nimages can fool the classifier but have little impact to human. Therefore, such\nattack instances are difficult to generate by searching the feature space. How\nto design an effective and robust generating method has become a spotlight.\nInspired by adversarial examples, we propose two novel generative models to\nproduce adaptive attack instances directly, in which conditional generative\nadversarial network is adopted and distinctive strategy is designed for\ntraining. Compared with the common method, such as Fast Gradient Sign Method,\nour models can reduce the generating cost and improve robustness and has about\none fifth running time for producing attack instance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 07:33:35 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Yu", "Ping", ""], ["Song", "Kaitao", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1903.07288", "submitter": "Mahidhar Dwarampudi", "authors": "Mahidhar Dwarampudi, N V Subba Reddy", "title": "Effects of padding on LSTMs and CNNs", "comments": "5 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Long Short-Term Memory (LSTM) Networks and Convolutional Neural Networks\n(CNN) have become very common and are used in many fields as they were\neffective in solving many problems where the general neural networks were\ninefficient. They were applied to various problems mostly related to images and\nsequences. Since LSTMs and CNNs take inputs of the same length and dimension,\ninput images and sequences are padded to maximum length while testing and\ntraining. This padding can affect the way the networks function and can make a\ngreat deal when it comes to performance and accuracies. This paper studies this\nand suggests the best way to pad an input sequence. This paper uses a simple\nsentiment analysis task for this purpose. We use the same dataset on both the\nnetworks with various padding to show the difference. This paper also discusses\nsome preprocessing techniques done on the data to ensure effective analysis of\nthe data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 07:52:59 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Dwarampudi", "Mahidhar", ""], ["Reddy", "N V Subba", ""]]}, {"id": "1903.07299", "submitter": "Daniele Grattarola", "authors": "Daniele Zambon, Daniele Grattarola, Lorenzo Livi, Cesare Alippi", "title": "Autoregressive Models for Sequences of Graphs", "comments": "International Joint Conference on Neural Networks (IJCNN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an autoregressive (AR) model for sequences of graphs,\nwhich generalises traditional AR models. A first novelty consists in\nformalising the AR model for a very general family of graphs, characterised by\na variable topology, and attributes associated with nodes and edges. A graph\nneural network (GNN) is also proposed to learn the AR function associated with\nthe graph-generating process (GGP), and subsequently predict the next graph in\na sequence. The proposed method is compared with four baselines on synthetic\nGGPs, denoting a significantly better performance on all considered problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:37:13 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Zambon", "Daniele", ""], ["Grattarola", "Daniele", ""], ["Livi", "Lorenzo", ""], ["Alippi", "Cesare", ""]]}, {"id": "1903.07303", "submitter": "Timo Korthals", "authors": "Timo Korthals", "title": "M$^2$VAE - Derivation of a Multi-Modal Variational Autoencoder Objective\n  from the Marginal Joint Log-Likelihood", "comments": "Appendix for the IEEE FUSION 2019 submission on multi-modal\n  variational Autoencoders for sensor fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work gives an in-depth derivation of the trainable evidence lower bound\nobtained from the marginal joint log-Likelihood with the goal of training a\nMulti-Modal Variational Autoencoder (M$^2$VAE).\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:45:27 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Korthals", "Timo", ""]]}, {"id": "1903.07307", "submitter": "Bamdev Mishra", "authors": "Pratik Jawanpuria, Mayank Meghwanshi, and Bamdev Mishra", "title": "Low-rank approximations of hyperbolic embeddings", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hyperbolic manifold is a smooth manifold of negative constant curvature.\nWhile the hyperbolic manifold is well-studied in the literature, it has gained\ninterest in the machine learning and natural language processing communities\nlately due to its usefulness in modeling continuous hierarchies. Tasks with\nhierarchical structures are ubiquitous in those fields and there is a general\ninterest to learning hyperbolic representations or embeddings of such tasks.\nAdditionally, these embeddings of related tasks may also share a low-rank\nsubspace. In this work, we propose to learn hyperbolic embeddings such that\nthey also lie in a low-dimensional subspace. In particular, we consider the\nproblem of learning a low-rank factorization of hyperbolic embeddings. We cast\nthese problems as manifold optimization problems and propose computationally\nefficient algorithms. Empirical results illustrate the efficacy of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:50:03 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Meghwanshi", "Mayank", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1903.07320", "submitter": "Kurt Cutajar", "authors": "Kurt Cutajar, Mark Pullin, Andreas Damianou, Neil Lawrence, Javier\n  Gonz\\'alez", "title": "Deep Gaussian Processes for Multi-fidelity Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-fidelity methods are prominently used when cheaply-obtained, but\npossibly biased and noisy, observations must be effectively combined with\nlimited or expensive true data in order to construct reliable models. This\narises in both fundamental machine learning procedures such as Bayesian\noptimization, as well as more practical science and engineering applications.\nIn this paper we develop a novel multi-fidelity model which treats layers of a\ndeep Gaussian process as fidelity levels, and uses a variational inference\nscheme to propagate uncertainty across them. This allows for capturing\nnonlinear correlations between fidelities with lower risk of overfitting than\nexisting methods exploiting compositional structure, which are conversely\nburdened by structural assumptions and constraints. We show that the proposed\napproach makes substantial improvements in quantifying and propagating\nuncertainty in multi-fidelity set-ups, which in turn improves their\neffectiveness in decision making pipelines.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 09:24:33 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Cutajar", "Kurt", ""], ["Pullin", "Mark", ""], ["Damianou", "Andreas", ""], ["Lawrence", "Neil", ""], ["Gonz\u00e1lez", "Javier", ""]]}, {"id": "1903.07348", "submitter": "Maximilian Soelch", "authors": "Maximilian Soelch, Adnan Akhundov, Patrick van der Smagt, Justin Bayer", "title": "On Deep Set Learning and the Choice of Aggregations", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30487-4_35", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been shown that many functions on sets can be represented by\nsum decompositions. These decompositons easily lend themselves to neural\napproximations, extending the applicability of neural nets to set-valued\ninputs---Deep Set learning. This work investigates a core component of Deep Set\narchitecture: aggregation functions. We suggest and examine alternatives to\ncommonly used aggregation functions, including learnable recurrent aggregation\nfunctions. Empirically, we show that the Deep Set networks are highly sensitive\nto the choice of aggregation functions: beyond improved performance, we find\nthat learnable aggregations lower hyper-parameter sensitivity and generalize\nbetter to out-of-distribution input size.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 10:24:10 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 14:56:07 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Soelch", "Maximilian", ""], ["Akhundov", "Adnan", ""], ["van der Smagt", "Patrick", ""], ["Bayer", "Justin", ""]]}, {"id": "1903.07358", "submitter": "Julien Brajard", "authors": "Julien Brajard and Anastase Charantonis and J\\'er\\^ome Sirven", "title": "Representing ill-known parts of a numerical model using a machine\n  learning approach", "comments": "submitted to GRL", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In numerical modeling of the Earth System, many processes remain unknown or\nill represented (let us quote sub-grid processes, the dependence to unknown\nlatent variables or the non-inclusion of complex dynamics in numerical models)\nbut sometimes can be observed. This paper proposes a methodology to produce a\nhybrid model combining a physical-based model (forecasting the well-known\nprocesses) with a neural-net model trained from observations (forecasting the\nremaining processes). The approach is applied to a shallow-water model in which\nthe forcing, dissipative and diffusive terms are assumed to be unknown. We show\nthat the hybrid model is able to reproduce with great accuracy the unknown\nterms (correlation close to 1). For long term simulations it reproduces with no\nsignificant difference the mean state, the kinetic energy, the potential energy\nand the potential vorticity of the system. Lastly it is able to function with\nnew forcings that were not encountered during the training phase of the neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 10:52:39 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Brajard", "Julien", ""], ["Charantonis", "Anastase", ""], ["Sirven", "J\u00e9r\u00f4me", ""]]}, {"id": "1903.07359", "submitter": "Olga Taran", "authors": "Olga Taran, Slavi Bonev and Slava Voloshynovskiy", "title": "Clonability of anti-counterfeiting printable graphical codes: a machine\n  learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, printable graphical codes have attracted a lot of attention\nenabling a link between the physical and digital worlds, which is of great\ninterest for the IoT and brand protection applications. The security of\nprintable codes in terms of their reproducibility by unauthorized parties or\nclonability is largely unexplored. In this paper, we try to investigate the\nclonability of printable graphical codes from a machine learning perspective.\nThe proposed framework is based on a simple system composed of fully connected\nneural network layers. The results obtained on real codes printed by several\nprinters demonstrate a possibility to accurately estimate digital codes from\ntheir printed counterparts in certain cases. This provides a new insight on\nscenarios, where printable graphical codes can be accurately cloned.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 10:57:36 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Taran", "Olga", ""], ["Bonev", "Slavi", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1903.07373", "submitter": "Denis Belomestny", "authors": "D. Belomestny and E. Moulines and S. Samsonov", "title": "Variance reduction for MCMC methods via martingale representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an efficient variance reduction approach for\nadditive functionals of Markov chains relying on a novel discrete time\nmartingale representation. Our approach is fully non-asymptotic and does not\nrequire the knowledge of the stationary distribution (and even any type of\nergodicity) or specific structure of the underlying density. By rigorously\nanalyzing the convergence properties of the proposed algorithm, we show that\nits cost-to-variance product is indeed smaller than one of the naive algorithm.\nThe numerical performance of the new method is illustrated for the\nLangevin-type Markov Chain Monte Carlo (MCMC) methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 11:33:07 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 10:29:10 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 17:57:15 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Belomestny", "D.", ""], ["Moulines", "E.", ""], ["Samsonov", "S.", ""]]}, {"id": "1903.07378", "submitter": "Michael Biehl", "authors": "Michiel Straat, Michael Biehl", "title": "On-line learning dynamics of ReLU neural networks using statistical\n  physics techniques", "comments": "Accepted contribution: ESANN 2019, 6 pages European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce exact macroscopic on-line learning dynamics of two-layer neural\nnetworks with ReLU units in the form of a system of differential equations,\nusing techniques borrowed from statistical physics. For the first experiments,\nnumerical solutions reveal similar behavior compared to sigmoidal activation\nresearched in earlier work. In these experiments the theoretical results show\ngood correspondence with simulations. In ove-rrealizable and unrealizable\nlearning scenarios, the learning behavior of ReLU networks shows distinctive\ncharacteristics compared to sigmoidal networks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:09:36 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Straat", "Michiel", ""], ["Biehl", "Michael", ""]]}, {"id": "1903.07389", "submitter": "Hamid Karimi", "authors": "Hamid Karimi and Jiliang Tang", "title": "Learning Hierarchical Discourse-level Structure for Fake News Detection", "comments": "Accepted to 2019 Annual Conference of the North American Chapter of\n  the Association for Computational Linguistics June 2-7, 2019 Minneapolis, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  On the one hand, nowadays, fake news articles are easily propagated through\nvarious online media platforms and have become a grand threat to the\ntrustworthiness of information. On the other hand, our understanding of the\nlanguage of fake news is still minimal. Incorporating hierarchical\ndiscourse-level structure of fake and real news articles is one crucial step\ntoward a better understanding of how these articles are structured.\nNevertheless, this has rarely been investigated in the fake news detection\ndomain and faces tremendous challenges. First, existing methods for capturing\ndiscourse-level structure rely on annotated corpora which are not available for\nfake news datasets. Second, how to extract out useful information from such\ndiscovered structures is another challenge. To address these challenges, we\npropose Hierarchical Discourse-level Structure for Fake news detection. HDSF\nlearns and constructs a discourse-level structure for fake/real news articles\nin an automated and data-driven manner. Moreover, we identify insightful\nstructure-related properties, which can explain the discovered structures and\nboost our understating of fake news. Conducted experiments show the\neffectiveness of the proposed approach. Further structural analysis suggests\nthat real and fake news present substantial differences in the hierarchical\ndiscourse-level structures.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 00:03:17 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 01:15:14 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 16:18:00 GMT"}, {"version": "v4", "created": "Thu, 4 Apr 2019 02:38:36 GMT"}, {"version": "v5", "created": "Fri, 5 Apr 2019 17:39:05 GMT"}, {"version": "v6", "created": "Wed, 10 Apr 2019 14:20:53 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Karimi", "Hamid", ""], ["Tang", "Jiliang", ""]]}, {"id": "1903.07390", "submitter": "Jorge Gonz\\'alez Ordiano", "authors": "Jorge \\'Angel Gonz\\'alez Ordiano (1), Lutz Gr\\\"oll (1), Ralf Mikut\n  (1), Veit Hagenmeyer (1) ((1) Institute for Automation and Applied\n  Informatics, Karlsruhe Institute of Technology)", "title": "Probabilistic Energy Forecasting using Quantile Regressions based on a\n  new Nearest Neighbors Quantile Filter", "comments": "36 pages, 5 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.ijforecast.2019.06.003", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parametric quantile regressions are a useful tool for creating probabilistic\nenergy forecasts. Nonetheless, since classical quantile regressions are trained\nusing a non-differentiable cost function, their creation using complex data\nmining techniques (e.g., artificial neural networks) may be complicated. This\narticle presents a method that uses a new nearest neighbors quantile filter to\nobtain quantile regressions independently of the utilized data mining technique\nand without the non-differentiable cost function. Thereafter, a validation of\nthe presented method using the dataset of the Global Energy Forecasting\nCompetition of 2014 is undertaken. The results show that the presented method\nis able to solve the competition's task with a similar accuracy and in a\nsimilar time as the competition's winner, but requiring a much less powerful\ncomputer. This property may be relevant in an online forecasting service for\nwhich the fast computation of probabilistic forecasts using not so powerful\nmachines is required.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:41:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ordiano", "Jorge \u00c1ngel Gonz\u00e1lez", ""], ["Gr\u00f6ll", "Lutz", ""], ["Mikut", "Ralf", ""], ["Hagenmeyer", "Veit", ""]]}, {"id": "1903.07395", "submitter": "Nicholas Cummins Dr", "authors": "Thomas Wiest, Nicholas Cummins, Alice Baird, Simone Hantke, Judith\n  Dineley, Bj\\\"orn Schuller", "title": "Voice command generation using Progressive Wavegans", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become exceedingly popular in a\nwide range of data-driven research fields, due in part to their success in\nimage generation. Their ability to generate new samples, often from only a\nsmall amount of input data, makes them an exciting research tool in areas with\nlimited data resources. One less-explored application of GANs is the synthesis\nof speech and audio samples. Herein, we propose a set of extensions to the\nWaveGAN paradigm, a recently proposed approach for sound generation using GANs.\nThe aim of these extensions - preprocessing, Audio-to-Audio generation, skip\nconnections and progressive structures - is to improve the human likeness of\nsynthetic speech samples. Scores from listening tests with 30 volunteers\ndemonstrated a moderate improvement (Cohen's d coefficient of 0.65) in human\nlikeness using the proposed extensions compared to the original WaveGAN\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 18:43:31 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Wiest", "Thomas", ""], ["Cummins", "Nicholas", ""], ["Baird", "Alice", ""], ["Hantke", "Simone", ""], ["Dineley", "Judith", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1903.07400", "submitter": "Jingwei Zhang", "authors": "Jingwei Zhang, Niklas Wetzel, Nicolai Dorka, Joschka Boedecker and\n  Wolfram Burgard", "title": "Scheduled Intrinsic Drive: A Hierarchical Take on Intrinsically\n  Motivated Exploration", "comments": "A video of our experimental results can be found at\n  https://youtu.be/b0MbY3lUlEI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in sparse reward reinforcement learning remains an open\nchallenge. Many state-of-the-art methods use intrinsic motivation to complement\nthe sparse extrinsic reward signal, giving the agent more opportunities to\nreceive feedback during exploration. Commonly these signals are added as bonus\nrewards, which results in a mixture policy that neither conducts exploration\nnor task fulfillment resolutely. In this paper, we instead learn separate\nintrinsic and extrinsic task policies and schedule between these different\ndrives to accelerate exploration and stabilize learning. Moreover, we introduce\na new type of intrinsic reward denoted as successor feature control (SFC),\nwhich is general and not task-specific. It takes into account statistics over\ncomplete trajectories and thus differs from previous methods that only use\nlocal information to evaluate intrinsic motivation. We evaluate our proposed\nscheduled intrinsic drive (SID) agent using three different environments with\npure visual inputs: VizDoom, DeepMind Lab and DeepMind Control Suite. The\nresults show a substantially improved exploration efficiency with SFC and the\nhierarchical usage of the intrinsic drives. A video of our experimental results\ncan be found at https://youtu.be/b0MbY3lUlEI.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:52:57 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 15:41:14 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhang", "Jingwei", ""], ["Wetzel", "Niklas", ""], ["Dorka", "Nicolai", ""], ["Boedecker", "Joschka", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1903.07406", "submitter": "Shivam Kalra", "authors": "Shivam Kalra, Larry Li, Hamid R. Tizhoosh", "title": "Automatic Classification of Pathology Reports using TF-IDF Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Pathology report is arguably one of the most important documents in\nmedicine containing interpretive information about the visual findings from the\npatient's biopsy sample. Each pathology report has a retention period of up to\n20 years after the treatment of a patient. Cancer registries process and encode\nhigh volumes of free-text pathology reports for surveillance of cancer and\ntumor diseases all across the world. In spite of their extremely valuable\ninformation they hold, pathology reports are not used in any systematic way to\nfacilitate computational pathology. Therefore, in this study, we investigate\nautomated machine-learning techniques to identify/predict the primary diagnosis\n(based on ICD-O code) from pathology reports. We performed experiments by\nextracting the TF-IDF features from the reports and classifying them using\nthree different methods---SVM, XGBoost, and Logistic Regression. We constructed\na new dataset with 1,949 pathology reports arranged into 37 ICD-O categories,\ncollected from four different primary sites, namely lung, kidney, thymus, and\ntestis. The reports were manually transcribed into text format after collecting\nthem as PDF files from NCI Genomic Data Commons public dataset. We subsequently\npre-processed the reports by removing irrelevant textual artifacts produced by\nOCR software. The highest classification accuracy we achieved was 92\\% using\nXGBoost classifier on TF-IDF feature vectors, the linear SVM scored 87\\%\naccuracy. Furthermore, the study shows that TF-IDF vectors are suitable for\nhighlighting the important keywords within a report which can be helpful for\nthe cancer research and diagnostic workflow. The results are encouraging in\ndemonstrating the potential of machine learning methods for classification and\nencoding of pathology reports.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:11:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kalra", "Shivam", ""], ["Li", "Larry", ""], ["Tizhoosh", "Hamid R.", ""]]}, {"id": "1903.07424", "submitter": "Yang Chen Mr", "authors": "Yang Chen, Xiaoyan Sun, Yaochu Jin", "title": "Communication-Efficient Federated Deep Learning with Asynchronous Model\n  Update and Temporally Weighted Aggregation", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": "10.1109/TNNLS.2019.2953131", "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning obtains a central model on the server by aggregating\nmodels trained locally on clients. As a result, federated learning does not\nrequire clients to upload their data to the server, thereby preserving the data\nprivacy of the clients. One challenge in federated learning is to reduce the\nclient-server communication since the end devices typically have very limited\ncommunication bandwidth. This paper presents an enhanced federated learning\ntechnique by proposing a synchronous learning strategy on the clients and a\ntemporally weighted aggregation of the local models on the server. In the\nasynchronous learning strategy, different layers of the deep neural networks\nare categorized into shallow and deeps layers and the parameters of the deep\nlayers are updated less frequently than those of the shallow layers.\nFurthermore, a temporally weighted aggregation strategy is introduced on the\nserver to make use of the previously trained local models, thereby enhancing\nthe accuracy and convergence of the central model. The proposed algorithm is\nempirically on two datasets with different deep neural networks. Our results\ndemonstrate that the proposed asynchronous federated deep learning outperforms\nthe baseline algorithm both in terms of communication cost and model accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 13:27:42 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Yang", ""], ["Sun", "Xiaoyan", ""], ["Jin", "Yaochu", ""]]}, {"id": "1903.07438", "submitter": "Dhruva Tirumala", "authors": "Dhruva Tirumala, Hyeonwoo Noh, Alexandre Galashov, Leonard\n  Hasenclever, Arun Ahuja, Greg Wayne, Razvan Pascanu, Yee Whye Teh, Nicolas\n  Heess", "title": "Exploiting Hierarchy for Learning and Transfer in KL-regularized RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As reinforcement learning agents are tasked with solving more challenging and\ndiverse tasks, the ability to incorporate prior knowledge into the learning\nsystem and to exploit reusable structure in solution space is likely to become\nincreasingly important. The KL-regularized expected reward objective\nconstitutes one possible tool to this end. It introduces an additional\ncomponent, a default or prior behavior, which can be learned alongside the\npolicy and as such partially transforms the reinforcement learning problem into\none of behavior modelling. In this work we consider the implications of this\nframework in cases where both the policy and default behavior are augmented\nwith latent variables. We discuss how the resulting hierarchical structures can\nbe used to implement different inductive biases and how their modularity can\nbenefit transfer. Empirically we find that they can lead to faster learning and\ntransfer on a range of continuous control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 13:43:12 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 17:00:58 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tirumala", "Dhruva", ""], ["Noh", "Hyeonwoo", ""], ["Galashov", "Alexandre", ""], ["Hasenclever", "Leonard", ""], ["Ahuja", "Arun", ""], ["Wayne", "Greg", ""], ["Pascanu", "Razvan", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "1903.07445", "submitter": "Harrison Uglow", "authors": "Harrison Uglow, Martin Zlocha, Szymon Zmy\\'slony", "title": "An Exploration of State-of-the-art Methods for Offensive Language\n  Detection", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a comprehensive investigation of different custom and\noff-the-shelf architectures as well as different approaches to generating\nfeature vectors for offensive language detection. We also show that these\napproaches work well on small and noisy datasets such as on the Offensive\nLanguage Identification Dataset (OLID), so it should be possible to use them\nfor other applications.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 13:05:23 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 17:53:30 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Uglow", "Harrison", ""], ["Zlocha", "Martin", ""], ["Zmy\u015blony", "Szymon", ""]]}, {"id": "1903.07461", "submitter": "Geoff Nitschke", "authors": "David Jones and Anja Schroeder and Geoff Nitschke", "title": "Evolutionary Deep Learning to Identify Galaxies in the Zone of Avoidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Zone of Avoidance makes it difficult for astronomers to catalogue\ngalaxies at low latitudes to our galactic plane due to high star densities and\nextinction. However, having a complete sky map of galaxies is important in a\nnumber of fields of research in astronomy. There are many unclassified sources\nof light in the Zone of Avoidance and it is therefore important that there\nexists an accurate automated system to identify and classify galaxies in this\nregion. This study aims to evaluate the efficiency and accuracy of using an\nevolutionary algorithm to evolve the topology and configuration of\nConvolutional Neural Network (CNNs) to automatically identify galaxies in the\nZone of Avoidance. A supervised learning method is used with data containing\nnear-infrared images. Input image resolution and number of near-infrared\npassbands needed by the evolutionary algorithm is also analyzed while the\naccuracy of the best evolved CNN is compared to other CNN variants.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 13:53:27 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 07:22:29 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Jones", "David", ""], ["Schroeder", "Anja", ""], ["Nitschke", "Geoff", ""]]}, {"id": "1903.07479", "submitter": "Phong Nguyen Huu", "authors": "Nguyen Huu Phong and Bernardete Ribeiro", "title": "Offline and Online Deep Learning for Image Recognition", "comments": "5 pages", "journal-ref": "2017 4th Experiment@International Conference (exp.at'17)", "doi": "10.1109/EXPAT.2017.7984421", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image recognition using Deep Learning has been evolved for decades though\nadvances in the field through different settings is still a challenge. In this\npaper, we present our findings in searching for better image classifiers in\noffline and online environments. We resort to Convolutional Neural Network and\nits variations of fully connected Multi-layer Perceptron. Though still\npreliminary, these results are encouraging and may provide a better\nunderstanding about the field and directions toward future works.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 14:39:20 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Phong", "Nguyen Huu", ""], ["Ribeiro", "Bernardete", ""]]}, {"id": "1903.07497", "submitter": "Nguyen Huu Phong", "authors": "Nguyen Huu Phong and Bernardete Ribeiro", "title": "Advanced Capsule Networks via Context Awareness", "comments": "12 pages", "journal-ref": null, "doi": "10.1007/978-3-030-30487-4_14", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule Networks (CN) offer new architectures for Deep Learning (DL)\ncommunity. Though its effectiveness has been demonstrated in MNIST and\nsmallNORB datasets, the networks still face challenges in other datasets for\nimages with distinct contexts. In this research, we improve the design of CN\n(Vector version) namely we expand more Pooling layers to filter image\nbackgrounds and increase Reconstruction layers to make better image\nrestoration. Additionally, we perform experiments to compare accuracy and speed\nof CN versus DL models. In DL models, we utilize Inception V3 and DenseNet V201\nfor powerful computers besides NASNet, MobileNet V1 and MobileNet V2 for small\nand embedded devices. We evaluate our models on a fingerspelling alphabet\ndataset from American Sign Language (ASL). The results show that CNs perform\ncomparably to DL models while dramatically reducing training time. We also make\na demonstration and give a link for the purpose of illustration.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:12:13 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 07:09:02 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Phong", "Nguyen Huu", ""], ["Ribeiro", "Bernardete", ""]]}, {"id": "1903.07507", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Daniel Pressel, Brian Lester, Matthew Nokleby", "title": "An Effective Label Noise Model for DNN Text Classification", "comments": "Accepted at NAACL-HLT 2019 Main Conference Long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because large, human-annotated datasets suffer from labeling errors, it is\ncrucial to be able to train deep neural networks in the presence of label\nnoise. While training image classification models with label noise have\nreceived much attention, training text classification models have not. In this\npaper, we propose an approach to training deep networks that is robust to label\nnoise. This approach introduces a non-linear processing layer (noise model)\nthat models the statistics of the label noise into a convolutional neural\nnetwork (CNN) architecture. The noise model and the CNN weights are learned\njointly from noisy training data, which prevents the model from overfitting to\nerroneous labels. Through extensive experiments on several text classification\ndatasets, we show that this approach enables the CNN to learn better sentence\nrepresentations and is robust even to extreme label noise. We find that proper\ninitialization and regularization of this noise model is critical. Further, by\ncontrast to results focusing on large batch sizes for mitigating label noise\nfor image classification, we find that altering the batch size does not have\nmuch effect on classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:27:50 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Jindal", "Ishan", ""], ["Pressel", "Daniel", ""], ["Lester", "Brian", ""], ["Nokleby", "Matthew", ""]]}, {"id": "1903.07510", "submitter": "Jack Albright", "authors": "Jack Albright", "title": "Forecasting the Progression of Alzheimer's Disease Using Neural Networks\n  and a Novel Pre-Processing Algorithm", "comments": "10 pages; updated acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is the most common neurodegenerative disease in\nolder people. Despite considerable efforts to find a cure for AD, there is a\n99.6% failure rate of clinical trials for AD drugs, likely because AD patients\ncannot easily be identified at early stages. This project investigated machine\nlearning approaches to predict the clinical state of patients in future years\nto benefit AD research. Clinical data from 1737 patients was obtained from the\nAlzheimer's Disease Neuroimaging Initiative (ADNI) database and was processed\nusing the \"All-Pairs\" technique, a novel methodology created for this project\ninvolving the comparison of all possible pairs of temporal data points for each\npatient. This data was then used to train various machine learning models.\nModels were evaluated using 7-fold cross-validation on the training dataset and\nconfirmed using data from a separate testing dataset (110 patients). A neural\nnetwork model was effective (mAUC = 0.866) at predicting the progression of AD\non a month-by-month basis, both in patients who were initially cognitively\nnormal and in patients suffering from mild cognitive impairment. Such a model\ncould be used to identify patients at early stages of AD and who are therefore\ngood candidates for clinical trials for AD therapeutics.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:32:33 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 17:54:44 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Albright", "Jack", ""]]}, {"id": "1903.07512", "submitter": "Klaus Diepold", "authors": "Michael Koller, Johannes Feldmaier, Klaus Diepold", "title": "A Comparison of Prediction Algorithms and Nexting for Short Term Weather\n  Forecasts", "comments": "9 pages, 8 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This report first provides a brief overview of a number of supervised\nlearning algorithms for regression tasks. Among those are neural networks,\nregression trees, and the recently introduced Nexting. Nexting has been\npresented in the context of reinforcement learning where it was used to predict\na large number of signals at different timescales. In the second half of this\nreport, we apply the algorithms to historical weather data in order to evaluate\ntheir suitability to forecast a local weather trend. Our experiments did not\nidentify one clearly preferable method, but rather show that choosing an\nappropriate algorithm depends on the available side information. For slowly\nvarying signals and a proficient number of training samples, Nexting achieved\ngood results in the studied cases.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:37:34 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Koller", "Michael", ""], ["Feldmaier", "Johannes", ""], ["Diepold", "Klaus", ""]]}, {"id": "1903.07515", "submitter": "Sean Bittner", "authors": "Sean R. Bittner and John P. Cunningham", "title": "Approximating exponential family models (not single distributions) with\n  a two-network architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently much attention has been paid to deep generative models, since they\nhave been used to great success for variational inference, generation of\ncomplex data types, and more. In most all of these settings, the goal has been\nto find a particular member of that model family: optimized parameters index a\ndistribution that is close (via a divergence or classification metric) to a\ntarget distribution. Much less attention, however, has been paid to the problem\nof learning a model itself. Here we introduce a two-network architecture and\noptimization procedure for learning intractable exponential family models (not\na single distribution from those models). These exponential families are\nlearned accurately, allowing operations like posterior inference to be executed\ndirectly and generically with an input choice of natural parameters, rather\nthan performing inference via optimization for each particular distribution\nwithin that model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:43:07 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Bittner", "Sean R.", ""], ["Cunningham", "John P.", ""]]}, {"id": "1903.07518", "submitter": "Andreas Loukas", "authors": "Jean-Baptiste Cordonnier and Andreas Loukas", "title": "Extrapolating paths with graph neural networks", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of path inference: given a path prefix, i.e., a\npartially observed sequence of nodes in a graph, we want to predict which nodes\nare in the missing suffix. In particular, we focus on natural paths occurring\nas a by-product of the interaction of an agent with a network---a driver on the\ntransportation network, an information seeker in Wikipedia, or a client in an\nonline shop. Our interest is sparked by the realization that, in contrast to\nshortest-path problems, natural paths are usually not optimal in any\ngraph-theoretic sense, but might still follow predictable patterns.\n  Our main contribution is a graph neural network called Gretel. Conditioned on\na path prefix, this network can efficiently extrapolate path suffixes, evaluate\npath likelihood, and sample from the future path distribution. Our experiments\nwith GPS traces on a road network and user-navigation paths in Wikipedia\nconfirm that Gretel is able to adapt to graphs with very different properties,\nwhile also comparing favorably to previous solutions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:47:28 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Cordonnier", "Jean-Baptiste", ""], ["Loukas", "Andreas", ""]]}, {"id": "1903.07534", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti and Marco\n  Gori", "title": "LYRICS: a General Interface Layer to Integrate Logic Inference and Deep\n  Learning", "comments": "To appear in proceedings of ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the amazing results obtained by deep learning in many\napplications, a real intelligent behavior of an agent acting in a complex\nenvironment is likely to require some kind of higher-level symbolic inference.\nTherefore, there is a clear need for the definition of a general and tight\nintegration between low-level tasks, processing sensorial data that can be\neffectively elaborated using deep learning techniques, and the logic reasoning\nthat allows humans to take decisions in complex environments. This paper\npresents LYRICS, a generic interface layer for AI, which is implemented in\nTersorFlow (TF). LYRICS provides an input language that allows to define\narbitrary First Order Logic (FOL) background knowledge. The predicates and\nfunctions of the FOL knowledge can be bound to any TF computational graph, and\nthe formulas are converted into a set of real-valued constraints, which\nparticipate to the overall optimization problem. This allows to learn the\nweights of the learners, under the constraints imposed by the prior knowledge.\nThe framework is extremely general as it imposes no restrictions in terms of\nwhich models or knowledge can be integrated. In this paper, we show the\ngenerality of the approach showing some use cases of the presented language,\nincluding model checking, supervised learning and collective classification.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 16:23:00 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 15:32:33 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Marra", "Giuseppe", ""], ["Giannini", "Francesco", ""], ["Diligenti", "Michelangelo", ""], ["Gori", "Marco", ""]]}, {"id": "1903.07571", "submitter": "Daniel Hsu", "authors": "Mikhail Belkin, Daniel Hsu, Ji Xu", "title": "Two models of double descent for weak features", "comments": null, "journal-ref": "SIAM Journal on Mathematics of Data Science, 2(4):1167-1180, 2020", "doi": "10.1137/20M1336072", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"double descent\" risk curve was proposed to qualitatively describe the\nout-of-sample prediction accuracy of variably-parameterized machine learning\nmodels. This article provides a precise mathematical analysis for the shape of\nthis curve in two simple data models with the least squares/least norm\npredictor. Specifically, it is shown that the risk peaks when the number of\nfeatures $p$ is close to the sample size $n$, but also that the risk decreases\ntowards its minimum as $p$ increases beyond $n$. This behavior is contrasted\nwith that of \"prescient\" models that select features in an a priori optimal\norder.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:09:08 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 02:18:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Belkin", "Mikhail", ""], ["Hsu", "Daniel", ""], ["Xu", "Ji", ""]]}, {"id": "1903.07594", "submitter": "Aliaksandr Hubin", "authors": "Aliaksandr Hubin, Geir Storvik", "title": "Combining Model and Parameter Uncertainty in Bayesian Neural Networks", "comments": "16 pages, 8 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) have recently regained a significant amount\nof attention in the deep learning community due to the development of scalable\napproximate Bayesian inference techniques. There are several advantages of\nusing Bayesian approach: Parameter and prediction uncertainty become easily\navailable, facilitating rigid statistical analysis. Furthermore, prior\nknowledge can be incorporated. However so far there have been no scalable\ntechniques capable of combining both model (structural) and parameter\nuncertainty. In this paper we introduce the concept of model uncertainty in\nBNNs and hence make inference in the joint space of models and parameters.\nMoreover, we suggest an adaptation of a scalable variational inference approach\nwith reparametrization of marginal inclusion probabilities to incorporate the\nmodel space constraints. Finally, we show that incorporating model uncertainty\nvia Bayesian model averaging and Bayesian model selection allows to drastically\nsparsify the structure of BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:41:33 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 17:49:40 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 14:07:09 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hubin", "Aliaksandr", ""], ["Storvik", "Geir", ""]]}, {"id": "1903.07609", "submitter": "Xavier Gitiaux", "authors": "Xavier Gitiaux and Huzefa Rangwala", "title": "Multi-Differential Fairness Auditor for Black Box Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are increasingly involved in sensitive\ndecision-making process with adversarial implications on individuals. This\npaper presents mdfa, an approach that identifies the characteristics of the\nvictims of a classifier's discrimination. We measure discrimination as a\nviolation of multi-differential fairness. Multi-differential fairness is a\nguarantee that a black box classifier's outcomes do not leak information on the\nsensitive attributes of a small group of individuals. We reduce the problem of\nidentifying worst-case violations to matching distributions and predicting\nwhere sensitive attributes and classifier's outcomes coincide. We apply mdfa to\na recidivism risk assessment classifier and demonstrate that individuals\nidentified as African-American with little criminal history are three-times\nmore likely to be considered at high risk of violent recidivism than similar\nindividuals but not African-American.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:58:47 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Gitiaux", "Xavier", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1903.07663", "submitter": "Tianchen Wang", "authors": "Tianchen Wang, Jinjun Xiong, Xiaowei Xu, Yiyu Shi", "title": "SCNN: A General Distribution based Statistical Convolutional Neural\n  Network with Application to Video Object Detection", "comments": "AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various convolutional neural networks (CNNs) were developed recently that\nachieved accuracy comparable with that of human beings in computer vision tasks\nsuch as image recognition, object detection and tracking, etc. Most of these\nnetworks, however, process one single frame of image at a time, and may not\nfully utilize the temporal and contextual correlation typically present in\nmultiple channels of the same image or adjacent frames from a video, thus\nlimiting the achievable throughput. This limitation stems from the fact that\nexisting CNNs operate on deterministic numbers. In this paper, we propose a\nnovel statistical convolutional neural network (SCNN), which extends existing\nCNN architectures but operates directly on correlated distributions rather than\ndeterministic numbers. By introducing a parameterized canonical model to model\ncorrelated data and defining corresponding operations as required for CNN\ntraining and inference, we show that SCNN can process multiple frames of\ncorrelated images effectively, hence achieving significant speedup over\nexisting CNN models. We use a CNN based video object detection as an example to\nillustrate the usefulness of the proposed SCNN as a general network model.\nExperimental results show that even a non-optimized implementation of SCNN can\nstill achieve 178% speedup over existing CNNs with slight accuracy degradation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 16:00:23 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wang", "Tianchen", ""], ["Xiong", "Jinjun", ""], ["Xu", "Xiaowei", ""], ["Shi", "Yiyu", ""]]}, {"id": "1903.07677", "submitter": "Matthew Dixon", "authors": "Matthew F. Dixon and Nicholas G. Polson", "title": "Deep Fundamental Factor Models", "comments": null, "journal-ref": "Forthcoming in SIAM J. Financial Mathematics, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep fundamental factor models are developed to automatically capture\nnon-linearity and interaction effects in factor modeling. Uncertainty\nquantification provides interpretability with interval estimation, ranking of\nfactor importances and estimation of interaction effects. With no hidden layers\nwe recover a linear factor model and for one or more hidden layers, uncertainty\nbands for the sensitivity to each input naturally arise from the network\nweights. Using 3290 assets in the Russell 1000 index over a period of December\n1989 to January 2018, we assess a 49 factor model and generate information\nratios that are approximately 1.5x greater than the OLS factor model.\nFurthermore, we compare our deep fundamental factor model with a quadratic\nLASSO model and demonstrate the superior performance and robustness to\noutliers. The Python source code and the data used for this study are provided.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 19:10:09 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 19:57:38 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 17:22:04 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Dixon", "Matthew F.", ""], ["Polson", "Nicholas G.", ""]]}, {"id": "1903.07714", "submitter": "Laurent Dinh", "authors": "Laurent Dinh, Jascha Sohl-Dickstein, Hugo Larochelle, Razvan Pascanu", "title": "A RAD approach to deep mixture models", "comments": "18.5 pages of main content, 3 pages of appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow based models such as Real NVP are an extremely powerful approach to\ndensity estimation. However, existing flow based models are restricted to\ntransforming continuous densities over a continuous input space into similarly\ncontinuous distributions over continuous latent variables. This makes them\npoorly suited for modeling and representing discrete structures in data\ndistributions, for example class membership or discrete symmetries. To address\nthis difficulty, we present a normalizing flow architecture which relies on\ndomain partitioning using locally invertible functions, and possesses both real\nand discrete valued latent variables. This Real and Discrete (RAD) approach\nretains the desirable normalizing flow properties of exact sampling, exact\ninference, and analytically computable probabilities, while at the same time\nallowing simultaneous modeling of both continuous and discrete structure in a\ndata distribution.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 20:55:53 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 16:19:49 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 02:25:59 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Dinh", "Laurent", ""], ["Sohl-Dickstein", "Jascha", ""], ["Larochelle", "Hugo", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1903.07722", "submitter": "Lucas May Petry", "authors": "Carlos Andres Ferrero, Lucas May Petry, Luis Otavio Alvares, Willian\n  Zalewski, Vania Bogorny", "title": "Discovering Heterogeneous Subsequences for Trajectory Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new parameter-free method for trajectory\nclassification which finds the best trajectory partition and dimension\ncombination for robust trajectory classification. Preliminary experiments show\nthat our approach is very promising.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 21:10:16 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ferrero", "Carlos Andres", ""], ["Petry", "Lucas May", ""], ["Alvares", "Luis Otavio", ""], ["Zalewski", "Willian", ""], ["Bogorny", "Vania", ""]]}, {"id": "1903.07740", "submitter": "Alexander Pashevich", "authors": "Alexander Pashevich, Robin Strudel, Igor Kalevatykh, Ivan Laptev,\n  Cordelia Schmid", "title": "Learning to Augment Synthetic Images for Sim2Real Policy Transfer", "comments": "7 pages", "journal-ref": "IROS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision and learning have made significant progress that could improve\nrobotics policies for complex tasks and environments. Learning deep neural\nnetworks for image understanding, however, requires large amounts of\ndomain-specific visual data. While collecting such data from real robots is\npossible, such an approach limits the scalability as learning policies\ntypically requires thousands of trials. In this work we attempt to learn\nmanipulation policies in simulated environments. Simulators enable scalability\nand provide access to the underlying world state during training. Policies\nlearned in simulators, however, do not transfer well to real scenes given the\ndomain gap between real and synthetic data. We follow recent work on domain\nrandomization and augment synthetic images with sequences of random\ntransformations. Our main contribution is to optimize the augmentation strategy\nfor sim2real transfer and to enable domain-independent policy learning. We\ndesign an efficient search for depth image augmentations using object\nlocalization as a proxy task. Given the resulting sequence of random\ntransformations, we use it to augment synthetic depth images during policy\nlearning. Our augmentation strategy is policy-independent and enables policy\nlearning with no real images. We demonstrate our approach to significantly\nimprove accuracy on three manipulation tasks evaluated on a real robot.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 22:01:57 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 14:47:57 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Pashevich", "Alexander", ""], ["Strudel", "Robin", ""], ["Kalevatykh", "Igor", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "1903.07745", "submitter": "Thomas Uriot Tu", "authors": "Thomas Uriot", "title": "Learning with Sets in Multiple Instance Regression Applied to Remote\n  Sensing", "comments": "KDD 2019, FEED Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach to tackle the multiple instance\nregression (MIR) problem. This problem arises when the data is a collection of\nbags, where each bag is made of multiple instances corresponding to the same\nunique real-valued label. Our goal is to train a regression model which maps\nthe instances of an unseen bag to its unique label. This MIR setting is common\nto remote sensing applications where there is high variability in the\nmeasurements and low geographical variability in the quantity being estimated.\nOur approach, in contrast to most competing methods, does not make the\nassumption that there exists a prime instance responsible for the label in each\nbag. Instead, we treat each bag as a set (i.e, an unordered sequence) of\ninstances and learn to map each bag to its unique label by using all the\ninstances in each bag. This is done by implementing an order-invariant\noperation characterized by a particular type of attention mechanism. This\nmethod is very flexible as it does not require domain knowledge nor does it\nmake any assumptions about the distribution of the instances within each bag.\nWe test our algorithm on five real world datasets and outperform previous\nstate-of-the-art on three of the datasets. In addition, we augment our feature\nspace by adding the moments of each feature for each bag, as extra features,\nand show that while the first moments lead to higher accuracy, there is a\ndiminishing return.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 22:27:47 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 16:39:18 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 12:19:50 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Uriot", "Thomas", ""]]}, {"id": "1903.07746", "submitter": "Lucas Maystre", "authors": "Lucas Maystre, Victor Kristof, Matthias Grossglauser", "title": "Pairwise Comparisons with Flexible Time-Dynamics", "comments": "Accepted at KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by applications in sports where the skill of players or teams\ncompeting against each other varies over time, we propose a probabilistic model\nof pairwise-comparison outcomes that can capture a wide range of time dynamics.\nWe achieve this by replacing the static parameters of a class of popular\npairwise-comparison models by continuous-time Gaussian processes; the\ncovariance function of these processes enables expressive dynamics. We develop\nan efficient inference algorithm that computes an approximate Bayesian\nposterior distribution. Despite the flexbility of our model, our inference\nalgorithm requires only a few linear-time iterations over the data and can take\nadvantage of modern multiprocessor computer architectures. We apply our model\nto several historical databases of sports outcomes and find that our approach\noutperforms competing approaches in terms of predictive performance, scales to\nmillions of observations, and generates compelling visualizations that help in\nunderstanding and interpreting the data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 22:31:35 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 11:10:22 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Maystre", "Lucas", ""], ["Kristof", "Victor", ""], ["Grossglauser", "Matthias", ""]]}, {"id": "1903.07749", "submitter": "Aleke Nolte", "authors": "Aleke Nolte, Lingyu Wang, Maciej Bilicki, Benne Holwerda and Michael\n  Biehl", "title": "Galaxy classification: A machine learning analysis of GAMA catalogue\n  data", "comments": "Accepted for the ESANN 2018 Special Issue of Neurocomputing", "journal-ref": "Neurocomputing 342: 172-190, 2019", "doi": "10.1016/j.neucom.2018.12.076", "report-no": null, "categories": "astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning analysis of five labelled galaxy catalogues\nfrom the Galaxy And Mass Assembly (GAMA): The SersicCatVIKING and\nSersicCatUKIDSS catalogues containing morphological features, the\nGaussFitSimple catalogue containing spectroscopic features, the MagPhys\ncatalogue including physical parameters for galaxies, and the Lambdar\ncatalogue, which contains photometric measurements. Extending work previously\npresented at the ESANN 2018 conference - in an analysis based on Generalized\nRelevance Matrix Learning Vector Quantization and Random Forests - we find that\nneither the data from the individual catalogues nor a combined dataset based on\nall 5 catalogues fully supports the visual-inspection-based galaxy\nclassification scheme employed to categorise the galaxies. In particular, only\none class, the Little Blue Spheroids, is consistently separable from the other\nclasses. To aid further insight into the nature of the employed visual-based\nclassification scheme with respect to physical and morphological features, we\npresent the galaxy parameters that are discriminative for the achieved class\ndistinctions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 22:49:39 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Nolte", "Aleke", ""], ["Wang", "Lingyu", ""], ["Bilicki", "Maciej", ""], ["Holwerda", "Benne", ""], ["Biehl", "Michael", ""]]}, {"id": "1903.07756", "submitter": "Wenbo Zhao", "authors": "Wenbo Zhao, Yang Gao, Shahan Ali Memon, Bhiksha Raj, Rita Singh", "title": "Hierarchical Routing Mixture of Experts", "comments": "9 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression tasks the distribution of the data is often too complex to be\nfitted by a single model. In contrast, partition-based models are developed\nwhere data is divided and fitted by local models. These models partition the\ninput space and do not leverage the input-output dependency of\nmultimodal-distributed data, and strong local models are needed to make good\npredictions. Addressing these problems, we propose a binary tree-structured\nhierarchical routing mixture of experts (HRME) model that has classifiers as\nnon-leaf node experts and simple regression models as leaf node experts. The\nclassifier nodes jointly soft-partition the input-output space based on the\nnatural separateness of multimodal data. This enables simple leaf experts to be\neffective for prediction. Further, we develop a probabilistic framework for the\nHRME model, and propose a recursive Expectation-Maximization (EM) based\nalgorithm to learn both the tree structure and the expert models. Experiments\non a collection of regression tasks validate the effectiveness of our method\ncompared to a variety of other regression models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:04:45 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Zhao", "Wenbo", ""], ["Gao", "Yang", ""], ["Memon", "Shahan Ali", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1903.07765", "submitter": "Yao Hengshuai", "authors": "Borislav Mavrin, Hengshuai Yao, Linglong Kong", "title": "Deep Reinforcement Learning with Decorrelation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an effective representation for high-dimensional data is a\nchallenging problem in reinforcement learning (RL). Deep reinforcement learning\n(DRL) such as Deep Q networks (DQN) achieves remarkable success in computer\ngames by learning deeply encoded representation from convolution networks. In\nthis paper, we propose a simple yet very effective method for representation\nlearning with DRL algorithms. Our key insight is that features learned by DRL\nalgorithms are highly correlated, which interferes with learning. By adding a\nregularized loss that penalizes correlation in latent features (with only\nslight computation), we decorrelate features represented by deep neural\nnetworks incrementally. On 49 Atari games, with the same regularization factor,\nour decorrelation algorithms perform $70\\%$ in terms of human-normalized\nscores, which is $40\\%$ better than DQN. In particular, ours performs better\nthan DQN on 39 games with 4 close ties and lost only slightly on $6$ games.\nEmpirical results also show that the decorrelation method applies to Quantile\nRegression DQN (QR-DQN) and significantly boosts performance. Further\nexperiments on the losing games show that our decorelation algorithms can win\nover DQN and QR-DQN with a fined tuned regularization factor.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:35:23 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 17:18:07 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 22:06:55 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mavrin", "Borislav", ""], ["Yao", "Hengshuai", ""], ["Kong", "Linglong", ""]]}, {"id": "1903.07768", "submitter": "Denisa Roberts", "authors": "Denisa Roberts", "title": "Neural Networks for Lorenz Map Prediction: A Trip Through Time", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": "AI-2020-0001", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article the Lorenz dynamical system is revived and revisited and the\ncurrent state of the art results for one step ahead forecasting for the Lorenz\ntrajectories are published. Multitask learning is shown to help learning the\nhard to learn z trajectory. The article is a reflection upon the evolution of\nneural networks with respect to the prediction performance on this canonical\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:45:40 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 11:49:33 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 13:57:57 GMT"}, {"version": "v4", "created": "Sun, 29 Mar 2020 19:22:13 GMT"}, {"version": "v5", "created": "Sun, 15 Nov 2020 14:53:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Roberts", "Denisa", ""]]}, {"id": "1903.07782", "submitter": "Yingrui Yang", "authors": "Yingrui Yang, Molin Wang", "title": "Semiparametric Methods for Exposure Misclassification in Propensity\n  Score-Based Time-to-Event Data Analysis", "comments": "Withdrawn due to grant related requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In epidemiology, identifying the effect of exposure variables in relation to\na time-to-event outcome is a classical research area of practical importance.\nIncorporating propensity score in the Cox regression model, as a measure to\ncontrol for confounding, has certain advantages when outcome is rare. However,\nin situations involving exposure measured with moderate to substantial error,\nidentifying the exposure effect using propensity score in Cox models remains a\nchallenging yet unresolved problem. In this paper, we propose an estimating\nequation method to correct for the exposure misclassification-caused bias in\nthe estimation of exposure-outcome associations. We also discuss the asymptotic\nproperties and derive the asymptotic variances of the proposed estimators. We\nconduct a simulation study to evaluate the performance of the proposed\nestimators in various settings. As an illustration, we apply our method to\ncorrect for the misclassification-caused bias in estimating the association of\nPM2.5 level with lung cancer mortality using a nationwide prospective cohort,\nthe Nurses' Health Study (NHS). The proposed methodology can be applied using\nour user-friendly R function published online.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 00:57:16 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 07:50:43 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Yang", "Yingrui", ""], ["Wang", "Molin", ""]]}, {"id": "1903.07792", "submitter": "Mehrdad Showkatbakhsh", "authors": "Mehrdad Showkatbakhsh, Can Karakus, Suhas Diggavi", "title": "Differentially Private Consensus-Based Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy is an important concern in learning, when datasets contain\nsensitive information about individuals. This paper considers consensus-based\ndistributed optimization under data privacy constraints. Consensus-based\noptimization consists of a set of computational nodes arranged in a graph, each\nhaving a local objective that depends on their local data, where in every step\nnodes take a linear combination of their neighbors' messages, as well as taking\na new gradient step. Since the algorithm requires exchanging messages that\ndepend on local data, private information gets leaked at every step. Taking\n$(\\epsilon, \\delta)$-differential privacy (DP) as our criterion, we consider\nthe strategy where the nodes add random noise to their messages before\nbroadcasting it, and show that the method achieves convergence with a bounded\nmean-squared error, while satisfying $(\\epsilon, \\delta)$-DP. By relaxing the\nmore stringent $\\epsilon$-DP requirement in previous work, we strengthen a\nknown convergence result in the literature. We conclude the paper with\nnumerical results demonstrating the effectiveness of our methods for mean\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 02:06:10 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Showkatbakhsh", "Mehrdad", ""], ["Karakus", "Can", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1903.07799", "submitter": "Mohan Shi", "authors": "Mohan Shi, Zhihai Wang, Jodong Yuan and Haiyang Liu", "title": "Random Pairwise Shapelets Forest", "comments": "There is some misunderstanding between authors when this manuscript\n  is submitted. Some of authors disagree to submit this manuscript. So we\n  decide to withdraw the article", "journal-ref": "PAKDD 2018: Advances in Knowledge Discovery and Data Mining", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapelet is a discriminative subsequence of time series. An advanced\nshapelet-based method is to embed shapelet into accurate and fast random\nforest. However, it shows several limitations. First, random shapelet forest\nrequires a large training cost for split threshold searching. Second, a single\nshapelet provides limited information for only one branch of the decision tree,\nresulting in insufficient accuracy and interpretability. Third, randomized\nensemble causes interpretability declining. For that, this paper presents\nRandom Pairwise Shapelets Forest (RPSF). RPSF combines a pair of shapelets from\ndifferent classes to construct random forest. It omits threshold searching to\nbe more efficient, includes more information for each node of the forest to be\nmore effective. Moreover, a discriminability metric, Decomposed Mean Decrease\nImpurity (DMDI), is proposed to identify influential region for every class.\nExtensive experiments show RPSF improves the accuracy and training speed of\nshapelet-based forest. Case studies demonstrate the interpretability of our\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 02:37:02 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 14:14:53 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Shi", "Mohan", ""], ["Wang", "Zhihai", ""], ["Yuan", "Jodong", ""], ["Liu", "Haiyang", ""]]}, {"id": "1903.07821", "submitter": "Yu Cheng", "authors": "Danli Wu, Yu Cheng, Dehan Luo, Kin-Yeung Wong, Kevin Hung, Zhijing\n  Yang", "title": "POP-CNN: Predicting Odor's Pleasantness with Convolutional Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting odor's pleasantness simplifies the evaluation of odors and has the\npotential to be applied in perfumes and environmental monitoring industry.\nClassical algorithms for predicting odor's pleasantness generally use a manual\nfeature extractor and an independent classifier. Manual designing a good\nfeature extractor depend on expert knowledge and experience is the key to the\naccuracy of the algorithms. In order to circumvent this difficulty, we proposed\na model for predicting odor's pleasantness by using convolutional neural\nnetwork. In our model, the convolutional neural layers replace manual feature\nextractor and show better performance. The experiments show that the\ncorrelation between our model and human is over 90% on pleasantness rating. And\nour model has 99.9% accuracy in distinguishing between absolutely pleasant or\nunpleasant odors.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 04:13:34 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wu", "Danli", ""], ["Cheng", "Yu", ""], ["Luo", "Dehan", ""], ["Wong", "Kin-Yeung", ""], ["Hung", "Kevin", ""], ["Yang", "Zhijing", ""]]}, {"id": "1903.07822", "submitter": "Martin Hirzel", "authors": "Subhrajit Roy, Kiran Kate and Martin Hirzel", "title": "A semi-supervised deep learning algorithm for abnormal EEG\n  identification", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems that can automatically analyze EEG signals can aid neurologists by\nreducing heavy workload and delays. However, such systems need to be first\ntrained using a labeled dataset. While large corpuses of EEG data exist, a\nfraction of them are labeled. Hand-labeling data increases workload for the\nvery neurologists we try to aid. This paper proposes a semi-supervised learning\nworkflow that can not only extract meaningful information from large unlabeled\nEEG datasets but also make predictions with minimal supervision, using labeled\ndatasets as small as 5 examples.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 04:23:04 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 21:39:01 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Roy", "Subhrajit", ""], ["Kate", "Kiran", ""], ["Hirzel", "Martin", ""]]}, {"id": "1903.07824", "submitter": "Joseph Cheng", "authors": "Joseph Y. Cheng, Feiyu Chen, Christopher Sandino, Morteza Mardani,\n  John M. Pauly, Shreyas S. Vasanawala", "title": "Compressed Sensing: From Research to Clinical Practice with Data-Driven\n  Learning", "comments": "Submitted to the Special Issue on Computational MRI: Compressed\n  Sensing and Beyond in the IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing in MRI enables high subsampling factors while maintaining\ndiagnostic image quality. This technique enables shortened scan durations\nand/or improved image resolution. Further, compressed sensing can increase the\ndiagnostic information and value from each scan performed. Overall, compressed\nsensing has significant clinical impact in improving the diagnostic quality and\npatient experience for imaging exams. However, a number of challenges exist\nwhen moving compressed sensing from research to the clinic. These challenges\ninclude hand-crafted image priors, sensitive tuning parameters, and long\nreconstruction times. Data-driven learning provides a solution to address these\nchallenges. As a result, compressed sensing can have greater clinical impact.\nIn this tutorial, we will review the compressed sensing formulation and outline\nsteps needed to transform this formulation to a deep learning framework.\nSupplementary open source code in python will be used to demonstrate this\napproach with open databases. Further, we will discuss considerations in\napplying data-driven compressed sensing in the clinical setting.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 04:28:07 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Cheng", "Joseph Y.", ""], ["Chen", "Feiyu", ""], ["Sandino", "Christopher", ""], ["Mardani", "Morteza", ""], ["Pauly", "John M.", ""], ["Vasanawala", "Shreyas S.", ""]]}, {"id": "1903.07825", "submitter": "Subhrajit Roy", "authors": "Subhrajit Roy", "title": "Machine Learning for removing EEG artifacts: Setting the benchmark", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalograms (EEG) are often contaminated by artifacts which make\ninterpreting them more challenging for clinicians. Hence, automated artifact\nrecognition systems have the potential to aid the clinical workflow. In this\nabstract, we share the first results on applying various machine learning\nalgorithms to the recently released world's largest open-source artifact\nrecognition dataset. We envision that these results will serve as a benchmark\nfor researchers who might work with this dataset in future.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 04:28:18 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Roy", "Subhrajit", ""]]}, {"id": "1903.07839", "submitter": "Junya Honda", "authors": "Junya Honda", "title": "A Note on KL-UCB+ Policy for the Stochastic Bandit", "comments": "6 pages, corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic setting of the stochastic K-armed bandit problem is considered in\nthis note. In this problem it has been known that KL-UCB policy achieves the\nasymptotically optimal regret bound and KL-UCB+ policy empirically performs\nbetter than the KL-UCB policy although the regret bound for the original form\nof the KL-UCB+ policy has been unknown. This note demonstrates that a simple\nproof of the asymptotic optimality of the KL-UCB+ policy can be given by the\nsame technique as those used for analyses of other known policies.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 05:16:43 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 11:19:45 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Honda", "Junya", ""]]}, {"id": "1903.07854", "submitter": "Liu Naijun", "authors": "Naijun Liu, Tao Lu, Yinghao Cai, Boyao Li, and Shuo Wang", "title": "Hindsight Generative Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to reinforcement learning, imitation learning (IL) is a powerful\nparadigm for training agents to learn control policies efficiently from expert\ndemonstrations. However, in most cases, obtaining demonstration data is costly\nand laborious, which poses a significant challenge in some scenarios. A\npromising alternative is to train agent learning skills via imitation learning\nwithout expert demonstrations, which, to some extent, would extremely expand\nimitation learning areas. To achieve such expectation, in this paper, we\npropose Hindsight Generative Adversarial Imitation Learning (HGAIL) algorithm,\nwith the aim of achieving imitation learning satisfying no need of\ndemonstrations. Combining hindsight idea with the generative adversarial\nimitation learning (GAIL) framework, we realize implementing imitation learning\nsuccessfully in cases of expert demonstration data are not available.\nExperiments show that the proposed method can train policies showing comparable\nperformance to current imitation learning methods. Further more, HGAIL\nessentially endows curriculum learning mechanism which is critical for learning\npolicies.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 06:16:56 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Liu", "Naijun", ""], ["Lu", "Tao", ""], ["Cai", "Yinghao", ""], ["Li", "Boyao", ""], ["Wang", "Shuo", ""]]}, {"id": "1903.07890", "submitter": "Roman Pogodin", "authors": "Roman Pogodin and Tor Lattimore", "title": "On First-Order Bounds, Variance and Gap-Dependent Bounds for Adversarial\n  Bandits", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make three contributions to the theory of k-armed adversarial bandits.\nFirst, we prove a first-order bound for a modified variant of the INF strategy\nby Audibert and Bubeck [2009], without sacrificing worst case optimality or\nmodifying the loss estimators. Second, we provide a variance analysis for\nalgorithms based on follow the regularised leader, showing that without\nadaptation the variance of the regret is typically {\\Omega}(n^2) where n is the\nhorizon. Finally, we study bounds that depend on the degree of separation of\nthe arms, generalising the results by Cowan and Katehakis [2015] from the\nstochastic setting to the adversarial and improving the result of Seldin and\nSlivkins [2014] by a factor of log(n)/log(log(n)).\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 09:05:43 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 13:09:50 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 12:39:55 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Pogodin", "Roman", ""], ["Lattimore", "Tor", ""]]}, {"id": "1903.07902", "submitter": "Vinay Setty", "authors": "Megha Khosla and Vinay Setty and Avishek Anand", "title": "A Comparative Study for Unsupervised Network Representation Learning", "comments": "Accepted for publication in IEEE TKDE", "journal-ref": null, "doi": "10.1109/TKDE.2019.2951398", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been appreciable progress in unsupervised network representation\nlearning (UNRL) approaches over graphs recently with flexible random-walk\napproaches, new optimization objectives and deep architectures. However, there\nis no common ground for systematic comparison of embeddings to understand their\nbehavior for different graphs and tasks. In this paper we theoretically group\ndifferent approaches under a unifying framework and empirically investigate the\neffectiveness of different network representation methods. In particular, we\nargue that most of the UNRL approaches either explicitly or implicit model and\nexploit context information of a node. Consequently, we propose a framework\nthat casts a variety of approaches -- random walk based, matrix factorization\nand deep learning based -- into a unified context-based optimization function.\nWe systematically group the methods based on their similarities and\ndifferences. We study the differences among these methods in detail which we\nlater use to explain their performance differences (on downstream tasks). We\nconduct a large-scale empirical study considering 9 popular and recent UNRL\ntechniques and 11 real-world datasets with varying structural properties and\ntwo common tasks -- node classification and link prediction. We find that there\nis no single method that is a clear winner and that the choice of a suitable\nmethod is dictated by certain properties of the embedding methods, task and\nstructural properties of the underlying graph. In addition we also report the\ncommon pitfalls in evaluation of UNRL methods and come up with suggestions for\nexperimental design and interpretation of results.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 09:36:22 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 18:19:22 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 20:24:47 GMT"}, {"version": "v4", "created": "Sat, 2 Nov 2019 17:36:28 GMT"}, {"version": "v5", "created": "Mon, 18 Nov 2019 12:07:43 GMT"}, {"version": "v6", "created": "Wed, 11 Mar 2020 14:03:04 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Khosla", "Megha", ""], ["Setty", "Vinay", ""], ["Anand", "Avishek", ""]]}, {"id": "1903.07903", "submitter": "Frederik Kratzert", "authors": "Frederik Kratzert, Mathew Herrnegger, Daniel Klotz, Sepp Hochreiter,\n  G\\\"unter Klambauer", "title": "NeuralHydrology -- Interpreting LSTMs in Hydrology", "comments": "Pre-print of published book chapter. See journal reference and DOI\n  for more info", "journal-ref": "In: Samek W., Montavon G., Vedaldi A., Hansen L., Muller KR. (eds)\n  Explainable AI: Interpreting, Explaining and Visualizing Deep Learning.\n  Lecture Notes in Computer Science, vol 11700. Springer, Cham, 2019", "doi": "10.1007/978-3-030-28954-6_19", "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the huge success of Long Short-Term Memory networks, their\napplications in environmental sciences are scarce. We argue that one reason is\nthe difficulty to interpret the internals of trained networks. In this study,\nwe look at the application of LSTMs for rainfall-runoff forecasting, one of the\ncentral tasks in the field of hydrology, in which the river discharge has to be\npredicted from meteorological observations. LSTMs are particularly well-suited\nfor this problem since memory cells can represent dynamic reservoirs and\nstorages, which are essential components in state-space modelling approaches of\nthe hydrological system. On basis of two different catchments, one with snow\ninfluence and one without, we demonstrate how the trained model can be analyzed\nand interpreted. In the process, we show that the network internally learns to\nrepresent patterns that are consistent with our qualitative understanding of\nthe hydrological system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 09:38:37 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 07:17:36 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kratzert", "Frederik", ""], ["Herrnegger", "Mathew", ""], ["Klotz", "Daniel", ""], ["Hochreiter", "Sepp", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "1903.07940", "submitter": "Yuhui Wang", "authors": "Yuhui Wang, Hao He, Chao Wen, Xiaoyang Tan", "title": "Truly Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal policy optimization (PPO) is one of the most successful deep\nreinforcement-learning methods, achieving state-of-the-art performance across a\nwide range of challenging tasks. However, its optimization behavior is still\nfar from being fully understood. In this paper, we show that PPO could neither\nstrictly restrict the likelihood ratio as it attempts to do nor enforce a\nwell-defined trust region constraint, which means that it may still suffer from\nthe risk of performance instability. To address this issue, we present an\nenhanced PPO method, named Truly PPO. Two critical improvements are made in our\nmethod: 1) it adopts a new clipping function to support a rollback behavior to\nrestrict the difference between the new policy and the old one; 2) the\ntriggering condition for clipping is replaced with a trust region-based one,\nsuch that optimizing the resulted surrogate objective function provides\nguaranteed monotonic improvement of the ultimate policy performance. It seems,\nby adhering more truly to making the algorithm proximal - confining the policy\nwithin the trust region, the new algorithm improves the original PPO on both\nsample efficiency and performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 11:18:29 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:59:49 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Wang", "Yuhui", ""], ["He", "Hao", ""], ["Wen", "Chao", ""], ["Tan", "Xiaoyang", ""]]}, {"id": "1903.07970", "submitter": "Mohammad Siami", "authors": "Mohammad Siami, Mohsen Naderpour, and Jie Lu", "title": "A Choquet Fuzzy Integral Vertical Bagging Classifier for Mobile\n  Telematics Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile app development in recent years has resulted in new products and\nfeatures to improve human life. Mobile telematics is one such development that\nencompasses multidisciplinary fields for transportation safety. The application\nof mobile telematics has been explored in many areas, such as insurance and\nroad safety. However, to the best of our knowledge, its application in gender\ndetection has not been explored. This paper proposes a Choquet fuzzy integral\nvertical bagging classifier that detects gender through mobile telematics. In\nthis model, different random forest classifiers are trained by randomly\ngenerated features with rough set theory, and the top three classifiers are\nfused using the Choquet fuzzy integral. The model is implemented and evaluated\non a real dataset. The empirical results indicate that the Choquet fuzzy\nintegral vertical bagging classifier outperforms other classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 12:52:46 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Siami", "Mohammad", ""], ["Naderpour", "Mohsen", ""], ["Lu", "Jie", ""]]}, {"id": "1903.07971", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Peter Richt\\'arik", "title": "Convergence Analysis of Inexact Randomized Iterative Methods", "comments": "29 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a convergence rate analysis of inexact variants of\nseveral randomized iterative methods. Among the methods studied are: stochastic\ngradient descent, stochastic Newton, stochastic proximal point and stochastic\nsubspace ascent. A common feature of these methods is that in their update rule\na certain sub-problem needs to be solved exactly. We relax this requirement by\nallowing for the sub-problem to be solved inexactly. In particular, we propose\nand analyze inexact randomized iterative methods for solving three closely\nrelated problems: a convex stochastic quadratic optimization problem, a best\napproximation problem and its dual, a concave quadratic maximization problem.\nWe provide iteration complexity results under several assumptions on the\ninexactness error. Inexact variants of many popular and some more exotic\nmethods, including randomized block Kaczmarz, randomized Gaussian Kaczmarz and\nrandomized block coordinate descent, can be cast as special cases. Numerical\nexperiments demonstrate the benefits of allowing inexactness.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 12:58:06 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1903.07988", "submitter": "Endre Grovik", "authors": "Endre Gr{\\o}vik, Darvin Yi, Michael Iv, Elisabeth Tong, Daniel L.\n  Rubin, Greg Zaharchuk", "title": "Deep Learning Enables Automatic Detection and Segmentation of Brain\n  Metastases on Multi-Sequence MRI", "comments": null, "journal-ref": null, "doi": "10.1002/jmri.26766", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and segmenting brain metastases is a tedious and time-consuming\ntask for many radiologists, particularly with the growing use of multi-sequence\n3D imaging. This study demonstrates automated detection and segmentation of\nbrain metastases on multi-sequence MRI using a deep learning approach based on\na fully convolution neural network (CNN). In this retrospective study, a total\nof 156 patients with brain metastases from several primary cancers were\nincluded. Pre-therapy MR images (1.5T and 3T) included pre- and post-gadolinium\nT1-weighted 3D fast spin echo, post-gadolinium T1-weighted 3D axial IR-prepped\nFSPGR, and 3D fluid attenuated inversion recovery. The ground truth was\nestablished by manual delineation by two experienced neuroradiologists. CNN\ntraining/development was performed using 100 and 5 patients, respectively, with\na 2.5D network based on a GoogLeNet architecture. The results were evaluated in\n51 patients, equally separated into those with few (1-3), multiple (4-10), and\nmany (>10) lesions. Network performance was evaluated using precision, recall,\nDice/F1 score, and ROC-curve statistics. For an optimal probability threshold,\ndetection and segmentation performance was assessed on a per metastasis basis.\nThe area under the ROC-curve (AUC), averaged across all patients, was 0.98. The\nAUC in the subgroups was 0.99, 0.97, and 0.97 for patients having 1-3, 4-10,\nand >10 metastases, respectively. Using an average optimal probability\nthreshold determined by the development set, precision, recall, and Dice-score\nwere 0.79, 0.53, and 0.79, respectively. At the same probability threshold, the\nnetwork showed an average false positive rate of 8.3/patient (no lesion-size\nlimit) and 3.4/patient (10 mm3 lesion size limit). In conclusion, a deep\nlearning approach using multi-sequence MRI can aid in the detection and\nsegmentation of brain metastases.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 09:48:42 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gr\u00f8vik", "Endre", ""], ["Yi", "Darvin", ""], ["Iv", "Michael", ""], ["Tong", "Elisabeth", ""], ["Rubin", "Daniel L.", ""], ["Zaharchuk", "Greg", ""]]}, {"id": "1903.07994", "submitter": "Yu-Jing Lin", "authors": "Yu-Jing Lin, Po-Wei Wu, Cheng-Han Hsu, I-Ping Tu, Shih-wei Liao", "title": "An Evaluation of Bitcoin Address Classification based on Transaction\n  History Summarization", "comments": "8 pages; accepted by ICBC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is a cryptocurrency that features a distributed, decentralized and\ntrustworthy mechanism, which has made Bitcoin a popular global transaction\nplatform. The transaction efficiency among nations and the privacy benefiting\nfrom address anonymity of the Bitcoin network have attracted many activities\nsuch as payments, investments, gambling, and even money laundering in the past\ndecade. Unfortunately, some criminal behaviors which took advantage of this\nplatform were not identified. This has discouraged many governments to support\ncryptocurrency. Thus, the capability to identify criminal addresses becomes an\nimportant issue in the cryptocurrency network. In this paper, we propose new\nfeatures in addition to those commonly used in the literature to build a\nclassification model for detecting abnormality of Bitcoin network addresses.\nThese features include various high orders of moments of transaction time\n(represented by block height) which summarizes the transaction history in an\nefficient way. The extracted features are trained by supervised machine\nlearning methods on a labeling category data set. The experimental evaluation\nshows that these features have improved the performance of Bitcoin address\nclassification significantly. We evaluate the results under eight classifiers\nand achieve the highest Micro-F1/Macro-F1 of 87%/86% with LightGBM.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 13:36:36 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Lin", "Yu-Jing", ""], ["Wu", "Po-Wei", ""], ["Hsu", "Cheng-Han", ""], ["Tu", "I-Ping", ""], ["Liao", "Shih-wei", ""]]}, {"id": "1903.08012", "submitter": "Fran\\c{c}ois Th\\'eberge", "authors": "Val\\'erie Poulin, Fran\\c{c}ois Th\\'eberge", "title": "Ensemble Clustering for Graphs: Comparisons and Applications", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": "10.1007/s41109-019-0162-z", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recently proposed a new ensemble clustering algorithm for graphs (ECG)\nbased on the concept of consensus clustering. We validated our approach by\nreplicating a study comparing graph clustering algorithms over benchmark\ngraphs, showing that ECG outperforms the leading algorithms. In this paper, we\nextend our comparison by considering a wider range of parameters for the\nbenchmark, generating graphs with different properties. We provide new\nexperimental results showing that the ECG algorithm alleviates the well-known\nresolution limit issue, and that it leads to better stability of the\npartitions. We also illustrate how the ensemble obtained with ECG can be used\nto quantify the presence of community structure in the graph, and to zoom in on\nthe sub-graph most closely associated with seed vertices. Finally, we\nillustrate further applications of ECG by comparing it to previous results for\ncommunity detection on weighted graphs, and community-aware anomaly detection.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 14:18:27 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Poulin", "Val\u00e9rie", ""], ["Th\u00e9berge", "Fran\u00e7ois", ""]]}, {"id": "1903.08023", "submitter": "Pedro Gonnet", "authors": "Pedro Gonnet, Thomas Deselaers", "title": "IndyLSTMs: Independently Recurrent LSTMs", "comments": "8 pages, submitted to ICDAR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Independently Recurrent Long Short-term Memory cells: IndyLSTMs.\nThese differ from regular LSTM cells in that the recurrent weights are not\nmodeled as a full matrix, but as a diagonal matrix, i.e.\\ the output and state\nof each LSTM cell depends on the inputs and its own output/state, as opposed to\nthe input and the outputs/states of all the cells in the layer. The number of\nparameters per IndyLSTM layer, and thus the number of FLOPS per evaluation, is\nlinear in the number of nodes in the layer, as opposed to quadratic for regular\nLSTM layers, resulting in potentially both smaller and faster models. We\nevaluate their performance experimentally by training several models on the\npopular \\iamondb and CASIA online handwriting datasets, as well as on several\nof our in-house datasets. We show that IndyLSTMs, despite their smaller size,\nconsistently outperform regular LSTMs both in terms of accuracy per parameter,\nand in best accuracy overall. We attribute this improved performance to the\nIndyLSTMs being less prone to overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 14:33:49 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Gonnet", "Pedro", ""], ["Deselaers", "Thomas", ""]]}, {"id": "1903.08072", "submitter": "Samy Blusseau", "authors": "Yunxiang Zhang (CMM, LTCI), Samy Blusseau (CMM), Santiago\n  Velasco-Forero (CMM), Isabelle Bloch (LTCI), Jesus Angulo (CMM)", "title": "Max-plus Operators Applied to Filter Selection and Model Pruning in\n  Neural Networks", "comments": null, "journal-ref": "International Symposium on Mathematical Morphology, Jul 2019,\n  Saarbr{\\\"u}cken, Germany", "doi": null, "report-no": null, "categories": "math.ST cs.CV cs.LG cs.NE stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following recent advances in morphological neural networks, we propose to\nstudy in more depth how Max-plus operators can be exploited to define\nmorphological units and how they behave when incorporated in layers of\nconventional neural networks. Besides showing that they can be easily\nimplemented with modern machine learning frameworks , we confirm and extend the\nobservation that a Max-plus layer can be used to select important filters and\nreduce redundancy in its previous layer, without incurring performance loss.\nExperimental results demonstrate that the filter selection strategy enabled by\na Max-plus is highly efficient and robust, through which we successfully\nperformed model pruning on different neural network architectures. We also\npoint out that there is a close connection between Maxout networks and our\npruned Max-plus networks by comparing their respective characteristics. The\ncode for reproducing our experiments is available online.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 15:58:43 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 12:51:57 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhang", "Yunxiang", "", "CMM, LTCI"], ["Blusseau", "Samy", "", "CMM"], ["Velasco-Forero", "Santiago", "", "CMM"], ["Bloch", "Isabelle", "", "LTCI"], ["Angulo", "Jesus", "", "CMM"]]}, {"id": "1903.08100", "submitter": "Diyuan Lu", "authors": "Diyuan Lu, Jochen Triesch", "title": "Residual Deep Convolutional Neural Network for EEG Signal Classification\n  in Epilepsy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is the fourth most common neurological disorder, affecting about 1%\nof the population at all ages. As many as 60% of people with epilepsy\nexperience focal seizures which originate in a certain brain area and are\nlimited to part of one cerebral hemisphere. In focal epilepsy patients, a\nprecise surgical removal of the seizure onset zone can lead to effective\nseizure control or even a seizure-free outcome. Thus, correct identification of\nthe seizure onset zone is essential. For clinical evaluation purposes,\nelectroencephalography (EEG) recordings are commonly used. However, their\ninterpretation is usually done manually by physicians and is time-consuming and\nerror-prone. In this work, we propose an automated epileptic signal\nclassification method based on modern deep learning methods. In contrast to\nprevious approaches, the network is trained directly on the EEG recordings,\navoiding hand-crafted feature extraction and selection procedures. This\nexploits the ability of deep neural networks to detect and extract relevant\nfeatures automatically, that may be too complex or subtle to be noticed by\nhumans. The proposed network structure is based on a convolutional neural\nnetwork with residual connections. We demonstrate that our network produces\nstate-of-the-art performance on two benchmark data sets, a data set from Bonn\nUniversity and the Bern-Barcelona data set. We conclude that modern deep\nlearning approaches can reach state-of-the-art performance on epileptic EEG\nclassification and automated seizure onset zone identification tasks when\ntrained on raw EEG data. This suggests that such approaches have potential for\nimproving clinical practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 16:38:19 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Lu", "Diyuan", ""], ["Triesch", "Jochen", ""]]}, {"id": "1903.08110", "submitter": "Arun Sai Suggala", "authors": "Arun Sai Suggala and Praneeth Netrapalli", "title": "Online Non-Convex Learning: Following the Perturbed Leader is Optimal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online learning with non-convex losses, where the\nlearner has access to an offline optimization oracle. We show that the\nclassical Follow the Perturbed Leader (FTPL) algorithm achieves optimal regret\nrate of $O(T^{-1/2})$ in this setting. This improves upon the previous\nbest-known regret rate of $O(T^{-1/3})$ for FTPL. We further show that an\noptimistic variant of FTPL achieves better regret bounds when the sequence of\nlosses encountered by the learner is `predictable'.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 16:54:43 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 00:19:23 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Suggala", "Arun Sai", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1903.08114", "submitter": "Ke Alexander Wang", "authors": "Ke Alexander Wang, Geoff Pleiss, Jacob R. Gardner, Stephen Tyree,\n  Kilian Q. Weinberger, Andrew Gordon Wilson", "title": "Exact Gaussian Processes on a Million Data Points", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are flexible non-parametric models, with a capacity\nthat grows with the available data. However, computational constraints with\nstandard inference procedures have limited exact GPs to problems with fewer\nthan about ten thousand training points, necessitating approximations for\nlarger datasets. In this paper, we develop a scalable approach for exact GPs\nthat leverages multi-GPU parallelization and methods like linear conjugate\ngradients, accessing the kernel matrix only through matrix multiplication. By\npartitioning and distributing kernel matrix multiplies, we demonstrate that an\nexact GP can be trained on over a million points, a task previously thought to\nbe impossible with current computing hardware, in less than 2 hours. Moreover,\nour approach is generally applicable, without constraints to grid data or\nspecific kernel classes. Enabled by this scalability, we perform the first-ever\ncomparison of exact GPs against scalable GP approximations on datasets with\n$10^4 \\!-\\! 10^6$ data points, showing dramatic performance improvements.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:10:28 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:44:52 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Wang", "Ke Alexander", ""], ["Pleiss", "Geoff", ""], ["Gardner", "Jacob R.", ""], ["Tyree", "Stephen", ""], ["Weinberger", "Kilian Q.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1903.08131", "submitter": "Corinne Jones", "authors": "Corinne Jones, Vincent Roulet, Zaid Harchaoui", "title": "Kernel-based Translations of Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks, as most artificial neural networks, are\ncommonly viewed as methods different in essence from kernel-based methods. We\nprovide a systematic translation of Convolutional Neural Networks (ConvNets)\ninto their kernel-based counterparts, Convolutional Kernel Networks (CKNs), and\ndemonstrate that this perception is unfounded both formally and empirically. We\nshow that, given a Convolutional Neural Network, we can design a corresponding\nConvolutional Kernel Network, easily trainable using a new stochastic gradient\nalgorithm based on an accurate gradient computation, that performs on par with\nits Convolutional Neural Network counterpart. We present experimental results\nsupporting our claims on landmark ConvNet architectures comparing each ConvNet\nto its CKN counterpart over several parameter settings.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:41:48 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Jones", "Corinne", ""], ["Roulet", "Vincent", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "1903.08192", "submitter": "Arun Sai Suggala", "authors": "Arun Sai Suggala, Kush Bhatia, Pradeep Ravikumar, Prateek Jain", "title": "Adaptive Hard Thresholding for Near-optimal Consistent Robust Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robust linear regression with response variable\ncorruptions. We consider the oblivious adversary model, where the adversary\ncorrupts a fraction of the responses in complete ignorance of the data. We\nprovide a nearly linear time estimator which consistently estimates the true\nregression vector, even with $1-o(1)$ fraction of corruptions. Existing results\nin this setting either don't guarantee consistent estimates or can only handle\na small fraction of corruptions. We also extend our estimator to robust sparse\nlinear regression and show that similar guarantees hold in this setting.\nFinally, we apply our estimator to the problem of linear regression with\nheavy-tailed noise and show that our estimator consistently estimates the\nregression vector even when the noise has unbounded variance (e.g., Cauchy\ndistribution), for which most existing results don't even apply. Our estimator\nis based on a novel variant of outlier removal via hard thresholding in which\nthe threshold is chosen adaptively and crucially relies on randomness to escape\nbad fixed points of the non-convex hard thresholding operation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 18:08:20 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Suggala", "Arun Sai", ""], ["Bhatia", "Kush", ""], ["Ravikumar", "Pradeep", ""], ["Jain", "Prateek", ""]]}, {"id": "1903.08193", "submitter": "Junyu Cao", "authors": "Junyu Cao, Wei Sun", "title": "Dynamic Learning of Sequential Choice Bandit Problem under Marketing\n  Fatigue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the observation that overexposure to unwanted marketing\nactivities leads to customer dissatisfaction, we consider a setting where a\nplatform offers a sequence of messages to its users and is penalized when users\nabandon the platform due to marketing fatigue. We propose a novel sequential\nchoice model to capture multiple interactions taking place between the platform\nand its user: Upon receiving a message, a user decides on one of the three\nactions: accept the message, skip and receive the next message, or abandon the\nplatform. Based on user feedback, the platform dynamically learns users'\nabandonment distribution and their valuations of messages to determine the\nlength of the sequence and the order of the messages, while maximizing the\ncumulative payoff over a horizon of length T. We refer to this online learning\ntask as the sequential choice bandit problem. For the offline combinatorial\noptimization problem, we show that an efficient polynomial-time algorithm\nexists. For the online problem, we propose an algorithm that balances\nexploration and exploitation, and characterize its regret bound. Lastly, we\ndemonstrate how to extend the model with user contexts to incorporate\npersonalization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 18:09:45 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Cao", "Junyu", ""], ["Sun", "Wei", ""]]}, {"id": "1903.08254", "submitter": "Kate Rakelly", "authors": "Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, Sergey\n  Levine", "title": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic\n  Context Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms require large amounts of experience to\nlearn an individual task. While in principle meta-reinforcement learning\n(meta-RL) algorithms enable agents to learn new skills from small amounts of\nexperience, several major challenges preclude their practicality. Current\nmethods rely heavily on on-policy experience, limiting their sample efficiency.\nThe also lack mechanisms to reason about task uncertainty when adapting to new\ntasks, limiting their effectiveness in sparse reward problems. In this paper,\nwe address these challenges by developing an off-policy meta-RL algorithm that\ndisentangles task inference and control. In our approach, we perform online\nprobabilistic filtering of latent task variables to infer how to solve a new\ntask from small amounts of experience. This probabilistic interpretation\nenables posterior sampling for structured and efficient exploration. We\ndemonstrate how to integrate these task variables with off-policy RL algorithms\nto achieve both meta-training and adaptation efficiency. Our method outperforms\nprior algorithms in sample efficiency by 20-100X as well as in asymptotic\nperformance on several meta-RL benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 20:51:04 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Rakelly", "Kate", ""], ["Zhou", "Aurick", ""], ["Quillen", "Deirdre", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.08256", "submitter": "Tim Jaschek", "authors": "Tim Jaschek, Marko Bucyk, and Jaspreet S. Oberoi", "title": "A Quantum Annealing-Based Approach to Extreme Clustering", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering, or grouping, dataset elements based on similarity can be used not\nonly to classify a dataset into a few categories, but also to approximate it by\na relatively large number of representative elements. In the latter scenario,\nreferred to as extreme clustering, datasets are enormous and the number of\nrepresentative clusters is large. We have devised a distributed method that can\nefficiently solve extreme clustering problems using quantum annealing. We prove\nthat this method yields optimal clustering assignments under a separability\nassumption, and show that the generated clustering assignments are of\ncomparable quality to those of assignments generated by common clustering\nalgorithms, yet can be obtained a full order of magnitude faster.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 21:01:59 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 20:00:07 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 23:27:18 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Jaschek", "Tim", ""], ["Bucyk", "Marko", ""], ["Oberoi", "Jaspreet S.", ""]]}, {"id": "1903.08289", "submitter": "Athirai A. Irissappane", "authors": "Gray Stanton, Athirai A. Irissappane", "title": "GANs for Semi-Supervised Opinion Spam Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews have become a vital source of information in purchasing a\nservice (product). Opinion spammers manipulate reviews, affecting the overall\nperception of the service. A key challenge in detecting opinion spam is\nobtaining ground truth. Though there exists a large set of reviews online, only\na few of them have been labeled spam or non-spam. In this paper, we propose\nspamGAN, a generative adversarial network which relies on limited set of\nlabeled data as well as unlabeled data for opinion spam detection. spamGAN\nimproves the state-of-the-art GAN based techniques for text classification.\nExperiments on TripAdvisor dataset show that spamGAN outperforms existing spam\ndetection techniques when limited labeled data is used. Apart from detecting\nspam reviews, spamGAN can also generate reviews with reasonable perplexity.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 23:33:41 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 19:03:03 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Stanton", "Gray", ""], ["Irissappane", "Athirai A.", ""]]}, {"id": "1903.08297", "submitter": "Nan Wu", "authors": "Nan Wu, Jason Phang, Jungkyu Park, Yiqiu Shen, Zhe Huang, Masha Zorin,\n  Stanis{\\l}aw Jastrz\\k{e}bski, Thibault F\\'evry, Joe Katsnelson, Eric Kim,\n  Stacey Wolfson, Ujas Parikh, Sushma Gaddam, Leng Leng Young Lin, Kara Ho,\n  Joshua D. Weinstein, Beatriu Reig, Yiming Gao, Hildegard Toth, Kristine\n  Pysarenko, Alana Lewin, Jiyon Lee, Krystal Airola, Eralda Mema, Stephanie\n  Chung, Esther Hwang, Naziya Samreen, S. Gene Kim, Laura Heacock, Linda Moy,\n  Kyunghyun Cho and Krzysztof J. Geras", "title": "Deep Neural Networks Improve Radiologists' Performance in Breast Cancer\n  Screening", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/SkxYez76FE", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep convolutional neural network for breast cancer screening\nexam classification, trained and evaluated on over 200,000 exams (over\n1,000,000 images). Our network achieves an AUC of 0.895 in predicting whether\nthere is a cancer in the breast, when tested on the screening population. We\nattribute the high accuracy of our model to a two-stage training procedure,\nwhich allows us to use a very high-capacity patch-level network to learn from\npixel-level labels alongside a network learning from macroscopic breast-level\nlabels. To validate our model, we conducted a reader study with 14 readers,\neach reading 720 screening mammogram exams, and find our model to be as\naccurate as experienced radiologists when presented with the same data.\nFinally, we show that a hybrid model, averaging probability of malignancy\npredicted by a radiologist with a prediction of our neural network, is more\naccurate than either of the two separately. To better understand our results,\nwe conduct a thorough analysis of our network's performance on different\nsubpopulations of the screening population, model design, training procedure,\nerrors, and properties of its internal representations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 00:51:01 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Wu", "Nan", ""], ["Phang", "Jason", ""], ["Park", "Jungkyu", ""], ["Shen", "Yiqiu", ""], ["Huang", "Zhe", ""], ["Zorin", "Masha", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["F\u00e9vry", "Thibault", ""], ["Katsnelson", "Joe", ""], ["Kim", "Eric", ""], ["Wolfson", "Stacey", ""], ["Parikh", "Ujas", ""], ["Gaddam", "Sushma", ""], ["Lin", "Leng Leng Young", ""], ["Ho", "Kara", ""], ["Weinstein", "Joshua D.", ""], ["Reig", "Beatriu", ""], ["Gao", "Yiming", ""], ["Toth", "Hildegard", ""], ["Pysarenko", "Kristine", ""], ["Lewin", "Alana", ""], ["Lee", "Jiyon", ""], ["Airola", "Krystal", ""], ["Mema", "Eralda", ""], ["Chung", "Stephanie", ""], ["Hwang", "Esther", ""], ["Samreen", "Naziya", ""], ["Kim", "S. Gene", ""], ["Heacock", "Laura", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "1903.08329", "submitter": "Shahin Shahrampour", "authors": "Shahin Shahrampour, Soheil Kolouri", "title": "On Sampling Random Features From Empirical Leverage Scores:\n  Implementation and Theoretical Guarantees", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random features provide a practical framework for large-scale kernel\napproximation and supervised learning. It has been shown that data-dependent\nsampling of random features using leverage scores can significantly reduce the\nnumber of features required to achieve optimal learning bounds. Leverage scores\nintroduce an optimized distribution for features based on an\ninfinite-dimensional integral operator (depending on input distribution), which\nis impractical to sample from. Focusing on empirical leverage scores in this\npaper, we establish an out-of-sample performance bound, revealing an\ninteresting trade-off between the approximated kernel and the eigenvalue decay\nof another kernel in the domain of random features defined based on data\ndistribution. Our experiments verify that the empirical algorithm consistently\noutperforms vanilla Monte Carlo sampling, and with a minor modification the\nmethod is even competitive to supervised data-dependent kernel learning,\nwithout using the output (label) information.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 03:41:01 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Shahrampour", "Shahin", ""], ["Kolouri", "Soheil", ""]]}, {"id": "1903.08333", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, David Wagner", "title": "On the Robustness of Deep K-Nearest Neighbors", "comments": "Published at Deep Learning and Security Workshop 2019 (IEEE S&P)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a large amount of attention on adversarial examples, very few works\nhave demonstrated an effective defense against this threat. We examine Deep\nk-Nearest Neighbor (DkNN), a proposed defense that combines k-Nearest Neighbor\n(kNN) and deep learning to improve the model's robustness to adversarial\nexamples. It is challenging to evaluate the robustness of this scheme due to a\nlack of efficient algorithm for attacking kNN classifiers with large k and\nhigh-dimensional data. We propose a heuristic attack that allows us to use\ngradient descent to find adversarial examples for kNN classifiers, and then\napply it to attack the DkNN defense as well. Results suggest that our attack is\nmoderately stronger than any naive attack on kNN and significantly outperforms\nother attacks on DkNN.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 03:50:34 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Wagner", "David", ""]]}, {"id": "1903.08351", "submitter": "Mehrdad Ghadiri", "authors": "Mehrdad Ghadiri, Mark Schmidt", "title": "Distributed Maximization of Submodular plus Diversity Functions for\n  Multi-label Feature Selection on Huge Datasets", "comments": "17 pages, accepted in AISTATS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many problems in machine learning and data mining which are\nequivalent to selecting a non-redundant, high \"quality\" set of objects.\nRecommender systems, feature selection, and data summarization are among many\napplications of this. In this paper, we consider this problem as an\noptimization problem that seeks to maximize the sum of a sum-sum diversity\nfunction and a non-negative monotone submodular function. The diversity\nfunction addresses the redundancy, and the submodular function controls the\npredictive quality. We consider the problem in big data settings (in other\nwords, distributed and streaming settings) where the data cannot be stored on a\nsingle machine or the process time is too high for a single machine. We show\nthat a greedy algorithm achieves a constant factor approximation of the optimal\nsolution in these settings. Moreover, we formulate the multi-label feature\nselection problem as such an optimization problem. This formulation combined\nwith our algorithm leads to the first distributed multi-label feature selection\nmethod. We compare the performance of this method with centralized multi-label\nfeature selection methods in the literature, and we show that its performance\nis comparable or in some cases is even better than current centralized\nmulti-label feature selection methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 06:08:03 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 05:29:43 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Ghadiri", "Mehrdad", ""], ["Schmidt", "Mark", ""]]}, {"id": "1903.08356", "submitter": "Omid Alemi", "authors": "Omid Alemi and Philippe Pasquier", "title": "Machine Learning for Data-Driven Movement Generation: a Review of the\n  State of the Art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of non-linear and interactive media such as video games has\nincreased the need for automatic movement animation generation. In this survey,\nwe review and analyze different aspects of building automatic movement\ngeneration systems using machine learning techniques and motion capture data.\nWe cover topics such as high-level movement characterization, training data,\nfeatures representation, machine learning models, and evaluation methods. We\nconclude by presenting a discussion of the reviewed literature and outlining\nthe research gaps and remaining challenges for future work.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 06:32:10 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Alemi", "Omid", ""], ["Pasquier", "Philippe", ""]]}, {"id": "1903.08375", "submitter": "Seongok Ryu", "authors": "Seongok Ryu, Yongchan Kwon, and Woo Youn Kim", "title": "Uncertainty quantification of molecular property prediction with\n  Bayesian neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have outperformed existing machine learning models in\nvarious molecular applications. In practical applications, it is still\ndifficult to make confident decisions because of the uncertainty in predictions\narisen from insufficient quality and quantity of training data. Here, we show\nthat Bayesian neural networks are useful to quantify the uncertainty of\nmolecular property prediction with three numerical experiments. In particular,\nit enables us to decompose the predictive variance into the model- and\ndata-driven uncertainties, which helps to elucidate the source of errors. In\nthe logP predictions, we show that data noise affected the data-driven\nuncertainties more significantly than the model-driven ones. Based on this\nanalysis, we were able to find unexpected errors in the Harvard Clean Energy\nProject dataset. Lastly, we show that the confidence of prediction is closely\nrelated to the predictive uncertainty by performing on bio-activity and\ntoxicity classification problems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 07:54:49 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Ryu", "Seongok", ""], ["Kwon", "Yongchan", ""], ["Kim", "Woo Youn", ""]]}, {"id": "1903.08504", "submitter": "Cl\\'audio Rebelo De S\\'a", "authors": "Cl\\'audio Rebelo de S\\'a and Paulo Azevedo and Carlos Soares and\n  Al\\'ipio M\\'ario Jorge and Arno Knobbe", "title": "Preference rules for label ranking: Mining patterns in multi-target\n  relations", "comments": null, "journal-ref": "Information Fusion, Volume 40, March 2018, Pages 112-125", "doi": "10.1016/j.inffus.2017.07.001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate two variants of association rules for preference\ndata, Label Ranking Association Rules and Pairwise Association Rules. Label\nRanking Association Rules (LRAR) are the equivalent of Class Association Rules\n(CAR) for the Label Ranking task. In CAR, the consequent is a single class, to\nwhich the example is expected to belong to. In LRAR, the consequent is a\nranking of the labels. The generation of LRAR requires special support and\nconfidence measures to assess the similarity of rankings. In this work, we\ncarry out a sensitivity analysis of these similarity-based measures. We want to\nunderstand which datasets benefit more from such measures and which parameters\nhave more influence in the accuracy of the model. Furthermore, we propose an\nalternative type of rules, the Pairwise Association Rules (PAR), which are\ndefined as association rules with a set of pairwise preferences in the\nconsequent. While PAR can be used both as descriptive and predictive models,\nthey are essentially descriptive models. Experimental results show the\npotential of both approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 13:33:31 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["de S\u00e1", "Cl\u00e1udio Rebelo", ""], ["Azevedo", "Paulo", ""], ["Soares", "Carlos", ""], ["Jorge", "Al\u00edpio M\u00e1rio", ""], ["Knobbe", "Arno", ""]]}, {"id": "1903.08519", "submitter": "Eduardo Paluzo-Hidalgo", "authors": "Rocio Gonzalez-Diaz, Miguel A. Guti\\'errez-Naranjo, Eduardo\n  Paluzo-Hidalgo", "title": "Representative Datasets: The Perceptron Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main drawbacks of the practical use of neural networks is the long\ntime needed in the training process. Such training process consists in an\niterative change of parameters trying to minimize a loss function. These\nchanges are driven by a dataset, which can be seen as a set of labeled points\nin an n-dimensional space. In this paper, we explore the concept of it\nrepresentative dataset which is smaller than the original dataset and satisfies\na nearness condition independent of isometric transformations. The\nrepresentativeness is measured using persistence diagrams due to its\ncomputational efficiency. We also prove that the accuracy of the learning\nprocess of a neural network on a representative dataset is comparable with the\naccuracy on the original dataset when the neural network architecture is a\nperceptron and the loss function is the mean squared error. These theoretical\nresults accompanied with experimentation open a door to the size reduction of\nthe dataset in order to gain time in the training process of any neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 14:33:20 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 17:07:55 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gonzalez-Diaz", "Rocio", ""], ["Guti\u00e9rrez-Naranjo", "Miguel A.", ""], ["Paluzo-Hidalgo", "Eduardo", ""]]}, {"id": "1903.08548", "submitter": "Maurice Quach", "authors": "Maurice Quach, Giuseppe Valenzise and Frederic Dufaux", "title": "Learning Convolutional Transforms for Lossy Point Cloud Geometry\n  Compression", "comments": "Published in ICIP 2019. The source code can be found at\n  https://github.com/mauriceqch/pcc_geo_cnn and the supplementary material can\n  be found at https://www.mauricequach.com/pcc_geo_cnn_samples", "journal-ref": null, "doi": "10.1109/ICIP.2019.8803413", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient point cloud compression is fundamental to enable the deployment of\nvirtual and mixed reality applications, since the number of points to code can\nrange in the order of millions. In this paper, we present a novel data-driven\ngeometry compression method for static point clouds based on learned\nconvolutional transforms and uniform quantization. We perform joint\noptimization of both rate and distortion using a trade-off parameter. In\naddition, we cast the decoding process as a binary classification of the point\ncloud occupancy map. Our method outperforms the MPEG reference solution in\nterms of rate-distortion on the Microsoft Voxelized Upper Bodies dataset with\n51.5% BDBR savings on average. Moreover, while octree-based methods face\nexponential diminution of the number of points at low bitrates, our method\nstill produces high resolution outputs even at low bitrates. Code and\nsupplementary material are available at\nhttps://github.com/mauriceqch/pcc_geo_cnn .\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:14:15 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 15:56:14 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Quach", "Maurice", ""], ["Valenzise", "Giuseppe", ""], ["Dufaux", "Frederic", ""]]}, {"id": "1903.08552", "submitter": "Dominic Kafka", "authors": "Dominic Kafka and Daniel Wilke", "title": "Traversing the noise of dynamic mini-batch sub-sampled loss functions: A\n  visual guide", "comments": "43 pages, 22 Figures, to be submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mini-batch sub-sampling in neural network training is unavoidable, due to\ngrowing data demands, memory-limited computational resources such as graphical\nprocessing units (GPUs), and the dynamics of on-line learning. In this study we\nspecifically distinguish between static mini-batch sub-sampled loss functions,\nwhere mini-batches are intermittently fixed during training, resulting in\nsmooth but biased loss functions; and the dynamic sub-sampling equivalent,\nwhere new mini-batches are sampled at every loss evaluation, trading bias for\nvariance in sampling induced discontinuities. These render automated\noptimization strategies such as minimization line searches ineffective, since\ncritical points may not exist and function minimizers find spurious,\ndiscontinuity induced minima.\n  This paper suggests recasting the optimization problem to find stochastic\nnon-negative associated gradient projection points (SNN-GPPs). We demonstrate\nthat the SNN-GPP optimality criterion is less susceptible to sub-sampling\ninduced discontinuities than critical points or minimizers. We conduct a visual\ninvestigation, comparing local minimum and SNN-GPP optimality criteria in the\nloss functions of a simple neural network training problem for a variety of\npopular activation functions. Since SNN-GPPs better approximate the location of\ntrue optima, particularly when using smooth activation functions with high\ncurvature characteristics, we postulate that line searches locating SNN-GPPs\ncan contribute significantly to automating neural network training\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:21:52 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 15:59:52 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kafka", "Dominic", ""], ["Wilke", "Daniel", ""]]}, {"id": "1903.08560", "submitter": "Andrea Montanari", "authors": "Trevor Hastie and Andrea Montanari and Saharon Rosset and Ryan J.\n  Tibshirani", "title": "Surprises in High-Dimensional Ridgeless Least Squares Interpolation", "comments": "68 pages; 16 figures. This revision contains non-asymptotic version\n  of earlier results, and results for general coefficients", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpolators -- estimators that achieve zero training error -- have\nattracted growing attention in machine learning, mainly because state-of-the\nart neural networks appear to be models of this type. In this paper, we study\nminimum $\\ell_2$ norm (``ridgeless'') interpolation in high-dimensional least\nsquares regression. We consider two different models for the feature\ndistribution: a linear model, where the feature vectors $x_i \\in {\\mathbb R}^p$\nare obtained by applying a linear transform to a vector of i.i.d.\\ entries,\n$x_i = \\Sigma^{1/2} z_i$ (with $z_i \\in {\\mathbb R}^p$); and a nonlinear model,\nwhere the feature vectors are obtained by passing the input through a random\none-layer neural network, $x_i = \\varphi(W z_i)$ (with $z_i \\in {\\mathbb R}^d$,\n$W \\in {\\mathbb R}^{p \\times d}$ a matrix of i.i.d.\\ entries, and $\\varphi$ an\nactivation function acting componentwise on $W z_i$). We recover -- in a\nprecise quantitative way -- several phenomena that have been observed in\nlarge-scale neural networks and kernel machines, including the \"double descent\"\nbehavior of the prediction risk, and the potential benefits of\noverparametrization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 16:53:11 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 16:34:19 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 00:37:59 GMT"}, {"version": "v4", "created": "Mon, 4 Nov 2019 16:47:40 GMT"}, {"version": "v5", "created": "Mon, 7 Dec 2020 17:59:02 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Hastie", "Trevor", ""], ["Montanari", "Andrea", ""], ["Rosset", "Saharon", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1903.08568", "submitter": "Andre Wibisono", "authors": "Santosh S. Vempala and Andre Wibisono", "title": "Rapid Convergence of the Unadjusted Langevin Algorithm: Isoperimetry\n  Suffices", "comments": "v2: Added analysis of R\\'enyi divergence and Poincar\\'e assumption \\\\\n  v3: Simplified analysis of R\\'enyi divergence, improved exposition, and added\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Unadjusted Langevin Algorithm (ULA) for sampling from a\nprobability distribution $\\nu = e^{-f}$ on $\\mathbb{R}^n$. We prove a\nconvergence guarantee in Kullback-Leibler (KL) divergence assuming $\\nu$\nsatisfies a log-Sobolev inequality and the Hessian of $f$ is bounded. Notably,\nwe do not assume convexity or bounds on higher derivatives. We also prove\nconvergence guarantees in R\\'enyi divergence of order $q > 1$ assuming the\nlimit of ULA satisfies either the log-Sobolev or Poincar\\'e inequality.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:49:10 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 16:52:02 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 16:27:16 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Vempala", "Santosh S.", ""], ["Wibisono", "Andre", ""]]}, {"id": "1903.08600", "submitter": "Xiaotian Yu", "authors": "Xiaotian Yu", "title": "Contextual Bandits with Random Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits with linear payoffs, which are also known as linear\nbandits, provide a powerful alternative for solving practical problems of\nsequential decisions, e.g., online advertisements. In the era of big data,\ncontextual data usually tend to be high-dimensional, which leads to new\nchallenges for traditional linear bandits mostly designed for the setting of\nlow-dimensional contextual data. Due to the curse of dimensionality, there are\ntwo challenges in most of the current bandit algorithms: the first is high\ntime-complexity; and the second is extreme large upper regret bounds with\nhigh-dimensional data. In this paper, in order to attack the above two\nchallenges effectively, we develop an algorithm of Contextual Bandits via\nRAndom Projection (\\texttt{CBRAP}) in the setting of linear payoffs, which\nworks especially for high-dimensional contextual data. The proposed\n\\texttt{CBRAP} algorithm is time-efficient and flexible, because it enables\nplayers to choose an arm in a low-dimensional space, and relaxes the sparsity\nassumption of constant number of non-zero components in previous work. Besides,\nwe provide a linear upper regret bound for the proposed algorithm, which is\nassociated with reduced dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:34:11 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Yu", "Xiaotian", ""]]}, {"id": "1903.08619", "submitter": "Hilal Asi", "authors": "Hilal Asi, John C. Duchi", "title": "The importance of better models in stochastic optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard stochastic optimization methods are brittle, sensitive to stepsize\nchoices and other algorithmic parameters, and they exhibit instability outside\nof well-behaved families of objectives. To address these challenges, we\ninvestigate models for stochastic minimization and learning problems that\nexhibit better robustness to problem families and algorithmic parameters. With\nappropriately accurate models---which we call the aProx family---stochastic\nmethods can be made stable, provably convergent and asymptotically optimal;\neven modeling that the objective is nonnegative is sufficient for this\nstability. We extend these results beyond convexity to weakly convex\nobjectives, which include compositions of convex losses with smooth functions\ncommon in modern machine learning applications. We highlight the importance of\nrobustness and accurate modeling with a careful experimental evaluation of\nconvergence time and algorithm sensitivity.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 17:04:24 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Asi", "Hilal", ""], ["Duchi", "John C.", ""]]}, {"id": "1903.08640", "submitter": "Frederik Heber", "authors": "Frederik Heber, Zofia Trstanova, Benedict Leimkuhler", "title": "TATi-Thermodynamic Analytics ToolkIt: TensorFlow-based software for\n  posterior sampling in machine learning applications", "comments": "25 pages: textual improvements with results unchanged, sections on\n  TATi architecture and software performance removed for size constraints,\n  extended EQN parts, added MNIST nonlinear perceptron example", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of GPU-assisted hardware and maturing high-efficiency\nsoftware platforms such as TensorFlow and PyTorch, Bayesian posterior sampling\nfor neural networks becomes plausible. In this article we discuss Bayesian\nparametrization in machine learning based on Markov Chain Monte Carlo methods,\nspecifically discretized stochastic differential equations such as Langevin\ndynamics and extended system methods in which an ensemble of walkers is\nemployed to enhance sampling. We provide a glimpse of the potential of the\nsampling-intensive approach by studying (and visualizing) the loss landscape of\na neural network applied to the MNIST data set. Moreover, we investigate how\nthe sampling efficiency itself can be significantly enhanced through an\nensemble quasi-Newton preconditioning method. This article accompanies the\nrelease of a new TensorFlow software package, the Thermodynamic Analytics\nToolkIt, which is used in the computational experiments.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 17:56:57 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 20:26:23 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Heber", "Frederik", ""], ["Trstanova", "Zofia", ""], ["Leimkuhler", "Benedict", ""]]}, {"id": "1903.08652", "submitter": "Luchen Liu", "authors": "Luchen Liu, Haoran Li, Zhiting Hu, Haoran Shi, Zichang Wang, Jian\n  Tang, Ming Zhang", "title": "Learning Hierarchical Representations of Electronic Health Records for\n  Clinical Outcome Prediction", "comments": "10 pages, 2 figures, accepted by AMIA annual symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical outcome prediction based on the Electronic Health Record (EHR) plays\na crucial role in improving the quality of healthcare. Conventional deep\nsequential models fail to capture the rich temporal patterns encoded in the\nlongand irregular clinical event sequences. We make the observation that\nclinical events at a long time scale exhibit strongtemporal patterns, while\nevents within a short time period tend to be disordered co-occurrence. We thus\npropose differentiated mechanisms to model clinical events at different time\nscales. Our model learns hierarchical representationsof event sequences, to\nadaptively distinguish between short-range and long-range events, and\naccurately capture coretemporal dependencies. Experimental results on real\nclinical data show that our model greatly improves over previous\nstate-of-the-art models, achieving AUC scores of 0.94 and 0.90 for predicting\ndeath and ICU admission respectively, Our model also successfully identifies\nimportant events for different clinical outcome prediction tasks\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 10:21:42 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 02:22:53 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liu", "Luchen", ""], ["Li", "Haoran", ""], ["Hu", "Zhiting", ""], ["Shi", "Haoran", ""], ["Wang", "Zichang", ""], ["Tang", "Jian", ""], ["Zhang", "Ming", ""]]}, {"id": "1903.08671", "submitter": "Rahaf Aljundi", "authors": "Rahaf Aljundi, Min Lin, Baptiste Goujaud and Yoshua Bengio", "title": "Gradient based sample selection for online continual learning", "comments": "Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continual learning agent learns online with a non-stationary and\nnever-ending stream of data. The key to such learning process is to overcome\nthe catastrophic forgetting of previously seen data, which is a well known\nproblem of neural networks. To prevent forgetting, a replay buffer is usually\nemployed to store the previous data for the purpose of rehearsal. Previous\nworks often depend on task boundary and i.i.d. assumptions to properly select\nsamples for the replay buffer. In this work, we formulate sample selection as a\nconstraint reduction problem based on the constrained optimization view of\ncontinual learning. The goal is to select a fixed subset of constraints that\nbest approximate the feasible region defined by the original constraints. We\nshow that it is equivalent to maximizing the diversity of samples in the replay\nbuffer with parameters gradient as the feature. We further develop a greedy\nalternative that is cheap and efficient. The advantage of the proposed method\nis demonstrated by comparing to other alternatives under the continual learning\nsetting. Further comparisons are made against state of the art methods that\nrely on task boundaries which show comparable or even better results for our\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:01:55 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 13:20:35 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 09:00:19 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 15:52:08 GMT"}, {"version": "v5", "created": "Thu, 31 Oct 2019 14:45:47 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Aljundi", "Rahaf", ""], ["Lin", "Min", ""], ["Goujaud", "Baptiste", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1903.08674", "submitter": "Yikuan Li", "authors": "Yikuan Li and Yajie Zhu", "title": "Performance Measurement for Deep Bayesian Neural Network", "comments": "university requires the paper going through a standard procedure\n  before publish, the paper will be published again after the procedure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Bayesian neural network has aroused a great attention in recent years\nsince it combines the benefits of deep neural network and probability theory.\nBecause of this, the network can make predictions and quantify the uncertainty\nof the predictions at the same time, which is important in many\nlife-threatening areas. However, most of the recent researches are mainly\nfocusing on making the Bayesian neural network easier to train, and proposing\nmethods to estimate the uncertainty. I notice there are very few works that\nproperly discuss the ways to measure the performance of the Bayesian neural\nnetwork. Although accuracy and average uncertainty are commonly used for now,\nthey are too general to provide any insight information about the model. In\nthis paper, we would like to introduce more specific criteria and propose\nseveral metrics to measure the model performance from different perspectives,\nwhich include model calibration measurement, data rejection ability and\nuncertainty divergence for samples from the same and different distributions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:04:16 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 13:16:45 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Li", "Yikuan", ""], ["Zhu", "Yajie", ""]]}, {"id": "1903.08689", "submitter": "Yilun Du", "authors": "Yilun Du and Igor Mordatch", "title": "Implicit Generation and Generalization in Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy based models (EBMs) are appealing due to their generality and\nsimplicity in likelihood modeling, but have been traditionally difficult to\ntrain. We present techniques to scale MCMC based EBM training on continuous\nneural networks, and we show its success on the high-dimensional data domains\nof ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories,\nachieving better samples than other likelihood models and nearing the\nperformance of contemporary GAN approaches, while covering all modes of the\ndata. We highlight some unique capabilities of implicit generation such as\ncompositionality and corrupt image reconstruction and inpainting. Finally, we\nshow that EBMs are useful models across a wide variety of tasks, achieving\nstate-of-the-art out-of-distribution classification, adversarially robust\nclassification, state-of-the-art continual online class learning, and coherent\nlong term predicted trajectory rollouts.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:34:29 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 02:54:05 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 19:54:22 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 20:53:53 GMT"}, {"version": "v5", "created": "Wed, 24 Jun 2020 01:52:12 GMT"}, {"version": "v6", "created": "Tue, 30 Jun 2020 03:25:59 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Du", "Yilun", ""], ["Mordatch", "Igor", ""]]}, {"id": "1903.08690", "submitter": "Xiang Wu", "authors": "Xiang Wu, Ruiqi Guo, David Simcha, Dave Dopson, Sanjiv Kumar", "title": "Efficient Inner Product Approximation in Hybrid Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many emerging use cases of data mining and machine learning operate on large\ndatasets with data from heterogeneous sources, specifically with both sparse\nand dense components. For example, dense deep neural network embedding vectors\nare often used in conjunction with sparse textual features to provide high\ndimensional hybrid representation of documents. Efficient search in such hybrid\nspaces is very challenging as the techniques that perform well for sparse\nvectors have little overlap with those that work well for dense vectors.\nPopular techniques like Locality Sensitive Hashing (LSH) and its data-dependent\nvariants also do not give good accuracy in high dimensional hybrid spaces. Even\nthough hybrid scenarios are becoming more prevalent, currently there exist no\nefficient techniques in literature that are both fast and accurate. In this\npaper, we propose a technique that approximates the inner product computation\nin hybrid vectors, leading to substantial speedup in search while maintaining\nhigh accuracy. We also propose efficient data structures that exploit modern\ncomputer architectures, resulting in orders of magnitude faster search than the\nexisting baselines. The performance of the proposed method is demonstrated on\nseveral datasets including a very large scale industrial dataset containing one\nbillion vectors in a billion dimensional space, achieving over 10x speedup and\nhigher accuracy against competitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:35:10 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Wu", "Xiang", ""], ["Guo", "Ruiqi", ""], ["Simcha", "David", ""], ["Dopson", "Dave", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1903.08708", "submitter": "Haihao Lu", "authors": "Haihao Lu, Sai Praneeth Karimireddy, Natalia Ponomareva, Vahab\n  Mirrokni", "title": "Accelerating Gradient Boosting Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Boosting Machine (GBM) is an extremely powerful supervised learning\nalgorithm that is widely used in practice. GBM routinely features as a leading\nalgorithm in machine learning competitions such as Kaggle and the KDDCup. In\nthis work, we propose Accelerated Gradient Boosting Machine (AGBM) by\nincorporating Nesterov's acceleration techniques into the design of GBM. The\ndifficulty in accelerating GBM lies in the fact that weak (inexact) learners\nare commonly used, and therefore the errors can accumulate in the momentum\nterm. To overcome it, we design a \"corrected pseudo residual\" and fit best weak\nlearner to this corrected pseudo residual, in order to perform the z-update.\nThus, we are able to derive novel computational guarantees for AGBM. This is\nthe first GBM type of algorithm with theoretically-justified accelerated\nconvergence rate. Finally we demonstrate with a number of numerical experiments\nthe effectiveness of AGBM over conventional GBM in obtaining a model with good\ntraining and/or testing data fidelity.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 19:19:08 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 19:03:18 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 17:41:35 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Lu", "Haihao", ""], ["Karimireddy", "Sai Praneeth", ""], ["Ponomareva", "Natalia", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1903.08734", "submitter": "Nicolo Frisiani", "authors": "Nicol\\`o Frisiani, Alexis Laignelet, Batuhan G\\\"uler", "title": "Combination of multiple Deep Learning architectures for Offensive\n  Language Detection in Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report contains the details regarding our submission to the OffensEval\n2019 (SemEval 2019 - Task 6). The competition was based on the Offensive\nLanguage Identification Dataset. We first discuss the details of the classifier\nimplemented and the type of input data used and pre-processing performed. We\nthen move onto critically evaluating our performance. We have achieved a\nmacro-average F1-score of 0.76, 0.68, 0.54, respectively for Task a, Task b,\nand Task c, which we believe reflects on the level of sophistication of the\nmodels implemented. Finally, we will be discussing the difficulties encountered\nand possible improvements for the future.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 11:19:38 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 16:13:31 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Frisiani", "Nicol\u00f2", ""], ["Laignelet", "Alexis", ""], ["G\u00fcler", "Batuhan", ""]]}, {"id": "1903.08738", "submitter": "Hoang M. Le", "authors": "Hoang M. Le, Cameron Voloshin, Yisong Yue", "title": "Batch Policy Learning under Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning policies for real-world domains, two important questions arise:\n(i) how to efficiently use pre-collected off-policy, non-optimal behavior data;\nand (ii) how to mediate among different competing objectives and constraints.\nWe thus study the problem of batch policy learning under multiple constraints,\nand offer a systematic solution. We first propose a flexible meta-algorithm\nthat admits any batch reinforcement learning and online learning procedure as\nsubroutines. We then present a specific algorithmic instantiation and provide\nperformance guarantees for the main objective and all constraints. To certify\nconstraint satisfaction, we propose a new and simple method for off-policy\npolicy evaluation (OPE) and derive PAC-style bounds. Our algorithm achieves\nstrong empirical results in different domains, including in a challenging\nproblem of simulated car driving subject to multiple constraints such as lane\nkeeping and smooth driving. We also show experimentally that our OPE method\noutperforms other popular OPE techniques on a standalone basis, especially in a\nhigh-dimensional setting.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 21:01:22 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Le", "Hoang M.", ""], ["Voloshin", "Cameron", ""], ["Yue", "Yisong", ""]]}, {"id": "1903.08739", "submitter": "Gerhard Wohlgenannt Dr.", "authors": "Gerhard Wohlgenannt and Artemii Babushkin and Denis Romashov and Igor\n  Ukrainets and Anton Maskaykin and Ilya Shutov", "title": "Russian Language Datasets in the Digitial Humanities Domain and Their\n  Evaluation with Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Russian language datasets in the digital humanities\ndomain for the evaluation of word embedding techniques or similar language\nmodeling and feature learning algorithms. The datasets are split into two task\ntypes, word intrusion and word analogy, and contain 31362 task units in total.\nThe characteristics of the tasks and datasets are that they build upon small,\ndomain-specific corpora, and that the datasets contain a high number of named\nentities. The datasets were created manually for two fantasy novel book series\n(\"A Song of Ice and Fire\" and \"Harry Potter\"). We provide baseline evaluations\nwith popular word embedding models trained on the book corpora for the given\ntasks, both for the Russian and English language versions of the datasets.\nFinally, we compare and analyze the results and discuss specifics of Russian\nlanguage with regards to the problem setting.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:18:48 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Wohlgenannt", "Gerhard", ""], ["Babushkin", "Artemii", ""], ["Romashov", "Denis", ""], ["Ukrainets", "Igor", ""], ["Maskaykin", "Anton", ""], ["Shutov", "Ilya", ""]]}, {"id": "1903.08752", "submitter": "Nirupam Gupta", "authors": "Nirupam Gupta and Nitin H. Vaidya", "title": "Byzantine Fault Tolerant Distributed Linear Regression", "comments": "Manuscript revised by adding; a new improved filtering technique, and\n  convergence analysis with noise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of Byzantine fault tolerance in distributed\nlinear regression in a multi-agent system. However, the proposed algorithms are\ngiven for a more general class of distributed optimization problems, of which\ndistributed linear regression is a special case. The system comprises of a\nserver and multiple agents, where each agent is holding a certain number of\ndata points and responses that satisfy a linear relationship (could be noisy).\nThe objective of the server is to determine this relationship, given that some\nof the agents in the system (up to a known number) are Byzantine faulty (aka.\nactively adversarial). We show that the server can achieve this objective, in a\ndeterministic manner, by robustifying the original distributed gradient descent\nmethod using norm based filters, namely 'norm filtering' and 'norm-cap\nfiltering', incurring an additional log-linear computation cost in each\niteration. The proposed algorithms improve upon the existing methods on three\nlevels: i) no assumptions are required on the probability distribution of data\npoints, ii) system can be partially asynchronous, and iii) the computational\noverhead (in order to handle Byzantine faulty agents) is log-linear in number\nof agents and linear in dimension of data points. The proposed algorithms\ndiffer from each other in the assumptions made for their correctness, and the\ngradient filter they use.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 21:37:42 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 15:05:46 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Gupta", "Nirupam", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "1903.08778", "submitter": "Matt Jordan", "authors": "Matt Jordan, Justin Lewis, Alexandros G. Dimakis", "title": "Provable Certificates for Adversarial Examples: Fitting a Ball in the\n  Union of Polytopes", "comments": "Code can be found here:\n  https://github.com/revbucket/geometric-certificates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for computing exact pointwise robustness of deep\nneural networks for all convex $\\ell_p$ norms. Our algorithm, GeoCert, finds\nthe largest $\\ell_p$ ball centered at an input point $x_0$, within which the\noutput class of a given neural network with ReLU nonlinearities remains\nunchanged. We relate the problem of computing pointwise robustness of these\nnetworks to that of computing the maximum norm ball with a fixed center that\ncan be contained in a non-convex polytope. This is a challenging problem in\ngeneral, however we show that there exists an efficient algorithm to compute\nthis for polyhedral complices. Further we show that piecewise linear neural\nnetworks partition the input space into a polyhedral complex. Our algorithm has\nthe ability to almost immediately output a nontrivial lower bound to the\npointwise robustness which is iteratively improved until it ultimately becomes\ntight. We empirically show that our approach generates distance lower bounds\nthat are tighter compared to prior work, under moderate time constraints.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 23:29:02 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 00:35:59 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Jordan", "Matt", ""], ["Lewis", "Justin", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1903.08789", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh, Dianne P. O'Leary", "title": "Interpreting Neural Networks Using Flip Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been criticized for their lack of easy interpretation,\nwhich undermines confidence in their use for important applications. Here, we\nintroduce a novel technique, interpreting a trained neural network by\ninvestigating its flip points. A flip point is any point that lies on the\nboundary between two output classes: e.g. for a neural network with a binary\nyes/no output, a flip point is any input that generates equal scores for \"yes\"\nand \"no\". The flip point closest to a given input is of particular importance,\nand this point is the solution to a well-posed optimization problem. This paper\ngives an overview of the uses of flip points and how they are computed. Through\nresults on standard datasets, we demonstrate how flip points can be used to\nprovide detailed interpretation of the output produced by a neural network.\nMoreover, for a given input, flip points enable us to measure confidence in the\ncorrectness of outputs much more effectively than softmax score. They also\nidentify influential features of the inputs, identify bias, and find changes in\nthe input that change the output of the model. We show that distance between an\ninput and the closest flip point identifies the most influential points in the\ntraining data. Using principal component analysis (PCA) and rank-revealing QR\nfactorization (RR-QR), the set of directions from each training input to its\nclosest flip point provides explanations of how a trained neural network\nprocesses an entire dataset: what features are most important for\nclassification into a given class, which features are most responsible for\nparticular misclassifications, how an adversary might fool the network, etc.\nAlthough we investigate flip points for neural networks, their usefulness is\nactually model-agnostic.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 01:03:42 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P.", ""]]}, {"id": "1903.08792", "submitter": "Richard Cheng", "authors": "Richard Cheng, Gabor Orosz, Richard M. Murray, Joel W. Burdick", "title": "End-to-End Safe Reinforcement Learning through Barrier Functions for\n  Safety-Critical Continuous Control Tasks", "comments": "Published in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms have found limited success beyond\nsimulated applications, and one main reason is the absence of safety guarantees\nduring the learning process. Real world systems would realistically fail or\nbreak before an optimal controller can be learned. To address this issue, we\npropose a controller architecture that combines (1) a model-free RL-based\ncontroller with (2) model-based controllers utilizing control barrier functions\n(CBFs) and (3) on-line learning of the unknown system dynamics, in order to\nensure safety during learning. Our general framework leverages the success of\nRL algorithms to learn high-performance controllers, while the CBF-based\ncontrollers both guarantee safety and guide the learning process by\nconstraining the set of explorable polices. We utilize Gaussian Processes (GPs)\nto model the system dynamics and its uncertainties.\n  Our novel controller synthesis algorithm, RL-CBF, guarantees safety with high\nprobability during the learning process, regardless of the RL algorithm used,\nand demonstrates greater policy exploration efficiency. We test our algorithm\non (1) control of an inverted pendulum and (2) autonomous car-following with\nwireless vehicle-to-vehicle communication, and show that our algorithm attains\nmuch greater sample efficiency in learning than other state-of-the-art\nalgorithms and maintains safety during the entire learning process.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 01:29:14 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Cheng", "Richard", ""], ["Orosz", "Gabor", ""], ["Murray", "Richard M.", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1903.08828", "submitter": "Anqi Qiu DR", "authors": "Caoqiang Liu, Hui Ji, Anqi Qiu", "title": "Convolutional Neural Network on Semi-Regular Triangulated Meshes and its\n  Application to Brain Image Data", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a convolution neural network (CNN) on semi-regular triangulated\nmeshes whose vertices have 6 neighbours. The key blocks of the proposed CNN,\nincluding convolution and down-sampling, are directly defined in a vertex\ndomain. By exploiting the ordering property of semi-regular meshes, the\nconvolution is defined on a vertex domain with strong motivation from the\nspatial definition of classic convolution. Moreover, the down-sampling of a\nsemi-regular mesh embedded in a 3D Euclidean space can achieve a down-sampling\nrate of 4, 16, 64, etc. We demonstrated the use of this vertex-based graph CNN\nfor the classification of mild cognitive impairment (MCI) and Alzheimer's\ndisease (AD) based on 3169 MRI scans of the Alzheimer's Disease Neuroimaging\nInitiative (ADNI). We compared the performance of the vertex-based graph CNN\nwith that of the spectral graph CNN.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 04:49:36 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 06:37:44 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 01:47:59 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Liu", "Caoqiang", ""], ["Ji", "Hui", ""], ["Qiu", "Anqi", ""]]}, {"id": "1903.08829", "submitter": "Arash Ali Amini", "authors": "Arash A. Amini, Marina Paez, Lizhen Lin and Zahra S. Razaee", "title": "Exact slice sampler for Hierarchical Dirichlet Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an exact slice sampler for Hierarchical Dirichlet process (HDP)\nand its associated mixture models (Teh et al., 2006). Although there are\nexisting MCMC algorithms for sampling from the HDP, a slice sampler has been\nmissing from the literature. Slice sampling is well-known for its desirable\nproperties including its fast mixing and its natural potential for\nparallelization. On the other hand, the hierarchical nature of HDPs poses\nchallenges to adopting a full-fledged slice sampler that automatically\ntruncates all the infinite measures involved without ad-hoc modifications. In\nthis work, we adopt the powerful idea of Bayesian variable augmentation to\naddress this challenge. By introducing new latent variables, we obtain a full\nfactorization of the joint distribution that is suitable for slice sampling.\nOur algorithm has several appealing features such as (1) fast mixing; (2)\nremaining exact while allowing natural truncation of the underlying\ninfinite-dimensional measures, as in (Kalli et al., 2011), resulting in updates\nof only a finite number of necessary atoms and weights in each iteration; and\n(3) being naturally suited to parallel implementations. The underlying\nprinciple for joint factorization of the full likelihood is simple and can be\napplied to many other settings, such as designing sampling algorithms for\ngeneral dependent Dirichlet process (DDP) models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 04:51:22 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Amini", "Arash A.", ""], ["Paez", "Marina", ""], ["Lin", "Lizhen", ""], ["Razaee", "Zahra S.", ""]]}, {"id": "1903.08850", "submitter": "Aditya Grover", "authors": "Aditya Grover, Eric Wang, Aaron Zweig, Stefano Ermon", "title": "Stochastic Optimization of Sorting Networks via Continuous Relaxations", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting input objects is an important step in many machine learning\npipelines. However, the sorting operator is non-differentiable with respect to\nits inputs, which prohibits end-to-end gradient-based optimization. In this\nwork, we propose NeuralSort, a general-purpose continuous relaxation of the\noutput of the sorting operator from permutation matrices to the set of unimodal\nrow-stochastic matrices, where every row sums to one and has a distinct arg\nmax. This relaxation permits straight-through optimization of any computational\ngraph involve a sorting operation. Further, we use this relaxation to enable\ngradient-based stochastic optimization over the combinatorially large space of\npermutations by deriving a reparameterized gradient estimator for the\nPlackett-Luce family of distributions over permutations. We demonstrate the\nusefulness of our framework on three tasks that require learning semantic\norderings of high-dimensional objects, including a fully differentiable,\nparameterized extension of the k-nearest neighbors algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 07:05:44 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 07:56:18 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Grover", "Aditya", ""], ["Wang", "Eric", ""], ["Zweig", "Aaron", ""], ["Ermon", "Stefano", ""]]}, {"id": "1903.08858", "submitter": "Fuad Noman", "authors": "Chun-Ren Phang, Chee-Ming Ting, Fuad Noman, Hernando Ombao", "title": "Classification of EEG-Based Brain Connectivity Networks in Schizophrenia\n  Using a Multi-Domain Connectome Convolutional Neural Network", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": "10.1109/JBHI.2019.2941222", "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exploit altered patterns in brain functional connectivity as features for\nautomatic discriminative analysis of neuropsychiatric patients. Deep learning\nmethods have been introduced to functional network classification only very\nrecently for fMRI, and the proposed architectures essentially focused on a\nsingle type of connectivity measure. We propose a deep convolutional neural\nnetwork (CNN) framework for classification of electroencephalogram\n(EEG)-derived brain connectome in schizophrenia (SZ). To capture complementary\naspects of disrupted connectivity in SZ, we explore combination of various\nconnectivity features consisting of time and frequency-domain metrics of\neffective connectivity based on vector autoregressive model and partial\ndirected coherence, and complex network measures of network topology. We design\na novel multi-domain connectome CNN (MDC-CNN) based on a parallel ensemble of\n1D and 2D CNNs to integrate the features from various domains and dimensions\nusing different fusion strategies. Hierarchical latent representations learned\nby the multiple convolutional layers from EEG connectivity reveal apparent\ngroup differences between SZ and healthy controls (HC). Results on a large\nresting-state EEG dataset show that the proposed CNNs significantly outperform\ntraditional support vector machine classifiers. The MDC-CNN with combined\nconnectivity features further improves performance over single-domain CNNs\nusing individual features, achieving remarkable accuracy of $93.06\\%$ with a\ndecision-level fusion. The proposed MDC-CNN by integrating information from\ndiverse brain connectivity descriptors is able to accurately discriminate SZ\nfrom HC. The new framework is potentially useful for developing diagnostic\ntools for SZ and other disorders.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 07:35:54 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Phang", "Chun-Ren", ""], ["Ting", "Chee-Ming", ""], ["Noman", "Fuad", ""], ["Ombao", "Hernando", ""]]}, {"id": "1903.08871", "submitter": "Xiwei Tang", "authors": "Xiwei Tang, Xuan Bi and Annie Qu", "title": "Individualized Multilayer Tensor Learning with An Application in Imaging\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is motivated by multimodality breast cancer imaging data, which is\nquite challenging in that the signals of discrete tumor-associated\nmicrovesicles (TMVs) are randomly distributed with heterogeneous patterns. This\nimposes a significant challenge for conventional imaging regression and\ndimension reduction models assuming a homogeneous feature structure. We develop\nan innovative multilayer tensor learning method to incorporate heterogeneity to\na higher-order tensor decomposition and predict disease status effectively\nthrough utilizing subject-wise imaging features and multimodality information.\nSpecifically, we construct a multilayer decomposition which leverages an\nindividualized imaging layer in addition to a modality-specific tensor\nstructure. One major advantage of our approach is that we are able to\nefficiently capture the heterogeneous spatial features of signals that are not\ncharacterized by a population structure as well as integrating multimodality\ninformation simultaneously. To achieve scalable computing, we develop a new\nbi-level block improvement algorithm. In theory, we investigate both the\nalgorithm convergence property, tensor signal recovery error bound and\nasymptotic consistency for prediction model estimation. We also apply the\nproposed method for simulated and human breast cancer imaging data. Numerical\nresults demonstrate that the proposed method outperforms other existing\ncompeting methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 08:18:08 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Tang", "Xiwei", ""], ["Bi", "Xuan", ""], ["Qu", "Annie", ""]]}, {"id": "1903.08889", "submitter": "Uriel Singer", "authors": "Uriel Singer and Ido Guy and Kira Radinsky", "title": "Node Embedding over Temporal Graphs", "comments": null, "journal-ref": "IJCAI 2019 Pages 4605-4612", "doi": "10.24963/ijcai.2019/640", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we present a method for node embedding in temporal graphs. We\npropose an algorithm that learns the evolution of a temporal graph's nodes and\nedges over time and incorporates this dynamics in a temporal node embedding\nframework for different graph prediction tasks. We present a joint loss\nfunction that creates a temporal embedding of a node by learning to combine its\nhistorical temporal embeddings, such that it optimizes per given task (e.g.,\nlink prediction). The algorithm is initialized using static node embeddings,\nwhich are then aligned over the representations of a node at different time\npoints, and eventually adapted for the given task in a joint optimization. We\nevaluate the effectiveness of our approach over a variety of temporal graphs\nfor the two fundamental tasks of temporal link prediction and multi-label node\nclassification, comparing to competitive baselines and algorithmic\nalternatives. Our algorithm shows performance improvements across many of the\ndatasets and baselines and is found particularly effective for graphs that are\nless cohesive, with a lower clustering coefficient.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 09:15:09 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 20:30:58 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 17:58:06 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Singer", "Uriel", ""], ["Guy", "Ido", ""], ["Radinsky", "Kira", ""]]}, {"id": "1903.08901", "submitter": "Anton Martinsson", "authors": "Z. Trstanova, A. Martinsson, C. Matthews, S. Jimenez, B. Leimkuhler,\n  T. Van Delft, M. Wilkinson", "title": "Transferability of Operational Status Classification Models Among\n  Different Wind Turbine Typesq", "comments": "9 pages", "journal-ref": null, "doi": "10.1088/1742-6596/1222/1/012041", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A detailed understanding of wind turbine performance status classification\ncan improve operations and maintenance in the wind energy industry. Due to\ndifferent engineering properties of wind turbines, the standard supervised\nlearning models used for classification do not generalize across data sets\nobtained from different wind sites. We propose two methods to deal with the\ntransferability of the trained models: first, data normalization in the form of\npower curve alignment, and second, a robust method based on convolutional\nneural networks and feature-space extension. We demonstrate the success of our\nmethods on real-world data sets with industrial applications.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 09:57:30 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Trstanova", "Z.", ""], ["Martinsson", "A.", ""], ["Matthews", "C.", ""], ["Jimenez", "S.", ""], ["Leimkuhler", "B.", ""], ["Van Delft", "T.", ""], ["Wilkinson", "M.", ""]]}, {"id": "1903.08912", "submitter": "Shyam A", "authors": "Shyam A, Vignesh Ravichandran, Preejith S.P, Jayaraj Joseph and\n  Mohanasankar Sivaprakasam", "title": "PPGnet: Deep Network for Device Independent Heart Rate Estimation from\n  Photoplethysmogram", "comments": "Under review in EMBC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photoplethysmogram (PPG) is increasingly used to provide monitoring of the\ncardiovascular system under ambulatory conditions. Wearable devices like\nsmartwatches use PPG to allow long term unobtrusive monitoring of heart rate in\nfree living conditions. PPG based heart rate measurement is unfortunately\nhighly susceptible to motion artifacts, particularly when measured from the\nwrist. Traditional machine learning and deep learning approaches rely on\ntri-axial accelerometer data along with PPG to perform heart rate estimation.\nThe conventional learning based approaches have not addressed the need for\ndevice-specific modeling due to differences in hardware design among PPG\ndevices. In this paper, we propose a novel end to end deep learning model to\nperform heart rate estimation using 8 second length input PPG signal. We\nevaluate the proposed model on the IEEE SPC 2015 dataset, achieving a mean\nabsolute error of 3.36+-4.1BPM for HR estimation on 12 subjects without\nrequiring patient specific training. We also studied the feasibility of\napplying transfer learning along with sparse retraining from a comprehensive in\nhouse PPG dataset for heart rate estimation across PPG devices with different\nhardware design.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 10:30:47 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["A", "Shyam", ""], ["Ravichandran", "Vignesh", ""], ["P", "Preejith S.", ""], ["Joseph", "Jayaraj", ""], ["Sivaprakasam", "Mohanasankar", ""]]}, {"id": "1903.08942", "submitter": "Dennis Soemers", "authors": "Dennis J. N. J. Soemers, \\'Eric Piette and Cameron Browne", "title": "Biasing MCTS with Features for General Games", "comments": "Accepted at IEEE CEC 2019, Special Session on Games. Copyright of\n  final version held by IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes using a linear function approximator, rather than a deep\nneural network (DNN), to bias a Monte Carlo tree search (MCTS) player for\ngeneral games. This is unlikely to match the potential raw playing strength of\nDNNs, but has advantages in terms of generality, interpretability and resources\n(time and hardware) required for training. Features describing local patterns\nare used as inputs. The features are formulated in such a way that they are\neasily interpretable and applicable to a wide range of general games, and might\nencode simple local strategies. We gradually create new features during the\nsame self-play training process used to learn feature weights. We evaluate the\nplaying strength of an MCTS player biased by learnt features against a standard\nupper confidence bounds for trees (UCT) player in multiple different board\ngames, and demonstrate significantly improved playing strength in the majority\nof them after a small number of self-play training games.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:09:27 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Soemers", "Dennis J. N. J.", ""], ["Piette", "\u00c9ric", ""], ["Browne", "Cameron", ""]]}, {"id": "1903.08950", "submitter": "Pavol Harar", "authors": "Pavol Harar, Roswitha Bammer, Anna Breger, Monika D\\\"orfler and Zdenek\n  Smekal", "title": "Improving Machine Hearing on Limited Data Sets", "comments": "13 pages, 3 figures, 2 tables. Repository for reproducibility:\n  https://gitlab.com/hararticles/gs-ms-mt/. Keywords: audio, CNN, limited data,\n  Mel scattering, mel-spectrogram, augmented target loss function. Rewritten\n  and restructured after peer revision. Recomputed and added new experiments\n  and visualizations. Changed the presentation of the results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) architectures have originated and\nrevolutionized machine learning for images. In order to take advantage of CNNs\nin predictive modeling with audio data, standard FFT-based signal processing\nmethods are often applied to convert the raw audio waveforms into an image-like\nrepresentations (e.g. spectrograms). Even though conventional images and\nspectrograms differ in their feature properties, this kind of pre-processing\nreduces the amount of training data necessary for successful training. In this\ncontribution we investigate how input and target representations interplay with\nthe amount of available training data in a music information retrieval setting.\nWe compare the standard mel-spectrogram inputs with a newly proposed\nrepresentation, called Mel scattering. Furthermore, we investigate the impact\nof additional target data representations by using an augmented target loss\nfunction which incorporates unused available information. We observe that all\nproposed methods outperform the standard mel-transform representation when\nusing a limited data set and discuss their strengths and limitations. The\nsource code for reproducibility of our experiments as well as intermediate\nresults and model checkpoints are available in an online repository.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:29:44 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 10:26:37 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 13:20:13 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Harar", "Pavol", ""], ["Bammer", "Roswitha", ""], ["Breger", "Anna", ""], ["D\u00f6rfler", "Monika", ""], ["Smekal", "Zdenek", ""]]}, {"id": "1903.08970", "submitter": "Alex Bird", "authors": "Alex Bird, Christopher K. I. Williams, Christopher Hawthorne", "title": "Multi-Task Time Series Analysis applied to Drug Response Modelling", "comments": "To appear in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series models such as dynamical systems are frequently fitted to a\ncohort of data, ignoring variation between individual entities such as\npatients. In this paper we show how these models can be personalised to an\nindividual level while retaining statistical power, via use of multi-task\nlearning (MTL). To our knowledge this is a novel development of MTL which\napplies to time series both with and without control inputs. The modelling\nframework is demonstrated on a physiological drug response problem which\nresults in improved predictive accuracy and uncertainty estimation over\nexisting state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 13:03:55 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Bird", "Alex", ""], ["Williams", "Christopher K. I.", ""], ["Hawthorne", "Christopher", ""]]}, {"id": "1903.08998", "submitter": "Panagiotis Tsakanikas", "authors": "Panagiotis Tsakanikas, Lemonia Christina Fengou, Evanthia Manthou,\n  Alexandra Lianou, Efstathios Z. Panagou, George John E. Nychas", "title": "A unified spectra analysis workflow for the assessment of microbial\n  contamination of ready to eat green salads: Comparative study and application\n  of non-invasive sensors", "comments": null, "journal-ref": "Computers and Electronics in Agriculture, 2018", "doi": "10.1016/j.compag.2018.10.025", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study provides a comparative assessment of non-invasive sensors\nas means of estimating the microbial contamination and time-on-shelf (i.e.\nstorage time) of leafy green vegetables, using a novel unified spectra analysis\nworkflow. Two fresh ready-to-eat green salads were used in the context of this\nstudy for the purpose of evaluating the efficiency and practical application of\nthe presented workflow: rocket and baby spinach salads. The employed analysis\nworkflow consisted of robust data normalization, powerful feature selection\nbased on random forests regression, and selection of the number of partial\nleast squares regression coefficients in the training process by estimating the\nknee-point on the explained variance plot. Training processes were based on\nmicrobiological and spectral data derived during storage of green salad samples\nat isothermal conditions (4, 8 and 12C), whereas testing was performed on data\nduring storage under dynamic temperature conditions (simulating real-life\ntemperature fluctuations in the food supply chain). Since an increasing\ninterest in the use of non-invasive sensors in food quality assessment has been\nmade evident in recent years, the unified spectra analysis workflow described\nherein, by being based on the creation/usage of limited sized featured sets,\ncould be very useful in food-specific low-cost sensor development.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 13:45:08 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 10:40:29 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Tsakanikas", "Panagiotis", ""], ["Fengou", "Lemonia Christina", ""], ["Manthou", "Evanthia", ""], ["Lianou", "Alexandra", ""], ["Panagou", "Efstathios Z.", ""], ["Nychas", "George John E.", ""]]}, {"id": "1903.09003", "submitter": "Jean Daunizeau", "authors": "Jean Daunizeau", "title": "Variational Bayesian modelling of mixed-effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is concerned with an accurate and computationally efficient\nvariational bayesian treatment of mixed-effects modelling. We focus on group\nstudies, i.e. empirical studies that report multiple measurements acquired in\nmultiple subjects. When approached from a bayesian perspective, such\nmixed-effects models typically rely upon a hierarchical generative model of the\ndata, whereby both within- and between-subject effects contribute to the\noverall observed variance. The ensuing VB scheme can be used to assess\nstatistical significance at the group level and/or to capture inter-individual\ndifferences. Alternatively, it can be seen as an adaptive regularization\nprocedure, which iteratively learns the corresponding within-subject priors\nfrom estimates of the group distribution of effects of interest (cf. so-called\n\"empirical bayes\" approaches). We outline the mathematical derivation of the\nensuing VB scheme, whose open-source implementation is available as part the\nVBA toolbox.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 13:50:07 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Daunizeau", "Jean", ""]]}, {"id": "1903.09009", "submitter": "Martin Morin", "authors": "Martin Morin and Pontus Giselsson", "title": "SVAG: Stochastic Variance Adjusted Gradient Descent and Biased\n  Stochastic Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine biased gradient updates in variance reduced stochastic gradient\nmethods. For this purpose we introduce SVAG, a SAG/SAGA-like method with\nadjustable bias. SVAG is analyzed under smoothness assumptions and we provide\nstep-size conditions for convergence that match or improve on previously known\nconditions for SAG and SAGA. The analysis highlights a step-size requirement\ndifference between when SVAG is applied to cocoercive operators and when\napplied to gradients of smooth functions, a difference not present in ordinary\ngradient descent. This difference is verified with numerical experiments. A\nvariant of SVAG that adaptively selects the bias is presented and compared\nnumerically to SVAG on a set of classification problems. The adaptive SVAG\nfrequently performs among the best and always improves on the worst-case\nperformance of the non-adaptive variant.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:00:05 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 17:35:59 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Morin", "Martin", ""], ["Giselsson", "Pontus", ""]]}, {"id": "1903.09029", "submitter": "Leo Duan", "authors": "Leo L Duan", "title": "Latent Simplex Position Model: High Dimensional Multi-view Clustering\n  with Uncertainty Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional data often contain multiple facets, and several clustering\npatterns can co-exist under different variable subspaces, also known as the\nviews. While multi-view clustering algorithms were proposed, the uncertainty\nquantification remains difficult --- a particular challenge is in the high\ncomplexity of estimating the cluster assignment probability under each view,\nand sharing information among views. In this article, we propose an approximate\nBayes approach --- treating the similarity matrices generated over the views as\nrough first-stage estimates for the co-assignment probabilities; in its\nKullback-Leibler neighborhood, we obtain a refined low-rank matrix, formed by\nthe pairwise product of simplex coordinates. Interestingly, each simplex\ncoordinate directly encodes the cluster assignment uncertainty. For multi-view\nclustering, we let each view draw a parameterization from a few candidates,\nleading to dimension reduction. With high model flexibility, the estimation can\nbe efficiently carried out as a continuous optimization problem, hence enjoys\ngradient-based computation. The theory establishes the connection of this model\nto a random partition distribution under multiple views. Compared to\nsingle-view clustering approaches, substantially more interpretable results are\nobtained when clustering brains from a human traumatic brain injury study,\nusing high-dimensional gene expression data.\n  KEY WORDS: Co-regularized Clustering, Consensus, PAC-Bayes, Random Cluster\nGraph, Variable Selection\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:37:17 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 21:21:33 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Duan", "Leo L", ""]]}, {"id": "1903.09030", "submitter": "Juan Maro\\~nas", "authors": "Juan Maro\\~nas, Roberto Paredes, Daniel Ramos", "title": "Generative Models For Deep Learning with Very Scarce Data", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-13469-3_3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The goal of this paper is to deal with a data scarcity scenario where deep\nlearning techniques use to fail. We compare the use of two well established\ntechniques, Restricted Boltzmann Machines and Variational Auto-encoders, as\ngenerative models in order to increase the training set in a classification\nframework. Essentially, we rely on Markov Chain Monte Carlo (MCMC) algorithms\nfor generating new samples. We show that generalization can be improved\ncomparing this methodology to other state-of-the-art techniques, e.g.\nsemi-supervised learning with ladder networks. Furthermore, we show that RBM is\nbetter than VAE generating new samples for training a classifier with good\ngeneralization capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:38:45 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Maro\u00f1as", "Juan", ""], ["Paredes", "Roberto", ""], ["Ramos", "Daniel", ""]]}, {"id": "1903.09033", "submitter": "Siamak Ravanbakhsh", "authors": "Devon Graham, Junhao Wang, Siamak Ravanbakhsh", "title": "Equivariant Entity-Relationship Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relational model is a ubiquitous representation of big-data, in part due\nto its extensive use in databases. In this paper, we propose the Equivariant\nEntity-Relationship Network (EERN), which is a Multilayer Perceptron\nequivariant to the symmetry transformations of the Entity-Relationship model.\nTo this end, we identify the most expressive family of linear maps that are\nexactly equivariant to entity relationship symmetries, and further show that\nthey subsume recently introduced equivariant maps for sets, exchangeable\ntensors, and graphs. The proposed feed-forward layer has linear complexity in\nthe data and can be used for both inductive and transductive reasoning about\nrelational databases, including database embedding, and the prediction of\nmissing records. This provides a principled theoretical foundation for the\napplication of deep learning to one of the most abundant forms of data.\nEmpirically, EERN outperforms different variants of coupled matrix tensor\nfactorization in both synthetic and real-data experiments.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:42:14 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 13:53:27 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 01:44:07 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 19:33:06 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Graham", "Devon", ""], ["Wang", "Junhao", ""], ["Ravanbakhsh", "Siamak", ""]]}, {"id": "1903.09056", "submitter": "Taiyao Wang", "authors": "Taiyao Wang and Ioannis Ch. Paschalidis", "title": "Prescriptive Cluster-Dependent Support Vector Machines with an\n  Application to Reducing Hospital Readmissions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We augment linear Support Vector Machine (SVM) classifiers by adding three\nimportant features: (i) we introduce a regularization constraint to induce a\nsparse classifier; (ii) we devise a method that partitions the positive class\ninto clusters and selects a sparse SVM classifier for each cluster; and (iii)\nwe develop a method to optimize the values of controllable variables in order\nto reduce the number of data points which are predicted to have an undesirable\noutcome, which, in our setting, coincides with being in the positive class. The\nlatter feature leads to personalized prescriptions/recommendations. We apply\nour methods to the problem of predicting and preventing hospital readmissions\nwithin 30-days from discharge for patients that underwent a general surgical\nprocedure. To that end, we leverage a large dataset containing over 2.28\nmillion patients who had surgeries in the period 2011--2014 in the U.S. The\ndataset has been collected as part of the American College of Surgeons National\nSurgical Quality Improvement Program (NSQIP).\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 15:24:38 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Wang", "Taiyao", ""], ["Paschalidis", "Ioannis Ch.", ""]]}, {"id": "1903.09084", "submitter": "Joseph Geumlek", "authors": "Joseph Geumlek, Kamalika Chaudhuri", "title": "Profile-Based Privacy for Locally Private Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy has emerged as a gold standard in privacy-preserving\ndata analysis. A popular variant is local differential privacy, where the data\nholder is the trusted curator. A major barrier, however, towards a wider\nadoption of this model is that it offers a poor privacy-utility tradeoff.\n  In this work, we address this problem by introducing a new variant of local\nprivacy called profile-based privacy. The central idea is that the problem\nsetting comes with a graph G of data generating distributions, whose edges\nencode sensitive pairs of distributions that should be made indistinguishable.\nThis provides higher utility because unlike local differential privacy, we no\nlonger need to make every pair of private values in the domain\nindistinguishable, and instead only protect the identity of the underlying\ndistribution. We establish privacy properties of the profile-based privacy\ndefinition, such as post-processing invariance and graceful composition.\nFinally, we provide mechanisms that are private in this framework, and show via\nsimulations that they achieve higher utility than the corresponding local\ndifferential privacy mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 03:06:14 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 15:50:22 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Geumlek", "Joseph", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1903.09094", "submitter": "Nimish Awalgaonkar", "authors": "Nimish Awalgaonkar, Ilias Bilionis, Xiaoqi Liu, Panagiota Karava,\n  Athanasios Tzempelikos", "title": "Learning Personalized Thermal Preferences via Bayesian Active Learning\n  with Unimodality Constraints", "comments": "39 pages, 11 figures. References are updated. Typos are corrected.\n  Changed \"room temperatures\" to \"indoor air temperatures\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermal preferences vary from person to person and may change over time. The\nmain objective of this paper is to sequentially pose intelligent queries to\noccupants in order to optimally learn the indoor air temperature values which\nmaximize their satisfaction. Our central hypothesis is that an occupant's\npreference relation over indoor air temperature can be described using a scalar\nfunction of these temperatures, which we call the \"occupant's thermal utility\nfunction\". Information about an occupant's preference over these temperatures\nis available to us through their response to thermal preference queries :\n\"prefer warmer,\" \"prefer cooler\" and \"satisfied\" which we interpret as\nstatements about the derivative of their utility function, i.e. the utility\nfunction is \"increasing\", \"decreasing\" and \"constant\" respectively. We model\nthis hidden utility function using a Gaussian process prior with built-in\nunimodality constraint, i.e., the utility function has a unique maximum, and we\ntrain this model using Bayesian inference. This permits an expected improvement\nbased selection of next preference query to pose to the occupant, which takes\ninto account both exploration (sampling from areas of high uncertainty) and\nexploitation (sampling from areas which are likely to offer an improvement over\ncurrent best observation). We use this framework to sequentially design\nexperiments and illustrate its benefits by showing that it requires drastically\nfewer observations to learn the maximally preferred temperature values as\ncompared to other methods. This framework is an important step towards the\ndevelopment of intelligent HVAC systems which would be able to respond to\noccupants' personalized thermal comfort needs. In order to encourage the use of\nour PE framework and ensure reproducibility in results, we publish an\nimplementation of our work named GPPrefElicit as an open-source package in\nPython.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 16:23:35 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 15:13:21 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Awalgaonkar", "Nimish", ""], ["Bilionis", "Ilias", ""], ["Liu", "Xiaoqi", ""], ["Karava", "Panagiota", ""], ["Tzempelikos", "Athanasios", ""]]}, {"id": "1903.09109", "submitter": "Changjian Shui", "authors": "Changjian Shui, Mahdieh Abbasi, Louis-\\'Emile Robitaille, Boyu Wang,\n  Christian Gagn\\'e", "title": "A Principled Approach for Learning Task Similarity in Multitask Learning", "comments": null, "journal-ref": "IJCAI, 2019", "doi": "10.24963/ijcai.2019/478", "report-no": "3446--3452", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning aims at solving a set of related tasks simultaneously, by\nexploiting the shared knowledge for improving the performance on individual\ntasks. Hence, an important aspect of multitask learning is to understand the\nsimilarities within a set of tasks. Previous works have incorporated this\nsimilarity information explicitly (e.g., weighted loss for each task) or\nimplicitly (e.g., adversarial loss for feature adaptation), for achieving good\nempirical performances. However, the theoretical motivations for adding task\nsimilarity knowledge are often missing or incomplete. In this paper, we give a\ndifferent perspective from a theoretical point of view to understand this\npractice. We first provide an upper bound on the generalization error of\nmultitask learning, showing the benefit of explicit and implicit task\nsimilarity knowledge. We systematically derive the bounds based on two distinct\ntask similarity metrics: H divergence and Wasserstein distance. From these\ntheoretical results, we revisit the Adversarial Multi-task Neural Network,\nproposing a new training algorithm to learn the task relation coefficients and\nneural network parameters iteratively. We assess our new algorithm empirically\non several benchmarks, showing not only that we find interesting and robust\ntask relations, but that the proposed approach outperforms the baselines,\nreaffirming the benefits of theoretical insight in algorithm design.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 16:59:53 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 20:24:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shui", "Changjian", ""], ["Abbasi", "Mahdieh", ""], ["Robitaille", "Louis-\u00c9mile", ""], ["Wang", "Boyu", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1903.09122", "submitter": "Anastasios Tsiamis", "authors": "Anastasios Tsiamis and George J. Pappas", "title": "Finite Sample Analysis of Stochastic System Identification", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the finite sample complexity of stochastic system\nidentification using modern tools from machine learning and statistics. An\nunknown discrete-time linear system evolves over time under Gaussian noise\nwithout external inputs. The objective is to recover the system parameters as\nwell as the Kalman filter gain, given a single trajectory of output\nmeasurements over a finite horizon of length $N$. Based on a subspace\nidentification algorithm and a finite number of $N$ output samples, we provide\nnon-asymptotic high-probability upper bounds for the system parameter\nestimation errors. Our analysis uses recent results from random matrix theory,\nself-normalized martingales and SVD robustness, in order to show that with high\nprobability the estimation errors decrease with a rate of $1/\\sqrt{N}$. Our\nnon-asymptotic bounds not only agree with classical asymptotic results, but are\nalso valid even when the system is marginally stable.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 17:30:42 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Tsiamis", "Anastasios", ""], ["Pappas", "George J.", ""]]}, {"id": "1903.09132", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Csaba Szepesvari, Mohammad Ghavamzadeh, and Craig\n  Boutilier", "title": "Perturbed-History Exploration in Stochastic Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new online algorithm for minimizing the cumulative regret in\nstochastic linear bandits. The key idea is to build a perturbed history, which\nmixes the history of observed rewards with a pseudo-history of randomly\ngenerated i.i.d. pseudo-rewards. Our algorithm, perturbed-history exploration\nin a linear bandit (LinPHE), estimates a linear model from its perturbed\nhistory and pulls the arm with the highest value under that model. We prove a\n$\\tilde{O}(d \\sqrt{n})$ gap-free bound on the expected $n$-round regret of\nLinPHE, where $d$ is the number of features. Our analysis relies on novel\nconcentration and anti-concentration bounds on the weighted sum of Bernoulli\nrandom variables. To show the generality of our design, we extend LinPHE to a\nlogistic reward model. We evaluate both algorithms empirically and show that\nthey are practical.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 17:45:11 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Kveton", "Branislav", ""], ["Szepesvari", "Csaba", ""], ["Ghavamzadeh", "Mohammad", ""], ["Boutilier", "Craig", ""]]}, {"id": "1903.09136", "submitter": "Eike Petersen", "authors": "Eike Petersen, Christian Hoffmann, Philipp Rostalski", "title": "On Approximate Nonlinear Gaussian Message Passing On Factor Graphs", "comments": null, "journal-ref": "2018 IEEE Statistical Signal Processing Workshop (SSP)", "doi": "10.1109/SSP.2018.8450699", "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor graphs have recently gained increasing attention as a unified\nframework for representing and constructing algorithms for signal processing,\nestimation, and control. One capability that does not seem to be well explored\nwithin the factor graph tool kit is the ability to handle deterministic\nnonlinear transformations, such as those occurring in nonlinear filtering and\nsmoothing problems, using tabulated message passing rules. In this\ncontribution, we provide general forward (filtering) and backward (smoothing)\napproximate Gaussian message passing rules for deterministic nonlinear\ntransformation nodes in arbitrary factor graphs fulfilling a Markov property,\nbased on numerical quadrature procedures for the forward pass and a\nRauch-Tung-Striebel-type approximation of the backward pass. These message\npassing rules can be employed for deriving many algorithms for solving\nnonlinear problems using factor graphs, as is illustrated by the proposition of\na nonlinear modified Bryson-Frazier (MBF) smoother based on the presented\nmessage passing rules.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 17:48:06 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Petersen", "Eike", ""], ["Hoffmann", "Christian", ""], ["Rostalski", "Philipp", ""]]}, {"id": "1903.09139", "submitter": "Anant Sahai", "authors": "Vidya Muthukumar and Kailas Vodrahalli and Vignesh Subramanian and\n  Anant Sahai", "title": "Harmless interpolation of noisy data in regression", "comments": "52 pages, expanded version of the paper presented at ITA in San Diego\n  in Feb 2019, ISIT in Paris in July 2019, at Simons in July, and as a plenary\n  at ITW in Visby in August 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continuing mystery in understanding the empirical success of deep neural\nnetworks is their ability to achieve zero training error and generalize well,\neven when the training data is noisy and there are more parameters than data\npoints. We investigate this overparameterized regime in linear regression,\nwhere all solutions that minimize training error interpolate the data,\nincluding noise. We characterize the fundamental generalization (mean-squared)\nerror of any interpolating solution in the presence of noise, and show that\nthis error decays to zero with the number of features. Thus,\noverparameterization can be explicitly beneficial in ensuring harmless\ninterpolation of noise. We discuss two root causes for poor generalization that\nare complementary in nature -- signal \"bleeding\" into a large number of alias\nfeatures, and overfitting of noise by parsimonious feature selectors. For the\nsparse linear model with noise, we provide a hybrid interpolating scheme that\nmitigates both these issues and achieves order-optimal MSE over all possible\ninterpolating solutions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 17:51:12 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 15:41:59 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Muthukumar", "Vidya", ""], ["Vodrahalli", "Kailas", ""], ["Subramanian", "Vignesh", ""], ["Sahai", "Anant", ""]]}, {"id": "1903.09215", "submitter": "Adam Oberman", "authors": "Adam M. Oberman, Chris Finlay, Alexander Iannantuono, Tiago Salvador", "title": "Calibrated Top-1 Uncertainty estimates for classification by score based\n  models", "comments": "12 pages, 5 figures, 6 tables (major revision, new benchmark allows\n  us to show model calibration is better)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the accuracy of modern deep learning models has significantly improved\nin recent years, the ability of these models to generate uncertainty estimates\nhas not progressed to the same degree. Uncertainty methods are designed to\nprovide an estimate of class probabilities when predicting class assignment.\n  While there are a number of proposed methods for estimating uncertainty, they\nall suffer from a lack of calibration: predicted probabilities can be off from\nempirical ones by a few percent or more. By restricting the scope of our\npredictions to only the probability of Top-1 error, we can decrease the\ncalibration error of existing methods to less than one percent. As a result,\nthe scores of the methods also improve significantly over benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 19:48:45 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 16:37:47 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 18:43:16 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 13:02:58 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Oberman", "Adam M.", ""], ["Finlay", "Chris", ""], ["Iannantuono", "Alexander", ""], ["Salvador", "Tiago", ""]]}, {"id": "1903.09231", "submitter": "Rina Panigrahy", "authors": "Surbhi Goel, Rina Panigrahy", "title": "Recovering the Lowest Layer of Deep Networks with High Threshold\n  Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Giving provable guarantees for learning neural networks is a core challenge\nof machine learning theory. Most prior work gives parameter recovery guarantees\nfor one hidden layer networks, however, the networks used in practice have\nmultiple non-linear layers. In this work, we show how we can strengthen such\nresults to deeper networks -- we address the problem of uncovering the lowest\nlayer in a deep neural network under the assumption that the lowest layer uses\na high threshold before applying the activation, the upper network can be\nmodeled as a well-behaved polynomial and the input distribution is Gaussian.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 20:41:58 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 01:00:13 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Goel", "Surbhi", ""], ["Panigrahy", "Rina", ""]]}, {"id": "1903.09235", "submitter": "Taiyao Wang", "authors": "Taiyao Wang, Ioannis Ch. Paschalidis", "title": "Convergence of Parameter Estimates for Regularized Mixed Linear\n  Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider {\\em Mixed Linear Regression (MLR)}, where training data have\nbeen generated from a mixture of distinct linear models (or clusters) and we\nseek to identify the corresponding coefficient vectors. We introduce a {\\em\nMixed Integer Programming (MIP)} formulation for MLR subject to regularization\nconstraints on the coefficient vectors. We establish that as the number of\ntraining samples grows large, the MIP solution converges to the true\ncoefficient vectors in the absence of noise. Subject to slightly stronger\nassumptions, we also establish that the MIP identifies the clusters from which\nthe training samples were generated. In the special case where training data\ncome from a single cluster, we establish that the corresponding MIP yields a\nsolution that converges to the true coefficient vector even when training data\nare perturbed by (martingale difference) noise. We provide a counterexample\nindicating that in the presence of noise, the MIP may fail to produce the true\ncoefficient vectors for more than one clusters. We also provide numerical\nresults testing the MIP solutions in synthetic examples with noise.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 20:44:20 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 15:30:59 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Taiyao", ""], ["Paschalidis", "Ioannis Ch.", ""]]}, {"id": "1903.09239", "submitter": "Alice Schoenauer Sebag", "authors": "Alice Schoenauer-Sebag, Louise Heinrich, Marc Schoenauer, Michele\n  Sebag, Lani F. Wu, Steve J. Altschuler", "title": "Multi-Domain Adversarial Learning", "comments": "Accepted at ICLR'19", "journal-ref": "ICLR 2019-Seventh annual International Conference on Learning\n  Representations", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain learning (MDL) aims at obtaining a model with minimal average\nrisk across multiple domains. Our empirical motivation is automated microscopy\ndata, where cultured cells are imaged after being exposed to known and unknown\nchemical perturbations, and each dataset displays significant experimental\nbias. This paper presents a multi-domain adversarial learning approach, MuLANN,\nto leverage multiple datasets with overlapping but distinct class sets, in a\nsemi-supervised setting. Our contributions include: i) a bound on the average-\nand worst-domain risk in MDL, obtained using the H-divergence; ii) a new loss\nto accommodate semi-supervised multi-domain learning and domain adaptation;\niii) the experimental validation of the approach, improving on the state of the\nart on two standard image benchmarks, and a novel bioimage dataset, Cell.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:18:21 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Schoenauer-Sebag", "Alice", ""], ["Heinrich", "Louise", ""], ["Schoenauer", "Marc", ""], ["Sebag", "Michele", ""], ["Wu", "Lani F.", ""], ["Altschuler", "Steve J.", ""]]}, {"id": "1903.09245", "submitter": "Soheil Khorram", "authors": "Soheil Khorram, Melvin G McInnis, Emily Mower Provost", "title": "Trainable Time Warping: Aligning Time-Series in the Continuous-Time\n  Domain", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DTW calculates the similarity or alignment between two signals, subject to\ntemporal warping. However, its computational complexity grows exponentially\nwith the number of time-series. Although there have been algorithms developed\nthat are linear in the number of time-series, they are generally quadratic in\ntime-series length. The exception is generalized time warping (GTW), which has\nlinear computational cost. Yet, it can only identify simple time warping\nfunctions. There is a need for a new fast, high-quality multisequence alignment\nalgorithm. We introduce trainable time warping (TTW), whose complexity is\nlinear in both the number and the length of time-series. TTW performs alignment\nin the continuous-time domain using a sinc convolutional kernel and a\ngradient-based optimization technique. We compare TTW and GTW on 85 UCR\ndatasets in time-series averaging and classification. TTW outperforms GTW on\n67.1% of the datasets for the averaging tasks, and 61.2% of the datasets for\nthe classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:42:19 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Khorram", "Soheil", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1903.09255", "submitter": "Yan Zhang", "authors": "Yan Zhang, Michael M. Zavlanos", "title": "Distributed off-Policy Actor-Critic Reinforcement Learning with Policy\n  Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a distributed off-policy actor critic method to\nsolve multi-agent reinforcement learning problems. Specifically, we assume that\nall agents keep local estimates of the global optimal policy parameter and\nupdate their local value function estimates independently. Then, we introduce\nan additional consensus step to let all the agents asymptotically achieve\nagreement on the global optimal policy function. The convergence analysis of\nthe proposed algorithm is provided and the effectiveness of the proposed\nalgorithm is validated using a distributed resource allocation example.\nCompared to relevant distributed actor critic methods, here the agents do not\nshare information about their local tasks, but instead they coordinate to\nestimate the global policy function.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 22:04:16 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Zhang", "Yan", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "1903.09267", "submitter": "Houshang Darabi", "authors": "Ashkan Sharabiani, Adam Bress, William Galanter, Rezvan Nazempour, and\n  Houshang Darabi", "title": "A Computer-Aided System for Determining the Application Range of a\n  Warfarin Clinical Dosing Algorithm Using Support Vector Machines with a\n  Polynomial Kernel Function", "comments": "6 pages, 8 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the optimal initial dose for warfarin is a critically important\ntask. Several factors have an impact on the therapeutic dose for individual\npatients, such as patients' physical attributes (Age, Height, etc.), medication\nprofile, co-morbidities, and metabolic genotypes (CYP2C9 and VKORC1). These\nwide range factors influencing therapeutic dose, create a complex environment\nfor clinicians to determine the optimal initial dose. Using a sample of 4,237\npatients, we have proposed a companion classification model to one of the most\npopular dosing algorithms (International Warfarin Pharmacogenetics Consortium\n(IWPC) clinical model), which identifies the appropriate cohort of patients for\napplying this model. The proposed model functions as a clinical decision\nsupport system which assists clinicians in dosing. We have developed a\nclassification model using Support Vector Machines, with a polynomial kernel\nfunction to determine if applying the dose prediction model is appropriate for\na given patient. The IWPC clinical model will only be used if the patient is\nclassified as \"Safe for model\". By using the proposed methodology, the dosing\nmode's prediction accuracy increases by 15 percent in terms of Root Mean\nSquared Error and 17 percent in terms of Mean Absolute Error in dose estimates\nof patients classified as \"Safe for model\".\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 23:05:38 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Sharabiani", "Ashkan", ""], ["Bress", "Adam", ""], ["Galanter", "William", ""], ["Nazempour", "Rezvan", ""], ["Darabi", "Houshang", ""]]}, {"id": "1903.09284", "submitter": "Waheed Bajwa", "authors": "Mohsen Ghassemi, Zahra Shakeri, Anand D. Sarwate, and Waheed U. Bajwa", "title": "Learning Mixtures of Separable Dictionaries for Tensor Data: Analysis\n  and Algorithms", "comments": "18 pages, 4 figures, 3 tables; Published in IEEE Trans. Signal\n  Processing", "journal-ref": "IEEE Trans. Signal Processing, vol. 68, pp. 33-48, 2020", "doi": "10.1109/TSP.2019.2952046", "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of learning sparse representations of tensor\ndata using structured dictionary learning. It proposes learning a mixture of\nseparable dictionaries to better capture the structure of tensor data by\ngeneralizing the separable dictionary learning model. Two different approaches\nfor learning mixture of separable dictionaries are explored and sufficient\nconditions for local identifiability of the underlying dictionary are derived\nin each case. Moreover, computational algorithms are developed to solve the\nproblem of learning mixture of separable dictionaries in both batch and online\nsettings. Numerical experiments are used to show the usefulness of the proposed\nmodel and the efficacy of the developed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 01:04:50 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 03:24:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ghassemi", "Mohsen", ""], ["Shakeri", "Zahra", ""], ["Sarwate", "Anand D.", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1903.09295", "submitter": "'Stephen' Zhen Gou", "authors": "Stephen Zhen Gou, Yuyang Liu", "title": "DQN with model-based exploration: efficient learning on environments\n  with sparse rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Deep Q-Networks (DQN) with model-based exploration, an algorithm\ncombining both model-free and model-based approaches that explores better and\nlearns environments with sparse rewards more efficiently. DQN is a\ngeneral-purpose, model-free algorithm and has been proven to perform well in a\nvariety of tasks including Atari 2600 games since it's first proposed by Minh\net el. However, like many other reinforcement learning (RL) algorithms, DQN\nsuffers from poor sample efficiency when rewards are sparse in an environment.\nAs a result, most of the transitions stored in the replay memory have no\ninformative reward signal, and provide limited value to the convergence and\ntraining of the Q-Network. However, one insight is that these transitions can\nbe used to learn the dynamics of the environment as a supervised learning\nproblem. The transitions also provide information of the distribution of\nvisited states. Our algorithm utilizes these two observations to perform a\none-step planning during exploration to pick an action that leads to states\nleast likely to be seen, thus improving the performance of exploration. We\ndemonstrate our agent's performance in two classic environments with sparse\nrewards in OpenAI gym: Mountain Car and Lunar Lander.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 01:41:50 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Gou", "Stephen Zhen", ""], ["Liu", "Yuyang", ""]]}, {"id": "1903.09296", "submitter": "Dianbo Liu Dr", "authors": "Li Huang and Dianbo Liu", "title": "Patient Clustering Improves Efficiency of Federated Machine Learning to\n  predict mortality and hospital stay time using distributed Electronic Medical\n  Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical records (EMRs) supports the development of machine\nlearning algorithms for predicting disease incidence, patient response to\ntreatment, and other healthcare events. But insofar most algorithms have been\ncentralized, taking little account of the decentralized, non-identically\nindependently distributed (non-IID), and privacy-sensitive characteristics of\nEMRs that can complicate data collection, sharing and learning. To address this\nchallenge, we introduced a community-based federated machine learning (CBFL)\nalgorithm and evaluated it on non-IID ICU EMRs. Our algorithm clustered the\ndistributed data into clinically meaningful communities that captured similar\ndiagnoses and geological locations, and learnt one model for each community.\nThroughout the learning process, the data was kept local on hospitals, while\nlocally-computed results were aggregated on a server. Evaluation results show\nthat CBFL outperformed the baseline FL algorithm in terms of Area Under the\nReceiver Operating Characteristic Curve (ROC AUC), Area Under the\nPrecision-Recall Curve (PR AUC), and communication cost between hospitals and\nthe server. Furthermore, communities' performance difference could be explained\nby how dissimilar one community was to others.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 01:49:30 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Huang", "Li", ""], ["Liu", "Dianbo", ""]]}, {"id": "1903.09326", "submitter": "Xinghua Yao", "authors": "Xinghua Yao, Qiang Cheng, Guo-Qiang Zhang", "title": "A Novel Independent RNN Approach to Classification of Seizures against\n  Non-seizures", "comments": "10 pages, 2 figures, submitted to AMIA symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current clinical practices, electroencephalograms (EEG) are reviewed and\nanalyzed by trained neurologists to provide supports for therapeutic decisions.\nManual reviews can be laborious and error prone. Automatic and accurate\nseizure/non-seizure classification methods are desirable. A critical challenge\nis that seizure morphologies exhibit considerable variabilities. In order to\ncapture essential seizure features, this paper leverages an emerging deep\nlearning model, the independently recurrent neural network (IndRNN), to\nconstruct a new approach for the seizure/non-seizure classification. This new\napproach gradually expands the time scales, thereby extracting temporal and\nspatial features from the local time duration to the entire record. Evaluations\nare conducted with cross-validation experiments across subjects over the noisy\ndata of CHB-MIT. Experimental results demonstrate that the proposed approach\noutperforms the current state-of-the-art methods. In addition, we explore how\nthe segment length affects the classification performance. Thirteen different\nsegment lengths are assessed, showing that the classification performance\nvaries over the segment lengths, and the maximal fluctuating margin is more\nthan 4%. Thus, the segment length is an important factor influencing the\nclassification performance.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 02:34:18 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Yao", "Xinghua", ""], ["Cheng", "Qiang", ""], ["Zhang", "Guo-Qiang", ""]]}, {"id": "1903.09338", "submitter": "Andrew Silva", "authors": "Andrew Silva, Taylor Killian, Ivan Dario Jimenez Rodriguez, Sung-Hyun\n  Son, Matthew Gombolay", "title": "Optimization Methods for Interpretable Differentiable Decision Trees in\n  Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics 2020, 1855-1865", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are ubiquitous in machine learning for their ease of use and\ninterpretability. Yet, these models are not typically employed in reinforcement\nlearning as they cannot be updated online via stochastic gradient descent. We\novercome this limitation by allowing for a gradient update over the entire tree\nthat improves sample complexity affords interpretable policy extraction. First,\nwe include theoretical motivation on the need for policy-gradient learning by\nexamining the properties of gradient descent over differentiable decision\ntrees. Second, we demonstrate that our approach equals or outperforms a neural\nnetwork on all domains and can learn discrete decision trees online with\naverage rewards up to 7x higher than a batch-trained decision tree. Third, we\nconduct a user study to quantify the interpretability of a decision tree, rule\nlist, and a neural network with statistically significant results ($p <\n0.001$).\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:19:26 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 19:51:44 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 02:19:53 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 20:54:54 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 22:27:49 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Silva", "Andrew", ""], ["Killian", "Taylor", ""], ["Rodriguez", "Ivan Dario Jimenez", ""], ["Son", "Sung-Hyun", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1903.09341", "submitter": "Kazuyoshi Yoshii", "authors": "Kazuki Shimada, Yoshiaki Bando, Masato Mimura, Katsutoshi Itoyama,\n  Kazuyoshi Yoshii, Tatsuya Kawahara", "title": "Unsupervised Speech Enhancement Based on Multichannel NMF-Informed\n  Beamforming for Noise-Robust Automatic Speech Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/TASLP.2019.2907015", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes multichannel speech enhancement for improving automatic\nspeech recognition (ASR) in noisy environments. Recently, the minimum variance\ndistortionless response (MVDR) beamforming has widely been used because it\nworks well if the steering vector of speech and the spatial covariance matrix\n(SCM) of noise are given. To estimating such spatial information, conventional\nstudies take a supervised approach that classifies each time-frequency (TF) bin\ninto noise or speech by training a deep neural network (DNN). The performance\nof ASR, however, is degraded in an unknown noisy environment. To solve this\nproblem, we take an unsupervised approach that decomposes each TF bin into the\nsum of speech and noise by using multichannel nonnegative matrix factorization\n(MNMF). This enables us to accurately estimate the SCMs of speech and noise not\nfrom observed noisy mixtures but from separated speech and noise components. In\nthis paper we propose online MVDR beamforming by effectively initializing and\nincrementally updating the parameters of MNMF. Another main contribution is to\ncomprehensively investigate the performances of ASR obtained by various types\nof spatial filters, i.e., time-invariant and variant versions of MVDR\nbeamformers and those of rank-1 and full-rank multichannel Wiener filters, in\ncombination with MNMF. The experimental results showed that the proposed method\noutperformed the state-of-the-art DNN-based beamforming method in unknown\nenvironments that did not match training data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:36:43 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 14:53:47 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Shimada", "Kazuki", ""], ["Bando", "Yoshiaki", ""], ["Mimura", "Masato", ""], ["Itoyama", "Katsutoshi", ""], ["Yoshii", "Kazuyoshi", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "1903.09343", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott Anthony Sisson", "title": "The Binary Space Partitioning-Tree Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mondrian process represents an elegant and powerful approach for space\npartition modelling. However, as it restricts the partitions to be\naxis-aligned, its modelling flexibility is limited. In this work, we propose a\nself-consistent Binary Space Partitioning (BSP)-Tree process to generalize the\nMondrian process. The BSP-Tree process is an almost surely right continuous\nMarkov jump process that allows uniformly distributed oblique cuts in a\ntwo-dimensional convex polygon. The BSP-Tree process can also be extended using\na non-uniform probability measure to generate direction differentiated cuts.\nThe process is also self-consistent, maintaining distributional invariance\nunder a restricted subdomain. We use Conditional-Sequential Monte Carlo for\ninference using the tree structure as the high-dimensional variable. The\nBSP-Tree process's performance on synthetic data partitioning and relational\nmodelling demonstrates clear inferential improvements over the standard\nMondrian process and other related methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:38:00 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.09348", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott Anthony Sisson", "title": "Binary Space Partitioning Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Binary Space Partitioning~(BSP)-Tree process is proposed to produce\nflexible 2-D partition structures which are originally used as a Bayesian\nnonparametric prior for relational modelling. It can hardly be applied to other\nlearning tasks such as regression trees because extending the BSP-Tree process\nto a higher dimensional space is nontrivial. This paper is the first attempt to\nextend the BSP-Tree process to a d-dimensional (d>2) space. We propose to\ngenerate a cutting hyperplane, which is assumed to be parallel to d-2\ndimensions, to cut each node in the d-dimensional BSP-tree. By designing a\nsubtle strategy to sample two free dimensions from d dimensions, the extended\nBSP-Tree process can inherit the essential self-consistency property from the\noriginal version. Based on the extended BSP-Tree process, an ensemble model,\nwhich is named the BSP-Forest, is further developed for regression tasks.\nThanks to the retained self-consistency property, we can thus significantly\nreduce the geometric calculations in the inference stage. Compared to its\ncounterpart, the Mondrian Forest, the BSP-Forest can achieve similar\nperformance with fewer cuts due to its flexibility. The BSP-Forest also\noutperforms other (Bayesian) regression forests on a number of real-world data\nsets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:48:48 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.09366", "submitter": "Masanori Yamada", "authors": "Heecheol Kim, Masanori Yamada, Kosuke Miyoshi, Hiroshi Yamakawa", "title": "Macro Action Reinforcement Learning with Sequence Disentanglement using\n  Variational Autoencoder", "comments": "First and second authors equally contributed to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One problem in the application of reinforcement learning to real-world\nproblems is the curse of dimensionality on the action space. Macro actions, a\nsequence of primitive actions, have been studied to diminish the dimensionality\nof the action space with regard to the time axis. However, previous studies\nrelied on humans defining macro actions or assumed macro actions as repetitions\nof the same primitive actions. We present Factorized Macro Action Reinforcement\nLearning (FaMARL) which autonomously learns disentangled factor representation\nof a sequence of actions to generate macro actions that can be directly applied\nto general reinforcement learning algorithms. FaMARL exhibits higher scores\nthan other reinforcement learning algorithms on environments that require an\nextensive amount of search.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 05:54:27 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 01:46:52 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kim", "Heecheol", ""], ["Yamada", "Masanori", ""], ["Miyoshi", "Kosuke", ""], ["Yamakawa", "Hiroshi", ""]]}, {"id": "1903.09367", "submitter": "Peng Zhao", "authors": "Peng Zhao, Yun Yang and Qiao-Chu He", "title": "Implicit Regularization via Hadamard Product Over-Parametrization in\n  High-Dimensional Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Hadamard product parametrization as a change-of-variable\n(over-parametrization) technique for solving least square problems in the\ncontext of linear regression. Despite the non-convexity and exponentially many\nsaddle points induced by the change-of-variable, we show that under certain\nconditions, this over-parametrization leads to implicit regularization: if we\ndirectly apply gradient descent to the residual sum of squares with\nsufficiently small initial values, then under proper early stopping rule, the\niterates converge to a nearly sparse rate-optimal solution with relatively\nbetter accuracy than explicit regularized approaches. In particular, the\nresulting estimator does not suffer from extra bias due to explicit penalties,\nand can achieve the parametric root-$n$ rate (independent of the dimension)\nunder proper conditions on the signal-to-noise ratio. We perform simulations to\ncompare our methods with high dimensional linear regression with explicit\nregularizations. Our results illustrate advantages of using implicit\nregularization via gradient descent after over-parametrization in sparse vector\nestimation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 05:56:04 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Zhao", "Peng", ""], ["Yang", "Yun", ""], ["He", "Qiao-Chu", ""]]}, {"id": "1903.09376", "submitter": "Ruimeng Hu", "authors": "Ruimeng Hu", "title": "Deep Fictitious Play for Stochastic Differential Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply the idea of fictitious play to design deep neural\nnetworks (DNNs), and develop deep learning theory and algorithms for computing\nthe Nash equilibrium of asymmetric $N$-player non-zero-sum stochastic\ndifferential games, for which we refer as \\emph{deep fictitious play}, a\nmulti-stage learning process. Specifically at each stage, we propose the\nstrategy of letting individual player optimize her own payoff subject to the\nother players' previous actions, equivalent to solve $N$ decoupled stochastic\ncontrol optimization problems, which are approximated by DNNs. Therefore, the\nfictitious play strategy leads to a structure consisting of $N$ DNNs, which\nonly communicate at the end of each stage. The resulted deep learning algorithm\nbased on fictitious play is scalable, parallel and model-free, {\\it i.e.},\nusing GPU parallelization, it can be applied to any $N$-player stochastic\ndifferential game with different symmetries and heterogeneities ({\\it e.g.},\nexistence of major players). We illustrate the performance of the deep learning\nalgorithm by comparing to the closed-form solution of the linear quadratic\ngame. Moreover, we prove the convergence of fictitious play under appropriate\nassumptions, and verify that the convergent limit forms an open-loop Nash\nequilibrium. We also discuss the extensions to other strategies designed upon\nfictitious play and closed-loop Nash equilibrium in the end.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 06:46:01 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 08:26:08 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 20:24:28 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Hu", "Ruimeng", ""]]}, {"id": "1903.09381", "submitter": "Yeping Hu", "authors": "Yeping Hu, Wei Zhan, Liting Sun, Masayoshi Tomizuka", "title": "Multi-modal Probabilistic Prediction of Interactive Behavior via an\n  Interpretable Model", "comments": "accepted by the 2019 IEEE Intelligent Vehicles Symposium (IV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For autonomous agents to successfully operate in real world, the ability to\nanticipate future motions of surrounding entities in the scene can greatly\nenhance their safety levels since potentially dangerous situations could be\navoided in advance. While impressive results have been shown on predicting each\nagent's behavior independently, we argue that it is not valid to consider road\nentities individually since transitions of vehicle states are highly coupled.\nMoreover, as the predicted horizon becomes longer, modeling prediction\nuncertainties and multi-modal distributions over future sequences will turn\ninto a more challenging task. In this paper, we address this challenge by\npresenting a multi-modal probabilistic prediction approach. The proposed method\nis based on a generative model and is capable of jointly predicting sequential\nmotions of each pair of interacting agents. Most importantly, our model is\ninterpretable, which can explain the underneath logic as well as obtain more\nreliability to use in real applications. A complicate real-world roundabout\nscenario is utilized to implement and examine the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 07:06:58 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 17:02:45 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hu", "Yeping", ""], ["Zhan", "Wei", ""], ["Sun", "Liting", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1903.09383", "submitter": "Dominic Kafka", "authors": "Dominic Kafka and Daniel Wilke", "title": "Gradient-only line searches: An Alternative to Probabilistic Line\n  Searches", "comments": "25 Pages, 12 Figures, to be submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Step sizes in neural network training are largely determined using\npredetermined rules such as fixed learning rates and learning rate schedules.\nThese require user input or expensive global optimization strategies to\ndetermine their functional form and associated hyperparameters. Line searches\nare capable of adaptively resolving learning rate schedules. However, due to\ndiscontinuities induced by mini-batch sub-sampling, they have largely fallen\nout of favour. Notwithstanding, probabilistic line searches, which use\nstatistical surrogates over a limited spatial domain, have recently\ndemonstrated viability in resolving learning rates for stochastic loss\nfunctions.\n  This paper introduces an alternative paradigm, Gradient-Only Line Searches\nthat are Inexact (GOLS-I), as an alternative strategy to automatically\ndetermine learning rates in stochastic loss functions over a range of 15 orders\nof magnitude without the use of surrogates. We show that GOLS-I is a\ncompetitive strategy to reliably determine step sizes, adding high value in\nterms of performance, while being easy to implement.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 07:14:00 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 13:40:12 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kafka", "Dominic", ""], ["Wilke", "Daniel", ""]]}, {"id": "1903.09395", "submitter": "Kurt Izak Cabanilla", "authors": "Kurt Izak Cabanilla and Kevin Thomas Go", "title": "Forecasting, Causality, and Impulse Response with Neural Vector\n  Autoregressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating nonlinearity is paramount to predicting the future states of a\ndynamical system, its response to shocks, and its underlying causal network.\nHowever, most existing methods for causality detection and impulse response,\nsuch as Vector Autoregression (VAR), assume linearity and are thus unable to\ncapture the complexity. Here, we introduce a vector autoencoder nonlinear\nautoregression neural network (VANAR) capable of both automatic time series\nfeature extraction for its inputs and functional form estimation. We evaluate\nVANAR in three ways: first in terms of pure forecast accuracy, second in terms\nof detecting the correct causality between variables, and lastly in terms of\nimpulse response where we model trajectories given external shocks. These tests\nwere performed on a simulated nonlinear chaotic system and an empirical system\nusing Philippine macroeconomic data. Results show that VANAR significantly\noutperforms VAR in the forecast and causality tests. VANAR has consistently\nsuperior accuracy even over state of the art models such as SARIMA and TBATS.\nFor the impulse response test, both models fail to predict the shocked\ntrajectories of the nonlinear chaotic system. VANAR was robust in its ability\nto model a wide variety of dynamics, from chaotic, high noise, and low data\nenvironments to macroeconomic systems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 08:15:35 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 07:45:26 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 07:23:35 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Cabanilla", "Kurt Izak", ""], ["Go", "Kevin Thomas", ""]]}, {"id": "1903.09434", "submitter": "Celestine Mendler-D\\\"unner", "authors": "Alessandro De Palma, Celestine Mendler-D\\\"unner, Thomas Parnell,\n  Andreea Anghel, Haralampos Pozidis", "title": "Sampling Acquisition Functions for Batch Bayesian Optimization", "comments": "Presented at BNP@NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Acquisition Thompson Sampling (ATS), a novel technique for batch\nBayesian Optimization (BO) based on the idea of sampling multiple acquisition\nfunctions from a stochastic process. We define this process through the\ndependency of the acquisition functions on a set of model hyper-parameters. ATS\nis conceptually simple, straightforward to implement and, unlike other batch BO\nmethods, it can be employed to parallelize any sequential acquisition function\nor to make existing parallel methods scale further. We present experiments on a\nvariety of benchmark functions and on the hyper-parameter optimization of a\npopular gradient boosting tree algorithm. These demonstrate the advantages of\nATS with respect to classical parallel Thompson Sampling for BO, its\ncompetitiveness with two state-of-the-art batch BO methods, and its\neffectiveness if applied to existing parallel BO algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 10:25:55 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 18:31:47 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["De Palma", "Alessandro", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Parnell", "Thomas", ""], ["Anghel", "Andreea", ""], ["Pozidis", "Haralampos", ""]]}, {"id": "1903.09478", "submitter": "Cristina Fernandes", "authors": "Luis Roque, Cristina A. C. Fernandes and Tony Silva", "title": "Optimal Combination Forecasts on Retail Multi-Dimensional Sales Data", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data in the retail world are particularly rich in terms of\ndimensionality, and these dimensions can be aggregated in groups or\nhierarchies. Valuable information is nested in these complex structures, which\nhelps to predict the aggregated time series data. From a portfolio of brands\nunder HUUB's monitoring, we selected two to explore their sales behaviour,\nleveraging the grouping properties of their product structure. Using\nstatistical models, namely SARIMA, to forecast each level of the hierarchy, an\noptimal combination approach was used to generate more consistent forecasts in\nthe higher levels. Our results show that the proposed methods can indeed\ncapture nested information in the more granular series, helping to improve the\nforecast accuracy of the aggregated series. The Weighted Least Squares (WLS)\nmethod surpasses all other methods proposed in the study, including the Minimum\nTrace (MinT) reconciliation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 12:53:23 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Roque", "Luis", ""], ["Fernandes", "Cristina A. C.", ""], ["Silva", "Tony", ""]]}, {"id": "1903.09493", "submitter": "Elena Beretta", "authors": "Elena Beretta, Antonio Santangelo, Bruno Lepri, Antonio Vetr\\`o, Juan\n  Carlos De Martin", "title": "The invisible power of fairness. How machine learning shapes democracy", "comments": "12 pages, 1 figure, preprint version, submitted to The 32nd Canadian\n  Conference on Artificial Intelligence that will take place in Kingston,\n  Ontario, May 28 to May 31, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many machine learning systems make extensive use of large amounts of data\nregarding human behaviors. Several researchers have found various\ndiscriminatory practices related to the use of human-related machine learning\nsystems, for example in the field of criminal justice, credit scoring and\nadvertising. Fair machine learning is therefore emerging as a new field of\nstudy to mitigate biases that are inadvertently incorporated into algorithms.\nData scientists and computer engineers are making various efforts to provide\ndefinitions of fairness. In this paper, we provide an overview of the most\nwidespread definitions of fairness in the field of machine learning, arguing\nthat the ideas highlighting each formalization are closely related to different\nideas of justice and to different interpretations of democracy embedded in our\nculture. This work intends to analyze the definitions of fairness that have\nbeen proposed to date to interpret the underlying criteria and to relate them\nto different ideas of democracy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 13:24:41 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Beretta", "Elena", ""], ["Santangelo", "Antonio", ""], ["Lepri", "Bruno", ""], ["Vetr\u00f2", "Antonio", ""], ["De Martin", "Juan Carlos", ""]]}, {"id": "1903.09536", "submitter": "Daniel Poh", "authors": "Daniel Poh, Stephen Roberts, Martin Tegn\\'er", "title": "A Machine Learning approach to Risk Minimisation in Electricity Markets\n  with Coregionalized Sparse Gaussian Processes", "comments": "24 pages, 4 figures, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-storability of electricity makes it unique among commodity assets,\nand it is an important driver of its price behaviour in secondary financial\nmarkets. The instantaneous and continuous matching of power supply with demand\nis a key factor explaining its volatility. During periods of high demand,\ncostlier generation capabilities are utilised since electricity cannot be\nstored and this has the impact of driving prices up very quickly. Furthermore,\nthe non-storability also complicates physical hedging. Owing to these, the\nproblem of joint price-quantity risk in electricity markets is a commonly\nstudied theme.\n  We propose using Gaussian Processes (GPs) to tackle this problem since GPs\nprovide a versatile and elegant non-parametric approach for regression and\ntime-series modelling. However, GPs scale poorly with the amount of training\ndata due to a cubic complexity. These considerations suggest that knowledge\ntransfer between price and load is vital for effective hedging, and that a\ncomputationally efficient method is required. To this end, we use the\ncoregionalized (or multi-task) sparse GPs which addresses the aforementioned\nissues.\n  To gauge the performance of our model, we use an average-load strategy as\ncomparator. The latter is a robust approach commonly used by industry. If the\nspot and load are uncorrelated and Gaussian, then hedging with the expected\nload will result in the minimum variance position.\n  Our main contributions are twofold. Firstly, in developing a coregionalized\nsparse GP-based approach for hedging. Secondly, in demonstrating that our\nmodel-based strategy outperforms the comparator, and can thus be employed for\neffective hedging in electricity markets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 14:48:14 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 10:43:06 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Poh", "Daniel", ""], ["Roberts", "Stephen", ""], ["Tegn\u00e9r", "Martin", ""]]}, {"id": "1903.09587", "submitter": "Connor McCurley", "authors": "Connor H. McCurley, James Bocinsky, Alina Zare", "title": "Comparison of Hand-held WEMI Target Detection Algorithms", "comments": "SPIE Defense + Commercial Sensing, 20 pages, 8 figures", "journal-ref": "Proc. SPIE 11012, Detection and Sensing of Mines, Explosive\n  Objects, and Obscured Targets XXIV, 110120U (10 May 2019)", "doi": "10.1117/12.2519454", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide-band Electromagnetic Induction Sensors (WEMI) have been used for a\nnumber of years in subsurface detection of explosive hazards. While WEMI\nsensors have proven effective at localizing objects exhibiting large magnetic\nresponses, detecting objects lacking or containing very low amounts of\nconductive materials can be challenging. In this paper, we compare a number of\ntarget detection algorithms in the literature in terms of detection\nperformance. In the comparison, methods are tested on two real-world data sets:\none containing relatively low amounts of ground noise pollution, and the other\ndemonstrating highly-magnetic soil interference. Results are quantitatively\nevaluated through receiver-operator characteristic (ROC) curves and are used to\nhighlight the strengths and weaknesses of the compared approaches in hand-held\nexplosive hazard detection.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 16:28:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["McCurley", "Connor H.", ""], ["Bocinsky", "James", ""], ["Zare", "Alina", ""]]}, {"id": "1903.09631", "submitter": "Parthe Pandit", "authors": "Parthe Pandit, Mojtaba Sahraee-Ardakan, Arash A. Amini, Sundeep\n  Rangan, Alyson K. Fletcher", "title": "High-Dimensional Bernoulli Autoregressive Process with Long-Range\n  Dependence", "comments": "To appear at AISTATS 2019 titled \"Sparse Multivariate Bernoulli\n  Processes in High Dimensions\"", "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan. PMLR:\n  Volume 89", "doi": null, "report-no": null, "categories": "math.ST cs.LG eess.SP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the parameters of a multivariate\nBernoulli process with auto-regressive feedback in the high-dimensional setting\nwhere the number of samples available is much less than the number of\nparameters. This problem arises in learning interconnections of networks of\ndynamical systems with spiking or binary-valued data. We allow the process to\ndepend on its past up to a lag $p$, for a general $p \\ge 1$, allowing for more\nrealistic modeling in many applications. We propose and analyze an\n$\\ell_1$-regularized maximum likelihood estimator (MLE) under the assumption\nthat the parameter tensor is approximately sparse. Rigorous analysis of such\nestimators is made challenging by the dependent and non-Gaussian nature of the\nprocess as well as the presence of the nonlinearities and multi-level feedback.\nWe derive precise upper bounds on the mean-squared estimation error in terms of\nthe number of samples, dimensions of the process, the lag $p$ and other key\nstatistical properties of the model. The ideas presented can be used in the\nhigh-dimensional analysis of regularized $M$-estimators for other sparse\nnonlinear and non-Gaussian processes with long-range dependence.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 06:06:27 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Pandit", "Parthe", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Amini", "Arash A.", ""], ["Rangan", "Sundeep", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "1903.09639", "submitter": "Varoon Mathur", "authors": "Cody Griffith, Varoon Mathur, Catherine Lin, Kevin Zhu", "title": "Understanding Childhood Vulnerability in The City of Surrey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the community conditions that best support universal access and\nimproved childhood outcomes allows ultimately to improve decision-making in the\nareas of planning and investment across the early stages of childhood\ndevelopment. Here we describe two different data-driven approaches to\nvisualizing the lived experiences of children throughout the City of Surrey,\ncombining data derived from both public and private sources. In one approach,\nwe find specifically that the Early Development Instrument measuring childhood\nvulnerabilities across varying domains can be used to cluster neighborhoods,\nand that census variables can help explain similarities between neighborhoods\nwithin these clusters. In our second approach, we use program registration data\nfrom the City of Surrey's Community and Recreation Services Division. We also\nfind a critical age of entry and exit for each program related to early\nchildhood development and beyond, and find that certain neighborhoods and\nrecreational programs have larger retention rates than others. This report\ndetails the journey of using data to tell the story of these neighborhoods, and\nprovides a lens to which community initiatives can be strategically crafted\nthrough their use.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:23:24 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Griffith", "Cody", ""], ["Mathur", "Varoon", ""], ["Lin", "Catherine", ""], ["Zhu", "Kevin", ""]]}, {"id": "1903.09644", "submitter": "Dreyer Fr\\'ed\\'eric", "authors": "Stefano Carrazza and Fr\\'ed\\'eric A. Dreyer", "title": "Jet grooming through reinforcement learning", "comments": "11 pages, 10 figures, code available at\n  https://github.com/JetsGame/GroomRL, updated to match published version", "journal-ref": "Phys. Rev. D 100, 014014 (2019)", "doi": "10.1103/PhysRevD.100.014014", "report-no": null, "categories": "hep-ph cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel implementation of a reinforcement learning (RL)\nalgorithm which is designed to find an optimal jet grooming strategy, a\ncritical tool for collider experiments. The RL agent is trained with a reward\nfunction constructed to optimize the resulting jet properties, using both\nsignal and background samples in a simultaneous multi-level training. We show\nthat the grooming algorithm derived from the deep RL agent can match\nstate-of-the-art techniques used at the Large Hadron Collider, resulting in\nimproved mass resolution for boosted objects. Given a suitable reward function,\nthe agent learns how to train a policy which optimally removes soft wide-angle\nradiation, allowing for a modular grooming technique that can be applied in a\nwide range of contexts. These results are accessible through the corresponding\nGroomRL framework.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 18:00:00 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 17:53:08 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Carrazza", "Stefano", ""], ["Dreyer", "Fr\u00e9d\u00e9ric A.", ""]]}, {"id": "1903.09668", "submitter": "Yuexi Wang", "authors": "Yuexi Wang, Nicholas G. Polson, Vadim O. Sokolov", "title": "Scalable Data Augmentation for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable Data Augmentation (SDA) provides a framework for training deep\nlearning models using auxiliary hidden layers. Scalable MCMC is available for\nnetwork training and inference. SDA provides a number of computational\nadvantages over traditional algorithms, such as avoiding backtracking, local\nmodes and can perform optimization with stochastic gradient descent (SGD) in\nTensorFlow. Standard deep neural networks with logit, ReLU and SVM activation\nfunctions are straightforward to implement. To illustrate our architectures and\nmethodology, we use P\\'{o}lya-Gamma logit data augmentation for a number of\nstandard datasets. Finally, we conclude with directions for future research.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 18:28:20 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Wang", "Yuexi", ""], ["Polson", "Nicholas G.", ""], ["Sokolov", "Vadim O.", ""]]}, {"id": "1903.09688", "submitter": "Erik Derner", "authors": "Ji\\v{r}\\'i Kubal\\'ik, Jan \\v{Z}egklitz, Erik Derner and Robert\n  Babu\\v{s}ka", "title": "Symbolic Regression Methods for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms can be used to optimally solve dynamic\ndecision-making and control problems. With continuous-valued state and input\nvariables, reinforcement learning algorithms must rely on function\napproximators to represent the value function and policy mappings. Commonly\nused numerical approximators, such as neural networks or basis function\nexpansions, have two main drawbacks: they are black-box models offering no\ninsight in the mappings learned, and they require significant trial and error\ntuning of their meta-parameters. In this paper, we propose a new approach to\nconstructing smooth value functions by means of symbolic regression. We\nintroduce three off-line methods for finding value functions based on a state\ntransition model: symbolic value iteration, symbolic policy iteration, and a\ndirect solution of the Bellman equation. The methods are illustrated on four\nnonlinear control problems: velocity control under friction, one-link and\ntwo-link pendulum swing-up, and magnetic manipulation. The results show that\nthe value functions not only yield well-performing policies, but also are\ncompact, human-readable and mathematically tractable. This makes them\npotentially suitable for further analysis of the closed-loop system. A\ncomparison with alternative approaches using neural networks shows that our\nmethod constructs well-performing value functions with substantially fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 19:53:29 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Kubal\u00edk", "Ji\u0159\u00ed", ""], ["\u017degklitz", "Jan", ""], ["Derner", "Erik", ""], ["Babu\u0161ka", "Robert", ""]]}, {"id": "1903.09731", "submitter": "Gilmer Valdes", "authors": "E.D. Gennatas, J.H. Friedman, L.H. Ungar, R. Pirracchio, E. Eaton, L.\n  Reichman, Y. Interian, C.B. Simone, A. Auerbach, E. Delgado, M.J. Van der\n  Laan, T.D. Solberg, G. Valdes", "title": "Expert-Augmented Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning is proving invaluable across disciplines. However, its\nsuccess is often limited by the quality and quantity of available data, while\nits adoption by the level of trust that models afford users. Human vs. machine\nperformance is commonly compared empirically to decide whether a certain task\nshould be performed by a computer or an expert. In reality, the optimal\nlearning strategy may involve combining the complementary strengths of man and\nmachine. Here we present Expert-Augmented Machine Learning (EAML), an automated\nmethod that guides the extraction of expert knowledge and its integration into\nmachine-learned models. We use a large dataset of intensive care patient data\nto predict mortality and show that we can extract expert knowledge using an\nonline platform, help reveal hidden confounders, improve generalizability on a\ndifferent population and learn using less data. EAML presents a novel framework\nfor high performance and dependable machine learning in critical applications.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 23:32:22 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 21:22:36 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 20:27:43 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Gennatas", "E. D.", ""], ["Friedman", "J. H.", ""], ["Ungar", "L. H.", ""], ["Pirracchio", "R.", ""], ["Eaton", "E.", ""], ["Reichman", "L.", ""], ["Interian", "Y.", ""], ["Simone", "C. B.", ""], ["Auerbach", "A.", ""], ["Delgado", "E.", ""], ["Van der Laan", "M. J.", ""], ["Solberg", "T. D.", ""], ["Valdes", "G.", ""]]}, {"id": "1903.09732", "submitter": "Paulo Mateus", "authors": "Samuel Arcadinho and Paulo Mateus", "title": "Time Series Imputation", "comments": "Master paper, draft to be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series is a very active topic in the research community and\nmany machine learning tasks are being used in order to extract information from\nthis type of data. However, in real-world problems data has missing values,\nwhich may difficult the application of machine learning techniques to extract\ninformation. In this paper we focus on the task of imputation of time series.\nMany imputation methods for time series are based on regression methods.\nUnfortunately, these methods perform poorly when the variables are categorical.\nTo address this case, we propose a new imputation method based on Expectation\nMaximization over dynamic Bayesian networks. The approach is assessed with\nsynthetic and real data, and it outperforms several state-of-the art methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 23:39:53 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Arcadinho", "Samuel", ""], ["Mateus", "Paulo", ""]]}, {"id": "1903.09734", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, Animashree Anandkumar", "title": "Regularized Learning for Domain Adaptation under Label Shifts", "comments": "International Conference on Learning Representations (ICLR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Regularized Learning under Label shifts (RLLS), a principled and a\npractical domain-adaptation algorithm to correct for shifts in the label\ndistribution between a source and a target domain. We first estimate importance\nweights using labeled source data and unlabeled target data, and then train a\nclassifier on the weighted source samples. We derive a generalization bound for\nthe classifier on the target domain which is independent of the (ambient) data\ndimensions, and instead only depends on the complexity of the function class.\nTo the best of our knowledge, this is the first generalization bound for the\nlabel-shift problem where the labels in the target domain are not available.\nBased on this bound, we propose a regularized estimator for the small-sample\nregime which accounts for the uncertainty in the estimated weights. Experiments\non the CIFAR-10 and MNIST datasets show that RLLS improves classification\naccuracy, especially in the low sample and large-shift regimes, compared to\nprevious methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 23:46:24 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Liu", "Anqi", ""], ["Yang", "Fanny", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1903.09790", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Csan\\'ad Cs\\'aji and Ambrus Tam\\'as", "title": "Semi-Parametric Uncertainty Bounds for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies binary classification and aims at estimating the underlying\nregression function which is the conditional expectation of the class labels\ngiven the inputs. The regression function is the key component of the Bayes\noptimal classifier, moreover, besides providing optimal predictions, it can\nalso assess the risk of misclassification. We aim at building non-asymptotic\nconfidence regions for the regression function and suggest three kernel-based\nsemi-parametric resampling methods. We prove that all of them guarantee regions\nwith exact coverage probabilities and they are strongly consistent.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 10:19:20 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Csan\u00e1d", ""], ["Tam\u00e1s", "Ambrus", ""]]}, {"id": "1903.09795", "submitter": "Pankaj Malhotra", "authors": "Vishnu TV, Diksha, Pankaj Malhotra, Lovekesh Vig, and Gautam Shroff", "title": "Data-driven Prognostics with Predictive Uncertainty Estimation using\n  Ensemble of Deep Ordinal Regression Models", "comments": "Accepted at International Journal of Prognostics and Health\n  Management (IJPHM), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prognostics or Remaining Useful Life (RUL) Estimation from multi-sensor time\nseries data is useful to enable condition-based maintenance and ensure high\noperational availability of equipment. We propose a novel deep learning based\napproach for Prognostics with Uncertainty Quantification that is useful in\nscenarios where: (i) access to labeled failure data is scarce due to rarity of\nfailures (ii) future operational conditions are unobserved and (iii) inherent\nnoise is present in the sensor readings. All three scenarios mentioned are\nunavoidable sources of uncertainty in the RUL estimation process often\nresulting in unreliable RUL estimates. To address (i), we formulate RUL\nestimation as an Ordinal Regression (OR) problem, and propose LSTM-OR: deep\nLong Short Term Memory (LSTM) network based approach to learn the OR function.\nWe show that LSTM-OR naturally allows for incorporation of censored operational\ninstances in training along with the failed instances, leading to more robust\nlearning. To address (ii), we propose a simple yet effective approach to\nquantify predictive uncertainty in the RUL estimation models by training an\nensemble of LSTM-OR models. Through empirical evaluation on C-MAPSS turbofan\nengine benchmark datasets, we demonstrate that LSTM-OR is significantly better\nthan the commonly used deep metric regression based approaches for RUL\nestimation, especially when failed training instances are scarce. Further, our\nuncertainty quantification approach yields high quality predictive uncertainty\nestimates while also leading to improved RUL estimates compared to single best\nLSTM-OR models.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 10:40:30 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 09:19:44 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 13:09:03 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 12:10:28 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["TV", "Vishnu", ""], ["Diksha", "", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1903.09799", "submitter": "Hao-Yun Chen", "authors": "Hao-Yun Chen, Jhao-Hong Liang, Shih-Chieh Chang, Jia-Yu Pan, Yu-Ting\n  Chen, Wei Wei, Da-Cheng Juan", "title": "Improving Adversarial Robustness via Guided Complement Entropy", "comments": "ICCV'19 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness has emerged as an important topic in deep learning as\ncarefully crafted attack samples can significantly disturb the performance of a\nmodel. Many recent methods have proposed to improve adversarial robustness by\nutilizing adversarial training or model distillation, which adds additional\nprocedures to model training. In this paper, we propose a new training paradigm\ncalled Guided Complement Entropy (GCE) that is capable of achieving\n\"adversarial defense for free,\" which involves no additional procedures in the\nprocess of improving adversarial robustness. In addition to maximizing model\nprobabilities on the ground-truth class like cross-entropy, we neutralize its\nprobabilities on the incorrect classes along with a \"guided\" term to balance\nbetween these two terms. We show in the experiments that our method achieves\nbetter model robustness with even better performance compared to the commonly\nused cross-entropy training objective. We also show that our method can be used\northogonal to adversarial training across well-known methods with noticeable\nrobustness gain. To the best of our knowledge, our approach is the first one\nthat improves model robustness without compromising performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 11:14:59 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 04:07:55 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 06:11:33 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Chen", "Hao-Yun", ""], ["Liang", "Jhao-Hong", ""], ["Chang", "Shih-Chieh", ""], ["Pan", "Jia-Yu", ""], ["Chen", "Yu-Ting", ""], ["Wei", "Wei", ""], ["Juan", "Da-Cheng", ""]]}, {"id": "1903.09848", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Otilia Stretcu and Graham Neubig and\n  Barnabas Poczos and Tom M. Mitchell", "title": "Competence-based Curriculum Learning for Neural Machine Translation", "comments": null, "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art NMT systems use large neural networks that are not\nonly slow to train, but also often require many heuristics and optimization\ntricks, such as specialized learning rate schedules and large batch sizes. This\nis undesirable as it requires extensive hyperparameter tuning. In this paper,\nwe propose a curriculum learning framework for NMT that reduces training time,\nreduces the need for specialized heuristics or large batch sizes, and results\nin overall better performance. Our framework consists of a principled way of\ndeciding which training samples are shown to the model at different times\nduring training, based on the estimated difficulty of a sample and the current\ncompetence of the model. Filtering training samples in this manner prevents the\nmodel from getting stuck in bad local optima, making it converge faster and\nreach a better solution than the common approach of uniformly sampling training\nexamples. Furthermore, the proposed method can be easily applied to existing\nNMT models by simply modifying their input data pipelines. We show that our\nframework can help improve the training time and the performance of both\nrecurrent neural network models and Transformers, achieving up to a 70%\ndecrease in training time, while at the same time obtaining accuracy\nimprovements of up to 2.2 BLEU.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 17:33:38 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 12:39:04 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Stretcu", "Otilia", ""], ["Neubig", "Graham", ""], ["Poczos", "Barnabas", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "1903.09885", "submitter": "Xiao Li", "authors": "Xiao Li and Calin Belta", "title": "Temporal Logic Guided Safe Reinforcement Learning Using Control Barrier\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using reinforcement learning to learn control policies is a challenge when\nthe task is complex with potentially long horizons. Ensuring adequate but safe\nexploration is also crucial for controlling physical systems. In this paper, we\nuse temporal logic to facilitate specification and learning of complex tasks.\nWe combine temporal logic with control Lyapunov functions to improve\nexploration. We incorporate control barrier functions to safeguard the\nexploration and deployment process. We develop a flexible and learnable system\nthat allows users to specify task objectives and constraints in different forms\nand at various levels. The framework is also able to take advantage of known\nsystem dynamics and handle unknown environmental dynamics by integrating\nmodel-free learning with model-based planning.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 21:29:49 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Li", "Xiao", ""], ["Belta", "Calin", ""]]}, {"id": "1903.09973", "submitter": "Evgeny Ponomarev", "authors": "Julia Gusak, Maksym Kholiavchenko, Evgeny Ponomarev, Larisa Markeeva,\n  Ivan Oseledets, Andrzej Cichocki", "title": "MUSCO: Multi-Stage Compression of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low-rank tensor approximation is very promising for the compression of\ndeep neural networks. We propose a new simple and efficient iterative approach,\nwhich alternates low-rank factorization with a smart rank selection and\nfine-tuning. We demonstrate the efficiency of our method comparing to\nnon-iterative ones. Our approach improves the compression rate while\nmaintaining the accuracy for a variety of tasks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 11:40:18 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 13:08:22 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 13:20:17 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 12:27:25 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Gusak", "Julia", ""], ["Kholiavchenko", "Maksym", ""], ["Ponomarev", "Evgeny", ""], ["Markeeva", "Larisa", ""], ["Oseledets", "Ivan", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1903.10012", "submitter": "Maria Perez-Ortiz", "authors": "Maria Perez-Ortiz, Pedro A. Gutierrez, Peter Tino, Carlos\n  Casanova-Mateo, Sancho Salcedo-Sanz", "title": "A mixture of experts model for predicting persistent weather patterns", "comments": "Published in IEEE International Joint Conference on Neural Networks\n  (IJCNN) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather and atmospheric patterns are often persistent. The simplest weather\nforecasting method is the so-called persistence model, which assumes that the\nfuture state of a system will be similar (or equal) to the present state.\nMachine learning (ML) models are widely used in different weather forecasting\napplications, but they need to be compared to the persistence model to analyse\nwhether they provide a competitive solution to the problem at hand. In this\npaper, we devise a new model for predicting low-visibility in airports using\nthe concepts of mixture of experts. Visibility level is coded as two different\nordered categorical variables: cloud height and runway visual height. The\nunderlying system in this application is stagnant approximately in 90% of the\ncases, and standard ML models fail to improve on the performance of the\npersistence model. Because of this, instead of trying to simply beat the\npersistence model using ML, we use this persistence as a baseline and learn an\nordinal neural network model that refines its results by focusing on learning\nweather fluctuations. The results show that the proposal outperforms\npersistence and other ordinal autoregressive models, especially for longer time\nhorizon predictions and for the runway visual height variable.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 16:17:07 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Perez-Ortiz", "Maria", ""], ["Gutierrez", "Pedro A.", ""], ["Tino", "Peter", ""], ["Casanova-Mateo", "Carlos", ""], ["Salcedo-Sanz", "Sancho", ""]]}, {"id": "1903.10022", "submitter": "Maria Perez-Ortiz", "authors": "Maria Perez-Ortiz, Peter Tino, Rafal Mantiuk, Cesar Hervas-Martinez", "title": "Exploiting Synthetically Generated Data with Semi-Supervised Learning\n  for Small and Imbalanced Datasets", "comments": "Published in the Thirty-Third AAAI Conference on Artificial\n  Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is rapidly gaining attention in machine learning. Synthetic\ndata can be generated by simple transformations or through the data\ndistribution. In the latter case, the main challenge is to estimate the label\nassociated to new synthetic patterns. This paper studies the effect of\ngenerating synthetic data by convex combination of patterns and the use of\nthese as unsupervised information in a semi-supervised learning framework with\nsupport vector machines, avoiding thus the need to label synthetic examples. We\nperform experiments on a total of 53 binary classification datasets. Our\nresults show that this type of data over-sampling supports the well-known\ncluster assumption in semi-supervised learning, showing outstanding results for\nsmall high-dimensional datasets and imbalanced learning problems.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 17:09:28 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Perez-Ortiz", "Maria", ""], ["Tino", "Peter", ""], ["Mantiuk", "Rafal", ""], ["Hervas-Martinez", "Cesar", ""]]}, {"id": "1903.10025", "submitter": "Yiwei Li", "authors": "Yiwei Li", "title": "Generalization of k-means Related Algorithms", "comments": "3 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article briefly introduced Arthur and Vassilvitshii's work on\n\\textbf{k-means++} algorithm and further generalized the center initialization\nprocess. It is found that choosing the most distant sample point from the\nnearest center as new center can mostly have the same effect as the center\ninitialization process in the \\textbf{k-means++} algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 17:34:29 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Li", "Yiwei", ""]]}, {"id": "1903.10039", "submitter": "Swagatam Das", "authors": "Saptarshi Chakraborty and Swagatam Das", "title": "A Strongly Consistent Sparse $k$-means Clustering with Direct $l_1$\n  Penalization on Variable Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Lasso Weighted $k$-means ($LW$-$k$-means) algorithm as a\nsimple yet efficient sparse clustering procedure for high-dimensional data\nwhere the number of features ($p$) can be much larger compared to the number of\nobservations ($n$). In the $LW$-$k$-means algorithm, we introduce a lasso-based\npenalty term, directly on the feature weights to incorporate feature selection\nin the framework of sparse clustering. $LW$-$k$-means does not make any\ndistributional assumption of the given dataset and thus, induces a\nnon-parametric method for feature selection. We also analytically investigate\nthe convergence of the underlying optimization procedure in $LW$-$k$-means and\nestablish the strong consistency of our algorithm. $LW$-$k$-means is tested on\nseveral real-life and synthetic datasets and through detailed experimental\nanalysis, we find that the performance of the method is highly competitive\nagainst some state-of-the-art procedures for clustering and feature selection,\nnot only in terms of clustering accuracy but also with respect to computational\ntime.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 18:45:35 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Chakraborty", "Saptarshi", ""], ["Das", "Swagatam", ""]]}, {"id": "1903.10047", "submitter": "Kenta Oono", "authors": "Kenta Oono, Taiji Suzuki", "title": "Approximation and Non-parametric Estimation of ResNet-type Convolutional\n  Neural Networks", "comments": "8 pages + References 2 pages + Supplemental material 18 pages", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been shown to achieve optimal\napproximation and estimation error rates (in minimax sense) in several function\nclasses. However, previous analyzed optimal CNNs are unrealistically wide and\ndifficult to obtain via optimization due to sparse constraints in important\nfunction classes, including the H\\\"older class. We show a ResNet-type CNN can\nattain the minimax optimal error rates in these classes in more plausible\nsituations -- it can be dense, and its width, channel size, and filter size are\nconstant with respect to sample size. The key idea is that we can replicate the\nlearning ability of Fully-connected neural networks (FNNs) by tailored CNNs, as\nlong as the FNNs have \\textit{block-sparse} structures. Our theory is general\nin a sense that we can automatically translate any approximation rate achieved\nby block-sparse FNNs into that by CNNs. As an application, we derive\napproximation and estimation error rates of the aformentioned type of CNNs for\nthe Barron and H\\\"older classes with the same strategy.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 19:42:39 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 12:22:39 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 13:23:30 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Oono", "Kenta", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1903.10075", "submitter": "Susan Athey", "authors": "Susan Athey and Guido Imbens", "title": "Machine Learning Methods Economists Should Know About", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the relevance of the recent Machine Learning (ML) literature for\neconomics and econometrics. First we discuss the differences in goals, methods\nand settings between the ML literature and the traditional econometrics and\nstatistics literatures. Then we discuss some specific methods from the machine\nlearning literature that we view as important for empirical researchers in\neconomics. These include supervised learning methods for regression and\nclassification, unsupervised learning methods, as well as matrix completion\nmethods. Finally, we highlight newly developed methods at the intersection of\nML and econometrics, methods that typically perform better than either\noff-the-shelf ML or more traditional econometric methods when applied to\nparticular classes of problems, problems that include causal inference for\naverage treatment effects, optimal policy estimation, and estimation of the\ncounterfactual effect of price changes in consumer choice models.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 22:58:02 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Athey", "Susan", ""], ["Imbens", "Guido", ""]]}, {"id": "1903.10077", "submitter": "Srivatsan Srinivasan", "authors": "Donghun Lee, Srivatsan Srinivasan, Finale Doshi-Velez", "title": "Truly Batch Apprenticeship Learning with Deep Successor Features", "comments": "10 pages, 3 figures, Under Conference Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel apprenticeship learning algorithm to learn an expert's\nunderlying reward structure in off-policy model-free \\emph{batch} settings.\nUnlike existing methods that require a dynamics model or additional data\nacquisition for on-policy evaluation, our algorithm requires only the batch\ndata of observed expert behavior. Such settings are common in real-world\ntasks---health care, finance or industrial processes ---where accurate\nsimulators do not exist or data acquisition is costly. To address challenges in\nbatch settings, we introduce Deep Successor Feature Networks(DSFN) that\nestimate feature expectations in an off-policy setting and a\ntransition-regularized imitation network that produces a near-expert initial\npolicy and an efficient feature representation. Our algorithm achieves superior\nresults in batch settings on both control benchmarks and a vital clinical task\nof sepsis management in the Intensive Care Unit.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 23:13:27 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Lee", "Donghun", ""], ["Srinivasan", "Srivatsan", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1903.10083", "submitter": "Veeranjaneyulu Sadhanala", "authors": "Veeranjaneyulu Sadhanala, Yu-Xiang Wang, Aaditya Ramdas, Ryan J.\n  Tibshirani", "title": "A Higher-Order Kolmogorov-Smirnov Test", "comments": "18 pages, AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of the Kolmogorov-Smirnov (KS) two-sample test, which\ncan be more sensitive to differences in the tails. Our test statistic is an\nintegral probability metric (IPM) defined over a higher-order total variation\nball, recovering the original KS test as its simplest case. We give an exact\nrepresenter result for our IPM, which generalizes the fact that the original KS\ntest statistic can be expressed in equivalent variational and CDF forms. For\nsmall enough orders ($k \\leq 5$), we develop a linear-time algorithm for\ncomputing our higher-order KS test statistic; for all others ($k \\geq 6$), we\ngive a nearly linear-time approximation. We derive the asymptotic null\ndistribution for our test, and show that our nearly linear-time approximation\nshares the same asymptotic null. Lastly, we complement our theory with\nnumerical studies.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 23:42:54 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Sadhanala", "Veeranjaneyulu", ""], ["Wang", "Yu-Xiang", ""], ["Ramdas", "Aaditya", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1903.10144", "submitter": "Hyunjae Kim", "authors": "Raehyun Kim, Hyunjae Kim, Janghyuk Lee, Jaewoo Kang", "title": "Predicting Multiple Demographic Attributes with Task Specific Embedding\n  Transformation and Attention Network", "comments": "SDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most companies utilize demographic information to develop their strategy in a\nmarket. However, such information is not available to most retail companies.\nSeveral studies have been conducted to predict the demographic attributes of\nusers from their transaction histories, but they have some limitations. First,\nthey focused on parameter sharing to predict all attributes but capturing\ntask-specific features is also important in multi-task learning. Second, they\nassumed that all transactions are equally important in predicting demographic\nattributes. However, some transactions are more useful than others for\npredicting a certain attribute. Furthermore, decision making process of models\ncannot be interpreted as they work in a black-box manner. To address the\nlimitations, we propose an Embedding Transformation Network with Attention\n(ETNA) model which shares representations at the bottom of the model structure\nand transforms them to task-specific representations using a simple linear\ntransformation method. In addition, we can obtain more informative transactions\nfor predicting certain attributes using the attention mechanism. The\nexperimental results show that our model outperforms the previous models on all\ntasks. In our qualitative analysis, we show the visualization of attention\nweights, which provides business managers with some useful insights.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 06:25:47 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Kim", "Raehyun", ""], ["Kim", "Hyunjae", ""], ["Lee", "Janghyuk", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1903.10145", "submitter": "Chunyuan Li", "authors": "Hao Fu, Chunyuan Li, Xiaodong Liu, Jianfeng Gao, Asli Celikyilmaz,\n  Lawrence Carin", "title": "Cyclical Annealing Schedule: A Simple Approach to Mitigating KL\n  Vanishing", "comments": "Published in NAACL 2019; The first two authors contribute equally;\n  Code: https://github.com/haofuml/cyclical_annealing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) with an auto-regressive decoder have been\napplied for many natural language processing (NLP) tasks. The VAE objective\nconsists of two terms, (i) reconstruction and (ii) KL regularization, balanced\nby a weighting hyper-parameter \\beta. One notorious training difficulty is that\nthe KL term tends to vanish. In this paper we study scheduling schemes for\n\\beta, and show that KL vanishing is caused by the lack of good latent codes in\ntraining the decoder at the beginning of optimization. To remedy this, we\npropose a cyclical annealing schedule, which repeats the process of increasing\n\\beta multiple times. This new procedure allows the progressive learning of\nmore meaningful latent codes, by leveraging the informative representations of\nprevious cycles as warm re-starts. The effectiveness of cyclical annealing is\nvalidated on a broad range of NLP tasks, including language modeling, dialog\nresponse generation and unsupervised language pre-training.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 06:28:24 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 06:50:06 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 21:43:02 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Fu", "Hao", ""], ["Li", "Chunyuan", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""], ["Carin", "Lawrence", ""]]}, {"id": "1903.10219", "submitter": "Alexandre Araujo", "authors": "Alexandre Araujo, Laurent Meunier, Rafael Pinot, Benjamin Negrevergne", "title": "Robust Neural Networks using Randomized Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of defending a neural network against\nadversarial attacks crafted with different norms (in particular $\\ell_\\infty$\nand $\\ell_2$ bounded adversarial examples). It has been observed that defense\nmechanisms designed to protect against one type of attacks often offer poor\nperformance against the other. We show that $\\ell_\\infty$ defense mechanisms\ncannot offer good protection against $\\ell_2$ attacks and vice-versa, and we\nprovide both theoretical and empirical insights on this phenomenon. Then, we\ndiscuss various ways of combining existing defense mechanisms in order to train\nneural networks robust against both types of attacks. Our experiments show that\nthese new defense mechanisms offer better protection when attacked with both\nnorms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 10:10:50 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 10:00:15 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 12:04:14 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Araujo", "Alexandre", ""], ["Meunier", "Laurent", ""], ["Pinot", "Rafael", ""], ["Negrevergne", "Benjamin", ""]]}, {"id": "1903.10304", "submitter": "Jui-Hsuan Kuo", "authors": "Fang-I Hsiao, Jui-Hsuan Kuo, Min Sun", "title": "Learning a Multi-Modal Policy via Imitating Demonstrations with Mixed\n  Behaviors", "comments": "10pages, 4 figures, NIPS 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to train a multi-modal policy from mixed\ndemonstrations without their behavior labels. We develop a method to discover\nthe latent factors of variation in the demonstrations. Specifically, our method\nis based on the variational autoencoder with a categorical latent variable. The\nencoder infers discrete latent factors corresponding to different behaviors\nfrom demonstrations. The decoder, as a policy, performs the behaviors\naccordingly. Once learned, the policy is able to reproduce a specific behavior\nby simply conditioning on a categorical vector. We evaluate our method on three\ndifferent tasks, including a challenging task with high-dimensional visual\ninputs. Experimental results show that our approach is better than various\nbaseline methods and competitive with a multi-modal policy trained by ground\ntruth behavior labels.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 13:28:26 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Hsiao", "Fang-I", ""], ["Kuo", "Jui-Hsuan", ""], ["Sun", "Min", ""]]}, {"id": "1903.10328", "submitter": "Huy N. Chau", "authors": "Huy N. Chau, Miklos Rasonyi", "title": "Stochastic Gradient Hamiltonian Monte Carlo for Non-Convex Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) is a momentum version of\nstochastic gradient descent with properly injected Gaussian noise to find a\nglobal minimum. In this paper, non-asymptotic convergence analysis of SGHMC is\ngiven in the context of non-convex optimization, where subsampling techniques\nare used over an i.i.d dataset for gradient updates. Our results complement\nthose of [RRT17] and improve on those of [GGZ18].\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 13:51:17 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 22:19:47 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 06:27:04 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chau", "Huy N.", ""], ["Rasonyi", "Miklos", ""]]}, {"id": "1903.10335", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Said Ouala, Lucas Drumetz, Ronan Fablet", "title": "EM-like Learning Chaotic Dynamics from Noisy and Partial Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of the governing equations of chaotic dynamical systems\nfrom data has recently emerged as a hot topic. While the seminal work by\nBrunton et al. reported proof-of-concepts for idealized observation setting for\nfully-observed systems, {\\em i.e.} large signal-to-noise ratios and\nhigh-frequency sampling of all system variables, we here address the learning\nof data-driven representations of chaotic dynamics for partially-observed\nsystems, including significant noise patterns and possibly lower and irregular\nsampling setting. Instead of considering training losses based on short-term\nprediction error like state-of-the-art learning-based schemes, we adopt a\nBayesian formulation and state this issue as a data assimilation problem with\nunknown model parameters. To solve for the joint inference of the hidden\ndynamics and of model parameters, we combine neural-network representations and\nstate-of-the-art assimilation schemes. Using iterative Expectation-Maximization\n(EM)-like procedures, the key feature of the proposed inference schemes is the\nderivation of the posterior of the hidden dynamics. Using a\nneural-network-based Ordinary Differential Equation (ODE) representation of\nthese dynamics, we investigate two strategies: their combination to Ensemble\nKalman Smoothers and Long Short-Term Memory (LSTM)-based variational\napproximations of the posterior. Through numerical experiments on the Lorenz-63\nsystem with different noise and time sampling settings, we demonstrate the\nability of the proposed schemes to recover and reproduce the hidden chaotic\ndynamics, including their Lyapunov characteristic exponents, when classic\nmachine learning approaches fail.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 14:01:22 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Nguyen", "Duong", ""], ["Ouala", "Said", ""], ["Drumetz", "Lucas", ""], ["Fablet", "Ronan", ""]]}, {"id": "1903.10346", "submitter": "Yao Qin", "authors": "Yao Qin, Nicholas Carlini, Ian Goodfellow, Garrison Cottrell and Colin\n  Raffel", "title": "Imperceptible, Robust, and Targeted Adversarial Examples for Automatic\n  Speech Recognition", "comments": "International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are inputs to machine learning models designed by an\nadversary to cause an incorrect output. So far, adversarial examples have been\nstudied most extensively in the image domain. In this domain, adversarial\nexamples can be constructed by imperceptibly modifying images to cause\nmisclassification, and are practical in the physical world. In contrast,\ncurrent targeted adversarial examples applied to speech recognition systems\nhave neither of these properties: humans can easily identify the adversarial\nperturbations, and they are not effective when played over-the-air. This paper\nmakes advances on both of these fronts. First, we develop effectively\nimperceptible audio adversarial examples (verified through a human study) by\nleveraging the psychoacoustic principle of auditory masking, while retaining\n100% targeted success rate on arbitrary full-sentence targets. Next, we make\nprogress towards physical-world over-the-air audio adversarial examples by\nconstructing perturbations which remain effective even after applying realistic\nsimulated environmental distortions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 17:46:35 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 17:43:09 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Qin", "Yao", ""], ["Carlini", "Nicholas", ""], ["Goodfellow", "Ian", ""], ["Cottrell", "Garrison", ""], ["Raffel", "Colin", ""]]}, {"id": "1903.10391", "submitter": "Xiang Wu", "authors": "Xiang Wu, Ruiqi Guo, Sanjiv Kumar and David Simcha", "title": "Local Orthogonal Decomposition for Maximum Inner Product Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverted file and asymmetric distance computation (IVFADC) have been\nsuccessfully applied to approximate nearest neighbor search and subsequently\nmaximum inner product search. In such a framework, vector quantization is used\nfor coarse partitioning while product quantization is used for quantizing\nresiduals. In the original IVFADC as well as all of its variants, after\nresiduals are computed, the second production quantization step is completely\nindependent of the first vector quantization step. In this work, we seek to\nexploit the connection between these two steps when we perform non-exhaustive\nsearch. More specifically, we decompose a residual vector locally into two\northogonal components and perform uniform quantization and multiscale\nquantization to each component respectively. The proposed method, called local\northogonal decomposition, combined with multiscale quantization consistently\nachieves higher recall than previous methods under the same bitrates. We\nconduct comprehensive experiments on large scale datasets as well as detailed\nablation tests, demonstrating effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:13:27 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Wu", "Xiang", ""], ["Guo", "Ruiqi", ""], ["Kumar", "Sanjiv", ""], ["Simcha", "David", ""]]}, {"id": "1903.10396", "submitter": "Adam Oberman", "authors": "Chris Finlay, Aram-Alexandre Pooladian, and Adam M. Oberman", "title": "The LogBarrier adversarial attack: making effective use of decision\n  boundary information", "comments": "12 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks for image classification are small perturbations to\nimages that are designed to cause misclassification by a model. Adversarial\nattacks formally correspond to an optimization problem: find a minimum norm\nimage perturbation, constrained to cause misclassification. A number of\neffective attacks have been developed. However, to date, no gradient-based\nattacks have used best practices from the optimization literature to solve this\nconstrained minimization problem. We design a new untargeted attack, based on\nthese best practices, using the established logarithmic barrier method. On\naverage, our attack distance is similar or better than all state-of-the-art\nattacks on benchmark datasets (MNIST, CIFAR10, ImageNet-1K). In addition, our\nmethod performs significantly better on the most challenging images, those\nwhich normally require larger perturbations for misclassification. We employ\nthe LogBarrier attack on several adversarially defended models, and show that\nit adversarially perturbs all images more efficiently than other attacks: the\ndistance needed to perturb all images is significantly smaller with the\nLogBarrier attack than with other state-of-the-art attacks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:21:20 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Finlay", "Chris", ""], ["Pooladian", "Aram-Alexandre", ""], ["Oberman", "Adam M.", ""]]}, {"id": "1903.10399", "submitter": "Giulia Denevi", "authors": "Giulia Denevi, Carlo Ciliberto, Riccardo Grazzi, Massimiliano Pontil", "title": "Learning-to-Learn Stochastic Gradient Descent with Biased Regularization", "comments": "37 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning-to-learn: inferring a learning algorithm\nthat works well on tasks sampled from an unknown distribution. As class of\nalgorithms we consider Stochastic Gradient Descent on the true risk regularized\nby the square euclidean distance to a bias vector. We present an average excess\nrisk bound for such a learning algorithm. This result quantifies the potential\nbenefit of using a bias vector with respect to the unbiased case. We then\naddress the problem of estimating the bias from a sequence of tasks. We propose\na meta-algorithm which incrementally updates the bias, as new tasks are\nobserved. The low space and time complexity of this approach makes it appealing\nin practice. We provide guarantees on the learning ability of the\nmeta-algorithm. A key feature of our results is that, when the number of tasks\ngrows and their variance is relatively small, our learning-to-learn approach\nhas a significant advantage over learning each task in isolation by Stochastic\nGradient Descent without a bias term. We report on numerical experiments which\ndemonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:26:56 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Denevi", "Giulia", ""], ["Ciliberto", "Carlo", ""], ["Grazzi", "Riccardo", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1903.10416", "submitter": "Siwei Feng", "authors": "Siwei Feng, Marco F. Duarte", "title": "Few-Shot Learning-Based Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning is a technique to learn a model with a very small amount of\nlabeled training data by transferring knowledge from relevant tasks. In this\npaper, we propose a few-shot learning method for wearable sensor based human\nactivity recognition, a technique that seeks high-level human activity\nknowledge from low-level sensor inputs. Due to the high costs to obtain human\ngenerated activity data and the ubiquitous similarities between activity modes,\nit can be more efficient to borrow information from existing activity\nrecognition models than to collect more data to train a new model from scratch\nwhen only a few data are available for model training. The proposed few-shot\nhuman activity recognition method leverages a deep learning model for feature\nextraction and classification while knowledge transfer is performed in the\nmanner of model parameter transfer. In order to alleviate negative transfer, we\npropose a metric to measure cross-domain class-wise relevance so that knowledge\nof higher relevance is assigned larger weights during knowledge transfer.\nPromising results in extensive experiments show the advantages of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:56:07 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Feng", "Siwei", ""], ["Duarte", "Marco F.", ""]]}, {"id": "1903.10464", "submitter": "Martin Jullum PhD", "authors": "Kjersti Aas, Martin Jullum, Anders L{\\o}land", "title": "Explaining individual predictions when features are dependent: More\n  accurate approximations to Shapley values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining complex or seemingly simple machine learning models is an\nimportant practical problem. We want to explain individual predictions from a\ncomplex machine learning model by learning simple, interpretable explanations.\nShapley values is a game theoretic concept that can be used for this purpose.\nThe Shapley value framework has a series of desirable theoretical properties,\nand can in principle handle any predictive model. Kernel SHAP is a\ncomputationally efficient approximation to Shapley values in higher dimensions.\nLike several other existing methods, this approach assumes that the features\nare independent, which may give very wrong explanations. This is the case even\nif a simple linear model is used for predictions. In this paper, we extend the\nKernel SHAP method to handle dependent features. We provide several examples of\nlinear and non-linear models with various degrees of feature dependence, where\nour method gives more accurate approximations to the true Shapley values. We\nalso propose a method for aggregating individual Shapley values, such that the\nprediction can be explained by groups of dependent variables.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 16:57:11 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 08:07:18 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 13:31:18 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Aas", "Kjersti", ""], ["Jullum", "Martin", ""], ["L\u00f8land", "Anders", ""]]}, {"id": "1903.10474", "submitter": "Jialong Jiang", "authors": "Jialong Jiang, David A. Sivak, and Matt Thomson", "title": "Active Learning of Spin Network Models", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech physics.data-an q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse statistical problem of finding direct interactions in complex\nnetworks is difficult. In the natural sciences, well-controlled perturbation\nexperiments are widely used to probe the structure of complex networks.\nHowever, our understanding of how and why perturbations aid inference remains\nheuristic, and we lack automated procedures that determine network structure by\ncombining inference and perturbation. Therefore, we propose a general\nmathematical framework to study inference with iteratively applied\nperturbations. Using the formulation of information geometry, our framework\nquantifies the difficulty of inference and the information gain from\nperturbations through the curvature of the underlying parameter manifold,\nmeasured by Fisher information. We apply the framework to the inference of spin\nnetwork models and find that designed perturbations can reduce the sampling\ncomplexity by $10^6$-fold across a variety of network architectures.\nPhysically, our framework reveals that perturbations boost inference by causing\na network to explore previously inaccessible states. Optimal perturbations\nbreak spin-spin correlations within a network, increasing the information\navailable for inference and thus reducing sampling complexity by orders of\nmagnitude. Our active learning framework could be powerful in the analysis of\ncomplex networks as well as in the rational design of experiments.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 17:22:17 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 00:58:20 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 22:11:29 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Jiang", "Jialong", ""], ["Sivak", "David A.", ""], ["Thomson", "Matt", ""]]}, {"id": "1903.10484", "submitter": "Nicholas Carlini", "authors": "J\\\"orn-Henrik Jacobsen and Jens Behrmannn and Nicholas Carlini and\n  Florian Tram\\`er and Nicolas Papernot", "title": "Exploiting Excessive Invariance caused by Norm-Bounded Adversarial\n  Robustness", "comments": "Accepted at the ICLR 2019 SafeML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are malicious inputs crafted to cause a model to\nmisclassify them. Their most common instantiation, \"perturbation-based\"\nadversarial examples introduce changes to the input that leave its true label\nunchanged, yet result in a different model prediction. Conversely,\n\"invariance-based\" adversarial examples insert changes to the input that leave\nthe model's prediction unaffected despite the underlying input's label having\nchanged.\n  In this paper, we demonstrate that robustness to perturbation-based\nadversarial examples is not only insufficient for general robustness, but\nworse, it can also increase vulnerability of the model to invariance-based\nadversarial examples. In addition to analytical constructions, we empirically\nstudy vision classifiers with state-of-the-art robustness to perturbation-based\nadversaries constrained by an $\\ell_p$ norm. We mount attacks that exploit\nexcessive model invariance in directions relevant to the task, which are able\nto find adversarial examples within the $\\ell_p$ ball. In fact, we find that\nclassifiers trained to be $\\ell_p$-norm robust are more vulnerable to\ninvariance-based adversarial examples than their undefended counterparts.\n  Excessive invariance is not limited to models trained to be robust to\nperturbation-based $\\ell_p$-norm adversaries. In fact, we argue that the term\nadversarial example is used to capture a series of model limitations, some of\nwhich may not have been discovered yet. Accordingly, we call for a set of\nprecise definitions that taxonomize and address each of these shortcomings in\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 17:29:52 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Jacobsen", "J\u00f6rn-Henrik", ""], ["Behrmannn", "Jens", ""], ["Carlini", "Nicholas", ""], ["Tram\u00e8r", "Florian", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1903.10536", "submitter": "Luke Kumar", "authors": "Luke Kumar and Russell Greiner", "title": "Gene Expression based Survival Prediction for Cancer Patients: A Topic\n  Modeling Approach", "comments": null, "journal-ref": "PLOS ONE 14 (2019) 1-30", "doi": "10.1371/journal.pone.0224446", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is one of the leading cause of death, worldwide. Many believe that\ngenomic data will enable us to better predict the survival time of these\npatients, which will lead to better, more personalized treatment options and\npatient care. As standard survival prediction models have a hard time coping\nwith the high-dimensionality of such gene expression (GE) data, many projects\nuse some dimensionality reduction techniques to overcome this hurdle. We\nintroduce a novel methodology, inspired by topic modeling from the natural\nlanguage domain, to derive expressive features from the high-dimensional GE\ndata. There, a document is represented as a mixture over a relatively small\nnumber of topics, where each topic corresponds to a distribution over the\nwords; here, to accommodate the heterogeneity of a patient's cancer, we\nrepresent each patient (~document) as a mixture over cancer-topics, where each\ncancer-topic is a mixture over GE values (~words). This required some\nextensions to the standard LDA model eg: to accommodate the \"real-valued\"\nexpression values - leading to our novel \"discretized\" Latent Dirichlet\nAllocation (dLDA) procedure. We initially focus on the METABRIC dataset, which\ndescribes breast cancer patients using the r=49,576 GE values, from\nmicroarrays. Our results show that our approach provides survival estimates\nthat are more accurate than standard models, in terms of the standard\nConcordance measure. We then validate this approach by running it on the\nPan-kidney (KIPAN) dataset, over r=15,529 GE values - here using the mRNAseq\nmodality - and find that it again achieves excellent results. In both cases, we\nalso show that the resulting model is calibrated, using the recent\n\"D-calibrated\" measure. These successes, in two different cancer types and\nexpression modalities, demonstrates the generality, and the effectiveness, of\nthis approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:12:30 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 04:16:53 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kumar", "Luke", ""], ["Greiner", "Russell", ""]]}, {"id": "1903.10567", "submitter": "Dmitry Kopitkov", "authors": "Dmitry Kopitkov and Vadim Indelman", "title": "General Probabilistic Surface Optimization and Log Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we contribute a novel algorithm family, which generalizes many\nunsupervised techniques including unnormalized and energy models, and allows us\nto infer different statistical modalities (e.g. data likelihood and ratio\nbetween densities) from data samples. The proposed unsupervised technique,\nnamed Probabilistic Surface Optimization (PSO), views a model as a flexible\nsurface which can be pushed according to loss-specific virtual stochastic\nforces, where a dynamical equilibrium is achieved when the pointwise forces on\nthe surface become equal. Concretely, the surface is pushed up and down at\npoints sampled from two different distributions. The averaged up and down\nforces become functions of these two distribution densities and of force\nmagnitudes defined by the loss of a particular PSO instance. Upon convergence,\nthe force equilibrium imposes an optimized model to be equal to various\nstatistical functions depending on the used magnitude functions. Furthermore,\nthis dynamical-statistical equilibrium is extremely intuitive and useful,\nproviding many implications and possible usages in probabilistic inference. We\nconnect PSO to numerous existing statistical works which are also PSO\ninstances, and derive new PSO-based inference methods as demonstration of PSO\nexceptional usability. Likewise, based on the insights coming from the\nvirtual-force perspective we analyze PSO stability and propose new ways to\nimprove it. Finally, we present new instances of PSO, termed PSO-LDE, for data\nlog-density estimation and also provide a new NN block-diagonal architecture\nfor increased surface flexibility, which significantly improves estimation\naccuracy. Both PSO-LDE and the new architecture are combined together as a new\ndensity estimation technique. In our experiments we demonstrate this technique\nto be superior over state-of-the-art baselines in density estimation task for\nmultimodal 20D data.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:43:50 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 20:47:16 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 15:44:04 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 17:12:59 GMT"}, {"version": "v5", "created": "Fri, 31 Jul 2020 12:48:31 GMT"}, {"version": "v6", "created": "Thu, 20 Aug 2020 11:55:14 GMT"}, {"version": "v7", "created": "Fri, 25 Sep 2020 15:16:48 GMT"}, {"version": "v8", "created": "Wed, 13 Jan 2021 11:30:01 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Kopitkov", "Dmitry", ""], ["Indelman", "Vadim", ""]]}, {"id": "1903.10572", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Chin-Teng Lin and Jian Huang and Zhigang Zeng", "title": "On the Functional Equivalence of TSK Fuzzy Systems to Neural Networks,\n  Mixture of Experts, CART, and Stacking Ensemble Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy systems have achieved great success in numerous applications. However,\nthere are still many challenges in designing an optimal fuzzy system, e.g., how\nto efficiently optimize its parameters, how to balance the trade-off between\ncooperations and competitions among the rules, how to overcome the curse of\ndimensionality, how to increase its generalization ability, etc. Literature has\nshown that by making appropriate connections between fuzzy systems and other\nmachine learning approaches, good practices from other domains may be used to\nimprove the fuzzy systems, and vice versa. This paper gives an overview on the\nfunctional equivalence between Takagi-Sugeno-Kang fuzzy systems and four\nclassic machine learning approaches -- neural networks, mixture of experts,\nclassification and regression trees, and stacking ensemble regression -- for\nregression problems. We also point out some promising new research directions,\ninspired by the functional equivalence, that could lead to solutions to the\naforementioned problems. To our knowledge, this is so far the most\ncomprehensive overview on the connections between fuzzy systems and other\npopular machine learning approaches, and hopefully will stimulate more\nhybridization between different machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:52:17 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 17:18:14 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Wu", "Dongrui", ""], ["Lin", "Chin-Teng", ""], ["Huang", "Jian", ""], ["Zeng", "Zhigang", ""]]}, {"id": "1903.10578", "submitter": "David Hachuel", "authors": "David Hachuel, Akshay Jha, Deborah Estrin, Alfonso Martinez, Kyle\n  Staller, Christopher Velez", "title": "Augmenting Gastrointestinal Health: A Deep Learning Approach to Human\n  Stool Recognition and Characterization in Macroscopic Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose - Functional bowel diseases, including irritable bowel syndrome,\nchronic constipation, and chronic diarrhea, are some of the most common\ndiseases seen in clinical practice. Many patients describe a range of triggers\nfor altered bowel consistency and symptoms. However, characterization of the\nrelationship between symptom triggers using bowel diaries is hampered by poor\ncompliance and lack of objective stool consistency measurements. We sought to\ndevelop a stool detection and tracking system using computer vision and deep\nconvolutional neural networks (CNN) that could be used by patients, providers,\nand researchers in the assessment of chronic gastrointestinal (GI) disease.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 20:08:17 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Hachuel", "David", ""], ["Jha", "Akshay", ""], ["Estrin", "Deborah", ""], ["Martinez", "Alfonso", ""], ["Staller", "Kyle", ""], ["Velez", "Christopher", ""]]}, {"id": "1903.10586", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang, Percy Liang", "title": "Defending against Whitebox Adversarial Attacks via Randomized\n  Discretization", "comments": "In proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial perturbations dramatically decrease the accuracy of\nstate-of-the-art image classifiers. In this paper, we propose and analyze a\nsimple and computationally efficient defense strategy: inject random Gaussian\nnoise, discretize each pixel, and then feed the result into any pre-trained\nclassifier. Theoretically, we show that our randomized discretization strategy\nreduces the KL divergence between original and adversarial inputs, leading to a\nlower bound on the classification accuracy of any classifier against any\n(potentially whitebox) $\\ell_\\infty$-bounded adversarial attack. Empirically,\nwe evaluate our defense on adversarial examples generated by a strong iterative\nPGD attack. On ImageNet, our defense is more robust than adversarially-trained\nnetworks and the winning defenses of the NIPS 2017 Adversarial Attacks &\nDefenses competition.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 20:24:47 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Zhang", "Yuchen", ""], ["Liang", "Percy", ""]]}, {"id": "1903.10588", "submitter": "Zonglin Yang", "authors": "Zonglin Yang, Xinggang Wang", "title": "Reducing the dilution: An analysis of the information sensitiveness of\n  capsule network with a practical improvement method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule network has shown various advantages over convolutional neural\nnetwork (CNN). It keeps more precise spatial information than CNN and uses\nequivariance instead of invariance during inference and highly potential to be\na new effective tool for visual tasks. However, the current capsule networks\nhave incompatible performance with CNN when facing datasets with background and\ncomplex target objects and are lacking in universal and efficient\nregularization method.\n  We analyze a main reason of the incompatible performance as the conflict\nbetween information sensitiveness of capsule network and unreasonably higher\nactivation value distribution of capsules in primary capsule layer.\nCorrespondingly, we propose a practical improvement method by restraining the\nactivation value of capsules in primary capsule layer to suppress\nnon-informative capsules and highlight discriminative capsules. In the\nexperiments, the method has achieved better performances on various mainstream\ndatasets. In addition, the proposed improvement methods can be seen as a\nsuitable, simple and efficient regularization method that can be generally used\nin capsule network.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 20:28:44 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 13:54:26 GMT"}, {"version": "v3", "created": "Thu, 2 May 2019 21:42:46 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Yang", "Zonglin", ""], ["Wang", "Xinggang", ""]]}, {"id": "1903.10598", "submitter": "Sina Aghaei", "authors": "Sina Aghaei, Mohammad Javad Azizi, Phebe Vayanos", "title": "Learning Optimal and Fair Decision Trees for Non-Discriminative\n  Decision-Making", "comments": "33rd AAAI Conference on Artificial Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, automated data-driven decision-making systems have enjoyed a\ntremendous success in a variety of fields (e.g., to make product\nrecommendations, or to guide the production of entertainment). More recently,\nthese algorithms are increasingly being used to assist socially sensitive\ndecision-making (e.g., to decide who to admit into a degree program or to\nprioritize individuals for public housing). Yet, these automated tools may\nresult in discriminative decision-making in the sense that they may treat\nindividuals unfairly or unequally based on membership to a category or a\nminority, resulting in disparate treatment or disparate impact and violating\nboth moral and ethical standards. This may happen when the training dataset is\nitself biased (e.g., if individuals belonging to a particular group have\nhistorically been discriminated upon). However, it may also happen when the\ntraining dataset is unbiased, if the errors made by the system affect\nindividuals belonging to a category or minority differently (e.g., if\nmisclassification rates for Blacks are higher than for Whites). In this paper,\nwe unify the definitions of unfairness across classification and regression. We\npropose a versatile mixed-integer optimization framework for learning optimal\nand fair decision trees and variants thereof to prevent disparate treatment\nand/or disparate impact as appropriate. This translates to a flexible schema\nfor designing fair and interpretable policies suitable for socially sensitive\ndecision-making. We conduct extensive computational studies that show that our\nframework improves the state-of-the-art in the field (which typically relies on\nheuristics) to yield non-discriminative decisions at lower cost to overall\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 21:16:39 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Aghaei", "Sina", ""], ["Azizi", "Mohammad Javad", ""], ["Vayanos", "Phebe", ""]]}, {"id": "1903.10630", "submitter": "Budhaditya Deb", "authors": "Budhaditya Deb and Peter Bailey and Milad Shokouhi", "title": "Diversifying Reply Suggestions using a Matching-Conditional Variational\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of diversifying automated reply suggestions for a\ncommercial instant-messaging (IM) system (Skype). Our conversation model is a\nstandard matching based information retrieval architecture, which consists of\ntwo parallel encoders to project messages and replies into a common feature\nrepresentation. During inference, we select replies from a fixed response set\nusing nearest neighbors in the feature space. To diversify responses, we\nformulate the model as a generative latent variable model with Conditional\nVariational Auto-Encoder (M-CVAE). We propose a constrained-sampling approach\nto make the variational inference in M-CVAE efficient for our production\nsystem. In offline experiments, M-CVAE consistently increased diversity by\n~30-40% without significant impact on relevance. This translated to a 5% gain\nin click-rate in our online production system.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 23:12:56 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Deb", "Budhaditya", ""], ["Bailey", "Peter", ""], ["Shokouhi", "Milad", ""]]}, {"id": "1903.10646", "submitter": "Yuan Gao", "authors": "Yuan Gao and Christian Kroer and Donald Goldfarb", "title": "Increasing Iterate Averaging for Solving Saddle-Point Problems", "comments": "Preprint. Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in machine learning and game theory can be formulated as\nsaddle-point problems, for which various first-order methods have been\ndeveloped and proven efficient in practice. Under the general convex-concave\nassumption, most first-order methods only guarantee an ergodic convergence\nrate, that is, the uniform averages of the iterates converge at a $O(1/T)$ rate\nin terms of the saddle-point residual. However, numerically, the iterates\nthemselves can often converge much faster than the uniform averages. This\nobservation motivates increasing averaging schemes that put more weight on\nlater iterates, in contrast to the usual uniform averaging. We show that such\nincreasing averaging schemes, applied to various first-order methods, are able\nto preserve the $O(1/T)$ convergence rate with no additional assumptions or\ncomputational overhead. Extensive numerical experiments on zero-sum game\nsolving, market equilibrium computation and image denoising demonstrate the\neffectiveness of the proposed schemes. In particular, the increasing averages\nconsistently outperform the uniform averages in all test problems by orders of\nmagnitude. When solving matrix and extensive-form games, increasing averages\nconsistently outperform the last iterates as well. For matrix games, a\nfirst-order method equipped with increasing averaging outperforms the highly\ncompetitive CFR$^+$ algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 01:00:53 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 02:04:31 GMT"}, {"version": "v3", "created": "Sat, 13 Jun 2020 18:59:52 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Gao", "Yuan", ""], ["Kroer", "Christian", ""], ["Goldfarb", "Donald", ""]]}, {"id": "1903.10672", "submitter": "Md. Ariful Islam", "authors": "Abhishek Murthy, Himel Das, Md Ariful Islam", "title": "Robustness of Neural Networks to Parameter Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization, a commonly used technique to reduce the memory footprint of a\nneural network for edge computing, entails reducing the precision of the\nfloating-point representation used for the parameters of the network. The\nimpact of such rounding-off errors on the overall performance of the neural\nnetwork is estimated using testing, which is not exhaustive and thus cannot be\nused to guarantee the safety of the model. We present a framework based on\nSatisfiability Modulo Theory (SMT) solvers to quantify the robustness of neural\nnetworks to parameter perturbation. To this end, we introduce notions of local\nand global robustness that capture the deviation in the confidence of class\nassignments due to parameter quantization. The robustness notions are then cast\nas instances of SMT problems and solved automatically using solvers, such as\ndReal. We demonstrate our framework on two simple Multi-Layer Perceptrons (MLP)\nthat perform binary classification on a two-dimensional input. In addition to\nquantifying the robustness, we also show that Rectified Linear Unit activation\nresults in higher robustness than linear activations for our MLPs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 04:37:54 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Murthy", "Abhishek", ""], ["Das", "Himel", ""], ["Islam", "Md Ariful", ""]]}, {"id": "1903.10679", "submitter": "Yishen Wang", "authors": "Yayu Peng, Yishen Wang, Xiao Lu, Haifeng Li, Di Shi, Zhiwei Wang, Jie\n  Li", "title": "Short-term Load Forecasting at Different Aggregation Levels with\n  Predictability Analysis", "comments": "To appear in ISGT ASIA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term load forecasting (STLF) is essential for the reliable and economic\noperation of power systems. Though many STLF methods were proposed over the\npast decades, most of them focused on loads at high aggregation levels only.\nThus, low-aggregation load forecast still requires further research and\ndevelopment. Compared with the substation or city level loads, individual loads\nare typically more volatile and much more challenging to forecast. To further\naddress this issue, this paper first discusses the characteristics of\nsmall-and-medium enterprise (SME) and residential loads at different\naggregation levels and quantifies their predictability with approximate\nentropy. Various STLF techniques, from the conventional linear regression to\nstate-of-the-art deep learning, are implemented for a detailed comparative\nanalysis to verify the forecasting performances as well as the predictability\nusing an Irish smart meter dataset. In addition, the paper also investigates\nhow using data processing improves individual-level residential load\nforecasting with low predictability. Effectiveness of the discussed method is\nvalidated with numerical results.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 05:16:14 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Peng", "Yayu", ""], ["Wang", "Yishen", ""], ["Lu", "Xiao", ""], ["Li", "Haifeng", ""], ["Shi", "Di", ""], ["Wang", "Zhiwei", ""], ["Li", "Jie", ""]]}, {"id": "1903.10684", "submitter": "Yishen Wang", "authors": "Qicheng Chang, Yishen Wang, Xiao Lu, Di Shi, Haifeng Li, Jiajun Duan,\n  Zhiwei Wang", "title": "Probabilistic Load Forecasting via Point Forecast Feature Integration", "comments": "To appear in ISGT ASIA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term load forecasting is a critical element of power systems energy\nmanagement systems. In recent years, probabilistic load forecasting (PLF) has\ngained increased attention for its ability to provide uncertainty information\nthat helps to improve the reliability and economics of system operation\nperformances. This paper proposes a two-stage probabilistic load forecasting\nframework by integrating point forecast as a key probabilistic forecasting\nfeature into PLF. In the first stage, all related features are utilized to\ntrain a point forecast model and also obtain the feature importance. In the\nsecond stage the forecasting model is trained, taking into consideration point\nforecast features, as well as selected feature subsets. During the testing\nperiod of the forecast model, the final probabilistic load forecast results are\nleveraged to obtain both point forecasting and probabilistic forecasting.\nNumerical results obtained from ISO New England demand data demonstrate the\neffectiveness of the proposed approach in the hour-ahead load forecasting,\nwhich uses the gradient boosting regression for the point forecasting and\nquantile regression neural networks for the probabilistic forecasting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 05:35:46 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Chang", "Qicheng", ""], ["Wang", "Yishen", ""], ["Lu", "Xiao", ""], ["Shi", "Di", ""], ["Li", "Haifeng", ""], ["Duan", "Jiajun", ""], ["Wang", "Zhiwei", ""]]}, {"id": "1903.10693", "submitter": "Artemy Kolchinsky", "authors": "Artemy Kolchinsky and Bernat Corominas-Murtra", "title": "Decomposing information into copying versus transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cond-mat.stat-mech math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world systems, information can be transmitted in two\nqualitatively different ways: by copying or by transformation. Copying occurs\nwhen messages are transmitted without modification, e.g., when an offspring\nreceives an unaltered copy of a gene from its parent. Transformation occurs\nwhen messages are modified systematically during transmission, e.g., when\nmutational biases occur during genetic replication. Standard\ninformation-theoretic measures do not distinguish these two modes of\ninformation transfer, although they may reflect different mechanisms and have\ndifferent functional consequences. Starting from a few simple axioms, we derive\na decomposition of mutual information into the information transmitted by\ncopying versus the information transmitted by transformation. We begin with a\ndecomposition that applies when the source and destination of the channel have\nthe same set of messages and a notion of message identity exists. We then\ngeneralize our decomposition to other kinds of channels, which can involve\ndifferent source and destination sets and broader notions of similarity. In\naddition, we show that copy information can be interpreted as the minimal work\nneeded by a physical copying process, which is relevant for understanding the\nphysics of replication. We use the proposed decomposition to explore a model of\namino acid substitution rates. Our results apply to any system in which the\nfidelity of copying, rather than simple predictability, is of critical\nrelevance.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 09:32:01 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 12:36:22 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 01:30:03 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Kolchinsky", "Artemy", ""], ["Corominas-Murtra", "Bernat", ""]]}, {"id": "1903.10699", "submitter": "Mostafa Haghir Chehreghani", "authors": "Mostafa Haghir Chehreghani", "title": "Regression and Singular Value Decomposition in Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of real-world graphs are {\\em dynamic}, i.e., they change over time.\nHowever, while problems such as regression and Singular Value Decomposition\n(SVD) have been studied for {\\em static} graphs, they have not been\ninvestigated for {\\em dynamic} graphs, yet. In this paper, we introduce,\nmotivate and study regression and SVD over dynamic graphs. First, we present\nthe notion of {\\em update-efficient matrix embedding} that defines the\nconditions sufficient for a matrix embedding to be used for the dynamic graph\nregression problem (under $l_2$ norm). We prove that given an $n \\times m$\nupdate-efficient matrix embedding (e.g., adjacency matrix), after an update\noperation in the graph, the optimal solution of the graph regression problem\nfor the revised graph can be computed in $O(nm)$ time. We also study dynamic\ngraph regression under least absolute deviation. Then, we characterize a class\nof matrix embeddings that can be used to efficiently update SVD of a dynamic\ngraph. For adjacency matrix and Laplacian matrix, we study those graph update\noperations for which SVD (and low rank approximation) can be updated\nefficiently.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 06:17:49 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 08:11:23 GMT"}, {"version": "v3", "created": "Sat, 4 Jan 2020 07:47:02 GMT"}, {"version": "v4", "created": "Thu, 9 Apr 2020 20:25:15 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Chehreghani", "Mostafa Haghir", ""]]}, {"id": "1903.10709", "submitter": "Yuuki Yamanaka", "authors": "Yuki Yamanaka, Tomoharu Iwata, Hiroshi Takahashi, Masanori Yamada,\n  Sekitoshi Kanai", "title": "Autoencoding Binary Classifiers for Supervised Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Autoencoding Binary Classifiers (ABC), a novel supervised\nanomaly detector based on the Autoencoder (AE). There are two main approaches\nin anomaly detection: supervised and unsupervised. The supervised approach\naccurately detects the known anomalies included in training data, but it cannot\ndetect the unknown anomalies. Meanwhile, the unsupervised approach can detect\nboth known and unknown anomalies that are located away from normal data points.\nHowever, it does not detect known anomalies as accurately as the supervised\napproach. Furthermore, even if we have labeled normal data points and\nanomalies, the unsupervised approach cannot utilize these labels. The ABC is a\nprobabilistic binary classifier that effectively exploits the label\ninformation, where normal data points are modeled using the AE as a component.\nBy maximizing the likelihood, the AE in the proposed ABC is trained to minimize\nthe reconstruction error for normal data points, and to maximize it for known\nanomalies. Since our approach becomes able to reconstruct the normal data\npoints accurately and fails to reconstruct the known and unknown anomalies, it\ncan accurately discriminate both known and unknown anomalies from normal data\npoints. Experimental results show that the ABC achieves higher detection\nperformance than existing supervised and unsupervised methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 07:12:36 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Yamanaka", "Yuki", ""], ["Iwata", "Tomoharu", ""], ["Takahashi", "Hiroshi", ""], ["Yamada", "Masanori", ""], ["Kanai", "Sekitoshi", ""]]}, {"id": "1903.10726", "submitter": "Sourav Mishra", "authors": "Sourav Mishra, Toshihiko Yamasaki and Hideaki Imaizumi", "title": "Improving image classifiers for small datasets by learning rate\n  adaptations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our paper introduces an efficient combination of established techniques to\nimprove classifier performance, in terms of accuracy and training time. We\nachieve two-fold to ten-fold speedup in nearing state of the art accuracy, over\ndifferent model architectures, by dynamically tuning the learning rate. We find\nit especially beneficial in the case of a small dataset, where reliability of\nmachine reasoning is lower. We validate our approach by comparing our method\nversus vanilla training on CIFAR-10. We also demonstrate its practical\nviability by implementing on an unbalanced corpus of diagnostic images.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 08:22:01 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 17:15:30 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Mishra", "Sourav", ""], ["Yamasaki", "Toshihiko", ""], ["Imaizumi", "Hideaki", ""]]}, {"id": "1903.10742", "submitter": "Zhengzhi Sun", "authors": "Zheng-Zhi Sun, Cheng Peng, Ding Liu, Shi-Ju Ran, and Gang Su", "title": "Generative Tensor Network Classification Model for Supervised Machine\n  Learning", "comments": "7 pages, 5 figures", "journal-ref": "Phys. Rev. B 101, 075135 (2020)", "doi": "10.1103/PhysRevB.101.075135", "report-no": null, "categories": "cs.LG cond-mat.str-el quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor network (TN) has recently triggered extensive interests in developing\nmachine-learning models in quantum many-body Hilbert space. Here we purpose a\ngenerative TN classification (GTNC) approach for supervised learning. The\nstrategy is to train the generative TN for each class of the samples to\nconstruct the classifiers. The classification is implemented by comparing the\ndistance in the many-body Hilbert space. The numerical experiments by GTNC show\nimpressive performance on the MNIST and Fashion-MNIST dataset. The testing\naccuracy is competitive to the state-of-the-art convolutional neural network\nwhile higher than the naive Bayes classifier (a generative classifier) and\nsupport vector machine. Moreover, GTNC is more efficient than the existing TN\nmodels that are in general discriminative. By investigating the distances in\nthe many-body Hilbert space, we find that (a) the samples are naturally\nclustering in such a space; and (b) bounding the bond dimensions of the TN's to\nfinite values corresponds to removing redundant information in the image\nrecognition. These two characters make GTNC an adaptive and universal model of\nexcellent performance.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 09:07:36 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Sun", "Zheng-Zhi", ""], ["Peng", "Cheng", ""], ["Liu", "Ding", ""], ["Ran", "Shi-Ju", ""], ["Su", "Gang", ""]]}, {"id": "1903.10826", "submitter": "Yujia Liu", "authors": "Yujia Liu, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard", "title": "A geometry-inspired decision-based attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently achieved tremendous success in image\nclassification. Recent studies have however shown that they are easily misled\ninto incorrect classification decisions by adversarial examples. Adversaries\ncan even craft attacks by querying the model in black-box settings, where no\ninformation about the model is released except its final decision. Such\ndecision-based attacks usually require lots of queries, while real-world image\nrecognition systems might actually restrict the number of queries. In this\npaper, we propose qFool, a novel decision-based attack algorithm that can\ngenerate adversarial examples using a small number of queries. The qFool method\ncan drastically reduce the number of queries compared to previous\ndecision-based attacks while reaching the same quality of adversarial examples.\nWe also enhance our method by constraining adversarial perturbations in\nlow-frequency subspace, which can make qFool even more computationally\nefficient. Altogether, we manage to fool commercial image recognition systems\nwith a small number of queries, which demonstrates the actual effectiveness of\nour new algorithm in practice.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 12:18:31 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Liu", "Yujia", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "1903.10833", "submitter": "Tiago Peixoto", "authors": "Tiago P. Peixoto", "title": "Network reconstruction and community detection from dynamics", "comments": "11 pages, 6 figures, 2 tables", "journal-ref": "Phys. Rev. Lett. 123, 128301 (2019)", "doi": "10.1103/PhysRevLett.123.128301", "report-no": null, "categories": "physics.soc-ph cs.SI physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a scalable nonparametric Bayesian method to perform network\nreconstruction from observed functional behavior that at the same time infers\nthe communities present in the network. We show that the joint reconstruction\nwith community detection has a synergistic effect, where the edge correlations\nused to inform the existence of communities are also inherently used to improve\nthe accuracy of the reconstruction which, in turn, can better inform the\nuncovering of communities. We illustrate the use of our method with\nobservations arising from epidemic models and the Ising model, both on\nsynthetic and empirical networks, as well as on data containing only functional\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 12:35:08 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 10:00:01 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Peixoto", "Tiago P.", ""]]}, {"id": "1903.10842", "submitter": "Yuchi Zhang", "authors": "Yuchi Zhang, Yongliang Wang, Liping Zhang, Zhiqiang Zhang, Kun Gai", "title": "Improve Diverse Text Generation by Self Labeling Conditional Variational\n  Auto Encoder", "comments": "Accepted as a conference paper in ICASSP 2019. But this copy is an\n  extended version of the submitted manuscript. With more theoretical analysis\n  and human evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity plays a vital role in many text generating applications. In recent\nyears, Conditional Variational Auto Encoders (CVAE) have shown promising\nperformances for this task. However, they often encounter the so called\nKL-Vanishing problem. Previous works mitigated such problem by heuristic\nmethods such as strengthening the encoder or weakening the decoder while\noptimizing the CVAE objective function. Nevertheless, the optimizing direction\nof these methods are implicit and it is hard to find an appropriate degree to\nwhich these methods should be applied. In this paper, we propose an explicit\noptimizing objective to complement the CVAE to directly pull away from\nKL-vanishing. In fact, this objective term guides the encoder towards the \"best\nencoder\" of the decoder to enhance the expressiveness. A labeling network is\nintroduced to estimate the \"best encoder\". It provides a continuous label in\nthe latent space of CVAE to help build a close connection between latent\nvariables and targets. The whole proposed method is named Self Labeling\nCVAE~(SLCVAE). To accelerate the research of diverse text generation, we also\npropose a large native one-to-many dataset. Extensive experiments are conducted\non two tasks, which show that our method largely improves the generating\ndiversity while achieving comparable accuracy compared with state-of-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 12:53:26 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Zhang", "Yuchi", ""], ["Wang", "Yongliang", ""], ["Zhang", "Liping", ""], ["Zhang", "Zhiqiang", ""], ["Gai", "Kun", ""]]}, {"id": "1903.10862", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Feifei Liu and Chengyu Liu", "title": "Active Stacking for Heart Rate Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart rate estimation from electrocardiogram signals is very important for\nthe early detection of cardiovascular diseases. However, due to large\nindividual differences and varying electrocardiogram signal quality, there does\nnot exist a single reliable estimation algorithm that works well on all\nsubjects. Every algorithm may break down on certain subjects, resulting in a\nsignificant estimation error. Ensemble regression, which aggregates the outputs\nof multiple base estimators for more reliable and stable estimates, can be used\nto remedy this problem. Moreover, active learning can be used to optimally\nselect a few trials from a new subject to label, based on which a stacking\nensemble regression model can be trained to aggregate the base estimators. This\npaper proposes four active stacking approaches, and demonstrates that they all\nsignificantly outperform three common unsupervised ensemble regression\napproaches, and a supervised stacking approach which randomly selects some\ntrials to label. Remarkably, our active stacking approaches only need three or\nfour labeled trials from each subject to achieve an average root mean squared\nestimation error below three beats per minute, making them very convenient for\nreal-world applications. To our knowledge, this is the first research on active\nstacking, and its application to heart rate estimation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 13:26:34 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Wu", "Dongrui", ""], ["Liu", "Feifei", ""], ["Liu", "Chengyu", ""]]}, {"id": "1903.10867", "submitter": "Thai Dang Tran", "authors": "Tran-Thai Dang, Tien-Lam Pham, Hiori Kino, Takashi Miyake, and\n  Hieu-Chi Dam", "title": "Measuring the Similarity between Materials with an Emphasis on the\n  Materials Distinctiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we establish a basis for selecting similarity measures when\napplying machine learning techniques to solve materials science problems. This\nselection is considered with an emphasis on the distinctiveness between\nmaterials that reflect their nature well. We perform a case study with a\ndataset of rare-earth transition metal crystalline compounds represented using\nthe Orbital Field Matrix descriptor and the Coulomb Matrix descriptor. We\nperform predictions of the formation energies using k-nearest neighbors\nregression, ridge regression, and kernel ridge regression. Through detailed\nanalyses of the yield prediction accuracy, we examine the relationship between\nthe characteristics of the material representation and similarity measures, and\nthe complexity of the energy function they can capture. Empirical experiments\nand theoretical analysis reveal that similarity measures and kernels that\nminimize the loss of materials distinctiveness improve the prediction\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 12:55:01 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Dang", "Tran-Thai", ""], ["Pham", "Tien-Lam", ""], ["Kino", "Hiori", ""], ["Miyake", "Takashi", ""], ["Dam", "Hieu-Chi", ""]]}, {"id": "1903.10870", "submitter": "Ankit Sharma", "authors": "Ankit Sharma, Late C. A. Murthy", "title": "Algorithms and Improved bounds for online learning under finite\n  hypothesis class", "comments": "17 pages, 2 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning is the process of answering a sequence of questions based on\nthe correct answers to the previous questions. It is studied in many research\nareas such as game theory, information theory and machine learning. There are\ntwo main components of online learning framework. First, the learning algorithm\nalso known as the learner and second, the hypothesis class which is essentially\na set of functions which learner uses to predict answers to the questions.\nSometimes, this class contains some functions which have the capability to\nprovide correct answers to the entire sequence of questions. This case is\ncalled realizable case. And when hypothesis class does not contain such\nfunctions is called unrealizable case. The goal of the learner, in both the\ncases, is to make as few mistakes as that could have been made by most powerful\nfunctions in hypothesis class over the entire sequence of questions.\nPerformance of the learners is analysed by theoretical bounds on the number of\nmistakes made by them. This paper proposes three algorithms to improve the\nmistakes bound in the unrealizable case. Proposed algorithms perform highly\nbetter than the existing ones in the long run when most of the input sequences\npresented to the learner are likely to be realizable.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 06:52:26 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Sharma", "Ankit", ""], ["Murthy", "Late C. A.", ""]]}, {"id": "1903.10899", "submitter": "Udo Schilcher", "authors": "Jorge F. Schmidt, Udo Schilcher, Mahin K. Atiq, and Christian\n  Bettstetter", "title": "Interference Prediction in Wireless Networks: Stochastic Geometry meets\n  Recursive Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes and evaluates a technique to predict the level of\ninterference in wireless networks. We design a recursive predictor that\nestimates future interference values by filtering measured interference at a\ngiven location. The predictor's parameterization is done offline by translating\nthe autocorrelation of interference into an autoregressive moving average\n(ARMA) representation. This ARMA model is inserted into a steady-state Kalman\nfilter enabling nodes to predict with low computational effort. Results show a\ngood accuracy of predicted values versus true values for relevant time\nhorizons. Although the predictor is parameterized for Poisson-distributed\nnodes, Rayleigh fading, and fixed message lengths, a sensitivity analysis shows\nthat it also tends to work well in more general network scenarios. Numerical\nexamples for underlay device-to-device communications, a common wireless sensor\ntechnology, and coexistence scenarios of Wi-Fi and LTE illustrate its broad\napplicability. The predictor can be applied as part of interference management\nto improve medium access, scheduling, and radio resource allocation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:08:51 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 11:02:43 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 10:19:50 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Schmidt", "Jorge F.", ""], ["Schilcher", "Udo", ""], ["Atiq", "Mahin K.", ""], ["Bettstetter", "Christian", ""]]}, {"id": "1903.10909", "submitter": "Kun Wang", "authors": "Kun Wang, Jun He, and Lei Zhang", "title": "Attention-based Convolutional Neural Network for Weakly Labeled Human\n  Activities Recognition with Wearable Sensors", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": "10.1109/JSEN.2019.2917225", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike images or videos data which can be easily labeled by human being,\nsensor data annotation is a time-consuming process. However, traditional\nmethods of human activity recognition require a large amount of such strictly\nlabeled data for training classifiers. In this paper, we present an\nattention-based convolutional neural network for human recognition from weakly\nlabeled data. The proposed attention model can focus on labeled activity among\na long sequence of sensor data, and while filter out a large amount of\nbackground noise signals. In experiment on the weakly labeled dataset, we show\nthat our attention model outperforms classical deep learning methods in\naccuracy. Besides, we determine the specific locations of the labeled activity\nin a long sequence of weakly labeled data by converting the compatibility score\nwhich is generated from attention model to compatibility density. Our method\ngreatly facilitates the process of sensor data annotation, and makes data\ncollection more easy.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 05:47:31 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 04:50:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wang", "Kun", ""], ["He", "Jun", ""], ["Zhang", "Lei", ""]]}, {"id": "1903.10926", "submitter": "Nguyen Q. Tran", "authors": "Nguyen Tran, Henrik Ambos and Alexander Jung", "title": "Classifying Partially Labeled Networked Data via Logistic Network Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the network Lasso to classify partially labeled data points which\nare characterized by high-dimensional feature vectors. In order to learn an\naccurate classifier from limited amounts of labeled data, we borrow statistical\nstrength, via an intrinsic network structure, across the dataset. The resulting\nlogistic network Lasso amounts to a regularized empirical risk minimization\nproblem using the total variation of a classifier as a regularizer. This\nminimization problem is a non-smooth convex optimization problem which we solve\nusing a primal-dual splitting method. This method is appealing for big data\napplications as it can be implemented as a highly scalable message passing\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:37:16 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Tran", "Nguyen", ""], ["Ambos", "Henrik", ""], ["Jung", "Alexander", ""]]}, {"id": "1903.10951", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Ye Yuan and Yihua Tan", "title": "Optimize TSK Fuzzy Systems for Regression Problems: Mini-Batch Gradient\n  Descent with Regularization, DropRule and AdaBound (MBGD-RDA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Takagi-Sugeno-Kang (TSK) fuzzy systems are very useful machine learning\nmodels for regression problems. However, to our knowledge, there has not\nexisted an efficient and effective training algorithm that ensures their\ngeneralization performance, and also enables them to deal with big data.\nInspired by the connections between TSK fuzzy systems and neural networks, we\nextend three powerful neural network optimization techniques, i.e., mini-batch\ngradient descent, regularization, and AdaBound, to TSK fuzzy systems, and also\npropose three novel techniques (DropRule, DropMF, and DropMembership)\nspecifically for training TSK fuzzy systems. Our final algorithm, mini-batch\ngradient descent with regularization, DropRule and AdaBound (MBGD-RDA), can\nachieve fast convergence in training TSK fuzzy systems, and also superior\ngeneralization performance in testing. It can be used for training TSK fuzzy\nsystems on datasets of any size; however, it is particularly useful for big\ndatasets, on which currently no other efficient training algorithms exist.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:16:24 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 11:37:38 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 01:45:17 GMT"}, {"version": "v4", "created": "Sun, 1 Dec 2019 04:58:47 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wu", "Dongrui", ""], ["Yuan", "Ye", ""], ["Tan", "Yihua", ""]]}, {"id": "1903.10956", "submitter": "Kun Yuan", "authors": "Kun Yuan, Sulaiman A. Alghunaim, Bicheng Ying, Ali H. Sayed", "title": "On the Influence of Bias-Correction on Distributed Stochastic\n  Optimization", "comments": "17 pages, 9 figure, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various bias-correction methods such as EXTRA, gradient tracking methods, and\nexact diffusion have been proposed recently to solve distributed {\\em\ndeterministic} optimization problems. These methods employ constant step-sizes\nand converge linearly to the {\\em exact} solution under proper conditions.\nHowever, their performance under stochastic and adaptive settings is less\nexplored. It is still unknown {\\em whether}, {\\em when} and {\\em why} these\nbias-correction methods can outperform their traditional counterparts (such as\nconsensus and diffusion) with noisy gradient and constant step-sizes.\n  This work studies the performance of exact diffusion under the stochastic and\nadaptive setting, and provides conditions under which exact diffusion has\nsuperior steady-state mean-square deviation (MSD) performance than traditional\nalgorithms without bias-correction. In particular, it is proven that this\nsuperiority is more evident over sparsely-connected network topologies such as\nlines, cycles, or grids. Conditions are also provided under which exact\ndiffusion method match or may even degrade the performance of traditional\nmethods. Simulations are provided to validate the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:28:36 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 06:54:02 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Yuan", "Kun", ""], ["Alghunaim", "Sulaiman A.", ""], ["Ying", "Bicheng", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1903.10978", "submitter": "Magda Gregorova", "authors": "Magda Gregorova", "title": "Sparse Learning for Variable Selection with Structures and\n  Nonlinearities", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis we discuss machine learning methods performing automated\nvariable selection for learning sparse predictive models. There are multiple\nreasons for promoting sparsity in the predictive models. By relying on a\nlimited set of input variables the models naturally counteract the overfitting\nproblem ubiquitous in learning from finite sets of training points. Sparse\nmodels are cheaper to use for predictions, they usually require lower\ncomputational resources and by relying on smaller sets of inputs can possibly\nreduce costs for data collection and storage. Sparse models can also contribute\nto better understanding of the investigated phenomenons as they are easier to\ninterpret than full models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 16:07:18 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Gregorova", "Magda", ""]]}, {"id": "1903.10992", "submitter": "Marco Ancona", "authors": "Marco Ancona, Cengiz \\\"Oztireli, Markus Gross", "title": "Explaining Deep Neural Networks with a Polynomial Time Algorithm for\n  Shapley Values Approximation", "comments": "ICML 2019", "journal-ref": "PMLR 97 (2019) 272-281", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of explaining the behavior of deep neural networks has recently\ngained a lot of attention. While several attribution methods have been\nproposed, most come without strong theoretical foundations, which raises\nquestions about their reliability. On the other hand, the literature on\ncooperative game theory suggests Shapley values as a unique way of assigning\nrelevance scores such that certain desirable properties are satisfied.\nUnfortunately, the exact evaluation of Shapley values is prohibitively\nexpensive, exponential in the number of input features. In this work, by\nleveraging recent results on uncertainty propagation, we propose a novel,\npolynomial-time approximation of Shapley values in deep neural networks. We\nshow that our method produces significantly better approximations of Shapley\nvalues than existing state-of-the-art attribution methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 16:27:21 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 14:07:42 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 21:57:15 GMT"}, {"version": "v4", "created": "Fri, 21 Jun 2019 15:39:37 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Ancona", "Marco", ""], ["\u00d6ztireli", "Cengiz", ""], ["Gross", "Markus", ""]]}, {"id": "1903.11012", "submitter": "Devdhar Patel", "authors": "Devdhar Patel, Hananel Hazan, Daniel J. Saunders, Hava Siegelmann,\n  Robert Kozma", "title": "Improved robustness of reinforcement learning policies upon conversion\n  to spiking neuronal network platforms applied to ATARI games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Reinforcement Learning (RL) demonstrates excellent performance on tasks\nthat can be solved by trained policy. It plays a dominant role among\ncutting-edge machine learning approaches using multi-layer Neural networks\n(NNs). At the same time, Deep RL suffers from high sensitivity to noisy,\nincomplete, and misleading input data. Following biological intuition, we\ninvolve Spiking Neural Networks (SNNs) to address some deficiencies of deep RL\nsolutions. Previous studies in image classification domain demonstrated that\nstandard NNs (with ReLU nonlinearity) trained using supervised learning can be\nconverted to SNNs with negligible deterioration in performance. In this paper,\nwe extend those conversion results to the domain of Q-Learning NNs trained\nusing RL. We provide a proof of principle of the conversion of standard NN to\nSNN. In addition, we show that the SNN has improved robustness to occlusion in\nthe input image. Finally, we introduce results with converting full-scale Deep\nQ-network to SNN, paving the way for future research to robust Deep RL\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 16:53:09 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 22:36:43 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 14:46:13 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Patel", "Devdhar", ""], ["Hazan", "Hananel", ""], ["Saunders", "Daniel J.", ""], ["Siegelmann", "Hava", ""], ["Kozma", "Robert", ""]]}, {"id": "1903.11020", "submitter": "Shuo Zhou", "authors": "Shuo Zhou, Wenwen Li, Christopher R. Cox, and Haiping Lu", "title": "Domain Independent SVM for Transfer Learning in Brain Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Brain imaging data are important in brain sciences yet expensive to obtain,\nwith big volume (i.e., large p) but small sample size (i.e., small n). To\ntackle this problem, transfer learning is a promising direction that leverages\nsource data to improve performance on related, target data. Most transfer\nlearning methods focus on minimizing data distribution mismatch. However, a big\nchallenge in brain imaging is the large domain discrepancies in cognitive\nexperiment designs and subject-specific structures and functions. A recent\ntransfer learning approach minimizes domain dependence to learn common features\nacross domains, via the Hilbert-Schmidt Independence Criterion (HSIC). Inspired\nby this method, we propose a new Domain Independent Support Vector Machine\n(DI-SVM) for transfer learning in brain condition decoding. Specifically,\nDI-SVM simultaneously minimizes the SVM empirical risk and the dependence on\ndomain information via a simplified HSIC. We use public data to construct 13\ntransfer learning tasks in brain decoding, including three interesting\nmulti-source transfer tasks. Experiments show that DI-SVM's superior\nperformance over eight competing methods on these tasks, particularly an\nimprovement of more than 24% on multi-source transfer tasks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:04:44 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Zhou", "Shuo", ""], ["Li", "Wenwen", ""], ["Cox", "Christopher R.", ""], ["Lu", "Haiping", ""]]}, {"id": "1903.11027", "submitter": "Holger Caesar", "authors": "Holger Caesar, Varun Bankiti, Alex H. Lang, Sourabh Vora, Venice Erin\n  Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, Oscar Beijbom", "title": "nuScenes: A multimodal dataset for autonomous driving", "comments": "CVPR 2020 camera ready incl. supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust detection and tracking of objects is crucial for the deployment of\nautonomous vehicle technology. Image based benchmark datasets have driven\ndevelopment in computer vision tasks such as object detection, tracking and\nsegmentation of agents in the environment. Most autonomous vehicles, however,\ncarry a combination of cameras and range sensors such as lidar and radar. As\nmachine learning based methods for detection and tracking become more\nprevalent, there is a need to train and evaluate such methods on datasets\ncontaining range sensor data along with images. In this work we present\nnuTonomy scenes (nuScenes), the first dataset to carry the full autonomous\nvehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree\nfield of view. nuScenes comprises 1000 scenes, each 20s long and fully\nannotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as\nmany annotations and 100x as many images as the pioneering KITTI dataset. We\ndefine novel 3D detection and tracking metrics. We also provide careful dataset\nanalysis as well as baselines for lidar and image based detection and tracking.\nData, development kit and more information are available online.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:19:56 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 10:06:43 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 09:01:24 GMT"}, {"version": "v4", "created": "Wed, 8 Jan 2020 10:30:05 GMT"}, {"version": "v5", "created": "Tue, 5 May 2020 09:13:24 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Caesar", "Holger", ""], ["Bankiti", "Varun", ""], ["Lang", "Alex H.", ""], ["Vora", "Sourabh", ""], ["Liong", "Venice Erin", ""], ["Xu", "Qiang", ""], ["Krishnan", "Anush", ""], ["Pan", "Yu", ""], ["Baldan", "Giancarlo", ""], ["Beijbom", "Oscar", ""]]}, {"id": "1903.11040", "submitter": "Pankaj Roy", "authors": "Pankaj Raj Roy and Guillaume-Alexandre Bilodeau", "title": "Adversarially Learned Abnormal Trajectory Classifier", "comments": "Accepted for the 16th Conference on Computer and Robot Vision (CRV)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of abnormal event detection from trajectory data. In\nthis paper, a new adversarial approach is proposed for building a deep neural\nnetwork binary classifier, trained in an unsupervised fashion, that can\ndistinguish normal from abnormal trajectory-based events without the need for\nsetting manual detection threshold. Inspired by the generative adversarial\nnetwork (GAN) framework, our GAN version is a discriminative one in which the\ndiscriminator is trained to distinguish normal and abnormal trajectory\nreconstruction errors given by a deep autoencoder. With urban traffic videos\nand their associated trajectories, our proposed method gives the best accuracy\nfor abnormal trajectory detection. In addition, our model can easily be\ngeneralized for abnormal trajectory-based event detection and can still yield\nthe best behavioural detection results as demonstrated on the CAVIAR dataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:39:06 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 23:24:57 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Roy", "Pankaj Raj", ""], ["Bilodeau", "Guillaume-Alexandre", ""]]}, {"id": "1903.11048", "submitter": "Kim Andrea Nicoli", "authors": "Kim Nicoli, Pan Kessel, Nils Strodthoff, Wojciech Samek, Klaus-Robert\n  M\\\"uller, Shinichi Nakajima", "title": "Comment on \"Solving Statistical Mechanics Using VANs\": Introducing\n  saVANt - VANs Enhanced by Importance and MCMC Sampling", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this comment on \"Solving Statistical Mechanics Using Variational\nAutoregressive Networks\" by Wu et al., we propose a subtle yet powerful\nmodification of their approach. We show that the inherent sampling error of\ntheir method can be corrected by using neural network-based MCMC or importance\nsampling which leads to asymptotically unbiased estimators for physical\nquantities. This modification is possible due to a singular property of VANs,\nnamely that they provide the exact sample probability. With these\nmodifications, we believe that their method could have a substantially greater\nimpact on various important fields of physics, including strongly-interacting\nfield theories and statistical physics.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:52:44 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Nicoli", "Kim", ""], ["Kessel", "Pan", ""], ["Strodthoff", "Nils", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Nakajima", "Shinichi", ""]]}, {"id": "1903.11101", "submitter": "Jared Dunnmon", "authors": "Jared Dunnmon, Alexander Ratner, Nishith Khandwala, Khaled Saab,\n  Matthew Markert, Hersh Sagreiya, Roger Goldman, Christopher Lee-Messer,\n  Matthew Lungren, Daniel Rubin, Christopher R\\'e", "title": "Cross-Modal Data Programming Enables Rapid Medical Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling training datasets has become a key barrier to building medical\nmachine learning models. One strategy is to generate training labels\nprogrammatically, for example by applying natural language processing pipelines\nto text reports associated with imaging studies. We propose cross-modal data\nprogramming, which generalizes this intuitive strategy in a\ntheoretically-grounded way that enables simpler, clinician-driven input,\nreduces required labeling time, and improves with additional unlabeled data. In\nthis approach, clinicians generate training labels for models defined over a\ntarget modality (e.g. images or time series) by writing rules over an auxiliary\nmodality (e.g. text reports). The resulting technical challenge consists of\nestimating the accuracies and correlations of these rules; we extend a recent\nunsupervised generative modeling technique to handle this cross-modal setting\nin a provably consistent way. Across four applications in radiography, computed\ntomography, and electroencephalography, and using only several hours of\nclinician time, our approach matches or exceeds the efficacy of\nphysician-months of hand-labeling with statistical significance, demonstrating\na fundamentally faster and more flexible way of building machine learning\nmodels in medicine.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 18:12:34 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Dunnmon", "Jared", ""], ["Ratner", "Alexander", ""], ["Khandwala", "Nishith", ""], ["Saab", "Khaled", ""], ["Markert", "Matthew", ""], ["Sagreiya", "Hersh", ""], ["Goldman", "Roger", ""], ["Lee-Messer", "Christopher", ""], ["Lungren", "Matthew", ""], ["Rubin", "Daniel", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1903.11112", "submitter": "Oluwaseyi Feyisetan", "authors": "Oluwaseyi Feyisetan, Thomas Drake, Borja Balle, Tom Diethe", "title": "Privacy-preserving Active Learning on Sensitive Data for User Intent\n  Classification", "comments": "To appear at PAL: Privacy-Enhancing Artificial Intelligence and\n  Language Technologies as part of the AAAI Spring Symposium Series (AAAI-SSS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning holds promise of significantly reducing data annotation costs\nwhile maintaining reasonable model performance. However, it requires sending\ndata to annotators for labeling. This presents a possible privacy leak when the\ntraining set includes sensitive user data. In this paper, we describe an\napproach for carrying out privacy preserving active learning with quantifiable\nguarantees. We evaluate our approach by showing the tradeoff between privacy,\nutility and annotation budget on a binary classification task in a active\nlearning setting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 18:48:43 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Drake", "Thomas", ""], ["Balle", "Borja", ""], ["Diethe", "Tom", ""]]}, {"id": "1903.11114", "submitter": "Felix M. Riese", "authors": "Felix M. Riese and Sina Keller", "title": "SuSi: Supervised Self-Organizing Maps for Regression and Classification\n  in Python", "comments": "An extended and peer-reviewed version exists at\n  doi:10.3390/rs12010007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many research fields, the sizes of the existing datasets vary widely.\nHence, there is a need for machine learning techniques which are well-suited\nfor these different datasets. One possible technique is the self-organizing map\n(SOM), a type of artificial neural network which is, so far, weakly represented\nin the field of machine learning. The SOM's unique characteristic is the\nneighborhood relationship of the output neurons. This relationship improves the\nability of generalization on small datasets. SOMs are mostly applied in\nunsupervised learning and few studies focus on using SOMs as supervised\nlearning approach. Furthermore, no appropriate SOM package is available with\nrespect to machine learning standards and in the widely used programming\nlanguage Python. In this paper, we introduce the freely available Supervised\nSelf-organizing maps (SuSi) Python package which performs supervised regression\nand classification. The implementation of SuSi is described with respect to the\nunderlying mathematics. Then, we present first evaluations of the SOM for\nregression and classification datasets from two different domains of geospatial\nimage analysis. Despite the early stage of its development, the SuSi framework\nperforms well and is characterized by only small performance differences\nbetween the training and the test datasets. A comparison of the SuSi framework\nwith existing Python and R packages demonstrates the importance of the SuSi\nframework. In future work, the SuSi framework will be extended, optimized and\nupgraded e.g. with tools to better understand and visualize the input data as\nwell as the handling of missing and incomplete data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 18:52:45 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 17:09:17 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 13:06:43 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Riese", "Felix M.", ""], ["Keller", "Sina", ""]]}, {"id": "1903.11158", "submitter": "Jo\\~ao Antunes", "authors": "Jo\\~ao Antunes, Alexandre Bernardino, Asim Smailagic, Daniel Siewiorek", "title": "Weighted Multisource Tradaboost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an improved method for transfer learning that takes\ninto account the balance between target and source data. This method builds on\nthe state-of-the-art Multisource Tradaboost, but weighs the importance of each\ndatapoint taking into account the amount of target and source data available. A\ncomparative study is then presented exposing the performance of four transfer\nlearning methods as well as the proposed Weighted Multisource Tradaboost. The\nexperimental results show that the proposed method is able to outperform the\nbase method as the number of target samples increase. These results are\npromising in the sense that source-target ratio weighing may be a path to\nimprove current methods of transfer learning. However, against the asymptotic\nconjecture, all transfer learning methods tested in this work get outperformed\nby a no-transfer SVM for large number on target samples.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 21:22:08 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Antunes", "Jo\u00e3o", ""], ["Bernardino", "Alexandre", ""], ["Smailagic", "Asim", ""], ["Siewiorek", "Daniel", ""]]}, {"id": "1903.11176", "submitter": "Rahul Gupta", "authors": "Taruna Agrawal, Rahul Gupta, Shrikanth Narayanan", "title": "On evaluating CNN representations for low resource medical image\n  classification", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have revolutionized performances in\nseveral machine learning tasks such as image classification, object tracking,\nand keyword spotting. However, given that they contain a large number of\nparameters, their direct applicability into low resource tasks is not\nstraightforward. In this work, we experiment with an application of CNN models\nto gastrointestinal landmark classification with only a few thousands of\ntraining samples through transfer learning. As in a standard transfer learning\napproach, we train CNNs on a large external corpus, followed by representation\nextraction for the medical images. Finally, a classifier is trained on these\nCNN representations. However, given that several variants of CNNs exist, the\nchoice of CNN is not obvious. To address this, we develop a novel metric that\ncan be used to predict test performances, given CNN representations on the\ntraining set. Not only we demonstrate the superiority of the CNN based transfer\nlearning approach against an assembly of knowledge driven features, but the\nproposed metric also carries an 87% correlation with the test set performances\nas obtained using various CNN representations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 22:05:58 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Agrawal", "Taruna", ""], ["Gupta", "Rahul", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1903.11178", "submitter": "Alexander Jung", "authors": "Alexander Jung and Nguyen Tran", "title": "Localized Linear Regression in Networked Data", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2918933", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network Lasso (nLasso) has been proposed recently as an efficient\nlearning algorithm for massive networked data sets (big data over networks). It\nextends the well-known least absolute shrinkage and selection operator (Lasso)\nfrom learning sparse (generalized) linear models to network models. Efficient\nimplementations of the nLasso have been obtained using convex optimization\nmethods lending to scalable message passing protocols. In this paper, we\nanalyze the statistical properties of nLasso when applied to localized linear\nregression problems involving networked data. Our main result is a sufficient\ncondition on the network structure and available label information such that\nnLasso accurately learns a localized linear regression model from a few labeled\ndata points. We also provide an implementation of nLasso for localized linear\nregression by specializing a primaldual method for solving the convex\n(non-smooth) nLasso problem.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 22:17:10 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 08:21:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Jung", "Alexander", ""], ["Tran", "Nguyen", ""]]}, {"id": "1903.11202", "submitter": "Hongwei Dong", "authors": "Hongwei Dong and Liming Yang", "title": "Kernel based regression with robust loss function via iteratively\n  reweighted least squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least squares kernel based methods have been widely used in regression\nproblems due to the simple implementation and good generalization performance.\nAmong them, least squares support vector regression (LS-SVR) and extreme\nlearning machine (ELM) are popular techniques. However, the noise sensitivity\nis a major bottleneck. To address this issue, a generalized loss function,\ncalled $\\ell_s$-loss, is proposed in this paper. With the support of novel loss\nfunction, two kernel based regressors are constructed by replacing the\n$\\ell_2$-loss in LS-SVR and ELM with the proposed $\\ell_s$-loss for better\nnoise robustness. Important properties of $\\ell_s$-loss, including robustness,\nasymmetry and asymptotic approximation behaviors, are verified theoretically.\nMoreover, iteratively reweighted least squares (IRLS) is utilized to optimize\nand interpret the proposed methods from a weighted viewpoint. The convergence\nof the proposal are proved, and detailed analyses of robustness are given.\nExperiments on both artificial and benchmark datasets confirm the validity of\nthe proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 00:40:18 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 03:57:26 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Dong", "Hongwei", ""], ["Yang", "Liming", ""]]}, {"id": "1903.11220", "submitter": "Lifeng Lai", "authors": "Erhan Bayraktar and Lifeng Lai", "title": "On the Adversarial Robustness of Multivariate Robust Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the adversarial robustness of multivariate\n$M$-Estimators. In the considered model, after observing the whole dataset, an\nadversary can modify all data points with the goal of maximizing inference\nerrors. We use adversarial influence function (AIF) to measure the asymptotic\nrate at which the adversary can change the inference result. We first\ncharacterize the adversary's optimal modification strategy and its\ncorresponding AIF. From the defender's perspective, we would like to design an\nestimator that has a small AIF. For the case of joint location and scale\nestimation problem, we characterize the optimal $M$-estimator that has the\nsmallest AIF. We further identify a tradeoff between robustness against\nadversarial modifications and robustness against outliers, and derive the\noptimal $M$-estimator that achieves the best tradeoff.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 01:54:16 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Lai", "Lifeng", ""]]}, {"id": "1903.11232", "submitter": "Tiffany Tang", "authors": "Yulia Baker, Tiffany M. Tang, Genevera I. Allen", "title": "Feature Selection for Data Integration with Mixed Multi-view Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data integration methods that analyze multiple sources of data simultaneously\ncan often provide more holistic insights than can separate inquiries of each\ndata source. Motivated by the advantages of data integration in the era of \"big\ndata\", we investigate feature selection for high-dimensional multi-view data\nwith mixed data types (e.g. continuous, binary, count-valued). This\nheterogeneity of multi-view data poses numerous challenges for existing feature\nselection methods. However, after critically examining these issues through\nempirical and theoretically-guided lenses, we develop a practical solution, the\nBlock Randomized Adaptive Iterative Lasso (B-RAIL), which combines the\nstrengths of the randomized Lasso, adaptive weighting schemes, and stability\nselection. B-RAIL serves as a versatile data integration method for sparse\nregression and graph selection, and we demonstrate the effectiveness of B-RAIL\nthrough extensive simulations and a case study to infer the ovarian cancer gene\nregulatory network. In this case study, B-RAIL successfully identifies\nwell-known biomarkers associated with ovarian cancer and hints at novel\ncandidates for future ovarian cancer research.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 02:56:26 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 16:40:47 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Baker", "Yulia", ""], ["Tang", "Tiffany M.", ""], ["Allen", "Genevera I.", ""]]}, {"id": "1903.11239", "submitter": "Andy Zeng", "authors": "Andy Zeng, Shuran Song, Johnny Lee, Alberto Rodriguez, Thomas\n  Funkhouser", "title": "TossingBot: Learning to Throw Arbitrary Objects with Residual Physics", "comments": "Summary Video: https://youtu.be/f5Zn2Up2RjQ Project webpage:\n  https://tossingbot.cs.princeton.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether a robot arm can learn to pick and throw arbitrary\nobjects into selected boxes quickly and accurately. Throwing has the potential\nto increase the physical reachability and picking speed of a robot arm.\nHowever, precisely throwing arbitrary objects in unstructured settings presents\nmany challenges: from acquiring reliable pre-throw conditions (e.g. initial\npose of object in manipulator) to handling varying object-centric properties\n(e.g. mass distribution, friction, shape) and dynamics (e.g. aerodynamics). In\nthis work, we propose an end-to-end formulation that jointly learns to infer\ncontrol parameters for grasping and throwing motion primitives from visual\nobservations (images of arbitrary objects in a bin) through trial and error.\nWithin this formulation, we investigate the synergies between grasping and\nthrowing (i.e., learning grasps that enable more accurate throws) and between\nsimulation and deep learning (i.e., using deep networks to predict residuals on\ntop of control parameters predicted by a physics simulator). The resulting\nsystem, TossingBot, is able to grasp and throw arbitrary objects into boxes\nlocated outside its maximum reach range at 500+ mean picks per hour (600+\ngrasps per hour with 85% throwing accuracy); and generalizes to new objects and\ntarget locations. Videos are available at https://tossingbot.cs.princeton.edu\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 04:04:28 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 19:16:12 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 15:59:12 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zeng", "Andy", ""], ["Song", "Shuran", ""], ["Lee", "Johnny", ""], ["Rodriguez", "Alberto", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "1903.11240", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Eigenvalue and Generalized Eigenvalue Problems: Tutorial", "comments": "8 pages, Tutorial paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a tutorial for eigenvalue and generalized eigenvalue problems.\nWe first introduce eigenvalue problem, eigen-decomposition (spectral\ndecomposition), and generalized eigenvalue problem. Then, we mention the\noptimization problems which yield to the eigenvalue and generalized eigenvalue\nproblems. We also provide examples from machine learning, including principal\ncomponent analysis, kernel supervised principal component analysis, and Fisher\ndiscriminant analysis, which result in eigenvalue and generalized eigenvalue\nproblems. Finally, we introduce the solutions to both eigenvalue and\ngeneralized eigenvalue problems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 22:22:42 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1903.11253", "submitter": "Qun Liu", "authors": "Qun Liu, Supratik Mukhopadhyay, Yimin Zhu, Ravindra Gudishala, Sanaz\n  Saeidi, Alimire Nabijiang", "title": "Improving Route Choice Models by Incorporating Contextual Factors via\n  Knowledge Distillation", "comments": "Paper was accepted at the 2019 International Joint Conference on\n  Neural Networks (IJCNN 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Route Choice Models predict the route choices of travelers traversing an\nurban area. Most of the route choice models link route characteristics of\nalternative routes to those chosen by the drivers. The models play an important\nrole in prediction of traffic levels on different routes and thus assist in\ndevelopment of efficient traffic management strategies that result in\nminimizing traffic delay and maximizing effective utilization of transport\nsystem. High fidelity route choice models are required to predict traffic\nlevels with higher accuracy. Existing route choice models do not take into\naccount dynamic contextual conditions such as the occurrence of an accident,\nthe socio-cultural and economic background of drivers, other human behaviors,\nthe dynamic personal risk level, etc. As a result, they can only make\npredictions at an aggregate level and for a fixed set of contextual factors.\nFor higher fidelity, it is highly desirable to use a model that captures\nsignificance of subjective or contextual factors in route choice. This paper\npresents a novel approach for developing high-fidelity route choice models with\nincreased predictive power by augmenting existing aggregate level baseline\nmodels with information on drivers' responses to contextual factors obtained\nfrom Stated Choice Experiments carried out in an Immersive Virtual Environment\nthrough the use of knowledge distillation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 05:18:21 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Liu", "Qun", ""], ["Mukhopadhyay", "Supratik", ""], ["Zhu", "Yimin", ""], ["Gudishala", "Ravindra", ""], ["Saeidi", "Sanaz", ""], ["Nabijiang", "Alimire", ""]]}, {"id": "1903.11257", "submitter": "Subutai Ahmad", "authors": "Subutai Ahmad, Luiz Scheinkman", "title": "How Can We Be So Dense? The Benefits of Using Highly Sparse\n  Representations", "comments": "Replaced incorrect Fig 5B", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most artificial networks today rely on dense representations, whereas\nbiological networks rely on sparse representations. In this paper we show how\nsparse representations can be more robust to noise and interference, as long as\nthe underlying dimensionality is sufficiently high. A key intuition that we\ndevelop is that the ratio of the operable volume around a sparse vector divided\nby the volume of the representational space decreases exponentially with\ndimensionality. We then analyze computationally efficient sparse networks\ncontaining both sparse weights and activations. Simulations on MNIST and the\nGoogle Speech Command Dataset show that such networks demonstrate significantly\nimproved robustness and stability compared to dense networks, while maintaining\ncompetitive accuracy. We discuss the potential benefits of sparsity on\naccuracy, noise robustness, hyperparameter tuning, learning speed,\ncomputational efficiency, and power requirements.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 05:43:33 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 17:23:08 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ahmad", "Subutai", ""], ["Scheinkman", "Luiz", ""]]}, {"id": "1903.11329", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Wendelin Boehmer, Shimon Whiteson", "title": "Generalized Off-Policy Actor-Critic", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new objective, the counterfactual objective, unifying existing\nobjectives for off-policy policy gradient algorithms in the continuing\nreinforcement learning (RL) setting. Compared to the commonly used excursion\nobjective, which can be misleading about the performance of the target policy\nwhen deployed, our new objective better predicts such performance. We prove the\nGeneralized Off-Policy Policy Gradient Theorem to compute the policy gradient\nof the counterfactual objective and use an emphatic approach to get an unbiased\nsample from this policy gradient, yielding the Generalized Off-Policy\nActor-Critic (Geoff-PAC) algorithm. We demonstrate the merits of Geoff-PAC over\nexisting algorithms in Mujoco robot simulation tasks, the first empirical\nsuccess of emphatic algorithms in prevailing deep RL benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:17:13 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 10:45:48 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 23:26:22 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 20:55:53 GMT"}, {"version": "v5", "created": "Fri, 13 Sep 2019 15:32:03 GMT"}, {"version": "v6", "created": "Mon, 16 Sep 2019 20:41:03 GMT"}, {"version": "v7", "created": "Mon, 14 Oct 2019 20:22:42 GMT"}, {"version": "v8", "created": "Mon, 28 Oct 2019 09:58:44 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Shangtong", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1903.11331", "submitter": "Alexandra Gessner", "authors": "Alexandra Gessner, Javier Gonzalez, Maren Mahsereci", "title": "Active Multi-Information Source Bayesian Quadrature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian quadrature (BQ) is a sample-efficient probabilistic numerical method\nto solve integrals of expensive-to-evaluate black-box functions, yet so\nfar,active BQ learning schemes focus merely on the integrand itself as\ninformation source, and do not allow for information transfer from cheaper,\nrelated functions. Here, we set the scene for active learning in BQ when\nmultiple related information sources of variable cost (in input and source) are\naccessible. This setting arises for example when evaluating the integrand\nrequires a complex simulation to be run that can be approximated by simulating\nat lower levels of sophistication and at lesser expense. We construct\nmeaningful cost-sensitive multi-source acquisition rates as an extension to\ncommon utility functions from vanilla BQ (VBQ),and discuss pitfalls that arise\nfrom blindly generalizing. Furthermore, we show that the VBQ acquisition policy\nis a corner-case of all considered cost-sensitive acquisition schemes, which\ncollapse onto one single de-generate policy in the case of one source and\nconstant cost. In proof-of-concept experiments we scrutinize the behavior of\nour generalized acquisition functions. On an epidemiological model, we\ndemonstrate that active multi-source BQ (AMS-BQ) allocates budget more\nefficiently than VBQ for learning the integral to a good accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:17:50 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 13:58:58 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 11:37:22 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Gessner", "Alexandra", ""], ["Gonzalez", "Javier", ""], ["Mahsereci", "Maren", ""]]}, {"id": "1903.11334", "submitter": "Yuebing Zhang", "authors": "Yuebing Zhang and Duoqian Miao and Jiaqi Wang", "title": "Hierarchical Attention Generative Adversarial Networks for Cross-domain\n  Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain sentiment classification (CDSC) is an importance task in domain\nadaptation and sentiment classification. Due to the domain discrepancy, a\nsentiment classifier trained on source domain data may not works well on target\ndomain data. In recent years, many researchers have used deep neural network\nmodels for cross-domain sentiment classification task, many of which use\nGradient Reversal Layer (GRL) to design an adversarial network structure to\ntrain a domain-shared sentiment classifier. Different from those methods, we\nproposed Hierarchical Attention Generative Adversarial Networks (HAGAN) which\nalternately trains a generator and a discriminator in order to produce a\ndocument representation which is sentiment-distinguishable but\ndomain-indistinguishable. Besides, the HAGAN model applies Bidirectional Gated\nRecurrent Unit (Bi-GRU) to encode the contextual information of a word and a\nsentence into the document representation. In addition, the HAGAN model use\nhierarchical attention mechanism to optimize the document representation and\nautomatically capture the pivots and non-pivots. The experiments on Amazon\nreview dataset show the effectiveness of HAGAN.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:22:55 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Zhang", "Yuebing", ""], ["Miao", "Duoqian", ""], ["Wang", "Jiaqi", ""]]}, {"id": "1903.11359", "submitter": "Francesco Croce", "authors": "Francesco Croce, Jonas Rauber, Matthias Hein", "title": "Scaling up the randomized gradient-free adversarial attack reveals\n  overestimation of robustness using established attacks", "comments": "Accepted at International Journal of Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are highly non-robust against adversarial\nmanipulation. A significant amount of work has been invested in techniques to\ncompute lower bounds on robustness through formal guarantees and to build\nprovably robust models. However, it is still difficult to get guarantees for\nlarger networks or robustness against larger perturbations. Thus attack\nstrategies are needed to provide tight upper bounds on the actual robustness.\nWe significantly improve the randomized gradient-free attack for ReLU networks\n[9], in particular by scaling it up to large networks. We show that our attack\nachieves similar or significantly smaller robust accuracy than state-of-the-art\nattacks like PGD or the one of Carlini and Wagner, thus revealing an\noverestimation of the robustness by these state-of-the-art methods. Our attack\nis not based on a gradient descent scheme and in this sense gradient-free,\nwhich makes it less sensitive to the choice of hyperparameters as no careful\nselection of the stepsize is required.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 11:41:27 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 17:04:43 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Croce", "Francesco", ""], ["Rauber", "Jonas", ""], ["Hein", "Matthias", ""]]}, {"id": "1903.11373", "submitter": "Dalit Engelhardt", "authors": "Dalit Engelhardt", "title": "Dynamic Control of Stochastic Evolution: A Deep Reinforcement Learning\n  Approach to Adaptively Targeting Emergent Drug Resistance", "comments": null, "journal-ref": "Journal of Machine Learning Research 21(203): 1-30, 2020", "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge in controlling stochastic systems in which low-probability\nevents can set the system on catastrophic trajectories is to develop a robust\nability to respond to such events without significantly compromising the\noptimality of the baseline control policy. This paper presents CelluDose, a\nstochastic simulation-trained deep reinforcement learning adaptive feedback\ncontrol prototype for automated precision drug dosing targeting stochastic and\nheterogeneous cell proliferation. Drug resistance can emerge from random and\nvariable mutations in targeted cell populations; in the absence of an\nappropriate dosing policy, emergent resistant subpopulations can proliferate\nand lead to treatment failure. Dynamic feedback dosage control holds promise in\ncombatting this phenomenon, but the application of traditional control\napproaches to such systems is fraught with challenges due to the complexity of\ncell dynamics, uncertainty in model parameters, and the need in medical\napplications for a robust controller that can be trusted to properly handle\nunexpected outcomes. Here, training on a sample biological scenario identified\nsingle-drug and combination therapy policies that exhibit a 100% success rate\nat suppressing cell proliferation and responding to diverse system\nperturbations while establishing low-dose no-event baselines. These policies\nwere found to be highly robust to variations in a key model parameter subject\nto significant uncertainty and unpredictable dynamical changes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 12:25:48 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 22:21:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Engelhardt", "Dalit", ""]]}, {"id": "1903.11385", "submitter": "Shuai Ma", "authors": "Shuai Ma, Jiahui Dai, Songtao Lu, Hang Li, Han Zhang, Chun Du, and\n  Shiyin Li", "title": "Signal Demodulation with Machine Learning Methods for Physical Layer\n  Visible Light Communications: Prototype Platform, Open Dataset and Algorithms", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2903375", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the design and implementation of machine\nlearning (ML) based demodulation methods in the physical layer of visible light\ncommunication (VLC) systems. We build a flexible hardware prototype of an\nend-to-end VLC system, from which the received signals are collected as the\nreal data. The dataset is available online, which contains eight types of\nmodulated signals. Then, we propose three ML demodulators based on\nconvolutional neural network (CNN), deep belief network (DBN), and adaptive\nboosting (AdaBoost), respectively. Specifically, the CNN based demodulator\nconverts the modulated signals to images and recognizes the signals by the\nimage classification. The proposed DBN based demodulator contains three\nrestricted Boltzmann machines (RBMs) to extract the modulation features. The\nAdaBoost method includes a strong classifier that is constructed by the weak\nclassifiers with the k-nearest neighbor (KNN) algorithm. These three\ndemodulators are trained and tested by our online open dataset. Experimental\nresults show that the demodulation accuracy of the three data-driven\ndemodulators drops as the transmission distance increases. A higher modulation\norder negatively influences the accuracy for a given transmission distance.\nAmong the three ML methods, the AdaBoost modulator achieves the best\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 11:38:10 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Ma", "Shuai", ""], ["Dai", "Jiahui", ""], ["Lu", "Songtao", ""], ["Li", "Hang", ""], ["Zhang", "Han", ""], ["Du", "Chun", ""], ["Li", "Shiyin", ""]]}, {"id": "1903.11406", "submitter": "Hung Nghiep Tran", "authors": "Hung Nghiep Tran, Atsuhiro Takasu", "title": "Analyzing Knowledge Graph Embedding Methods from a Multi-Embedding\n  Interaction Perspective", "comments": "DSI4 at EDBT/ICDT 2019. Source code is available on github at\n  https://github.com/tranhungnghiep/AnalyzingKGEmbeddings", "journal-ref": "Data Science for Industry 4.0 at EDBT/ICDT 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graph is a popular format for representing knowledge, with many\napplications to semantic search engines, question-answering systems, and\nrecommender systems. Real-world knowledge graphs are usually incomplete, so\nknowledge graph embedding methods, such as Canonical decomposition/Parallel\nfactorization (CP), DistMult, and ComplEx, have been proposed to address this\nissue. These methods represent entities and relations as embedding vectors in\nsemantic space and predict the links between them. The embedding vectors\nthemselves contain rich semantic information and can be used in other\napplications such as data analysis. However, mechanisms in these models and the\nembedding vectors themselves vary greatly, making it difficult to understand\nand compare them. Given this lack of understanding, we risk using them\nineffectively or incorrectly, particularly for complicated models, such as CP,\nwith two role-based embedding vectors, or the state-of-the-art ComplEx model,\nwith complex-valued embedding vectors. In this paper, we propose a\nmulti-embedding interaction mechanism as a new approach to uniting and\ngeneralizing these models. We derive them theoretically via this mechanism and\nprovide empirical analyses and comparisons between them. We also propose a new\nmulti-embedding model based on quaternion algebra and show that it achieves\npromising results using popular benchmarks. Source code is available on github\nat https://github.com/tranhungnghiep/AnalyzingKGEmbeddings\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:09:16 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 04:34:16 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 19:58:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Tran", "Hung Nghiep", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "1903.11420", "submitter": "Alicja Gosiewska", "authors": "Alicja Gosiewska and Przemyslaw Biecek", "title": "Do Not Trust Additive Explanations", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI)has received a great deal of\nattention recently. Explainability is being presented as a remedy for the\ndistrust of complex and opaque models. Model agnostic methods such as LIME,\nSHAP, or Break Down promise instance-level interpretability for any complex\nmachine learning model. But how faithful are these additive explanations? Can\nwe rely on additive explanations for non-additive models?\n  In this paper, we (1) examine the behavior of the most popular instance-level\nexplanations under the presence of interactions, (2) introduce a new method\nthat detects interactions for instance-level explanations, (3) perform a large\nscale benchmark to see how frequently additive explanations may be misleading.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:37:30 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 06:20:49 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 15:19:18 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1903.11431", "submitter": "Bihan Wen Dr", "authors": "Bihan Wen, Saiprasad Ravishankar, Luke Pfister and Yoram Bresler", "title": "Transform Learning for Magnetic Resonance Image Reconstruction: From\n  Model-based Learning to Building Neural Networks", "comments": "Accepted to IEEE Signal Processing Magazine, Special Issue on\n  Computational MRI: Compressed Sensing and Beyond", "journal-ref": null, "doi": "10.1109/MSP.2019.2951469", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) is widely used in clinical practice, but it\nhas been traditionally limited by its slow data acquisition. Recent advances in\ncompressed sensing (CS) techniques for MRI reduce acquisition time while\nmaintaining high image quality. Whereas classical CS assumes the images are\nsparse in known analytical dictionaries or transform domains, methods using\nlearned image models for reconstruction have become popular. The model could be\npre-learned from datasets, or learned simultaneously with the reconstruction,\ni.e., blind CS (BCS). Besides the well-known synthesis dictionary model, recent\nadvances in transform learning (TL) provide an efficient alternative framework\nfor sparse modeling in MRI. TL-based methods enjoy numerous advantages\nincluding exact sparse coding, transform update, and clustering solutions,\ncheap computation, and convergence guarantees, and provide high-quality results\nin MRI compared to popular competing methods. This paper provides a review of\nsome recent works in MRI reconstruction from limited data, with focus on the\nrecent TL-based methods. A unified framework for incorporating various TL-based\nmodels is presented. We discuss the connections between transform learning and\nconvolutional or filter bank models and corresponding multi-layer extensions,\nwith connections to deep learning. Finally, we discuss recent trends in MRI,\nopen problems, and future directions for the field.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 03:13:18 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 13:26:01 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wen", "Bihan", ""], ["Ravishankar", "Saiprasad", ""], ["Pfister", "Luke", ""], ["Bresler", "Yoram", ""]]}, {"id": "1903.11436", "submitter": "Alexey Zaytsev", "authors": "Evgenya Romanenkova, Alexey Zaytsev, Nikita Klyuchnikov, Arseniy\n  Gruzdev, Ksenia Antipova, Leyla Ismailova, Evgeny Burnaev, Artyom Semenikhin,\n  Vitaliy Koryabkin, Igor Simon, Dmitry Koroteev", "title": "Real-time data-driven detection of the rock type alteration during a\n  directional drilling", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2019.2959845", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the directional drilling, a bit may sometimes go to a nonproductive\nrock layer due to the gap about 20m between the bit and high-fidelity rock type\nsensors. The only way to detect the lithotype changes in time is the usage of\nMeasurements While Drilling (MWD) data. However, there are no general\nmathematical modeling approaches that both well reconstruct the rock type based\non MWD data and correspond to specifics of the oil and gas industry. In this\narticle, we present a data-driven procedure that utilizes MWD data for quick\ndetection of changes in rock type. We propose the approach that combines\ntraditional machine learning based on the solution of the rock type\nclassification problem with change detection procedures rarely used before in\nthe Oil\\&Gas industry. The data come from a newly developed oilfield in the\nnorth of western Siberia. The results suggest that we can detect a significant\npart of changes in rock type reducing the change detection delay from $20$ to\n$1.8$ meters and the number of false-positive alarms from $43$ to $6$ per well.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:04:32 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 09:59:39 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Romanenkova", "Evgenya", ""], ["Zaytsev", "Alexey", ""], ["Klyuchnikov", "Nikita", ""], ["Gruzdev", "Arseniy", ""], ["Antipova", "Ksenia", ""], ["Ismailova", "Leyla", ""], ["Burnaev", "Evgeny", ""], ["Semenikhin", "Artyom", ""], ["Koryabkin", "Vitaliy", ""], ["Simon", "Igor", ""], ["Koroteev", "Dmitry", ""]]}, {"id": "1903.11451", "submitter": "Nino Antulov-Fantulin", "authors": "Johannes Beck, Roberta Huang, David Lindner, Tian Guo, Ce Zhang, Dirk\n  Helbing, Nino Antulov-Fantulin", "title": "Sensing Social Media Signals for Cryptocurrency News", "comments": "full version of the paper, that is accepted at ACM WWW '19\n  Conference, MSM'19 Workshop", "journal-ref": null, "doi": "10.1145/3308560.3316706", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to track and monitor relevant and important news in real-time is\nof crucial interest in multiple industrial sectors. In this work, we focus on\nthe set of cryptocurrency news, which recently became of emerging interest to\nthe general and financial audience. In order to track relevant news in\nreal-time, we (i) match news from the web with tweets from social media, (ii)\ntrack their intraday tweet activity and (iii) explore different machine\nlearning models for predicting the number of the article mentions on Twitter\nwithin the first 24 hours after its publication. We compare several machine\nlearning models, such as linear extrapolation, linear and random forest\nautoregressive models, and a sequence-to-sequence neural network. We find that\nthe random forest autoregressive model behaves comparably to more complex\nmodels in the majority of tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:27:22 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Beck", "Johannes", ""], ["Huang", "Roberta", ""], ["Lindner", "David", ""], ["Guo", "Tian", ""], ["Zhang", "Ce", ""], ["Helbing", "Dirk", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "1903.11454", "submitter": "Milena \\v{C}uki\\'c Dr", "authors": "Milena Cukic Radenkovic", "title": "Machine learning approaches in Detecting the Depression from\n  Resting-state Electroencephalogram (EEG): A Review Study", "comments": "31 pages, 4 Figures. arXiv admin note: text overlap with\n  arXiv:1803.05985 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aimed at reviewing several different approaches present\ntoday in the search for more accurate diagnostic and treatment management in\nmental healthcare. Our focus is on mood disorders, and in particular on the\nmajor depressive disorder (MDD). We are reviewing and discussing findings based\non neuroimaging studies (MRI and fMRI) first to get the impression of the body\nof knowledge about the anatomical and functional differences in depression.\nThen, we are focusing on less expensive data-driven approach, applicable for\neveryday clinical practice, in particular, those based on\nelectroencephalographic (EEG) recordings. Among those studies utilizing EEG, we\nare discussing a group of applications used for detecting of depression based\non the resting state EEG (detection studies) and interventional studies (using\nstimulus in their protocols or aiming to predict the outcome of therapy). We\nconclude with a discussion and review of guidelines to improve the reliability\nof developed models that could serve improvement of diagnostic of depression in\npsychiatry.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:45:43 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Radenkovic", "Milena Cukic", ""]]}, {"id": "1903.11460", "submitter": "Chengjing Wang", "authors": "Peipei Tang, Chengjing Wang, Defeng Sun, and Kim-Chuan Toh", "title": "A sparse semismooth Newton based proximal majorization-minimization\n  algorithm for nonconvex square-root-loss regression problems", "comments": "34 pages, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider high-dimensional nonconvex square-root-loss\nregression problems and introduce a proximal majorization-minimization (PMM)\nalgorithm for these problems. Our key idea for making the proposed PMM to be\nefficient is to develop a sparse semismooth Newton method to solve the\ncorresponding subproblems. By using the Kurdyka-{\\L}ojasiewicz property\nexhibited in the underlining problems, we prove that the PMM algorithm\nconverges to a d-stationary point. We also analyze the oracle property of the\ninitial subproblem used in our algorithm. Extensive numerical experiments are\npresented to demonstrate the high efficiency of the proposed PMM algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:51:35 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 12:03:39 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 05:59:27 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Tang", "Peipei", ""], ["Wang", "Chengjing", ""], ["Sun", "Defeng", ""], ["Toh", "Kim-Chuan", ""]]}, {"id": "1903.11482", "submitter": "Ingo Steinwart", "authors": "Ingo Steinwart", "title": "A Sober Look at Neural Network Initializations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initializing the weights and the biases is a key part of the training process\nof a neural network. Unlike the subsequent optimization phase, however, the\ninitialization phase has gained only limited attention in the literature. In\nthis paper we discuss some consequences of commonly used initialization\nstrategies for vanilla DNNs with ReLU activations. Based on these insights we\nthen develop an alternative initialization strategy. Finally, we present some\nlarge scale experiments assessing the quality of the new initialization\nstrategy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 15:22:37 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 18:04:14 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Steinwart", "Ingo", ""]]}, {"id": "1903.11483", "submitter": "Erik Derner", "authors": "Erik Derner, Ji\\v{r}\\'i Kubal\\'ik, Nicola Ancona and Robert\n  Babu\\v{s}ka", "title": "Constructing Parsimonious Analytic Models for Dynamic Systems via\n  Symbolic Regression", "comments": null, "journal-ref": "Applied Soft Computing, Volume 94, September 2020, 106432", "doi": "10.1016/j.asoc.2020.106432", "report-no": null, "categories": "cs.LG cs.NE cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing mathematical models of dynamic systems is central to many\ndisciplines of engineering and science. Models facilitate simulations, analysis\nof the system's behavior, decision making and design of automatic control\nalgorithms. Even inherently model-free control techniques such as reinforcement\nlearning (RL) have been shown to benefit from the use of models, typically\nlearned online. Any model construction method must address the tradeoff between\nthe accuracy of the model and its complexity, which is difficult to strike. In\nthis paper, we propose to employ symbolic regression (SR) to construct\nparsimonious process models described by analytic equations. We have equipped\nour method with two different state-of-the-art SR algorithms which\nautomatically search for equations that fit the measured data: Single Node\nGenetic Programming (SNGP) and Multi-Gene Genetic Programming (MGGP). In\naddition to the standard problem formulation in the state-space domain, we show\nhow the method can also be applied to input-output models of the NARX\n(nonlinear autoregressive with exogenous input) type. We present the approach\non three simulated examples with up to 14-dimensional state space: an inverted\npendulum, a mobile robot, and a bipedal walking robot. A comparison with deep\nneural networks and local linear regression shows that SR in most cases\noutperforms these commonly used alternative methods. We demonstrate on a real\npendulum system that the analytic model found enables a RL controller to\nsuccessfully perform the swing-up task, based on a model constructed from only\n100 data samples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 15:22:38 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 09:17:27 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Derner", "Erik", ""], ["Kubal\u00edk", "Ji\u0159\u00ed", ""], ["Ancona", "Nicola", ""], ["Babu\u0161ka", "Robert", ""]]}, {"id": "1903.11524", "submitter": "Dmytro Korenkevych", "authors": "Dmytro Korenkevych, A. Rupam Mahmood, Gautham Vasan, James Bergstra", "title": "Autoregressive Policies for Continuous Control Deep Reinforcement\n  Learning", "comments": "Submitted to 28th International Joint Conference on Artificial\n  Intelligence (IJCAI 2019). Video: https://youtu.be/NCpyXBNqNmw Code:\n  https://github.com/dkorenkevych/arp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms rely on exploration to discover new\nbehaviors, which is typically achieved by following a stochastic policy. In\ncontinuous control tasks, policies with a Gaussian distribution have been\nwidely adopted. Gaussian exploration however does not result in smooth\ntrajectories that generally correspond to safe and rewarding behaviors in\npractical tasks. In addition, Gaussian policies do not result in an effective\nexploration of an environment and become increasingly inefficient as the action\nrate increases. This contributes to a low sample efficiency often observed in\nlearning continuous control tasks. We introduce a family of stationary\nautoregressive (AR) stochastic processes to facilitate exploration in\ncontinuous control domains. We show that proposed processes possess two\ndesirable features: subsequent process observations are temporally coherent\nwith continuously adjustable degree of coherence, and the process stationary\ndistribution is standard normal. We derive an autoregressive policy (ARP) that\nimplements such processes maintaining the standard agent-environment interface.\nWe show how ARPs can be easily used with the existing off-the-shelf learning\nalgorithms. Empirically we demonstrate that using ARPs results in improved\nexploration and sample efficiency in both simulated and real world domains,\nand, furthermore, provides smooth exploration trajectories that enable safe\noperation of robotic hardware.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 16:22:48 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Korenkevych", "Dmytro", ""], ["Mahmood", "A. Rupam", ""], ["Vasan", "Gautham", ""], ["Bergstra", "James", ""]]}, {"id": "1903.11551", "submitter": "Mark Stamp", "authors": "Niket Bhodia, Pratikkumar Prajapati, Fabio Di Troia, Mark Stamp", "title": "Transfer Learning for Image-Based Malware Classification", "comments": "3rd International Workshop on Formal Methods for Security Engineering\n  (ForSE 2019), in conjunction with the 5th International Conference on\n  Information Systems Security and Privacy (ICISSP 2019), Prague, Czech\n  Republic, February 23-25, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of malware detection and\nclassification based on image analysis. We convert executable files to images\nand apply image recognition using deep learning (DL) models. To train these\nmodels, we employ transfer learning based on existing DL models that have been\npre-trained on massive image datasets. We carry out various experiments with\nthis technique and compare its performance to that of an extremely simple\nmachine learning technique, namely, k-nearest neighbors (\\kNN). For our k-NN\nexperiments, we use features extracted directly from executables, rather than\nimage analysis. While our image-based DL technique performs well in the\nexperiments, surprisingly, it is outperformed by k-NN. We show that DL models\nare better able to generalize the data, in the sense that they outperform k-NN\nin simulated zero-day experiments.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 02:15:53 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Bhodia", "Niket", ""], ["Prajapati", "Pratikkumar", ""], ["Di Troia", "Fabio", ""], ["Stamp", "Mark", ""]]}, {"id": "1903.11576", "submitter": "Shiqian Ma", "authors": "Shixiang Chen, Shiqian Ma, Lingzhou Xue, Hui Zou", "title": "An Alternating Manifold Proximal Gradient Method for Sparse PCA and\n  Sparse CCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse principal component analysis (PCA) and sparse canonical correlation\nanalysis (CCA) are two essential techniques from high-dimensional statistics\nand machine learning for analyzing large-scale data. Both problems can be\nformulated as an optimization problem with nonsmooth objective and nonconvex\nconstraints. Since non-smoothness and nonconvexity bring numerical\ndifficulties, most algorithms suggested in the literature either solve some\nrelaxations or are heuristic and lack convergence guarantees. In this paper, we\npropose a new alternating manifold proximal gradient method to solve these two\nhigh-dimensional problems and provide a unified convergence analysis. Numerical\nexperiment results are reported to demonstrate the advantages of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 17:44:00 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Chen", "Shixiang", ""], ["Ma", "Shiqian", ""], ["Xue", "Lingzhou", ""], ["Zou", "Hui", ""]]}, {"id": "1903.11626", "submitter": "Junghoon Seo", "authors": "Beomsu Kim, Junghoon Seo, Taegyun Jeon", "title": "Bridging Adversarial Robustness and Gradient Interpretability", "comments": "Accepted at the 2019 ICLR Workshop on Safe Machine Learning:\n  Specification, Robustness, and Assurance (SafeML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a training scheme designed to counter adversarial\nattacks by augmenting the training dataset with adversarial examples.\nSurprisingly, several studies have observed that loss gradients from\nadversarially trained DNNs are visually more interpretable than those from\nstandard DNNs. Although this phenomenon is interesting, there are only few\nworks that have offered an explanation. In this paper, we attempted to bridge\nthis gap between adversarial robustness and gradient interpretability. To this\nend, we identified that loss gradients from adversarially trained DNNs align\nbetter with human perception because adversarial training restricts gradients\ncloser to the image manifold. We then demonstrated that adversarial training\ncauses loss gradients to be quantitatively meaningful. Finally, we showed that\nunder the adversarial training framework, there exists an empirical trade-off\nbetween test accuracy and loss gradient interpretability and proposed two\npotential approaches to resolving this trade-off.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 18:06:06 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 07:35:00 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Kim", "Beomsu", ""], ["Seo", "Junghoon", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1903.11673", "submitter": "Ozan Ozdenizci", "authors": "Ozan Ozdenizci, Ye Wang, Toshiaki Koike-Akino, Deniz Erdogmus", "title": "Adversarial Deep Learning in EEG Biometrics", "comments": "Accepted for publication by IEEE Signal Processing Letters", "journal-ref": "IEEE Signal Processing Letters, 2019", "doi": "10.1109/LSP.2019.2906826", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods for person identification based on\nelectroencephalographic (EEG) brain activity encounters the problem of\nexploiting the temporally correlated structures or recording session specific\nvariability within EEG. Furthermore, recent methods have mostly trained and\nevaluated based on single session EEG data. We address this problem from an\ninvariant representation learning perspective. We propose an adversarial\ninference approach to extend such deep learning models to learn\nsession-invariant person-discriminative representations that can provide\nrobustness in terms of longitudinal usability. Using adversarial learning\nwithin a deep convolutional network, we empirically assess and show\nimprovements with our approach based on longitudinally collected EEG data for\nperson identification from half-second EEG epochs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 19:50:24 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ozdenizci", "Ozan", ""], ["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "1903.11680", "submitter": "Samet Oymak", "authors": "Mingchen Li, Mahdi Soltanolkotabi, Samet Oymak", "title": "Gradient Descent with Early Stopping is Provably Robust to Label Noise\n  for Overparameterized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are typically trained in an over-parameterized regime\nwhere the parameters of the model far exceed the size of the training data.\nSuch neural networks in principle have the capacity to (over)fit any set of\nlabels including pure noise. Despite this, somewhat paradoxically, neural\nnetwork models trained via first-order methods continue to predict well on yet\nunseen test data. This paper takes a step towards demystifying this phenomena.\nUnder a rich dataset model, we show that gradient descent is provably robust to\nnoise/corruption on a constant fraction of the labels despite\noverparameterization. In particular, we prove that: (i) In the first few\niterations where the updates are still in the vicinity of the initialization\ngradient descent only fits to the correct labels essentially ignoring the noisy\nlabels. (ii) to start to overfit to the noisy labels network must stray rather\nfar from from the initialization which can only occur after many more\niterations. Together, these results show that gradient descent with early\nstopping is provably robust to label noise and shed light on the empirical\nrobustness of deep networks as well as commonly adopted heuristics to prevent\noverfitting.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:00:15 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 19:57:05 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 23:48:05 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Li", "Mingchen", ""], ["Soltanolkotabi", "Mahdi", ""], ["Oymak", "Samet", ""]]}, {"id": "1903.11683", "submitter": "Vasileios Tzoumas", "authors": "Vasileios Tzoumas, Pasquale Antonante, Luca Carlone", "title": "Outlier-Robust Spatial Perception: Hardness, General-Purpose Algorithms,\n  and Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.RO cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial perception is the backbone of many robotics applications, and spans a\nbroad range of research problems, including localization and mapping, point\ncloud alignment, and relative pose estimation from camera images. Robust\nspatial perception is jeopardized by the presence of incorrect data\nassociation, and in general, outliers. Although techniques to handle outliers\ndo exist, they can fail in unpredictable manners (e.g., RANSAC, robust\nestimators), or can have exponential runtime (e.g., branch-and-bound). In this\npaper, we advance the state of the art in outlier rejection by making three\ncontributions. First, we show that even a simple linear instance of outlier\nrejection is inapproximable: in the worst-case one cannot design a\nquasi-polynomial time algorithm that computes an approximate solution\nefficiently. Our second contribution is to provide the first per-instance\nsub-optimality bounds to assess the approximation quality of a given outlier\nrejection outcome. Our third contribution is to propose a simple\ngeneral-purpose algorithm, named adaptive trimming, to remove outliers. Our\nalgorithm leverages recently-proposed global solvers that are able to solve\noutlier-free problems, and iteratively removes measurements with large errors.\nWe demonstrate the proposed algorithm on three spatial perception problems: 3D\nregistration, two-view geometry, and SLAM. The results show that our algorithm\noutperforms several state-of-the-art methods across applications while being a\ngeneral-purpose method.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:12:37 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 19:46:50 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Tzoumas", "Vasileios", ""], ["Antonante", "Pasquale", ""], ["Carlone", "Luca", ""]]}, {"id": "1903.11696", "submitter": "Carel F.W. Peeters", "authors": "Carel F.W. Peeters, Caroline \\\"Ubelh\\\"or, Steven W. Mes, Roland\n  Martens, Thomas Koopman, Pim de Graaf, Floris H.P. van Velden, Ronald\n  Boellaard, Jonas A. Castelijns, Dennis E. te Beest, Martijn W. Heymans, Mark\n  A. van de Wiel", "title": "Stable prediction with radiomics data", "comments": "52 pages: 14 pages Main Text and 38 pages of Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Radiomics refers to the high-throughput mining of quantitative\nfeatures from radiographic images. It is a promising field in that it may\nprovide a non-invasive solution for screening and classification. Standard\nmachine learning classification and feature selection techniques, however, tend\nto display inferior performance in terms of (the stability of) predictive\nperformance. This is due to the heavy multicollinearity present in radiomic\ndata. We set out to provide an easy-to-use approach that deals with this\nproblem.\n  Results: We developed a four-step approach that projects the original\nhigh-dimensional feature space onto a lower-dimensional latent-feature space,\nwhile retaining most of the covariation in the data. It consists of (i)\npenalized maximum likelihood estimation of a redundancy filtered correlation\nmatrix. The resulting matrix (ii) is the input for a maximum likelihood factor\nanalysis procedure. This two-stage maximum-likelihood approach can be used to\n(iii) produce a compact set of stable features that (iv) can be directly used\nin any (regression-based) classifier or predictor. It outperforms other\nclassification (and feature selection) techniques in both external and internal\nvalidation settings regarding survival in squamous cell cancers.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:45:58 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Peeters", "Carel F. W.", ""], ["\u00dcbelh\u00f6r", "Caroline", ""], ["Mes", "Steven W.", ""], ["Martens", "Roland", ""], ["Koopman", "Thomas", ""], ["de Graaf", "Pim", ""], ["van Velden", "Floris H. P.", ""], ["Boellaard", "Ronald", ""], ["Castelijns", "Jonas A.", ""], ["Beest", "Dennis E. te", ""], ["Heymans", "Martijn W.", ""], ["van de Wiel", "Mark A.", ""]]}, {"id": "1903.11703", "submitter": "Minh Tu Hoang", "authors": "Minh Tu Hoang, Brosnan Yuen, Xiaodai Dong, Tao Lu, Robert Westendorp,\n  and Kishore Reddy", "title": "Recurrent Neural Networks For Accurate RSSI Indoor Localization", "comments": "Received signal strength indicator (RSSI), WiFi indoor localization,\n  recurrent neuron network (RNN), long shortterm memory (LSTM),\n  fingerprint-based localization", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes recurrent neuron networks (RNNs) for a fingerprinting\nindoor localization using WiFi. Instead of locating user's position one at a\ntime as in the cases of conventional algorithms, our RNN solution aims at\ntrajectory positioning and takes into account the relation among the received\nsignal strength indicator (RSSI) measurements in a trajectory. Furthermore, a\nweighted average filter is proposed for both input RSSI data and sequential\noutput locations to enhance the accuracy among the temporal fluctuations of\nRSSI. The results using different types of RNN including vanilla RNN, long\nshort-term memory (LSTM), gated recurrent unit (GRU) and bidirectional LSTM\n(BiLSTM) are presented. On-site experiments demonstrate that the proposed\nstructure achieves an average localization error of $0.75$ m with $80\\%$ of the\nerrors under $1$ m, which outperforms the conventional KNN algorithms and\nprobabilistic algorithms by approximately $30\\%$ under the same test\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 21:14:12 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 19:08:32 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Hoang", "Minh Tu", ""], ["Yuen", "Brosnan", ""], ["Dong", "Xiaodai", ""], ["Lu", "Tao", ""], ["Westendorp", "Robert", ""], ["Reddy", "Kishore", ""]]}, {"id": "1903.11719", "submitter": "Aria Khademi", "authors": "Aria Khademi, Sanghack Lee, David Foley, Vasant Honavar", "title": "Fairness in Algorithmic Decision Making: An Excursion Through the Lens\n  of Causality", "comments": "7 pages, 2 figures, 2 tables.To appear in Proceedings of the\n  International Conference on World Wide Web (WWW), 2019", "journal-ref": null, "doi": "10.1145/3308558.3313559", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As virtually all aspects of our lives are increasingly impacted by\nalgorithmic decision making systems, it is incumbent upon us as a society to\nensure such systems do not become instruments of unfair discrimination on the\nbasis of gender, race, ethnicity, religion, etc. We consider the problem of\ndetermining whether the decisions made by such systems are discriminatory,\nthrough the lens of causal models. We introduce two definitions of group\nfairness grounded in causality: fair on average causal effect (FACE), and fair\non average causal effect on the treated (FACT). We use the Rubin-Neyman\npotential outcomes framework for the analysis of cause-effect relationships to\nrobustly estimate FACE and FACT. We demonstrate the effectiveness of our\nproposed approach on synthetic data. Our analyses of two real-world data sets,\nthe Adult income data set from the UCI repository (with gender as the protected\nattribute), and the NYC Stop and Frisk data set (with race as the protected\nattribute), show that the evidence of discrimination obtained by FACE and FACT,\nor lack thereof, is often in agreement with the findings from other studies. We\nfurther show that FACT, being somewhat more nuanced compared to FACE, can yield\nfindings of discrimination that differ from those obtained using FACE.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 22:27:22 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Khademi", "Aria", ""], ["Lee", "Sanghack", ""], ["Foley", "David", ""], ["Honavar", "Vasant", ""]]}, {"id": "1903.11774", "submitter": "Quan Vuong", "authors": "Quan Vuong, Sharad Vikram, Hao Su, Sicun Gao, Henrik I. Christensen", "title": "How to pick the domain randomization parameters for sim-to-real transfer\n  of reinforcement learning policies?", "comments": "2-page extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning (RL) algorithms have demonstrated remarkable\nsuccess in learning complicated behaviors from minimally processed input.\nHowever, most of this success is limited to simulation. While there are\npromising successes in applying RL algorithms directly on real systems, their\nperformance on more complex systems remains bottle-necked by the relative data\ninefficiency of RL algorithms. Domain randomization is a promising direction of\nresearch that has demonstrated impressive results using RL algorithms to\ncontrol real robots. At a high level, domain randomization works by training a\npolicy on a distribution of environmental conditions in simulation. If the\nenvironments are diverse enough, then the policy trained on this distribution\nwill plausibly generalize to the real world. A human-specified design choice in\ndomain randomization is the form and parameters of the distribution of\nsimulated environments. It is unclear how to the best pick the form and\nparameters of this distribution and prior work uses hand-tuned distributions.\nThis extended abstract demonstrates that the choice of the distribution plays a\nmajor role in the performance of the trained policies in the real world and\nthat the parameter of this distribution can be optimized to maximize the\nperformance of the trained policies in the real world\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:24:44 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Vuong", "Quan", ""], ["Vikram", "Sharad", ""], ["Su", "Hao", ""], ["Gao", "Sicun", ""], ["Christensen", "Henrik I.", ""]]}, {"id": "1903.11775", "submitter": "Hamid Tizhoosh", "authors": "Sara Ross-Howe and H.R. Tizhoosh", "title": "Atrial Fibrillation Detection Using Deep Features and Convolutional\n  Networks", "comments": "Accepted for publication in the IEEE-EMBS International Conference on\n  Biomedical and Health Informatics (BHI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atrial fibrillation is a cardiac arrhythmia that affects an estimated 33.5\nmillion people globally and is the potential cause of 1 in 3 strokes in people\nover the age of 60. Detection and diagnosis of atrial fibrillation (AFIB) is\ndone noninvasively in the clinical environment through the evaluation of\nelectrocardiograms (ECGs). Early research into automated methods for the\ndetection of AFIB in ECG signals focused on traditional bio-medical signal\nanalysis to extract important features for use in statistical classification\nmodels. Artificial intelligence models have more recently been used that employ\nconvolutional and/or recurrent network architectures. In this work, significant\ntime and frequency domain characteristics of the ECG signal are extracted by\napplying the short-time Fourier trans-form and then visually representing the\ninformation in a spectrogram. Two different classification approaches were\ninvestigated that utilized deep features in the spectrograms construct-ed from\nECG segments. The first approach used a pretrained DenseNet model to extract\nfeatures that were then classified using Support Vector Machines, and the\nsecond approach used the spectrograms as direct input into a convolutional\nnetwork. Both approaches were evaluated against the MIT-BIH AFIB dataset, where\nthe convolutional network approach achieved a classification accuracy of\n93.16%. While these results do not surpass established automated atrial\nfibrillation detection methods, they are promising and warrant further\ninvestigation given they did not require any noise prefiltering, hand-crafted\nfeatures, nor a reliance on beat detection.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:30:25 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ross-Howe", "Sara", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "1903.11780", "submitter": "Sherjil Ozair", "authors": "Sherjil Ozair, Corey Lynch, Yoshua Bengio, Aaron van den Oord, Sergey\n  Levine, Pierre Sermanet", "title": "Wasserstein Dependency Measure for Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual information maximization has emerged as a powerful learning objective\nfor unsupervised representation learning obtaining state-of-the-art performance\nin applications such as object recognition, speech recognition, and\nreinforcement learning. However, such approaches are fundamentally limited\nsince a tight lower bound of mutual information requires sample size\nexponential in the mutual information. This limits the applicability of these\napproaches for prediction tasks with high mutual information, such as in video\nunderstanding or reinforcement learning. In these settings, such techniques are\nprone to overfit, both in theory and in practice, and capture only a few of the\nrelevant factors of variation. This leads to incomplete representations that\nare not optimal for downstream tasks. In this work, we empirically demonstrate\nthat mutual information-based representation learning approaches do fail to\nlearn complete representations on a number of designed and real-world tasks. To\nmitigate these problems we introduce the Wasserstein dependency measure, which\nlearns more complete representations by using the Wasserstein distance instead\nof the KL divergence in the mutual information estimator. We show that a\npractical approximation to this theoretically motivated solution, constructed\nusing Lipschitz constraint techniques from the GAN literature, achieves\nsubstantially improved results on tasks where incomplete representations are a\nmajor challenge.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:51:17 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ozair", "Sherjil", ""], ["Lynch", "Corey", ""], ["Bengio", "Yoshua", ""], ["Oord", "Aaron van den", ""], ["Levine", "Sergey", ""], ["Sermanet", "Pierre", ""]]}, {"id": "1903.11789", "submitter": "Evan N. Feinberg", "authors": "Evan N. Feinberg, Robert Sheridan, Elizabeth Joshi, Vijay S. Pande,\n  Alan C. Cheng", "title": "Step Change Improvement in ADMET Prediction with PotentialNet Deep\n  Featurization", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Absorption, Distribution, Metabolism, Elimination, and Toxicity (ADMET)\nproperties of drug candidates are estimated to account for up to 50% of all\nclinical trial failures. Predicting ADMET properties has therefore been of\ngreat interest to the cheminformatics and medicinal chemistry communities in\nrecent decades. Traditional cheminformatics approaches, whether the learner is\na random forest or a deep neural network, leverage fixed fingerprint feature\nrepresentations of molecules. In contrast, in this paper, we learn the features\nmost relevant to each chemical task at hand by representing each molecule\nexplicitly as a graph, where each node is an atom and each edge is a bond. By\napplying graph convolutions to this explicit molecular representation, we\nachieve, to our knowledge, unprecedented accuracy in prediction of ADMET\nproperties. By challenging our methodology with rigorous cross-validation\nprocedures and prospective analyses, we show that deep featurization better\nenables molecular predictors to not only interpolate but also extrapolate to\nnew regions of chemical space.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 05:18:28 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Feinberg", "Evan N.", ""], ["Sheridan", "Robert", ""], ["Joshi", "Elizabeth", ""], ["Pande", "Vijay S.", ""], ["Cheng", "Alan C.", ""]]}, {"id": "1903.11835", "submitter": "Nils Kriege", "authors": "Nils M. Kriege, Fredrik D. Johansson, Christopher Morris", "title": "A Survey on Graph Kernels", "comments": null, "journal-ref": "Applied Network Science 5 (2020)", "doi": "10.1007/s41109-019-0195-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernels have become an established and widely-used technique for\nsolving classification tasks on graphs. This survey gives a comprehensive\noverview of techniques for kernel-based graph classification developed in the\npast 15 years. We describe and categorize graph kernels based on properties\ninherent to their design, such as the nature of their extracted graph features,\ntheir method of computation and their applicability to problems in practice. In\nan extensive experimental evaluation, we study the classification accuracy of a\nlarge suite of graph kernels on established benchmarks as well as new datasets.\nWe compare the performance of popular kernels with several baseline methods and\nstudy the effect of applying a Gaussian RBF kernel to the metric induced by a\ngraph kernel. In doing so, we find that simple baselines become competitive\nafter this transformation on some datasets. Moreover, we study the extent to\nwhich existing graph kernels agree in their predictions (and prediction errors)\nand obtain a data-driven categorization of kernels as result. Finally, based on\nour experimental results, we derive a practitioner's guide to kernel-based\ngraph classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 08:44:21 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 13:08:07 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Kriege", "Nils M.", ""], ["Johansson", "Fredrik D.", ""], ["Morris", "Christopher", ""]]}, {"id": "1903.11900", "submitter": "Riccardo Volpi", "authors": "Riccardo Volpi, Vittorio Murino", "title": "Addressing Model Vulnerability to Distributional Shifts over Image\n  Transformation Sets", "comments": "ICCV 2019 (camera ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with the vulnerability of computer vision models to\ndistributional shifts. We formulate a combinatorial optimization problem that\nallows evaluating the regions in the image space where a given model is more\nvulnerable, in terms of image transformations applied to the input, and face it\nwith standard search algorithms. We further embed this idea in a training\nprocedure, where we define new data augmentation rules according to the image\ntransformations that the current model is most vulnerable to, over iterations.\nAn empirical evaluation on classification and semantic segmentation problems\nsuggests that the devised algorithm allows to train models that are more robust\nagainst content-preserving image manipulations and, in general, against\ndistributional shifts.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 11:24:38 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 09:51:24 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Volpi", "Riccardo", ""], ["Murino", "Vittorio", ""]]}, {"id": "1903.11907", "submitter": "Jonathan Schwarz", "authors": "Alexandre Galashov, Jonathan Schwarz, Hyunjik Kim, Marta Garnelo,\n  David Saxton, Pushmeet Kohli, S.M. Ali Eslami, Yee Whye Teh", "title": "Meta-Learning surrogate models for sequential decision making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a unified probabilistic framework for solving sequential\ndecision making problems ranging from Bayesian optimisation to contextual\nbandits and reinforcement learning. This is accomplished by a probabilistic\nmodel-based approach that explains observed data while capturing predictive\nuncertainty during the decision making process. Crucially, this probabilistic\nmodel is chosen to be a Meta-Learning system that allows learning from a\ndistribution of related problems, allowing data efficient adaptation to a\ntarget task. As a suitable instantiation of this framework, we explore the use\nof Neural processes due to statistical and computational desiderata. We apply\nour framework to a broad range of problem domains, such as control problems,\nrecommender systems and adversarial attacks on RL agents, demonstrating an\nefficient and general black-box learning approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 11:57:54 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 11:38:15 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Galashov", "Alexandre", ""], ["Schwarz", "Jonathan", ""], ["Kim", "Hyunjik", ""], ["Garnelo", "Marta", ""], ["Saxton", "David", ""], ["Kohli", "Pushmeet", ""], ["Eslami", "S. M. Ali", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1903.11960", "submitter": "Luca Franceschi", "authors": "Luca Franceschi, Mathias Niepert, Massimiliano Pontil, Xiao He", "title": "Learning Discrete Structures for Graph Neural Networks", "comments": "ICML 2019, code at https://github.com/lucfra/LDS - Revision of Sec. 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are a popular class of machine learning models\nwhose major advantage is their ability to incorporate a sparse and discrete\ndependency structure between data points. Unfortunately, GNNs can only be used\nwhen such a graph-structure is available. In practice, however, real-world\ngraphs are often noisy and incomplete or might not be available at all. With\nthis work, we propose to jointly learn the graph structure and the parameters\nof graph convolutional networks (GCNs) by approximately solving a bilevel\nprogram that learns a discrete probability distribution on the edges of the\ngraph. This allows one to apply GCNs not only in scenarios where the given\ngraph is incomplete or corrupted but also in those where a graph is not\navailable. We conduct a series of experiments that analyze the behavior of the\nproposed method and demonstrate that it outperforms related methods by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 13:30:24 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 09:53:04 GMT"}, {"version": "v3", "created": "Fri, 17 May 2019 09:43:48 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 09:44:16 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Franceschi", "Luca", ""], ["Niepert", "Mathias", ""], ["Pontil", "Massimiliano", ""], ["He", "Xiao", ""]]}, {"id": "1903.11981", "submitter": "Rinu Boney", "authors": "Rinu Boney, Norman Di Palo, Mathias Berglund, Alexander Ilin, Juho\n  Kannala, Antti Rasmus, Harri Valpola", "title": "Regularizing Trajectory Optimization with Denoising Autoencoders", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory optimization using a learned model of the environment is one of\nthe core elements of model-based reinforcement learning. This procedure often\nsuffers from exploiting inaccuracies of the learned model. We propose to\nregularize trajectory optimization by means of a denoising autoencoder that is\ntrained on the same trajectories as the model of the environment. We show that\nthe proposed regularization leads to improved planning with both gradient-based\nand gradient-free optimizers. We also demonstrate that using regularized\ntrajectory optimization leads to rapid initial learning in a set of popular\nmotor control tasks, which suggests that the proposed approach can be a useful\ntool for improving sample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:02:04 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 08:19:48 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 18:08:24 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Boney", "Rinu", ""], ["Di Palo", "Norman", ""], ["Berglund", "Mathias", ""], ["Ilin", "Alexander", ""], ["Kannala", "Juho", ""], ["Rasmus", "Antti", ""], ["Valpola", "Harri", ""]]}, {"id": "1903.11983", "submitter": "Adil \\c{C}oban", "authors": "\\.Ilhan Tar{\\i}mer, Adil \\c{C}oban and Arif Emre Kocaman", "title": "Sentiment Analysis on IMDB Movie Comments and Twitter Data by Machine\n  Learning and Vector Space Techniques", "comments": "8 pages, submitted to CIEA2018 (http://iciea.cumhuriyet.edu.tr/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study's goal is to create a model of sentiment analysis on a 2000 rows\nIMDB movie comments and 3200 Twitter data by using machine learning and vector\nspace techniques; positive or negative preliminary information about the text\nis to provide. In the study, a vector space was created in the KNIME Analytics\nplatform, and a classification study was performed on this vector space by\nDecision Trees, Na\\\"ive Bayes and Support Vector Machines classification\nalgorithms. The conclusions obtained were compared in terms of each algorithms.\nThe classification results for IMDB movie comments are obtained as 94,00%,\n73,20%, and 85,50% by Decision Tree, Naive Bayes and SVM algorithms. The\nclassification results for Twitter data set are presented as 82,76%, 75,44% and\n72,50% by Decision Tree, Naive Bayes SVM algorithms as well. It is seen that\nthe best classification results presented in both data sets are which\ncalculated by SVM algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 09:25:10 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Tar\u0131mer", "\u0130lhan", ""], ["\u00c7oban", "Adil", ""], ["Kocaman", "Arif Emre", ""]]}, {"id": "1903.11990", "submitter": "Simone Scardapane", "authors": "Michele Cirillo, Simone Scardapane, Steven Van Vaerenbergh, Aurelio\n  Uncini", "title": "On the Stability and Generalization of Learning with Kernel Activation\n  Functions", "comments": "Submitted as a brief paper to IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this brief we investigate the generalization properties of a\nrecently-proposed class of non-parametric activation functions, the kernel\nactivation functions (KAFs). KAFs introduce additional parameters in the\nlearning process in order to adapt nonlinearities individually on a per-neuron\nbasis, exploiting a cheap kernel expansion of every activation value. While\nthis increase in flexibility has been shown to provide significant improvements\nin practice, a theoretical proof for its generalization capability has not been\naddressed yet in the literature. Here, we leverage recent literature on the\nstability properties of non-convex models trained via stochastic gradient\ndescent (SGD). By indirectly proving two key smoothness properties of the\nmodels under consideration, we prove that neural networks endowed with KAFs\ngeneralize well when trained with SGD for a finite number of steps.\nInterestingly, our analysis provides a guideline for selecting one of the\nhyper-parameters of the model, the bandwidth of the scalar Gaussian kernel. A\nshort experimental evaluation validates the proof.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:13:16 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Cirillo", "Michele", ""], ["Scardapane", "Simone", ""], ["Van Vaerenbergh", "Steven", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1903.11991", "submitter": "Maximus Mutschler", "authors": "Maximus Mutschler and Andreas Zell", "title": "Parabolic Approximation Line Search for DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in current optimization research for deep learning is to\nautomatically find optimal step sizes for each update step. The optimal step\nsize is closely related to the shape of the loss in the update step direction.\nHowever, this shape has not yet been examined in detail. This work shows\nempirically that the batch loss over lines in negative gradient direction is\nmostly convex locally and well suited for one-dimensional parabolic\napproximations. By exploiting this parabolic property we introduce a simple and\nrobust line search approach, which performs loss-shape dependent update steps.\nOur approach combines well-known methods such as parabolic approximation, line\nsearch and conjugate gradient, to perform efficiently. It surpasses other step\nsize estimating methods and competes with common optimization methods on a\nlarge variety of experiments without the need of hand-designed step size\nschedules. Thus, it is of interest for objectives where step-size schedules are\nunknown or do not perform well. Our extensive evaluation includes multiple\ncomprehensive hyperparameter grid searches on several datasets and\narchitectures. Finally, we provide a general investigation of exact line\nsearches in the context of batch losses and exact losses, including their\nrelation to our line search approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:13:21 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 10:03:30 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 11:17:22 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 14:06:03 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mutschler", "Maximus", ""], ["Zell", "Andreas", ""]]}, {"id": "1903.12019", "submitter": "Conghui Zheng", "authors": "Conghui Zheng, Li Pan and Peng Wu", "title": "Multimodal Deep Network Embedding with Integrated Structure and\n  Attribute Information", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding is the process of learning low-dimensional representations\nfor nodes in a network, while preserving node features. Existing studies only\nleverage network structure information and focus on preserving structural\nfeatures. However, nodes in real-world networks often have a rich set of\nattributes providing extra semantic information. It has been demonstrated that\nboth structural and attribute features are important for network analysis\ntasks. To preserve both features, we investigate the problem of integrating\nstructure and attribute information to perform network embedding and propose a\nMultimodal Deep Network Embedding (MDNE) method. MDNE captures the non-linear\nnetwork structures and the complex interactions among structures and\nattributes, using a deep model consisting of multiple layers of non-linear\nfunctions. Since structures and attributes are two different types of\ninformation, a multimodal learning method is adopted to pre-process them and\nhelp the model to better capture the correlations between node structure and\nattribute information. We employ both structural proximity and attribute\nproximity in the loss function to preserve the respective features and the\nrepresentations are obtained by minimizing the loss function. Results of\nextensive experiments on four real-world datasets show that the proposed method\nperforms significantly better than baselines on a variety of tasks, which\ndemonstrate the effectiveness and generality of our method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:47:33 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zheng", "Conghui", ""], ["Pan", "Li", ""], ["Wu", "Peng", ""]]}, {"id": "1903.12044", "submitter": "\\\"Omer Deniz Akyildiz", "authors": "\\\"Omer Deniz Akyildiz, Joaqu\\'in M\\'iguez", "title": "Convergence rates for optimised adaptive importance samplers", "comments": "Revised version, new results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive importance samplers are adaptive Monte Carlo algorithms to estimate\nexpectations with respect to some target distribution which \\textit{adapt}\nthemselves to obtain better estimators over a sequence of iterations. Although\nit is straightforward to show that they have the same $\\mathcal{O}(1/\\sqrt{N})$\nconvergence rate as standard importance samplers, where $N$ is the number of\nMonte Carlo samples, the behaviour of adaptive importance samplers over the\nnumber of iterations has been left relatively unexplored. In this work, we\ninvestigate an adaptation strategy based on convex optimisation which leads to\na class of adaptive importance samplers termed \\textit{optimised adaptive\nimportance samplers} (OAIS). These samplers rely on the iterative minimisation\nof the $\\chi^2$-divergence between an exponential-family proposal and the\ntarget. The analysed algorithms are closely related to the class of adaptive\nimportance samplers which minimise the variance of the weight function. We\nfirst prove non-asymptotic error bounds for the mean squared errors (MSEs) of\nthese algorithms, which explicitly depend on the number of iterations and the\nnumber of samples together. The non-asymptotic bounds derived in this paper\nimply that when the target belongs to the exponential family, the $L_2$ errors\nof the optimised samplers converge to the optimal rate of\n$\\mathcal{O}(1/\\sqrt{N})$ and the rate of convergence in the number of\niterations are explicitly provided. When the target does not belong to the\nexponential family, the rate of convergence is the same but the asymptotic\n$L_2$ error increases by a factor $\\sqrt{\\rho^\\star} > 1$, where $\\rho^\\star -\n1$ is the minimum $\\chi^2$-divergence between the target and an\nexponential-family proposal.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 15:21:53 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 09:17:45 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2019 19:56:08 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 01:08:45 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Akyildiz", "\u00d6mer Deniz", ""], ["M\u00edguez", "Joaqu\u00edn", ""]]}, {"id": "1903.12069", "submitter": "Dominik Heider", "authors": "Sebastian Sp\\\"anig, Agnes Emberger-Klein, Jan-Peter Sowa, Ali Canbay,\n  Klaus Menrad, Dominik Heider", "title": "The Virtual Doctor: An Interactive Artificial Intelligence based on Deep\n  Learning for Non-Invasive Prediction of Diabetes", "comments": "16 pages, 4 figues", "journal-ref": "Artificial Intelligence in Medicine 2019", "doi": "10.1016/j.artmed.2019.101706", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) will pave the way to a new era in medicine.\nHowever, currently available AI systems do not interact with a patient, e.g.,\nfor anamnesis, and thus are only used by the physicians for predictions in\ndiagnosis or prognosis. However, these systems are widely used, e.g., in\ndiabetes or cancer prediction. In the current study, we developed an AI that is\nable to interact with a patient (virtual doctor) by using a speech recognition\nand speech synthesis system and thus can autonomously interact with the\npatient, which is particularly important for, e.g., rural areas, where the\navailability of primary medical care is strongly limited by low population\ndensities. As a proof-of-concept, the system is able to predict type 2 diabetes\nmellitus (T2DM) based on non-invasive sensors and deep neural networks.\nMoreover, the system provides an easy-to-interpret probability estimation for\nT2DM for a given patient. Besides the development of the AI, we further\nanalyzed the acceptance of young people for AI in healthcare to estimate the\nimpact of such system in the future.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 13:41:46 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Sp\u00e4nig", "Sebastian", ""], ["Emberger-Klein", "Agnes", ""], ["Sowa", "Jan-Peter", ""], ["Canbay", "Ali", ""], ["Menrad", "Klaus", ""], ["Heider", "Dominik", ""]]}, {"id": "1903.12070", "submitter": "Snehanshu Banerjee", "authors": "Snehanshu Banerjee, Mansoureh Jeihani, Danny D. Brown, and Samira\n  Ahangari", "title": "Comprehensive Analysis of Dynamic Message Sign Impact on Driver\n  Behavior: A Random Forest Approach", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the potential effects of different Dynamic Message\nSigns (DMSs) on driver behavior using a full-scale high-fidelity driving\nsimulator. Different DMSs are categorized by their content, structure, and type\nof messages. A random forest algorithm is used for three separate behavioral\nanalyses; a route diversion analysis, a route choice analysis and a compliance\nanalysis; to identify the potential and relative influences of different DMSs\non these aspects of driver behavior. A total of 390 simulation runs are\nconducted using a sample of 65 participants from diverse socioeconomic\nbackgrounds. Results obtained suggest that DMSs displaying lane closure and\ndelay information with advisory messages are most influential with regards to\ndiversion while color-coded DMSs and DMSs with avoid route advice are the top\ncontributors impacting route choice decisions and DMS compliance. In this\nfirst-of-a-kind study, based on the responses to the pre and post simulation\nsurveys as well as results obtained from the analysis of\ndriving-simulation-session data, the authors found that color-blind-friendly,\ncolor-coded DMSs are more effective than alphanumeric DMSs - especially in\nscenarios that demand high compliance from drivers. The increased effectiveness\nmay be attributed to reduced comprehension time and ease with which such DMSs\nare understood by a greater percentage of road users.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 02:10:28 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Banerjee", "Snehanshu", ""], ["Jeihani", "Mansoureh", ""], ["Brown", "Danny D.", ""], ["Ahangari", "Samira", ""]]}, {"id": "1903.12074", "submitter": "William La Cava", "authors": "William La Cava, Christopher Bauer, Jason H. Moore, Sarah A\n  Pendergrass", "title": "Interpretation of machine learning predictions for patient outcomes in\n  electronic health records", "comments": "10 pages, 5 figures, submitted to AMIA Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records are an increasingly important resource for\nunderstanding the interactions between patient health, environment, and\nclinical decisions. In this paper we report an empirical study of predictive\nmodeling of several patient outcomes using three state-of-the-art machine\nlearning methods. Our primary goal is to validate the models by interpreting\nthe importance of predictors in the final models. Central to interpretation is\nthe use of feature importance scores, which vary depending on the underlying\nmethodology. In order to assess feature importance, we compared univariate\nstatistical tests, information-theoretic measures, permutation testing, and\nnormalized coefficients from multivariate logistic regression models. In\ngeneral we found poor correlation between methods in their assessment of\nfeature importance, even when their performance is comparable and relatively\ngood. However, permutation tests applied to random forest and gradient boosting\nmodels showed the most agreement, and the importance scores matched the\nclinical interpretation most frequently.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 19:05:37 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["La Cava", "William", ""], ["Bauer", "Christopher", ""], ["Moore", "Jason H.", ""], ["Pendergrass", "Sarah A", ""]]}, {"id": "1903.12080", "submitter": "Carl Chalmers", "authors": "C. Chalmers, P.Fergus, C. Aday Curbelo Montanez, S.Sikdar, F.Ball and\n  B. Kendall", "title": "Detecting Activities of Daily Living and Routine Behaviours in Dementia\n  Patients Living Alone Using Smart Meter Load Disaggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of an ageing population is a significant public health concern.\nThis has led to an increase in the number of people living with progressive\nneurodegenerative disorders like dementia. Consequently, the strain this is\nplaces on health and social care services means providing 24-hour monitoring is\nnot sustainable. Technological intervention is being considered, however no\nsolution exists to non-intrusively monitor the independent living needs of\npatients with dementia. As a result many patients hit crisis point before\nintervention and support is provided. In parallel, patient care relies on\nfeedback from informal carers about significant behavioural changes. Yet, not\nall people have a social support network and early intervention in dementia\ncare is often missed. The smart meter rollout has the potential to change this.\nUsing machine learning and signal processing techniques, a home energy supply\ncan be disaggregated to detect which home appliances are turned on and off.\nThis will allow Activities of Daily Living (ADLs) to be assessed, such as\neating and drinking, and observed changes in routine to be detected for early\nintervention. The primary aim is to help reduce deterioration and enable\npatients to stay in their homes for longer. A Support Vector Machine (SVM) and\nRandom Decision Forest classifier are modelled using data from three test\nhomes. The trained models are then used to monitor two patients with dementia\nduring a six-month clinical trial undertaken in partnership with Mersey Care\nNHS Foundation Trust. In the case of load disaggregation for appliance\ndetection, the SVM achieved (AUC=0.86074, Sen=0.756 and Spec=0.92838). While\nthe Decision Forest achieved (AUC=0.9429, Sen=0.9634 and Spec=0.9634). ADLs are\nalso analysed to identify the behavioural patterns of the occupant while\ndetecting alterations in routine.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 11:54:19 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Chalmers", "C.", ""], ["Fergus", "P.", ""], ["Montanez", "C. Aday Curbelo", ""], ["Sikdar", "S.", ""], ["Ball", "F.", ""], ["Kendall", "B.", ""]]}, {"id": "1903.12090", "submitter": "Fabrizio Sebastiani", "authors": "Alejandro Moreo Fern\\'andez, Andrea Esuli, Fabrizio Sebastiani", "title": "Learning to Weight for Text Classification", "comments": "To appear in IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In information retrieval (IR) and related tasks, term weighting approaches\ntypically consider the frequency of the term in the document and in the\ncollection in order to compute a score reflecting the importance of the term\nfor the document. In tasks characterized by the presence of training data (such\nas text classification) it seems logical that the term weighting function\nshould take into account the distribution (as estimated from training data) of\nthe term across the classes of interest. Although `supervised term weighting'\napproaches that use this intuition have been described before, they have failed\nto show consistent improvements. In this article we analyse the possible\nreasons for this failure, and call consolidated assumptions into question.\nFollowing this criticism we propose a novel supervised term weighting approach\nthat, instead of relying on any predefined formula, learns a term weighting\nfunction optimised on the training set of interest; we dub this approach\n\\emph{Learning to Weight} (LTW). The experiments that we run on several\nwell-known benchmarks, and using different learning methods, show that our\nmethod outperforms previous term weighting approaches in text classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:13:35 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Fern\u00e1ndez", "Alejandro Moreo", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1903.12094", "submitter": "John Gideon", "authors": "John Gideon, Melvin G McInnis, Emily Mower Provost", "title": "Improving Cross-Corpus Speech Emotion Recognition with Adversarial\n  Discriminative Domain Generalization (ADDoG)", "comments": null, "journal-ref": null, "doi": "10.1109/TAFFC.2019.2916092", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech emotion recognition provides computers with critical context\nto enable user understanding. While methods trained and tested within the same\ndataset have been shown successful, they often fail when applied to unseen\ndatasets. To address this, recent work has focused on adversarial methods to\nfind more generalized representations of emotional speech. However, many of\nthese methods have issues converging, and only involve datasets collected in\nlaboratory conditions. In this paper, we introduce Adversarial Discriminative\nDomain Generalization (ADDoG), which follows an easier to train \"meet in the\nmiddle\" approach. The model iteratively moves representations learned for each\ndataset closer to one another, improving cross-dataset generalization. We also\nintroduce Multiclass ADDoG, or MADDoG, which is able to extend the proposed\nmethod to more than two datasets, simultaneously. Our results show consistent\nconvergence for the introduced methods, with significantly improved results\nwhen not using labels from the target dataset. We also show how, in most cases,\nADDoG and MADDoG can be used to improve upon baseline state-of-the-art methods\nwhen target dataset labels are added and in-the-wild data are considered. Even\nthough our experiments focus on cross-corpus speech emotion, these methods\ncould be used to remove unwanted factors of variation in other settings.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:19:20 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 13:59:26 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Gideon", "John", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1903.12125", "submitter": "Haoyu Wang", "authors": "Haoyu Wang, Yawen Guan and Brian J Reich", "title": "Nearest-Neighbor Neural Networks for Geostatistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kriging is the predominant method used for spatial prediction, but relies on\nthe assumption that predictions are linear combinations of the observations.\nKriging often also relies on additional assumptions such as normality and\nstationarity. We propose a more flexible spatial prediction method based on the\nNearest-Neighbor Neural Network (4N) process that embeds deep learning into a\ngeostatistical model. We show that the 4N process is a valid stochastic process\nand propose a series of new ways to construct features to be used as inputs to\nthe deep learning model based on neighboring information. Our model framework\noutperforms some existing state-of-art geostatistical modelling methods for\nsimulated non-Gaussian data and is applied to a massive forestry dataset.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:10:59 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Wang", "Haoyu", ""], ["Guan", "Yawen", ""], ["Reich", "Brian J", ""]]}, {"id": "1903.12127", "submitter": "Emilia Apostolova PhD", "authors": "Tony Wang, Tim Tschampel, Emilia Apostolova and Tom Velez", "title": "Using Latent Class Analysis to Identify ARDS Sub-phenotypes for Enhanced\n  Machine Learning Predictive Performance", "comments": "Work in progress, preliminary results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we utilize Machine Learning for early recognition of patients\nat high risk of acute respiratory distress syndrome (ARDS), which is critical\nfor successful prevention strategies for this devastating syndrome. The\ndifficulty in early ARDS recognition stems from its complex and heterogenous\nnature. In this study, we integrate knowledge of the heterogeneity of ARDS\npatients into predictive model building. Using MIMIC-III data, we first apply\nlatent class analysis (LCA) to identify homogeneous sub-groups in the ARDS\npopulation, and then build predictive models on the partitioned data. The\nresults indicate that significantly improved performances of prediction can be\nobtained for two of the three identified sub-phenotypes of ARDS. Experiments\nsuggests that identifying sub-phenotypes is beneficial for building predictive\nmodel for ARDS.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:12:35 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Wang", "Tony", ""], ["Tschampel", "Tim", ""], ["Apostolova", "Emilia", ""], ["Velez", "Tom", ""]]}, {"id": "1903.12128", "submitter": "Philipp-Immanuel Schneider", "authors": "Philipp-Immanuel Schneider, Martin Hammerschmidt, Lin Zschiedrich,\n  Sven Burger", "title": "Using Gaussian process regression for efficient parameter reconstruction", "comments": "8 pages, 4 figures", "journal-ref": "Proc. SPIE 10959, 1095911 (2019)", "doi": "10.1117/12.2513268", "report-no": null, "categories": "physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical scatterometry is a method to measure the size and shape of periodic\nmicro- or nanostructures on surfaces. For this purpose the geometry parameters\nof the structures are obtained by reproducing experimental measurement results\nthrough numerical simulations. We compare the performance of Bayesian\noptimization to different local minimization algorithms for this numerical\noptimization problem. Bayesian optimization uses Gaussian-process regression to\nfind promising parameter values. We examine how pre-computed simulation results\ncan be used to train the Gaussian process and to accelerate the optimization.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:13:29 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Schneider", "Philipp-Immanuel", ""], ["Hammerschmidt", "Martin", ""], ["Zschiedrich", "Lin", ""], ["Burger", "Sven", ""]]}, {"id": "1903.12141", "submitter": "Xinshao Wang Dr", "authors": "Xinshao Wang, Yang Hua, Elyor Kodirov, Neil M. Robertson", "title": "IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat\n  Examples Equally and Gradient Magnitude's Variance Matters", "comments": "Updated Version. IMAE for Noise-Robust Learning: Mean Absolute Error\n  Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters\n  Code:\n  \\url{https://github.com/XinshaoAmosWang/Improving-Mean-Absolute-Error-against-CCE}.\n  Please feel free to contact for discussions or implementation problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study robust deep learning against abnormal training data\nfrom the perspective of example weighting built in empirical loss functions,\ni.e., gradient magnitude with respect to logits, an angle that is not\nthoroughly studied so far. Consequently, we have two key findings: (1) Mean\nAbsolute Error (MAE) Does Not Treat Examples Equally. We present new\nobservations and insightful analysis about MAE, which is theoretically proved\nto be noise-robust. First, we reveal its underfitting problem in practice.\nSecond, we analyse that MAE's noise-robustness is from emphasising on uncertain\nexamples instead of treating training samples equally, as claimed in prior\nwork. (2) The Variance of Gradient Magnitude Matters. We propose an effective\nand simple solution to enhance MAE's fitting ability while preserving its\nnoise-robustness. Without changing MAE's overall weighting scheme, i.e., what\nexamples get higher weights, we simply change its weighting variance\nnon-linearly so that the impact ratio between two examples are adjusted. Our\nsolution is termed Improved MAE (IMAE). We prove IMAE's effectiveness using\nextensive experiments: image classification under clean labels, synthetic label\nnoise, and real-world unknown noise. We conclude IMAE is superior to CCE, the\nmost popular loss for training DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:27:05 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 12:23:00 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 10:30:04 GMT"}, {"version": "v4", "created": "Tue, 13 Aug 2019 21:51:20 GMT"}, {"version": "v5", "created": "Fri, 18 Oct 2019 15:44:53 GMT"}, {"version": "v6", "created": "Tue, 17 Dec 2019 13:02:56 GMT"}, {"version": "v7", "created": "Sat, 11 Jan 2020 23:44:10 GMT"}, {"version": "v8", "created": "Mon, 27 Jan 2020 11:59:02 GMT"}, {"version": "v9", "created": "Sun, 15 Nov 2020 09:38:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wang", "Xinshao", ""], ["Hua", "Yang", ""], ["Kodirov", "Elyor", ""], ["Robertson", "Neil M.", ""]]}, {"id": "1903.12173", "submitter": "Tilman Tr\\\"oster", "authors": "Tilman Tr\\\"oster, Cameron Ferguson, Joachim Harnois-D\\'eraps, Ian G.\n  McCarthy", "title": "Painting with baryons: augmenting N-body simulations with gas using deep\n  generative models", "comments": "Comments welcome. Code and trained models can be found at\n  https://www.github.com/tilmantroester/baryon_painter. Accepted in MNRAS\n  Letters", "journal-ref": "Monthly Notices of the Royal Astronomical Society: Letters, Volume\n  487, Issue 1, (2019), p.L24-L29", "doi": "10.1093/mnrasl/slz075", "report-no": null, "categories": "astro-ph.CO astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running hydrodynamical simulations to produce mock data of large-scale\nstructure and baryonic probes, such as the thermal Sunyaev-Zeldovich (tSZ)\neffect, at cosmological scales is computationally challenging. We propose to\nleverage the expressive power of deep generative models to find an effective\ndescription of the large-scale gas distribution and temperature. We train two\ndeep generative models, a variational auto-encoder and a generative adversarial\nnetwork, on pairs of matter density and pressure slices from the BAHAMAS\nhydrodynamical simulation. The trained models are able to successfully map\nmatter density to the corresponding gas pressure. We then apply the trained\nmodels on 100 lines-of-sight from SLICS, a suite of N-body simulations\noptimised for weak lensing covariance estimation, to generate maps of the tSZ\neffect. The generated tSZ maps are found to be statistically consistent with\nthose from BAHAMAS. We conclude by considering a specific observable, the\nangular cross-power spectrum between the weak lensing convergence and the tSZ\neffect and its variance, where we find excellent agreement between the\npredictions from BAHAMAS and SLICS, thus enabling the use of SLICS for tSZ\ncovariance estimation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:59:16 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 11:51:36 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Tr\u00f6ster", "Tilman", ""], ["Ferguson", "Cameron", ""], ["Harnois-D\u00e9raps", "Joachim", ""], ["McCarthy", "Ian G.", ""]]}, {"id": "1903.12235", "submitter": "Ozan Ozdenizci", "authors": "Ozan Ozdenizci, Deniz Erdogmus", "title": "Information Theoretic Feature Transformation Learning for Brain\n  Interfaces", "comments": "Accepted for publication by IEEE Transactions on Biomedical\n  Engineering", "journal-ref": "IEEE Transactions on Biomedical Engineering, 2019", "doi": "10.1109/TBME.2019.2908099", "report-no": null, "categories": "cs.LG cs.HC cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A variety of pattern analysis techniques for model training in\nbrain interfaces exploit neural feature dimensionality reduction based on\nfeature ranking and selection heuristics. In the light of broad evidence\ndemonstrating the potential sub-optimality of ranking based feature selection\nby any criterion, we propose to extend this focus with an information theoretic\nlearning driven feature transformation concept. Methods: We present a maximum\nmutual information linear transformation (MMI-LinT), and a nonlinear\ntransformation (MMI-NonLinT) framework derived by a general definition of the\nfeature transformation learning problem. Empirical assessments are performed\nbased on electroencephalographic (EEG) data recorded during a four class motor\nimagery brain-computer interface (BCI) task. Exploiting state-of-the-art\nmethods for initial feature vector construction, we compare the proposed\napproaches with conventional feature selection based dimensionality reduction\ntechniques which are widely used in brain interfaces. Furthermore, for the\nmulti-class problem, we present and exploit a hierarchical graphical model\nbased BCI decoding system. Results: Both binary and multi-class decoding\nanalyses demonstrate significantly better performances with the proposed\nmethods. Conclusion: Information theoretic feature transformations are capable\nof tackling potential confounders of conventional approaches in various\nsettings. Significance: We argue that this concept provides significant\ninsights to extend the focus on feature selection heuristics to a broader\ndefinition of feature transformation learning in brain interfaces.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 19:41:05 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 17:10:57 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Ozdenizci", "Ozan", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "1903.12248", "submitter": "Mayank Mishra", "authors": "Prathosh A. P., Varun Srivastava, Mayank Mishra", "title": "Adversarial Approximate Inference for Speech to Electroglottograph\n  Conversion", "comments": "Submitted to IEEE/ACM Transactions on Audio, Speech and Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech produced by human vocal apparatus conveys substantial non-semantic\ninformation including the gender of the speaker, voice quality, affective\nstate, abnormalities in the vocal apparatus etc. Such information is attributed\nto the properties of the voice source signal, which is usually estimated from\nthe speech signal. However, most of the source estimation techniques depend\nheavily on the goodness of the model assumptions and are prone to noise. A\npopular alternative is to indirectly obtain the source information through the\nElectroglottographic (EGG) signal that measures the electrical admittance\naround the vocal folds using dedicated hardware. In this paper, we address the\nproblem of estimating the EGG signal directly from the speech signal, devoid of\nany hardware. Sampling from the intractable conditional distribution of the EGG\nsignal given the speech signal is accomplished through optimization of an\nevidence lower bound. This is constructed via minimization of the KL-divergence\nbetween the true and the approximated posteriors of a latent variable learned\nusing a deep neural auto-encoder that serves an informative prior. We\ndemonstrate the efficacy of the method at generating the EGG signal by\nconducting several experiments on datasets comprising multiple speakers, voice\nqualities, noise settings and speech pathologies. The proposed method is\nevaluated on many benchmark metrics and is found to agree with the gold\nstandard while proving better than the state-of-the-art algorithms on a few\ntasks such as epoch extraction.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 20:30:17 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 20:04:52 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["P.", "Prathosh A.", ""], ["Srivastava", "Varun", ""], ["Mishra", "Mayank", ""]]}, {"id": "1903.12258", "submitter": "Rosdyana Mangir Irawan Kusuma", "authors": "Rosdyana Mangir Irawan Kusuma, Trang-Thi Ho, Wei-Chun Kao, Yu-Yen Ou\n  and Kai-Lung Hua", "title": "Using Deep Learning Neural Networks and Candlestick Chart Representation\n  to Predict Stock Market", "comments": "conference,13 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock market prediction is still a challenging problem because there are many\nfactors effect to the stock market price such as company news and performance,\nindustry performance, investor sentiment, social media sentiment and economic\nfactors. This work explores the predictability in the stock market using Deep\nConvolutional Network and candlestick charts. The outcome is utilized to design\na decision support framework that can be used by traders to provide suggested\nindications of future stock price direction. We perform this work using various\ntypes of neural networks like convolutional neural network, residual network\nand visual geometry group network. From stock market historical data, we\nconverted it to candlestick charts. Finally, these candlestick charts will be\nfeed as input for training a Convolutional Neural Network model. This\nConvolutional Neural Network model will help us to analyze the patterns inside\nthe candlestick chart and predict the future movements of stock market. The\neffectiveness of our method is evaluated in stock market prediction with a\npromising results 92.2% and 92.1% accuracy for Taiwan and Indonesian stock\nmarket dataset respectively. The constructed model have been implemented as a\nweb-based system freely available at http://140.138.155.216/deepcandle/ for\npredicting stock market using candlestick chart and deep learning neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 03:47:40 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Kusuma", "Rosdyana Mangir Irawan", ""], ["Ho", "Trang-Thi", ""], ["Kao", "Wei-Chun", ""], ["Ou", "Yu-Yen", ""], ["Hua", "Kai-Lung", ""]]}, {"id": "1903.12261", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Thomas Dietterich", "title": "Benchmarking Neural Network Robustness to Common Corruptions and\n  Perturbations", "comments": "ICLR 2019 camera-ready; datasets available at\n  https://github.com/hendrycks/robustness ; this article supersedes\n  arXiv:1807.01697", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we establish rigorous benchmarks for image classifier\nrobustness. Our first benchmark, ImageNet-C, standardizes and expands the\ncorruption robustness topic, while showing which classifiers are preferable in\nsafety-critical applications. Then we propose a new dataset called ImageNet-P\nwhich enables researchers to benchmark a classifier's robustness to common\nperturbations. Unlike recent robustness research, this benchmark evaluates\nperformance on common corruptions and perturbations not worst-case adversarial\nperturbations. We find that there are negligible changes in relative corruption\nrobustness from AlexNet classifiers to ResNet classifiers. Afterward we\ndiscover ways to enhance corruption and perturbation robustness. We even find\nthat a bypassed adversarial defense provides substantial common perturbation\nrobustness. Together our benchmarks may aid future work toward networks that\nrobustly generalize.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 20:56:37 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Hendrycks", "Dan", ""], ["Dietterich", "Thomas", ""]]}, {"id": "1903.12262", "submitter": "Negar Rostamzadeh", "authors": "Misha Benjamin, Paul Gagnon, Negar Rostamzadeh, Chris Pal, Yoshua\n  Bengio, Alex Shee", "title": "Towards Standardization of Data Licenses: The Montreal Data License", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a taxonomy for the licensing of data in the fields of\nartificial intelligence and machine learning. The paper's goal is to build\ntowards a common framework for data licensing akin to the licensing of open\nsource software. Increased transparency and resolving conceptual ambiguities in\nexisting licensing language are two noted benefits of the approach proposed in\nthe paper. In parallel, such benefits may help foster fairer and more efficient\nmarkets for data through bringing about clearer tools and concepts that better\ndefine how data can be used in the fields of AI and ML. The paper's approach is\nsummarized in a new family of data license language - \\textit{the Montreal Data\nLicense (MDL)}. Alongside this new license, the authors and their collaborators\nhave developed a web-based tool to generate license language espousing the\ntaxonomies articulated in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 00:28:59 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Benjamin", "Misha", ""], ["Gagnon", "Paul", ""], ["Rostamzadeh", "Negar", ""], ["Pal", "Chris", ""], ["Bengio", "Yoshua", ""], ["Shee", "Alex", ""]]}, {"id": "1903.12264", "submitter": "Timur Osadchiy", "authors": "Timur Osadchiy, Ivan Poliakov, Patrick Olivier, Maisie Rowland, Emma\n  Foster", "title": "Validation of a recommender system for prompting omitted foods in online\n  dietary assessment surveys", "comments": null, "journal-ref": "PervasiveHealth 2019 Proceedings of the 13th EAI International\n  Conference on Pervasive Computing Technologies for Healthcare", "doi": "10.1145/3329189.3329191", "report-no": "ISBN: 978-1-4503-6126-2", "categories": "cs.CY cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recall assistance methods are among the key aspects that improve the accuracy\nof online dietary assessment surveys. These methods still mainly rely on\nexperience of trained interviewers with nutritional background, but data driven\napproaches could improve cost-efficiency and scalability of automated dietary\nassessment. We evaluated the effectiveness of a recommender algorithm developed\nfor an online dietary assessment system called Intake24, that automates the\nmultiple-pass 24-hour recall method. The recommender builds a model of eating\nbehavior from recalls collected in past surveys. Based on foods they have\nalready selected, the model is used to remind respondents of associated foods\nthat they may have omitted to report. The performance of prompts generated by\nthe model was compared to that of prompts hand-coded by nutritionists in two\ndietary studies. The results of our studies demonstrate that the recommender\nsystem is able to capture a higher number of foods omitted by respondents of\nonline dietary surveys than prompts hand-coded by nutritionists. However, the\nconsiderably lower precision of generated prompts indicates an opportunity for\nfurther improvement of the system.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:42:54 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Osadchiy", "Timur", ""], ["Poliakov", "Ivan", ""], ["Olivier", "Patrick", ""], ["Rowland", "Maisie", ""], ["Foster", "Emma", ""]]}, {"id": "1903.12266", "submitter": "Maciej Zamorski", "authors": "Maciej Zamorski, Adrian Zdobylak, Maciej Zi\\k{e}ba, Jerzy\n  \\'Swi\\k{a}tek", "title": "Generative Adversarial Networks: recent developments", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional generative modeling, good data representation is very often a\nbase for a good machine learning model. It can be linked to good\nrepresentations encoding more explanatory factors that are hidden in the\noriginal data. With the invention of Generative Adversarial Networks (GANs), a\nsubclass of generative models that are able to learn representations in an\nunsupervised and semi-supervised fashion, we are now able to adversarially\nlearn good mappings from a simple prior distribution to a target data\ndistribution. This paper presents an overview of recent developments in GANs\nwith a focus on learning latent space representations.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 18:10:35 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Zamorski", "Maciej", ""], ["Zdobylak", "Adrian", ""], ["Zi\u0119ba", "Maciej", ""], ["\u015awi\u0105tek", "Jerzy", ""]]}, {"id": "1903.12286", "submitter": "Maciej Mikulski", "authors": "Maciej Mikulski and Jaroslaw Duda", "title": "Toroidal AutoEncoder", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enforcing distributions of latent variables in neural networks is an active\nsubject. It is vital in all kinds of generative models, where we want to be\nable to interpolate between points in the latent space, or sample from it.\nModern generative AutoEncoders (AE) like WAE, SWAE, CWAE add a regularizer to\nthe standard (deterministic) AE, which allows to enforce Gaussian distribution\nin the latent space. Enforcing different distributions, especially\ntopologically nontrivial, might bring some new interesting possibilities, but\nthis subject seems unexplored so far.\n  This article proposes a new approach to enforce uniform distribution on\nd-dimensional torus. We introduce a circular spring loss, which enforces\nminibatch points to be equally spaced and satisfy cyclic boundary conditions.\n  As example of application we propose multiple-path morphing. Minimal distance\ngeodesic between two points in uniform distribution on latent space of angles\nbecomes a line, however, torus topology allows us to choose such lines in\nalternative ways, going through different edges of $[-\\pi,\\pi]^d$.\n  Further applications to explore can be for example trying to learn real-life\ntopologically nontrivial spaces of features, like rotations to automatically\nrecognize 2D rotation of an object in picture by training on relative angles,\nor even 3D rotations by additionally using spherical features - this way\nmorphing should be close to object rotation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 21:48:46 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Mikulski", "Maciej", ""], ["Duda", "Jaroslaw", ""]]}, {"id": "1903.12287", "submitter": "Adam Lerer", "authors": "Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt,\n  Abhijit Bose, Alex Peysakhovich", "title": "PyTorch-BigGraph: A Large-scale Graph Embedding System", "comments": null, "journal-ref": "Proceedings of The Conference on Systems and Machine Learning,\n  2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding methods produce unsupervised node features from graphs that\ncan then be used for a variety of machine learning tasks. Modern graphs,\nparticularly in industrial applications, contain billions of nodes and\ntrillions of edges, which exceeds the capability of existing embedding systems.\nWe present PyTorch-BigGraph (PBG), an embedding system that incorporates\nseveral modifications to traditional multi-relation embedding systems that\nallow it to scale to graphs with billions of nodes and trillions of edges. PBG\nuses graph partitioning to train arbitrarily large embeddings on either a\nsingle machine or in a distributed environment. We demonstrate comparable\nperformance with existing embedding systems on common benchmarks, while\nallowing for scaling to arbitrarily large graphs and parallelization on\nmultiple machines. We train and evaluate embeddings on several large social\nnetwork graphs as well as the full Freebase dataset, which contains over 100\nmillion nodes and 2 billion edges.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 21:51:09 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 16:48:00 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 15:41:25 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Lerer", "Adam", ""], ["Wu", "Ledell", ""], ["Shen", "Jiajun", ""], ["Lacroix", "Timothee", ""], ["Wehrstedt", "Luca", ""], ["Bose", "Abhijit", ""], ["Peysakhovich", "Alex", ""]]}, {"id": "1903.12297", "submitter": "Jean Feng", "authors": "Jean Feng, Noah Simon", "title": "An analysis of the cost of hyper-parameter selection via split-sample\n  validation, with applications to penalized regression", "comments": null, "journal-ref": null, "doi": "10.5705/ss.202017.0310", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the regression setting, given a set of hyper-parameters, a\nmodel-estimation procedure constructs a model from training data. The optimal\nhyper-parameters that minimize generalization error of the model are usually\nunknown. In practice they are often estimated using split-sample validation. Up\nto now, there is an open question regarding how the generalization error of the\nselected model grows with the number of hyper-parameters to be estimated. To\nanswer this question, we establish finite-sample oracle inequalities for\nselection based on a single training/test split and based on cross-validation.\nWe show that if the model-estimation procedures are smoothly parameterized by\nthe hyper-parameters, the error incurred from tuning hyper-parameters shrinks\nat nearly a parametric rate. Hence for semi- and non-parametric\nmodel-estimation procedures with a fixed number of hyper-parameters, this\nadditional error is negligible. For parametric model-estimation procedures,\nadding a hyper-parameter is roughly equivalent to adding a parameter to the\nmodel itself. In addition, we specialize these ideas for penalized regression\nproblems with multiple penalty parameters. We establish that the fitted models\nare Lipschitz in the penalty parameters and thus our oracle inequalities apply.\nThis result encourages development of regularization methods with many penalty\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 23:04:43 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Feng", "Jean", ""], ["Simon", "Noah", ""]]}, {"id": "1903.12322", "submitter": "Liam Hodgkinson", "authors": "Liam Hodgkinson, Robert Salomone, Fred Roosta", "title": "Implicit Langevin Algorithms for Sampling From Log-concave Densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For sampling from a log-concave density, we study implicit integrators\nresulting from $\\theta$-method discretization of the overdamped Langevin\ndiffusion stochastic differential equation. Theoretical and algorithmic\nproperties of the resulting sampling methods for $ \\theta \\in [0,1] $ and a\nrange of step sizes are established. Our results generalize and extend prior\nworks in several directions. In particular, for $\\theta\\ge1/2$, we prove\ngeometric ergodicity and stability of the resulting methods for all step sizes.\nWe show that obtaining subsequent samples amounts to solving a strongly-convex\noptimization problem, which is readily achievable using one of numerous\nexisting methods. Numerical examples supporting our theoretical analysis are\nalso presented.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 02:13:16 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 07:31:46 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hodgkinson", "Liam", ""], ["Salomone", "Robert", ""], ["Roosta", "Fred", ""]]}, {"id": "1903.12328", "submitter": "Joseph West", "authors": "Joseph West, Frederic Maire, Cameron Browne and Simon Denman", "title": "Improved Reinforcement Learning with Curriculum", "comments": "Draft prior to submission to IEEE Trans on Games. Changed paper\n  slightly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans tend to learn complex abstract concepts faster if examples are\npresented in a structured manner. For instance, when learning how to play a\nboard game, usually one of the first concepts learned is how the game ends,\ni.e. the actions that lead to a terminal state (win, lose or draw). The\nadvantage of learning end-games first is that once the actions which lead to a\nterminal state are understood, it becomes possible to incrementally learn the\nconsequences of actions that are further away from a terminal state - we call\nthis an end-game-first curriculum. Currently the state-of-the-art machine\nlearning player for general board games, AlphaZero by Google DeepMind, does not\nemploy a structured training curriculum; instead learning from the entire game\nat all times. By employing an end-game-first training curriculum to train an\nAlphaZero inspired player, we empirically show that the rate of learning of an\nartificial player can be improved during the early stages of training when\ncompared to a player not using a training curriculum.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 02:27:54 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 04:23:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["West", "Joseph", ""], ["Maire", "Frederic", ""], ["Browne", "Cameron", ""], ["Denman", "Simon", ""]]}, {"id": "1903.12344", "submitter": "Liang Zhao", "authors": "Liang Zhao and Wei Xu", "title": "Learning Good Representation via Continuous Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present our scientific discovery that good representation\ncan be learned via continuous attention during the interaction between\nUnsupervised Learning(UL) and Reinforcement Learning(RL) modules driven by\nintrinsic motivation. Specifically, we designed intrinsic rewards generated\nfrom UL modules for driving the RL agent to focus on objects for a period of\ntime and to learn good representations of objects for later object recognition\ntask. We evaluate our proposed algorithm in both with and without extrinsic\nreward settings. Experiments with end-to-end training in simulated environments\nwith applications to few-shot object recognition demonstrated the effectiveness\nof the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 03:43:36 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 03:35:15 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhao", "Liang", ""], ["Xu", "Wei", ""]]}, {"id": "1903.12347", "submitter": "Neil Borle", "authors": "Neil C. Borle, Edmond A. Ryan, Russell Greiner", "title": "The Challenge of Predicting Meal-to-meal Blood Glucose Concentrations\n  for Patients with Type I Diabetes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients with Type I Diabetes (T1D) must take insulin injections to prevent\nthe serious long term effects of hyperglycemia - high blood glucose (BG).\nPatients must also be careful not to inject too much insulin because this could\ninduce hypoglycemia (low BG), which can potentially be fatal. Patients\ntherefore follow a \"regimen\" that determines how much insulin to inject at\ncertain times. Current methods for managing this disease require adjusting the\npatient's regimen over time based on the disease's behavior (recorded in the\npatient's diabetes diary). If we can accurately predict a patient's future BG\nvalues from his/her current features (e.g., predicting today's lunch BG value\ngiven today's diabetes diary entry for breakfast, including insulin injections,\nand perhaps earlier entries), then it is relatively easy to produce an\neffective regimen. This study explores the challenges of BG modeling by\napplying several machine learning algorithms and various data preprocessing\nvariations (corresponding to 312 [learner, preprocessed-dataset] combinations),\nto a new T1D dataset containing 29 601 entries from 47 different patients. Our\nmost accurate predictor is a weighted ensemble of two Gaussian Process\nRegression models, which achieved an errL1 loss of 2.70 mmol/L (48.65 mg/dl).\nThis was an unexpectedly poor result given that one can obtain an errL1 of 2.91\nmmol/L (52.43 mg/dl) using the naive approach of simply predicting the\npatient's average BG. For each of data-variant/model combination we report\nseveral evaluation metrics, including glucose-specific metrics, and find\nsimilarly disappointing results (the best model was only incrementally better\nthan the simplest measure). These results suggest that the diabetes diary data\nthat is typically collected may not be sufficient to produce accurate BG\nprediction models; additional data may be necessary to build accurate BG\nprediction models.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 03:51:22 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Borle", "Neil C.", ""], ["Ryan", "Edmond A.", ""], ["Greiner", "Russell", ""]]}, {"id": "1903.12370", "submitter": "Mitch Hill", "authors": "Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, Ying Nian Wu", "title": "On the Anatomy of MCMC-Based Maximum Likelihood Learning of Energy-Based\n  Models", "comments": "Code available at: https://github.com/point0bar1/ebm-anatomy", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the effects of Markov chain Monte Carlo (MCMC)\nsampling in unsupervised Maximum Likelihood (ML) learning. Our attention is\nrestricted to the family of unnormalized probability densities for which the\nnegative log density (or energy function) is a ConvNet. We find that many of\nthe techniques used to stabilize training in previous studies are not\nnecessary. ML learning with a ConvNet potential requires only a few\nhyper-parameters and no regularization. Using this minimal framework, we\nidentify a variety of ML learning outcomes that depend solely on the\nimplementation of MCMC sampling.\n  On one hand, we show that it is easy to train an energy-based model which can\nsample realistic images with short-run Langevin. ML can be effective and stable\neven when MCMC samples have much higher energy than true steady-state samples\nthroughout training. Based on this insight, we introduce an ML method with\npurely noise-initialized MCMC, high-quality short-run synthesis, and the same\nbudget as ML with informative MCMC initialization such as CD or PCD. Unlike\nprevious models, our energy model can obtain realistic high-diversity samples\nfrom a noise signal after training.\n  On the other hand, ConvNet potentials learned with non-convergent MCMC do not\nhave a valid steady-state and cannot be considered approximate unnormalized\ndensities of the training data because long-run MCMC samples differ greatly\nfrom observed images. We show that it is much harder to train a ConvNet\npotential to learn a steady-state over realistic images. To our knowledge,\nlong-run MCMC samples of all previous models lose the realism of short-run\nsamples. With correct tuning of Langevin noise, we train the first ConvNet\npotentials for which long-run and steady-state MCMC samples are realistic\nimages.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 06:45:03 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 00:14:15 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 08:09:22 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 20:16:29 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Nijkamp", "Erik", ""], ["Hill", "Mitch", ""], ["Han", "Tian", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1903.12384", "submitter": "Andreas Heinecke", "authors": "Andreas Heinecke, Wen-Liang Hwang", "title": "Deep Representation with ReLU Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deep feedforward neural networks with rectified linear units from\na signal processing perspective. In this view, such representations mark the\ntransition from using a single (data-driven) linear representation to utilizing\na large collection of affine linear representations tailored to particular\nregions of the signal space. This paper provides a precise description of the\nindividual affine linear representations and corresponding domain regions that\nthe (data-driven) neural network associates to each signal of the input space.\nIn particular, we describe atomic decompositions of the representations and,\nbased on estimating their Lipschitz regularity, suggest some conditions that\ncan stabilize learning independent of the network depth. Such an analysis may\npromote further theoretical insight from both the signal processing and machine\nlearning communities.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:12:39 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Heinecke", "Andreas", ""], ["Hwang", "Wen-Liang", ""]]}, {"id": "1903.12389", "submitter": "Junichi Yamagishi", "authors": "Mingyang Zhang, Xin Wang, Fuming Fang, Haizhou Li, Junichi Yamagishi", "title": "Joint training framework for text-to-speech and voice conversion using\n  multi-source Tacotron and WaveNet", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the training of a shared model for both text-to-speech (TTS)\nand voice conversion (VC) tasks. We propose using an extended model\narchitecture of Tacotron, that is a multi-source sequence-to-sequence model\nwith a dual attention mechanism as the shared model for both the TTS and VC\ntasks. This model can accomplish these two different tasks respectively\naccording to the type of input. An end-to-end speech synthesis task is\nconducted when the model is given text as the input while a\nsequence-to-sequence voice conversion task is conducted when it is given the\nspeech of a source speaker as the input. Waveform signals are generated by\nusing WaveNet, which is conditioned by using a predicted mel-spectrogram. We\npropose jointly training a shared model as a decoder for a target speaker that\nsupports multiple sources. Listening experiments show that our proposed\nmulti-source encoder-decoder model can efficiently achieve both the TTS and VC\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:26:13 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 23:40:14 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhang", "Mingyang", ""], ["Wang", "Xin", ""], ["Fang", "Fuming", ""], ["Li", "Haizhou", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1903.12392", "submitter": "Junichi Yamagishi", "authors": "Shinji Takaki, Hirokazu Kameoka, Junichi Yamagishi", "title": "Training a Neural Speech Waveform Model using Spectral Losses of\n  Short-Time Fourier Transform and Continuous Wavelet Transform", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we proposed short-time Fourier transform (STFT)-based loss\nfunctions for training a neural speech waveform model. In this paper, we\ngeneralize the above framework and propose a training scheme for such models\nbased on spectral amplitude and phase losses obtained by either STFT or\ncontinuous wavelet transform (CWT), or both of them. Since CWT is capable of\nhaving time and frequency resolutions different from those of STFT and is cable\nof considering those closer to human auditory scales, the proposed loss\nfunctions could provide complementary information on speech signals.\nExperimental results showed that it is possible to train a high-quality model\nby using the proposed CWT spectral loss and is as good as one using STFT-based\nloss.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:36:06 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 23:37:21 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Takaki", "Shinji", ""], ["Kameoka", "Hirokazu", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1903.12394", "submitter": "Laura von Rueden", "authors": "Laura von Rueden, Sebastian Mayer, Katharina Beckh, Bogdan Georgiev,\n  Sven Giesselbach, Raoul Heese, Birgit Kirsch, Julius Pfrommer, Annika Pick,\n  Rajkumar Ramamurthy, Michal Walczak, Jochen Garcke, Christian Bauckhage,\n  Jannis Schuecker", "title": "Informed Machine Learning -- A Taxonomy and Survey of Integrating\n  Knowledge into Learning Systems", "comments": "Accepted at IEEE Transactions on Knowledge and Data Engineering:\n  https://ieeexplore.ieee.org/document/9429985", "journal-ref": null, "doi": "10.1109/TKDE.2021.3079836", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite its great success, machine learning can have its limits when dealing\nwith insufficient training data. A potential solution is the additional\nintegration of prior knowledge into the training process which leads to the\nnotion of informed machine learning. In this paper, we present a structured\noverview of various approaches in this field. We provide a definition and\npropose a concept for informed machine learning which illustrates its building\nblocks and distinguishes it from conventional machine learning. We introduce a\ntaxonomy that serves as a classification framework for informed machine\nlearning approaches. It considers the source of knowledge, its representation,\nand its integration into the machine learning pipeline. Based on this taxonomy,\nwe survey related research and describe how different knowledge representations\nsuch as algebraic equations, logic rules, or simulation results can be used in\nlearning systems. This evaluation of numerous papers on the basis of our\ntaxonomy uncovers key methods in the field of informed machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:37:40 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 21:10:43 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 07:34:41 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["von Rueden", "Laura", ""], ["Mayer", "Sebastian", ""], ["Beckh", "Katharina", ""], ["Georgiev", "Bogdan", ""], ["Giesselbach", "Sven", ""], ["Heese", "Raoul", ""], ["Kirsch", "Birgit", ""], ["Pfrommer", "Julius", ""], ["Pick", "Annika", ""], ["Ramamurthy", "Rajkumar", ""], ["Walczak", "Michal", ""], ["Garcke", "Jochen", ""], ["Bauckhage", "Christian", ""], ["Schuecker", "Jannis", ""]]}, {"id": "1903.12416", "submitter": "Zal\\'an Borsos", "authors": "Zal\\'an Borsos, Sebastian Curi, Kfir Y. Levy, Andreas Krause", "title": "Online Variance Reduction with Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive importance sampling for stochastic optimization is a promising\napproach that offers improved convergence through variance reduction. In this\nwork, we propose a new framework for variance reduction that enables the use of\nmixtures over predefined sampling distributions, which can naturally encode\nprior knowledge about the data. While these sampling distributions are fixed,\nthe mixture weights are adapted during the optimization process. We propose\nVRM, a novel and efficient adaptive scheme that asymptotically recovers the\nbest mixture weights in hindsight and can also accommodate sampling\ndistributions over sets of points. We empirically demonstrate the versatility\nof VRM in a range of applications.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 09:41:57 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Borsos", "Zal\u00e1n", ""], ["Curi", "Sebastian", ""], ["Levy", "Kfir Y.", ""], ["Krause", "Andreas", ""]]}, {"id": "1903.12436", "submitter": "Partha Ghosh", "authors": "Partha Ghosh, Mehdi S. M. Sajjadi, Antonio Vergari, Michael Black,\n  Bernhard Sch\\\"olkopf", "title": "From Variational to Deterministic Autoencoders", "comments": "Partha Ghosh and Mehdi S. M. Sajjadi contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) provide a theoretically-backed and popular\nframework for deep generative models. However, learning a VAE from data poses\nstill unanswered theoretical questions and considerable practical challenges.\nIn this work, we propose an alternative framework for generative modeling that\nis simpler, easier to train, and deterministic, yet has many of the advantages\nof VAEs. We observe that sampling a stochastic encoder in a Gaussian VAE can be\ninterpreted as simply injecting noise into the input of a deterministic\ndecoder. We investigate how substituting this kind of stochasticity, with other\nexplicit and implicit regularization schemes, can lead to an equally smooth and\nmeaningful latent space without forcing it to conform to an arbitrarily chosen\nprior. To retrieve a generative mechanism to sample new data, we introduce an\nex-post density estimation step that can be readily applied also to existing\nVAEs, improving their sample quality. We show, in a rigorous empirical study,\nthat the proposed regularized deterministic autoencoders are able to generate\nsamples that are comparable to, or better than, those of VAEs and more powerful\nalternatives when applied to images as well as to structured data such as\nmolecules. \\footnote{An implementation is available at:\n\\url{https://github.com/ParthaEth/Regularized_autoencoders-RAE-}}\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 10:31:55 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 13:00:21 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 22:35:33 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 09:18:24 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ghosh", "Partha", ""], ["Sajjadi", "Mehdi S. M.", ""], ["Vergari", "Antonio", ""], ["Black", "Michael", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1903.12483", "submitter": "Saulo Martiello Mastelini", "authors": "Saulo Martiello Mastelini, Sylvio Barbon Jr., Andr\\'e Carlos Ponce de\n  Leon Ferreira de Carvalho", "title": "Online Multi-target regression trees with stacked leaf models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the current challenges in machine learning is how to deal with data\ncoming at increasing rates in data streams. New predictive learning strategies\nare needed to cope with the high throughput data and concept drift. One of the\ndata stream mining tasks where new learning strategies are needed is\nmulti-target regression, due to its applicability in a high number of real\nworld problems. While reliable and effective learning strategies have been\nproposed for batch multi-target regression, few have been proposed for\nmulti-target online learning in data streams. Besides, most of the existing\nsolutions do not consider the occurrence of inter-target correlations when\nmaking predictions. In this work, we propose a novel online learning strategy\nfor multi-target regression in data streams. The proposed strategy extends\nexisting online decision tree learning algorithm to explore inter-target\ndependencies while making predictions. For such, the proposed strategy, called\nStacked Single-target Hoeffding Tree (SST-HT), uses the inter-target\ndependencies as an additional information source to enhance predictive\naccuracy. Throughout an extensive experimental setup, we evaluate our proposal\nagainst state-of-the-art decision tree-based algorithms for online multi-target\nregression. According to the experimental results, SST-HT presents superior\npredictive accuracy, with a small increase in the processing time and memory\nrequirements.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 12:42:03 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 12:21:44 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 19:50:03 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 17:59:39 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Mastelini", "Saulo Martiello", ""], ["Barbon", "Sylvio", "Jr."], ["de Carvalho", "Andr\u00e9 Carlos Ponce de Leon Ferreira", ""]]}, {"id": "1903.12489", "submitter": "Elnaz Soleimani", "authors": "Elnaz Soleimani, Ehsan Nazerfard", "title": "Cross-Subject Transfer Learning in Human Activity Recognition Systems\n  using Generative Adversarial Networks", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": "10.1016/j.neucom.2020.10.056", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application of intelligent systems especially in smart homes and\nhealth-related topics has been drawing more attention in the last decades.\nTraining Human Activity Recognition (HAR) models -- as a major module --\nrequires a fair amount of labeled data. Despite training with large datasets,\nmost of the existing models will face a dramatic performance drop when they are\ntested against unseen data from new users. Moreover, recording enough data for\neach new user is unviable due to the limitations and challenges of working with\nhuman users. Transfer learning techniques aim to transfer the knowledge which\nhas been learned from the source domain (subject) to the target domain in order\nto decrease the models' performance loss in the target domain. This paper\npresents a novel method of adversarial knowledge transfer named SA-GAN stands\nfor Subject Adaptor GAN which utilizes Generative Adversarial Network framework\nto perform cross-subject transfer learning in the domain of wearable\nsensor-based Human Activity Recognition. SA-GAN outperformed other\nstate-of-the-art methods in more than 66% of experiments and showed the second\nbest performance in the remaining 25% of experiments. In some cases, it reached\nup to 90% of the accuracy which can be obtained by supervised training over the\nsame domain data.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 12:50:04 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Soleimani", "Elnaz", ""], ["Nazerfard", "Ehsan", ""]]}, {"id": "1903.12519", "submitter": "Matthew Mirman", "authors": "Matthew Mirman, Gagandeep Singh, Martin Vechev", "title": "A Provable Defense for Deep Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a training system, which can provably defend significantly larger\nneural networks than previously possible, including ResNet-34 and DenseNet-100.\nOur approach is based on differentiable abstract interpretation and introduces\ntwo novel concepts: (i) abstract layers for fine-tuning the precision and\nscalability of the abstraction, (ii) a flexible domain specific language (DSL)\nfor describing training objectives that combine abstract and concrete losses\nwith arbitrary specifications. Our training method is implemented in the DiffAI\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 13:35:31 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 14:50:42 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mirman", "Matthew", ""], ["Singh", "Gagandeep", ""], ["Vechev", "Martin", ""]]}, {"id": "1903.12536", "submitter": "Vignesh R", "authors": "Vignesh Ravichandran, Balamurali Murugesan, Sharath M\n  Shankaranarayana, Keerthi Ram, Preejith S.P, Jayaraj Joseph and Mohanasankar\n  Sivaprakasam", "title": "Deep Network for Capacitive ECG Denoising", "comments": "Accepted IEEE MEMEA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous monitoring of cardiac health under free living condition is\ncrucial to provide effective care for patients undergoing post operative\nrecovery and individuals with high cardiac risk like the elderly. Capacitive\nElectrocardiogram (cECG) is one such technology which allows comfortable and\nlong term monitoring through its ability to measure biopotential in conditions\nwithout having skin contact. cECG monitoring can be done using many household\nobjects like chairs, beds and even car seats allowing for seamless monitoring\nof individuals. This method is unfortunately highly susceptible to motion\nartifacts which greatly limits its usage in clinical practice. The current use\nof cECG systems has been limited to performing rhythmic analysis. In this paper\nwe propose a novel end-to-end deep learning architecture to perform the task of\ndenoising capacitive ECG. The proposed network is trained using motion\ncorrupted three channel cECG and a reference LEAD I ECG collected on\nindividuals while driving a car. Further, we also propose a novel joint loss\nfunction to apply loss on both signal and frequency domain. We conduct\nextensive rhythmic analysis on the model predictions and the ground truth. We\nfurther evaluate the signal denoising using Mean Square Error(MSE) and Cross\nCorrelation between model predictions and ground truth. We report MSE of 0.167\nand Cross Correlation of 0.476. The reported results highlight the feasibility\nof performing morphological analysis using the filtered cECG. The proposed\napproach can allow for continuous and comprehensive monitoring of the\nindividuals in free living conditions.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 14:23:01 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Ravichandran", "Vignesh", ""], ["Murugesan", "Balamurali", ""], ["Shankaranarayana", "Sharath M", ""], ["Ram", "Keerthi", ""], ["P", "Preejith S.", ""], ["Joseph", "Jayaraj", ""], ["Sivaprakasam", "Mohanasankar", ""]]}, {"id": "1903.12549", "submitter": "Alireza Koochali", "authors": "Alireza Koochali, Peter Schichtel, Sheraz Ahmed and Andreas Dengel", "title": "Probabilistic Forecasting of Sensory Data with Generative Adversarial\n  Networks - ForGAN", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2915544", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is one of the challenging problems for humankind.\nTraditional forecasting methods using mean regression models have severe\nshortcomings in reflecting real-world fluctuations. While new probabilistic\nmethods rush to rescue, they fight with technical difficulties like quantile\ncrossing or selecting a prior distribution. To meld the different strengths of\nthese fields while avoiding their weaknesses as well as to push the boundary of\nthe state-of-the-art, we introduce ForGAN - one step ahead probabilistic\nforecasting with generative adversarial networks. ForGAN utilizes the power of\nthe conditional generative adversarial network to learn the data generating\ndistribution and compute probabilistic forecasts from it. We argue how to\nevaluate ForGAN in opposition to regression methods. To investigate\nprobabilistic forecasting of ForGAN, we create a new dataset and demonstrate\nour method abilities on it. This dataset will be made publicly available for\ncomparison. Furthermore, we test ForGAN on two publicly available datasets,\nnamely Mackey-Glass dataset and Internet traffic dataset (A5M) where the\nimpressive performance of ForGAN demonstrate its high capability in forecasting\nfuture values.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 14:39:00 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Koochali", "Alireza", ""], ["Schichtel", "Peter", ""], ["Ahmed", "Sheraz", ""], ["Dengel", "Andreas", ""]]}, {"id": "1903.12577", "submitter": "Sebastijan Dumancic", "authors": "Sebastijan Dumancic, Tias Guns, Wannes Meert, Hendrik Blockeel", "title": "Learning Relational Representations with Auto-encoding Logic Programs", "comments": "8 pages,4 figures, paper + supplement, published at IJCAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods capable of handling relational data have proliferated\nover the last years. In contrast to traditional relational learning methods\nthat leverage first-order logic for representing such data, these deep learning\nmethods aim at re-representing symbolic relational data in Euclidean spaces.\nThey offer better scalability, but can only numerically approximate relational\nstructures and are less flexible in terms of reasoning tasks supported. This\npaper introduces a novel framework for relational representation learning that\ncombines the best of both worlds. This framework, inspired by the auto-encoding\nprinciple, uses first-order logic as a data representation language, and the\nmapping between the original and latent representation is done by means of\nlogic programs instead of neural networks. We show how learning can be cast as\na constraint optimisation problem for which existing solvers can be used. The\nuse of logic as a representation language makes the proposed framework more\naccurate (as the representation is exact, rather than approximate), more\nflexible, and more interpretable than deep learning methods. We experimentally\nshow that these latent representations are indeed beneficial in relational\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:38:02 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 16:32:33 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Dumancic", "Sebastijan", ""], ["Guns", "Tias", ""], ["Meert", "Wannes", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1903.12584", "submitter": "Erik Drysdale", "authors": "Erik Drysdale, Yingwei Peng, Timothy P. Hanna, Paul Nguyen, Anna\n  Goldenberg", "title": "The False Positive Control Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensional settings where a small number of regressors are expected\nto be important, the Lasso estimator can be used to obtain a sparse solution\nvector with the expectation that most of the non-zero coefficients are\nassociated with true signals. While several approaches have been developed to\ncontrol the inclusion of false predictors with the Lasso, these approaches are\nlimited by relying on asymptotic theory, having to empirically estimate terms\nbased on theoretical quantities, assuming a continuous response class with\nGaussian noise and design matrices, or high computation costs. In this paper we\nshow how: (1) an existing model (the SQRT-Lasso) can be recast as a method of\ncontrolling the number of expected false positives, (2) how a similar estimator\ncan used for all other generalized linear model classes, and (3) this approach\ncan be fit with existing fast Lasso optimization solvers. Our justification for\nfalse positive control using randomly weighted self-normalized sum theory is to\nour knowledge novel. Moreover, our estimator's properties hold in finite\nsamples up to some approximation error which we find in practical settings to\nbe negligible under a strict mutual incoherence condition.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:50:43 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Drysdale", "Erik", ""], ["Peng", "Yingwei", ""], ["Hanna", "Timothy P.", ""], ["Nguyen", "Paul", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1903.12600", "submitter": "Marek Rychlik", "authors": "Marek Rychlik", "title": "A proof of convergence of multi-class logistic regression network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the special type of a neural network known under two\nnames. In the statistics and machine learning community it is known as a\nmulti-class logistic regression neural network. In the neural network\ncommunity, it is simply the soft-max layer. The importance is underscored by\nits role in deep learning: as the last layer, whose autput is actually the\nclassification of the input patterns, such as images. Our exposition focuses on\nmathematically rigorous derivation of the key equation expressing the gradient.\nThe fringe benefit of our approach is a fully vectorized expression, which is a\nbasis of an efficient implementation. The second result of this paper is the\npositivity of the second derivative of the cross-entropy loss function as\nfunction of the weights. This result proves that optimization methods based on\nconvexity may be used to train this network. As a corollary, we demonstrate\nthat no $L^2$-regularizer is needed to guarantee convergence of gradient\ndescent.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 16:26:52 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 02:37:27 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 22:30:38 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 19:40:40 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Rychlik", "Marek", ""]]}, {"id": "1903.12648", "submitter": "Kibok Lee", "authors": "Kibok Lee, Kimin Lee, Jinwoo Shin, Honglak Lee", "title": "Overcoming Catastrophic Forgetting with Unlabeled Data in the Wild", "comments": "ICCV 2019; v3 updated Figure 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning with deep neural networks is well-known to suffer from\ncatastrophic forgetting: the performance on previous tasks drastically degrades\nwhen learning a new task. To alleviate this effect, we propose to leverage a\nlarge stream of unlabeled data easily obtainable in the wild. In particular, we\ndesign a novel class-incremental learning scheme with (a) a new distillation\nloss, termed global distillation, (b) a learning strategy to avoid overfitting\nto the most recent task, and (c) a confidence-based sampling method to\neffectively leverage unlabeled external data. Our experimental results on\nvarious datasets, including CIFAR and ImageNet, demonstrate the superiority of\nthe proposed methods over prior methods, particularly when a stream of\nunlabeled data is accessible: our method shows up to 15.8% higher accuracy and\n46.5% less forgetting compared to the state-of-the-art method. The code is\navailable at https://github.com/kibok90/iccv2019-inc.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 17:48:15 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 08:43:25 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 17:17:50 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lee", "Kibok", ""], ["Lee", "Kimin", ""], ["Shin", "Jinwoo", ""], ["Lee", "Honglak", ""]]}, {"id": "1903.12650", "submitter": "Masafumi Yamazaki", "authors": "Masafumi Yamazaki, Akihiko Kasagi, Akihiro Tabuchi, Takumi Honda,\n  Masahiro Miwa, Naoto Fukumoto, Tsuguchika Tabaru, Atsushi Ike, Kohta\n  Nakashima", "title": "Yet Another Accelerated SGD: ResNet-50 Training on ImageNet in 74.7\n  seconds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a strong demand for algorithms that can execute machine\nlearning as faster as possible and the speed of deep learning has accelerated\nby 30 times only in the past two years. Distributed deep learning using the\nlarge mini-batch is a key technology to address the demand and is a great\nchallenge as it is difficult to achieve high scalability on large clusters\nwithout compromising accuracy. In this paper, we introduce optimization methods\nwhich we applied to this challenge. We achieved the training time of 74.7\nseconds using 2,048 GPUs on ABCI cluster applying these methods. The training\nthroughput is over 1.73 million images/sec and the top-1 validation accuracy is\n75.08%.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 17:55:31 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Yamazaki", "Masafumi", ""], ["Kasagi", "Akihiko", ""], ["Tabuchi", "Akihiro", ""], ["Honda", "Takumi", ""], ["Miwa", "Masahiro", ""], ["Fukumoto", "Naoto", ""], ["Tabaru", "Tsuguchika", ""], ["Ike", "Atsushi", ""], ["Nakashima", "Kohta", ""]]}]