[{"id": "2009.00003", "submitter": "Andrew Allmon", "authors": "Andrew G. Allmon, J.S. Marron, and Michael G. Hudgens", "title": "diproperm: An R Package for the DiProPerm Test", "comments": "Package located at https://github.com/allmondrew/diproperm", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional low sample size (HDLSS) data sets emerge frequently in many\nbiomedical applications. A common task for analyzing HDLSS data is to assign\ndata to the correct class using a classifier. Classifiers which use two labels\nand a linear combination of features are known as binary linear classifiers.\nThe direction-projection-permutation (DiProPerm) test was developed for testing\nthe difference of two high-dimensional distributions induced by a binary linear\nclassifier. This paper discusses the key components of the DiProPerm test,\nintroduces the diproperm R package, and demonstrates the package on a\nreal-world data set.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 20:14:26 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Allmon", "Andrew G.", ""], ["Marron", "J. S.", ""], ["Hudgens", "Michael G.", ""]]}, {"id": "2009.00038", "submitter": "Panagiota Birmpa", "authors": "Panagiota Birmpa, Markos A. Katsoulakis", "title": "Uncertainty quantification for Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an information-based uncertainty quantification method for general\nMarkov Random Fields. Markov Random Fields (MRF) are structured, probabilistic\ngraphical models over undirected graphs, and provide a fundamental unifying\nmodeling tool for statistical mechanics, probabilistic machine learning, and\nartificial intelligence. Typically MRFs are complex and high-dimensional with\nnodes and edges (connections) built in a modular fashion from simpler,\nlow-dimensional probabilistic models and their local connections; in turn, this\nmodularity allows to incorporate available data to MRFs and efficiently\nsimulate them by leveraging their graph-theoretic structure. Learning graphical\nmodels from data and/or constructing them from physical modeling and\nconstraints necessarily involves uncertainties inherited from data, modeling\nchoices, or numerical approximations. These uncertainties in the MRF can be\nmanifested either in the graph structure or the probability distribution\nfunctions, and necessarily will propagate in predictions for quantities of\ninterest. Here we quantify such uncertainties using tight, information based\nbounds on the predictions of quantities of interest; these bounds take\nadvantage of the graphical structure of MRFs and are capable of handling the\ninherent high-dimensionality of such graphical models. We demonstrate our\nmethods in MRFs for medical diagnostics and statistical mechanics models. In\nthe latter, we develop uncertainty quantification bounds for finite size\neffects and phase diagrams, which constitute two of the typical predictions\ngoals of statistical mechanics modeling.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 18:07:24 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 02:18:47 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 04:35:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Birmpa", "Panagiota", ""], ["Katsoulakis", "Markos A.", ""]]}, {"id": "2009.00089", "submitter": "Dai Feng", "authors": "Dai Feng and Richard Baumgartner", "title": "Random Forest (RF) Kernel for Regression, Classification and Survival", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breiman's random forest (RF) can be interpreted as an implicit kernel\ngenerator,where the ensuing proximity matrix represents the data-driven RF\nkernel. Kernel perspective on the RF has been used to develop a principled\nframework for theoretical investigation of its statistical properties. However,\npractical utility of the links between kernels and the RF has not been widely\nexplored and systematically evaluated.Focus of our work is investigation of the\ninterplay between kernel methods and the RF. We elucidate the performance and\nproperties of the data driven RF kernels used by regularized linear models in a\ncomprehensive simulation study comprising of continuous, binary and survival\ntargets. We show that for continuous and survival targets, the RF kernels are\ncompetitive to RF in higher dimensional scenarios with larger number of noisy\nfeatures. For the binary target, the RF kernel and RF exhibit comparable\nperformance. As the RF kernel asymptotically converges to the Laplace kernel,\nwe included it in our evaluation. For most simulation setups, the RF and\nRFkernel outperformed the Laplace kernel. Nevertheless, in some cases the\nLaplace kernel was competitive, showing its potential value for applications.\nWe also provide the results from real life data sets for the regression,\nclassification and survival to illustrate how these insights may be leveraged\nin practice.Finally, we discuss further extensions of the RF kernels in the\ncontext of interpretable prototype and landmarking classification, regression\nand survival. We outline future line of research for kernels furnished by\nBayesian counterparts of the RF.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 20:21:27 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Feng", "Dai", ""], ["Baumgartner", "Richard", ""]]}, {"id": "2009.00093", "submitter": "Zheda Mai", "authors": "Dongsub Shim, Zheda Mai, Jihwan Jeong, Scott Sanner, Hyunwoo Kim,\n  Jongseong Jang", "title": "Online Class-Incremental Continual Learning with Adversarial Shapley\n  Value", "comments": "Proceedings of the 35th AAAI Conference on Artificial Intelligence\n  (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As image-based deep learning becomes pervasive on every device, from cell\nphones to smart watches, there is a growing need to develop methods that\ncontinually learn from data while minimizing memory footprint and power\nconsumption. While memory replay techniques have shown exceptional promise for\nthis task of continual learning, the best method for selecting which buffered\nimages to replay is still an open question. In this paper, we specifically\nfocus on the online class-incremental setting where a model needs to learn new\nclasses continually from an online data stream. To this end, we contribute a\nnovel Adversarial Shapley value scoring method that scores memory data samples\naccording to their ability to preserve latent decision boundaries for\npreviously observed classes (to maintain learning stability and avoid\nforgetting) while interfering with latent decision boundaries of current\nclasses being learned (to encourage plasticity and optimal learning of new\nclass boundaries). Overall, we observe that our proposed ASER method provides\ncompetitive or improved performance compared to state-of-the-art replay-based\ncontinual learning methods on a variety of datasets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 20:52:27 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 07:27:00 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 03:05:46 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 20:03:10 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Shim", "Dongsub", ""], ["Mai", "Zheda", ""], ["Jeong", "Jihwan", ""], ["Sanner", "Scott", ""], ["Kim", "Hyunwoo", ""], ["Jang", "Jongseong", ""]]}, {"id": "2009.00097", "submitter": "Linjun Zhou", "authors": "Linjun Zhou, Peng Cui, Yinan Jiang, Shiqiang Yang", "title": "Adversarial Eigen Attack on Black-Box Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box adversarial attack has attracted a lot of research interests for\nits practical use in AI safety. Compared with the white-box attack, a black-box\nsetting is more difficult for less available information related to the\nattacked model and the additional constraint on the query budget. A general way\nto improve the attack efficiency is to draw support from a pre-trained\ntransferable white-box model. In this paper, we propose a novel setting of\ntransferable black-box attack: attackers may use external information from a\npre-trained model with available network parameters, however, different from\nprevious studies, no additional training data is permitted to further change or\ntune the pre-trained model. To this end, we further propose a new algorithm,\nEigenBA to tackle this problem. Our method aims to explore more gradient\ninformation of the black-box model, and promote the attack efficiency, while\nkeeping the perturbation to the original attacked image small, by leveraging\nthe Jacobian matrix of the pre-trained white-box model. We show the optimal\nperturbations are closely related to the right singular vectors of the Jacobian\nmatrix. Further experiments on ImageNet and CIFAR-10 show that even the\nunlearnable pre-trained white-box model could also significantly boost the\nefficiency of the black-box attack and our proposed method could further\nimprove the attack efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 07:37:43 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Zhou", "Linjun", ""], ["Cui", "Peng", ""], ["Jiang", "Yinan", ""], ["Yang", "Shiqiang", ""]]}, {"id": "2009.00131", "submitter": "Prasanth Shyamsundar", "authors": "Konstantin T. Matchev, Prasanth Shyamsundar", "title": "InClass Nets: Independent Classifier Networks for Nonparametric\n  Estimation of Conditional Independence Mixture Models and Unsupervised\n  Classification", "comments": "46 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM hep-ph physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new machine-learning-based approach, which we call the\nIndependent Classifier networks (InClass nets) technique, for the\nnonparameteric estimation of conditional independence mixture models (CIMMs).\nWe approach the estimation of a CIMM as a multi-class classification problem,\nsince dividing the dataset into different categories naturally leads to the\nestimation of the mixture model. InClass nets consist of multiple independent\nclassifier neural networks (NNs), each of which handles one of the variates of\nthe CIMM. Fitting the CIMM to the data is performed by simultaneously training\nthe individual NNs using suitable cost functions. The ability of NNs to\napproximate arbitrary functions makes our technique nonparametric. Further\nleveraging the power of NNs, we allow the conditionally independent variates of\nthe model to be individually high-dimensional, which is the main advantage of\nour technique over existing non-machine-learning-based approaches. We derive\nsome new results on the nonparametric identifiability of bivariate CIMMs, in\nthe form of a necessary and a (different) sufficient condition for a bivariate\nCIMM to be identifiable. We provide a public implementation of InClass nets as\na Python package called RainDancesVI and validate our InClass nets technique\nwith several worked out examples. Our method also has applications in\nunsupervised and semi-supervised classification problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 22:24:09 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Matchev", "Konstantin T.", ""], ["Shyamsundar", "Prasanth", ""]]}, {"id": "2009.00133", "submitter": "Siqi Sun", "authors": "Siqi Sun", "title": "Unsupervised and Supervised Structure Learning for Protein Contact\n  Prediction", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein contacts provide key information for the understanding of protein\nstructure and function, and therefore contact prediction from sequences is an\nimportant problem. Recent research shows that some correctly predicted\nlong-range contacts could help topology-level structure modeling. Thus, contact\nprediction and contact-assisted protein folding also proves the importance of\nthis problem. In this thesis, I will briefly introduce the extant related work,\nthen show how to establish the contact prediction through unsupervised\ngraphical models with topology constraints. Further, I will explain how to use\nthe supervised deep learning methods to further boost the accuracy of contact\nprediction. Finally, I will propose a scoring system called diversity score to\nmeasure the novelty of contact predictions, as well as an algorithm that\npredicts contacts with respect to the new scoring system.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 22:37:16 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Sun", "Siqi", ""]]}, {"id": "2009.00142", "submitter": "Pan Li", "authors": "Pan Li, Yanbang Wang, Hongwei Wang, Jure Leskovec", "title": "Distance Encoding: Design Provably More Powerful Neural Networks for\n  Graph Representation Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations of sets of nodes in a graph is crucial for\napplications ranging from node-role discovery to link prediction and molecule\nclassification. Graph Neural Networks (GNNs) have achieved great success in\ngraph representation learning. However, expressive power of GNNs is limited by\nthe 1-Weisfeiler-Lehman (WL) test and thus GNNs generate identical\nrepresentations for graph substructures that may in fact be very different.\nMore powerful GNNs, proposed recently by mimicking higher-order-WL tests, only\nfocus on representing entire graphs and they are computationally inefficient as\nthey cannot utilize sparsity of the underlying graph. Here we propose and\nmathematically analyze a general class of structure-related features, termed\nDistance Encoding (DE). DE assists GNNs in representing any set of nodes, while\nproviding strictly more expressive power than the 1-WL test. DE captures the\ndistance between the node set whose representation is to be learned and each\nnode in the graph. To capture the distance DE can apply various graph-distance\nmeasures such as shortest path distance or generalized PageRank scores. We\npropose two ways for GNNs to use DEs (1) as extra node features, and (2) as\ncontrollers of message aggregation in GNNs. Both approaches can utilize the\nsparse structure of the underlying graph, which leads to computational\nefficiency and scalability. We also prove that DE can distinguish node sets\nembedded in almost all regular graphs where traditional GNNs always fail. We\nevaluate DE on three tasks over six real networks: structural role prediction,\nlink prediction, and triangle prediction. Results show that our models\noutperform GNNs without DE by up-to 15\\% in accuracy and AUROC. Furthermore,\nour models also significantly outperform other state-of-the-art methods\nespecially designed for the above tasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 23:15:40 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 15:18:27 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 15:46:32 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 17:11:07 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Li", "Pan", ""], ["Wang", "Yanbang", ""], ["Wang", "Hongwei", ""], ["Leskovec", "Jure", ""]]}, {"id": "2009.00162", "submitter": "Yue Guan", "authors": "Yue Guan, Qifan Zhang, Panagiotis Tsiotras", "title": "Learning Nash Equilibria in Zero-Sum Stochastic Games via\n  Entropy-Regularized Policy Approximation", "comments": "Accepted at IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of policy approximations to reduce the computational cost\nof learning Nash equilibria in zero-sum stochastic games. We propose a new\nQ-learning type algorithm that uses a sequence of entropy-regularized soft\npolicies to approximate the Nash policy during the Q-function updates. We prove\nthat under certain conditions, by updating the regularized Q-function, the\nalgorithm converges to a Nash equilibrium. We also demonstrate the proposed\nalgorithm's ability to transfer previous training experiences, enabling the\nagents to adapt quickly to new environments. We provide a dynamic\nhyper-parameter scheduling scheme to further expedite convergence. Empirical\nresults applied to a number of stochastic games verify that the proposed\nalgorithm converges to the Nash equilibrium, while exhibiting a major speed-up\nover existing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:03:44 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 04:26:01 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Guan", "Yue", ""], ["Zhang", "Qifan", ""], ["Tsiotras", "Panagiotis", ""]]}, {"id": "2009.00169", "submitter": "Yang Wang", "authors": "Yang Wang", "title": "A Mathematical Introduction to Generative Adversarial Nets (GAN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Nets (GAN) have received considerable attention since\nthe 2014 groundbreaking work by Goodfellow et al. Such attention has led to an\nexplosion in new ideas, techniques and applications of GANs. To better\nunderstand GANs we need to understand the mathematical foundation behind them.\nThis paper attempts to provide an overview of GANs from a mathematical point of\nview. Many students in mathematics may find the papers on GANs more difficulty\nto fully understand because most of them are written from computer science and\nengineer point of view. The aim of this paper is to give more mathematically\noriented students an introduction to GANs in a language that is more familiar\nto them.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:31:47 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wang", "Yang", ""]]}, {"id": "2009.00236", "submitter": "Pengzhen Ren", "authors": "Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li,\n  Xiaojiang Chen and Xin Wang", "title": "A Survey of Deep Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) attempts to maximize the performance gain of the model\nby marking the fewest samples. Deep learning (DL) is greedy for data and\nrequires a large amount of data supply to optimize massive parameters, so that\nthe model learns how to extract high-quality features. In recent years, due to\nthe rapid development of internet technology, we are in an era of information\ntorrents and we have massive amounts of data. In this way, DL has aroused\nstrong interest of researchers and has been rapidly developed. Compared with\nDL, researchers have relatively low interest in AL. This is mainly because\nbefore the rise of DL, traditional machine learning requires relatively few\nlabeled samples. Therefore, early AL is difficult to reflect the value it\ndeserves. Although DL has made breakthroughs in various fields, most of this\nsuccess is due to the publicity of the large number of existing annotation\ndatasets. However, the acquisition of a large number of high-quality annotated\ndatasets consumes a lot of manpower, which is not allowed in some fields that\nrequire high expertise, especially in the fields of speech recognition,\ninformation extraction, medical images, etc. Therefore, AL has gradually\nreceived due attention. A natural idea is whether AL can be used to reduce the\ncost of sample annotations, while retaining the powerful learning capabilities\nof DL. Therefore, deep active learning (DAL) has emerged. Although the related\nresearch has been quite abundant, it lacks a comprehensive survey of DAL. This\narticle is to fill this gap, we provide a formal classification method for the\nexisting work, and a comprehensive and systematic overview. In addition, we\nalso analyzed and summarized the development of DAL from the perspective of\napplication. Finally, we discussed the confusion and problems in DAL, and gave\nsome possible development directions for DAL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 04:28:31 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ren", "Pengzhen", ""], ["Xiao", "Yun", ""], ["Chang", "Xiaojun", ""], ["Huang", "Po-Yao", ""], ["Li", "Zhihui", ""], ["Chen", "Xiaojiang", ""], ["Wang", "Xin", ""]]}, {"id": "2009.00237", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat and Bogdan Gabrys", "title": "An in-depth comparison of methods handling mixed-attribute data for\n  general fuzzy min-max neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A general fuzzy min-max (GFMM) neural network is one of the efficient\nneuro-fuzzy systems for classification problems. However, a disadvantage of\nmost of the current learning algorithms for GFMM is that they can handle\neffectively numerical valued features only. Therefore, this paper provides some\npotential approaches to adapting GFMM learning algorithms for classification\nproblems with mixed-type or only categorical features as they are very common\nin practical applications and often carry very useful information. We will\ncompare and assess three main methods of handling datasets with mixed features,\nincluding the use of encoding methods, the combination of the GFMM model with\nother classifiers, and employing the specific learning algorithms for both\ntypes of features. The experimental results showed that the target and\nJames-Stein are appropriate categorical encoding methods for learning\nalgorithms of GFMM models, while the combination of GFMM neural networks and\ndecision trees is a flexible way to enhance the classification performance of\nGFMM models on datasets with the mixed features. The learning algorithms with\nthe mixed-type feature abilities are potential approaches to deal with\nmixed-attribute data in a natural way, but they need further improvement to\nachieve a better classification accuracy. Based on the analysis, we also\nidentify the strong and weak points of different methods and propose potential\nresearch directions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:12:22 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2009.00254", "submitter": "Sarkar Snigdha Sarathi Das", "authors": "Sarkar Snigdha Sarathi Das, Mohammed Eunus Ali, Yuan-Fang Li, Yong-Bin\n  Kang, Timos Sellis", "title": "Boosting House Price Predictions using Geo-Spatial Network Embedding", "comments": "23 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real estate contributes significantly to all major economies around the\nworld. In particular, house prices have a direct impact on stakeholders,\nranging from house buyers to financing companies. Thus, a plethora of\ntechniques have been developed for real estate price prediction. Most of the\nexisting techniques rely on different house features to build a variety of\nprediction models to predict house prices. Perceiving the effect of spatial\ndependence on house prices, some later works focused on introducing spatial\nregression models for improving prediction performance. However, they fail to\ntake into account the geo-spatial context of the neighborhood amenities such as\nhow close a house is to a train station, or a highly-ranked school, or a\nshopping center. Such contextual information may play a vital role in users'\ninterests in a house and thereby has a direct influence on its price. In this\npaper, we propose to leverage the concept of graph neural networks to capture\nthe geo-spatial context of the neighborhood of a house. In particular, we\npresent a novel method, the Geo-Spatial Network Embedding (GSNE), that learns\nthe embeddings of houses and various types of Points of Interest (POIs) in the\nform of multipartite networks, where the houses and the POIs are represented as\nattributed nodes and the relationships between them as edges. Extensive\nexperiments with a large number of regression techniques show that the\nembeddings produced by our proposed GSNE technique consistently and\nsignificantly improve the performance of the house price prediction task\nregardless of the downstream regression model.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 06:17:21 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Das", "Sarkar Snigdha Sarathi", ""], ["Ali", "Mohammed Eunus", ""], ["Li", "Yuan-Fang", ""], ["Kang", "Yong-Bin", ""], ["Sellis", "Timos", ""]]}, {"id": "2009.00278", "submitter": "Shaolei Ren", "authors": "Bingqian Lu, Jianyi Yang, and Shaolei Ren", "title": "Scaling Up Deep Neural Network Optimization for Edge Inference", "comments": "Position paper. New algorithm added. Part of the content (from\n  Section 5 \"Learning to Optimize\") will be presented in the work-in-progress\n  poster session of the ACM/IEEE Symposium on Edge Computing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been increasingly deployed on and integrated\nwith edge devices, such as mobile phones, drones, robots and wearables. To run\nDNN inference directly on edge devices (a.k.a. edge inference) with a\nsatisfactory performance, optimizing the DNN design (e.g., network architecture\nand quantization policy) is crucial. While state-of-the-art DNN designs have\nleveraged performance predictors to speed up the optimization process, they are\ndevice-specific (i.e., each predictor for only one target device) and hence\ncannot scale well in the presence of extremely diverse edge devices. Moreover,\neven with performance predictors, the optimizer (e.g., search-based\noptimization) can still be time-consuming when optimizing DNNs for many\ndifferent devices. In this work, we propose two approaches to scaling up DNN\noptimization. In the first approach, we reuse the performance predictors built\non a proxy device, and leverage the performance monotonicity to scale up the\nDNN optimization without re-building performance predictors for each different\ndevice. In the second approach, we build scalable performance predictors that\ncan estimate the resulting performance (e.g., inference\naccuracy/latency/energy) given a DNN-device pair, and use a neural\nnetwork-based automated optimizer that takes both device features and\noptimization parameters as input and then directly outputs the optimal DNN\ndesign without going through a lengthy optimization process for each individual\ndevice.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 07:47:22 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 06:06:22 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 07:41:44 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lu", "Bingqian", ""], ["Yang", "Jianyi", ""], ["Ren", "Shaolei", ""]]}, {"id": "2009.00296", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Marco Gori, Simone Marullo, Stefano Melacci", "title": "Developing Constrained Neural Units Over Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a foundational study on a constrained method that\ndefines learning problems with Neural Networks in the context of the principle\nof least cognitive action, which very much resembles the principle of least\naction in mechanics. Starting from a general approach to enforce constraints\ninto the dynamical laws of learning, this work focuses on an alternative way of\ndefining Neural Networks, that is different from the majority of existing\napproaches. In particular, the structure of the neural architecture is defined\nby means of a special class of constraints that are extended also to the\ninteraction with data, leading to \"architectural\" and \"input-related\"\nconstraints, respectively. The proposed theory is cast into the time domain, in\nwhich data are presented to the network in an ordered manner, that makes this\nstudy an important step toward alternative ways of processing continuous\nstreams of data with Neural Networks. The connection with the classic\nBackpropagation-based update rule of the weights of networks is discussed,\nshowing that there are conditions under which our approach degenerates to\nBackpropagation. Moreover, the theory is experimentally evaluated on a simple\nproblem that allows us to deeply study several aspects of the theory itself and\nto show the soundness of the model.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 09:07:25 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""], ["Marullo", "Simone", ""], ["Melacci", "Stefano", ""]]}, {"id": "2009.00298", "submitter": "Quoc Hoan Tran", "authors": "Takahiro Goto, Quoc Hoan Tran, and Kohei Nakajima", "title": "Universal Approximation Property of Quantum Feature Map", "comments": "Main (5 pages, 2 figures); Supplemental material (12 pages, 1\n  figure); Add the evaluation for approximation rate", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoding classical inputs into quantum states is considered a quantum feature\nmap to map classical data into a quantum Hilbert space. This feature map\nprovides opportunities to incorporate quantum advantages into machine learning\nalgorithms to be performed on near-term intermediate-scale quantum computers.\nWhile the quantum feature map has demonstrated its capability when combined\nwith linear classification models in some specific applications, its expressive\npower from the theoretical perspective remains unknown. We prove that the\nquantum feature map is a universal approximator of continuous functions under\nits typical settings in many practical applications. We also study the\ncapability of the quantum feature map in the classification of disjoint\nregions. Our work enables an important theoretical analysis to ensure that\nquantum-enhanced machine learning algorithms based on quantum feature maps can\nhandle a broad class of machine learning tasks. In light of this, one can\ndesign a quantum machine learning model with more powerful expressivity.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 09:09:29 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 15:24:37 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Goto", "Takahiro", ""], ["Tran", "Quoc Hoan", ""], ["Nakajima", "Kohei", ""]]}, {"id": "2009.00329", "submitter": "Giambattista Parascandolo", "authors": "Giambattista Parascandolo, Alexander Neitz, Antonio Orvieto, Luigi\n  Gresele, Bernhard Sch\\\"olkopf", "title": "Learning explanations that are hard to vary", "comments": "From v1: extended 2.2 and 2.3, added details for reproducibility and\n  link to codebase", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the principle that `good explanations are hard\nto vary' in the context of deep learning. We show that averaging gradients\nacross examples -- akin to a logical OR of patterns -- can favor memorization\nand `patchwork' solutions that sew together different strategies, instead of\nidentifying invariances. To inspect this, we first formalize a notion of\nconsistency for minima of the loss surface, which measures to what extent a\nminimum appears only when examples are pooled. We then propose and\nexperimentally validate a simple alternative algorithm based on a logical AND,\nthat focuses on invariances and prevents memorization in a set of real-world\ntasks. Finally, using a synthetic dataset with a clear distinction between\ninvariant and spurious mechanisms, we dissect learning signals and compare this\napproach to well-established regularizers.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 10:17:48 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 14:46:16 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2020 11:32:18 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Parascandolo", "Giambattista", ""], ["Neitz", "Alexander", ""], ["Orvieto", "Antonio", ""], ["Gresele", "Luigi", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2009.00351", "submitter": "Haining Zheng", "authors": "Haining Zheng and Antonio R. Paiva and Chris S. Gurciullo", "title": "Advancing from Predictive Maintenance to Intelligent Maintenance with AI\n  and IIoT", "comments": "The 3rd International Workshop on Artificial Intelligence of Things\n  (AIoT) In conjunction with the 26th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining (KDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Artificial Intelligent (AI) technology advances and increasingly large\namounts of data become readily available via various Industrial Internet of\nThings (IIoT) projects, we evaluate the state of the art of predictive\nmaintenance approaches and propose our innovative framework to improve the\ncurrent practice. The paper first reviews the evolution of reliability\nmodelling technology in the past 90 years and discusses major technologies\ndeveloped in industry and academia. We then introduce the next generation\nmaintenance framework - Intelligent Maintenance, and discuss its key\ncomponents. This AI and IIoT based Intelligent Maintenance framework is\ncomposed of (1) latest machine learning algorithms including probabilistic\nreliability modelling with deep learning, (2) real-time data collection,\ntransfer, and storage through wireless smart sensors, (3) Big Data\ntechnologies, (4) continuously integration and deployment of machine learning\nmodels, (5) mobile device and AR/VR applications for fast and better\ndecision-making in the field. Particularly, we proposed a novel probabilistic\ndeep learning reliability modelling approach and demonstrate it in the Turbofan\nEngine Degradation Dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 11:10:13 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Zheng", "Haining", ""], ["Paiva", "Antonio R.", ""], ["Gurciullo", "Chris S.", ""]]}, {"id": "2009.00365", "submitter": "Ievgen Redko", "authors": "Charlotte Laclau, Franck Iutzeler, Ievgen Redko", "title": "Rank-one partitioning: formalization, illustrative examples, and a new\n  cluster enhancing strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and formalize a rank-one partitioning learning\nparadigm that unifies partitioning methods that proceed by summarizing a data\nset using a single vector that is further used to derive the final clustering\npartition. Using this unification as a starting point, we propose a novel\nalgorithmic solution for the partitioning problem based on rank-one matrix\nfactorization and denoising of piecewise constant signals. Finally, we propose\nan empirical demonstration of our findings and demonstrate the robustness of\nthe proposed denoising step. We believe that our work provides a new point of\nview for several unsupervised learning techniques that helps to gain a deeper\nunderstanding about the general mechanisms of data partitioning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 11:37:28 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Laclau", "Charlotte", ""], ["Iutzeler", "Franck", ""], ["Redko", "Ievgen", ""]]}, {"id": "2009.00387", "submitter": "Xiaokai Chen", "authors": "Xiaokai Chen and Xiaoguang Gu and Libo Fu", "title": "Boosting Share Routing for Multi-task Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3442442.3452323", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-task learning (MTL) aims to make full use of the knowledge contained in\nmulti-task supervision signals to improve the overall performance. How to make\nthe knowledge of multiple tasks shared appropriately is an open problem for\nMTL. Most existing deep MTL models are based on parameter sharing. However,\nsuitable sharing mechanism is hard to design as the relationship among tasks is\ncomplicated. In this paper, we propose a general framework called Multi-Task\nNeural Architecture Search (MTNAS) to efficiently find a suitable sharing route\nfor a given MTL problem. MTNAS modularizes the sharing part into multiple\nlayers of sub-networks. It allows sparse connection among these sub-networks\nand soft sharing based on gating is enabled for a certain route. Benefiting\nfrom such setting, each candidate architecture in our search space defines a\ndynamic sparse sharing route which is more flexible compared with full-sharing\nin previous approaches. We show that existing typical sharing approaches are\nsub-graphs in our search space. Extensive experiments on three real-world\nrecommendation datasets demonstrate MTANS achieves consistent improvement\ncompared with single-task models and typical multi-task methods while\nmaintaining high computation efficiency. Furthermore, in-depth experiments\ndemonstrates that MTNAS can learn suitable sparse route to mitigate negative\ntransfer.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:37:19 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 12:00:31 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Chen", "Xiaokai", ""], ["Gu", "Xiaoguang", ""], ["Fu", "Libo", ""]]}, {"id": "2009.00401", "submitter": "Philippe Goulet Coulombe", "authors": "Philippe Goulet Coulombe", "title": "Time-Varying Parameters as Ridge Regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-varying parameters (TVPs) models are frequently used in economics to\nmodel structural change. I show that they are in fact ridge regressions.\nInstantly, this makes computations, tuning, and implementation much easier than\nin the state-space paradigm. Among other things, solving the equivalent dual\nridge problem is computationally very fast even in high dimensions, and the\ncrucial \"amount of time variation\" is tuned by cross-validation. Evolving\nvolatility is dealt with using a two-step ridge regression. I consider\nextensions that incorporate sparsity (the algorithm selects which parameters\nvary and which do not) and reduced-rank restrictions (variation is tied to a\nfactor model). To demonstrate the usefulness of the approach, I use it to study\nthe evolution of monetary policy in Canada. The application requires the\nestimation of about 4600 TVPs, a task well within the reach of the new method.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 13:07:04 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 20:07:56 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Coulombe", "Philippe Goulet", ""]]}, {"id": "2009.00437", "submitter": "Xuanyi Dong", "authors": "Xuanyi Dong, Lu Liu, Katarzyna Musial, Bogdan Gabrys", "title": "NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and\n  Size", "comments": "Accepted to IEEE TPAMI 2021, an extended version of NAS-Bench-201\n  (ICLR 2020) [arXiv:2001.00326]", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3054824", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has attracted a lot of attention and has\nbeen illustrated to bring tangible benefits in a large number of applications\nin the past few years. Architecture topology and architecture size have been\nregarded as two of the most important aspects for the performance of deep\nlearning models and the community has spawned lots of searching algorithms for\nboth aspects of the neural architectures. However, the performance gain from\nthese searching algorithms is achieved under different search spaces and\ntraining setups. This makes the overall performance of the algorithms to some\nextent incomparable and the improvement from a sub-module of the searching\nmodel unclear. In this paper, we propose NATS-Bench, a unified benchmark on\nsearching for both topology and size, for (almost) any up-to-date NAS\nalgorithm. NATS-Bench includes the search space of 15,625 neural cell\ncandidates for architecture topology and 32,768 for architecture size on three\ndatasets. We analyze the validity of our benchmark in terms of various criteria\nand performance comparison of all candidates in the search space. We also show\nthe versatility of NATS-Bench by benchmarking 13 recent state-of-the-art NAS\nalgorithms on it. All logs and diagnostic information trained using the same\nsetup for each candidate are provided. This facilitates a much larger community\nof researchers to focus on developing better NAS algorithms in a more\ncomparable and computationally cost friendly environment. All codes are\npublicly available at: https://xuanyidong.com/assets/projects/NATS-Bench.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:34:56 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 01:50:27 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 05:39:42 GMT"}, {"version": "v4", "created": "Wed, 2 Dec 2020 15:19:25 GMT"}, {"version": "v5", "created": "Mon, 25 Jan 2021 02:42:25 GMT"}, {"version": "v6", "created": "Tue, 26 Jan 2021 02:33:39 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Dong", "Xuanyi", ""], ["Liu", "Lu", ""], ["Musial", "Katarzyna", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2009.00497", "submitter": "Philomene Chagniot", "authors": "Philom\\`ene Chagniot, Flavian Vasile, David Rohde", "title": "From Clicks to Conversions: Recommendation for long-term reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are often optimised for short-term reward: a\nrecommendation is considered successful if a reward (e.g. a click) can be\nobserved immediately after the recommendation. The advantage of this framework\nis that with some reasonable (although questionable) assumptions, it allows\nfamiliar supervised learning tools to be used for the recommendation task.\nHowever, it means that long-term business metrics, e.g. sales or retention are\nignored. In this paper we introduce a framework for modeling long-term rewards\nin the RecoGym simulation environment. We use this newly introduced\nfunctionality to showcase problems introduced by the last-click attribution\nscheme in the case of conversion-optimized recommendations and propose a simple\nextension that leads to state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 14:53:57 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Chagniot", "Philom\u00e8ne", ""], ["Vasile", "Flavian", ""], ["Rohde", "David", ""]]}, {"id": "2009.00505", "submitter": "Firas Laakom", "authors": "Firas Laakom, Jenni Raitoharju, Nikolaos Passalis, Alexandros\n  Iosifidis, Moncef Gabbouj", "title": "Graph Embedding with Data Uncertainty", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  spectral-based subspace learning is a common data preprocessing step in many\nmachine learning pipelines. The main aim is to learn a meaningful low\ndimensional embedding of the data. However, most subspace learning methods do\nnot take into consideration possible measurement inaccuracies or artifacts that\ncan lead to data with high uncertainty. Thus, learning directly from raw data\ncan be misleading and can negatively impact the accuracy. In this paper, we\npropose to model artifacts in training data using probability distributions;\neach data point is represented by a Gaussian distribution centered at the\noriginal data point and having a variance modeling its uncertainty. We\nreformulate the Graph Embedding framework to make it suitable for learning from\ndistributions and we study as special cases the Linear Discriminant Analysis\nand the Marginal Fisher Analysis techniques. Furthermore, we propose two\nschemes for modeling data uncertainty based on pair-wise distances in an\nunsupervised and a supervised contexts.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:08:23 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Laakom", "Firas", ""], ["Raitoharju", "Jenni", ""], ["Passalis", "Nikolaos", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2009.00520", "submitter": "Weikai Li", "authors": "Weikai Li and Songcan Chen", "title": "Unsupervised Domain Adaptation with Progressive Adaptation of Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Domain Adaptation (UDA) aims to classify unlabeled target domain\nby transferring knowledge from labeled source domain with domain shift. Most of\nthe existing UDA methods try to mitigate the adverse impact induced by the\nshift via reducing domain discrepancy. However, such approaches easily suffer a\nnotorious mode collapse issue due to the lack of labels in target domain.\nNaturally, one of the effective ways to mitigate this issue is to reliably\nestimate the pseudo labels for target domain, which itself is hard. To overcome\nthis, we propose a novel UDA method named Progressive Adaptation of Subspaces\napproach (PAS) in which we utilize such an intuition that appears much\nreasonable to gradually obtain reliable pseudo labels. Speci fically, we\nprogressively and steadily refine the shared subspaces as bridge of knowledge\ntransfer by adaptively anchoring/selecting and leveraging those target samples\nwith reliable pseudo labels. Subsequently, the refined subspaces can in turn\nprovide more reliable pseudo-labels of the target domain, making the mode\ncollapse highly mitigated. Our thorough evaluation demonstrates that PAS is not\nonly effective for common UDA, but also outperforms the state-of-the arts for\nmore challenging Partial Domain Adaptation (PDA) situation, where the source\nlabel set subsumes the target one.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:40:50 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Li", "Weikai", ""], ["Chen", "Songcan", ""]]}, {"id": "2009.00534", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Guiping Hu", "title": "Improved Weighted Random Forest for Classification Problems", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-66501-2_4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several studies have shown that combining machine learning models in an\nappropriate way will introduce improvements in the individual predictions made\nby the base models. The key to make well-performing ensemble model is in the\ndiversity of the base models. Of the most common solutions for introducing\ndiversity into the decision trees are bagging and random forest. Bagging\nenhances the diversity by sampling with replacement and generating many\ntraining data sets, while random forest adds selecting a random number of\nfeatures as well. This has made the random forest a winning candidate for many\nmachine learning applications. However, assuming equal weights for all base\ndecision trees does not seem reasonable as the randomization of sampling and\ninput feature selection may lead to different levels of decision-making\nabilities across base decision trees. Therefore, we propose several algorithms\nthat intend to modify the weighting strategy of regular random forest and\nconsequently make better predictions. The designed weighting frameworks include\noptimal weighted random forest based on ac-curacy, optimal weighted random\nforest based on the area under the curve (AUC), performance-based weighted\nrandom forest, and several stacking-based weighted random forest models. The\nnumerical results show that the proposed models are able to introduce\nsignificant improvements compared to regular random forest.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:08:45 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Hu", "Guiping", ""]]}, {"id": "2009.00538", "submitter": "Tijin Yan", "authors": "Tijin Yan, Hongwei Zhang, Zirui Li, Yuanqing Xia", "title": "Stochastic Graph Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning over graph structure data has been widely studied due\nto its wide application prospects. However, previous methods mainly focus on\nstatic graphs while many real-world graphs evolve over time. Modeling such\nevolution is important for predicting properties of unseen networks. To resolve\nthis challenge, we propose SGRNN, a novel neural architecture that applies\nstochastic latent variables to simultaneously capture the evolution in node\nattributes and topology. Specifically, deterministic states are separated from\nstochastic states in the iterative process to suppress mutual interference.\nWith semi-implicit variational inference integrated to SGRNN, a non-Gaussian\nvariational distribution is proposed to help further improve the performance.\nIn addition, to alleviate KL-vanishing problem in SGRNN, a simple and\ninterpretable structure is proposed based on the lower bound of KL-divergence.\nExtensive experiments on real-world datasets demonstrate the effectiveness of\nthe proposed model. Code is available at\nhttps://github.com/StochasticGRNN/SGRNN.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:14:30 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Yan", "Tijin", ""], ["Zhang", "Hongwei", ""], ["Li", "Zirui", ""], ["Xia", "Yuanqing", ""]]}, {"id": "2009.00540", "submitter": "Prasanna Date", "authors": "Prasanna Date, Christopher D. Carothers, John E. Mitchell, James A.\n  Hendler, Malik Magdon-Ismail", "title": "Training Deep Neural Networks with Constrained Learning Parameters", "comments": null, "journal-ref": null, "doi": "10.1109/ICRC2020.2020.00018", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's deep learning models are primarily trained on CPUs and GPUs. Although\nthese models tend to have low error, they consume high power and utilize large\namount of memory owing to double precision floating point learning parameters.\nBeyond the Moore's law, a significant portion of deep learning tasks would run\non edge computing systems, which will form an indispensable part of the entire\ncomputation fabric. Subsequently, training deep learning models for such\nsystems will have to be tailored and adopted to generate models that have the\nfollowing desirable characteristics: low error, low memory, and low power. We\nbelieve that deep neural networks (DNNs), where learning parameters are\nconstrained to have a set of finite discrete values, running on neuromorphic\ncomputing systems would be instrumental for intelligent edge computing systems\nhaving these desirable characteristics. To this extent, we propose the\nCombinatorial Neural Network Training Algorithm (CoNNTrA), that leverages a\ncoordinate gradient descent-based approach for training deep learning models\nwith finite discrete learning parameters. Next, we elaborate on the theoretical\nunderpinnings and evaluate the computational complexity of CoNNTrA. As a proof\nof concept, we use CoNNTrA to train deep learning models with ternary learning\nparameters on the MNIST, Iris and ImageNet data sets and compare their\nperformance to the same models trained using Backpropagation. We use following\nperformance metrics for the comparison: (i) Training error; (ii) Validation\nerror; (iii) Memory usage; and (iv) Training time. Our results indicate that\nCoNNTrA models use 32x less memory and have errors at par with the\nBackpropagation models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:20:11 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Date", "Prasanna", ""], ["Carothers", "Christopher D.", ""], ["Mitchell", "John E.", ""], ["Hendler", "James A.", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "2009.00565", "submitter": "Jordan Masakuna F", "authors": "Jordan F. Masakuna, Simukai W. Utete, Steve Kroon", "title": "Performance-Agnostic Fusion of Probabilistic Classifier Outputs", "comments": "This paper was accepted at the 23rd International Conference on\n  Information Fusion 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for combining probabilistic outputs of classifiers to\nmake a single consensus class prediction when no further information about the\nindividual classifiers is available, beyond that they have been trained for the\nsame task. The lack of relevant prior information rules out typical\napplications of Bayesian or Dempster-Shafer methods, and the default approach\nhere would be methods based on the principle of indifference, such as the sum\nor product rule, which essentially weight all classifiers equally. In contrast,\nour approach considers the diversity between the outputs of the various\nclassifiers, iteratively updating predictions based on their correspondence\nwith other predictions until the predictions converge to a consensus decision.\nThe intuition behind this approach is that classifiers trained for the same\ntask should typically exhibit regularities in their outputs on a new task; the\npredictions of classifiers which differ significantly from those of others are\nthus given less credence using our approach. The approach implicitly assumes a\nsymmetric loss function, in that the relative cost of various prediction errors\nare not taken into account. Performance of the model is demonstrated on\ndifferent benchmark datasets. Our proposed method works well in situations\nwhere accuracy is the performance metric; however, it does not output\ncalibrated probabilities, so it is not suitable in situations where such\nprobabilities are required for further processing.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:53:29 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Masakuna", "Jordan F.", ""], ["Utete", "Simukai W.", ""], ["Kroon", "Steve", ""]]}, {"id": "2009.00585", "submitter": "Guilherme Pires", "authors": "Guilherme G. P. Freitas Pires, M\\'ario A. T. Figueiredo", "title": "Variational Mixture of Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, deep generative models, such as generative adversarial\nnetworks \\autocite{GAN}, variational autoencoders \\autocite{vaepaper}, and\ntheir variants, have seen wide adoption for the task of modelling complex data\ndistributions. In spite of the outstanding sample quality achieved by those\nearly methods, they model the target distributions \\emph{implicitly}, in the\nsense that the probability density functions induced by them are not explicitly\naccessible. This fact renders those methods unfit for tasks that require, for\nexample, scoring new instances of data with the learned distributions.\nNormalizing flows have overcome this limitation by leveraging the\nchange-of-variables formula for probability density functions, and by using\ntransformations designed to have tractable and cheaply computable Jacobians.\nAlthough flexible, this framework lacked (until recently\n\\autocites{semisuplearning_nflows, RAD}) a way to introduce discrete structure\n(such as the one found in mixtures) in the models it allows to construct, in an\nunsupervised scenario. The present work overcomes this by using normalizing\nflows as components in a mixture model and devising an end-to-end training\nprocedure for such a model. This procedure is based on variational inference,\nand uses a variational posterior parameterized by a neural network. As will\nbecome clear, this model naturally lends itself to (multimodal) density\nestimation, semi-supervised learning, and clustering. The proposed model is\nillustrated on two synthetic datasets, as well as on a real-world dataset.\nKeywords: Deep generative models, normalizing flows, variational inference,\nprobabilistic modelling, mixture models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:20:08 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Pires", "Guilherme G. P. Freitas", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "2009.00606", "submitter": "Oren Yuval", "authors": "Oren Yuval and Saharon Rosset", "title": "Semi-Supervised Empirical Risk Minimization: When can unlabeled data\n  improve prediction?", "comments": "36 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general methodology for using unlabeled data to design semi\nsupervised learning (SSL) variants of the Empirical Risk Minimization (ERM)\nlearning process. Focusing on generalized linear regression, we provide a\ncareful treatment of the effectiveness of the SSL to improve prediction\nperformance. The key ideas are carefully considering the null model as a\ncompetitor, and utilizing the unlabeled data to determine signal-noise\ncombinations where the SSL outperforms both the ERM learning and the null\nmodel. In the special case of linear regression with Gaussian covariates, we\nshow that the previously suggested semi-supervised estimator is in fact not\ncapable of improving on both the supervised estimator and the null model\nsimultaneously. However, the new estimator presented in this work, can achieve\nan improvement of $O(1/n)$ term over both competitors simultaneously. On the\nother hand, we show that in other scenarios, such as non-Gaussian covariates,\nmisspecified linear regression, or generalized linear regression with\nnon-linear link functions, having unlabeled data can derive substantial\nimprovement in practice by applying our suggested SSL approach. Moreover, it is\npossible to identify the situations where SSL improves prediction, by using the\nresults we establish throughout this work. This is shown empirically through\nextensive simulations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:55:51 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 11:49:52 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 14:58:19 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Yuval", "Oren", ""], ["Rosset", "Saharon", ""]]}, {"id": "2009.00647", "submitter": "Chen Wang", "authors": "Chen Wang, Yuheng Qiu, Sebastian Scherer", "title": "Lifelong Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks are powerful models for many graph-structured tasks. In\nthis paper, we aim to solve the problem of lifelong learning for graph neural\nnetworks. One of the main challenges is the effect of \"catastrophic forgetting\"\nfor continuously learning a sequence of tasks, as the nodes can only be present\nto the model once. Moreover, the number of nodes changes dynamically in\nlifelong learning and this makes many graph models and sampling strategies\ninapplicable. To solve these problems, we construct a new graph topology,\ncalled the feature graph. It takes features as new nodes and turns nodes into\nindependent graphs. This successfully converts the original problem of node\nclassification to graph classification. In this way, the increasing nodes in\nlifelong learning can be regarded as increasing training samples, which makes\nlifelong learning easier. We demonstrate that the feature graph achieves much\nhigher accuracy than the state-of-the-art methods in both data-incremental and\nclass-incremental tasks. We expect that the feature graph will have broad\npotential applications for graph-structured tasks in lifelong learning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 18:21:34 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Wang", "Chen", ""], ["Qiu", "Yuheng", ""], ["Scherer", "Sebastian", ""]]}, {"id": "2009.00666", "submitter": "Akash Kumar Dhaka", "authors": "Akash Kumar Dhaka, Alejandro Catalina, Michael Riis Andersen, M{\\aa}ns\n  Magnusson, Jonathan H. Huggins, Aki Vehtari", "title": "Robust, Accurate Stochastic Optimization for Variational Inference", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of fitting variational posterior approximations using\nstochastic optimization methods. The performance of these approximations\ndepends on (1) how well the variational family matches the true posterior\ndistribution,(2) the choice of divergence, and (3) the optimization of the\nvariational objective. We show that even in the best-case scenario when the\nexact posterior belongs to the assumed variational family, common stochastic\noptimization methods lead to poor variational approximations if the problem\ndimension is moderately large. We also demonstrate that these methods are not\nrobust across diverse model types. Motivated by these findings, we develop a\nmore robust and accurate stochastic optimization framework by viewing the\nunderlying optimization algorithm as producing a Markov chain. Our approach is\ntheoretically motivated and includes a diagnostic for convergence and a novel\nstopping rule, both of which are robust to noisy evaluations of the objective\nfunction. We show empirically that the proposed framework works well on a\ndiverse set of models: it can automatically detect stochastic optimization\nfailure or inaccurate variational approximation\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 19:12:11 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 15:45:09 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Dhaka", "Akash Kumar", ""], ["Catalina", "Alejandro", ""], ["Andersen", "Michael Riis", ""], ["Magnusson", "M\u00e5ns", ""], ["Huggins", "Jonathan H.", ""], ["Vehtari", "Aki", ""]]}, {"id": "2009.00690", "submitter": "Junyi Li", "authors": "Junyi Li, Bin Gu, Heng Huang", "title": "Improved Bilevel Model: Fast and Optimal Algorithm with Theoretical\n  Guarantee", "comments": "submitted to ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the hierarchical structure of many machine learning problems, bilevel\nprogramming is becoming more and more important recently, however, the\ncomplicated correlation between the inner and outer problem makes it extremely\nchallenging to solve. Although several intuitive algorithms based on the\nautomatic differentiation have been proposed and obtained success in some\napplications, not much attention has been paid to finding the optimal\nformulation of the bilevel model. Whether there exists a better formulation is\nstill an open problem. In this paper, we propose an improved bilevel model\nwhich converges faster and better compared to the current formulation. We\nprovide theoretical guarantee and evaluation results over two tasks: Data\nHyper-Cleaning and Hyper Representation Learning. The empirical results show\nthat our model outperforms the current bilevel model with a great margin.\n\\emph{This is a concurrent work with \\citet{liu2020generic} and we submitted to\nICML 2020. Now we put it on the arxiv for record.}\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 20:52:57 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Li", "Junyi", ""], ["Gu", "Bin", ""], ["Huang", "Heng", ""]]}, {"id": "2009.00700", "submitter": "Utkarsh Sarawgi", "authors": "Utkarsh Sarawgi, Wazeer Zulfikar, Nouran Soliman, Pattie Maes", "title": "Multimodal Inductive Transfer Learning for Detection of Alzheimer's\n  Dementia and its Severity", "comments": "To appear in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Alzheimer's disease is estimated to affect around 50 million people worldwide\nand is rising rapidly, with a global economic burden of nearly a trillion\ndollars. This calls for scalable, cost-effective, and robust methods for\ndetection of Alzheimer's dementia (AD). We present a novel architecture that\nleverages acoustic, cognitive, and linguistic features to form a multimodal\nensemble system. It uses specialized artificial neural networks with temporal\ncharacteristics to detect AD and its severity, which is reflected through\nMini-Mental State Exam (MMSE) scores. We first evaluate it on the ADReSS\nchallenge dataset, which is a subject-independent and balanced dataset matched\nfor age and gender to mitigate biases, and is available through DementiaBank.\nOur system achieves state-of-the-art test accuracy, precision, recall, and\nF1-score of 83.3% each for AD classification, and state-of-the-art test root\nmean squared error (RMSE) of 4.60 for MMSE score regression. To the best of our\nknowledge, the system further achieves state-of-the-art AD classification\naccuracy of 88.0% when evaluated on the full benchmark DementiaBank Pitt\ndatabase. Our work highlights the applicability and transferability of\nspontaneous speech to produce a robust inductive transfer learning model, and\ndemonstrates generalizability through a task-agnostic feature-space. The source\ncode is available at https://github.com/wazeerzulfikar/alzheimers-dementia\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 21:47:26 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Sarawgi", "Utkarsh", ""], ["Zulfikar", "Wazeer", ""], ["Soliman", "Nouran", ""], ["Maes", "Pattie", ""]]}, {"id": "2009.00713", "submitter": "Nanxin Chen", "authors": "Nanxin Chen, Yu Zhang, Heiga Zen, Ron J. Weiss, Mohammad Norouzi,\n  William Chan", "title": "WaveGrad: Estimating Gradients for Waveform Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces WaveGrad, a conditional model for waveform generation\nwhich estimates gradients of the data density. The model is built on prior work\non score matching and diffusion probabilistic models. It starts from a Gaussian\nwhite noise signal and iteratively refines the signal via a gradient-based\nsampler conditioned on the mel-spectrogram. WaveGrad offers a natural way to\ntrade inference speed for sample quality by adjusting the number of refinement\nsteps, and bridges the gap between non-autoregressive and autoregressive models\nin terms of audio quality. We find that it can generate high fidelity audio\nsamples using as few as six iterations. Experiments reveal WaveGrad to generate\nhigh fidelity audio, outperforming adversarial non-autoregressive baselines and\nmatching a strong likelihood-based autoregressive baseline using fewer\nsequential operations. Audio samples are available at\nhttps://wavegrad.github.io/.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:44:10 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 15:21:58 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Chen", "Nanxin", ""], ["Zhang", "Yu", ""], ["Zen", "Heiga", ""], ["Weiss", "Ron J.", ""], ["Norouzi", "Mohammad", ""], ["Chan", "William", ""]]}, {"id": "2009.00757", "submitter": "Matt Shannon", "authors": "Matt Shannon", "title": "Properties of f-divergences and f-GAN training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this technical report we describe some properties of f-divergences and\nf-GAN training. We present an elementary derivation of the f-divergence lower\nbounds which form the basis of f-GAN training. We derive informative but\nperhaps underappreciated properties of f-divergences and f-GAN training,\nincluding a gradient matching property and the fact that all f-divergences\nagree up to an overall scale factor on the divergence between nearby\ndistributions. We provide detailed expressions for computing various common\nf-divergences and their variational lower bounds. Finally, based on our\nreformulation, we slightly generalize f-GAN training in a way that may improve\nits stability.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 00:21:57 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Shannon", "Matt", ""]]}, {"id": "2009.00774", "submitter": "Yanchao Sun", "authors": "Yanchao Sun, Da Huo and Furong Huang", "title": "Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown\n  Dynamics", "comments": null, "journal-ref": "The Ninth International Conference on Learning Representations\n  (ICLR 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attacks on Reinforcement Learning (RL) systems could take advantage\nof RL algorithm's vulnerabilities and cause failure of the learning. However,\nprior works on poisoning RL usually either unrealistically assume the attacker\nknows the underlying Markov Decision Process (MDP), or directly apply the\npoisoning methods in supervised learning to RL. In this work, we build a\ngeneric poisoning framework for online RL via a comprehensive investigation of\nheterogeneous poisoning models in RL. Without any prior knowledge of the MDP,\nwe propose a strategic poisoning algorithm called Vulnerability-Aware\nAdversarial Critic Poison (VA2C-P), which works for most policy-based deep RL\nagents, closing the gap that no poisoning method exists for policy-based RL\nagents. VA2C-P uses a novel metric, stability radius in RL, that measures the\nvulnerability of RL algorithms. Experiments on multiple deep RL agents and\nmultiple environments show that our poisoning algorithm successfully prevents\nagents from learning a good policy or teaches the agents to converge to a\ntarget policy, with a limited attacking budget.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 01:43:30 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 22:24:47 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 16:09:16 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Sun", "Yanchao", ""], ["Huo", "Da", ""], ["Huang", "Furong", ""]]}, {"id": "2009.00792", "submitter": "Jun Shu", "authors": "Ziyi Yang, Jun Shu, Yong Liang, Deyu Meng and Zongben Xu", "title": "Select-ProtoNet: Learning to Select for Few-Shot Disease Subtype\n  Prediction", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current machine learning has made great progress on computer vision and many\nother fields attributed to the large amount of high-quality training samples,\nwhile it does not work very well on genomic data analysis, since they are\nnotoriously known as small data. In our work, we focus on few-shot disease\nsubtype prediction problem, identifying subgroups of similar patients that can\nguide treatment decisions for a specific individual through training on small\ndata. In fact, doctors and clinicians always address this problem by studying\nseveral interrelated clinical variables simultaneously. We attempt to simulate\nsuch clinical perspective, and introduce meta learning techniques to develop a\nnew model, which can extract the common experience or knowledge from\ninterrelated clinical tasks and transfer it to help address new tasks. Our new\nmodel is built upon a carefully designed meta-learner, called Prototypical\nNetwork, that is a simple yet effective meta learning machine for few-shot\nimage classification. Observing that gene expression data have specifically\nhigh dimensionality and high noise properties compared with image data, we\nproposed a new extension of it by appending two modules to address these\nissues. Concretely, we append a feature selection layer to automatically filter\nout the disease-irrelated genes and incorporate a sample reweighting strategy\nto adaptively remove noisy data, and meanwhile the extended model is capable of\nlearning from a limited number of training examples and generalize well.\nSimulations and real gene expression data experiments substantiate the\nsuperiority of the proposed method for predicting the subtypes of disease and\nidentifying potential disease-related genes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 02:50:30 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 15:50:22 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Yang", "Ziyi", ""], ["Shu", "Jun", ""], ["Liang", "Yong", ""], ["Meng", "Deyu", ""], ["Xu", "Zongben", ""]]}, {"id": "2009.00802", "submitter": "Andrew Lohn", "authors": "Andrew J. Lohn", "title": "Estimating the Brittleness of AI: Safety Integrity Levels and the Need\n  for Testing Out-Of-Distribution Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test, Evaluation, Verification, and Validation (TEVV) for Artificial\nIntelligence (AI) is a challenge that threatens to limit the economic and\nsocietal rewards that AI researchers have devoted themselves to producing. A\ncentral task of TEVV for AI is estimating brittleness, where brittleness\nimplies that the system functions well within some bounds and poorly outside of\nthose bounds. This paper argues that neither of those criteria are certain of\nDeep Neural Networks. First, highly touted AI successes (eg. image\nclassification and speech recognition) are orders of magnitude more\nfailure-prone than are typically certified in critical systems even within\ndesign bounds (perfectly in-distribution sampling). Second, performance falls\noff only gradually as inputs become further Out-Of-Distribution (OOD). Enhanced\nemphasis is needed on designing systems that are resilient despite\nfailure-prone AI components as well as on evaluating and improving OOD\nperformance in order to get AI to where it can clear the challenging hurdles of\nTEVV and certification.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:33:40 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Lohn", "Andrew J.", ""]]}, {"id": "2009.00845", "submitter": "Wouter Kouw", "authors": "Wouter M Kouw", "title": "Online system identification in a Duffing oscillator by free energy\n  minimisation", "comments": "10 pages, 5 figures. Accepted to the International Workshop on Active\n  Inference (final author version)", "journal-ref": null, "doi": "10.1007/978-3-030-64919-7_6", "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online system identification is the estimation of parameters of a dynamical\nsystem, such as mass or friction coefficients, for each measurement of the\ninput and output signals. Here, the nonlinear stochastic differential equation\nof a Duffing oscillator is cast to a generative model and dynamical parameters\nare inferred using variational message passing on a factor graph of the model.\nThe approach is validated with an experiment on data from an electronic\nimplementation of a Duffing oscillator. The proposed inference procedure\nperforms as well as offline prediction error minimisation in a state-of-the-art\nnonlinear model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 06:51:56 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kouw", "Wouter M", ""]]}, {"id": "2009.00909", "submitter": "Wen Zhang", "authors": "Wen Zhang, Lingfei Deng, Lei Zhang, Dongrui Wu", "title": "A Survey on Negative Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning (TL) tries to utilize data or knowledge from one or more\nsource domains to facilitate the learning in a target domain. It is\nparticularly useful when the target domain has few or no labeled data, due to\nannotation expense, privacy concerns, etc. Unfortunately, the effectiveness of\nTL is not always guaranteed. Negative transfer (NT), i.e., the source domain\ndata/knowledge cause reduced learning performance in the target domain, has\nbeen a long-standing and challenging problem in TL. Various approaches to\nhandle NT have been proposed in the literature. However, this filed lacks a\nsystematic survey on the formalization of NT, their factors and the algorithms\nthat handle NT. This paper proposes to fill this gap. First, the definition of\nnegative transfer is considered and a taxonomy of the factors are discussed.\nThen, near fifty representative approaches for handling NT are categorized and\nreviewed, from four perspectives: secure transfer, domain similarity\nestimation, distant transfer and negative transfer mitigation. NT in related\nfields, e.g., multi-task learning, lifelong learning, and adversarial attacks\nare also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 09:20:20 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 03:05:51 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 13:01:08 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zhang", "Wen", ""], ["Deng", "Lingfei", ""], ["Zhang", "Lei", ""], ["Wu", "Dongrui", ""]]}, {"id": "2009.00934", "submitter": "Lu Yu", "authors": "Lu Yu, Shichao Pei, Chuxu Zhang, Lizhong Ding, Jun Zhou, Longfei Li,\n  Xiangliang Zhang", "title": "Self-supervised Smoothing Graph Neural Networks", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies learning node representations with GNNs for unsupervised\nscenarios. We make a theoretical understanding and empirical demonstration\nabout the non-steady performance of GNNs over different graph datasets, when\nthe supervision signals are not appropriately defined. The performance of GNNs\ndepends on both the node feature smoothness and the graph locality. To smooth\nthe discrepancy of node proximity measured by graph topology and node feature,\nwe proposed KS2L - a novel graph \\underline{K}nowledge distillation regularized\n\\underline{S}elf-\\underline{S}upervised \\underline{L}earning framework, with\ntwo complementary regularization modules, for intra-and cross-model graph\nknowledge distillation. We demonstrate the competitive performance of KS2L on a\nvariety of benchmarks. Even with a single GCN layer, KS2L has consistently\ncompetitive or even better performance on various benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 10:27:30 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Yu", "Lu", ""], ["Pei", "Shichao", ""], ["Zhang", "Chuxu", ""], ["Ding", "Lizhong", ""], ["Zhou", "Jun", ""], ["Li", "Longfei", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2009.00945", "submitter": "Christos Koutlis", "authors": "Christos Koutlis, Symeon Papadopoulos, Manos Schinas, Ioannis\n  Kompatsiaris", "title": "LAVARNET: Neural Network Modeling of Causal Variable Relationships for\n  Multivariate Time Series Forecasting", "comments": null, "journal-ref": null, "doi": "10.1016/j.asoc.2020.106685", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting is of great importance to many\nscientific disciplines and industrial sectors. The evolution of a multivariate\ntime series depends on the dynamics of its variables and the connectivity\nnetwork of causal interrelationships among them. Most of the existing time\nseries models do not account for the causal effects among the system's\nvariables and even if they do they rely just on determining the\nbetween-variables causality network. Knowing the structure of such a complex\nnetwork and even more specifically knowing the exact lagged variables that\ncontribute to the underlying process is crucial for the task of multivariate\ntime series forecasting. The latter is a rather unexplored source of\ninformation to leverage. In this direction, here a novel neural network-based\narchitecture is proposed, termed LAgged VAriable Representation NETwork\n(LAVARNET), which intrinsically estimates the importance of lagged variables\nand combines high dimensional latent representations of them to predict future\nvalues of time series. Our model is compared with other baseline and state of\nthe art neural network architectures on one simulated data set and four real\ndata sets from meteorology, music, solar activity, and finance areas. The\nproposed architecture outperforms the competitive architectures in most of the\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 10:57:28 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Koutlis", "Christos", ""], ["Papadopoulos", "Symeon", ""], ["Schinas", "Manos", ""], ["Kompatsiaris", "Ioannis", ""]]}, {"id": "2009.00952", "submitter": "Kun Zhan", "authors": "Kun Zhan, Chaoxi Niu", "title": "Mutual Teaching for Graph Convolutional Networks", "comments": "GCN, 8 pages, 1 figures", "journal-ref": "Future Generation Computer Systems, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks produce good predictions of unlabeled samples\ndue to its transductive label propagation. Since samples have different\npredicted confidences, we take high-confidence predictions as pseudo labels to\nexpand the label set so that more samples are selected for updating models. We\npropose a new training method named as mutual teaching, i.e., we train dual\nmodels and let them teach each other during each batch. First, each network\nfeeds forward all samples and selects samples with high-confidence predictions.\nSecond, each model is updated by samples selected by its peer network. We view\nthe high-confidence predictions as useful knowledge, and the useful knowledge\nof one network teaches the peer network with model updating in each batch. In\nmutual teaching, the pseudo-label set of a network is from its peer network.\nSince we use the new strategy of network training, performance improves\nsignificantly. Extensive experimental results demonstrate that our method\nachieves superior performance over state-of-the-art methods under very low\nlabel rates.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 11:10:55 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Zhan", "Kun", ""], ["Niu", "Chaoxi", ""]]}, {"id": "2009.01004", "submitter": "Omar Mossad", "authors": "Omar Mossad, Amgad Ahmed, Anandharaju Raju, Hari Karthikeyan, and\n  Zayed Ahmed", "title": "FAT ALBERT: Finding Answers in Large Texts using Semantic Similarity\n  Attention Layer based on BERT", "comments": "source code available: https://github.com/omossad/fat-albert", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine based text comprehension has always been a significant research field\nin natural language processing. Once a full understanding of the text context\nand semantics is achieved, a deep learning model can be trained to solve a\nlarge subset of tasks, e.g. text summarization, classification and question\nanswering. In this paper we focus on the question answering problem,\nspecifically the multiple choice type of questions. We develop a model based on\nBERT, a state-of-the-art transformer network. Moreover, we alleviate the\nability of BERT to support large text corpus by extracting the highest\ninfluence sentences through a semantic similarity model. Evaluations of our\nproposed model demonstrate that it outperforms the leading models in the\nMovieQA challenge and we are currently ranked first in the leader board with\ntest accuracy of 87.79%. Finally, we discuss the model shortcomings and suggest\npossible improvements to overcome these limitations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 08:04:21 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mossad", "Omar", ""], ["Ahmed", "Amgad", ""], ["Raju", "Anandharaju", ""], ["Karthikeyan", "Hari", ""], ["Ahmed", "Zayed", ""]]}, {"id": "2009.01016", "submitter": "Semin Kwak", "authors": "Semin Kwak and Nikolas Geroliminis", "title": "Travel time prediction for congested freeways with a dynamic linear\n  model", "comments": "in IEEE Transactions on Intelligent Transportation Systems, 2020", "journal-ref": null, "doi": "10.1109/TITS.2020.3006910", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of travel time is an essential feature to support\nIntelligent Transportation Systems (ITS). The non-linearity of traffic states,\nhowever, makes this prediction a challenging task. Here we propose to use\ndynamic linear models (DLMs) to approximate the non-linear traffic states.\nUnlike a static linear regression model, the DLMs assume that their parameters\nare changing across time. We design a DLM with model parameters defined at each\ntime unit to describe the spatio-temporal characteristics of time-series\ntraffic data. Based on our DLM and its model parameters analytically trained\nusing historical data, we suggest an optimal linear predictor in the minimum\nmean square error (MMSE) sense. We compare our prediction accuracy of travel\ntime for freeways in California (I210-E and I5-S) under highly congested\ntraffic conditions with those of other methods: the instantaneous travel time,\nk-nearest neighbor, support vector regression, and artificial neural network.\nWe show significant improvements in the accuracy, especially for short-term\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:48:06 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Kwak", "Semin", ""], ["Geroliminis", "Nikolas", ""]]}, {"id": "2009.01026", "submitter": "Hammond Pearce", "authors": "Hammond Pearce, Benjamin Tan, Ramesh Karri", "title": "DAVE: Deriving Automatically Verilog from English", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": "10.1145/3380446.3430634", "report-no": null, "categories": "cs.SE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While specifications for digital systems are provided in natural language,\nengineers undertake significant efforts to translate them into the programming\nlanguages understood by compilers for digital systems. Automating this process\nallows designers to work with the language in which they are most comfortable\n--the original natural language -- and focus instead on other downstream design\nchallenges. We explore the use of state-of-the-art machine learning (ML) to\nautomatically derive Verilog snippets from English via fine-tuning GPT-2, a\nnatural language ML system. We describe our approach for producing a suitable\ndataset of novice-level digital design tasks and provide a detailed exploration\nof GPT-2, finding encouraging translation performance across our task sets\n(94.8% correct), with the ability to handle both simple and abstract design\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:25:03 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Pearce", "Hammond", ""], ["Tan", "Benjamin", ""], ["Karri", "Ramesh", ""]]}, {"id": "2009.01027", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Xiaoxing Wang, Bo Zhang, Shun Lu, Xiaolin Wei, Junchi\n  Yan", "title": "DARTS-: Robustly Stepping out of Performance Collapse Without Indicators", "comments": "Accepted to ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fast development of differentiable architecture search (DARTS),\nit suffers from long-standing performance instability, which extremely limits\nits application. Existing robustifying methods draw clues from the resulting\ndeteriorated behavior instead of finding out its causing factor. Various\nindicators such as Hessian eigenvalues are proposed as a signal to stop\nsearching before the performance collapses. However, these indicator-based\nmethods tend to easily reject good architectures if the thresholds are\ninappropriately set, let alone the searching is intrinsically noisy. In this\npaper, we undertake a more subtle and direct approach to resolve the collapse.\nWe first demonstrate that skip connections have a clear advantage over other\ncandidate operations, where it can easily recover from a disadvantageous state\nand become dominant. We conjecture that this privilege is causing degenerated\nperformance. Therefore, we propose to factor out this benefit with an auxiliary\nskip connection, ensuring a fairer competition for all operations. We call this\napproach DARTS-. Extensive experiments on various datasets verify that it can\nsubstantially improve robustness. Our code is available at\nhttps://github.com/Meituan-AutoML/DARTS- .\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:54:13 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 07:58:11 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Wang", "Xiaoxing", ""], ["Zhang", "Bo", ""], ["Lu", "Shun", ""], ["Wei", "Xiaolin", ""], ["Yan", "Junchi", ""]]}, {"id": "2009.01046", "submitter": "Marc-Andr\\'e Larochelle", "authors": "Khoury Richard and Larochelle Marc-Andr\\'e", "title": "Generalisation of Cyberbullying Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberbullying is a problem in today's ubiquitous online communities.\nFiltering it out of online conversations has proven a challenge, and efforts\nhave led to the creation of many different datasets, all offered as resources\nto train classifiers. Through these datasets, we will explore the variety of\ndefinitions of cyberbullying behaviors and the impact of these differences on\nthe portability of one classifier to another community. By analyzing the\nsimilarities between datasets, we also gain insight on the generalization power\nof the classifiers trained from them. A study of ensemble models combining\nthese classifiers will help us understand how they interact with each other.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 14:57:17 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Richard", "Khoury", ""], ["Marc-Andr\u00e9", "Larochelle", ""]]}, {"id": "2009.01047", "submitter": "Vahid Behzadan", "authors": "Bibek Upadhayay and Vahid Behzadan", "title": "Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake\n  Claim Classification", "comments": "Accepted for publication in the proceedings of IEEE ISI '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rampant integration of social media in our every day lives and culture\nhas given rise to fast and easier access to the flow of information than ever\nin human history. However, the inherently unsupervised nature of social media\nplatforms has also made it easier to spread false information and fake news.\nFurthermore, the high volume and velocity of information flow in such platforms\nmake manual supervision and control of information propagation infeasible. This\npaper aims to address this issue by proposing a novel deep learning approach\nfor automated detection of false short-text claims on social media. We first\nintroduce Sentimental LIAR, which extends the LIAR dataset of short claims by\nadding features based on sentiment and emotion analysis of claims. Furthermore,\nwe propose a novel deep learning architecture based on the BERT-Base language\nmodel for classification of claims as genuine or fake. Our results demonstrate\nthat the proposed architecture trained on Sentimental LIAR can achieve an\naccuracy of 70%, which is an improvement of ~30% over previously reported\nresults for the LIAR benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 02:48:11 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 04:57:21 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Upadhayay", "Bibek", ""], ["Behzadan", "Vahid", ""]]}, {"id": "2009.01048", "submitter": "Thai Le", "authors": "Thai Le, Suhang Wang, Dongwon Lee", "title": "MALCOM: Generating Malicious Comments to Attack Neural Fake News\n  Detection Models", "comments": "Accepted at the 20th IEEE International Conference on Data Mining\n  (ICDM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the proliferation of so-called \"fake news\" has caused much\ndisruptions in society and weakened the news ecosystem. Therefore, to mitigate\nsuch problems, researchers have developed state-of-the-art models to\nauto-detect fake news on social media using sophisticated data science and\nmachine learning techniques. In this work, then, we ask \"what if adversaries\nattempt to attack such detection models?\" and investigate related issues by (i)\nproposing a novel threat model against fake news detectors, in which\nadversaries can post malicious comments toward news articles to mislead fake\nnews detectors, and (ii) developing MALCOM, an end-to-end adversarial comment\ngeneration framework to achieve such an attack. Through a comprehensive\nevaluation, we demonstrate that about 94% and 93.5% of the time on average\nMALCOM can successfully mislead five of the latest neural detection models to\nalways output targeted real and fake news labels. Furthermore, MALCOM can also\nfool black box fake news detectors to always output real news labels 90% of the\ntime on average. We also compare our attack model with four baselines across\ntwo real-world datasets, not only on attack performance but also on generated\nquality, coherency, transferability, and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:26:01 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 10:15:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Le", "Thai", ""], ["Wang", "Suhang", ""], ["Lee", "Dongwon", ""]]}, {"id": "2009.01054", "submitter": "Antti Airola", "authors": "Markus Viljanen, Antti Airola, Tapio Pahikkala", "title": "Generalized vec trick for fast learning of pairwise kernel models", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise learning corresponds to the supervised learning setting where the\ngoal is to make predictions for pairs of objects. Prominent applications\ninclude predicting drug-target or protein-protein interactions, or\ncustomer-product preferences. Several kernel functions have been proposed for\nincorporating prior knowledge about the relationship between the objects, when\ntraining kernel based learning methods. However, the number of training pairs n\nis often very large, making O(n^2) cost of constructing the pairwise kernel\nmatrix infeasible. If each training pair x= (d,t) consists of drug d and target\nt, let m and q denote the number of unique drugs and targets appearing in the\ntraining pairs. In many real-world applications m,q << n, which can be used to\ndevelop computational shortcuts. Recently, a O(nm+nq) time algorithm we refer\nto as the generalized vec trick was introduced for training kernel methods with\nthe Kronecker kernel. In this work, we show that a large class of pairwise\nkernels can be expressed as a sum of product matrices, which generalizes the\nresult to the most commonly used pairwise kernels. This includes symmetric and\nanti-symmetric, metric-learning, Cartesian, ranking, as well as linear,\npolynomial and Gaussian kernels. In the experiments, we demonstrate how the\nintroduced approach allows scaling pairwise kernels to much larger data sets\nthan previously feasible, and compare the kernels on a number of biological\ninteraction prediction tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:27:51 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Viljanen", "Markus", ""], ["Airola", "Antti", ""], ["Pahikkala", "Tapio", ""]]}, {"id": "2009.01062", "submitter": "Akram Hussain Engr.", "authors": "Akram Hussain, Yuan Luo", "title": "Decentralized Source Localization without Sensor Parameters in Wireless\n  Sensor Networks", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the source (event) localization problem in decentralized\nwireless sensor networks (WSNs) under the fault model without knowing the\nsensor parameters. Event localizations have many applications such as\nlocalizing intruders, Wifi hotspots and users, and faults in power systems.\nPrevious studies assume the true knowledge (or good estimates) of sensor\nparameters (e.g., fault model probability or Region of Influence (ROI) of the\nsource) for source localization. However, we propose two methods to estimate\nthe source location in this paper under the fault model: hitting set approach\nand feature selection method, which only utilize the noisy data set at the\nfusion center for estimation of the source location without knowing the sensor\nparameters. The proposed methods have been shown to localize the source\neffectively. We also study the lower bound on the sample complexity requirement\nfor hitting set method. These methods have also been extended for multiple\nsources localizations. In addition, we modify the proposed feature selection\napproach to use maximum likelihood. Finally, extensive simulations are carried\nout for different settings (i.e., the number of sensor nodes and sample\ncomplexity) to validate our proposed methods in comparison to centroid, maximum\nlikelihood, FTML, SNAP estimators.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:34:55 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 13:32:52 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 13:18:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hussain", "Akram", ""], ["Luo", "Yuan", ""]]}, {"id": "2009.01076", "submitter": "Simon Jaxy", "authors": "Simon Jaxy", "title": "Teaching a Machine to Diagnose a Heart Disease; Beginning from\n  digitizing scanned ECGs to detecting the Brugada Syndrome (BrS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical diagnoses can shape and change the life of a person drastically.\nTherefore, it is always best advised to collect as much evidence as possible to\nbe certain about the diagnosis. Unfortunately, in the case of the Brugada\nSyndrome (BrS), a rare and inherited heart disease, only one diagnostic\ncriterion exists, namely, a typical pattern in the Electrocardiogram (ECG). In\nthe following treatise, we question whether the investigation of ECG strips by\nthe means of machine learning methods improves the detection of BrS positive\ncases and hence, the diagnostic process. We propose a pipeline that reads in\nscanned images of ECGs, and transforms the encaptured signals to digital\ntime-voltage data after several processing steps. Then, we present a long\nshort-term memory (LSTM) classifier that is built based on the previously\nextracted data and that makes the diagnosis. The proposed pipeline\ndistinguishes between three major types of ECG images and recreates each\nrecorded lead signal. Features and quality are retained during the digitization\nof the data, albeit some encountered issues are not fully removed (Part I).\nNevertheless, the results of the aforesaid program are suitable for further\ninvestigation of the ECG by a computational method such as the proposed\nclassifier which proves the concept and could be the architectural basis for\nfuture research (Part II). This thesis is divided into two parts as they are\npart of the same process but conceptually different. It is hoped that this work\nbuilds a new foundation for computational investigations in the case of the BrS\nand its diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:12:50 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Jaxy", "Simon", ""]]}, {"id": "2009.01077", "submitter": "Isotta Landi", "authors": "Isotta Landi, Veronica Mandelli, Michael V. Lombardo", "title": "reval: a Python package to determine best clustering solutions with\n  stability-based relative clustering validation", "comments": null, "journal-ref": "Patterns (2021)", "doi": "10.1016/j.patter.2021.100228", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the best partition for a dataset can be a challenging task\nbecause of 1) the lack of a priori information within an unsupervised learning\nframework; and 2) the absence of a unique clustering validation approach to\nevaluate clustering solutions. Here we present reval: a Python package that\nleverages stability-based relative clustering validation methods to determine\nbest clustering solutions as the ones that best generalize to unseen data.\nStatistical software, both in R and Python, usually rely on internal validation\nmetrics, such as silhouette, to select the number of clusters that best fits\nthe data. Meanwhile, open-source software solutions that easily implement\nrelative clustering techniques are lacking. Internal validation methods exploit\ncharacteristics of the data itself to produce a result, whereas relative\napproaches attempt to leverage the unknown underlying distribution of data\npoints looking for generalizable and replicable results. The implementation of\nrelative validation methods can further the theory of clustering by enriching\nthe already available methods that can be used to investigate clustering\nresults in different situations and for different data distributions. This work\naims at contributing to this effort by developing a stability-based method that\nselects the best clustering solution as the one that replicates, via supervised\nlearning, on unseen subsets of data. The package works with multiple clustering\nand classification algorithms, hence allowing both the automatization of the\nlabeling process and the assessment of the stability of different clustering\nmechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:36:56 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 00:32:07 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Landi", "Isotta", ""], ["Mandelli", "Veronica", ""], ["Lombardo", "Michael V.", ""]]}, {"id": "2009.01109", "submitter": "Radu Tudor Ionescu", "authors": "Cezara Benegui, Radu Tudor Ionescu", "title": "Adversarial Attacks on Deep Learning Systems for User Identification\n  based on Motion Sensors", "comments": "Extended version (12 pages, 1 figure) of our paper (9 pages, 1\n  figure) accepted at ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the time being, mobile devices employ implicit authentication mechanisms,\nnamely, unlock patterns, PINs or biometric-based systems such as fingerprint or\nface recognition. While these systems are prone to well-known attacks, the\nintroduction of an explicit and unobtrusive authentication layer can greatly\nenhance security. In this study, we focus on deep learning methods for explicit\nauthentication based on motion sensor signals. In this scenario, attackers\ncould craft adversarial examples with the aim of gaining unauthorized access\nand even restraining a legitimate user to access his mobile device. To our\nknowledge, this is the first study that aims at quantifying the impact of\nadversarial attacks on machine learning models used for user identification\nbased on motion sensors. To accomplish our goal, we study multiple methods for\ngenerating adversarial examples. We propose three research questions regarding\nthe impact and the universality of adversarial examples, conducting relevant\nexperiments in order to answer our research questions. Our empirical results\ndemonstrate that certain adversarial example generation methods are specific to\nthe attacked classification model, while others tend to be generic. We thus\nconclude that deep neural networks trained for user identification tasks based\non motion sensors are subject to a high percentage of misclassification when\ngiven adversarial input.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 14:35:05 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 20:11:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Benegui", "Cezara", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "2009.01152", "submitter": "Hamed Ayoobi", "authors": "H. Ayoobi, H. Kasaei, M. Cao, R. Verbrugge, B. Verheij", "title": "Local-HDP: Interactive Open-Ended 3D Object Categorization in Real-Time\n  Robotic Scenarios", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a non-parametric hierarchical Bayesian approach for open-ended\n3D object categorization, named the Local Hierarchical Dirichlet Process\n(Local-HDP). This method allows an agent to learn independent topics for each\ncategory incrementally and to adapt to the environment in time. Hierarchical\nBayesian approaches like Latent Dirichlet Allocation (LDA) can transform\nlow-level features to high-level conceptual topics for 3D object\ncategorization. However, the efficiency and accuracy of LDA-based approaches\ndepend on the number of topics that is chosen manually. Moreover, fixing the\nnumber of topics for all categories can lead to overfitting or underfitting of\nthe model. In contrast, the proposed Local-HDP can autonomously determine the\nnumber of topics for each category. Furthermore, the online variational\ninference method has been adapted for fast posterior approximation in the\nLocal-HDP model. Experiments show that the proposed Local-HDP method\noutperforms other state-of-the-art approaches in terms of accuracy,\nscalability, and memory efficiency by a large margin. Moreover, two robotic\nexperiments have been conducted to show the applicability of the proposed\napproach in real-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 15:55:49 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 17:18:12 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 17:58:49 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ayoobi", "H.", ""], ["Kasaei", "H.", ""], ["Cao", "M.", ""], ["Verbrugge", "R.", ""], ["Verheij", "B.", ""]]}, {"id": "2009.01185", "submitter": "Zhongyang Li", "authors": "Zhongyang Li", "title": "Exact Recovery of Community Detection in k-Community Gaussian Mixture\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the community detection problem on a Gaussian mixture model, in\nwhich vertices are divided into $k\\geq 2$ distinct communities. The major\ndifference in our model is that the intensities for Gaussian perturbations are\ndifferent for different entries in the observation matrix, and we do not assume\nthat every community has the same number of vertices. We explicitly find the\nthreshold for the exact recovery of the maximum likelihood estimation.\nApplications include the community detection on hypergraphs.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 19:27:20 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Li", "Zhongyang", ""]]}, {"id": "2009.01231", "submitter": "E M Wasifur Rahman Chowdhury", "authors": "Wasifur Rahman, Sangwu Lee, Md. Saiful Islam, Victor Nikhil Antony,\n  Harshil Ratnu, Mohammad Rafayet Ali, Abdullah Al Mamun, Ellen Wagner, Stella\n  Jensen-Roberts, Max A. Little, Ray Dorsey, and Ehsan Hoque", "title": "Detecting Parkinson's Disease From an Online Speech-task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CY cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we envision a web-based framework that can help anyone,\nanywhere around the world record a short speech task, and analyze the recorded\ndata to screen for Parkinson's disease (PD). We collected data from 726 unique\nparticipants (262 PD, 38% female; 464 non-PD, 65% female; average age: 61) --\nfrom all over the US and beyond. A small portion of the data was collected in a\nlab setting to compare quality. The participants were instructed to utter a\npopular pangram containing all the letters in the English alphabet \"the quick\nbrown fox jumps over the lazy dog..\". We extracted both standard acoustic\nfeatures (Mel Frequency Cepstral Coefficients (MFCC), jitter and shimmer\nvariants) and deep learning based features from the speech data. Using these\nfeatures, we trained several machine learning algorithms. We achieved 0.75 AUC\n(Area Under The Curve) performance on determining presence of self-reported\nParkinson's disease by modeling the standard acoustic features through the\nXGBoost -- a gradient-boosted decision tree model. Further analysis reveal that\nthe widely used MFCC features and a subset of previously validated dysphonia\nfeatures designed for detecting Parkinson's from verbal phonation task\n(pronouncing 'ahh') contains the most distinct information. Our model performed\nequally well on data collected in controlled lab environment as well as 'in the\nwild' across different gender and age groups. Using this tool, we can collect\ndata from almost anyone anywhere with a video/audio enabled device,\ncontributing to equity and access in neurological care.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:16:24 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 01:14:48 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 01:35:03 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 21:08:05 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Rahman", "Wasifur", ""], ["Lee", "Sangwu", ""], ["Islam", "Md. Saiful", ""], ["Antony", "Victor Nikhil", ""], ["Ratnu", "Harshil", ""], ["Ali", "Mohammad Rafayet", ""], ["Mamun", "Abdullah Al", ""], ["Wagner", "Ellen", ""], ["Jensen-Roberts", "Stella", ""], ["Little", "Max A.", ""], ["Dorsey", "Ray", ""], ["Hoque", "Ehsan", ""]]}, {"id": "2009.01235", "submitter": "Prasanna Date", "authors": "Prasanna Date", "title": "Quantum Discriminator for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computers operate in the high-dimensional tensor product spaces and\nare known to outperform classical computers on many problems. They are poised\nto accelerate machine learning tasks in the future. In this work, we operate in\nthe quantum machine learning (QML) regime where a QML model is trained using a\nquantum-classical hybrid algorithm and inferencing is performed using a quantum\nalgorithm. We leverage the traditional two-step machine learning workflow,\nwhere features are extracted from the data in the first step and a\ndiscriminator acting on the extracted features is used to classify the data in\nthe second step. Assuming that the binary features have been extracted from the\ndata, we propose a quantum discriminator for binary classification. The quantum\ndiscriminator takes as input the binary features of a data point and a\nprediction qubit in the zero state, and outputs the correct class of the data\npoint. The quantum discriminator is defined by a parameterized unitary matrix\n$U_\\Theta$ containing $\\mathcal{O}(N)$ parameters, where $N$ is the number of\ndata points in the training data set. Furthermore, we show that the quantum\ndiscriminator can be trained in $\\mathcal{O}(N \\log N)$ time using\n$\\mathcal{O}(N \\log N)$ classical bits and $\\mathcal{O}(\\log N)$ qubits. We\nalso show that inferencing for the quantum discriminator can be done in\n$\\mathcal{O}(N)$ time using $\\mathcal{O}(\\log N)$ qubits. Finally, we use the\nquantum discriminator to classify the XOR problem on the IBM Q universal\nquantum computer with $100\\%$ accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:00:23 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Date", "Prasanna", ""]]}, {"id": "2009.01272", "submitter": "Sirui Xie", "authors": "Sirui Xie, Shoukang Hu, Xinjiang Wang, Chunxiao Liu, Jianping Shi,\n  Xunying Liu, Dahua Lin", "title": "Understanding the wiring evolution in differentiable neural architecture\n  search", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Controversy exists on whether differentiable neural architecture search\nmethods discover wiring topology effectively. To understand how wiring topology\nevolves, we study the underlying mechanism of several existing differentiable\nNAS frameworks. Our investigation is motivated by three observed searching\npatterns of differentiable NAS: 1) they search by growing instead of pruning;\n2) wider networks are more preferred than deeper ones; 3) no edges are selected\nin bi-level optimization. To anatomize these phenomena, we propose a unified\nview on searching algorithms of existing frameworks, transferring the global\noptimization to local cost minimization. Based on this reformulation, we\nconduct empirical and theoretical analyses, revealing implicit inductive biases\nin the cost's assignment mechanism and evolution dynamics that cause the\nobserved phenomena. These biases indicate strong discrimination towards certain\ntopologies. To this end, we pose questions that future differentiable methods\nfor neural wiring discovery need to confront, hoping to evoke a discussion and\nrethinking on how much bias has been enforced implicitly in existing NAS\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:08:34 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 20:19:26 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 18:55:33 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 05:44:52 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Xie", "Sirui", ""], ["Hu", "Shoukang", ""], ["Wang", "Xinjiang", ""], ["Liu", "Chunxiao", ""], ["Shi", "Jianping", ""], ["Liu", "Xunying", ""], ["Lin", "Dahua", ""]]}, {"id": "2009.01279", "submitter": "Christopher Strohmeier", "authors": "C. Strohmeier, D. Needell", "title": "Clustering of Nonnegative Data and an Application to Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple algorithm to cluster nonnegative data\nlying in disjoint subspaces. We analyze its performance in relation to a\ncertain measure of correlation between said subspaces. We use our clustering\nalgorithm to develop a matrix completion algorithm which can outperform\nstandard matrix completion algorithms on data matrices satisfying certain\nnatural conditions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:24:47 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Strohmeier", "C.", ""], ["Needell", "D.", ""]]}, {"id": "2009.01328", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew", "title": "An Internal Cluster Validity Index Using a Distance-based Separability\n  Measure", "comments": "8 pages, 4 figures. Accepted by IEEE ICTAI 2020 (Long Paper & Oral\n  Presentation)", "journal-ref": "IEEE 32nd International Conference on Tools with Artificial\n  Intelligence (ICTAI), 2020, pp. 827-834", "doi": "10.1109/ICTAI50040.2020.00131", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To evaluate clustering results is a significant part of cluster analysis.\nThere are no true class labels for clustering in typical unsupervised learning.\nThus, a number of internal evaluations, which use predicted labels and data,\nhave been created. They are also named internal cluster validity indices\n(CVIs). Without true labels, to design an effective CVI is not simple because\nit is similar to create a clustering method. And, to have more CVIs is crucial\nbecause there is no universal CVI that can be used to measure all datasets, and\nno specific method for selecting a proper CVI for clusters without true labels.\nTherefore, to apply more CVIs to evaluate clustering results is necessary. In\nthis paper, we propose a novel CVI - called Distance-based Separability Index\n(DSI), based on a data separability measure. We applied the DSI and eight other\ninternal CVIs including early studies from Dunn (1974) to most recent studies\nCVDD (2019) as comparison. We used an external CVI as ground truth for\nclustering results of five clustering algorithms on 12 real and 97 synthetic\ndatasets. Results show DSI is an effective, unique, and competitive CVI to\nother compared CVIs. In addition, we summarized the general process to evaluate\nCVIs and created a new method - rank difference - to compare the results of\nCVIs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 20:20:29 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 21:22:03 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""]]}, {"id": "2009.01339", "submitter": "Udari Madhushani", "authors": "Udari Madhushani and Naomi Leonard", "title": "Heterogeneous Explore-Exploit Strategies on Multi-Star Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the benefits of heterogeneity in multi-agent explore-exploit\ndecision making where the goal of the agents is to maximize cumulative group\nreward. To do so we study a class of distributed stochastic bandit problems in\nwhich agents communicate over a multi-star network and make sequential choices\namong options in the same uncertain environment. Typically, in multi-agent\nbandit problems, agents use homogeneous decision-making strategies. However,\ngroup performance can be improved by incorporating heterogeneity into the\nchoices agents make, especially when the network graph is irregular, i.e. when\nagents have different numbers of neighbors. We design and analyze new\nheterogeneous explore-exploit strategies, using the multi-star as the model\nirregular network graph. The key idea is to enable center agents to do more\nexploring than they would do using the homogeneous strategy, as a means of\nproviding more useful data to the peripheral agents. In the case all agents\nbroadcast their reward values and choices to their neighbors with the same\nprobability, we provide theoretical guarantees that group performance improves\nunder the proposed heterogeneous strategies as compared to under homogeneous\nstrategies. We use numerical simulations to illustrate our results and to\nvalidate our theoretical bounds.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 20:56:49 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 01:47:29 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Madhushani", "Udari", ""], ["Leonard", "Naomi", ""]]}, {"id": "2009.01358", "submitter": "Aur\\'elien Serre", "authors": "Aur\\'elien Serre, Didier Ch\\'etelat, Andrea Lodi", "title": "Change Point Detection by Cross-Entropy Maximization", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many offline unsupervised change point detection algorithms rely on\nminimizing a penalized sum of segment-wise costs. We extend this framework by\nproposing to minimize a sum of discrepancies between segments. In particular,\nwe propose to select the change points so as to maximize the cross-entropy\nbetween successive segments, balanced by a penalty for introducing new change\npoints. We propose a dynamic programming algorithm to solve this problem and\nanalyze its complexity. Experiments on two challenging datasets demonstrate the\nadvantages of our method compared to three state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:45:13 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Serre", "Aur\u00e9lien", ""], ["Ch\u00e9telat", "Didier", ""], ["Lodi", "Andrea", ""]]}, {"id": "2009.01360", "submitter": "Djordje Gligorijevic", "authors": "Djordje Gligorijevic, Tian Zhou, Bharatbhushan Shetty, Brendan Kitts,\n  Shengjun Pan, Junwei Pan, Aaron Flores", "title": "Bid Shading in The Brave New World of First-Price Auctions", "comments": "In Proceedings of the 29th ACM International Conference on\n  Information and Knowledge Management (CIKM'20), October 19-23, 2020, Virtual\n  Event, Ireland", "journal-ref": null, "doi": "10.1145/3340531.3412689", "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online auctions play a central role in online advertising, and are one of the\nmain reasons for the industry's scalability and growth. With great changes in\nhow auctions are being organized, such as changing the second- to first-price\nauction type, advertisers and demand platforms are compelled to adapt to a new\nvolatile environment. Bid shading is a known technique for preventing\noverpaying in auction systems that can help maintain the strategy equilibrium\nin first-price auctions, tackling one of its greatest drawbacks. In this study,\nwe propose a machine learning approach of modeling optimal bid shading for\nnon-censored online first-price ad auctions. We clearly motivate the approach\nand extensively evaluate it in both offline and online settings on a major\ndemand side platform. The results demonstrate the superiority and robustness of\nthe new approach as compared to the existing approaches across a range of\nperformance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:48:21 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Gligorijevic", "Djordje", ""], ["Zhou", "Tian", ""], ["Shetty", "Bharatbhushan", ""], ["Kitts", "Brendan", ""], ["Pan", "Shengjun", ""], ["Pan", "Junwei", ""], ["Flores", "Aaron", ""]]}, {"id": "2009.01362", "submitter": "Matthew Dowling", "authors": "Matthew Dowling, Yuan Zhao, Il Memming Park", "title": "Non-parametric generalized linear model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in statistical neuroscience is to model how neurons\nencode information by analyzing electrophysiological recordings. A popular and\nwidely-used approach is to fit the spike trains with an autoregressive point\nprocess model. These models are characterized by a set of convolutional\ntemporal filters, whose subsequent analysis can help reveal how neurons encode\nstimuli, interact with each other, and process information. In practice a\nsufficiently rich but small ensemble of temporal basis functions needs to be\nchosen to parameterize the filters. However, obtaining a satisfactory fit often\nrequires burdensome model selection and fine tuning the form of the basis\nfunctions and their temporal span. In this paper we propose a nonparametric\napproach for jointly inferring the filters and hyperparameters using the\nGaussian process framework. Our method is computationally efficient taking\nadvantage of the sparse variational approximation while being flexible and rich\nenough to characterize arbitrary filters in continuous time lag. Moreover, our\nmethod automatically learns the temporal span of the filter. For the particular\napplication in neuroscience, we designed priors for stimulus and history\nfilters useful for the spike trains. We compare and validate our method on\nsimulated and real neural spike train data.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:54:53 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Dowling", "Matthew", ""], ["Zhao", "Yuan", ""], ["Park", "Il Memming", ""]]}, {"id": "2009.01367", "submitter": "Nathan Tsoi", "authors": "Nathan Tsoi, Yofti Milkessa, Marynel V\\'azquez", "title": "A Heaviside Function Approximation for Neural Network Binary\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network binary classifiers are often evaluated on metrics like\naccuracy and $F_1$-Score, which are based on confusion matrix values (True\nPositives, False Positives, False Negatives, and True Negatives). However,\nthese classifiers are commonly trained with a different loss, e.g. log loss.\nWhile it is preferable to perform training on the same loss as the evaluation\nmetric, this is difficult in the case of confusion matrix based metrics because\nset membership is a step function without a derivative useful for\nbackpropagation. To address this challenge, we propose an approximation of the\nstep function that adheres to the properties necessary for effective training\nof binary networks using confusion matrix based metrics. This approach allows\nfor end-to-end training of binary deep neural classifiers via batch gradient\ndescent. We demonstrate the flexibility of this approach in several\napplications with varying levels of class imbalance. We also demonstrate how\nthe approximation allows balancing between precision and recall in the\nappropriate ratio for the task at hand.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 22:13:26 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Tsoi", "Nathan", ""], ["Milkessa", "Yofti", ""], ["V\u00e1zquez", "Marynel", ""]]}, {"id": "2009.01395", "submitter": "E Zhenqian", "authors": "E Zhenqian and Gao Weiguo", "title": "A Partial Regularization Method for Network Compression", "comments": "made a mistake of submit the paper; I have updated the version of\n  arXiv:1912.05078", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have achieved remarkable success relying on the\ndeveloping availability of GPUs and large-scale datasets with increasing\nnetwork depth and width. However, due to the expensive computation and\nintensive memory, researchers have concentrated on designing compression\nmethods in order to make them practical for constrained platforms. In this\npaper, we propose an approach of partial regularization rather than the\noriginal form of penalizing all parameters, which is said to be full\nregularization, to conduct model compression at a higher speed. It is\nreasonable and feasible according to the existence of the permutation invariant\nproperty of neural networks. Experimental results show that as we expected, the\ncomputational complexity is reduced by observing less running time in almost\nall situations. It should be owing to the fact that partial regularization\nmethod invovles a lower number of elements for calculation. Surprisingly, it\nhelps to improve some important metrics such as regression fitting results and\nclassification accuracy in both training and test phases on multiple datasets,\ntelling us that the pruned models have better performance and generalization\nability. What's more, we analyze the results and draw a conclusion that an\noptimal network structure must exist and depend on the input data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 00:38:27 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 02:51:03 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Zhenqian", "E", ""], ["Weiguo", "Gao", ""]]}, {"id": "2009.01398", "submitter": "Jacob Springer", "authors": "Jacob M. Springer, Garrett T. Kenyon", "title": "It's Hard for Neural Networks To Learn the Game of Life", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efforts to improve the learning abilities of neural networks have focused\nmostly on the role of optimization methods rather than on weight\ninitializations. Recent findings, however, suggest that neural networks rely on\nlucky random initial weights of subnetworks called \"lottery tickets\" that\nconverge quickly to a solution. To investigate how weight initializations\naffect performance, we examine small convolutional networks that are trained to\npredict n steps of the two-dimensional cellular automaton Conway's Game of\nLife, the update rules of which can be implemented efficiently in a 2n+1 layer\nconvolutional network. We find that networks of this architecture trained on\nthis task rarely converge. Rather, networks require substantially more\nparameters to consistently converge. In addition, near-minimal architectures\nare sensitive to tiny changes in parameters: changing the sign of a single\nweight can cause the network to fail to learn. Finally, we observe a critical\nvalue d_0 such that training minimal networks with examples in which cells are\nalive with probability d_0 dramatically increases the chance of convergence to\na solution. We conclude that training convolutional neural networks to learn\nthe input/output function represented by n steps of Game of Life exhibits many\ncharacteristics predicted by the lottery ticket hypothesis, namely, that the\nsize of the networks required to learn this function are often significantly\nlarger than the minimal network required to implement the function.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 00:47:08 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Springer", "Jacob M.", ""], ["Kenyon", "Garrett T.", ""]]}, {"id": "2009.01407", "submitter": "Masanobu Inubushi", "authors": "Masanobu Inubushi and Susumu Goto", "title": "Transfer learning for nonlinear dynamics and its application to fluid\n  turbulence", "comments": "8 pages, 7 figures", "journal-ref": "Phys. Rev. E 102, 043301 (2020)", "doi": "10.1103/PhysRevE.102.043301", "report-no": null, "categories": "physics.flu-dyn math.DS nlin.CD physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce transfer learning for nonlinear dynamics, which enables\nefficient predictions of chaotic dynamics by utilizing a small amount of data.\nFor the Lorenz chaos, by optimizing the transfer rate, we accomplish more\naccurate inference than the conventional method by an order of magnitude.\nMoreover, a surprisingly small amount of learning is enough to infer the energy\ndissipation rate of the Navier-Stokes turbulence because we can, thanks to the\nsmall-scale universality of turbulence, transfer a large amount of the\nknowledge learned from turbulence data at lower Reynolds number.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 01:40:56 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Inubushi", "Masanobu", ""], ["Goto", "Susumu", ""]]}, {"id": "2009.01411", "submitter": "Bowen Jing", "authors": "Bowen Jing, Stephan Eismann, Patricia Suriana, Raphael J.L. Townshend,\n  Ron Dror", "title": "Learning from Protein Structure with Geometric Vector Perceptrons", "comments": "Presented at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning on 3D structures of large biomolecules is emerging as a distinct\narea in machine learning, but there has yet to emerge a unifying network\narchitecture that simultaneously leverages the graph-structured and geometric\naspects of the problem domain. To address this gap, we introduce geometric\nvector perceptrons, which extend standard dense layers to operate on\ncollections of Euclidean vectors. Graph neural networks equipped with such\nlayers are able to perform both geometric and relational reasoning on efficient\nand natural representations of macromolecular structure. We demonstrate our\napproach on two important problems in learning from protein structure: model\nquality assessment and computational protein design. Our approach improves over\nexisting classes of architectures, including state-of-the-art graph-based and\nvoxel-based methods. We release our code at https://github.com/drorlab/gvp.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 01:54:25 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 15:30:18 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 02:35:25 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Jing", "Bowen", ""], ["Eismann", "Stephan", ""], ["Suriana", "Patricia", ""], ["Townshend", "Raphael J. L.", ""], ["Dror", "Ron", ""]]}, {"id": "2009.01433", "submitter": "Alejandro Parada-Mayorga", "authors": "Alejandro Parada-Mayorga and Alejandro Ribeiro", "title": "Algebraic Neural Networks: Stability to Deformations", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3084537", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algebraic neural networks (AlgNNs) with commutative algebras which\nunify diverse architectures such as Euclidean convolutional neural networks,\ngraph neural networks, and group neural networks under the umbrella of\nalgebraic signal processing. An AlgNN is a stacked layered information\nprocessing structure where each layer is conformed by an algebra, a vector\nspace and a homomorphism between the algebra and the space of endomorphisms of\nthe vector space. Signals are modeled as elements of the vector space and are\nprocessed by convolutional filters that are defined as the images of the\nelements of the algebra under the action of the homomorphism. We analyze\nstability of algebraic filters and AlgNNs to deformations of the homomorphism\nand derive conditions on filters that lead to Lipschitz stable operators. We\nconclude that stable algebraic filters have frequency responses -- defined as\neigenvalue domain representations -- whose derivative is inversely proportional\nto the frequency -- defined as eigenvalue magnitudes. It follows that for a\ngiven level of discriminability, AlgNNs are more stable than algebraic filters,\nthereby explaining their better empirical performance. This same phenomenon has\nbeen proven for Euclidean convolutional neural networks and graph neural\nnetworks. Our analysis shows that this is a deep algebraic property shared by a\nnumber of architectures.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 03:41:38 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 19:04:39 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 22:14:54 GMT"}, {"version": "v4", "created": "Sat, 1 May 2021 05:10:35 GMT"}, {"version": "v5", "created": "Wed, 30 Jun 2021 23:17:55 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Parada-Mayorga", "Alejandro", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2009.01444", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Sara Evensen and Chang Ge and Dongjin Choi and \\c{C}a\\u{g}atay\n  Demiralp", "title": "Data Programming by Demonstration: A Framework for Interactively\n  Learning Labeling Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DB cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data programming is a programmatic weak supervision approach to efficiently\ncurate large-scale labeled training data. Writing data programs (labeling\nfunctions) requires, however, both programming literacy and domain expertise.\nMany subject matter experts have neither programming proficiency nor time to\neffectively write data programs. Furthermore, regardless of one's expertise in\ncoding or machine learning, transferring domain expertise into labeling\nfunctions by enumerating rules and thresholds is not only time consuming but\nalso inherently difficult. Here we propose a new framework, data programming by\ndemonstration (DPBD), to generate labeling rules using interactive\ndemonstrations of users. DPBD aims to relieve the burden of writing labeling\nfunctions from users, enabling them to focus on higher-level semantics such as\nidentifying relevant signals for labeling tasks. We operationalize our\nframework with Ruler, an interactive system that synthesizes labeling rules for\ndocument classification by using span-level annotations of users on document\nexamples. We compare Ruler with conventional data programming through a user\nstudy conducted with 10 data scientists creating labeling functions for\nsentiment and spam classification tasks. We find that Ruler is easier to use\nand learn and offers higher overall satisfaction, while providing\ndiscriminative model performances comparable to ones achieved by conventional\ndata programming.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 04:25:08 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 01:44:22 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 22:44:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Evensen", "Sara", ""], ["Ge", "Chang", ""], ["Choi", "Dongjin", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "2009.01461", "submitter": "Sunghwan Moon", "authors": "Jae-Mo Kang and Sunghwan Moon", "title": "Error estimate for a universal function approximator of ReLU network\n  with a local connection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have shown high successful performance in a wide range of\ntasks, but further studies are needed to improve its performance. We analyze\nthe approximation error of the specific neural network architecture with a\nlocal connection and higher application than one with the full connection\nbecause the local-connected network can be used to explain diverse neural\nnetworks such as CNNs. Our error estimate depends on two parameters: one\ncontrolling the depth of the hidden layer, and the other, the width of the\nhidden layers.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 05:58:46 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Kang", "Jae-Mo", ""], ["Moon", "Sunghwan", ""]]}, {"id": "2009.01462", "submitter": "Qi Sun", "authors": "Qi Sun, Hexin Dong, Zewei Chen, Weizhen Dian, Jiacheng Sun, Yitong\n  Sun, Zhenguo Li, Bin Dong", "title": "A Practical Layer-Parallel Training Algorithm for Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based algorithms for training ResNets typically require a forward\npass of the input data, followed by back-propagating the objective gradient to\nupdate parameters, which are time-consuming for deep ResNets. To break the\ndependencies between modules in both the forward and backward modes,\nauxiliary-variable methods such as the penalty and augmented Lagrangian (AL)\napproaches have attracted much interest lately due to their ability to exploit\nlayer-wise parallelism. However, we observe that large communication overhead\nand lacking data augmentation are two key challenges of these methods, which\nmay lead to low speedup ratio and accuracy drop across multiple compute\ndevices. Inspired by the optimal control formulation of ResNets, we propose a\nnovel serial-parallel hybrid training strategy to enable the use of data\naugmentation, together with downsampling filters to reduce the communication\ncost. The proposed strategy first trains the network parameters by solving a\nsuccession of independent sub-problems in parallel and then corrects the\nnetwork parameters through a full serial forward-backward propagation of data.\nSuch a strategy can be applied to most of the existing layer-parallel training\nmethods using auxiliary variables. As an example, we validate the proposed\nstrategy using penalty and AL methods on ResNet and WideResNet across MNIST,\nCIFAR-10 and CIFAR-100 datasets, achieving significant speedup over the\ntraditional layer-serial training methods while maintaining comparable\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 06:03:30 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 14:25:56 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Sun", "Qi", ""], ["Dong", "Hexin", ""], ["Chen", "Zewei", ""], ["Dian", "Weizhen", ""], ["Sun", "Jiacheng", ""], ["Sun", "Yitong", ""], ["Li", "Zhenguo", ""], ["Dong", "Bin", ""]]}, {"id": "2009.01476", "submitter": "Jordan Bishop", "authors": "Jordan T. Bishop, Marcus Gallagher", "title": "Optimality-based Analysis of XCSF Compaction in Discrete Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58115-2_33", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems (LCSs) are population-based predictive systems\nthat were originally envisioned as agents to act in reinforcement learning (RL)\nenvironments. These systems can suffer from population bloat and so are\namenable to compaction techniques that try to strike a balance between\npopulation size and performance. A well-studied LCS architecture is XCSF, which\nin the RL setting acts as a Q-function approximator. We apply XCSF to a\ndeterministic and stochastic variant of the FrozenLake8x8 environment from\nOpenAI Gym, with its performance compared in terms of function approximation\nerror and policy accuracy to the optimal Q-functions and policies produced by\nsolving the environments via dynamic programming. We then introduce a novel\ncompaction algorithm (Greedy Niche Mass Compaction - GNMC) and study its\noperation on XCSF's trained populations. Results show that given a suitable\nparametrisation, GNMC preserves or even slightly improves function\napproximation error while yielding a significant reduction in population size.\nReasonable preservation of policy accuracy also occurs, and we link this metric\nto the commonly used steps-to-goal metric in maze-like environments,\nillustrating how the metrics are complementary rather than competitive.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 06:31:43 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Bishop", "Jordan T.", ""], ["Gallagher", "Marcus", ""]]}, {"id": "2009.01492", "submitter": "Alexander Jung", "authors": "A. Jung", "title": "Explainable Empirical Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of modern machine learning methods in decision making\ncrucially depends on their interpretability or explainability. The human users\n(decision makers) of machine learning methods are often not only interested in\ngetting accurate predictions or projections. Rather, as a decision-maker, the\nuser also needs a convincing answer (or explanation) to the question of why a\nparticular prediction was delivered. Explainable machine learning might be a\nlegal requirement when used for decision making with an immediate effect on the\nhealth of human beings. As an example consider the computer vision of a\nself-driving car whose predictions are used to decide if to stop the car. We\nhave recently proposed an information-theoretic approach to construct\npersonalized explanations for predictions obtained from ML. This method was\nmodel-agnostic and only required some training samples of the model to be\nexplained along with a user feedback signal. This paper uses an\ninformation-theoretic measure for the quality of an explanation to learn\npredictors that are intrinsically explainable to a specific user. Our approach\nis not restricted to a particular hypothesis space, such as linear maps or\nshallow decision trees, whose predictor maps are considered as explainable by\ndefinition. Rather, we regularize an arbitrary hypothesis space using a\npersonalized measure for the explainability of a particular predictor.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 07:16:34 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Jung", "A.", ""]]}, {"id": "2009.01495", "submitter": "Ran Tian", "authors": "Ran Tian, Liting Sun, and Masayoshi Tomizuka", "title": "Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse\n  Reward Learning with Iterative Reasoning and Cumulative Prospect Theory", "comments": "Accepted by 2021 AAAI Conference on Artificial Intelligence", "journal-ref": "2021 AAAI Conference on Artificial Intelligence", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical game-theoretic approaches for multi-agent systems in both the\nforward policy design problem and the inverse reward learning problem often\nmake strong rationality assumptions: agents perfectly maximize expected\nutilities under uncertainties. Such assumptions, however, substantially\nmismatch with observed humans' behaviors such as satisficing with sub-optimal,\nrisk-seeking, and loss-aversion decisions. In this paper, we investigate the\nproblem of bounded risk-sensitive Markov Game (BRSMG) and its inverse reward\nlearning problem for modeling human realistic behaviors and learning human\nbehavioral models. Drawing on iterative reasoning models and cumulative\nprospect theory, we embrace that humans have bounded intelligence and maximize\nrisk-sensitive utilities in BRSMGs. Convergence analysis for both the forward\npolicy design and the inverse reward learning problems are established under\nthe BRSMG framework. We validate the proposed forward policy design and inverse\nreward learning algorithms in a navigation scenario. The results show that the\nbehaviors of agents demonstrate both risk-averse and risk-seeking\ncharacteristics. Moreover, in the inverse reward learning task, the proposed\nbounded risk-sensitive inverse learning algorithm outperforms a baseline\nrisk-neutral inverse learning algorithm by effectively recovering not only more\naccurate reward values but also the intelligence levels and the risk-measure\nparameters given demonstrations of agents' interactive behaviors.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 07:32:32 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 07:23:16 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 07:32:00 GMT"}, {"version": "v4", "created": "Sun, 15 Nov 2020 19:04:59 GMT"}, {"version": "v5", "created": "Sat, 19 Dec 2020 04:55:32 GMT"}, {"version": "v6", "created": "Sat, 13 Feb 2021 04:01:25 GMT"}, {"version": "v7", "created": "Sun, 21 Mar 2021 02:10:20 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Tian", "Ran", ""], ["Sun", "Liting", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2009.01514", "submitter": "Xiangyu Chang", "authors": "Shao-Bo Lin, Xiangyu Chang, Xingping Sun", "title": "Kernel Interpolation of High Dimensional Scattered Data", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sites selected from modeling high-dimensional problems often appear\nscattered in non-paternalistic ways. Except for sporadic-clustering at some\nspots, they become relatively far apart as the dimension of the ambient space\ngrows. These features defy any theoretical treatment that requires local or\nglobal quasi-uniformity of distribution of data sites. Incorporating a\nrecently-developed application of integral operator theory in machine learning,\nwe propose and study in the current article a new framework to analyze kernel\ninterpolation of high dimensional data, which features bounding stochastic\napproximation error by a hybrid (discrete and continuous) $K$-functional tied\nto the spectrum of the underlying kernel matrix. Both theoretical analysis and\nnumerical simulations show that spectra of kernel matrices are reliable and\nstable barometers for gauging the performance of kernel-interpolation methods\nfor high dimensional data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 08:34:00 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Lin", "Shao-Bo", ""], ["Chang", "Xiangyu", ""], ["Sun", "Xingping", ""]]}, {"id": "2009.01534", "submitter": "Yossi Adi", "authors": "Shahar Segal, Yossi Adi, Benny Pinkas, Carsten Baum, Chaya Ganesh,\n  Joseph Keshet", "title": "Fairness in the Eyes of the Data: Certifying Machine-Learning Models", "comments": "Accepted to AIES-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework that allows to certify the fairness degree of a model\nbased on an interactive and privacy-preserving test. The framework verifies any\ntrained model, regardless of its training process and architecture. Thus, it\nallows us to evaluate any deep learning model on multiple fairness definitions\nempirically. We tackle two scenarios, where either the test data is privately\navailable only to the tester or is publicly known in advance, even to the model\ncreator. We investigate the soundness of the proposed approach using\ntheoretical analysis and present statistical guarantees for the interactive\ntest. Finally, we provide a cryptographic technique to automate fairness\ntesting and certified inference with only black-box access to the model at hand\nwhile hiding the participants' sensitive data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 09:22:39 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 09:03:42 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 07:57:06 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Segal", "Shahar", ""], ["Adi", "Yossi", ""], ["Pinkas", "Benny", ""], ["Baum", "Carsten", ""], ["Ganesh", "Chaya", ""], ["Keshet", "Joseph", ""]]}, {"id": "2009.01555", "submitter": "Joerg Franke", "authors": "J\\\"org K.H. Franke, Gregor K\\\"ohler, Andr\\'e Biedenkapp, Frank Hutter", "title": "Sample-Efficient Automated Deep Reinforcement Learning", "comments": "In Proceedings of the International Conference on Learning\n  Representations (ICLR 2021), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress in challenging problems across various domains,\napplying state-of-the-art deep reinforcement learning (RL) algorithms remains\nchallenging due to their sensitivity to the choice of hyperparameters. This\nsensitivity can partly be attributed to the non-stationarity of the RL problem,\npotentially requiring different hyperparameter settings at various stages of\nthe learning process. Additionally, in the RL setting, hyperparameter\noptimization (HPO) requires a large number of environment interactions,\nhindering the transfer of the successes in RL to real-world applications. In\nthis work, we tackle the issues of sample-efficient and dynamic HPO in RL. We\npropose a population-based automated RL (AutoRL) framework to meta-optimize\narbitrary off-policy RL algorithms. In this framework, we optimize the\nhyperparameters and also the neural architecture while simultaneously training\nthe agent. By sharing the collected experience across the population, we\nsubstantially increase the sample efficiency of the meta-optimization. We\ndemonstrate the capabilities of our sample-efficient AutoRL approach in a case\nstudy with the popular TD3 algorithm in the MuJoCo benchmark suite, where we\nreduce the number of environment interactions needed for meta-optimization by\nup to an order of magnitude compared to population-based training.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:04:06 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 09:49:51 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 14:43:36 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Franke", "J\u00f6rg K. H.", ""], ["K\u00f6hler", "Gregor", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Hutter", "Frank", ""]]}, {"id": "2009.01561", "submitter": "Zahra Dasht Bozorgi", "authors": "Zahra Dasht Bozorgi, Irene Teinemaa, Marlon Dumas, Marcello La Rosa,\n  Artem Polyvyanyy", "title": "Process Mining Meets Causal Machine Learning: Discovering Causal Rules\n  from Event Logs", "comments": "8 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach to analyze an event log of a business process\nin order to generate case-level recommendations of treatments that maximize the\nprobability of a given outcome. Users classify the attributes in the event log\ninto controllable and non-controllable, where the former correspond to\nattributes that can be altered during an execution of the process (the possible\ntreatments). We use an action rule mining technique to identify treatments that\nco-occur with the outcome under some conditions. Since action rules are\ngenerated based on correlation rather than causation, we then use a causal\nmachine learning technique, specifically uplift trees, to discover subgroups of\ncases for which a treatment has a high causal effect on the outcome after\nadjusting for confounding variables. We test the relevance of this approach\nusing an event log of a loan application process and compare our findings with\nrecommendations manually produced by process mining experts.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:10:30 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Bozorgi", "Zahra Dasht", ""], ["Teinemaa", "Irene", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Polyvyanyy", "Artem", ""]]}, {"id": "2009.01564", "submitter": "Marc Hanussek", "authors": "Marc Hanussek, Matthias Blohm, Maximilien Kintz", "title": "Can AutoML outperform humans? An evaluation on popular OpenML datasets\n  using AutoML Benchmark", "comments": "To be published in AIRC 2020 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, Automated Machine Learning (AutoML) has gained much\nattention. With that said, the question arises whether AutoML can outperform\nresults achieved by human data scientists. This paper compares four AutoML\nframeworks on 12 different popular datasets from OpenML; six of them supervised\nclassification tasks and the other six supervised regression ones.\nAdditionally, we consider a real-life dataset from one of our recent projects.\nThe results show that the automated frameworks perform better or equal than the\nmachine learning community in 7 out of 12 OpenML tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:25:34 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 09:33:02 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Hanussek", "Marc", ""], ["Blohm", "Matthias", ""], ["Kintz", "Maximilien", ""]]}, {"id": "2009.01571", "submitter": "Pinkesh Badjatiya", "authors": "Anubha Kabra, Ayush Chopra, Nikaash Puri, Pinkesh Badjatiya, Sukriti\n  Verma, Piyush Gupta, Balaji K", "title": "MixBoost: Synthetic Oversampling with Boosted Mixup for Handling Extreme\n  Imbalance", "comments": "Work done as part of internship at MDSR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a classification model on a dataset where the instances of one class\noutnumber those of the other class is a challenging problem. Such imbalanced\ndatasets are standard in real-world situations such as fraud detection, medical\ndiagnosis, and computational advertising. We propose an iterative data\naugmentation method, MixBoost, which intelligently selects (Boost) and then\ncombines (Mix) instances from the majority and minority classes to generate\nsynthetic hybrid instances that have characteristics of both classes. We\nevaluate MixBoost on 20 benchmark datasets, show that it outperforms existing\napproaches, and test its efficacy through significance testing. We also present\nablation studies to analyze the impact of the different components of MixBoost.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:34:24 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Kabra", "Anubha", ""], ["Chopra", "Ayush", ""], ["Puri", "Nikaash", ""], ["Badjatiya", "Pinkesh", ""], ["Verma", "Sukriti", ""], ["Gupta", "Piyush", ""], ["K", "Balaji", ""]]}, {"id": "2009.01591", "submitter": "Malik Tiomoko", "authors": "Malik Tiomoko, Romain Couillet and Hafiz Tiomoko", "title": "Large Dimensional Analysis and Improvement of Multi Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi Task Learning (MTL) efficiently leverages useful information contained\nin multiple related tasks to help improve the generalization performance of all\ntasks. This article conducts a large dimensional analysis of a simple but, as\nwe shall see, extremely powerful when carefully tuned, Least Square Support\nVector Machine (LSSVM) version of MTL, in the regime where the dimension $p$ of\nthe data and their number $n$ grow large at the same rate.\n  Under mild assumptions on the input data, the theoretical analysis of the\nMTL-LSSVM algorithm first reveals the \"sufficient statistics\" exploited by the\nalgorithm and their interaction at work. These results demonstrate, as a\nstriking consequence, that the standard approach to MTL-LSSVM is largely\nsuboptimal, can lead to severe effects of negative transfer but that these\nimpairments are easily corrected. These corrections are turned into an improved\nMTL-LSSVM algorithm which can only benefit from additional data, and the\ntheoretical performance of which is also analyzed.\n  As evidenced and theoretically sustained in numerous recent works, these\nlarge dimensional results are robust to broad ranges of data distributions,\nwhich our present experiments corroborate. Specifically, the article reports a\nsystematically close behavior between theoretical and empirical performances on\npopular datasets, which is strongly suggestive of the applicability of the\nproposed carefully tuned MTL-LSSVM method to real data. This fine-tuning is\nfully based on the theoretical analysis and does not in particular require any\ncross validation procedure. Besides, the reported performances on real datasets\nalmost systematically outperform much more elaborate and less intuitive\nstate-of-the-art multi-task and transfer learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 11:40:14 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Tiomoko", "Malik", ""], ["Couillet", "Romain", ""], ["Tiomoko", "Hafiz", ""]]}, {"id": "2009.01672", "submitter": "Han Xu", "authors": "Han Xu, Yaxin Li, Xiaorui Liu, Hui Liu, Jiliang Tang", "title": "Yet Meta Learning Can Adapt Fast, It Can Also Break Easily", "comments": "Meta Learning Robustnss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta learning algorithms have been widely applied in many tasks for efficient\nlearning, such as few-shot image classification and fast reinforcement\nlearning. During meta training, the meta learner develops a common learning\nstrategy, or experience, from a variety of learning tasks. Therefore, during\nmeta test, the meta learner can use the learned strategy to quickly adapt to\nnew tasks even with a few training samples. However, there is still a dark side\nabout meta learning in terms of reliability and robustness. In particular, is\nmeta learning vulnerable to adversarial attacks? In other words, would a\nwell-trained meta learner utilize its learned experience to build wrong or\nlikely useless knowledge, if an adversary unnoticeably manipulates the given\ntraining set? Without the understanding of this problem, it is extremely risky\nto apply meta learning in safety-critical applications. Thus, in this paper, we\nperform the initial study about adversarial attacks on meta learning under the\nfew-shot classification problem. In particular, we formally define key elements\nof adversarial attacks unique to meta learning and propose the first attacking\nalgorithm against meta learning under various settings. We evaluate the\neffectiveness of the proposed attacking strategy as well as the robustness of\nseveral representative meta learning algorithms. Experimental results\ndemonstrate that the proposed attacking strategy can easily break the meta\nlearner and meta learning is vulnerable to adversarial attacks. The\nimplementation of the proposed framework will be released upon the acceptance\nof this paper.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 15:03:14 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Xu", "Han", ""], ["Li", "Yaxin", ""], ["Liu", "Xiaorui", ""], ["Liu", "Hui", ""], ["Tang", "Jiliang", ""]]}, {"id": "2009.01674", "submitter": "Yanqiao Zhu", "authors": "Yanqiao Zhu and Yichen Xu and Feng Yu and Shu Wu and Liang Wang", "title": "CAGNN: Cluster-Aware Graph Neural Networks for Unsupervised Graph\n  Representation Learning", "comments": "21 pages, in submission to ACM TIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised graph representation learning aims to learn low-dimensional node\nembeddings without supervision while preserving graph topological structures\nand node attributive features. Previous graph neural networks (GNN) require a\nlarge number of labeled nodes, which may not be accessible in real-world graph\ndata. In this paper, we present a novel cluster-aware graph neural network\n(CAGNN) model for unsupervised graph representation learning using\nself-supervised techniques. In CAGNN, we perform clustering on the node\nembeddings and update the model parameters by predicting the cluster\nassignments. Moreover, we observe that graphs often contain inter-class edges,\nwhich mislead the GNN model to aggregate noisy information from neighborhood\nnodes. We further refine the graph topology by strengthening intra-class edges\nand reducing node connections between different classes based on cluster\nlabels, which better preserves cluster structures in the embedding space. We\nconduct comprehensive experiments on two benchmark tasks using real-world\ndatasets. The results demonstrate the superior performance of the proposed\nmodel over existing baseline methods. Notably, our model gains over 7%\nimprovements in terms of accuracy on node clustering over state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 13:57:18 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Zhu", "Yanqiao", ""], ["Xu", "Yichen", ""], ["Yu", "Feng", ""], ["Wu", "Shu", ""], ["Wang", "Liang", ""]]}, {"id": "2009.01675", "submitter": "Zihao Wang", "authors": "Zihao Wang, Herv\\'e Delingette", "title": "Quasi-symplectic Langevin Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoder (VAE) is a very popular and well-investigated\ngenerative model in neural learning research. To leverage VAE in practical\ntasks dealing with a massive dataset of large dimensions, it is required to\ndeal with the difficulty of building low variance evidence lower bounds (ELBO).\nMarkov Chain Monte Carlo (MCMC) is an effective approach to tighten the ELBO\nfor approximating the posterior distribution and Hamiltonian Variational\nAutoencoder (HVAE) is an effective MCMC inspired approach for constructing a\nlow-variance ELBO that is amenable to the reparameterization trick. The HVAE\nadapted the Hamiltonian dynamic flow into variational inference that\nsignificantly improves the performance of the posterior estimation. We propose\nin this work a Langevin dynamic flow-based inference approach by incorporating\nthe gradients information in the inference process through the Langevin dynamic\nwhich is a kind of MCMC based method similar to HVAE. Specifically, we employ a\nquasi-symplectic integrator to cope with the prohibit problem of the Hessian\ncomputing in naive Langevin flow. We show the theoretical and practical\neffectiveness of the proposed framework with other gradient flow-based methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:13:27 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 13:28:54 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 18:50:43 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 09:05:17 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Zihao", ""], ["Delingette", "Herv\u00e9", ""]]}, {"id": "2009.01696", "submitter": "Martin Zaefferer", "authors": "Tom Peetz, Sebastian Vogt, Martin Zaefferer, Thomas Bartz-Beielstein", "title": "Simulation of an Elevator Group Control Using Generative Adversarial\n  Networks and Related AI Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing new, innovative technologies is a crucial task for safety and\nacceptance. But how can new systems be tested if no historical real-world data\nexist? Simulation provides an answer to this important question. Classical\nsimulation tools such as event-based simulation are well accepted. But most of\nthese established simulation models require the specification of many\nparameters. Furthermore, simulation runs, e.g., CFD simulations, are very time\nconsuming. Generative Adversarial Networks (GANs) are powerful tools for\ngenerating new data for a variety of tasks. Currently, their most frequent\napplication domain is image generation. This article investigates the\napplicability of GANs for imitating simulations. We are comparing the\nsimulation output of a technical system with the output of a GAN. To exemplify\nthis approach, a well-known multi-car elevator system simulator was chosen. Our\nstudy demonstrates the feasibility of this approach. It also discusses pitfalls\nand technical problems that occurred during the implementation. Although we\nwere able to show that in principle, GANs can be used as substitutes for\nexpensive simulation runs, we also show that they cannot be used \"out of the\nbox\". Fine tuning is needed. We present a proof-of-concept, which can serve as\na starting point for further research.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 14:22:26 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Peetz", "Tom", ""], ["Vogt", "Sebastian", ""], ["Zaefferer", "Martin", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2009.01721", "submitter": "Syrine Belakaria", "authors": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "title": "Max-value Entropy Search for Multi-Objective Bayesian Optimization with\n  Constraints", "comments": "2 figure, 1 table. arXiv admin note: text overlap with\n  arXiv:2008.07029", "journal-ref": "Third Workshop on Machine Learning and the Physical Sciences\n  (NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constrained multi-objective blackbox optimization\nusing expensive function evaluations, where the goal is to approximate the true\nPareto set of solutions satisfying a set of constraints while minimizing the\nnumber of function evaluations. For example, in aviation power system design\napplications, we need to find the designs that trade-off total energy and the\nmass while satisfying specific thresholds for motor temperature and voltage of\ncells. This optimization requires performing expensive computational\nsimulations to evaluate designs. In this paper, we propose a new approach\nreferred as {\\em Max-value Entropy Search for Multi-objective Optimization with\nConstraints (MESMOC)} to solve this problem. MESMOC employs an output-space\nentropy based acquisition function to efficiently select the sequence of inputs\nfor evaluation to uncover high-quality pareto-set solutions while satisfying\nconstraints.\n  We apply MESMOC to two real-world engineering design applications to\ndemonstrate its effectiveness over state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:00:01 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 02:20:58 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Belakaria", "Syrine", ""], ["Deshwal", "Aryan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2009.01726", "submitter": "Olivier Goudet Dr", "authors": "Mikael Escobar-Bach and Olivier Goudet", "title": "On the study of the Beran estimator for generalized censoring indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the analysis of time-to-event data, it is common to assume that\nonly partial information is given at hand. In the presence of right-censored\ndata with covariates, the conditional Kaplan-Meier estimator (also referred as\nthe Beran estimator) is known to propose a consistent estimate for the\nlifetimes conditional survival function. However, a necessary condition is the\nclear knowledge of whether each individual is censored or not, although, this\ninformation might be incomplete or even totally absent in practice. We thus\npropose a study on the Beran estimator when the censoring indicator is not\nclearly specified. From this, we provide a new estimator for the conditional\nsurvival function and establish its asymptotic normality under mild conditions.\nWe further study the supervised learning problem where the conditional survival\nfunction is to be predicted with no censorship indicators. To this aim, we\ninvestigate various approaches estimating the conditional expectation for the\ncensoring indicator. Along with the theoretical results, we illustrate how the\nestimators work for small samples by means of a simulation study and show their\npractical applicability with the analysis of synthetic data and the study of\nreal data for the prognosis of monoclonal gammopathy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 15:04:27 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Escobar-Bach", "Mikael", ""], ["Goudet", "Olivier", ""]]}, {"id": "2009.01730", "submitter": "Marco Huber", "authors": "Marco F. Huber", "title": "Bayesian Perceptron: Towards fully Bayesian Neural Networks", "comments": "Accepted for publication at the 59th IEEE Conference on Decision and\n  Control (CDC) 2020. v2: correction of typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (NNs) have become the de facto standard in machine\nlearning. They allow learning highly nonlinear transformations in a plethora of\napplications. However, NNs usually only provide point estimates without\nsystematically quantifying corresponding uncertainties. In this paper a novel\napproach towards fully Bayesian NNs is proposed, where training and predictions\nof a perceptron are performed within the Bayesian inference framework in\nclosed-form. The weights and the predictions of the perceptron are considered\nGaussian random variables. Analytical expressions for predicting the\nperceptron's output and for learning the weights are provided for commonly used\nactivation functions like sigmoid or ReLU. This approach requires no\ncomputationally expensive gradient calculations and further allows sequential\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 15:08:49 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 05:02:40 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Huber", "Marco F.", ""]]}, {"id": "2009.01742", "submitter": "Guanhua Fang", "authors": "Guanhua Fang and Owen G. Ward and Tian Zheng", "title": "Online Community Detection for Event Streams on Networks", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common goal in network modeling is to uncover the latent community\nstructure present among nodes. For many real-world networks, observed\nconnections consist of events arriving as streams, which are then aggregated to\nform edges, ignoring the temporal dynamic component. A natural way to take\naccount of this temporal dynamic component of interactions is to use point\nprocesses as the foundation of the network models for community detection.\nComputational complexity hampers the scalability of such approaches to large\nsparse networks. To circumvent this challenge, we propose a fast online\nvariational inference algorithm for learning the community structure underlying\ndynamic event arrivals on a network using continuous-time point process latent\nnetwork models. We provide regret bounds on the loss function of this\nprocedure, giving theoretical guarantees on performance. The proposed algorithm\nis illustrated, using both simulation studies and real data, to have comparable\nperformance in terms of community structure in terms of community recovery to\nnon-online variants. Our proposed framework can also be readily modified to\nincorporate other popular network structures.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 15:39:55 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Fang", "Guanhua", ""], ["Ward", "Owen G.", ""], ["Zheng", "Tian", ""]]}, {"id": "2009.01791", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Pedro A. Ortega, Jimmy Ba, Thomas Parr, Karl Friston,\n  Nicolas Heess", "title": "Action and Perception as Divergence Minimization", "comments": "14 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a unified objective for action and perception of intelligent\nagents. Extending representation learning and control, we minimize the joint\ndivergence between the combined system of agent and environment and a target\ndistribution. Intuitively, such agents use perception to align their beliefs\nwith the world, and use actions to align the world with their beliefs.\nMinimizing the joint divergence to an expressive target maximizes the mutual\ninformation between the agent's representations and inputs, thus inferring\nrepresentations that are informative of past inputs and exploring future inputs\nthat are informative of the representations. This lets us explain intrinsic\nobjectives, such as representation learning, information gain, empowerment, and\nskill discovery from minimal assumptions. Moreover, interpreting the target\ndistribution as a latent variable model suggests powerful world models as a\npath toward highly adaptive agents that seek large niches in their\nenvironments, rendering task rewards optional. The framework provides a common\nlanguage for comparing a wide range of objectives, advances the understanding\nof latent variables for decision making, and offers a recipe for designing\nnovel objectives. We recommend deriving future agent objectives the joint\ndivergence to facilitate comparison, to point out the agent's target\ndistribution, and to identify the intrinsic objective terms needed to reach\nthat distribution.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:52:46 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:52:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hafner", "Danijar", ""], ["Ortega", "Pedro A.", ""], ["Ba", "Jimmy", ""], ["Parr", "Thomas", ""], ["Friston", "Karl", ""], ["Heess", "Nicolas", ""]]}, {"id": "2009.01797", "submitter": "Martin Mundt", "authors": "Martin Mundt, Yong Won Hong, Iuliia Pliushch, Visvanathan Ramesh", "title": "A Wholistic View of Continual Learning with Deep Neural Networks:\n  Forgotten Lessons and the Bridge to Active and Open World Learning", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning research is dominated by benchmark evaluation. A method\nis regarded as favorable if it empirically performs well on the dedicated test\nset. This mentality is seamlessly reflected in the resurfacing area of\ncontinual learning, where consecutively arriving sets of benchmark data are\ninvestigated. The core challenge is framed as protecting previously acquired\nrepresentations from being catastrophically forgotten due to the iterative\nparameter updates. However, comparison of individual methods is nevertheless\ntreated in isolation from real world application and typically judged by\nmonitoring accumulated test set performance. The closed world assumption\nremains predominant. It is assumed that during deployment a model is guaranteed\nto encounter data that stems from the same distribution as used for training.\nThis poses a massive challenge as neural networks are well known to provide\noverconfident false predictions on unknown instances and break down in the face\nof corrupted data. In this work we argue that notable lessons from open set\nrecognition, the identification of statistically deviating data outside of the\nobserved dataset, and the adjacent field of active learning, where data is\nincrementally queried such that the expected performance gain is maximized, are\nfrequently overlooked in the deep learning era. Based on these forgotten\nlessons, we propose a consolidated view to bridge continual learning, active\nlearning and open set recognition in deep neural networks. Our results show\nthat this not only benefits each individual paradigm, but highlights the\nnatural synergies in a common framework. We empirically demonstrate\nimprovements when alleviating catastrophic forgetting, querying data in active\nlearning, selecting task orders, while exhibiting robust open world application\nwhere previously proposed methods fail.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:56:36 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:57:41 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Mundt", "Martin", ""], ["Hong", "Yong Won", ""], ["Pliushch", "Iuliia", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "2009.01798", "submitter": "John Mitros", "authors": "John Mitros and Arjun Pakrashi and Brian Mac Namee", "title": "Ramifications of Approximate Posterior Inference for Bayesian Deep\n  Learning in Adversarial and Out-of-Distribution Settings", "comments": "AROW@ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been successful in diverse discriminative\nclassification tasks, although, they are poorly calibrated often assigning high\nprobability to misclassified predictions. Potential consequences could lead to\ntrustworthiness and accountability of the models when deployed in real\napplications, where predictions are evaluated based on their confidence scores.\nExisting solutions suggest the benefits attained by combining deep neural\nnetworks and Bayesian inference to quantify uncertainty over the models'\npredictions for ambiguous datapoints. In this work we propose to validate and\ntest the efficacy of likelihood based models in the task of out of distribution\ndetection (OoD). Across different datasets and metrics we show that Bayesian\ndeep learning models on certain occasions marginally outperform conventional\nneural networks and in the event of minimal overlap between in/out distribution\nclasses, even the best models exhibit a reduction in AUC scores in detecting\nOoD data. Preliminary investigations indicate the potential inherent role of\nbias due to choices of initialisation, architecture or activation functions. We\nhypothesise that the sensitivity of neural networks to unseen inputs could be a\nmulti-factor phenomenon arising from the different architectural design choices\noften amplified by the curse of dimensionality. Furthermore, we perform a study\nto find the effect of the adversarial noise resistance methods on in and\nout-of-distribution performance, as well as, also investigate adversarial noise\nrobustness of Bayesian deep learners.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:58:15 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 14:46:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Mitros", "John", ""], ["Pakrashi", "Arjun", ""], ["Mac Namee", "Brian", ""]]}, {"id": "2009.01803", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai", "title": "Sparse Meta Networks for Sequential Adaptation and its Application to\n  Adaptive Language Modelling", "comments": "9 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a deep neural network requires a large amount of single-task data\nand involves a long time-consuming optimization phase. This is not scalable to\ncomplex, realistic environments with new unexpected changes. Humans can perform\nfast incremental learning on the fly and memory systems in the brain play a\ncritical role. We introduce Sparse Meta Networks -- a meta-learning approach to\nlearn online sequential adaptation algorithms for deep neural networks, by\nusing deep neural networks. We augment a deep neural network with a\nlayer-specific fast-weight memory. The fast-weights are generated sparsely at\neach time step and accumulated incrementally through time providing a useful\ninductive bias for online continual adaptation. We demonstrate strong\nperformance on a variety of sequential adaptation scenarios, from a simple\nonline reinforcement learning to a large scale adaptive language modelling.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:06:52 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""]]}, {"id": "2009.01807", "submitter": "Youzuo Lin", "authors": "Ren\\'an Rojas-G\\'omez, Jihyun Yang, Youzuo Lin, James Theiler, Brendt\n  Wohlberg", "title": "Physics-Consistent Data-driven Waveform Inversion with Adaptive Data\n  Augmentation", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2020.3022021", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Seismic full-waveform inversion (FWI) is a nonlinear computational imaging\ntechnique that can provide detailed estimates of subsurface geophysical\nproperties. Solving the FWI problem can be challenging due to its ill-posedness\nand high computational cost. In this work, we develop a new hybrid\ncomputational approach to solve FWI that combines physics-based models with\ndata-driven methodologies. In particular, we develop a data augmentation\nstrategy that can not only improve the representativity of the training set but\nalso incorporate important governing physics into the training process and\ntherefore improve the inversion accuracy. To validate the performance, we apply\nour method to synthetic elastic seismic waveform data generated from a\nsubsurface geologic model built on a carbon sequestration site at Kimberlina,\nCalifornia. We compare our physics-consistent data-driven inversion method to\nboth purely physics-based and purely data-driven approaches and observe that\nour method yields higher accuracy and greater generalization ability.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:12:55 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Rojas-G\u00f3mez", "Ren\u00e1n", ""], ["Yang", "Jihyun", ""], ["Lin", "Youzuo", ""], ["Theiler", "James", ""], ["Wohlberg", "Brendt", ""]]}, {"id": "2009.01884", "submitter": "Ulrich A\\\"ivodji", "authors": "Ulrich A\\\"ivodji, Alexandre Bolot, S\\'ebastien Gambs", "title": "Model extraction from counterfactual explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc explanation techniques refer to a posteriori methods that can be\nused to explain how black-box machine learning models produce their outcomes.\nAmong post-hoc explanation techniques, counterfactual explanations are becoming\none of the most popular methods to achieve this objective. In particular, in\naddition to highlighting the most important features used by the black-box\nmodel, they provide users with actionable explanations in the form of data\ninstances that would have received a different outcome. Nonetheless, by doing\nso, they also leak non-trivial information about the model itself, which raises\nprivacy issues. In this work, we demonstrate how an adversary can leverage the\ninformation provided by counterfactual explanations to build high-fidelity and\nhigh-accuracy model extraction attacks. More precisely, our attack enables the\nadversary to build a faithful copy of a target model by accessing its\ncounterfactual explanations. The empirical evaluation of the proposed attack on\nblack-box models trained on real-world datasets demonstrates that they can\nachieve high-fidelity and high-accuracy extraction even under low query\nbudgets.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 19:02:55 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Bolot", "Alexandre", ""], ["Gambs", "S\u00e9bastien", ""]]}, {"id": "2009.01934", "submitter": "Arun Kumar Singh", "authors": "Arun Kumar Singh (1), Priyanka Singh (2) ((1) Indian Institute of\n  Technology Jammu, (2) Dhirubhai Ambani Institute of Information and\n  Communication Technology)", "title": "Detection of AI-Synthesized Speech Using Cepstral & Bispectral\n  Statistics", "comments": "6 Pages, 6 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital technology has made possible unimaginable applications come true. It\nseems exciting to have a handful of tools for easy editing and manipulation,\nbut it raises alarming concerns that can propagate as speech clones,\nduplicates, or maybe deep fakes. Validating the authenticity of a speech is one\nof the primary problems of digital audio forensics. We propose an approach to\ndistinguish human speech from AI synthesized speech exploiting the Bi-spectral\nand Cepstral analysis. Higher-order statistics have less correlation for human\nspeech in comparison to a synthesized speech. Also, Cepstral analysis revealed\na durable power component in human speech that is missing for a synthesized\nspeech. We integrate both these analyses and propose a machine learning model\nto detect AI synthesized speech.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 21:29:41 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 11:41:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Singh", "Arun Kumar", ""], ["Singh", "Priyanka", ""]]}, {"id": "2009.01959", "submitter": "Marcelo De Rezende Martins", "authors": "Marcelo de Rezende Martins and Marco A. Gerosa", "title": "CoNCRA: A Convolutional Neural Network Code Retrieval Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3422392.3422462", "report-no": null, "categories": "cs.LG cs.CL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software developers routinely search for code using general-purpose search\nengines. However, these search engines cannot find code semantically unless it\nhas an accompanying description. We propose a technique for semantic code\nsearch: A Convolutional Neural Network approach to code retrieval (CoNCRA). Our\ntechnique aims to find the code snippet that most closely matches the\ndeveloper's intent, expressed in natural language. We evaluated our approach's\nefficacy on a dataset composed of questions and code snippets collected from\nStack Overflow. Our preliminary results showed that our technique, which\nprioritizes local interactions (words nearby), improved the state-of-the-art\n(SOTA) by 5% on average, retrieving the most relevant code snippets in the top\n3 (three) positions by almost 80% of the time. Therefore, our technique is\npromising and can improve the efficacy of semantic code retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 23:38:52 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Martins", "Marcelo de Rezende", ""], ["Gerosa", "Marco A.", ""]]}, {"id": "2009.01974", "submitter": "Wei-Lun Chao", "authors": "Hong-You Chen, Wei-Lun Chao", "title": "FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning aims to collaboratively train a strong global model by\naccessing users' locally trained models but not their own data. A crucial step\nis therefore to aggregate local models into a global model, which has been\nshown challenging when users have non-i.i.d. data. In this paper, we propose a\nnovel aggregation algorithm named FedBE, which takes a Bayesian inference\nperspective by sampling higher-quality global models and combining them via\nBayesian model Ensemble, leading to much robust aggregation. We show that an\neffective model distribution can be constructed by simply fitting a Gaussian or\nDirichlet distribution to the local models. Our empirical studies validate\nFedBE's superior performance, especially when users' data are not i.i.d. and\nwhen the neural networks go deeper. Moreover, FedBE is compatible with recent\nefforts in regularizing users' model training, making it an easily applicable\nmodule: you only need to replace the aggregation method but leave other parts\nof your federated learning algorithm intact.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 01:18:25 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 23:42:34 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 21:36:23 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chen", "Hong-You", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2009.02003", "submitter": "Ethan Fang", "authors": "Yining Wang, Yi Chen, Ethan X. Fang, Zhaoran Wang and Runze Li", "title": "Nearly Dimension-Independent Sparse Linear Bandit over Small Action\n  Spaces via Best Subset Selection", "comments": "54 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic contextual bandit problem under the high\ndimensional linear model. We focus on the case where the action space is finite\nand random, with each action associated with a randomly generated contextual\ncovariate. This setting finds essential applications such as personalized\nrecommendation, online advertisement, and personalized medicine. However, it is\nvery challenging as we need to balance exploration and exploitation. We propose\ndoubly growing epochs and estimating the parameter using the best subset\nselection method, which is easy to implement in practice. This approach\nachieves $ \\tilde{\\mathcal{O}}(s\\sqrt{T})$ regret with high probability, which\nis nearly independent in the ``ambient'' regression model dimension $d$. We\nfurther attain a sharper $\\tilde{\\mathcal{O}}(\\sqrt{sT})$ regret by using the\n\\textsc{SupLinUCB} framework and match the minimax lower bound of\nlow-dimensional linear stochastic bandit problems. Finally, we conduct\nextensive numerical experiments to demonstrate the applicability and robustness\nof our algorithms empirically.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 04:10:39 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Wang", "Yining", ""], ["Chen", "Yi", ""], ["Fang", "Ethan X.", ""], ["Wang", "Zhaoran", ""], ["Li", "Runze", ""]]}, {"id": "2009.02009", "submitter": "Jaeseong Lee", "authors": "Jaeseong Lee, Duseok Kang and Soonhoi Ha", "title": "S3NAS: Fast NPU-aware Neural Architecture Search Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the application area of convolutional neural networks (CNN) is growing in\nembedded devices, it becomes popular to use a hardware CNN accelerator, called\nneural processing unit (NPU), to achieve higher performance per watt than CPUs\nor GPUs. Recently, automated neural architecture search (NAS) emerges as the\ndefault technique to find a state-of-the-art CNN architecture with higher\naccuracy than manually-designed architectures for image classification. In this\npaper, we present a fast NPU-aware NAS methodology, called S3NAS, to find a CNN\narchitecture with higher accuracy than the existing ones under a given latency\nconstraint. It consists of three steps: supernet design, Single-Path NAS for\nfast architecture exploration, and scaling. To widen the search space of the\nsupernet structure that consists of stages, we allow stages to have a different\nnumber of blocks and blocks to have parallel layers of different kernel sizes.\nFor a fast neural architecture search, we apply a modified Single-Path NAS\ntechnique to the proposed supernet structure. In this step, we assume a shorter\nlatency constraint than the required to reduce the search space and the search\ntime. The last step is to scale up the network maximally within the latency\nconstraint. For accurate latency estimation, an analytical latency estimator is\ndevised, based on a cycle-level NPU simulator that runs an entire CNN\nconsidering the memory access overhead accurately. With the proposed\nmethodology, we are able to find a network in 3 hours using TPUv3, which shows\n82.72% top-1 accuracy on ImageNet with 11.66 ms latency. Code are released at\nhttps://github.com/cap-lab/S3NAS\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 04:45:50 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Lee", "Jaeseong", ""], ["Kang", "Duseok", ""], ["Ha", "Soonhoi", ""]]}, {"id": "2009.02027", "submitter": "Han Yang", "authors": "Han Yang and Kaili Ma and James Cheng", "title": "Rethinking Graph Regularization for Graph Neural Networks", "comments": "AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph Laplacian regularization term is usually used in semi-supervised\nrepresentation learning to provide graph structure information for a model\n$f(X)$. However, with the recent popularity of graph neural networks (GNNs),\ndirectly encoding graph structure $A$ into a model, i.e., $f(A, X)$, has become\nthe more common approach. While we show that graph Laplacian regularization\nbrings little-to-no benefit to existing GNNs, and propose a simple but\nnon-trivial variant of graph Laplacian regularization, called\nPropagation-regularization (P-reg), to boost the performance of existing GNN\nmodels. We provide formal analyses to show that P-reg not only infuses extra\ninformation (that is not captured by the traditional graph Laplacian\nregularization) into GNNs, but also has the capacity equivalent to an\ninfinite-depth graph convolutional network. We demonstrate that P-reg can\neffectively boost the performance of existing GNN models on both node-level and\ngraph-level tasks across many different datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:04:51 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 15:52:58 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yang", "Han", ""], ["Ma", "Kaili", ""], ["Cheng", "James", ""]]}, {"id": "2009.02040", "submitter": "Hang Zhao", "authors": "Hang Zhao, Yujing Wang, Juanyong Duan, Congrui Huang, Defu Cao, Yunhai\n  Tong, Bixiong Xu, Jing Bai, Jie Tong, Qi Zhang", "title": "Multivariate Time-series Anomaly Detection via Graph Attention Network", "comments": "Accepted by ICDM 2020. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection on multivariate time-series is of great importance in both\ndata mining research and industrial applications. Recent approaches have\nachieved significant progress in this topic, but there is remaining\nlimitations. One major limitation is that they do not capture the relationships\nbetween different time-series explicitly, resulting in inevitable false alarms.\nIn this paper, we propose a novel self-supervised framework for multivariate\ntime-series anomaly detection to address this issue. Our framework considers\neach univariate time-series as an individual feature and includes two graph\nattention layers in parallel to learn the complex dependencies of multivariate\ntime-series in both temporal and feature dimensions. In addition, our approach\njointly optimizes a forecasting-based model and are construction-based model,\nobtaining better time-series representations through a combination of\nsingle-timestamp prediction and reconstruction of the entire time-series. We\ndemonstrate the efficacy of our model through extensive experiments. The\nproposed method outperforms other state-of-the-art models on three real-world\ndatasets. Further analysis shows that our method has good interpretability and\nis useful for anomaly diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:46:19 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Zhao", "Hang", ""], ["Wang", "Yujing", ""], ["Duan", "Juanyong", ""], ["Huang", "Congrui", ""], ["Cao", "Defu", ""], ["Tong", "Yunhai", ""], ["Xu", "Bixiong", ""], ["Bai", "Jing", ""], ["Tong", "Jie", ""], ["Zhang", "Qi", ""]]}, {"id": "2009.02085", "submitter": "Adrian Jarret", "authors": "Simon Brandeis, Adrian Jarret, Pierre Sevestre", "title": "About Graph Degeneracy, Representation Learning and Scalability", "comments": "Research project as part of CentraleSupelec final year engineering\n  degree", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs or networks are a very convenient way to represent data with lots of\ninteraction. Recently, Machine Learning on Graph data has gained a lot of\ntraction. In particular, vertex classification and missing edge detection have\nvery interesting applications, ranging from drug discovery to recommender\nsystems. To achieve such tasks, tremendous work has been accomplished to learn\nembedding of nodes and edges into finite-dimension vector spaces. This task is\ncalled Graph Representation Learning. However, Graph Representation Learning\ntechniques often display prohibitive time and memory complexities, preventing\ntheir use in real-time with business size graphs. In this paper, we address\nthis issue by leveraging a degeneracy property of Graphs - the K-Core\nDecomposition. We present two techniques taking advantage of this decomposition\nto reduce the time and memory consumption of walk-based Graph Representation\nLearning algorithms. We evaluate the performances, expressed in terms of\nquality of embedding and computational resources, of the proposed techniques on\nseveral academic datasets. Our code is available at\nhttps://github.com/SBrandeis/kcore-embedding\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 09:39:43 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Brandeis", "Simon", ""], ["Jarret", "Adrian", ""], ["Sevestre", "Pierre", ""]]}, {"id": "2009.02098", "submitter": "Nijat Mehdiyev", "authors": "Nijat Mehdiyev and Peter Fettke", "title": "Explainable Artificial Intelligence for Process Mining: A General\n  Overview and Application of a Novel Local Explanation Approach for Predictive\n  Process Monitoring", "comments": "Manuscript submitted (10.07.2020) to the edited volume \"Interpretable\n  Artificial Intelligence: A perspective of Granular Computing\" (published by\n  Springer)", "journal-ref": null, "doi": "10.1007/978-3-030-64949-4_1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contemporary process-aware information systems possess the capabilities\nto record the activities generated during the process execution. To leverage\nthese process specific fine-granular data, process mining has recently emerged\nas a promising research discipline. As an important branch of process mining,\npredictive business process management, pursues the objective to generate\nforward-looking, predictive insights to shape business processes. In this\nstudy, we propose a conceptual framework sought to establish and promote\nunderstanding of decision-making environment, underlying business processes and\nnature of the user characteristics for developing explainable business process\nprediction solutions. Consequently, with regard to the theoretical and\npractical implications of the framework, this study proposes a novel local\npost-hoc explanation approach for a deep learning classifier that is expected\nto facilitate the domain experts in justifying the model decisions. In contrary\nto alternative popular perturbation-based local explanation approaches, this\nstudy defines the local regions from the validation dataset by using the\nintermediate latent space representations learned by the deep neural networks.\nTo validate the applicability of the proposed explanation method, the real-life\nprocess log data delivered by the Volvo IT Belgium's incident management system\nare used.The adopted deep learning classifier achieves a good performance with\nthe Area Under the ROC Curve of 0.94. The generated local explanations are also\nvisualized and presented with relevant evaluation measures that are expected to\nincrease the users' trust in the black-box-model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 10:28:56 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 07:24:36 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Mehdiyev", "Nijat", ""], ["Fettke", "Peter", ""]]}, {"id": "2009.02165", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Kei Uchizawa", "title": "A Generalization of Spatial Monte Carlo Integration", "comments": null, "journal-ref": null, "doi": "10.1162/neco_a_01365", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial Monte Carlo integration (SMCI) is an extension of standard Monte\nCarlo integration and can approximate expectations on Markov random fields with\nhigh accuracy. SMCI was applied to pairwise Boltzmann machine (PBM) learning,\nwith superior results to those from some existing methods. The approximation\nlevel of SMCI can be changed, and it was proved that a higher-order\napproximation of SMCI is statistically more accurate than a lower-order\napproximation. However, SMCI as proposed in the previous studies suffers from a\nlimitation that prevents the application of a higher-order method to dense\nsystems.\n  This study makes two different contributions as follows. A generalization of\nSMCI (called generalized SMCI (GSMCI)) is proposed, which allows relaxation of\nthe above-mentioned limitation; moreover, a statistical accuracy bound of GSMCI\nis proved. This is the first contribution of this study. A new PBM learning\nmethod based on SMCI is proposed, which is obtained by combining SMCI and the\npersistent contrastive divergence. The proposed learning method greatly\nimproves the accuracy of learning. This is the second contribution of this\nstudy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:02:58 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 01:02:56 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Yasuda", "Muneki", ""], ["Uchizawa", "Kei", ""]]}, {"id": "2009.02183", "submitter": "Giacomo Nannicini", "authors": "Giacomo Nannicini", "title": "On the implementation of a global optimization method for mixed-variable\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the optimization algorithm implemented in the open-source\nderivative-free solver RBFOpt. The algorithm is based on the radial basis\nfunction method of Gutmann and the metric stochastic response surface method of\nRegis and Shoemaker. We propose several modifications aimed at generalizing and\nimproving these two algorithms: (i) the use of an extended space to represent\ncategorical variables in unary encoding; (ii) a refinement phase to locally\nimprove a candidate solution; (iii) interpolation models without the\nunisolvence condition, to both help deal with categorical variables, and\ninitiate the optimization before a uniquely determined model is possible; (iv)\na master-worker framework to allow asynchronous objective function evaluations\nin parallel. Numerical experiments show the effectiveness of these ideas.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:36:56 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 14:37:55 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 03:27:05 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 23:27:28 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Nannicini", "Giacomo", ""]]}, {"id": "2009.02188", "submitter": "Mohamed Ghalwash", "authors": "Mohamed Ghalwash, Zijun Yao, Prithwish Chakraborty, James Codella,\n  Daby Sow", "title": "Phenotypical Ontology Driven Framework for Multi-Task Learning", "comments": "To be appear on ACM CHIL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the large number of patients in Electronic Health Records (EHRs), the\nsubset of usable data for modeling outcomes of specific phenotypes are often\nimbalanced and of modest size. This can be attributed to the uneven coverage of\nmedical concepts in EHRs. In this paper, we propose OMTL, an Ontology-driven\nMulti-Task Learning framework, that is designed to overcome such data\nlimitations. The key contribution of our work is the effective use of knowledge\nfrom a predefined well-established medical relationship graph (ontology) to\nconstruct a novel deep learning network architecture that mirrors this\nontology. It can effectively leverage knowledge from a well-established medical\nrelationship graph (ontology) by constructing a deep learning network\narchitecture that mirrors this graph. This enables common representations to be\nshared across related phenotypes, and was found to improve the learning\nperformance. The proposed OMTL naturally allows for multitask learning of\ndifferent phenotypes on distinct predictive tasks. These phenotypes are tied\ntogether by their semantic distance according to the external medical ontology.\nUsing the publicly available MIMIC-III database, we evaluate OMTL and\ndemonstrate its efficacy on several real patient outcome predictions over\nstate-of-the-art multi-task learning schemes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:46:07 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Ghalwash", "Mohamed", ""], ["Yao", "Zijun", ""], ["Chakraborty", "Prithwish", ""], ["Codella", "James", ""], ["Sow", "Daby", ""]]}, {"id": "2009.02205", "submitter": "Benjamin Nachman", "authors": "Kees Benkendorfer, Luc Le Pottier, and Benjamin Nachman", "title": "Simulation-Assisted Decorrelation for Resonant Anomaly Detection", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of weak- and unsupervised machine learning approaches to\nanomaly detection are being proposed to significantly extend the search program\nat the Large Hadron Collider and elsewhere. One of the prototypical examples\nfor these methods is the search for resonant new physics, where a bump hunt can\nbe performed in an invariant mass spectrum. A significant challenge to methods\nthat rely entirely on data is that they are susceptible to sculpting artificial\nbumps from the dependence of the machine learning classifier on the invariant\nmass. We explore two solutions to this challenge by minimally incorporating\nsimulation into the learning. In particular, we study the robustness of\nSimulation Assisted Likelihood-free Anomaly Detection (SALAD) to correlations\nbetween the classifier and the invariant mass. Next, we propose a new approach\nthat only uses the simulation for decorrelation but the Classification without\nLabels (CWoLa) approach for achieving signal sensitivity. Both methods are\ncompared using a full background fit analysis on simulated data from the LHC\nOlympics and are robust to correlations in the data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 14:02:15 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Benkendorfer", "Kees", ""], ["Pottier", "Luc Le", ""], ["Nachman", "Benjamin", ""]]}, {"id": "2009.02251", "submitter": "Xiangyun Ding", "authors": "Xiangyun Ding, Wenjian Yu, Yuyang Xie, Shenghua Liu", "title": "Efficient Model-Based Collaborative Filtering with Fast Adaptive PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model-based collaborative filtering (CF) approach utilizing fast adaptive\nrandomized singular value decomposition (SVD) is proposed for the matrix\ncompletion problem in recommender system. Firstly, a fast adaptive PCA\nframeworkis presented which combines the fixed-precision randomized matrix\nfactorization algorithm [1] and accelerating skills for handling large sparse\ndata. Then, a novel termination mechanism for the adaptive PCA is proposed to\nautomatically determine a number of latent factors for achieving the near\noptimal prediction accuracy during the subsequent model-based CF. The resulted\nCF approach has good accuracy while inheriting high runtime efficiency.\nExperiments on real data show that, the proposed adaptive PCA is up to 2.7X and\n6.7X faster than the original fixed-precision SVD approach [1] and svds in\nMatlab repsectively, while preserving accuracy. The proposed model-based CF\napproach is able to efficiently process the MovieLens data with 20M ratings and\nexhibits more than 10X speedup over the regularized matrix factorization based\napproach [2] and the fast singular value thresholding approach [3] with\ncomparable or better accuracy. It also owns the advantage of parameter free.\nCompared with the deep-learning-based CF approach, the proposed approach is\nmuch more computationally efficient, with just marginal performance loss.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:32:14 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Ding", "Xiangyun", ""], ["Yu", "Wenjian", ""], ["Xie", "Yuyang", ""], ["Liu", "Shenghua", ""]]}, {"id": "2009.02286", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Weidong Shi", "title": "Vulnerability of Face Recognition Systems Against Composite Face\n  Reconstruction Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rounding confidence score is considered trivial but a simple and effective\ncountermeasure to stop gradient descent based image reconstruction attacks.\nHowever, its capability in the face of more sophisticated reconstruction\nattacks is an uninvestigated research area. In this paper, we prove that, the\nface reconstruction attacks based on composite faces can reveal the\ninefficiency of rounding policy as countermeasure. We assume that, the attacker\ntakes advantage of face composite parts which helps the attacker to get access\nto the most important features of the face or decompose it to the independent\nsegments. Afterwards, decomposed segments are exploited as search parameters to\ncreate a search path to reconstruct optimal face. Face composition parts enable\nthe attacker to violate the privacy of face recognition models even with a\nblind search. However, we assume that, the attacker may take advantage of\nrandom search to reconstruct the target face faster. The algorithm is started\nwith random composition of face parts as initial face and confidence score is\nconsidered as fitness value. Our experiments show that, since the rounding\npolicy as countermeasure can't stop the random search process, current face\nrecognition systems are extremely vulnerable against such sophisticated\nattacks. To address this problem, we successfully test Face Detection Score\nFiltering (FDSF) as a countermeasure to protect the privacy of training data\nagainst proposed attack.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 03:37:51 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Shi", "Weidong", ""]]}, {"id": "2009.02296", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Said Ouala, Lucas Drumetz and Ronan Fablet", "title": "Variational Deep Learning for the Identification and Reconstruction of\n  Chaotic and Stochastic Dynamical Systems from Noisy and Partial Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data-driven recovery of the unknown governing equations of dynamical\nsystems has recently received an increasing interest. However, the\nidentification of governing equations remains challenging when dealing with\nnoisy and partial observations. Here, we address this challenge and investigate\nvariational deep learning schemes. Within the proposed framework, we jointly\nlearn an inference model to reconstruct the true states of the system and the\ngoverning laws of these states from series of noisy and partial data. In doing\nso, this framework bridges classical data assimilation and state-of-the-art\nmachine learning techniques. We also demonstrate that it generalises\nstate-of-the-art methods. Importantly, both the inference model and the\ngoverning model embed stochastic components to account for stochastic\nvariabilities, model errors, and reconstruction uncertainties. Various\nexperiments on chaotic and stochastic dynamical systems support the relevance\nof our scheme w.r.t. state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 16:48:00 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 16:32:35 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 22:27:28 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 17:28:05 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2021 17:00:08 GMT"}, {"version": "v6", "created": "Tue, 16 Feb 2021 16:58:18 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Nguyen", "Duong", ""], ["Ouala", "Said", ""], ["Drumetz", "Lucas", ""], ["Fablet", "Ronan", ""]]}, {"id": "2009.02302", "submitter": "Austin Xu", "authors": "Austin Xu and Mark A. Davenport", "title": "Simultaneous Preference and Metric Learning from Paired Comparisons", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular model of preference in the context of recommendation systems is the\nso-called \\emph{ideal point} model. In this model, a user is represented as a\nvector $\\mathbf{u}$ together with a collection of items $\\mathbf{x_1}, \\ldots,\n\\mathbf{x_N}$ in a common low-dimensional space. The vector $\\mathbf{u}$\nrepresents the user's \"ideal point,\" or the ideal combination of features that\nrepresents a hypothesized most preferred item. The underlying assumption in\nthis model is that a smaller distance between $\\mathbf{u}$ and an item\n$\\mathbf{x_j}$ indicates a stronger preference for $\\mathbf{x_j}$. In the vast\nmajority of the existing work on learning ideal point models, the underlying\ndistance has been assumed to be Euclidean. However, this eliminates any\npossibility of interactions between features and a user's underlying\npreferences. In this paper, we consider the problem of learning an ideal point\nrepresentation of a user's preferences when the distance metric is an unknown\nMahalanobis metric. Specifically, we present a novel approach to estimate the\nuser's ideal point $\\mathbf{u}$ and the Mahalanobis metric from paired\ncomparisons of the form \"item $\\mathbf{x_i}$ is preferred to item\n$\\mathbf{x_j}$.\" This can be viewed as a special case of a more general metric\nlearning problem where the location of some points are unknown a priori. We\nconduct extensive experiments on synthetic and real-world datasets to exhibit\nthe effectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 16:59:35 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 00:31:42 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Xu", "Austin", ""], ["Davenport", "Mark A.", ""]]}, {"id": "2009.02316", "submitter": "Toktam Khatibi", "authors": "Toktam Khatibi, Ali Farahani, Hossein Sarmadian", "title": "Proposing a two-step Decision Support System (TPIS) based on Stacked\n  ensemble classifier for early and low cost (step-1) and final (step-2)\n  differential diagnosis of Mycobacterium Tuberculosis from non-tuberculosis\n  Pneumonia", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Mycobacterium Tuberculosis (TB) is an infectious bacterial\ndisease presenting similar symptoms to pneumonia; therefore, differentiating\nbetween TB and pneumonia is challenging. Therefore, the main aim of this study\nis proposing an automatic method for differential diagnosis of TB from\nPneumonia. Methods: In this study, a two-step decision support system named\nTPIS is proposed for differential diagnosis of TB from pneumonia based on\nstacked ensemble classifiers. The first step of our proposed model aims at\nearly diagnosis based on low-cost features including demographic\ncharacteristics and patient symptoms (including 18 features). TPIS second step\nmakes the final decision based on the meta features extracted in the first\nstep, the laboratory tests and chest radiography reports. This retrospective\nstudy considers 199 patient medical records for patients suffering from TB or\npneumonia, which has been registered in a hospital in Arak, Iran. Results:\nExperimental results show that TPIS outperforms the compared machine learning\nmethods for early differential diagnosis of pulmonary tuberculosis from\npneumonia with AUC of 90.26 and accuracy of 91.37 and final decision making\nwith AUC of 92.81 and accuracy of 93.89. Conclusions: The main advantage of\nearly diagnosis is beginning the treatment procedure for confidently diagnosed\npatients as soon as possible and preventing latency in treatment. Therefore,\nearly diagnosis reduces the maturation of late treatment of both diseases.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 17:47:41 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Khatibi", "Toktam", ""], ["Farahani", "Ali", ""], ["Sarmadian", "Hossein", ""]]}, {"id": "2009.02326", "submitter": "Mojan Javaheripi", "authors": "Mojan Javaheripi, Mohammad Samragh, Gregory Fields, Tara Javidi,\n  Farinaz Koushanfar", "title": "CLEANN: Accelerated Trojan Shield for Embedded Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3400302.3415671", "report-no": null, "categories": "cs.LG cs.AR cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose CLEANN, the first end-to-end framework that enables online\nmitigation of Trojans for embedded Deep Neural Network (DNN) applications. A\nTrojan attack works by injecting a backdoor in the DNN while training; during\ninference, the Trojan can be activated by the specific backdoor trigger. What\ndifferentiates CLEANN from the prior work is its lightweight methodology which\nrecovers the ground-truth class of Trojan samples without the need for labeled\ndata, model retraining, or prior assumptions on the trigger or the attack. We\nleverage dictionary learning and sparse approximation to characterize the\nstatistical behavior of benign data and identify Trojan triggers. CLEANN is\ndevised based on algorithm/hardware co-design and is equipped with specialized\nhardware to enable efficient real-time execution on resource-constrained\nembedded platforms. Proof of concept evaluations on CLEANN for the\nstate-of-the-art Neural Trojan attacks on visual benchmarks demonstrate its\ncompetitive advantage in terms of attack resiliency and execution overhead.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 05:29:38 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Javaheripi", "Mojan", ""], ["Samragh", "Mohammad", ""], ["Fields", "Gregory", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2009.02365", "submitter": "Yuzhou Chen", "authors": "Yuzhou Chen, Yulia R. Gel, Konstantin Avrachenkov", "title": "LFGCN: Levitating over Graphs with Levy Flights", "comments": "To Appear in the 2020 IEEE International Conference on Data Mining\n  (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to high utility in many applications, from social networks to blockchain\nto power grids, deep learning on non-Euclidean objects such as graphs and\nmanifolds, coined Geometric Deep Learning (GDL), continues to gain an ever\nincreasing interest. We propose a new L\\'evy Flights Graph Convolutional\nNetworks (LFGCN) method for semi-supervised learning, which casts the L\\'evy\nFlights into random walks on graphs and, as a result, allows both to accurately\naccount for the intrinsic graph topology and to substantially improve\nclassification performance, especially for heterogeneous graphs. Furthermore,\nwe propose a new preferential P-DropEdge method based on the Girvan-Newman\nargument. That is, in contrast to uniform removing of edges as in DropEdge,\nfollowing the Girvan-Newman algorithm, we detect network periphery structures\nusing information on edge betweenness and then remove edges according to their\nbetweenness centrality. Our experimental results on semi-supervised node\nclassification tasks demonstrate that the LFGCN coupled with P-DropEdge\naccelerates the training task, increases stability and further improves\npredictive accuracy of learned graph topology structure. Finally, in our case\nstudies we bring the machinery of LFGCN and other deep networks tools to\nanalysis of power grid networks - the area where the utility of GDL remains\nuntapped.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 19:13:48 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Chen", "Yuzhou", ""], ["Gel", "Yulia R.", ""], ["Avrachenkov", "Konstantin", ""]]}, {"id": "2009.02388", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich", "title": "On Communication Compression for Distributed Optimization on\n  Heterogeneous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy gradient compression, with either unbiased or biased compressors, has\nbecome a key tool to avoid the communication bottleneck in centrally\ncoordinated distributed training of machine learning models. We analyze the\nperformance of two standard and general types of methods: (i) distributed\nquantized SGD (D-QSGD) with arbitrary unbiased quantizers and (ii) distributed\nSGD with error-feedback and biased compressors (D-EF-SGD) in the heterogeneous\n(non-iid) data setting. Our results indicate that D-EF-SGD is much less\naffected than D-QSGD by non-iid data, but both methods can suffer a slowdown if\ndata-skewness is high. We further study two alternatives that are not (or much\nless) affected by heterogenous data distributions: first, a recently proposed\nmethod that is effective on strongly convex problems, and secondly, we point\nout a more general approach that is applicable to linear compressors only but\neffective in all considered scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:48:08 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 09:41:09 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Stich", "Sebastian U.", ""]]}, {"id": "2009.02391", "submitter": "Recep Yusuf Bekci", "authors": "Recep Yusuf Bekci, Mehmet G\\\"um\\\"u\\c{s}", "title": "Visualizing the Loss Landscape of Actor Critic Methods with Applications\n  in Inventory Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous control is a widely applicable area of reinforcement learning. The\nmain players of this area are actor-critic methods that utilize policy\ngradients of neural approximators as a common practice. The focus of our study\nis to show the characteristics of the actor loss function which is the\nessential part of the optimization. We exploit low dimensional visualizations\nof the loss function and provide comparisons for loss landscapes of various\nalgorithms. Furthermore, we apply our approach to multi-store dynamic inventory\ncontrol, a notoriously difficult problem in supply chain operations, and\nexplore the shape of the loss function associated with the optimal policy. We\nmodelled and solved the problem using reinforcement learning while having a\nloss landscape in favor of optimality.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:52:05 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bekci", "Recep Yusuf", ""], ["G\u00fcm\u00fc\u015f", "Mehmet", ""]]}, {"id": "2009.02400", "submitter": "Pablo Andretta Jaskowiak", "authors": "Pablo Andretta Jaskowiak, Ivan Gesteira Costa, Ricardo Jos\\'e\n  Gabrielli Barreto Campello", "title": "The Area Under the ROC Curve as a Measure of Clustering Quality", "comments": "37 pages, 5 figures, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Area Under the the Receiver Operating Characteristics (ROC) Curve,\nreferred to as AUC, is a well-known performance measure in the supervised\nlearning domain. Due to its compelling features, it has been employed in a\nnumber of studies to evaluate and compare the performance of different\nclassifiers. In this work, we explore AUC as a performance measure in the\nunsupervised learning domain, more specifically, in the context of cluster\nanalysis. In particular, we elaborate on the use of AUC as an internal/relative\nmeasure of clustering quality, which we refer to as Area Under the Curve for\nClustering (AUCC). We show that the AUCC of a given candidate clustering\nsolution has an expected value under a null model of random clustering\nsolutions, regardless of the size of the dataset and, more importantly,\nregardless of the number or the (im)balance of clusters under evaluation. In\naddition, we demonstrate that, in the context of internal/relative clustering\nvalidation, AUCC is actually a linear transformation of the Gamma criterion\nfrom Baker and Hubert (1975), for which we also formally derive a theoretical\nexpected value for chance clusterings. We also discuss the computational\ncomplexity of these criteria and show that, while an ordinary implementation of\nGamma can be computationally prohibitive and impractical for most real\napplications of cluster analysis, its equivalence with AUCC actually unveils a\ncomputationally much more efficient and practical algorithmic procedure. Our\ntheoretical findings are supported by experimental results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 21:34:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Jaskowiak", "Pablo Andretta", ""], ["Costa", "Ivan Gesteira", ""], ["Campello", "Ricardo Jos\u00e9 Gabrielli Barreto", ""]]}, {"id": "2009.02436", "submitter": "Vasileios Charisopoulos", "authors": "Vasileios Charisopoulos, Austin R. Benson, Anil Damle", "title": "Communication-efficient distributed eigenspace estimation", "comments": "v2: Removes unnecessary assumption, fixes typo in Theorem 3. 39\n  pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed computing is a standard way to scale up machine learning and data\nscience algorithms to process large amounts of data. In such settings, avoiding\ncommunication amongst machines is paramount for achieving high performance.\nRather than distribute the computation of existing algorithms, a common\npractice for avoiding communication is to compute local solutions or parameter\nestimates on each machine and then combine the results; in many convex\noptimization problems, even simple averaging of local solutions can work well.\nHowever, these schemes do not work when the local solutions are not unique.\nSpectral methods are a collection of such problems, where solutions are\northonormal bases of the leading invariant subspace of an associated data\nmatrix, which are only unique up to rotation and reflections. Here, we develop\na communication-efficient distributed algorithm for computing the leading\ninvariant subspace of a data matrix. Our algorithm uses a novel alignment\nscheme that minimizes the Procrustean distance between local solutions and a\nreference solution, and only requires a single round of communication. For the\nimportant case of principal component analysis (PCA), we show that our\nalgorithm achieves a similar error rate to that of a centralized estimator. We\npresent numerical experiments demonstrating the efficacy of our proposed\nalgorithm for distributed PCA, as well as other problems where solutions\nexhibit rotational symmetry, such as node embeddings for graph data and\nspectral initialization for quadratic sensing.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 02:11:22 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 22:43:50 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Charisopoulos", "Vasileios", ""], ["Benson", "Austin R.", ""], ["Damle", "Anil", ""]]}, {"id": "2009.02439", "submitter": "Norman Tatro", "authors": "N. Joseph Tatro, Pin-Yu Chen, Payel Das, Igor Melnyk, Prasanna\n  Sattigeri, Rongjie Lai", "title": "Optimizing Mode Connectivity via Neuron Alignment", "comments": "Accepted to NeurIPS 2020, 24 pages, 9 figures, code available at\n  https://github.com/IBM/NeuronAlignment", "journal-ref": "Advances in Neural Information Processing Systems, Volume 33, 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss landscapes of deep neural networks are not well understood due to\ntheir high nonconvexity. Empirically, the local minima of these loss functions\ncan be connected by a learned curve in model space, along which the loss\nremains nearly constant; a feature known as mode connectivity. Yet, current\ncurve finding algorithms do not consider the influence of symmetry in the loss\nsurface created by model weight permutations. We propose a more general\nframework to investigate the effect of symmetry on landscape connectivity by\naccounting for the weight permutations of the networks being connected. To\napproximate the optimal permutation, we introduce an inexpensive heuristic\nreferred to as neuron alignment. Neuron alignment promotes similarity between\nthe distribution of intermediate activations of models along the curve. We\nprovide theoretical analysis establishing the benefit of alignment to mode\nconnectivity based on this simple heuristic. We empirically verify that the\npermutation given by alignment is locally optimal via a proximal alternating\nminimization scheme. Empirically, optimizing the weight permutation is critical\nfor efficiently learning a simple, planar, low-loss curve between networks that\nsuccessfully generalizes. Our alignment method can significantly alleviate the\nrecently identified robust loss barrier on the path connecting two adversarial\nrobust models and find more robust and accurate models on the path.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 02:25:23 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 23:56:40 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Tatro", "N. Joseph", ""], ["Chen", "Pin-Yu", ""], ["Das", "Payel", ""], ["Melnyk", "Igor", ""], ["Sattigeri", "Prasanna", ""], ["Lai", "Rongjie", ""]]}, {"id": "2009.02463", "submitter": "Chuanhao Li", "authors": "Chuanhao Li, Qingyun Wu and Hongning Wang", "title": "Unifying Clustered and Non-stationary Bandits", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-stationary bandits and online clustering of bandits lift the restrictive\nassumptions in contextual bandits and provide solutions to many important\nreal-world scenarios. Though the essence in solving these two problems overlaps\nconsiderably, they have been studied independently. In this paper, we connect\nthese two strands of bandit research under the notion of test of homogeneity,\nwhich seamlessly addresses change detection for non-stationary bandit and\ncluster identification for online clustering of bandit in a unified solution\nframework. Rigorous regret analysis and extensive empirical evaluations\ndemonstrate the value of our proposed solution, especially its flexibility in\nhandling various environment assumptions.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:58:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Li", "Chuanhao", ""], ["Wu", "Qingyun", ""], ["Wang", "Hongning", ""]]}, {"id": "2009.02467", "submitter": "Rafael De Araujo Monteiro Da Silva", "authors": "Rafael Monteiro", "title": "Binary Classification as a Phase Separation Process", "comments": "68 pages, 22 figures, 6 tables, supplementary material available on\n  git-hub. Abstract shortened, two figures changed, typos fixed, captions\n  improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.DS math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new binary classification model called Phase Separation Binary\nClassifier (PSBC). It consists of a discretization of a nonlinear\nreaction-diffusion equation coupled with an ODE, and is inspired by fluid\nbehavior, namely, on how binary fluids phase separate. Hence, parameters and\nhyperparameters have physical meaning, whose effects are carefully studied in\nseveral different scenarios. PSBC's coefficients are trainable weights, chosen\naccording to a minimization problem using Gradient Descent; optimization relies\non a classical Backpropagation with weight sharing. The model can be seen under\nthe framework of feedforward networks, and is endowed with a nonlinear\nactivation function that is linear in trainable weights but polynomial in other\nvariables, yielding a cost function that is also polynomial. In view of the\nmodel's connection with ODEs and parabolic PDEs, forward propagation amounts to\nan initial value problem. Thus, stability conditions are established using the\nconcept of Invariant regions. Interesting model compression properties are\nthoroughly discussed. We illustrate the classifier's qualities by applying it\nto the subset of numbers \"0\" and \"1\" of the classical MNIST database, where we\nare able to discern individuals with more than 94\\% accuracy, sometimes using\nless only about 10\\% of variables.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 05:47:05 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 02:17:29 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Monteiro", "Rafael", ""]]}, {"id": "2009.02472", "submitter": "Lei Cheng", "authors": "Lei Cheng, Zhongtao Chen, Qingjiang Shi, Yik-Chung Wu, and Sergios\n  Theodoridis", "title": "Towards Probabilistic Tensor Canonical Polyadic Decomposition 2.0:\n  Automatic Tensor Rank Learning Using Generalized Hyperbolic Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor rank learning for canonical polyadic decomposition (CPD) has long been\ndeemed as an essential but challenging problem. In particular, since the tensor\nrank controls the complexity of the CPD model, its inaccurate learning would\ncause overfitting to noise or underfitting to the signal sources, and even\ndestroy the interpretability of model parameters. However, the optimal\ndetermination of a tensor rank is known to be a non-deterministic\npolynomial-time hard (NP-hard) task. Rather than exhaustively searching for the\nbest tensor rank via trial-and-error experiments, Bayesian inference under the\nGaussian-gamma prior was introduced in the context of probabilistic CPD\nmodeling and it was shown to be an effective strategy for automatic tensor rank\ndetermination. This triggered flourishing research on other structured tensor\nCPDs with automatic tensor rank learning. As the other side of the coin, these\nresearch works also reveal that the Gaussian-gamma model does not perform well\nfor high-rank tensors or/and low signal-to-noise ratios (SNRs). To overcome\nthese drawbacks, in this paper, we introduce a more advanced generalized\nhyperbolic (GH) prior to the probabilistic CPD model, which not only includes\nthe Gaussian-gamma model as a special case, but also provides more\nflexibilities to adapt to different levels of sparsity. Based on this novel\nprobabilistic model, an algorithm is developed under the framework of\nvariational inference, where each update is obtained in a closed-form.\nExtensive numerical results, using synthetic data and real-world datasets,\ndemonstrate the excellent performance of the proposed method in learning both\nlow as well as high tensor ranks even for low SNR cases.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 06:07:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Cheng", "Lei", ""], ["Chen", "Zhongtao", ""], ["Shi", "Qingjiang", ""], ["Wu", "Yik-Chung", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "2009.02479", "submitter": "Jinhwan Park", "authors": "Wonyong Sung, Iksoo Choi, Jinhwan Park, Seokhyun Choi, Sungho Shin", "title": "S-SGD: Symmetrical Stochastic Gradient Descent with Weight Noise\n  Injection for Reaching Flat Minima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic gradient descent (SGD) method is most widely used for deep\nneural network (DNN) training. However, the method does not always converge to\na flat minimum of the loss surface that can demonstrate high generalization\ncapability. Weight noise injection has been extensively studied for finding\nflat minima using the SGD method. We devise a new weight-noise injection-based\nSGD method that adds symmetrical noises to the DNN weights. The training with\nsymmetrical noise evaluates the loss surface at two adjacent points, by which\nconvergence to sharp minima can be avoided. Fixed-magnitude symmetric noises\nare added to minimize training instability. The proposed method is compared\nwith the conventional SGD method and previous weight-noise injection algorithms\nusing convolutional neural networks for image classification. Particularly,\nperformance improvements in large batch training are demonstrated. This method\nshows superior performance compared with conventional SGD and weight-noise\ninjection methods regardless of the batch-size and learning rate scheduling\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 07:02:02 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Sung", "Wonyong", ""], ["Choi", "Iksoo", ""], ["Park", "Jinhwan", ""], ["Choi", "Seokhyun", ""], ["Shin", "Sungho", ""]]}, {"id": "2009.02539", "submitter": "Hung Tran-The", "authors": "Hung Tran-The, Sunil Gupta, Santu Rana, Huong Ha, Svetha Venkatesh", "title": "Sub-linear Regret Bounds for Bayesian Optimisation in Unknown Search\n  Spaces", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a popular method for efficient optimisation of\nexpensive black-box functions. Traditionally, BO assumes that the search space\nis known. However, in many problems, this assumption does not hold. To this\nend, we propose a novel BO algorithm which expands (and shifts) the search\nspace over iterations based on controlling the expansion rate thought a\nhyperharmonic series. Further, we propose another variant of our algorithm that\nscales to high dimensions. We show theoretically that for both our algorithms,\nthe cumulative regret grows at sub-linear rates. Our experiments with synthetic\nand real-world optimisation tasks demonstrate the superiority of our algorithms\nover the current state-of-the-art methods for Bayesian optimisation in unknown\nsearch space.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:24:40 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 00:26:20 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 00:31:27 GMT"}, {"version": "v4", "created": "Sun, 1 Nov 2020 12:38:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Tran-The", "Hung", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Ha", "Huong", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2009.02544", "submitter": "Yang-Hui He", "authors": "Yang-Hui He, and Andre Lukas", "title": "Machine Learning Calabi-Yau Four-folds", "comments": "6 pages, 2 figures; references added", "journal-ref": null, "doi": "10.1016/j.physletb.2021.136139", "report-no": null, "categories": "hep-th math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hodge numbers of Calabi-Yau manifolds depend non-trivially on the underlying\nmanifold data and they present an interesting challenge for machine learning.\nIn this letter we consider the data set of complete intersection Calabi-Yau\nfour-folds, a set of about 900,000 topological types, and study supervised\nlearning of the Hodge numbers h^1,1 and h^3,1 for these manifolds. We find that\nh^1,1 can be successfully learned (to 96% precision) by fully connected\nclassifier and regressor networks. While both types of networks fail for h^3,1,\nwe show that a more complicated two-branch network, combined with feature\nenhancement, can act as an efficient regressor (to 98% precision) for h^3,1, at\nleast for a subset of the data. This hints at the existence of an, as yet\nunknown, formula for Hodge numbers.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:54:25 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 11:11:55 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["He", "Yang-Hui", ""], ["Lukas", "Andre", ""]]}, {"id": "2009.02553", "submitter": "Luo Luo", "authors": "Luo Luo, Cheng Chen, Guangzeng Xie, Haishan Ye", "title": "Revisiting Co-Occurring Directions: Sharper Analysis and Efficient\n  Algorithm for Sparse Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study the streaming model for approximate matrix multiplication (AMM). We\nare interested in the scenario that the algorithm can only take one pass over\nthe data with limited memory. The state-of-the-art deterministic sketching\nalgorithm for streaming AMM is the co-occurring directions (COD), which has\nmuch smaller approximation errors than randomized algorithms and outperforms\nother deterministic sketching methods empirically. In this paper, we provide a\ntighter error bound for COD whose leading term considers the potential\napproximate low-rank structure and the correlation of input matrices. We prove\nCOD is space optimal with respect to our improved error bound. We also propose\na variant of COD for sparse matrices with theoretical guarantees. The\nexperiments on real-world sparse datasets show that the proposed algorithm is\nmore efficient than baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 15:35:59 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 06:55:55 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Luo", "Luo", ""], ["Chen", "Cheng", ""], ["Xie", "Guangzeng", ""], ["Ye", "Haishan", ""]]}, {"id": "2009.02557", "submitter": "Hui Chen", "authors": "Pei Fang, Zhendong Cai, Hui Chen and QingJiang Shi", "title": "FLFE: A Communication-Efficient and Privacy-Preserving Federated Feature\n  Engineering Framework", "comments": "11pages, multi-party feature engineering problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering is the process of using domain knowledge to extract\nfeatures from raw data via data mining techniques and is a key step to improve\nthe performance of machine learning algorithms. In the multi-party feature\nengineering scenario (features are stored in many different IoT devices),\ndirect and unlimited multivariate feature transformations will quickly exhaust\nmemory, power, and bandwidth of devices, not to mention the security of\ninformation threatened. Given this, we present a framework called FLFE to\nconduct privacy-preserving and communication-preserving multi-party feature\ntransformations. The framework pre-learns the pattern of the feature to\ndirectly judge the usefulness of the transformation on a feature. Explored the\nnew useful feature, the framework forsakes the encryption-based algorithm for\nthe well-designed feature exchange mechanism, which largely decreases the\ncommunication overhead under the premise of confidentiality. We made\nexperiments on datasets of both open-sourced and real-world thus validating the\ncomparable effectiveness of FLFE to evaluation-based approaches, along with the\nfar more superior efficacy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:08:54 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Fang", "Pei", ""], ["Cai", "Zhendong", ""], ["Chen", "Hui", ""], ["Shi", "QingJiang", ""]]}, {"id": "2009.02560", "submitter": "Basheer Qolomany", "authors": "Basheer Qolomany, Kashif Ahmad, Ala Al-Fuqaha, Junaid Qadir", "title": "Particle Swarm Optimized Federated Learning For Industrial IoT and Smart\n  City Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the research on Federated Learning (FL) has focused on analyzing\nglobal optimization, privacy, and communication, with limited attention\nfocusing on analyzing the critical matter of performing efficient local\ntraining and inference at the edge devices. One of the main challenges for\nsuccessful and efficient training and inference on edge devices is the careful\nselection of parameters to build local Machine Learning (ML) models. To this\naim, we propose a Particle Swarm Optimization (PSO)-based technique to optimize\nthe hyperparameter settings for the local ML models in an FL environment. We\nevaluate the performance of our proposed technique using two case studies.\nFirst, we consider smart city services and use an experimental transportation\ndataset for traffic prediction as a proxy for this setting. Second, we consider\nIndustrial IoT (IIoT) services and use the real-time telemetry dataset to\npredict the probability that a machine will fail shortly due to component\nfailures. Our experiments indicate that PSO provides an efficient approach for\ntuning the hyperparameters of deep Long short-term memory (LSTM) models when\ncompared to the grid search method. Our experiments illustrate that the number\nof clients-server communication rounds to explore the landscape of\nconfigurations to find the near-optimal parameters are greatly reduced (roughly\nby two orders of magnitude needing only 2%--4% of the rounds compared to state\nof the art non-PSO-based approaches). We also demonstrate that utilizing the\nproposed PSO-based technique to find the near-optimal configurations for FL and\ncentralized learning models does not adversely affect the accuracy of the\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:20:47 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Qolomany", "Basheer", ""], ["Ahmad", "Kashif", ""], ["Al-Fuqaha", "Ala", ""], ["Qadir", "Junaid", ""]]}, {"id": "2009.02562", "submitter": "Ziwei Zhang", "authors": "Ziwei Zhang, Chenhao Niu, Peng Cui, Bo Zhang, Wei Cui, Wenwu Zhu", "title": "A Simple and General Graph Neural Network with Stochastic Message\n  Passing", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are emerging machine learning models on graphs.\nOne key property behind the expressiveness of existing GNNs is that the learned\nnode representations are permutation-equivariant. Though being a desirable\nproperty for certain tasks, however, permutation-equivariance prevents GNNs\nfrom being proximity-aware, i.e., preserving the walk-based proximities between\npairs of nodes, which is another critical property for graph analytical tasks.\nOn the other hand, some variants of GNNs are proposed to preserve node\nproximities, but they fail to maintain permutation-equivariance. How to empower\nGNNs to be proximity-aware while maintaining permutation-equivariance remains\nan open problem. In this paper, we propose Stochastic Message Passing (SMP), a\ngeneral and simple GNN to maintain both proximity-awareness and\npermutation-equivariance properties. Specifically, we augment the existing GNNs\nwith stochastic node representations learned to preserve node proximities.\nThough seemingly simple, we prove that such a mechanism can enable GNNs to\npreserve node proximities in theory while maintaining permutation-equivariance\nwith certain parametrization. Extensive experimental results demonstrate the\neffectiveness and efficiency of SMP for tasks including node classification and\nlink prediction.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:46:56 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhang", "Ziwei", ""], ["Niu", "Chenhao", ""], ["Cui", "Peng", ""], ["Zhang", "Bo", ""], ["Cui", "Wei", ""], ["Zhu", "Wenwu", ""]]}, {"id": "2009.02571", "submitter": "Rahul Dubey Dr", "authors": "Param Khakhar and, Rahul Kumar Dubey, Senior Member IEEE", "title": "The Integrity of Machine Learning Algorithms against Software Defect\n  Prediction", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increased computerization in recent years has resulted in the production\nof a variety of different software, however measures need to be taken to ensure\nthat the produced software isn't defective. Many researchers have worked in\nthis area and have developed different Machine Learning-based approaches that\npredict whether the software is defective or not. This issue can't be resolved\nsimply by using different conventional classifiers because the dataset is\nhighly imbalanced i.e the number of defective samples detected is extremely\nless as compared to the number of non-defective samples. Therefore, to address\nthis issue, certain sophisticated methods are required. The different methods\ndeveloped by the researchers can be broadly classified into Resampling based\nmethods, Cost-sensitive learning-based methods, and Ensemble Learning. Among\nthese methods. This report analyses the performance of the Online Sequential\nExtreme Learning Machine (OS-ELM) proposed by Liang et.al. against several\nclassifiers such as Logistic Regression, Support Vector Machine, Random Forest,\nand Na\\\"ive Bayes after oversampling the data. OS-ELM trains faster than\nconventional deep neural networks and it always converges to the globally\noptimal solution. A comparison is performed on the original dataset as well as\nthe over-sampled data set. The oversampling technique used is Cluster-based\nOver-Sampling with Noise Filtering. This technique is better than several\nstate-of-the-art techniques for oversampling. The analysis is carried out on 3\nprojects KC1, PC4 and PC3 carried out by the NASA group. The metrics used for\nmeasurement are recall and balanced accuracy. The results are higher for OS-ELM\nas compared to other classifiers in both scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 17:26:56 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["and", "Param Khakhar", ""], ["Dubey", "Rahul Kumar", ""], ["IEEE", "Senior Member", ""]]}, {"id": "2009.02572", "submitter": "Selim Firat Yilmaz", "authors": "Selim F. Yilmaz and Suleyman S. Kozat", "title": "PySAD: A Streaming Anomaly Detection Framework in Python", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PySAD is an open-source python framework for anomaly detection on streaming\ndata. PySAD serves various state-of-the-art methods for streaming anomaly\ndetection. The framework provides a complete set of tools to design anomaly\ndetection experiments ranging from projectors to probability calibrators. PySAD\nbuilds upon popular open-source frameworks such as PyOD and scikit-learn. We\nenforce software quality by enforcing compliance with PEP8 guidelines,\nfunctional testing and using continuous integration. The source code is\npublicly available on https://github.com/selimfirat/pysad.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 17:41:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yilmaz", "Selim F.", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2009.02594", "submitter": "Andrei Apostol", "authors": "Andrei Apostol, Maarten Stol, Patrick Forr\\'e", "title": "FlipOut: Uncovering Redundant Weights via Sign Flipping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks, although achieving state-of-the-art results on many\ntasks, tend to have a large number of parameters, which increases training time\nand resource usage. This problem can be alleviated by pruning. Existing\nmethods, however, often require extensive parameter tuning or multiple cycles\nof pruning and retraining to convergence in order to obtain a favorable\naccuracy-sparsity trade-off. To address these issues, we propose a novel\npruning method which uses the oscillations around $0$ (i.e. sign flips) that a\nweight has undergone during training in order to determine its saliency. Our\nmethod can perform pruning before the network has converged, requires little\ntuning effort due to having good default values for its hyperparameters, and\ncan directly target the level of sparsity desired by the user. Our experiments,\nperformed on a variety of object classification architectures, show that it is\ncompetitive with existing methods and achieves state-of-the-art performance for\nlevels of sparsity of $99.6\\%$ and above for most of the architectures tested.\nFor reproducibility, we release our code publicly at\nhttps://github.com/AndreiXYZ/flipout.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 20:27:32 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Apostol", "Andrei", ""], ["Stol", "Maarten", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2009.02597", "submitter": "Kun Chen", "authors": "Wenjie Wang, Chongliang Luo, Robert H. Aseltine, Fei Wang, Jun Yan,\n  Kun Chen", "title": "Suicide Risk Modeling with Uncertain Diagnostic Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the pressing need for suicide prevention through improving\nbehavioral healthcare, we use medical claims data to study the risk of\nsubsequent suicide attempts for patients who were hospitalized due to suicide\nattempts and later discharged. Understanding the risk behaviors of such\npatients at elevated suicide risk is an important step towards the goal of\n\"Zero Suicide\". An immediate and unconventional challenge is that the\nidentification of suicide attempts from medical claims contains substantial\nuncertainty: almost 20\\% of \"suspected\" suicide attempts are identified from\ndiagnostic codes indicating external causes of injury and poisoning with\nundermined intent. It is thus of great interest to learn which of these\nundetermined events are more likely actual suicide attempts and how to properly\nutilize them in survival analysis with severe censoring. To tackle these\ninterrelated problems, we develop an integrative Cox cure model with\nregularization to perform survival regression with uncertain events and a\nlatent cure fraction. We apply the proposed approach to study the risk of\nsubsequent suicide attempt after suicide-related hospitalization for adolescent\nand young adult population, using medical claims data from Connecticut. The\nidentified risk factors are highly interpretable; more intriguingly, our method\ndistinguishes the risk factors that are most helpful in assessing either\nsusceptibility or timing of subsequent attempt. The predicted statuses of the\nuncertain attempts are further investigated, leading to several new insights on\nsuicide event identification.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 20:47:16 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wang", "Wenjie", ""], ["Luo", "Chongliang", ""], ["Aseltine", "Robert H.", ""], ["Wang", "Fei", ""], ["Yan", "Jun", ""], ["Chen", "Kun", ""]]}, {"id": "2009.02602", "submitter": "Ashkan Zehfroosh", "authors": "Ashkan Zehfroosh and Herbert G. Tanner", "title": "A Hybrid PAC Reinforcement Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a new hybrid probably approximately correct (PAC)\nreinforcement learning (RL) algorithm for Markov decision processes (MDPs) that\nintelligently maintains favorable features of its parents. The designed\nalgorithm, referred to as the Dyna-Delayed Q-learning (DDQ) algorithm, combines\nmodel-free and model-based learning approaches while outperforming both in most\ncases. The paper includes a PAC analysis of the DDQ algorithm and a derivation\nof its sample complexity. Numerical results are provided to support the claim\nregarding the new algorithm's sample efficiency compared to its parents as well\nas the best known model-free and model-based algorithms in application.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 21:32:42 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 05:24:39 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Zehfroosh", "Ashkan", ""], ["Tanner", "Herbert G.", ""]]}, {"id": "2009.02604", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Jos\\'e Bento", "title": "Distributed Optimization, Averaging via ADMM, and Network Topology", "comments": "to appear in \"Proceedings of the IEEE\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing necessity for scalable optimization methods,\nespecially due to the explosion in the size of datasets and model complexity in\nmodern machine learning applications. Scalable solvers often distribute the\ncomputation over a network of processing units. For simple algorithms such as\ngradient descent the dependency of the convergence time with the topology of\nthis network is well-known. However, for more involved algorithms such as the\nAlternating Direction Methods of Multipliers (ADMM) much less is known. At the\nheart of many distributed optimization algorithms there exists a gossip\nsubroutine which averages local information over the network, and whose\nefficiency is crucial for the overall performance of the method. In this paper\nwe review recent research in this area and, with the goal of isolating such a\ncommunication exchange behaviour, we compare different algorithms when applied\nto a canonical distributed averaging consensus problem. We also show\ninteresting connections between ADMM and lifted Markov chains besides providing\nan explicitly characterization of its convergence and optimal parameter tuning\nin terms of spectral properties of the network. Finally, we empirically study\nthe connection between network topology and convergence rates for different\nalgorithms on a real world problem of sensor localization.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 21:44:39 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "2009.02609", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Richard J. Samworth", "title": "Isotonic regression with unknown permutations: Statistics, computation,\n  and adaptation", "comments": "Version v2 contains reorganized material, one figure, and expanded\n  discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by models for multiway comparison data, we consider the problem of\nestimating a coordinate-wise isotonic function on the domain $[0, 1]^d$ from\nnoisy observations collected on a uniform lattice, but where the design points\nhave been permuted along each dimension. While the univariate and bivariate\nversions of this problem have received significant attention, our focus is on\nthe multivariate case $d \\geq 3$. We study both the minimax risk of estimation\n(in empirical $L_2$ loss) and the fundamental limits of adaptation (quantified\nby the adaptivity index) to a family of piecewise constant functions. We\nprovide a computationally efficient Mirsky partition estimator that is minimax\noptimal while also achieving the smallest adaptivity index possible for\npolynomial time procedures. Thus, from a worst-case perspective and in sharp\ncontrast to the bivariate case, the latent permutations in the model do not\nintroduce significant computational difficulties over and above vanilla\nisotonic regression. On the other hand, the fundamental limits of adaptation\nare significantly different with and without unknown permutations: Assuming a\nhardness conjecture from average-case complexity theory, a\nstatistical-computational gap manifests in the former case. In a complementary\ndirection, we show that natural modifications of existing estimators fail to\nsatisfy at least one of the desiderata of optimal worst-case statistical\nperformance, computational efficiency, and fast adaptation. Along the way to\nshowing our results, we improve adaptation results in the special case $d = 2$\nand establish some properties of estimators for vanilla isotonic regression,\nboth of which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 22:17:51 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 13:58:37 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Samworth", "Richard J.", ""]]}, {"id": "2009.02623", "submitter": "Zifeng Wang", "authors": "Zifeng Wang and Xi Chen and Rui Wen and Shao-Lun Huang and Ercan E.\n  Kuruoglu and Yefeng Zheng", "title": "Information Theoretic Counterfactual Learning from Missing-Not-At-Random\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual learning for dealing with missing-not-at-random data (MNAR) is\nan intriguing topic in the recommendation literature since MNAR data are\nubiquitous in modern recommender systems. Missing-at-random (MAR) data, namely\nrandomized controlled trials (RCTs), are usually required by most previous\ncounterfactual learning methods for debiasing learning. However, the execution\nof RCTs is extraordinarily expensive in practice. To circumvent the use of\nRCTs, we build an information-theoretic counterfactual variational information\nbottleneck (CVIB), as an alternative for debiasing learning without RCTs. By\nseparating the task-aware mutual information term in the original information\nbottleneck Lagrangian into factual and counterfactual parts, we derive a\ncontrastive information loss and an additional output confidence penalty, which\nfacilitates balanced learning between the factual and counterfactual domains.\nEmpirical evaluation on real-world datasets shows that our CVIB significantly\nenhances both shallow and deep models, which sheds light on counterfactual\nlearning in recommendation that goes beyond RCTs.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 01:22:47 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 13:54:54 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Zifeng", ""], ["Chen", "Xi", ""], ["Wen", "Rui", ""], ["Huang", "Shao-Lun", ""], ["Kuruoglu", "Ercan E.", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2009.02653", "submitter": "Jiang Lu", "authors": "Jiang Lu, Pinghua Gong, Jieping Ye, and Changshui Zhang", "title": "Learning from Very Few Samples: A Survey", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few sample learning (FSL) is significant and challenging in the field of\nmachine learning. The capability of learning and generalizing from very few\nsamples successfully is a noticeable demarcation separating artificial\nintelligence and human intelligence since humans can readily establish their\ncognition to novelty from just a single or a handful of examples whereas\nmachine learning algorithms typically entail hundreds or thousands of\nsupervised samples to guarantee generalization ability. Despite the long\nhistory dated back to the early 2000s and the widespread attention in recent\nyears with booming deep learning technologies, little surveys or reviews for\nFSL are available until now. In this context, we extensively review 300+ papers\nof FSL spanning from the 2000s to 2019 and provide a timely and comprehensive\nsurvey for FSL. In this survey, we review the evolution history as well as the\ncurrent progress on FSL, categorize FSL approaches into the generative model\nbased and discriminative model based kinds in principle, and emphasize\nparticularly on the meta learning based FSL approaches. We also summarize\nseveral recently emerging extensional topics of FSL and review the latest\nadvances on these topics. Furthermore, we highlight the important FSL\napplications covering many research hotspots in computer vision, natural\nlanguage processing, audio and speech, reinforcement learning and robotic, data\nanalysis, etc. Finally, we conclude the survey with a discussion on promising\ntrends in the hope of providing guidance and insights to follow-up researches.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 06:13:09 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 14:21:57 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lu", "Jiang", ""], ["Gong", "Pinghua", ""], ["Ye", "Jieping", ""], ["Zhang", "Changshui", ""]]}, {"id": "2009.02661", "submitter": "Himanshu Buckchash", "authors": "Vipul Bansal, Himanshu Buckchash, Balasubramanian Raman", "title": "Computational Models for Academic Performance Estimation", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of students' performance for the completion of courses has been a\nmajor problem for both students and faculties during the work-from-home period\nin this COVID pandemic situation. To this end, this paper presents an in-depth\nanalysis of deep learning and machine learning approaches for the formulation\nof an automated students' performance estimation system that works on partially\navailable students' academic records. Our main contributions are (a) a large\ndataset with fifteen courses (shared publicly for academic research) (b)\nstatistical analysis and ablations on the estimation problem for this dataset\n(c) predictive analysis through deep learning approaches and comparison with\nother arts and machine learning algorithms. Unlike previous approaches that\nrely on feature engineering or logical function deduction, our approach is\nfully data-driven and thus highly generic with better performance across\ndifferent prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 07:31:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bansal", "Vipul", ""], ["Buckchash", "Himanshu", ""], ["Raman", "Balasubramanian", ""]]}, {"id": "2009.02668", "submitter": "Jalaj Upadhyay", "authors": "Jalaj Upadhyay, Sarvagya Upadhyay", "title": "A Framework for Private Matrix Analysis", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study private matrix analysis in the sliding window model where only the\nlast $W$ updates to matrices are considered useful for analysis. We give first\nefficient $o(W)$ space differentially private algorithms for spectral\napproximation, principal component analysis, and linear regression. We also\ninitiate and show efficient differentially private algorithms for two important\nvariants of principal component analysis: sparse principal component analysis\nand non-negative principal component analysis. Prior to our work, no such\nresult was known for sparse and non-negative differentially private principal\ncomponent analysis even in the static data setting. These algorithms are\nobtained by identifying sufficient conditions on positive semidefinite matrices\nformed from streamed matrices. We also show a lower bound on space required to\ncompute low-rank approximation even if the algorithm gives multiplicative\napproximation and incurs additive error. This follows via reduction to a\ncertain communication complexity problem.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 08:01:59 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Upadhyay", "Jalaj", ""], ["Upadhyay", "Sarvagya", ""]]}, {"id": "2009.02695", "submitter": "Kohei Yoshikawa", "authors": "Kohei Yoshikawa, Shuichi Kawano", "title": "Multilinear Common Component Analysis via Kronecker Product\n  Representation", "comments": "35 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of extracting a common structure from multiple tensor\ndatasets. For this purpose, we propose multilinear common component analysis\n(MCCA) based on Kronecker products of mode-wise covariance matrices. MCCA\nconstructs a common basis represented by linear combinations of the original\nvariables which loses as little information of the multiple tensor datasets. We\nalso develop an estimation algorithm for MCCA that guarantees mode-wise global\nconvergence. Numerical studies are conducted to show the effectiveness of MCCA.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:03:17 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 08:06:05 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Yoshikawa", "Kohei", ""], ["Kawano", "Shuichi", ""]]}, {"id": "2009.02701", "submitter": "Yuhao Zhou", "authors": "Yuhao Zhou, Qing Ye, Hailun Zhang, Jiancheng Lv", "title": "HPSGD: Hierarchical Parallel SGD With Stale Gradients Featuring", "comments": "12 pages, 10 figures, ICONIP2020 under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While distributed training significantly speeds up the training process of\nthe deep neural network (DNN), the utilization of the cluster is relatively low\ndue to the time-consuming data synchronizing between workers. To alleviate this\nproblem, a novel Hierarchical Parallel SGD (HPSGD) strategy is proposed based\non the observation that the data synchronization phase can be paralleled with\nthe local training phase (i.e., Feed-forward and back-propagation).\nFurthermore, an improved model updating method is unitized to remedy the\nintroduced stale gradients problem, which commits updates to the replica (i.e.,\na temporary model that has the same parameters as the global model) and then\nmerges the average changes to the global model. Extensive experiments are\nconducted to demonstrate that the proposed HPSGD approach substantially boosts\nthe distributed DNN training, reduces the disturbance of the stale gradients\nand achieves better accuracy in given fixed wall-time.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:17:56 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 15:36:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhou", "Yuhao", ""], ["Ye", "Qing", ""], ["Zhang", "Hailun", ""], ["Lv", "Jiancheng", ""]]}, {"id": "2009.02709", "submitter": "Eugene Ndiaye", "authors": "Eugene Ndiaye and Olivier Fercoq and Joseph Salmon", "title": "Screening Rules and its Complexity for Active Set Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screening rules were recently introduced as a technique for explicitly\nidentifying active structures such as sparsity, in optimization problem arising\nin machine learning. This has led to new methods of acceleration based on a\nsubstantial dimension reduction. We show that screening rules stem from a\ncombination of natural properties of subdifferential sets and optimality\nconditions, and can hence be understood in a unified way. Under mild\nassumptions, we analyze the number of iterations needed to identify the optimal\nactive set for any converging algorithm. We show that it only depends on its\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 11:10:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Fercoq", "Olivier", ""], ["Salmon", "Joseph", ""]]}, {"id": "2009.02728", "submitter": "Kailash Budhathoki", "authors": "Kailash Budhathoki, Mario Boley and Jilles Vreeken", "title": "Discovering Reliable Causal Rules", "comments": "Poster presented in NeurIPS 2018 Workshop on Causal Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of deriving policies, or rules, that when enacted on a\ncomplex system, cause a desired outcome. Absent the ability to perform\ncontrolled experiments, such rules have to be inferred from past observations\nof the system's behaviour. This is a challenging problem for two reasons:\nFirst, observational effects are often unrepresentative of the underlying\ncausal effect because they are skewed by the presence of confounding factors.\nSecond, naive empirical estimations of a rule's effect have a high variance,\nand, hence, their maximisation can lead to random results.\n  To address these issues, first we measure the causal effect of a rule from\nobservational data---adjusting for the effect of potential confounders.\nImportantly, we provide a graphical criteria under which causal rule discovery\nis possible. Moreover, to discover reliable causal rules from a sample, we\npropose a conservative and consistent estimator of the causal effect, and\nderive an efficient and exact algorithm that maximises the estimator. On\nsynthetic data, the proposed estimator converges faster to the ground truth\nthan the naive estimator and recovers relevant causal rules even at small\nsample sizes. Extensive experiments on a variety of real-world datasets show\nthat the proposed algorithm is efficient and discovers meaningful rules.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:08:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 07:53:40 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Budhathoki", "Kailash", ""], ["Boley", "Mario", ""], ["Vreeken", "Jilles", ""]]}, {"id": "2009.02738", "submitter": "Chuanxi Chen", "authors": "Dengpan Ye, Chuanxi Chen, Changrui Liu, Hao Wang, Shunzhi Jiang", "title": "Detection Defense Against Adversarial Attacks with Saliency Map", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well established that neural networks are vulnerable to adversarial\nexamples, which are almost imperceptible on human vision and can cause the deep\nmodels misbehave. Such phenomenon may lead to severely inestimable consequences\nin the safety and security critical applications. Existing defenses are trend\nto harden the robustness of models against adversarial attacks, e.g.,\nadversarial training technology. However, these are usually intractable to\nimplement due to the high cost of re-training and the cumbersome operations of\naltering the model architecture or parameters. In this paper, we discuss the\nsaliency map method from the view of enhancing model interpretability, it is\nsimilar to introducing the mechanism of the attention to the model, so as to\ncomprehend the progress of object identification by the deep networks. We then\npropose a novel method combined with additional noises and utilize the\ninconsistency strategy to detect adversarial examples. Our experimental results\nof some representative adversarial attacks on common datasets including\nImageNet and popular models show that our method can detect all the attacks\nwith high detection success rate effectively. We compare it with the existing\nstate-of-the-art technique, and the experiments indicate that our method is\nmore general.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:57:17 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ye", "Dengpan", ""], ["Chen", "Chuanxi", ""], ["Liu", "Changrui", ""], ["Wang", "Hao", ""], ["Jiang", "Shunzhi", ""]]}, {"id": "2009.02741", "submitter": "Alexander Goscinski", "authors": "Alexander Goscinski and Guillaume Fraux and Giulio Imbalzano and\n  Michele Ceriotti", "title": "The role of feature space in atomistic learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eficient, physically-inspired descriptors of the structure and composition of\nmolecules and materials play a key role in the application of machine-learning\ntechniques to atomistic simulations. The proliferation of approaches, as well\nas the fact that each choice of features can lead to very different behavior\ndepending on how they are used, e.g. by introducing non-linear kernels and\nnon-Euclidean metrics to manipulate them, makes it difficult to objectively\ncompare different methods, and to address fundamental questions on how one\nfeature space is related to another. In this work we introduce a framework to\ncompare different sets of descriptors, and different ways of transforming them\nby means of metrics and kernels, in terms of the structure of the feature space\nthat they induce. We define diagnostic tools to determine whether alternative\nfeature spaces contain equivalent amounts of information, and whether the\ncommon information is substantially distorted when going from one feature space\nto another. We compare, in particular, representations that are built in terms\nof n-body correlations of the atom density, quantitatively assessing the\ninformation loss associated with the use of low-order features. We also\ninvestigate the impact of different choices of basis functions and\nhyperparameters of the widely used SOAP and Behler-Parrinello features, and\ninvestigate how the use of non-linear kernels, and of a Wasserstein-type\nmetric, change the structure of the feature space in comparison to a simpler\nlinear feature space.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 14:12:09 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 15:23:55 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 15:16:50 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 10:17:59 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Goscinski", "Alexander", ""], ["Fraux", "Guillaume", ""], ["Imbalzano", "Giulio", ""], ["Ceriotti", "Michele", ""]]}, {"id": "2009.02755", "submitter": "Boris Lorbeer", "authors": "Boris Lorbeer, Max Botler", "title": "Anomaly Detection With Partitioning Overfitting Autoencoder Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose POTATOES (Partitioning OverfiTting AuTOencoder\nEnSemble), a new method for unsupervised outlier detection (UOD). More\nprecisely, given any autoencoder for UOD, this technique can be used to improve\nits accuracy while at the same time removing the burden of tuning its\nregularization. The idea is to not regularize at all, but to rather randomly\npartition the data into sufficiently many equally sized parts, overfit each\npart with its own autoencoder, and to use the maximum over all autoencoder\nreconstruction errors as the anomaly score. We apply our model to various\nrealistic datasets and show that if the set of inliers is dense enough, our\nmethod indeed improves the UOD performance of a given autoencoder\nsignificantly. For reproducibility, the code is made available on github so the\nreader can recreate the results in this paper as well as apply the method to\nother autoencoders and datasets.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 15:35:53 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 14:58:15 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 07:53:58 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 05:55:18 GMT"}, {"version": "v5", "created": "Wed, 28 Apr 2021 14:23:07 GMT"}, {"version": "v6", "created": "Sun, 4 Jul 2021 05:14:50 GMT"}, {"version": "v7", "created": "Fri, 9 Jul 2021 04:40:04 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Lorbeer", "Boris", ""], ["Botler", "Max", ""]]}, {"id": "2009.02763", "submitter": "Hao Li", "authors": "Chang Wang, Jian Liang, Mingkai Huang, Bing Bai, Kun Bai, Hao Li", "title": "Hybrid Differentially Private Federated Learning on Vertically\n  Partitioned Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HDP-VFL, the first hybrid differentially private (DP) framework\nfor vertical federated learning (VFL) to demonstrate that it is possible to\njointly learn a generalized linear model (GLM) from vertically partitioned data\nwith only a negligible cost, w.r.t. training time, accuracy, etc., comparing to\nidealized non-private VFL. Our work builds on the recent advances in VFL-based\ncollaborative training among different organizations which rely on protocols\nlike Homomorphic Encryption (HE) and Secure Multi-Party Computation (MPC) to\nsecure computation and training. In particular, we analyze how VFL's\nintermediate result (IR) can leak private information of the training data\nduring communication and design a DP-based privacy-preserving algorithm to\nensure the data confidentiality of VFL participants. We mathematically prove\nthat our algorithm not only provides utility guarantees for VFL, but also\noffers multi-level privacy, i.e. DP w.r.t. IR and joint differential privacy\n(JDP) w.r.t. model weights. Experimental results demonstrate that our work,\nunder adequate privacy budgets, is quantitatively and qualitatively similar to\nGLMs, learned in idealized non-private VFL setting, rather than the increased\ncost in memory and processing time in most prior works based on HE or MPC. Our\ncodes will be released if this paper is accepted.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:06:04 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wang", "Chang", ""], ["Liang", "Jian", ""], ["Huang", "Mingkai", ""], ["Bai", "Bing", ""], ["Bai", "Kun", ""], ["Li", "Hao", ""]]}, {"id": "2009.02773", "submitter": "Zinan Lin", "authors": "Zinan Lin, Vyas Sekar, Giulia Fanti", "title": "Why Spectral Normalization Stabilizes GANs: Analysis and Improvements", "comments": "54 pages, 74 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral normalization (SN) is a widely-used technique for improving the\nstability and sample quality of Generative Adversarial Networks (GANs).\nHowever, there is currently limited understanding of why SN is effective. In\nthis work, we show that SN controls two important failure modes of GAN\ntraining: exploding and vanishing gradients. Our proofs illustrate a (perhaps\nunintentional) connection with the successful LeCun initialization. This\nconnection helps to explain why the most popular implementation of SN for GANs\nrequires no hyper-parameter tuning, whereas stricter implementations of SN have\npoor empirical performance out-of-the-box. Unlike LeCun initialization which\nonly controls gradient vanishing at the beginning of training, SN preserves\nthis property throughout training. Building on this theoretical understanding,\nwe propose a new spectral normalization technique: Bidirectional Scaled\nSpectral Normalization (BSSN), which incorporates insights from later\nimprovements to LeCun initialization: Xavier initialization and Kaiming\ninitialization. Theoretically, we show that BSSN gives better gradient control\nthan SN. Empirically, we demonstrate that it outperforms SN in sample quality\nand training stability on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:51:42 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 00:29:30 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Lin", "Zinan", ""], ["Sekar", "Vyas", ""], ["Fanti", "Giulia", ""]]}, {"id": "2009.02799", "submitter": "Pietro Barbiero", "authors": "Giansalvo Cirrincione, Pietro Barbiero, Gabriele Ciravegna, Vincenzo\n  Randazzo", "title": "Gradient-based Competitive Learning: Theory", "comments": "18 pages. arXiv admin note: text overlap with arXiv:2008.09477", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been widely used for supervised learning and\nclassification/regression problems. Recently, a novel area of research has\napplied this paradigm to unsupervised tasks; indeed, a gradient-based approach\nextracts, efficiently and autonomously, the relevant features for handling\ninput data. However, state-of-the-art techniques focus mostly on algorithmic\nefficiency and accuracy rather than mimic the input manifold. On the contrary,\ncompetitive learning is a powerful tool for replicating the input distribution\ntopology. This paper introduces a novel perspective in this area by combining\nthese two techniques: unsupervised gradient-based and competitive learning. The\ntheory is based on the intuition that neural networks are able to learn\ntopological structures by working directly on the transpose of the input\nmatrix. At this purpose, the vanilla competitive layer and its dual are\npresented. The former is just an adaptation of a standard competitive layer for\ndeep clustering, while the latter is trained on the transposed matrix. Their\nequivalence is extensively proven both theoretically and experimentally.\nHowever, the dual layer is better suited for handling very high-dimensional\ndatasets. The proposed approach has a great potential as it can be generalized\nto a vast selection of topological learning tasks, such as non-stationary and\nhierarchical clustering; furthermore, it can also be integrated within more\ncomplex architectures such as autoencoders and generative adversarial networks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 19:00:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Cirrincione", "Giansalvo", ""], ["Barbiero", "Pietro", ""], ["Ciravegna", "Gabriele", ""], ["Randazzo", "Vincenzo", ""]]}, {"id": "2009.02825", "submitter": "Seyedeh Niusha Alavi Foumani", "authors": "Seyedeh Niusha Alavi Foumani, Ce Guo, Wayne Luk", "title": "An Analysis of Alternating Direction Method of Multipliers for\n  Feed-forward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a hardware compatible neural network training\nalgorithm in which we used alternating direction method of multipliers (ADMM)\nand iterative least-square methods. The motive behind this approach was to\nconduct a method of training neural networks that is scalable and can be\nparallelised. These characteristics make this algorithm suitable for hardware\nimplementation. We have achieved 6.9\\% and 6.8\\% better accuracy comparing to\nSGD and Adam respectively, with a four-layer neural network with hidden size of\n28 on HIGGS dataset. Likewise, we could observe 21.0\\% and 2.2\\% accuracy\nimprovement comparing to SGD and Adam respectively, on IRIS dataset with a\nthree-layer neural network with hidden size of 8. This is while the use of\nmatrix inversion, which is challenging for hardware implementation, is avoided\nin this method. We assessed the impact of avoiding matrix inversion on ADMM\naccuracy and we observed that we can safely replace matrix inversion with\niterative least-square methods and maintain the desired performance. Also, the\ncomputational complexity of the implemented method is polynomial regarding\ndimensions of the input dataset and hidden size of the network.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 22:13:54 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Foumani", "Seyedeh Niusha Alavi", ""], ["Guo", "Ce", ""], ["Luk", "Wayne", ""]]}, {"id": "2009.02845", "submitter": "Hui Li", "authors": "Yuqiu Qian, Conghui Tan, Danhao Ding, Hui Li, Nikos Mamoulis", "title": "Fast and Secure Distributed Nonnegative Matrix Factorization", "comments": "Published in IEEE Transactions on Knowledge and Data Engineering\n  (TKDE). This arXiv version includes the appendices with additional proofs", "journal-ref": null, "doi": "10.1109/TKDE.2020.2985964", "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has been successfully applied in\nseveral data mining tasks. Recently, there is an increasing interest in the\nacceleration of NMF, due to its high cost on large matrices. On the other hand,\nthe privacy issue of NMF over federated data is worthy of attention, since NMF\nis prevalently applied in image and text analysis which may involve leveraging\nprivacy data (e.g, medical image and record) across several parties (e.g.,\nhospitals). In this paper, we study the acceleration and security problems of\ndistributed NMF. Firstly, we propose a distributed sketched alternating\nnonnegative least squares (DSANLS) framework for NMF, which utilizes a matrix\nsketching technique to reduce the size of nonnegative least squares subproblems\nwith a convergence guarantee. For the second problem, we show that DSANLS with\nmodification can be adapted to the security setting, but only for one or\nlimited iterations. Consequently, we propose four efficient distributed NMF\nmethods in both synchronous and asynchronous settings with a security\nguarantee. We conduct extensive experiments on several real datasets to show\nthe superiority of our proposed methods. The implementation of our methods is\navailable at https://github.com/qianyuqiu79/DSANLS.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 01:12:20 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Qian", "Yuqiu", ""], ["Tan", "Conghui", ""], ["Ding", "Danhao", ""], ["Li", "Hui", ""], ["Mamoulis", "Nikos", ""]]}, {"id": "2009.02859", "submitter": "Khanh Luong", "authors": "Khanh Luong and Richi Nayak", "title": "Learning Inter- and Intra-manifolds for Matrix Factorization-based\n  Multi-Aspect Data Clustering", "comments": "15 pages with appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering on the data with multiple aspects, such as multi-view or\nmulti-type relational data, has become popular in recent years due to their\nwide applicability. The approach using manifold learning with the Non-negative\nMatrix Factorization (NMF) framework, that learns the accurate low-rank\nrepresentation of the multi-dimensional data, has shown effectiveness. We\npropose to include the inter-manifold in the NMF framework, utilizing the\ndistance information of data points of different data types (or views) to learn\nthe diverse manifold for data clustering. Empirical analysis reveals that the\nproposed method can find partial representations of various interrelated types\nand select useful features during clustering. Results on several datasets\ndemonstrate that the proposed method outperforms the state-of-the-art\nmulti-aspect data clustering methods in both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 02:21:08 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Luong", "Khanh", ""], ["Nayak", "Richi", ""]]}, {"id": "2009.02861", "submitter": "Yining Wang", "authors": "Yining Wang and He Wang", "title": "Constant Regret Re-solving Heuristics for Price-based Revenue Management", "comments": "Revised version. Improved regret upper bounds to O(1) and\n  extension/generalization to multiple products and heteroscedastic demand\n  noises", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Price-based revenue management is an important problem in operations\nmanagement with many practical applications. The problem considers a retailer\nwho sells a product (or multiple products) over $T$ consecutive time periods\nand is subject to constraints on the initial inventory levels. While the\noptimal pricing policy could be obtained via dynamic programming, such an\napproach is sometimes undesirable because of high computational costs.\nApproximate policies, such as the re-solving heuristics, are often applied as\ncomputationally tractable alternatives. In this paper, we show the following\ntwo results. First, we prove that a natural re-solving heuristic attains $O(1)$\nregret compared to the value of the optimal policy. This improves the $O(\\ln\nT)$ regret upper bound established in the prior work of\n\\cite{jasin2014reoptimization}. Second, we prove that there is an $\\Omega(\\ln\nT)$ gap between the value of the optimal policy and that of the fluid model.\nThis complements our upper bound result by showing that the fluid is not an\nadequate information-relaxed benchmark when analyzing price-based revenue\nmanagement algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 02:28:26 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 20:01:20 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Wang", "Yining", ""], ["Wang", "He", ""]]}, {"id": "2009.02874", "submitter": "Shankar Deka", "authors": "Shankar A. Deka and Du\\v{s}an M. Stipanovi\\'c and Claire J. Tomlin", "title": "Dynamically Computing Adversarial Perturbations for Recurrent Neural\n  Networks", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional and recurrent neural networks have been widely employed to\nachieve state-of-the-art performance on classification tasks. However, it has\nalso been noted that these networks can be manipulated adversarially with\nrelative ease, by carefully crafted additive perturbations to the input. Though\nseveral experimentally established prior works exist on crafting and defending\nagainst attacks, it is also desirable to have theoretical guarantees on the\nexistence of adversarial examples and robustness margins of the network to such\nexamples. We provide both in this paper. We focus specifically on recurrent\narchitectures and draw inspiration from dynamical systems theory to naturally\ncast this as a control problem, allowing us to dynamically compute adversarial\nperturbations at each timestep of the input sequence, thus resembling a\nfeedback controller. Illustrative examples are provided to supplement the\ntheoretical discussions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 03:37:03 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Deka", "Shankar A.", ""], ["Stipanovi\u0107", "Du\u0161an M.", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "2009.02880", "submitter": "Xiancai Tian", "authors": "Xiancai Tian, Chen Zhang, Baihua Zheng", "title": "Crowding Prediction of In-Situ Metro Passengers Using Smart Card Data", "comments": "11 pages, preprint for IEEE transactions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The metro system is playing an increasingly important role in the urban\npublic transit network, transferring a massive human flow across space everyday\nin the city. In recent years, extensive research studies have been conducted to\nimprove the service quality of metro systems. Among them, crowd management has\nbeen a critical issue for both public transport agencies and train operators.\nIn this paper, by utilizing accumulated smart card data, we propose a\nstatistical model to predict in-situ passenger density, i.e., number of\non-board passengers between any two neighbouring stations, inside a closed\nmetro system. The proposed model performs two main tasks: i) forecasting\ntime-dependent Origin-Destination (OD) matrix by applying mature statistical\nmodels; and ii) estimating the travel time cost required by different parts of\nthe metro network via truncated normal mixture distributions with\nExpectation-Maximization (EM) algorithm. Based on the prediction results, we\nare able to provide accurate prediction of in-situ passenger density for a\nfuture time point. A case study using real smart card data in Singapore Mass\nRapid Transit (MRT) system demonstrate the efficacy and efficiency of our\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 04:07:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Tian", "Xiancai", ""], ["Zhang", "Chen", ""], ["Zheng", "Baihua", ""]]}, {"id": "2009.02909", "submitter": "Beomjo Shin", "authors": "Beomjo Shin, Junsu Cho, Hwanjo Yu, Seungjin Choi", "title": "Sparse Network Inversion for Key Instance Detection in Multiple Instance\n  Learning", "comments": "8 pages, 4 figures, in Proceedings of the 25th International\n  Conference on Pattern Recognition (ICPR-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple Instance Learning (MIL) involves predicting a single label for a bag\nof instances, given positive or negative labels at bag-level, without accessing\nto label for each instance in the training phase. Since a positive bag contains\nboth positive and negative instances, it is often required to detect positive\ninstances (key instances) when a set of instances is categorized as a positive\nbag. The attention-based deep MIL model is a recent advance in both bag-level\nclassification and key instance detection (KID). However, if the positive and\nnegative instances in a positive bag are not clearly distinguishable, the\nattention-based deep MIL model has limited KID performance as the attention\nscores are skewed to few positive instances. In this paper, we present a method\nto improve the attention-based deep MIL model in the task of KID. The main idea\nis to use the neural network inversion to find which instances made\ncontribution to the bag-level prediction produced by the trained MIL model.\nMoreover, we incorporate a sparseness constraint into the neural network\ninversion, leading to the sparse network inversion which is solved by the\nproximal gradient method. Numerical experiments on an MNIST-based image MIL\ndataset and two real-world histopathology datasets verify the validity of our\nmethod, demonstrating the KID performance is significantly improved while the\nperformance of bag-level prediction is maintained.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 07:01:59 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 01:09:53 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Shin", "Beomjo", ""], ["Cho", "Junsu", ""], ["Yu", "Hwanjo", ""], ["Choi", "Seungjin", ""]]}, {"id": "2009.02911", "submitter": "Guiyu Hong", "authors": "Xinyun Chen, Yunan Liu and Guiyu Hong", "title": "An online learning approach to dynamic pricing and capacity sizing in\n  service systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a dynamic pricing and capacity sizing problem in a GI/GI/1 queue,\nwhere the service provider's objective is to obtain the optimal service fee $p$\nand service capacity $\\mu$ so as to maximize cumulative expected profit (the\nservice revenue minus the staffing cost and delay penalty). Due to the complex\nnature of the queueing dynamics, such a problem has no analytic solution so\nthat previous research often resorts to heavy-traffic analysis in that both the\narrival rate and service rate are sent to infinity. In this work we propose an\nonline learning framework designed for solving this problem which does not\nrequire the system's scale to increase. Our algorithm organizes the time\nhorizon into successive operational cycles and prescribes an efficient\nprocedure to obtain improved pricing and staffing policies in each cycle using\ndata collected in previous cycles. Data here include the number of customer\narrivals, waiting times, and the server's busy times. The ingenuity of this\napproach lies in its online nature, which allows the service provider do better\nby interacting with the environment. Effectiveness of our online learning\nalgorithm is substantiated by (i) theoretical results including the algorithm\nconvergence and regret analysis (with a logarithmic regret bound), and (ii)\nengineering confirmation via simulation experiments of a variety of\nrepresentative GI/GI/1 queues.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 07:17:20 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Chen", "Xinyun", ""], ["Liu", "Yunan", ""], ["Hong", "Guiyu", ""]]}, {"id": "2009.02913", "submitter": "Pietro Vischia", "authors": "Pietro Vischia", "title": "Unfolding by Folding: a resampling approach to the problem of matrix\n  inversion without actually inverting any matrix", "comments": "20 pages, 16 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ex physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix inversion problems are often encountered in experimental physics, and\nin particular in high-energy particle physics, under the name of unfolding. The\ntrue spectrum of a physical quantity is deformed by the presence of a detector,\nresulting in an observed spectrum. If we discretize both the true and observed\nspectra into histograms, we can model the detector response via a matrix.\nInferring a true spectrum starting from an observed spectrum requires therefore\ninverting the response matrix. Many methods exist in literature for this task,\nall starting from the observed spectrum and using a simulated true spectrum as\na guide to obtain a meaningful solution in cases where the response matrix is\nnot easily invertible.\n  In this Manuscript, I take a different approach to the unfolding problem.\nRather than inverting the response matrix and transforming the observed\ndistribution into the most likely parent distribution in generator space, I\nsample many distributions in generator space, fold them through the original\nresponse matrix, and pick the generator-level distribution that yields the\nfolded distribution closest to the data distribution. Regularization schemes\ncan be introduced to treat the case where non-diagonal response matrices result\nin high-frequency oscillations of the solution in true space, and the\nintroduced bias is studied.\n  The algorithm performs as well as traditional unfolding algorithms in cases\nwhere the inverse problem is well-defined in terms of the discretization of the\ntrue and smeared space, and outperforms them in cases where the inverse problem\nis ill-defined---when the number of truth-space bins is larger than that of\nsmeared-space bins. These advantages stem from the fact that the algorithm does\nnot technically invert any matrix and uses only the data distribution as a\nguide to choose the best solution.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 07:20:45 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Vischia", "Pietro", ""]]}, {"id": "2009.02955", "submitter": "Roy Mitz", "authors": "Roy Mitz, Yoel Shkolnisky", "title": "A perturbation based out-of-sample extension framework", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-sample extension is an important task in various kernel based\nnon-linear dimensionality reduction algorithms. In this paper, we derive a\nperturbation based extension framework by extending results from classical\nperturbation theory. We prove that our extension framework generalizes the\nwell-known Nystr{\\\"o}m method as well as some of its variants. We provide an\nerror analysis for our extension framework, and suggest new forms of extension\nunder this framework that take advantage of the structure of the kernel matrix.\nWe support our theoretical results numerically and demonstrate the advantages\nof our extension framework both on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:14:18 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Mitz", "Roy", ""], ["Shkolnisky", "Yoel", ""]]}, {"id": "2009.02961", "submitter": "Cemre Zor", "authors": "Sara Atito Ali Ahmed, Cemre Zor, Berrin Yanikoglu, Muhammad Awais,\n  Josef Kittler", "title": "Deep Convolutional Neural Network Ensembles using ECOC", "comments": "13 pages double column IEEE transactions style", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have enhanced the performance of decision making systems\nin many applications including image understanding, and further gains can be\nachieved by constructing ensembles. However, designing an ensemble of deep\nnetworks is often not very beneficial since the time needed to train the\nnetworks is very high or the performance gain obtained is not very significant.\nIn this paper, we analyse error correcting output coding (ECOC) framework to be\nused as an ensemble technique for deep networks and propose different design\nstrategies to address the accuracy-complexity trade-off. We carry out an\nextensive comparative study between the introduced ECOC designs and the\nstate-of-the-art ensemble techniques such as ensemble averaging and gradient\nboosting decision trees. Furthermore, we propose a combinatory technique which\nis shown to achieve the highest classification performance amongst all.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:20:24 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 16:39:12 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Ahmed", "Sara Atito Ali", ""], ["Zor", "Cemre", ""], ["Yanikoglu", "Berrin", ""], ["Awais", "Muhammad", ""], ["Kittler", "Josef", ""]]}, {"id": "2009.02980", "submitter": "Guillaume Perez", "authors": "Guillaume Perez, Sebastian Ament, Carla Gomes, Michel Barlaud", "title": "Efficient Projection Algorithms onto the Weighted l1 Ball", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projected gradient descent has been proved efficient in many optimization and\nmachine learning problems. The weighted $\\ell_1$ ball has been shown effective\nin sparse system identification and features selection. In this paper we\npropose three new efficient algorithms for projecting any vector of finite\nlength onto the weighted $\\ell_1$ ball. The first two algorithms have a linear\nworst case complexity. The third one has a highly competitive performances in\npractice but the worst case has a quadratic complexity. These new algorithms\nare efficient tools for machine learning methods based on projected gradient\ndescent such as compress sensing, feature selection. We illustrate this\neffectiveness by adapting an efficient compress sensing algorithm to weighted\nprojections. We demonstrate the efficiency of our new algorithms on benchmarks\nusing very large vectors. For instance, it requires only 8 ms, on an Intel I7\n3rd generation, for projecting vectors of size $10^7$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:48:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Perez", "Guillaume", ""], ["Ament", "Sebastian", ""], ["Gomes", "Carla", ""], ["Barlaud", "Michel", ""]]}, {"id": "2009.02994", "submitter": "Sebastian Neumayer", "authors": "Paul Hagemann and Sebastian Neumayer", "title": "Stabilizing Invertible Neural Networks Using Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the properties of invertible neural networks, which\nprovide a way of solving inverse problems. Our main focus lies on investigating\nand controlling the Lipschitz constants of the corresponding inverse networks.\nWithout such an control, numerical simulations are prone to errors and not much\nis gained against traditional approaches. Fortunately, our analysis indicates\nthat changing the latent distribution from a standard normal one to a Gaussian\nmixture model resolves the issue of exploding Lipschitz constants. Indeed,\nnumerical simulations confirm that this modification leads to significantly\nimproved sampling quality in multimodal applications.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:20:43 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 20:00:49 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hagemann", "Paul", ""], ["Neumayer", "Sebastian", ""]]}, {"id": "2009.03017", "submitter": "Pierre Alquier", "authors": "Pierre Alquier", "title": "Non-exponentially weighted aggregation: regret bounds for unbounded loss\n  functions", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, Proceedings of Machine Learning Research, 2021, vol. 139, pp.\n  207-218", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of online optimization with a general, possibly\nunbounded, loss function. It is well known that when the loss is bounded, the\nexponentially weighted aggregation strategy (EWA) leads to a regret in\n$\\sqrt{T}$ after $T$ steps. In this paper, we study a generalized aggregation\nstrategy, where the weights no longer depend exponentially on the losses. Our\nstrategy is based on Follow The Regularized Leader (FTRL): we minimize the\nexpected losses plus a regularizer, that is here a $\\phi$-divergence. When the\nregularizer is the Kullback-Leibler divergence, we obtain EWA as a special\ncase. Using alternative divergences enables unbounded losses, at the cost of a\nworst regret bound in some cases.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:09:08 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 11:19:03 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 03:33:25 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 04:08:10 GMT"}, {"version": "v5", "created": "Thu, 17 Jun 2021 09:27:00 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Alquier", "Pierre", ""]]}, {"id": "2009.03027", "submitter": "Alexander Malafeev", "authors": "Alexander Malafeev, Anneke Hertig-Godeschalk, David R. Schreier,\n  Jelena Skorucak, Johannes Mathis, Peter Achermann", "title": "Automatic detection of microsleep episodes with deep learning", "comments": null, "journal-ref": null, "doi": "10.3389/fnins.2021.564098", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brief fragments of sleep shorter than 15 s are defined as microsleep episodes\n(MSEs), often subjectively perceived as sleepiness. Their main characteristic\nis a slowing in frequency in the electroencephalogram (EEG), similar to stage\nN1 sleep according to standard criteria. The maintenance of wakefulness test\n(MWT) is often used in a clinical setting to assess vigilance. Scoring of the\nMWT in most sleep-wake centers is limited to classical definition of sleep\n(30-s epochs), and MSEs are mostly not considered in the absence of established\nscoring criteria defining MSEs but also because of the laborious work. We aimed\nfor automatic detection of MSEs with machine learning, i.e. with deep learning\nbased on raw EEG and EOG data as input. We analyzed MWT data of 76 patients.\nExperts visually scored wakefulness, and according to recently developed\nscoring criteria MSEs, microsleep episode candidates (MSEc), and episodes of\ndrowsiness (ED). We implemented segmentation algorithms based on convolutional\nneural networks (CNNs) and a combination of a CNN with a long-short term memory\n(LSTM) network. A LSTM network is a type of a recurrent neural network which\nhas a memory for past events and takes them into account. Data of 53 patients\nwere used for training of the classifiers, 12 for validation and 11 for\ntesting. Our algorithms showed a good performance close to human experts. The\ndetection was very good for wakefulness and MSEs and poor for MSEc and ED,\nsimilar to the low inter-expert reliability for these borderline segments. We\nprovide a proof of principle that it is feasible to reliably detect MSEs with\ndeep neuronal networks based on raw EEG and EOG data with a performance close\nto that of human experts. Code of algorithms (\nhttps://github.com/alexander-malafeev/microsleep-detection ) and data (\nhttps://zenodo.org/record/3251716 ) are available.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:38:40 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 17:40:15 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Malafeev", "Alexander", ""], ["Hertig-Godeschalk", "Anneke", ""], ["Schreier", "David R.", ""], ["Skorucak", "Jelena", ""], ["Mathis", "Johannes", ""], ["Achermann", "Peter", ""]]}, {"id": "2009.03034", "submitter": "Minyoung Kim", "authors": "Minyoung Kim and Vladimir Pavlovic", "title": "Ordinal-Content VAE: Isolating Ordinal-Valued Content Factors in Deep\n  Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep representational learning, it is often desired to isolate a\nparticular factor (termed {\\em content}) from other factors (referred to as\n{\\em style}). What constitutes the content is typically specified by users\nthrough explicit labels in the data, while all unlabeled/unknown factors are\nregarded as style. Recently, it has been shown that such content-labeled data\ncan be effectively exploited by modifying the deep latent factor models (e.g.,\nVAE) such that the style and content are well separated in the latent\nrepresentations. However, the approach assumes that the content factor is\ncategorical-valued (e.g., subject ID in face image data, or digit class in the\nMNIST dataset). In certain situations, the content is ordinal-valued, that is,\nthe values the content factor takes are {\\em ordered} rather than categorical,\nmaking content-labeled VAEs, including the latent space they infer, suboptimal.\nIn this paper, we propose a novel extension of VAE that imposes a partially\nordered set (poset) structure in the content latent space, while simultaneously\nmaking it aligned with the ordinal content values. To this end, instead of the\niid Gaussian latent prior adopted in prior approaches, we introduce a\nconditional Gaussian spacing prior model. This model admits a tractable joint\nGaussian prior, but also effectively places negligible density values on the\ncontent latent configurations that violate the poset constraint. To evaluate\nthis model, we consider two specific ordinal structured problems: estimating a\nsubject's age in a face image and elucidating the calorie amount in a food meal\nimage. We demonstrate significant improvements in content-style separation over\nprevious non-ordinal approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:59:27 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kim", "Minyoung", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "2009.03077", "submitter": "Kazuharu Harada", "authors": "Kazuharu Harada and Hironori Fujisawa", "title": "Estimation of Structural Causal Model via Sparsely Mixing Independent\n  Component Analysis", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the causal structure from observational\ndata, especially when the structure is sparse. This type of problem is usually\nformulated as an inference of a directed acyclic graph (DAG) model. The linear\nnon-Gaussian acyclic model (LiNGAM) is one of the most successful DAG models,\nand various estimation methods have been developed. However, existing methods\nare not efficient for some reasons: (i) the sparse structure is not always\nincorporated in causal order estimation, and (ii) the whole information of the\ndata is not used in parameter estimation. To address {these issues}, we propose\na new estimation method for a linear DAG model with non-Gaussian noises. The\nproposed method is based on the log-likelihood of independent component\nanalysis (ICA) with two penalty terms related to the sparsity and the\nconsistency condition. The proposed method enables us to estimate the causal\norder and the parameters simultaneously. For stable and efficient optimization,\nwe propose some devices, such as a modified natural gradient. Numerical\nexperiments show that the proposed method outperforms existing methods,\nincluding LiNGAM and NOTEARS.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:08:10 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Harada", "Kazuharu", ""], ["Fujisawa", "Hironori", ""]]}, {"id": "2009.03091", "submitter": "Lenart Treven", "authors": "Luka Kolar, Rok \\v{S}ikonja, Lenart Treven", "title": "Iterative Correction of Sensor Degradation and a Bayesian Multi-Sensor\n  Data Fusion Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for inferring ground-truth signal from multiple\ndegraded signals, affected by different amounts of sensor exposure. The\nalgorithm learns a multiplicative degradation effect by performing iterative\ncorrections of two signals solely from the ratio between them. The degradation\nfunction d should be continuous, satisfy monotonicity, and d(0) = 1. We use\nsmoothed monotonic regression method, where we easily incorporate the\naforementioned criteria to the fitting part. We include theoretical analysis\nand prove convergence to the ground-truth signal for the noiseless measurement\nmodel. Lastly, we present an approach to fuse the noisy corrected signals using\nGaussian processes. We use sparse Gaussian processes that can be utilized for a\nlarge number of measurements together with a specialized kernel that enables\nthe estimation of noise values of all sensors. The data fusion framework\nnaturally handles data gaps and provides a simple and powerful method for\nobserving the signal trends on multiple timescales(long-term and short-term\nsignal properties). The viability of correction method is evaluated on a\nsynthetic dataset with known ground-truth signal.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:24:47 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kolar", "Luka", ""], ["\u0160ikonja", "Rok", ""], ["Treven", "Lenart", ""]]}, {"id": "2009.03106", "submitter": "Jaewoo Lee", "authors": "Jaewoo Lee and Daniel Kifer", "title": "Scaling up Differentially Private Deep Learning with Fast Per-Example\n  Gradient Clipping", "comments": "To appear in PETS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on Renyi Differential Privacy has shown the feasibility of\napplying differential privacy to deep learning tasks. Despite their promise,\nhowever, differentially private deep networks often lag far behind their\nnon-private counterparts in accuracy, showing the need for more research in\nmodel architectures, optimizers, etc. One of the barriers to this expanded\nresearch is the training time -- often orders of magnitude larger than training\nnon-private networks. The reason for this slowdown is a crucial privacy-related\nstep called \"per-example gradient clipping\" whose naive implementation undoes\nthe benefits of batch training with GPUs. By analyzing the back-propagation\nequations we derive new methods for per-example gradient clipping that are\ncompatible with auto-differentiation (e.g., in PyTorch and TensorFlow) and\nprovide better GPU utilization. Our implementation in PyTorch showed\nsignificant training speed-ups (by factors of 54x - 94x for training various\nmodels with batch sizes of 128). These techniques work for a variety of\narchitectural choices including convolutional layers, recurrent networks,\nattention, residual blocks, etc.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:51:26 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Lee", "Jaewoo", ""], ["Kifer", "Daniel", ""]]}, {"id": "2009.03136", "submitter": "Matthew Ciolino", "authors": "Josh Kalin, Matthew Ciolino, David Noever, Gerry Dozier", "title": "Black Box to White Box: Discover Model Characteristics Based on\n  Strategic Probing", "comments": "4 Pages, 3 Figure, IEEE Format, Ai4i 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning, White Box Adversarial Attacks rely on knowing underlying\nknowledge about the model attributes. This works focuses on discovering to\ndistrinct pieces of model information: the underlying architecture and primary\ntraining dataset. With the process in this paper, a structured set of input\nprobes and the output of the model become the training data for a deep\nclassifier. Two subdomains in Machine Learning are explored: image based\nclassifiers and text transformers with GPT-2. With image classification, the\nfocus is on exploring commonly deployed architectures and datasets available in\npopular public libraries. Using a single transformer architecture with multiple\nlevels of parameters, text generation is explored by fine tuning off different\ndatasets. Each dataset explored in image and text are distinguishable from one\nanother. Diversity in text transformer outputs implies further research is\nneeded to successfully classify architecture attribution in text domain.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 14:44:28 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kalin", "Josh", ""], ["Ciolino", "Matthew", ""], ["Noever", "David", ""], ["Dozier", "Gerry", ""]]}, {"id": "2009.03151", "submitter": "Sida Peng", "authors": "Yang Ning and Sida Peng and Jing Tao", "title": "Doubly Robust Semiparametric Difference-in-Differences Estimators with\n  High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a doubly robust two-stage semiparametric\ndifference-in-difference estimator for estimating heterogeneous treatment\neffects with high-dimensional data. Our new estimator is robust to model\nmiss-specifications and allows for, but does not require, many more regressors\nthan observations. The first stage allows a general set of machine learning\nmethods to be used to estimate the propensity score. In the second stage, we\nderive the rates of convergence for both the parametric parameter and the\nunknown function under a partially linear specification for the outcome\nequation. We also provide bias correction procedures to allow for valid\ninference for the heterogeneous treatment effects. We evaluate the finite\nsample performance with extensive simulation studies. Additionally, a real data\nanalysis on the effect of Fair Minimum Wage Act on the unemployment rate is\nperformed as an illustration of our method. An R package for implementing the\nproposed method is available on Github.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:14:29 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ning", "Yang", ""], ["Peng", "Sida", ""], ["Tao", "Jing", ""]]}, {"id": "2009.03183", "submitter": "Vincent Grari", "authors": "Vincent Grari, Oualid El Hajouji, Sylvain Lamprier, Marcin Detyniecki", "title": "Learning Unbiased Representations via R\\'enyi Minimization", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, significant work has been done to include fairness\nconstraints in the training objective of machine learning algorithms. Many\nstate-of the-art algorithms tackle this challenge by learning a fair\nrepresentation which captures all the relevant information to predict the\noutput Y while not containing any information about a sensitive attribute S. In\nthis paper, we propose an adversarial algorithm to learn unbiased\nrepresentations via the Hirschfeld-Gebelein-Renyi (HGR) maximal correlation\ncoefficient. We leverage recent work which has been done to estimate this\ncoefficient by learning deep neural network transformations and use it as a\nminmax game to penalize the intrinsic bias in a multi dimensional latent\nrepresentation. Compared to other dependence measures, the HGR coefficient\ncaptures more information about the non-linear dependencies with the sensitive\nvariable, making the algorithm more efficient in mitigating bias in the\nrepresentation. We empirically evaluate and compare our approach and\ndemonstrate significant improvements over existing works in the field.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:48:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Grari", "Vincent", ""], ["Hajouji", "Oualid El", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2009.03192", "submitter": "Ulf-G. Mei{\\ss}ner", "authors": "Bastian Kaspschak and Ulf-G. Mei{\\ss}ner", "title": "A Neural Network Perturbation Theory Based on the Born Series", "comments": "29 pages, 4 figures, revised with more focus on neural network\n  perturbation theory, accepted for publication in Phys. Rev. Research", "journal-ref": "Phys. Rev. Research 3, 023223 (2021)", "doi": "10.1103/PhysRevResearch.3.023223", "report-no": null, "categories": "cs.LG nucl-th physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning using the eponymous deep neural networks (DNNs) has become an\nattractive approach towards various data-based problems of theoretical physics\nin the past decade. There has been a clear trend to deeper architectures\ncontaining increasingly more powerful and involved layers. Contrarily, Taylor\ncoefficients of DNNs still appear mainly in the light of interpretability\nstudies, where they are computed at most to first order. However, especially in\ntheoretical physics numerous problems benefit from accessing higher orders, as\nwell. This gap motivates a general formulation of neural network (NN) Taylor\nexpansions. Restricting our analysis to multilayer perceptrons (MLPs) and\nintroducing quantities we refer to as propagators and vertices, both depending\non the MLP's weights and biases, we establish a graph-theoretical approach.\nSimilarly to Feynman rules in quantum field theories, we can systematically\nassign diagrams containing propagators and vertices to the corresponding\npartial derivative. Examining this approach for S-wave scattering lengths of\nshallow potentials, we observe NNs to adapt their derivatives mainly to the\nleading order of the target function's Taylor expansion. To circumvent this\nproblem, we propose an iterative NN perturbation theory. During each iteration\nwe eliminate the leading order, such that the next-to-leading order can be\nfaithfully learned during the subsequent iteration. After performing two\niterations, we find that the first- and second-order Born terms are correctly\nadapted during the respective iterations. Finally, we combine both results to\nfind a proxy that acts as a machine-learned second-order Born approximation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:54:27 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 08:09:47 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kaspschak", "Bastian", ""], ["Mei\u00dfner", "Ulf-G.", ""]]}, {"id": "2009.03207", "submitter": "James Grant", "authors": "James A. Grant, David S. Leslie", "title": "Learning to Rank under Multinomial Logit Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the optimal ordering of content is an important challenge in website\ndesign. The learning to rank (LTR) framework models this problem as a\nsequential problem of selecting lists of content and observing where users\ndecide to click. Most previous work on LTR assumes that the user considers each\nitem in the list in isolation, and makes binary choices to click or not on\neach. We introduce a multinomial logit (MNL) choice model to the LTR framework,\nwhich captures the behaviour of users who consider the ordered list of items as\na whole and make a single choice among all the items and a no-click option.\nUnder the MNL model, the user favours items which are either inherently more\nattractive, or placed in a preferable position within the list. We propose\nupper confidence bound algorithms to minimise regret in two settings - where\nthe position dependent parameters are known, and unknown. We present\ntheoretical analysis leading to an $\\Omega(\\sqrt{T})$ lower bound for the\nproblem, an $\\tilde{O}(\\sqrt{T})$ upper bound on regret for the known parameter\nversion. Our analyses are based on tight new concentration results for\nGeometric random variables, and novel functional inequalities for maximum\nlikelihood estimators computed on discrete data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:15:12 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Grant", "James A.", ""], ["Leslie", "David S.", ""]]}, {"id": "2009.03228", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias and Francisco J. R. Ruiz and Sotirios\n  Nikoloutsopoulos and Alexandre Galashov", "title": "Information Theoretic Meta Learning with Gaussian Processes", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate meta learning using information theoretic concepts; namely,\nmutual information and the information bottleneck. The idea is to learn a\nstochastic representation or encoding of the task description, given by a\ntraining set, that is highly informative about predicting the validation set.\nBy making use of variational approximations to the mutual information, we\nderive a general and tractable framework for meta learning. This framework\nunifies existing gradient-based algorithms and also allows us to derive new\nalgorithms. In particular, we develop a memory-based algorithm that uses\nGaussian processes to obtain non-parametric encoding representations. We\ndemonstrate our method on a few-shot regression problem and on four few-shot\nclassification problems, obtaining competitive accuracy when compared to\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:47:30 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 13:40:54 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 12:26:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Ruiz", "Francisco J. R.", ""], ["Nikoloutsopoulos", "Sotirios", ""], ["Galashov", "Alexandre", ""]]}, {"id": "2009.03238", "submitter": "Niharika Shimona D'Souza", "authors": "Niharika Shimona D'Souza, Mary Beth Nebel, Nicholas Wymbs, Stewart H.\n  Mostofsky, Archana Venkataraman", "title": "A Joint Network Optimization Framework to Predict Clinical Severity from\n  Resting State Functional MRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel optimization framework to predict clinical severity from\nresting state fMRI (rs-fMRI) data. Our model consists of two coupled terms. The\nfirst term decomposes the correlation matrices into a sparse set of\nrepresentative subnetworks that define a network manifold. These subnetworks\nare modeled as rank-one outer-products which correspond to the elemental\npatterns of co-activation across the brain; the subnetworks are combined via\npatient-specific non-negative coefficients. The second term is a linear\nregression model that uses the patient-specific coefficients to predict a\nmeasure of clinical severity. We validate our framework on two separate\ndatasets in a ten fold cross validation setting. The first is a cohort of\nfifty-eight patients diagnosed with Autism Spectrum Disorder (ASD). The second\ndataset consists of sixty three patients from a publicly available ASD\ndatabase. Our method outperforms standard semi-supervised frameworks, which\nemploy conventional graph theoretic and statistical representation learning\ntechniques to relate the rs-fMRI correlations to behavior. In contrast, our\njoint network optimization framework exploits the structure of the rs-fMRI\ncorrelation matrices to simultaneously capture group level effects and patient\nheterogeneity. Finally, we demonstrate that our proposed framework robustly\nidentifies clinically relevant networks characteristic of ASD.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 23:43:25 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["D'Souza", "Niharika Shimona", ""], ["Nebel", "Mary Beth", ""], ["Wymbs", "Nicholas", ""], ["Mostofsky", "Stewart H.", ""], ["Venkataraman", "Archana", ""]]}, {"id": "2009.03259", "submitter": "Yumeng Xue", "authors": "Rongzheng Bian, Yumeng Xue, Liang Zhou, Jian Zhang, Baoquan Chen,\n  Daniel Weiskopf, Yunhai Wang", "title": "Implicit Multidimensional Projection of Local Subspaces", "comments": null, "journal-ref": null, "doi": "10.1109/TVCG.2020.3030368", "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a visualization method to understand the effect of\nmultidimensional projection on local subspaces, using implicit function\ndifferentiation. Here, we understand the local subspace as the multidimensional\nlocal neighborhood of data points. Existing methods focus on the projection of\nmultidimensional data points, and the neighborhood information is ignored. Our\nmethod is able to analyze the shape and directional information of the local\nsubspace to gain more insights into the global structure of the data through\nthe perception of local structures. Local subspaces are fitted by\nmultidimensional ellipses that are spanned by basis vectors. An accurate and\nefficient vector transformation method is proposed based on analytical\ndifferentiation of multidimensional projections formulated as implicit\nfunctions. The results are visualized as glyphs and analyzed using a full set\nof specifically-designed interactions supported in our efficient web-based\nvisualization tool. The usefulness of our method is demonstrated using various\nmulti- and high-dimensional benchmark datasets. Our implicit differentiation\nvector transformation is evaluated through numerical comparisons; the overall\nmethod is evaluated through exploration examples and use cases.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:27:27 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bian", "Rongzheng", ""], ["Xue", "Yumeng", ""], ["Zhou", "Liang", ""], ["Zhang", "Jian", ""], ["Chen", "Baoquan", ""], ["Weiskopf", "Daniel", ""], ["Wang", "Yunhai", ""]]}, {"id": "2009.03272", "submitter": "Vivek Subramanian", "authors": "Vivek Subramanian, Joshua Khani", "title": "Graph Convolutional Networks Reveal Neural Connections Encoding\n  Prosthetic Sensation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting stimulus features from neuronal ensembles is of great interest to\nthe development of neuroprosthetics that project sensory information directly\nto the brain via electrical stimulation. Machine learning strategies that\noptimize stimulation parameters as the subject learns to interpret the\nartificial input could improve device efficacy, increase prosthetic\nperformance, ensure stability of evoked sensations, and improve power\nconsumption by eliminating extraneous input. Recent advances extending deep\nlearning techniques to non-Euclidean graph data provide a novel approach to\ninterpreting neuronal spiking activity. For this study, we apply graph\nconvolutional networks (GCNs) to infer the underlying functional relationship\nbetween neurons that are involved in the processing of artificial sensory\ninformation. Data was collected from a freely behaving rat using a four\ninfrared (IR) sensor, ICMS-based neuroprosthesis to localize IR light sources.\nWe use GCNs to predict the stimulation frequency across four stimulating\nchannels in the prosthesis, which encode relative distance and directional\ninformation to an IR-emitting reward port. Our GCN model is able to achieve a\npeak performance of 73.5% on a modified ordinal regression performance metric\nin a multiclass classification problem consisting of 7 classes, where chance is\n14.3%. Additionally, the inferred adjacency matrix provides a adequate\nrepresentation of the underlying neural circuitry encoding the artificial\nsensation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 01:43:46 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Subramanian", "Vivek", ""], ["Khani", "Joshua", ""]]}, {"id": "2009.03288", "submitter": "Elisa Negrini", "authors": "Elisa Negrini, Giovanna Citti, Luca Capogna", "title": "System Identification Through Lipschitz Regularized Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use neural networks to learn governing equations from data.\nSpecifically we reconstruct the right-hand side of a system of ODEs $\\dot{x}(t)\n= f(t, x(t))$ directly from observed uniformly time-sampled data using a neural\nnetwork. In contrast with other neural network based approaches to this\nproblem, we add a Lipschitz regularization term to our loss function. In the\nsynthetic examples we observed empirically that this regularization results in\na smoother approximating function and better generalization properties when\ncompared with non-regularized models, both on trajectory and non-trajectory\ndata, especially in presence of noise. In contrast with sparse regression\napproaches, since neural networks are universal approximators, we don't need\nany prior knowledge on the ODE system. Since the model is applied component\nwise, it can handle systems of any dimension, making it usable for real-world\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:52:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Negrini", "Elisa", ""], ["Citti", "Giovanna", ""], ["Capogna", "Luca", ""]]}, {"id": "2009.03294", "submitter": "Tianle Cai", "authors": "Tianle Cai, Shengjie Luo, Keyulu Xu, Di He, Tie-Yan Liu, Liwei Wang", "title": "GraphNorm: A Principled Approach to Accelerating Graph Neural Network\n  Training", "comments": "ICML 2021, Code: https://github.com/lsj2408/GraphNorm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization is known to help the optimization of deep neural networks.\nCuriously, different architectures require specialized normalization methods.\nIn this paper, we study what normalization is effective for Graph Neural\nNetworks (GNNs). First, we adapt and evaluate the existing methods from other\ndomains to GNNs. Faster convergence is achieved with InstanceNorm compared to\nBatchNorm and LayerNorm. We provide an explanation by showing that InstanceNorm\nserves as a preconditioner for GNNs, but such preconditioning effect is weaker\nwith BatchNorm due to the heavy batch noise in graph datasets. Second, we show\nthat the shift operation in InstanceNorm results in an expressiveness\ndegradation of GNNs for highly regular graphs. We address this issue by\nproposing GraphNorm with a learnable shift. Empirically, GNNs with GraphNorm\nconverge faster compared to GNNs using other normalization. GraphNorm also\nimproves the generalization of GNNs, achieving better performance on graph\nclassification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:55:21 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 03:53:02 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 09:35:15 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Cai", "Tianle", ""], ["Luo", "Shengjie", ""], ["Xu", "Keyulu", ""], ["He", "Di", ""], ["Liu", "Tie-Yan", ""], ["Wang", "Liwei", ""]]}, {"id": "2009.03349", "submitter": "Jithin Jagannath", "authors": "Jithin Jagannath, Anu Jagannath, Sean Furman, Tyler Gwin", "title": "Deep Learning and Reinforcement Learning for Autonomous Unmanned Aerial\n  Systems: Roadmap for Theory to Deployment", "comments": "Preprint of Book Chapter to be published in Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Systems (UAS) are being increasingly deployed for commercial,\ncivilian, and military applications. The current UAS state-of-the-art still\ndepends on a remote human controller with robust wireless links to perform\nseveral of these applications. The lack of autonomy restricts the domains of\napplication and tasks for which a UAS can be deployed. Enabling autonomy and\nintelligence to the UAS will help overcome this hurdle and expand its use\nimproving safety and efficiency. The exponential increase in computing\nresources and the availability of large amount of data in this digital era has\nled to the resurgence of machine learning from its last winter. Therefore, in\nthis chapter, we discuss how some of the advances in machine learning,\nspecifically deep learning and reinforcement learning can be leveraged to\ndevelop next-generation autonomous UAS. We first begin motivating this chapter\nby discussing the application, challenges, and opportunities of the current UAS\nin the introductory section. We then provide an overview of some of the key\ndeep learning and reinforcement learning techniques discussed throughout this\nchapter. A key area of focus that will be essential to enable autonomy to UAS\nis computer vision. Accordingly, we discuss how deep learning approaches have\nbeen used to accomplish some of the basic tasks that contribute to providing\nUAS autonomy. Then we discuss how reinforcement learning is explored for using\nthis information to provide autonomous control and navigation for UAS. Next, we\nprovide the reader with directions to choose appropriate simulation suites and\nhardware platforms that will help to rapidly prototype novel machine learning\nbased solutions for UAS. We additionally discuss the open problems and\nchallenges pertaining to each aspect of developing autonomous UAS solutions to\nshine light on potential research areas.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:10:16 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 00:32:11 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Jagannath", "Jithin", ""], ["Jagannath", "Anu", ""], ["Furman", "Sean", ""], ["Gwin", "Tyler", ""]]}, {"id": "2009.03393", "submitter": "Stanislas Polu", "authors": "Stanislas Polu, Ilya Sutskever", "title": "Generative Language Modeling for Automated Theorem Proving", "comments": "15+5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the application of transformer-based language models to automated\ntheorem proving. This work is motivated by the possibility that a major\nlimitation of automated theorem provers compared to humans -- the generation of\noriginal mathematical terms -- might be addressable via generation from\nlanguage models. We present an automated prover and proof assistant, GPT-f, for\nthe Metamath formalization language, and analyze its performance. GPT-f found\nnew short proofs that were accepted into the main Metamath library, which is to\nour knowledge, the first time a deep-learning based system has contributed\nproofs that were adopted by a formal mathematics community.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:50:10 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Polu", "Stanislas", ""], ["Sutskever", "Ilya", ""]]}, {"id": "2009.03417", "submitter": "Kiran Tomlinson", "authors": "Kiran Tomlinson and Austin R. Benson", "title": "Learning Interpretable Feature Context Effects in Discrete Choice", "comments": "20 pages, 4 figures; updated results after bug fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outcomes of elections, product sales, and the structure of social\nconnections are all determined by the choices individuals make when presented\nwith a set of options, so understanding the factors that contribute to choice\nis crucial. Of particular interest are context effects, which occur when the\nset of available options influences a chooser's relative preferences, as they\nviolate traditional rationality assumptions yet are widespread in practice.\nHowever, identifying these effects from observed choices is challenging, often\nrequiring foreknowledge of the effect to be measured. In contrast, we provide a\nmethod for the automatic discovery of a broad class of context effects from\nobserved choice data. Our models are easier to train and more flexible than\nexisting models and also yield intuitive, interpretable, and statistically\ntestable context effects. Using our models, we identify new context effects in\nwidely used choice datasets and provide the first analysis of choice set\ncontext effects in social network growth.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 20:59:24 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 21:23:45 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Tomlinson", "Kiran", ""], ["Benson", "Austin R.", ""]]}, {"id": "2009.03455", "submitter": "Rodrigo Rivera-Castro", "authors": "Ivan Maksimov, Rodrigo Rivera-Castro and Evgeny Burnaev", "title": "Addressing Cold Start in Recommender Systems with Hierarchical Graph\n  Neural Networks", "comments": "V2 with multiple changes", "journal-ref": "IEEE Big Data 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have become an essential instrument in a wide range of\nindustries to personalize the user experience. A significant issue that has\ncaptured both researchers' and industry experts' attention is the cold start\nproblem for new items. In this work, we present a graph neural network\nrecommender system using item hierarchy graphs and a bespoke architecture to\nhandle the cold start case for items. The experimental study on multiple\ndatasets and millions of users and interactions indicates that our method\nachieves better forecasting quality than the state-of-the-art with a comparable\ncomputational time.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 23:28:40 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 21:59:06 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Maksimov", "Ivan", ""], ["Rivera-Castro", "Rodrigo", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2009.03488", "submitter": "Jintang Li", "authors": "Jintang Li, Tao Xie, Liang Chen, Fenfang Xie, Xiangnan He, Zibin Zheng", "title": "Adversarial Attack on Large Scale Graph", "comments": "Accepted by TKDE, the codes are availiable at\n  https://github.com/EdisonLeeeee/SGAttack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that graph neural networks (GNNs) are vulnerable\nagainst perturbations due to lack of robustness and can therefore be easily\nfooled. Currently, most works on attacking GNNs are mainly using gradient\ninformation to guide the attack and achieve outstanding performance. However,\nthe high complexity of time and space makes them unmanageable for large scale\ngraphs and becomes the major bottleneck that prevents the practical usage. We\nargue that the main reason is that they have to use the whole graph for\nattacks, resulting in the increasing time and space complexity as the data\nscale grows. In this work, we propose an efficient Simplified Gradient-based\nAttack (SGA) method to bridge this gap. SGA can cause the GNNs to misclassify\nspecific target nodes through a multi-stage attack framework, which needs only\na much smaller subgraph. In addition, we present a practical metric named\nDegree Assortativity Change (DAC) to measure the impacts of adversarial attacks\non graph data. We evaluate our attack method on four real-world graph networks\nby attacking several commonly used GNNs. The experimental results demonstrate\nthat SGA can achieve significant time and memory efficiency improvements while\nmaintaining competitive attack performance compared to state-of-art attack\ntechniques. Codes are available via: https://github.com/EdisonLeeeee/SGAttack.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 02:17:55 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 14:15:27 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Li", "Jintang", ""], ["Xie", "Tao", ""], ["Chen", "Liang", ""], ["Xie", "Fenfang", ""], ["He", "Xiangnan", ""], ["Zheng", "Zibin", ""]]}, {"id": "2009.03506", "submitter": "Sheng Yu", "authors": "Yucong Lin, Keming Lu, Yulin Chen, Chuan Hong, Sheng Yu", "title": "High-throughput relation extraction algorithm development associating\n  knowledge articles and electronic health records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Medical relations are the core components of medical knowledge\ngraphs that are needed for healthcare artificial intelligence. However, the\nrequirement of expert annotation by conventional algorithm development\nprocesses creates a major bottleneck for mining new relations. In this paper,\nwe present Hi-RES, a framework for high-throughput relation extraction\nalgorithm development. We also show that combining knowledge articles with\nelectronic health records (EHRs) significantly increases the classification\naccuracy. Methods: We use relation triplets obtained from structured databases\nand semistructured webpages to label sentences from target corpora as positive\ntraining samples. Two methods are also provided for creating improved negative\nsamples by combining positive samples with na\\\"ive negative samples. We propose\na common model that summarizes sentence information using large-scale\npretrained language models and multi-instance attention, which then joins with\nthe concept embeddings trained from the EHRs for relation prediction. Results:\nWe apply the Hi-RES framework to develop classification algorithms for\ndisorder-disorder relations and disorder-location relations. Millions of\nsentences are created as training data. Using pretrained language models and\nEHR-based embeddings individually provides considerable accuracy increases over\nthose of previous models. Joining them together further tremendously increases\nthe accuracy to 0.947 and 0.998 for the two sets of relations, respectively,\nwhich are 10-17 percentage points higher than those of previous models.\nConclusion: Hi-RES is an efficient framework for achieving high-throughput and\naccurate relation extraction algorithm development.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 03:48:30 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Lin", "Yucong", ""], ["Lu", "Keming", ""], ["Chen", "Yulin", ""], ["Hong", "Chuan", ""], ["Yu", "Sheng", ""]]}, {"id": "2009.03509", "submitter": "Shikun Feng", "authors": "Yunsheng Shi, Zhengjie Huang, Shikun Feng, Hui Zhong, Wenjin Wang, Yu\n  Sun", "title": "Masked Label Prediction: Unified Message Passing Model for\n  Semi-Supervised Classification", "comments": "7 pages, 3 figures and 8 tables; Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network (GNN) and label propagation algorithm (LPA) are both\nmessage passing algorithms, which have achieved superior performance in\nsemi-supervised classification. GNN performs feature propagation by a neural\nnetwork to make predictions, while LPA uses label propagation across graph\nadjacency matrix to get results. However, there is still no effective way to\ndirectly combine these two kinds of algorithms. To address this issue, we\npropose a novel Unified Message Passaging Model (UniMP) that can incorporate\nfeature and label propagation at both training and inference time. First, UniMP\nadopts a Graph Transformer network, taking feature embedding and label\nembedding as input information for propagation. Second, to train the network\nwithout overfitting in self-loop input label information, UniMP introduces a\nmasked label prediction strategy, in which some percentage of input label\ninformation are masked at random, and then predicted. UniMP conceptually\nunifies feature propagation and label propagation and is empirically powerful.\nIt obtains new state-of-the-art semi-supervised classification results in Open\nGraph Benchmark (OGB).\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 04:04:04 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 07:19:36 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 10:09:19 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 07:32:58 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 02:23:20 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Shi", "Yunsheng", ""], ["Huang", "Zhengjie", ""], ["Feng", "Shikun", ""], ["Zhong", "Hui", ""], ["Wang", "Wenjin", ""], ["Sun", "Yu", ""]]}, {"id": "2009.03510", "submitter": "Boyi Liu", "authors": "Boyi Liu, Bingjie Yan, Yize Zhou, Zhixuan Liang, Cheng-Zhong Xu", "title": "FedCM: A Real-time Contribution Measurement Method for Participants in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated Learning (FL) creates an ecosystem for multiple agents to\ncollaborate on building models with data privacy consideration. The method for\ncontribution measurement of each agent in the FL system is critical for fair\ncredits allocation but few are proposed. In this paper, we develop a real-time\ncontribution measurement method FedCM that is simple but powerful. The method\ndefines the impact of each agent, comprehensively considers the current round\nand the previous round to obtain the contribution rate of each agent with\nattention aggregation. Moreover, FedCM updates contribution every round, which\nenable it to perform in real-time. Real-time is not considered by the existing\napproaches, but it is critical for FL systems to allocate computing power,\ncommunication resources, etc. Compared to the state-of-the-art method, the\nexperimental results show that FedCM is more sensitive to data quantity and\ndata quality under the premise of real-time. Furthermore, we developed\nfederated learning open-source software based on FedCM. The software has been\napplied to identify COVID-19 based on medical images.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 04:05:10 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:03:54 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Liu", "Boyi", ""], ["Yan", "Bingjie", ""], ["Zhou", "Yize", ""], ["Liang", "Zhixuan", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "2009.03527", "submitter": "Yuanyu Wan", "authors": "Yuanyu Wan and Lijun Zhang", "title": "Approximate Multiplication of Sparse Matrices with Limited Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate matrix multiplication with limited space has received\never-increasing attention due to the emergence of large-scale applications.\nRecently, based on a popular matrix sketching algorithm---frequent directions,\nprevious work has introduced co-occuring directions (COD) to reduce the\napproximation error for this problem. Although it enjoys the space complexity\nof $O((m_x+m_y)\\ell)$ for two input matrices $X\\in\\mathbb{R}^{m_x\\times n}$ and\n$Y\\in\\mathbb{R}^{m_y\\times n}$ where $\\ell$ is the sketch size, its time\ncomplexity is $O\\left(n(m_x+m_y+\\ell)\\ell\\right)$, which is still very high for\nlarge input matrices. In this paper, we propose to reduce the time complexity\nby exploiting the sparsity of the input matrices. The key idea is to employ an\napproximate singular value decomposition (SVD) method which can utilize the\nsparsity, to reduce the number of QR decompositions required by COD. In this\nway, we develop sparse co-occuring directions, which reduces the time\ncomplexity to $\\widetilde{O}\\left((\\nnz(X)+\\nnz(Y))\\ell+n\\ell^2\\right)$ in\nexpectation while keeps the same space complexity as $O((m_x+m_y)\\ell)$, where\n$\\nnz(X)$ denotes the number of non-zero entries in $X$. Theoretical analysis\nreveals that the approximation error of our algorithm is almost the same as\nthat of COD. Furthermore, we empirically verify the efficiency and\neffectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 05:39:19 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Wan", "Yuanyu", ""], ["Zhang", "Lijun", ""]]}, {"id": "2009.03534", "submitter": "Hyungjun Kim", "authors": "Eunho Koo and Hyungjun Kim", "title": "Empirical Strategy for Stretching Probability Distribution in\n  Neural-network-based Regression", "comments": "13 pages, 4 figures, to be submitted to Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression analysis under artificial neural networks, the prediction\nperformance depends on determining the appropriate weights between layers. As\nrandomly initialized weights are updated during back-propagation using the\ngradient descent procedure under a given loss function, the loss function\nstructure can affect the performance significantly. In this study, we\nconsidered the distribution error, i.e., the inconsistency of two distributions\n(those of the predicted values and label), as the prediction error, and\nproposed weighted empirical stretching (WES) as a novel loss function to\nincrease the overlap area of the two distributions. The function depends on the\ndistribution of a given label, thus, it is applicable to any distribution\nshape. Moreover, it contains a scaling hyperparameter such that the appropriate\nparameter value maximizes the common section of the two distributions. To test\nthe function capability, we generated ideal distributed curves (unimodal,\nskewed unimodal, bimodal, and skewed bimodal) as the labels, and used the\nFourier-extracted input data from the curves under a feedforward neural\nnetwork. In general, WES outperformed loss functions in wide use, and the\nperformance was robust to the various noise levels. The improved results in\nRMSE for the extreme domain (i.e., both tail regions of the distribution) are\nexpected to be utilized for prediction of abnormal events in non-linear complex\nsystems such as natural disaster and financial crisis.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 06:08:14 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Koo", "Eunho", ""], ["Kim", "Hyungjun", ""]]}, {"id": "2009.03543", "submitter": "Alistair Shilton", "authors": "Alistair Shilton, Sunil Gupta, Santu Rana, Svetha Venkatesh", "title": "Sequential Subspace Search for Functional Bayesian Optimization\n  Incorporating Experimenter Intuition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for Bayesian functional optimisation - that is,\nfinding the function to optimise a process - guided by experimenter beliefs and\nintuitions regarding the expected characteristics (length-scale, smoothness,\ncyclicity etc.) of the optimal solution encoded into the covariance function of\na Gaussian Process. Our algorithm generates a sequence of finite-dimensional\nrandom subspaces of functional space spanned by a set of draws from the\nexperimenter's Gaussian Process. Standard Bayesian optimisation is applied on\neach subspace, and the best solution found used as a starting point (origin)\nfor the next subspace. Using the concept of effective dimensionality, we\nanalyse the convergence of our algorithm and provide a regret bound to show\nthat our algorithm converges in sub-linear time provided a finite effective\ndimension exists. We test our algorithm in simulated and real-world\nexperiments, namely blind function matching, finding the optimal\nprecipitation-strengthening function for an aluminium alloy, and learning rate\nschedule optimisation for deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 06:54:11 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Shilton", "Alistair", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2009.03586", "submitter": "Aijun Zhang", "authors": "Zebin Yang and Aijun Zhang", "title": "Hyperparameter Optimization via Sequential Uniform Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization (HPO) plays a central role in the automated\nmachine learning (AutoML). It is a challenging task as the response surfaces of\nhyperparameters are generally unknown, hence essentially a global optimization\nproblem. This paper reformulates HPO as a computer experiment and proposes a\nnovel sequential uniform design (SeqUD) strategy with three-fold advantages: a)\nthe hyperparameter space is adaptively explored with evenly spread design\npoints, without the need of expensive meta-modeling and acquisition\noptimization; b) the batch-by-batch design points are sequentially generated\nwith parallel processing support; c) a new augmented uniform design algorithm\nis developed for the efficient real-time generation of follow-up design points.\nExtensive experiments are conducted on both global optimization tasks and HPO\napplications. The numerical results show that the proposed SeqUD strategy\noutperforms benchmark HPO methods, and it can be therefore a promising and\ncompetitive alternative to existing AutoML tools.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:55:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 09:12:26 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yang", "Zebin", ""], ["Zhang", "Aijun", ""]]}, {"id": "2009.03614", "submitter": "Francisco Javier Bald\\'an", "authors": "Francisco J. Bald\\'an, Jos\\'e M. Ben\\'itez", "title": "Multivariable times series classification through an interpretable\n  representation", "comments": "26 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series classification is a task with increasing importance\ndue to the proliferation of new problems in various fields (economy, health,\nenergy, transport, crops, etc.) where a large number of information sources are\navailable. Direct extrapolation of methods that traditionally worked in\nunivariate environments cannot frequently be applied to obtain the best results\nin multivariate problems. This is mainly due to the inability of these methods\nto capture the relationships between the different variables that conform a\nmultivariate time series. The multivariate proposals published to date offer\ncompetitive results but are hard to interpret. In this paper we propose a time\nseries classification method that considers an alternative representation of\ntime series through a set of descriptive features taking into account the\nrelationships between the different variables of a multivariate time series. We\nhave applied traditional classification algorithms obtaining interpretable and\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 09:44:03 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bald\u00e1n", "Francisco J.", ""], ["Ben\u00edtez", "Jos\u00e9 M.", ""]]}, {"id": "2009.03622", "submitter": "Pablo Lanillos", "authors": "Otto van der Himst, Pablo Lanillos", "title": "Deep Active Inference for Partially Observable MDPs", "comments": "1st International Workshop on Active inference, European Conference\n  on Machine Learning (ECML/PCKDD 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-64919-7_8", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep active inference has been proposed as a scalable approach to perception\nand action that deals with large policy and state spaces. However, current\nmodels are limited to fully observable domains. In this paper, we describe a\ndeep active inference model that can learn successful policies directly from\nhigh-dimensional sensory inputs. The deep learning architecture optimizes a\nvariant of the expected free energy and encodes the continuous state\nrepresentation by means of a variational autoencoder. We show, in the OpenAI\nbenchmark, that our approach has comparable or better performance than deep\nQ-learning, a state-of-the-art deep reinforcement learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:02:40 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["van der Himst", "Otto", ""], ["Lanillos", "Pablo", ""]]}, {"id": "2009.03632", "submitter": "Chris Dongjoo Kim", "authors": "Chris Dongjoo Kim, Jinseo Jeong, and Gunhee Kim", "title": "Imbalanced Continual Learning with Partitioning Reservoir Sampling", "comments": "Published to ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning from a sequential stream of data is a crucial challenge\nfor machine learning research. Most studies have been conducted on this topic\nunder the single-label classification setting along with an assumption of\nbalanced label distribution. This work expands this research horizon towards\nmulti-label classification. In doing so, we identify unanticipated adversity\ninnately existent in many multi-label datasets, the long-tailed distribution.\nWe jointly address the two independently solved problems, Catastropic\nForgetting and the long-tailed label distribution by first empirically showing\na new challenge of destructive forgetting of the minority concepts on the tail.\nThen, we curate two benchmark datasets, COCOseq and NUS-WIDEseq, that allow the\nstudy of both intra- and inter-task imbalances. Lastly, we propose a new\nsampling strategy for replay-based approach named Partitioning Reservoir\nSampling (PRS), which allows the model to maintain a balanced knowledge of both\nhead and tail classes. We publicly release the dataset and the code in our\nproject page.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:28:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Kim", "Chris Dongjoo", ""], ["Jeong", "Jinseo", ""], ["Kim", "Gunhee", ""]]}, {"id": "2009.03651", "submitter": "Sasho Nedelkoski", "authors": "Sasho Nedelkoski, Mihail Bogojeski, Odej Kao", "title": "Learning more expressive joint distributions in multimodal variational\n  methods", "comments": "12 pages, Accepted and presented at LOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data often are formed of multiple modalities, which jointly describe the\nobserved phenomena. Modeling the joint distribution of multimodal data requires\nlarger expressive power to capture high-level concepts and provide better data\nrepresentations. However, multimodal generative models based on variational\ninference are limited due to the lack of flexibility of the approximate\nposterior, which is obtained by searching within a known parametric family of\ndistributions. We introduce a method that improves the representational\ncapacity of multimodal variational methods using normalizing flows. It\napproximates the joint posterior with a simple parametric distribution and\nsubsequently transforms into a more complex one. Through several experiments,\nwe demonstrate that the model improves on state-of-the-art multimodal methods\nbased on variational inference on various computer vision tasks such as\ncolorization, edge and mask detection, and weakly supervised learning. We also\nshow that learning more powerful approximate joint distributions improves the\nquality of the generated samples. The code of our model is publicly available\nat https://github.com/SashoNedelkoski/BPFDMVM.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 11:45:27 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nedelkoski", "Sasho", ""], ["Bogojeski", "Mihail", ""], ["Kao", "Odej", ""]]}, {"id": "2009.03661", "submitter": "Rodrigo Rivera-Castro", "authors": "Rodrigo Rivera-Castro, Aleksandr Pletnev, Polina Pilyugina, Grecia\n  Diaz, Ivan Nazarov, Wanyi Zhu and Evgeny Burnaev", "title": "Topology-based Clusterwise Regression for User Segmentation and Demand\n  Forecasting", "comments": null, "journal-ref": "2019 IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA)", "doi": "10.1109/DSAA.2019.00048", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis (TDA) is a recent approach to analyze data sets\nfrom the perspective of their topological structure. Its use for time series\ndata has been limited. In this work, a system developed for a leading provider\nof cloud computing combining both user segmentation and demand forecasting is\npresented. It consists of a TDA-based clustering method for time series\ninspired by a popular managerial framework for customer segmentation and\nextended to the case of clusterwise regression using matrix factorization\nmethods to forecast demand. Increasing customer loyalty and producing accurate\nforecasts remain active topics of discussion both for researchers and managers.\nUsing a public and a novel proprietary data set of commercial data, this\nresearch shows that the proposed system enables analysts to both cluster their\nuser base and plan demand at a granular level with significantly higher\naccuracy than a state of the art baseline. This work thus seeks to introduce\nTDA-based clustering of time series and clusterwise regression with matrix\nfactorization methods as viable tools for the practitioner.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:10:10 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Rivera-Castro", "Rodrigo", ""], ["Pletnev", "Aleksandr", ""], ["Pilyugina", "Polina", ""], ["Diaz", "Grecia", ""], ["Nazarov", "Ivan", ""], ["Zhu", "Wanyi", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2009.03714", "submitter": "Zhao Zhang", "authors": "Yan Zhang, Zhao Zhang, Yang Wang, Zheng Zhang, Li Zhang, Shuicheng\n  Yan, Meng Wang", "title": "Dual-constrained Deep Semi-Supervised Coupled Factorization Network with\n  Enriched Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization is usually powerful for learning the\n\"shallow\" parts-based representation, but it clearly fails to discover deep\nhierarchical information within both the basis and representation spaces. In\nthis paper, we technically propose a new enriched prior based Dual-constrained\nDeep Semi-Supervised Coupled Factorization Network, called DS2CF-Net, for\nlearning the hierarchical coupled representations. To ex-tract hidden deep\nfeatures, DS2CF-Net is modeled as a deep-structure and geometrical\nstructure-constrained neural network. Specifically, DS2CF-Net designs a deep\ncoupled factorization architecture using multi-layers of linear\ntransformations, which coupled updates the bases and new representations in\neach layer. To improve the discriminating ability of learned deep\nrepresentations and deep coefficients, our network clearly considers enriching\nthe supervised prior by the joint deep coefficients-regularized label\nprediction, and incorporates enriched prior information as additional label and\nstructure constraints. The label constraint can enable the samples of the same\nlabel to have the same coordinate in the new feature space, while the structure\nconstraint forces the coefficient matrices in each layer to be block-diagonal\nso that the enhanced prior using the self-expressive label propagation are more\naccurate. Our network also integrates the adaptive dual-graph learning to\nretain the local manifold structures of both the data manifold and feature\nmanifold by minimizing the reconstruction errors in each layer. Extensive\nexperiments on several real databases demonstrate that our DS2CF-Net can obtain\nstate-of-the-art performance for representation learning and clustering.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:10:21 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zhang", "Yan", ""], ["Zhang", "Zhao", ""], ["Wang", "Yang", ""], ["Zhang", "Zheng", ""], ["Zhang", "Li", ""], ["Yan", "Shuicheng", ""], ["Wang", "Meng", ""]]}, {"id": "2009.03717", "submitter": "Zhiqiang Zhong", "authors": "Zhiqiang Zhong, Cheng-Te Li, and Jun Pang", "title": "Hierarchical Message-Passing Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have become a promising approach to machine\nlearning with graphs. Since existing GNN models are based on flat\nmessage-passing mechanisms, two limitations need to be tackled. One is costly\nin encoding global information on the graph topology. The other is failing to\nmodel meso- and macro-level semantics hidden in the graph, such as the\nknowledge of institutes and research areas in an academic collaboration\nnetwork. To deal with these two issues, we propose a novel Hierarchical\nMessage-Passing Graph Neural Networks framework. The main idea is to generate a\nhierarchical structure that re-organises all nodes in a graph into multi-level\nclusters, along with intra- and inter-level edge connections. The derived\nhierarchy not only creates shortcuts connecting far-away nodes so that global\ninformation can be efficiently accessed via message passing but also\nincorporates meso- and macro-level semantics into the learning of node\nembedding. We present the first model to implement this hierarchical\nmessage-passing mechanism, termed Hierarchical Community-aware Graph Neural\nNetwork (HC-GNN), based on hierarchical communities detected from the graph.\nExperiments conducted on eight datasets under transductive, inductive, and\nfew-shot settings exhibit that HC-GNN can outperform state-of-the-art GNN\nmodels in network analysis tasks, including node classification, link\nprediction, and community detection.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:11:07 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zhong", "Zhiqiang", ""], ["Li", "Cheng-Te", ""], ["Pang", "Jun", ""]]}, {"id": "2009.03727", "submitter": "Takumi Ishiyama", "authors": "Takumi Ishiyama, Takuya Suzuki, Hayato Yamana", "title": "Highly Accurate CNN Inference Using Approximate Activation Functions\n  over Homomorphic Encryption", "comments": "Accepted at 7th International Workshop on Privacy and Security of Big\n  Data in conjunction with 2020 IEEE International Conference on Big Data (IEEE\n  BigData 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, cloud-based machine learning as a service (MLaaS) has\nattracted considerable attention. However, when handling sensitive data, such\nas financial and medical data, a privacy issue emerges, because the cloud\nserver can access clients' raw data. A common method of handling sensitive data\nin the cloud uses homomorphic encryption, which allows computation over\nencrypted data without decryption. Previous research usually adopted a\nlow-degree polynomial mapping function, such as the square function, for data\nclassification. However, this technique results in low classification accuracy.\nIn this study, we seek to improve the classification accuracy for inference\nprocessing in a convolutional neural network (CNN) while using homomorphic\nencryption. We adopt an activation function that approximates Google's Swish\nactivation function while using a fourth-order polynomial. We also adopt batch\nnormalization to normalize the inputs for the Swish function to fit the input\nrange to minimize the error. We implemented CNN inference labeling over\nhomomorphic encryption using the Microsoft's Simple Encrypted Arithmetic\nLibrary for the Cheon-Kim-Kim-Song (CKKS) scheme. The experimental evaluations\nconfirmed classification accuracies of 99.22% and 80.48% for MNIST and\nCIFAR-10, respectively, which entails 0.04% and 4.11% improvements,\nrespectively, over previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:20:59 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 15:09:48 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Ishiyama", "Takumi", ""], ["Suzuki", "Takuya", ""], ["Yamana", "Hayato", ""]]}, {"id": "2009.03732", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Moun\\^im A. El Yacoubi, Mehdi Ammi", "title": "Enhancing the Interpretability of Deep Models in Heathcare Through\n  Attention: Application to Glucose Forecasting for Diabetic People", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of deep learning in healthcare is hindered by their \"black box\"\nnature. In this paper, we explore the RETAIN architecture for the task of\nglusose forecasting for diabetic people. By using a two-level attention\nmechanism, the recurrent-neural-network-based RETAIN model is interpretable. We\nevaluate the RETAIN model on the type-2 IDIAB and the type-1 OhioT1DM datasets\nby comparing its statistical and clinical performances against two deep models\nand three models based on decision trees. We show that the RETAIN model offers\na very good compromise between accuracy and interpretability, being almost as\naccurate as the LSTM and FCN models while remaining interpretable. We show the\nusefulness of its interpretable nature by analyzing the contribution of each\nvariable to the final prediction. It revealed that signal values older than one\nhour are not used by the RETAIN model for the 30-minutes ahead of time\nprediction of glucose. Also, we show how the RETAIN model changes its behavior\nupon the arrival of an event such as carbohydrate intakes or insulin infusions.\nIn particular, it showed that the patient's state before the event is\nparticularily important for the prediction. Overall the RETAIN model, thanks to\nits interpretability, seems to be a very promissing model for regression or\nclassification tasks in healthcare.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:27:52 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["De Bois", "Maxime", ""], ["Yacoubi", "Moun\u00eem A. El", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.03771", "submitter": "Lanfranco Zanzi", "authors": "Lanfranco Zanzi, Vincenzo Sciancalepore, Andres Garcia-Saavedra, Hans\n  D. Schotten, Xavier Costa-Perez", "title": "LACO: A Latency-Driven Network Slicing Orchestration in Beyond-5G\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TWC.2020.3027963", "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Slicing is expected to become a game changer in the upcoming 5G\nnetworks and beyond, enlarging the telecom business ecosystem through\nstill-unexplored vertical industry profits. This implies that heterogeneous\nservice level agreements (SLAs) must be guaranteed per slice given the\nmultitude of predefined requirements. In this paper, we pioneer a novel radio\nslicing orchestration solution that simultaneously provides-latency and\nthroughput guarantees in a multi-tenancy environment. Leveraging on a solid\nmathematical framework, we exploit the exploration-vs-exploitation paradigm by\nmeans of a multi-armed-bandit-based(MAB) orchestrator, LACO, that makes\nadaptive resource slicing decisions with no prior knowledge on the traffic\ndemand or channel quality statistics. As opposed to traditional MAB methods\nthat are blind to the underlying system, LACO relies on system structure\ninformation to expedite decisions. After a preliminary simulations campaign\nempirically proving the validness of our solution, we provide a robust\nimplementation of LACO using off-the-shelf equipment to fully emulate realistic\nnetwork conditions:near-optimal results within affordable computational time\nare measured when LACO is in place.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:50:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zanzi", "Lanfranco", ""], ["Sciancalepore", "Vincenzo", ""], ["Garcia-Saavedra", "Andres", ""], ["Schotten", "Hans D.", ""], ["Costa-Perez", "Xavier", ""]]}, {"id": "2009.03779", "submitter": "Edward Raff", "authors": "Edward Raff, Richard Zak, Gary Lopez Munoz, William Fleming, Hyrum S.\n  Anderson, Bobby Filar, Charles Nicholas, James Holt", "title": "Automatic Yara Rule Generation Using Biclustering", "comments": "to be published in the 13th ACM Workshop on Artificial Intelligence\n  and Security (AISec)", "journal-ref": null, "doi": "10.1145/3411508.3421372", "report-no": null, "categories": "cs.CR cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yara rules are a ubiquitous tool among cybersecurity practitioners and\nanalysts. Developing high-quality Yara rules to detect a malware family of\ninterest can be labor- and time-intensive, even for expert users. Few tools\nexist and relatively little work has been done on how to automate the\ngeneration of Yara rules for specific families. In this paper, we leverage\nlarge n-grams ($n \\geq 8$) combined with a new biclustering algorithm to\nconstruct simple Yara rules more effectively than currently available software.\nOur method, AutoYara, is fast, allowing for deployment on low-resource\nequipment for teams that deploy to remote networks. Our results demonstrate\nthat AutoYara can help reduce analyst workload by producing rules with useful\ntrue-positive rates while maintaining low false-positive rates, sometimes\nmatching or even outperforming human analysts. In addition, real-world testing\nby malware analysts indicates AutoYara could reduce analyst time spent\nconstructing Yara rules by 44-86%, allowing them to spend their time on the\nmore advanced malware that current tools can't handle. Code will be made\navailable at https://github.com/NeuromorphicComputationResearchProgram .\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 02:02:43 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Raff", "Edward", ""], ["Zak", "Richard", ""], ["Munoz", "Gary Lopez", ""], ["Fleming", "William", ""], ["Anderson", "Hyrum S.", ""], ["Filar", "Bobby", ""], ["Nicholas", "Charles", ""], ["Holt", "James", ""]]}, {"id": "2009.03782", "submitter": "Sara Hahner", "authors": "Sara Hahner, Rodrigo Iza-Teran, Jochen Garcke", "title": "Analysis and Prediction of Deforming 3D Shapes using Oriented Bounding\n  Boxes and LSTM Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sequences of complex 3D shapes in time we present a general approach to\ndetect patterns for their analysis and to predict the deformation by making use\nof structural components of the complex shape. We incorporate long short-term\nmemory (LSTM) layers into an autoencoder to create low dimensional\nrepresentations that allow the detection of patterns in the data and\nadditionally detect the temporal dynamics in the deformation behavior. This is\nachieved with two decoders, one for reconstruction and one for prediction of\nfuture time steps of the sequence. In a preprocessing step the components of\nthe studied object are converted to oriented bounding boxes which capture the\nimpact of plastic deformation and allow reducing the dimensionality of the data\ndescribing the structure. The architecture is tested on the results of 196 car\ncrash simulations of a model with 133 different components, where material\nproperties are varied. In the latent representation we can detect patterns in\nthe plastic deformation for the different components. The predicted bounding\nboxes give an estimate of the final simulation result and their quality is\nimproved in comparison to different baselines.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 08:07:32 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Hahner", "Sara", ""], ["Iza-Teran", "Rodrigo", ""], ["Garcke", "Jochen", ""]]}, {"id": "2009.03796", "submitter": "Benjamin Nachman", "authors": "Sascha Diefenbacher, Engin Eren, Gregor Kasieczka, Anatolii Korol,\n  Benjamin Nachman, and David Shih", "title": "DCTRGAN: Improving the Precision of Generative Models with Reweighting", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": "10.1088/1748-0221/15/11/P11004", "report-no": null, "categories": "hep-ph hep-ex physics.data-an physics.ins-det stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances in deep learning have led to more widely used and\nprecise neural network-based generative models such as Generative Adversarial\nNetworks (GANs). We introduce a post-hoc correction to deep generative models\nto further improve their fidelity, based on the Deep neural networks using the\nClassification for Tuning and Reweighting (DCTR) protocol. The correction takes\nthe form of a reweighting function that can be applied to generated examples\nwhen making predictions from the simulation. We illustrate this approach using\nGANs trained on standard multimodal probability densities as well as\ncalorimeter simulations from high energy physics. We show that the weighted GAN\nexamples significantly improve the accuracy of the generated samples without a\nlarge loss in statistical power. This approach could be applied to any\ngenerative model and is a promising refinement method for high energy physics\napplications and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 18:00:27 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Diefenbacher", "Sascha", ""], ["Eren", "Engin", ""], ["Kasieczka", "Gregor", ""], ["Korol", "Anatolii", ""], ["Nachman", "Benjamin", ""], ["Shih", "David", ""]]}, {"id": "2009.03816", "submitter": "Qing Ye", "authors": "Qing Ye, Yuxuan Han, Yanan sun and JIancheng Lv", "title": "PSO-PS: Parameter Synchronization with Particle Swarm Optimization for\n  Distributed Training of Deep Neural Networks", "comments": "7pages", "journal-ref": "IJCNN2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter updating is an important stage in parallelism-based distributed\ndeep learning. Synchronous methods are widely used in distributed training the\nDeep Neural Networks (DNNs). To reduce the communication and synchronization\noverhead of synchronous methods, decreasing the synchronization frequency\n(e.g., every $n$ mini-batches) is a straightforward approach. However, it often\nsuffers from poor convergence. In this paper, we propose a new algorithm of\nintegrating Particle Swarm Optimization (PSO) into the distributed training\nprocess of DNNs to automatically compute new parameters. In the proposed\nalgorithm, a computing work is encoded by a particle, the weights of DNNs and\nthe training loss are modeled by the particle attributes. At each\nsynchronization stage, the weights are updated by PSO from the sub weights\ngathered from all workers, instead of averaging the weights or the gradients.\nTo verify the performance of the proposed algorithm, the experiments are\nperformed on two commonly used image classification benchmarks: MNIST and\nCIFAR10, and compared with the peer competitors at multiple different\nsynchronization configurations. The experimental results demonstrate the\ncompetitiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 05:18:32 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ye", "Qing", ""], ["Han", "Yuxuan", ""], ["sun", "Yanan", ""], ["Lv", "JIancheng", ""]]}, {"id": "2009.03825", "submitter": "Neil Yorke-Smith", "authors": "T\\'omas Thorbjarnarson and Neil Yorke-Smith", "title": "On Training Neural Networks with Mixed Integer Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown potential in using Mixed Integer Programming (MIP)\nsolvers to optimize certain aspects of neural networks (NN). However little\nresearch has gone into training NNs with solvers. State of the art methods to\ntrain NNs are typically gradient-based and require significant data,\ncomputation on GPUs and extensive hyper-parameter tuning. In contrast, training\nwith MIP solvers should not require GPUs or hyper-parameter tuning but can\nlikely not handle large amounts of data. This work builds on recent advances\nthat train binarized NNs using MIP solvers. We go beyond current work by\nformulating new MIP models to increase the amount of data that can be used and\nto train non-binary integer-valued networks. Our results show that comparable\nresults to using gradient descent can be achieved when minimal data is\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:45:44 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:40:58 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 12:58:36 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Thorbjarnarson", "T\u00f3mas", ""], ["Yorke-Smith", "Neil", ""]]}, {"id": "2009.03831", "submitter": "Joon Kwon", "authors": "Joon Kwon", "title": "Refined approachability algorithms and application to regret\n  minimization with global costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blackwell's approachability is a framework where two players, the Decision\nMaker and the Environment, play a repeated game with vector-valued payoffs. The\ngoal of the Decision Maker is to make the average payoff converge to a given\nset called the target. When this is indeed possible, simple algorithms which\nguarantee the convergence are known. This abstract tool was successfully used\nfor the construction of optimal strategies in various repeated games, but also\nfound several applications in online learning. By extending an approach\nproposed by (Abernethy et al., 2011), we construct and analyze a class of\nFollow the Regularized Leader algorithms (FTRL) for Blackwell's approachability\nwhich are able to minimize not only the Euclidean distance to the target set\n(as it is often the case in the context of Blackwell's approachability) but a\nwide range of distance-like quantities. This flexibility enables us to apply\nthese algorithms to closely minimize the quantity of interest in various online\nlearning problems. In particular, for regret minimization with $\\ell_p$ global\ncosts, we obtain the first bounds with explicit dependence in $p$ and the\ndimension $d$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:54:08 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 14:47:33 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 14:03:13 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kwon", "Joon", ""]]}, {"id": "2009.03836", "submitter": "Mohammed Sharafath Abdul Hameed", "authors": "Mohammed Sharafath Abdul Hameed, Andreas Schwung", "title": "Reinforcement Learning on Job Shop Scheduling Problems Using Graph\n  Networks", "comments": "8 pages, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel approach for job shop scheduling problems using\ndeep reinforcement learning. To account for the complexity of production\nenvironment, we employ graph neural networks to model the various relations\nwithin production environments. Furthermore, we cast the JSSP as a distributed\noptimization problem in which learning agents are individually assigned to\nresources which allows for higher flexibility with respect to changing\nproduction environments. The proposed distributed RL agents used to optimize\nproduction schedules for single resources are running together with a\nco-simulation framework of the production environment to obtain the required\namount of data. The approach is applied to a multi-robot environment and a\ncomplex production scheduling benchmark environment. The initial results\nunderline the applicability and performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:05:04 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Hameed", "Mohammed Sharafath Abdul", ""], ["Schwung", "Andreas", ""]]}, {"id": "2009.03851", "submitter": "Iwona Hawryluk", "authors": "Iwona Hawryluk, Swapnil Mishra, Seth Flaxman, Samir Bhatt and Thomas\n  A. Mellan", "title": "Referenced Thermodynamic Integration for Bayesian Model Selection:\n  Application to COVID-19 Model Selection", "comments": "27 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection is a fundamental part of the applied Bayesian statistical\nmethodology. Metrics such as the Akaike Information Criterion are commonly used\nin practice to select models but do not incorporate the uncertainty of the\nmodels' parameters and can give misleading choices. One approach that uses the\nfull posterior distribution is to compute the ratio of two models' normalising\nconstants, known as the Bayes factor. Often in realistic problems, this\ninvolves the integration of analytically intractable, high-dimensional\ndistributions, and therefore requires the use of stochastic methods such as\nthermodynamic integration (TI). In this paper we apply a variation of the TI\nmethod, referred to as referenced TI, which computes a single model's\nnormalising constant in an efficient way by using a judiciously chosen\nreference density. The advantages of the approach and theoretical\nconsiderations are set out, along with explicit pedagogical 1 and 2D examples.\nBenchmarking is presented with comparable methods and we find favourable\nconvergence performance. The approach is shown to be useful in practice when\napplied to a real problem - to perform model selection for a semi-mechanistic\nhierarchical Bayesian model of COVID-19 transmission in South Korea involving\nthe integration of a 200D density.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:32:06 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 17:26:52 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 22:21:50 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Hawryluk", "Iwona", ""], ["Mishra", "Swapnil", ""], ["Flaxman", "Seth", ""], ["Bhatt", "Samir", ""], ["Mellan", "Thomas A.", ""]]}, {"id": "2009.03859", "submitter": "Ghazal Fazelnia Ph.D.", "authors": "Greg Benton, Ghazal Fazelnia, Alice Wang, Ben Carterette", "title": "Trajectory Based Podcast Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Podcast recommendation is a growing area of research that presents new\nchallenges and opportunities. Individuals interact with podcasts in a way that\nis distinct from most other media; and primary to our concerns is distinct from\nmusic consumption. We show that successful and consistent recommendations can\nbe made by viewing users as moving through the podcast library sequentially.\nRecommendations for future podcasts are then made using the trajectory taken\nfrom their sequential behavior. Our experiments provide evidence that user\nbehavior is confined to local trends, and that listening patterns tend to be\nfound over short sequences of similar types of shows. Ultimately, our approach\ngives a450%increase in effectiveness over a collaborative filtering baseline.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:49:12 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Benton", "Greg", ""], ["Fazelnia", "Ghazal", ""], ["Wang", "Alice", ""], ["Carterette", "Ben", ""]]}, {"id": "2009.03873", "submitter": "Joshua Cardosi", "authors": "Joshua D. Cardosi, Herman Shen, Jonathan I. Groner, Megan Armstrong,\n  Henry Xiang", "title": "Machine Intelligence for Outcome Predictions of Trauma Patients During\n  Emergency Department Care", "comments": "23 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trauma mortality results from a multitude of non-linear dependent risk\nfactors including patient demographics, injury characteristics, medical care\nprovided, and characteristics of medical facilities; yet traditional approach\nattempted to capture these relationships using rigid regression models. We\nhypothesized that a transfer learning based machine learning algorithm could\ndeeply understand a trauma patient's condition and accurately identify\nindividuals at high risk for mortality without relying on restrictive\nregression model criteria. Anonymous patient visit data were obtained from\nyears 2007-2014 of the National Trauma Data Bank. Patients with incomplete\nvitals, unknown outcome, or missing demographics data were excluded. All\npatient visits occurred in U.S. hospitals, and of the 2,007,485 encounters that\nwere retrospectively examined, 8,198 resulted in mortality (0.4%). The machine\nintelligence model was evaluated on its sensitivity, specificity, positive and\nnegative predictive value, and Matthews Correlation Coefficient. Our model\nachieved similar performance in age-specific comparison models and generalized\nwell when applied to all ages simultaneously. While testing for confounding\nfactors, we discovered that excluding fall-related injuries boosted performance\nfor adult trauma patients; however, it reduced performance for children. The\nmachine intelligence model described here demonstrates similar performance to\ncontemporary machine intelligence models without requiring restrictive\nregression model criteria or extensive medical expertise.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:26:34 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 21:50:57 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Cardosi", "Joshua D.", ""], ["Shen", "Herman", ""], ["Groner", "Jonathan I.", ""], ["Armstrong", "Megan", ""], ["Xiang", "Henry", ""]]}, {"id": "2009.03887", "submitter": "Albert Gural", "authors": "Albert Gural, Phillip Nadeau, Mehul Tikekar, Boris Murmann", "title": "Low-Rank Training of Deep Neural Networks for Emerging Memory Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of neural networks for solving difficult decision tasks\nhas incentivized incorporating smart decision making \"at the edge.\" However,\nthis work has traditionally focused on neural network inference, rather than\ntraining, due to memory and compute limitations, especially in emerging\nnon-volatile memory systems, where writes are energetically costly and reduce\nlifespan. Yet, the ability to train at the edge is becoming increasingly\nimportant as it enables real-time adaptability to device drift and\nenvironmental variation, user customization, and federated learning across\ndevices. In this work, we address two key challenges for training on edge\ndevices with non-volatile memory: low write density and low auxiliary memory.\nWe present a low-rank training scheme that addresses these challenges while\nmaintaining computational efficiency. We then demonstrate the technique on a\nrepresentative convolutional neural network across several adaptation problems,\nwhere it out-performs standard SGD both in accuracy and in number of weight\nwrites.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:59:56 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 03:06:18 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gural", "Albert", ""], ["Nadeau", "Phillip", ""], ["Tikekar", "Mehul", ""], ["Murmann", "Boris", ""]]}, {"id": "2009.03892", "submitter": "Yihao Hu", "authors": "Yihao Hu, Tong Zhao, Zhiliang Xu, Lizhen Lin", "title": "Neural Time-Dependent Partial Differential Equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations (PDEs) play a crucial role in studying a vast\nnumber of problems in science and engineering. Numerically solving nonlinear\nand/or high-dimensional PDEs is often a challenging task. Inspired by the\ntraditional finite difference and finite elements methods and emerging\nadvancements in machine learning, we propose a sequence deep learning framework\ncalled Neural-PDE, which allows to automatically learn governing rules of any\ntime-dependent PDE system from existing data by using a bidirectional LSTM\nencoder, and predict the next n time steps data. One critical feature of our\nproposed framework is that the Neural-PDE is able to simultaneously learn and\nsimulate the multiscale variables.We test the Neural-PDE by a range of examples\nfrom one-dimensional PDEs to a high-dimensional and nonlinear complex fluids\nmodel. The results show that the Neural-PDE is capable of learning the initial\nconditions, boundary conditions and differential operators without the\nknowledge of the specific form of a PDE system.In our experiments the\nNeural-PDE can efficiently extract the dynamics within 20 epochs training, and\nproduces accurate predictions. Furthermore, unlike the traditional machine\nlearning approaches in learning PDE such as CNN and MLP which require vast\nparameters for model precision, Neural-PDE shares parameters across all time\nsteps, thus considerably reduces the computational complexity and leads to a\nfast learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:46:00 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hu", "Yihao", ""], ["Zhao", "Tong", ""], ["Xu", "Zhiliang", ""], ["Lin", "Lizhen", ""]]}, {"id": "2009.03937", "submitter": "Alessandro Morandini", "authors": "Andrea De Simone, Alessandro Morandini", "title": "Nonparametric Density Estimation from Markov Chains", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "SISSA 22/2020/FISI", "categories": "stat.ME cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new nonparametric density estimator inspired by Markov Chains,\nand generalizing the well-known Kernel Density Estimator (KDE). Our estimator\npresents several benefits with respect to the usual ones and can be used\nstraightforwardly as a foundation in all density-based algorithms. We prove the\nconsistency of our estimator and we find it typically outperforms KDE in\nsituations of large sample size and high dimensionality. We also employ our\ndensity estimator to build a local outlier detector, showing very promising\nresults when applied to some realistic datasets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 18:33:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["De Simone", "Andrea", ""], ["Morandini", "Alessandro", ""]]}, {"id": "2009.03966", "submitter": "Sayanti Mukherjee", "authors": "Zhiyuan Wei and Sayanti Mukherjee", "title": "Health-behaviors associated with the growing risk of adolescent suicide\n  attempts: A data-driven cross-sectional study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: Identify and examine the associations between health behaviors and\nincreased risk of adolescent suicide attempts, while controlling for\nsocioeconomic and demographic differences. Design: A data-driven analysis using\ncross-sectional data. Setting: Communities in the state of Montana from 1999 to\n2017. Subjects: Selected 22,447 adolescents of whom 1,631 adolescents attempted\nsuicide at least once. Measures: Overall 29 variables (predictors) accounting\nfor psychological behaviors, illegal substances consumption, daily activities\nat schools and demographic backgrounds, were considered. Analysis: A library of\nmachine learning algorithms along with the traditionally-used logistic\nregression were used to model and predict suicide attempt risk. Model\nperformances (goodness-of-fit and predictive accuracy) were measured using\naccuracy, precision, recall and F-score metrics. Results: The non-parametric\nBayesian tree ensemble model outperformed all other models, with 80.0% accuracy\nin goodness-of-fit (F-score:0.802) and 78.2% in predictive accuracy\n(F-score:0.785). Key health-behaviors identified include: being sad/hopeless,\nfollowed by safety concerns at school, physical fighting, inhalant usage,\nillegal drugs consumption at school, current cigarette usage, and having first\nsex at an early age (below 15 years of age). Additionally, the minority groups\n(American Indian/Alaska Natives, Hispanics/Latinos), and females are also found\nto be highly vulnerable to attempting suicides. Conclusion: Significant\ncontribution of this work is understanding the key health-behaviors and health\ndisparities that lead to higher frequency of suicide attempts among\nadolescents, while accounting for the non-linearity and complex interactions\namong the outcome and the exposure variables.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:29:18 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Wei", "Zhiyuan", ""], ["Mukherjee", "Sayanti", ""]]}, {"id": "2009.03969", "submitter": "Chao Gao", "authors": "Fengshuo Zhang and Chao Gao", "title": "Convergence Rates of Empirical Bayes Posterior Distributions: A\n  Variational Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence rates of empirical Bayes posterior distributions for\nnonparametric and high-dimensional inference. We show that as long as the\nhyperparameter set is discrete, the empirical Bayes posterior distribution\ninduced by the maximum marginal likelihood estimator can be regarded as a\nvariational approximation to a hierarchical Bayes posterior distribution. This\nconnection between empirical Bayes and variational Bayes allows us to leverage\nthe recent results in the variational Bayes literature, and directly obtains\nthe convergence rates of empirical Bayes posterior distributions from a\nvariational perspective. For a more general hyperparameter set that is not\nnecessarily discrete, we introduce a new technique called \"prior decomposition\"\nto deal with prior distributions that can be written as convex combinations of\nprobability measures whose supports are low-dimensional subspaces. This leads\nto generalized versions of the classical \"prior mass and testing\" conditions\nfor the convergence rates of empirical Bayes. Our theory is applied to a number\nof statistical estimation problems including nonparametric density estimation\nand sparse linear regression.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:35:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zhang", "Fengshuo", ""], ["Gao", "Chao", ""]]}, {"id": "2009.03979", "submitter": "Hengrui Luo", "authors": "Leland Wilkinson, Hengrui Luo", "title": "A Distance-preserving Matrix Sketch", "comments": "46 pages, 11 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing very large matrices involves many formidable problems. Various\npopular solutions to these problems involve sampling, clustering, projection,\nor feature selection to reduce the size and complexity of the original task. An\nimportant aspect of these methods is how to preserve relative distances between\npoints in the higher-dimensional space after reducing rows and columns to fit\nin a lower dimensional space. This aspect is important because conclusions\nbased on faulty visual reasoning can be harmful. Judging dissimilar points as\nsimilar or similar points as dissimilar on the basis of a visualization can\nlead to false conclusions. To ameliorate this bias and to make visualizations\nof very large datasets feasible, we introduce two new algorithms that\nrespectively select a subset of rows and columns of a rectangular matrix. This\nselection is designed to preserve relative distances as closely as possible. We\ncompare our matrix sketch to more traditional alternatives on a variety of\nartificial and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 20:15:14 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:51:23 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wilkinson", "Leland", ""], ["Luo", "Hengrui", ""]]}, {"id": "2009.03986", "submitter": "Jianji Wang", "authors": "Jianji Wang, Qi Liu, Shupei Zhang, Nanning Zheng, Fei-Yue Wang", "title": "Conditional Uncorrelation and Efficient Non-approximate Subset Selection\n  in Sparse Regression", "comments": "17 pages, 0 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $m$ $d$-dimensional responsors and $n$ $d$-dimensional predictors,\nsparse regression finds at most $k$ predictors for each responsor for linear\napproximation, $1\\leq k \\leq d-1$. The key problem in sparse regression is\nsubset selection, which usually suffers from high computational cost. Recent\nyears, many improved approximate methods of subset selection have been\npublished. However, less attention has been paid on the non-approximate method\nof subset selection, which is very necessary for many questions in data\nanalysis. Here we consider sparse regression from the view of correlation, and\npropose the formula of conditional uncorrelation. Then an efficient\nnon-approximate method of subset selection is proposed in which we do not need\nto calculate any coefficients in regression equation for candidate predictors.\nBy the proposed method, the computational complexity is reduced from\n$O(\\frac{1}{6}{k^3}+mk^2+mkd)$ to $O(\\frac{1}{6}{k^3}+\\frac{1}{2}mk^2)$ for\neach candidate subset in sparse regression. Because the dimension $d$ is\ngenerally the number of observations or experiments and large enough, the\nproposed method can greatly improve the efficiency of non-approximate subset\nselection.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 20:32:26 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 10:00:18 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wang", "Jianji", ""], ["Liu", "Qi", ""], ["Zhang", "Shupei", ""], ["Zheng", "Nanning", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "2009.03998", "submitter": "Tai-Xiang Jiang", "authors": "Guangjing Song, Michael K. Ng, Tai-Xiang Jiang", "title": "Tangent Space Based Alternating Projections for Nonnegative Low Rank\n  Matrix Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new alternating projection method to compute\nnonnegative low rank matrix approximation for nonnegative matrices. In the\nnonnegative low rank matrix approximation method, the projection onto the\nmanifold of fixed rank matrices can be expensive as the singular value\ndecomposition is required. We propose to use the tangent space of the point in\nthe manifold to approximate the projection onto the manifold in order to reduce\nthe computational cost. We show that the sequence generated by the alternating\nprojections onto the tangent spaces of the fixed rank matrices manifold and the\nnonnegative matrix manifold, converge linearly to a point in the intersection\nof the two manifolds where the convergent point is sufficiently close to\noptimal solutions. This convergence result based inexact projection onto the\nmanifold is new and is not studied in the literature. Numerical examples in\ndata clustering, pattern recognition and hyperspectral data analysis are given\nto demonstrate that the performance of the proposed method is better than that\nof nonnegative matrix factorization methods in terms of computational time and\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 05:25:16 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Song", "Guangjing", ""], ["Ng", "Michael K.", ""], ["Jiang", "Tai-Xiang", ""]]}, {"id": "2009.04003", "submitter": "Toryn Schafer", "authors": "Toryn L. J. Schafer, Christopher K. Wikle and Mevin B. Hooten", "title": "Bayesian Inverse Reinforcement Learning for Collective Animal Movement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based methods allow for defining simple rules that generate complex\ngroup behaviors. The governing rules of such models are typically set a priori\nand parameters are tuned from observed behavior trajectories. Instead of making\nsimplifying assumptions across all anticipated scenarios, inverse reinforcement\nlearning provides inference on the short-term (local) rules governing long term\nbehavior policies by using properties of a Markov decision process. We use the\ncomputationally efficient linearly-solvable Markov decision process to learn\nthe local rules governing collective movement for a simulation of the self\npropelled-particle (SPP) model and a data application for a captive guppy\npopulation. The estimation of the behavioral decision costs is done in a\nBayesian framework with basis function smoothing. We recover the true costs in\nthe SPP simulation and find the guppies value collective movement more than\ntargeted movement toward shelter.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 21:33:52 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Schafer", "Toryn L. J.", ""], ["Wikle", "Christopher K.", ""], ["Hooten", "Mevin B.", ""]]}, {"id": "2009.04013", "submitter": "Wanrong Zhang", "authors": "Wanrong Zhang, Olga Ohrimenko, Rachel Cummings", "title": "Attribute Privacy: Framework and Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring the privacy of training data is a growing concern since many machine\nlearning models are trained on confidential and potentially sensitive data.\nMuch attention has been devoted to methods for protecting individual privacy\nduring analyses of large datasets. However in many settings, global properties\nof the dataset may also be sensitive (e.g., mortality rate in a hospital rather\nthan presence of a particular patient in the dataset). In this work, we depart\nfrom individual privacy to initiate the study of attribute privacy, where a\ndata owner is concerned about revealing sensitive properties of a whole dataset\nduring analysis. We propose definitions to capture \\emph{attribute privacy} in\ntwo relevant cases where global attributes may need to be protected: (1)\nproperties of a specific dataset and (2) parameters of the underlying\ndistribution from which dataset is sampled. We also provide two efficient\nmechanisms and one inefficient mechanism that satisfy attribute privacy for\nthese settings. We base our results on a novel use of the Pufferfish framework\nto account for correlations across attributes in the data, thus addressing \"the\nchallenging problem of developing Pufferfish instantiations and algorithms for\ngeneral aggregate secrets\" that was left open by \\cite{kifer2014pufferfish}.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 22:38:57 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 23:23:04 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zhang", "Wanrong", ""], ["Ohrimenko", "Olga", ""], ["Cummings", "Rachel", ""]]}, {"id": "2009.04053", "submitter": "Junxiang Wang", "authors": "Junxiang Wang, Zheng Chai, Yue Cheng, Liang Zhao", "title": "Tunable Subnetwork Splitting for Model-parallelism of Neural Network\n  Training", "comments": "ICML 2020 Workshop on \"Beyond first-order methods in ML systems\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating minimization methods have recently been proposed as alternatives\nto the gradient descent for deep neural network optimization. Alternating\nminimization methods can typically decompose a deep neural network into\nlayerwise subproblems, which can then be optimized in parallel. Despite the\nsignificant parallelism, alternating minimization methods are rarely explored\nin training deep neural networks because of the severe accuracy degradation. In\nthis paper, we analyze the reason and propose to achieve a compelling trade-off\nbetween parallelism and accuracy by a reformulation called Tunable Subnetwork\nSplitting Method (TSSM), which can tune the decomposition granularity of deep\nneural networks. Two methods gradient splitting Alternating Direction Method of\nMultipliers (gsADMM) and gradient splitting Alternating Minimization (gsAM) are\nproposed to solve the TSSM formulation. Experiments on five benchmark datasets\nshow that our proposed TSSM can achieve significant speedup without observable\nloss of training accuracy. The code has been released at\nhttps://github.com/xianggebenben/TSSM.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 01:05:12 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 21:18:59 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Wang", "Junxiang", ""], ["Chai", "Zheng", ""], ["Cheng", "Yue", ""], ["Zhao", "Liang", ""]]}, {"id": "2009.04075", "submitter": "Markos Georgopoulos", "authors": "Markos Georgopoulos, Grigorios Chrysos, Maja Pantic, Yannis Panagakis", "title": "Multilinear Latent Conditioning for Generating Unseen Attribute\n  Combinations", "comments": "published at International Conference on Machine Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models rely on their inductive bias to facilitate\ngeneralization, especially for problems with high dimensional data, like\nimages. However, empirical studies have shown that variational autoencoders\n(VAE) and generative adversarial networks (GAN) lack the generalization ability\nthat occurs naturally in human perception. For example, humans can visualize a\nwoman smiling after only seeing a smiling man. On the contrary, the standard\nconditional VAE (cVAE) is unable to generate unseen attribute combinations. To\nthis end, we extend cVAE by introducing a multilinear latent conditioning\nframework that captures the multiplicative interactions between the attributes.\nWe implement two variants of our model and demonstrate their efficacy on MNIST,\nFashion-MNIST and CelebA. Altogether, we design a novel conditioning framework\nthat can be used with any architecture to synthesize unseen attribute\ncombinations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:23:13 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Georgopoulos", "Markos", ""], ["Chrysos", "Grigorios", ""], ["Pantic", "Maja", ""], ["Panagakis", "Yannis", ""]]}, {"id": "2009.04076", "submitter": "Omid Bazgir", "authors": "Omid Bazgir, Souparno Ghosh, Ranadip Pal", "title": "Investigation of REFINED CNN ensemble learning for anti-cancer drug\n  sensitivity prediction", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/btab336", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anti-cancer drug sensitivity prediction using deep learning models for\nindividual cell line is a significant challenge in personalized medicine.\nREFINED (REpresentation of Features as Images with NEighborhood Dependencies)\nCNN (Convolutional Neural Network) based models have shown promising results in\ndrug sensitivity prediction. The primary idea behind REFINED CNN is\nrepresenting high dimensional vectors as compact images with spatial\ncorrelations that can benefit from convolutional neural network architectures.\nHowever, the mapping from a vector to a compact 2D image is not unique due to\nvariations in considered distance measures and neighborhoods. In this article,\nwe consider predictions based on ensembles built from such mappings that can\nimprove upon the best single REFINED CNN model prediction. Results illustrated\nusing NCI60 and NCIALMANAC databases shows that the ensemble approaches can\nprovide significant performance improvement as compared to individual models.\nWe further illustrate that a single mapping created from the amalgamation of\nthe different mappings can provide performance similar to stacking ensemble but\nwith significantly lower computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:27:29 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 04:15:28 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bazgir", "Omid", ""], ["Ghosh", "Souparno", ""], ["Pal", "Ranadip", ""]]}, {"id": "2009.04126", "submitter": "Se Jung Kwon", "authors": "Dongsoo Lee, Se Jung Kwon, Byeongwook Kim, Yongkweon Jeon, Baeseong\n  Park and Jeongin Yun", "title": "FleXOR: Trainable Fractional Quantization", "comments": "Neurips 2020 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization based on the binary codes is gaining attention because each\nquantized bit can be directly utilized for computations without dequantization\nusing look-up tables. Previous attempts, however, only allow for integer\nnumbers of quantization bits, which ends up restricting the search space for\ncompression ratio and accuracy. In this paper, we propose an encryption\nalgorithm/architecture to compress quantized weights so as to achieve\nfractional numbers of bits per weight. Decryption during inference is\nimplemented by digital XOR-gate networks added into the neural network model\nwhile XOR gates are described by utilizing $\\tanh(x)$ for backward propagation\nto enable gradient calculations. We perform experiments using MNIST, CIFAR-10,\nand ImageNet to show that inserting XOR gates learns quantization/encrypted bit\ndecisions through training and obtains high accuracy even for fractional sub\n1-bit weights. As a result, our proposed method yields smaller size and higher\nmodel accuracy compared to binary neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 06:26:27 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 06:54:36 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lee", "Dongsoo", ""], ["Kwon", "Se Jung", ""], ["Kim", "Byeongwook", ""], ["Jeon", "Yongkweon", ""], ["Park", "Baeseong", ""], ["Yun", "Jeongin", ""]]}, {"id": "2009.04131", "submitter": "Linyi Li", "authors": "Linyi Li, Xiangyu Qi, Tao Xie, Bo Li", "title": "SoK: Certified Robustness for Deep Neural Networks", "comments": "14 pages for the main text; code available at\n  https://github.com/AI-secure/VeriGauge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Great advancement in deep neural networks (DNNs) has led to state-of-the-art\nperformance on a wide range of tasks. However, recent studies have shown that\nDNNs are vulnerable to adversarial attacks, which have brought great concerns\nwhen deploying these models to safety-critical applications such as autonomous\ndriving. Different defense approaches have been proposed against adversarial\nattacks, including: 1) empirical defenses, which can be adaptively attacked\nagain without providing robustness certification; and 2) certifiably robust\napproaches, which consist of robustness verification providing the lower bound\nof robust accuracy against any attacks under certain conditions and\ncorresponding robust training approaches. In this paper, we focus on these\ncertifiably robust approaches and provide the first work to perform large-scale\nsystematic analysis of different robustness verification and training\napproaches. In particular, we 1) provide a taxonomy for the robustness\nverification and training approaches, as well as discuss the detailed\nmethodologies for representative algorithms, 2) reveal the fundamental\nconnections among these approaches, 3) discuss current research progresses,\ntheoretical barriers, main challenges, and several promising future directions\nfor certified defenses for DNNs, and 4) provide an open-sourced unified\nplatform to evaluate 20+ representative verification and corresponding robust\ntraining approaches on a wide range of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 07:00:55 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 05:04:49 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Li", "Linyi", ""], ["Qi", "Xiangyu", ""], ["Xie", "Tao", ""], ["Li", "Bo", ""]]}, {"id": "2009.04142", "submitter": "Ofir Lindenbaum", "authors": "Ofir Lindenbaum, Amir Sagiv, Gal Mishne, Ronen Talmon", "title": "Kernel-based parameter estimation of dynamical systems with unknown\n  observation functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A low-dimensional dynamical system is observed in an experiment as a\nhigh-dimensional signal; for example, a video of a chaotic pendulums system.\nAssuming that we know the dynamical model up to some unknown parameters, can we\nestimate the underlying system's parameters by measuring its time-evolution\nonly once? The key information for performing this estimation lies in the\ntemporal inter-dependencies between the signal and the model. We propose a\nkernel-based score to compare these dependencies. Our score generalizes a\nmaximum likelihood estimator for a linear model to a general nonlinear setting\nin an unknown feature space. We estimate the system's underlying parameters by\nmaximizing the proposed score. We demonstrate the accuracy and efficiency of\nthe method using two chaotic dynamical systems - the double pendulum and the\nLorenz '63 model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 07:29:11 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 11:07:09 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 09:44:55 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lindenbaum", "Ofir", ""], ["Sagiv", "Amir", ""], ["Mishne", "Gal", ""], ["Talmon", "Ronen", ""]]}, {"id": "2009.04197", "submitter": "Jian Hu", "authors": "Jian Hu, Seth Austin Harding, Haibin Wu, Siyue Hu, Shih-wei Liao", "title": "QR-MIX: Distributional Value Function Factorisation for Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "There are some experimental errors and experimental unfairness in\n  this paper that will seriously affect the later studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cooperative Multi-Agent Reinforcement Learning (MARL) and under the\nsetting of Centralized Training with Decentralized Execution (CTDE), agents\nobserve and interact with their environment locally and independently. With\nlocal observation and random sampling, the randomness in rewards and\nobservations leads to randomness in long-term returns. Existing methods such as\nValue Decomposition Network (VDN) and QMIX estimate the value of long-term\nreturns as a scalar that does not contain the information of randomness. Our\nproposed model QR-MIX introduces quantile regression, modeling joint\nstate-action values as a distribution, combining QMIX with Implicit Quantile\nNetwork (IQN). However, the monotonicity in QMIX limits the expression of joint\nstate-action value distribution and may lead to incorrect estimation results in\nnon-monotonic cases. Therefore, we proposed a flexible loss function to\napproximate the monotonicity found in QMIX. Our model is not only more tolerant\nof the randomness of returns, but also more tolerant of the randomness of\nmonotonic constraints. The experimental results demonstrate that QR-MIX\noutperforms the previous state-of-the-art method QMIX in the StarCraft\nMulti-Agent Challenge (SMAC) environment.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:28:44 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 06:19:53 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 13:19:11 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 08:10:48 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 12:37:48 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Hu", "Jian", ""], ["Harding", "Seth Austin", ""], ["Wu", "Haibin", ""], ["Hu", "Siyue", ""], ["Liao", "Shih-wei", ""]]}, {"id": "2009.04239", "submitter": "Jon Cockayne", "authors": "Jon Cockayne and Andrew B. Duncan", "title": "Probabilistic Gradients for Fast Calibration of Differential Equation\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration of large-scale differential equation models to observational or\nexperimental data is a widespread challenge throughout applied sciences and\nengineering. A crucial bottleneck in state-of-the art calibration methods is\nthe calculation of local sensitivities, i.e. derivatives of the loss function\nwith respect to the estimated parameters, which often necessitates several\nnumerical solves of the underlying system of partial or ordinary differential\nequations. In this paper we present a new probabilistic approach to computing\nlocal sensitivities. The proposed method has several advantages over classical\nmethods. Firstly, it operates within a constrained computational budget and\nprovides a probabilistic quantification of uncertainty incurred in the\nsensitivities from this constraint. Secondly, information from previous\nsensitivity estimates can be recycled in subsequent computations, reducing the\noverall computational effort for iterative gradient-based calibration methods.\nThe methodology presented is applied to two challenging test problems and\ncompared against classical methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:35:09 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 08:08:35 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Cockayne", "Jon", ""], ["Duncan", "Andrew B.", ""]]}, {"id": "2009.04266", "submitter": "Thibault Sejourne", "authors": "Thibault S\\'ejourn\\'e, Fran\\c{c}ois-Xavier Vialard and Gabriel Peyr\\'e", "title": "The Unbalanced Gromov Wasserstein Distance: Conic Formulation and\n  Relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing metric measure spaces (i.e. a metric space endowed with\naprobability distribution) is at the heart of many machine learning problems.\nThe most popular distance between such metric measure spaces is\ntheGromov-Wasserstein (GW) distance, which is the solution of a quadratic\nassignment problem. The GW distance is however limited to the comparison of\nmetric measure spaces endowed with a probability distribution.To alleviate this\nissue, we introduce two Unbalanced Gromov-Wasserstein formulations: a distance\nand a more tractable upper-bounding relaxation.They both allow the comparison\nof metric spaces equipped with arbitrary positive measures up to isometries.\nThe first formulation is a positive and definite divergence based on a\nrelaxation of the mass conservation constraint using a novel type of\nquadratically-homogeneous divergence. This divergence works hand in hand with\nthe entropic regularization approach which is popular to solve large scale\noptimal transport problems. We show that the underlying non-convex optimization\nproblem can be efficiently tackled using a highly parallelizable and\nGPU-friendly iterative scheme. The second formulation is a distance between\nmm-spaces up to isometries based on a conic lifting. Lastly, we provide\nnumerical experiments onsynthetic examples and domain adaptation data with a\nPositive-Unlabeled learning task to highlight the salient features of the\nunbalanced divergence and its potential applications in ML.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 12:38:14 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 06:42:41 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["S\u00e9journ\u00e9", "Thibault", ""], ["Vialard", "Fran\u00e7ois-Xavier", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "2009.04278", "submitter": "Victor Manuel Martinez Alvarez", "authors": "Victor M. Martinez Alvarez and Rare\\c{s} Ro\\c{s}ca and Cristian G.\n  F\\u{a}lcu\\c{t}escu", "title": "DyNODE: Neural Ordinary Differential Equations for Dynamics Modeling in\n  Continuous Control", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach (DyNODE) that captures the underlying dynamics of\na system by incorporating control in a neural ordinary differential equation\nframework. We conduct a systematic evaluation and comparison of our method and\nstandard neural network architectures for dynamics modeling. Our results\nindicate that a simple DyNODE architecture when combined with an actor-critic\nreinforcement learning (RL) algorithm that uses model predictions to improve\nthe critic's target values, outperforms canonical neural networks, both in\nsample efficiency and predictive performance across a diverse range of\ncontinuous tasks that are frequently used to benchmark RL algorithms. This\napproach provides a new avenue for the development of models that are more\nsuited to learn the evolution of dynamical systems, particularly useful in the\ncontext of model-based reinforcement learning. To assist related work, we have\nmade code available at https://github.com/vmartinezalvarez/DyNODE .\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 12:56:58 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Alvarez", "Victor M. Martinez", ""], ["Ro\u015fca", "Rare\u015f", ""], ["F\u0103lcu\u0163escu", "Cristian G.", ""]]}, {"id": "2009.04292", "submitter": "Chien-Liang Liu", "authors": "Bin Xiao, Chien-Liang Liu, Wen-Hoar Hsaio", "title": "Proxy Network for Few Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of a few examples for each class to train a predictive model that can\nbe generalized to novel classes is a crucial and valuable research direction in\nartificial intelligence. This work addresses this problem by proposing a\nfew-shot learning (FSL) algorithm called proxy network under the architecture\nof meta-learning. Metric-learning based approaches assume that the data points\nwithin the same class should be close, whereas the data points in the different\nclasses should be separated as far as possible in the embedding space. We\nconclude that the success of metric-learning based approaches lies in the data\nembedding, the representative of each class, and the distance metric. In this\nwork, we propose a simple but effective end-to-end model that directly learns\nproxies for class representative and distance metric from data simultaneously.\nWe conduct experiments on CUB and mini-ImageNet datasets in 1-shot-5-way and\n5-shot-5-way scenarios, and the experimental results demonstrate the\nsuperiority of our proposed method over state-of-the-art methods. Besides, we\nprovide a detailed analysis of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 13:28:07 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Xiao", "Bin", ""], ["Liu", "Chien-Liang", ""], ["Hsaio", "Wen-Hoar", ""]]}, {"id": "2009.04318", "submitter": "Julien Brajard", "authors": "Julien Brajard, Alberto Carrassi, Marc Bocquet and Laurent Bertino", "title": "Combining data assimilation and machine learning to infer unresolved\n  scale parametrisation", "comments": "16 pages, 3 figures, in press in Philosophical transactions A", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning (ML) has been proposed to devise\ndata-driven parametrisations of unresolved processes in dynamical numerical\nmodels. In most cases, the ML training leverages high-resolution simulations to\nprovide a dense, noiseless target state. Our goal is to go beyond the use of\nhigh-resolution simulations and train ML-based parametrisation using direct\ndata, in the realistic scenario of noisy and sparse observations.\n  The algorithm proposed in this work is a two-step process. First, data\nassimilation (DA) techniques are applied to estimate the full state of the\nsystem from a truncated model. The unresolved part of the truncated model is\nviewed as a model error in the DA system. In a second step, ML is used to\nemulate the unresolved part, a predictor of model error given the state of the\nsystem. Finally, the ML-based parametrisation model is added to the physical\ncore truncated model to produce a hybrid model.\n  The DA component of the proposed method relies on an ensemble Kalman filter\nwhile the ML parametrisation is represented by a neural network. The approach\nis applied to the two-scale Lorenz model and to MAOOAM, a reduced-order coupled\nocean-atmosphere model. We show that in both cases the hybrid model yields\nforecasts with better skill than the truncated model. Moreover, the attractor\nof the system is significantly better represented by the hybrid model than by\nthe truncated model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:12:11 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 11:13:51 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Brajard", "Julien", ""], ["Carrassi", "Alberto", ""], ["Bocquet", "Marc", ""], ["Bertino", "Laurent", ""]]}, {"id": "2009.04323", "submitter": "Quan Wang", "authors": "Quan Wang, Ignacio Lopez Moreno, Mert Saglam, Kevin Wilson, Alan\n  Chiao, Renjie Liu, Yanzhang He, Wei Li, Jason Pelecanos, Marily Nika,\n  Alexander Gruenstein", "title": "VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device\n  Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce VoiceFilter-Lite, a single-channel source separation model that\nruns on the device to preserve only the speech signals from a target user, as\npart of a streaming speech recognition system. Delivering such a model presents\nnumerous challenges: It should improve the performance when the input signal\nconsists of overlapped speech, and must not hurt the speech recognition\nperformance under all other acoustic conditions. Besides, this model must be\ntiny, fast, and perform inference in a streaming fashion, in order to have\nminimal impact on CPU, memory, battery and latency. We propose novel techniques\nto meet these multi-faceted requirements, including using a new asymmetric\nloss, and adopting adaptive runtime suppression strength. We also show that\nsuch a model can be quantized as a 8-bit integer model and run in realtime.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:26:56 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Wang", "Quan", ""], ["Moreno", "Ignacio Lopez", ""], ["Saglam", "Mert", ""], ["Wilson", "Kevin", ""], ["Chiao", "Alan", ""], ["Liu", "Renjie", ""], ["He", "Yanzhang", ""], ["Li", "Wei", ""], ["Pelecanos", "Jason", ""], ["Nika", "Marily", ""], ["Gruenstein", "Alexander", ""]]}, {"id": "2009.04324", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes, Loucas Pillaud-Vivien, Francis Bach, Alessandro Rudi", "title": "Overcoming the curse of dimensionality with Laplacian regularization in\n  semi-supervised learning", "comments": "40 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As annotations of data can be scarce in large-scale practical problems,\nleveraging unlabelled examples is one of the most important aspects of machine\nlearning. This is the aim of semi-supervised learning. To benefit from the\naccess to unlabelled data, it is natural to diffuse smoothly knowledge of\nlabelled data to unlabelled one. This induces to the use of Laplacian\nregularization. Yet, current implementations of Laplacian regularization suffer\nfrom several drawbacks, notably the well-known curse of dimensionality. In this\npaper, we provide a statistical analysis to overcome those issues, and unveil a\nlarge body of spectral filtering methods that exhibit desirable behaviors. They\nare implemented through (reproducing) kernel methods, for which we provide\nrealistic computational guidelines in order to make our method usable with\nlarge amounts of data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:28:54 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 18:05:58 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 09:26:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Cabannes", "Vivien", ""], ["Pillaud-Vivien", "Loucas", ""], ["Bach", "Francis", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2009.04372", "submitter": "Hakan G\\\"okcesu", "authors": "Kaan Gokcesu, Hakan Gokcesu", "title": "A Generalized Online Algorithm for Translation and Scale Invariant\n  Prediction with Expert Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim to create a completely online algorithmic framework for\nprediction with expert advice that is translation-free and scale-free of the\nexpert losses. Our goal is to create a generalized algorithm that is suitable\nfor use in a wide variety of applications. For this purpose, we study the\nexpected regret of our algorithm against a generic competition class in the\nsequential prediction by expert advice problem, where the expected regret\nmeasures the difference between the losses of our prediction algorithm and the\nlosses of the 'best' expert selection strategy in the competition. We design\nour algorithm using the universal prediction perspective to compete against a\nspecified class of expert selection strategies, which is not necessarily a\nfixed expert selection. The class of expert selection strategies that we want\nto compete against is purely determined by the specific application at hand and\nis left generic, which makes our generalized algorithm suitable for use in many\ndifferent problems. We show that no preliminary knowledge about the loss\nsequence is required by our algorithm and its performance bounds, which are\nsecond order, expressed in terms of sums of squared losses. Our regret bounds\nare stable under arbitrary scalings and translations of the losses.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:45:28 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Gokcesu", "Kaan", ""], ["Gokcesu", "Hakan", ""]]}, {"id": "2009.04374", "submitter": "Ulrich Paquet", "authors": "Nenad Toma\\v{s}ev, Ulrich Paquet, Demis Hassabis and Vladimir Kramnik", "title": "Assessing Game Balance with AlphaZero: Exploring Alternative Rule Sets\n  in Chess", "comments": "98 pages. Game AZ-8 on page 39 (Stalemate=win variant) replaced from\n  version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is non-trivial to design engaging and balanced sets of game rules. Modern\nchess has evolved over centuries, but without a similar recourse to history,\nthe consequences of rule changes to game dynamics are difficult to predict.\nAlphaZero provides an alternative in silico means of game balance assessment.\nIt is a system that can learn near-optimal strategies for any rule set from\nscratch, without any human supervision, by continually learning from its own\nexperience. In this study we use AlphaZero to creatively explore and design new\nchess variants. There is growing interest in chess variants like Fischer Random\nChess, because of classical chess's voluminous opening theory, the high\npercentage of draws in professional play, and the non-negligible number of\ngames that end while both players are still in their home preparation. We\ncompare nine other variants that involve atomic changes to the rules of chess.\nThe changes allow for novel strategic and tactical patterns to emerge, while\nkeeping the games close to the original. By learning near-optimal strategies\nfor each variant with AlphaZero, we determine what games between strong human\nplayers might look like if these variants were adopted. Qualitatively, several\nvariants are very dynamic. An analytic comparison show that pieces are valued\ndifferently between variants, and that some variants are more decisive than\nclassical chess. Our findings demonstrate the rich possibilities that lie\nbeyond the rules of modern chess.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:49:14 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 16:11:34 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Toma\u0161ev", "Nenad", ""], ["Paquet", "Ulrich", ""], ["Hassabis", "Demis", ""], ["Kramnik", "Vladimir", ""]]}, {"id": "2009.04381", "submitter": "Mark Collier", "authors": "Mark Collier, Efi Kokiopoulou, Andrea Gesmundo, Jesse Berent", "title": "Routing Networks with Co-training for Continual Learning", "comments": "Presented at ICML Workshop on Continual Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core challenge with continual learning is catastrophic forgetting, the\nphenomenon that when neural networks are trained on a sequence of tasks they\nrapidly forget previously learned tasks. It has been observed that catastrophic\nforgetting is most severe when tasks are dissimilar to each other. We propose\nthe use of sparse routing networks for continual learning. For each input,\nthese network architectures activate a different path through a network of\nexperts. Routing networks have been shown to learn to route similar tasks to\noverlapping sets of experts and dissimilar tasks to disjoint sets of experts.\nIn the continual learning context this behaviour is desirable as it minimizes\ninterference between dissimilar tasks while allowing positive transfer between\nrelated tasks. In practice, we find it is necessary to develop a new training\nmethod for routing networks, which we call co-training which avoids poorly\ninitialized experts when new tasks are presented. When combined with a small\nepisodic memory replay buffer, sparse routing networks with co-training\noutperform densely connected networks on the MNIST-Permutations and\nMNIST-Rotations benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:58:51 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Collier", "Mark", ""], ["Kokiopoulou", "Efi", ""], ["Gesmundo", "Andrea", ""], ["Berent", "Jesse", ""]]}, {"id": "2009.04382", "submitter": "Rui Gao", "authors": "Rui Gao", "title": "Finite-Sample Guarantees for Wasserstein Distributionally Robust\n  Optimization: Breaking the Curse of Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein distributionally robust optimization (DRO) aims to find robust\nand generalizable solutions by hedging against data perturbations in\nWasserstein distance. Despite its recent empirical success in operations\nresearch and machine learning, existing performance guarantees for generic loss\nfunctions are either overly conservative due to the curse of dimensionality, or\nplausible only in large sample asymptotics. In this paper, we develop a\nnon-asymptotic framework for analyzing the out-of-sample performance for\nWasserstein robust learning and the generalization bound for its related\nLipschitz and gradient regularization problems. To the best of our knowledge,\nthis gives the first finite-sample guarantee for generic Wasserstein DRO\nproblems without suffering from the curse of dimensionality. Our results\nhighlight the bias-variation trade-off intrinsic in the Wasserstein DRO, which\nbalances between the empirical mean of the loss and the variation of the loss,\nmeasured by the Lipschitz norm or the gradient norm of the loss. Our analysis\nis based on two novel methodological developments that are of independent\ninterest: 1) a new concentration inequality controlling the decay rate of large\ndeviation probabilities by the variation of the loss and, 2) a localized\nRademacher complexity theory based on the variation of the loss.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:02:57 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 11:01:13 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Gao", "Rui", ""]]}, {"id": "2009.04383", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Mukund Telukunta and Venkata Sriram Siddhardh Nadendla", "title": "On the Identification of Fair Auditors to Evaluate Recommender Systems\n  based on a Novel Non-Comparative Fairness Notion", "comments": "10 pages, Accepted to FAccTRec-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-support systems are information systems that offer support to\npeople's decisions in various applications such as judiciary, real-estate and\nbanking sectors. Lately, these support systems have been found to be\ndiscriminatory in the context of many practical deployments. In an attempt to\nevaluate and mitigate these biases, algorithmic fairness literature has been\nnurtured using notions of comparative justice, which relies primarily on\ncomparing two/more individuals or groups within the society that is supported\nby such systems. However, such a fairness notion is not very useful in the\nidentification of fair auditors who are hired to evaluate latent biases within\ndecision-support systems. As a solution, we introduce a paradigm shift in\nalgorithmic fairness via proposing a new fairness notion based on the principle\nof non-comparative justice. Assuming that the auditor makes fairness\nevaluations based on some (potentially unknown) desired properties of the\ndecision-support system, the proposed fairness notion compares the system's\noutcome with that of the auditor's desired outcome. We show that the proposed\nfairness notion also provides guarantees in terms of comparative fairness\nnotions by proving that any system can be deemed fair from the perspective of\ncomparative fairness (e.g. individual fairness and statistical parity) if it is\nnon-comparatively fair with respect to an auditor who has been deemed fair with\nrespect to the same fairness notions. We also show that the converse holds true\nin the context of individual fairness. A brief discussion is also presented\nregarding how our fairness notion can be used to identify fair and reliable\nauditors, and how we can use them to quantify biases in decision-support\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:04:41 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Telukunta", "Mukund", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2009.04404", "submitter": "Gilles Vandewiele", "authors": "Gilles Vandewiele, Bram Steenwinckel, Pieter Bonte, Michael Weyns,\n  Heiko Paulheim, Petar Ristoski, Filip De Turck, Femke Ongenae", "title": "Walk Extraction Strategies for Node Embeddings with RDF2Vec in Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As KGs are symbolic constructs, specialized techniques have to be applied in\norder to make them compatible with data mining techniques. RDF2Vec is an\nunsupervised technique that can create task-agnostic numerical representations\nof the nodes in a KG by extending successful language modelling techniques. The\noriginal work proposed the Weisfeiler-Lehman (WL) kernel to improve the quality\nof the representations. However, in this work, we show both formally and\nempirically that the WL kernel does little to improve walk embeddings in the\ncontext of a single KG. As an alternative to the WL kernel, we propose five\ndifferent strategies to extract information complementary to basic random\nwalks. We compare these walks on several benchmark datasets to show that the\n\\emph{n-gram} strategy performs best on average on node classification tasks\nand that tuning the walk strategy can result in improved predictive\nperformances.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:26:31 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Vandewiele", "Gilles", ""], ["Steenwinckel", "Bram", ""], ["Bonte", "Pieter", ""], ["Weyns", "Michael", ""], ["Paulheim", "Heiko", ""], ["Ristoski", "Petar", ""], ["De Turck", "Filip", ""], ["Ongenae", "Femke", ""]]}, {"id": "2009.04413", "submitter": "Ziqiao Wang", "authors": "Ziqiao Wang, Yongyi Mao, Hongyu Guo, Richong Zhang", "title": "On SkipGram Word Embedding Models with Negative Sampling: Unified\n  Framework and Impact of Noise Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SkipGram word embedding models with negative sampling, or SGN in short, is an\nelegant family of word embedding models. In this paper, we formulate a\nframework for word embedding, referred to as Word-Context Classification (WCC),\nthat generalizes SGN to a wide family of models. The framework, utilizing some\n\"noise examples\", is justified through a theoretical analysis. The impact of\nnoise distribution on the learning of the WCC embedding models is studied\nexperimentally, suggesting that the best noise distribution is in fact the data\ndistribution, in terms of both the embedding performance and the speed of\nconvergence during training. Along our way, we discover several novel embedding\nmodels that outperform the existing WCC models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 02:11:51 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Wang", "Ziqiao", ""], ["Mao", "Yongyi", ""], ["Guo", "Hongyu", ""], ["Zhang", "Richong", ""]]}, {"id": "2009.04416", "submitter": "Karl Cobbe", "authors": "Karl Cobbe, Jacob Hilton, Oleg Klimov, John Schulman", "title": "Phasic Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Phasic Policy Gradient (PPG), a reinforcement learning framework\nwhich modifies traditional on-policy actor-critic methods by separating policy\nand value function training into distinct phases. In prior methods, one must\nchoose between using a shared network or separate networks to represent the\npolicy and value function. Using separate networks avoids interference between\nobjectives, while using a shared network allows useful features to be shared.\nPPG is able to achieve the best of both worlds by splitting optimization into\ntwo phases, one that advances training and one that distills features. PPG also\nenables the value function to be more aggressively optimized with a higher\nlevel of sample reuse. Compared to PPO, we find that PPG significantly improves\nsample efficiency on the challenging Procgen Benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:52:53 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Cobbe", "Karl", ""], ["Hilton", "Jacob", ""], ["Klimov", "Oleg", ""], ["Schulman", "John", ""]]}, {"id": "2009.04433", "submitter": "Akash Srivastava", "authors": "Seungwook Han, Akash Srivastava, Cole Hurwitz, Prasanna Sattigeri and\n  David D. Cox", "title": "not-so-BigGAN: Generating High-Fidelity Images on Small Compute with\n  Wavelet-based Super-Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art models for high-resolution image generation, such as BigGAN\nand VQVAE-2, require an incredible amount of compute resources and/or time (512\nTPU-v3 cores) to train, putting them out of reach for the larger research\ncommunity. On the other hand, GAN-based image super-resolution models, such as\nESRGAN, can not only upscale images to high dimensions, but also are efficient\nto train. In this paper, we present not-so-big-GAN (nsb-GAN), a simple yet\ncost-effective two-step training framework for deep generative models (DGMs) of\nhigh-dimensional natural images. First, we generate images in low-frequency\nbands by training a sampler in the wavelet domain. Then, we super-resolve these\nimages from the wavelet domain back to the pixel-space with our novel wavelet\nsuper-resolution decoder network. Wavelet-based down-sampling method preserves\nmore structural information than pixel-based methods, leading to significantly\nbetter generative quality of the low-resolution sampler (e.g., 64x64). Since\nthe sampler and decoder can be trained in parallel and operate on much lower\ndimensional spaces than end-to-end models, the training cost is substantially\nreduced. On ImageNet 512x512, our model achieves a Fr\\'echet Inception Distance\n(FID) of 10.59 -- beating the baseline BigGAN model -- at half the compute (256\nTPU-v3 cores).\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:29:40 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 18:41:09 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Han", "Seungwook", ""], ["Srivastava", "Akash", ""], ["Hurwitz", "Cole", ""], ["Sattigeri", "Prasanna", ""], ["Cox", "David D.", ""]]}, {"id": "2009.04441", "submitter": "Diego Antognini", "authors": "Kirtan Padh, Diego Antognini, Emma Lejal Glaude, Boi Faltings, Claudiu\n  Musat", "title": "Addressing Fairness in Classification with a Model-Agnostic\n  Multi-Objective Algorithm", "comments": "Accepted at UAI 2021. 14 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of fairness in classification is to learn a classifier that does not\ndiscriminate against groups of individuals based on sensitive attributes, such\nas race and gender. One approach to designing fair algorithms is to use\nrelaxations of fairness notions as regularization terms or in a constrained\noptimization problem. We observe that the hyperbolic tangent function can\napproximate the indicator function. We leverage this property to define a\ndifferentiable relaxation that approximates fairness notions provably better\nthan existing relaxations. In addition, we propose a model-agnostic\nmulti-objective architecture that can simultaneously optimize for multiple\nfairness notions and multiple sensitive attributes and supports all statistical\nparity-based notions of fairness. We use our relaxation with the\nmulti-objective architecture to learn fair classifiers. Experiments on public\ndatasets show that our method suffers a significantly lower loss of accuracy\nthan current debiasing algorithms relative to the unconstrained model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:40:24 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:17:00 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 12:39:26 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Padh", "Kirtan", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.04442", "submitter": "Ruiyuan Lin", "authors": "Ruiyuan Lin, Zhiruo Zhou, Suya You, Raghuveer Rao and C.-C. Jay Kuo", "title": "From Two-Class Linear Discriminant Analysis to Interpretable Multilayer\n  Perceptron Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A closed-form solution exists in two-class linear discriminant analysis\n(LDA), which discriminates two Gaussian-distributed classes in a\nmulti-dimensional feature space. In this work, we interpret the multilayer\nperceptron (MLP) as a generalization of a two-class LDA system so that it can\nhandle an input composed by multiple Gaussian modalities belonging to multiple\nclasses. Besides input layer $l_{in}$ and output layer $l_{out}$, the MLP of\ninterest consists of two intermediate layers, $l_1$ and $l_2$. We propose a\nfeedforward design that has three stages: 1) from $l_{in}$ to $l_1$: half-space\npartitionings accomplished by multiple parallel LDAs, 2) from $l_1$ to $l_2$:\nsubspace isolation where one Gaussian modality is represented by one neuron, 3)\nfrom $l_2$ to $l_{out}$: class-wise subspace mergence, where each Gaussian\nmodality is connected to its target class. Through this process, we present an\nautomatic MLP design that can specify the network architecture (i.e., the layer\nnumber and the neuron number at a layer) and all filter weights in a\nfeedforward one-pass fashion. This design can be generalized to an arbitrary\ndistribution by leveraging the Gaussian mixture model (GMM). Experiments are\nconducted to compare the performance of the traditional backpropagation-based\nMLP (BP-MLP) and the new feedforward MLP (FF-MLP).\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:43:39 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Lin", "Ruiyuan", ""], ["Zhou", "Zhiruo", ""], ["You", "Suya", ""], ["Rao", "Raghuveer", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2009.04446", "submitter": "Ryohei Hisano", "authors": "Wenning Zhang, Ryohei Hisano, Takaaki Ohnishi, Takayuki Mizuno", "title": "Nondiagonal Mixture of Dirichlet Network Distributions for Analyzing a\n  Stock Ownership Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block modeling is widely used in studies on complex networks. The cornerstone\nmodel is the stochastic block model (SBM), widely used over the past decades.\nHowever, the SBM is limited in analyzing complex networks as the model is, in\nessence, a random graph model that cannot reproduce the basic properties of\nmany complex networks, such as sparsity and heavy-tailed degree distribution.\nIn this paper, we provide an edge exchangeable block model that incorporates\nsuch basic features and simultaneously infers the latent block structure of a\ngiven complex network. Our model is a Bayesian nonparametric model that\nflexibly estimates the number of blocks and takes into account the possibility\nof unseen nodes. Using one synthetic dataset and one real-world stock ownership\ndataset, we show that our model outperforms state-of-the-art SBMs for held-out\nlink prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 05:56:10 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 12:10:41 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhang", "Wenning", ""], ["Hisano", "Ryohei", ""], ["Ohnishi", "Takaaki", ""], ["Mizuno", "Takayuki", ""]]}, {"id": "2009.04447", "submitter": "Jie Bu", "authors": "Jie Bu, M. Maruf, Arka Daw", "title": "Beyond Observed Connections : Link Injection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed the \\textit{link injection}, a novel method that\nhelps any differentiable graph machine learning models to go beyond observed\nconnections from the input data in an end-to-end learning fashion. It finds out\n(weak) connections in favor of the current task that is not present in the\ninput data via a parametric link injection layer. We evaluate our method on\nboth node classification and link prediction tasks using a series of\nstate-of-the-art graph convolution networks. Results show that the link\ninjection helps a variety of models to achieve better performances on both\napplications. Further empirical analysis shows a great potential of this method\nin efficiently exploiting unseen connections from the injected links.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 14:22:23 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Bu", "Jie", ""], ["Maruf", "M.", ""], ["Daw", "Arka", ""]]}, {"id": "2009.04450", "submitter": "Micol Marchetti-Bowick", "authors": "Lingyao Zhang, Po-Hsun Su, Jerrick Hoang, Galen Clark Haynes, Micol\n  Marchetti-Bowick", "title": "Map-Adaptive Goal-Based Trajectory Prediction", "comments": "Published at CoRL 2020", "journal-ref": "Conference on Robot Learning (CoRL) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for multi-modal, long-term vehicle trajectory\nprediction. Our approach relies on using lane centerlines captured in rich maps\nof the environment to generate a set of proposed goal paths for each vehicle.\nUsing these paths -- which are generated at run time and therefore dynamically\nadapt to the scene -- as spatial anchors, we predict a set of goal-based\ntrajectories along with a categorical distribution over the goals. This\napproach allows us to directly model the goal-directed behavior of traffic\nactors, which unlocks the potential for more accurate long-term prediction. Our\nexperimental results on both a large-scale internal driving dataset and on the\npublic nuScenes dataset show that our model outperforms state-of-the-art\napproaches for vehicle trajectory prediction over a 6-second horizon. We also\nempirically demonstrate that our model is better able to generalize to road\nscenes from a completely new city than existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:57:01 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 23:20:43 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhang", "Lingyao", ""], ["Su", "Po-Hsun", ""], ["Hoang", "Jerrick", ""], ["Haynes", "Galen Clark", ""], ["Marchetti-Bowick", "Micol", ""]]}, {"id": "2009.04465", "submitter": "Aaron Voelker", "authors": "Peter Blouw, Gurshaant Malik, Benjamin Morcos, Aaron R. Voelker, and\n  Chris Eliasmith", "title": "Hardware Aware Training for Efficient Keyword Spotting on General\n  Purpose and Specialized Hardware", "comments": "5 pages, TinyML Research Symposium '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) provides a critical user interface for many mobile and\nedge applications, including phones, wearables, and cars. As KWS systems are\ntypically 'always on', maximizing both accuracy and power efficiency are\ncentral to their utility. In this work we use hardware aware training (HAT) to\nbuild new KWS neural networks based on the Legendre Memory Unit (LMU) that\nachieve state-of-the-art (SotA) accuracy and low parameter counts. This allows\nthe neural network to run efficiently on standard hardware (212$\\mu$W). We also\ncharacterize the power requirements of custom designed accelerator hardware\nthat achieves SotA power efficiency of 8.79$\\mu$W, beating general purpose low\npower hardware (a microcontroller) by 24x and special purpose ASICs by 16x.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:06:28 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 15:49:23 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 03:10:09 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Blouw", "Peter", ""], ["Malik", "Gurshaant", ""], ["Morcos", "Benjamin", ""], ["Voelker", "Aaron R.", ""], ["Eliasmith", "Chris", ""]]}, {"id": "2009.04544", "submitter": "Levi McClenny", "authors": "Levi McClenny, Ulisses Braga-Neto", "title": "Self-Adaptive Physics-Informed Neural Networks using a Soft Attention\n  Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-Informed Neural Networks (PINNs) have emerged recently as a promising\napplication of deep neural networks to the numerical solution of nonlinear\npartial differential equations (PDEs). However, the original PINN algorithm is\nknown to suffer from stability and accuracy problems in cases where the\nsolution has sharp spatio-temporal transitions. These stiff PDEs require an\nunreasonably large number of collocation points to be solved accurately. It has\nbeen recognized that adaptive procedures are needed to force the neural network\nto fit accurately the stubborn spots in the solution of stiff PDEs. To\naccomplish this, previous approaches have used fixed weights hard-coded over\nregions of the solution deemed to be important. In this paper, we propose a\nfundamentally new method to train PINNs adaptively, where the adaptation\nweights are fully trainable, so the neural network learns by itself which\nregions of the solution are difficult and is forced to focus on them, which is\nreminiscent of soft multiplicative-mask attention mechanism used in computer\nvision. The basic idea behind these Self-Adaptive PINNs is to make the weights\nincrease where the corresponding loss is higher, which is accomplished by\ntraining the network to simultaneously minimize the losses and maximize the\nweights, i.e., to find a saddle point in the cost surface. We show that this is\nformally equivalent to solving a PDE-constrained optimization problem using a\npenalty-based method, though in a way where the monotonically-nondecreasing\npenalty coefficients are trainable. Numerical experiments with an Allen-Cahn\nstiff PDE, the Self-Adaptive PINN outperformed other state-of-the-art PINN\nalgorithms in L2 error by a wide margin, while using a smaller number of\ntraining epochs. An Appendix contains additional results with Burger's and\nHelmholtz PDEs, which confirmed the trends observed in the Allen-Cahn\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 04:07:52 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 06:05:45 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["McClenny", "Levi", ""], ["Braga-Neto", "Ulisses", ""]]}, {"id": "2009.04549", "submitter": "Daniel Dunlavy", "authors": "Scott Heidbrink, Kathryn N. Rodhouse, Daniel M. Dunlavy", "title": "Multimodal Deep Learning for Flaw Detection in Software Programs", "comments": "13 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": "SAND2020-9429R", "categories": "cs.LG cs.AI cs.CR cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of multiple deep learning models for detecting flaws in\nsoftware programs. Current, standard approaches for flaw detection rely on a\nsingle representation of a software program (e.g., source code or a program\nbinary). We illustrate that, by using techniques from multimodal deep learning,\nwe can simultaneously leverage multiple representations of software programs to\nimprove flaw detection over single representation analyses. Specifically, we\nadapt three deep learning models from the multimodal learning literature for\nuse in flaw detection and demonstrate how these models outperform traditional\ndeep learning models. We present results on detecting software flaws using the\nJuliet Test Suite and Linux Kernel.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 20:15:11 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Heidbrink", "Scott", ""], ["Rodhouse", "Kathryn N.", ""], ["Dunlavy", "Daniel M.", ""]]}, {"id": "2009.04550", "submitter": "Zichao Li", "authors": "Nicolas Fraiman, Zichao Li", "title": "Biclustering with Alternating K-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is the task of simultaneously clustering the rows and columns of\nthe data matrix into different subgroups such that the rows and columns within\na subgroup exhibit similar patterns. In this paper, we consider the case of\nproducing exclusive row and column biclusters. We provide a new formulation of\nthe biclustering problem based on the idea of minimizing the empirical\nclustering risk. We develop and prove a consistency result with respect to the\nempirical clustering risk. Since the optimization problem is combinatorial in\nnature, finding the global minimum is computationally intractable. In light of\nthis fact, we propose a simple and novel algorithm that finds a local minimum\nby alternating the use of an adapted version of the k-means clustering\nalgorithm between columns and rows. We evaluate and compare the performance of\nour algorithm to other related biclustering methods on both simulated data and\nreal-world gene expression data sets. The results demonstrate that our\nalgorithm is able to detect meaningful structures in the data and outperform\nother competing biclustering methods in various settings and situations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 20:15:24 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Fraiman", "Nicolas", ""], ["Li", "Zichao", ""]]}, {"id": "2009.04559", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni", "title": "Developing and Improving Risk Models using Machine-learning Based\n  Algorithms", "comments": null, "journal-ref": null, "doi": "10.1145/3299815.3314478", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this study is to develop a good risk model for classifying\nbusiness delinquency by simultaneously exploring several machine learning based\nmethods including regularization, hyper-parameter optimization, and model\nensembling algorithms. The rationale under the analyses is firstly to obtain\ngood base binary classifiers (include Logistic Regression ($LR$), K-Nearest\nNeighbors ($KNN$), Decision Tree ($DT$), and Artificial Neural Networks\n($ANN$)) via regularization and appropriate settings of hyper-parameters. Then\ntwo model ensembling algorithms including bagging and boosting are performed on\nthe good base classifiers for further model improvement. The models are\nevaluated using accuracy, Area Under the Receiver Operating Characteristic\nCurve (AUC of ROC), recall, and F1 score via repeating 10-fold cross-validation\n10 times. The results show the optimal base classifiers along with the\nhyper-parameter settings are $LR$ without regularization, $KNN$ by using 9\nnearest neighbors, $DT$ by setting the maximum level of the tree to be 7, and\n$ANN$ with three hidden layers. Bagging on $KNN$ with $K$ valued 9 is the\noptimal model we can get for risk classification as it reaches the average\naccuracy, AUC, recall, and F1 score valued 0.90, 0.93, 0.82, and 0.89,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 20:38:00 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""]]}, {"id": "2009.04570", "submitter": "Eric Hall", "authors": "S{\\o}ren Taverniers and Eric J. Hall and Markos A. Katsoulakis and\n  Daniel M. Tartakovsky", "title": "Mutual Information for Explainable Deep Learning of Multiscale Systems", "comments": "27 pages, 8 figures. Added additional examples", "journal-ref": null, "doi": "10.1016/j.jcp.2021.110551", "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely completion of design cycles for complex systems ranging from consumer\nelectronics to hypersonic vehicles relies on rapid simulation-based\nprototyping. The latter typically involves high-dimensional spaces of possibly\ncorrelated control variables (CVs) and quantities of interest (QoIs) with\nnon-Gaussian and possibly multimodal distributions. We develop a\nmodel-agnostic, moment-independent global sensitivity analysis (GSA) that\nrelies on differential mutual information to rank the effects of CVs on QoIs.\nThe data requirements of this information-theoretic approach to GSA are met by\nreplacing computationally intensive components of the physics-based model with\na deep neural network surrogate. Subsequently, the GSA is used to explain the\nnetwork predictions, and the surrogate is deployed to close design loops.\nViewed as an uncertainty quantification method for interrogating the surrogate,\nthis framework is compatible with a wide variety of black-box models. We\ndemonstrate that the surrogate-driven mutual information GSA provides useful\nand distinguishable rankings on two applications of interest in energy storage.\nConsequently, our information-theoretic GSA provides an \"outer loop\" for\naccelerated product design by identifying the most and least sensitive input\ndirections and performing subsequent optimization over appropriately reduced\nparameter subspaces.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:26:21 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 10:04:18 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Taverniers", "S\u00f8ren", ""], ["Hall", "Eric J.", ""], ["Katsoulakis", "Markos A.", ""], ["Tartakovsky", "Daniel M.", ""]]}, {"id": "2009.04575", "submitter": "M. Sadegh Talebi", "authors": "Mohammad Sadegh Talebi, Anders Jonsson, Odalric-Ambrym Maillard", "title": "Improved Exploration in Factored Average-Reward MDPs", "comments": "23 pages. To appear in Proceedings of the 24th International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a regret minimization task under the average-reward criterion in\nan unknown Factored Markov Decision Process (FMDP). More specifically, we\nconsider an FMDP where the state-action space $\\mathcal X$ and the state-space\n$\\mathcal S$ admit the respective factored forms of $\\mathcal X =\n\\otimes_{i=1}^n \\mathcal X_i$ and $\\mathcal S=\\otimes_{i=1}^m \\mathcal S_i$,\nand the transition and reward functions are factored over $\\mathcal X$ and\n$\\mathcal S$. Assuming known factorization structure, we introduce a novel\nregret minimization strategy inspired by the popular UCRL2 strategy, called\nDBN-UCRL, which relies on Bernstein-type confidence sets defined for individual\nelements of the transition function. We show that for a generic factorization\nstructure, DBN-UCRL achieves a regret bound, whose leading term strictly\nimproves over existing regret bounds in terms of the dependencies on the size\nof $\\mathcal S_i$'s and the involved diameter-related terms. We further show\nthat when the factorization structure corresponds to the Cartesian product of\nsome base MDPs, the regret of DBN-UCRL is upper bounded by the sum of regret of\nthe base MDPs. We demonstrate, through numerical experiments on standard\nenvironments, that DBN-UCRL enjoys substantially improved regret empirically\nover existing algorithms that have frequentist regret guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 21:15:01 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 11:04:41 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 13:01:24 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Talebi", "Mohammad Sadegh", ""], ["Jonsson", "Anders", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "2009.04591", "submitter": "Peng Liu", "authors": "Ying Chen, Peng Liu, Chung Piaw Teo", "title": "Regularised Text Logistic Regression: Key Word Detection and Sentiment\n  Classification for Online Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online customer reviews have become important for managers and executives in\nthe hospitality and catering industry who wish to obtain a comprehensive\nunderstanding of their customers' demands and expectations. We propose a\nRegularized Text Logistic (RTL) regression model to perform text analytics and\nsentiment classification on unstructured text data, which automatically\nidentifies a set of statistically significant and operationally insightful word\nfeatures, and achieves satisfactory predictive classification accuracy. We\napply the RTL model to two online review datasets, Restaurant and Hotel, from\nTripAdvisor. Our results demonstrate satisfactory classification performance\ncompared with alternative classifiers with a highest true positive rate of\n94.9%. Moreover, RTL identifies a small set of word features, corresponding to\n3% for Restaurant and 20% for Hotel, which boosts working efficiency by\nallowing managers to drill down into a much smaller set of important customer\nreviews. We also develop the consistency, sparsity and oracle property of the\nestimator.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 22:37:53 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chen", "Ying", ""], ["Liu", "Peng", ""], ["Teo", "Chung Piaw", ""]]}, {"id": "2009.04607", "submitter": "Runzhe Wan", "authors": "Runzhe Wan, Xinyu Zhang, Rui Song", "title": "Multi-Objective Reinforcement Learning for Infectious Disease Control\n  with Application to COVID-19 Spread", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Severe infectious diseases such as the novel coronavirus (COVID-19) pose a\nhuge threat to public health. Stringent control measures, such as school\nclosures and stay-at-home orders, while having significant effects, also bring\nhuge economic losses. A crucial question for policymakers around the world is\nhow to make the trade-off and implement the appropriate interventions. In this\nwork, we propose a Multi-Objective Reinforcement Learning framework to\nfacilitate the data-driven decision making and minimize the long-term overall\ncost. Specifically, at each decision point, a Bayesian epidemiological model is\nfirst learned as the environment model, and then we use the proposed\nmodel-based multi-objective planning algorithm to find a set of Pareto-optimal\npolicies. This framework, combined with the prediction bands for each policy,\nprovides a real-time decision support tool for policymakers. The application is\ndemonstrated with the spread of COVID-19 in China.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 23:55:27 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 20:34:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wan", "Runzhe", ""], ["Zhang", "Xinyu", ""], ["Song", "Rui", ""]]}, {"id": "2009.04614", "submitter": "Kun Fang", "authors": "Kun Fang, Xiaolin Huang, Fanghui Liu and Jie Yang", "title": "End-to-end Kernel Learning via Generative Random Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Fourier features enable researchers to build feature map to learn the\nspectral distribution of the underlying kernel. Current distribution-based\nmethods follow a two-stage scheme: they first learn and optimize the feature\nmap by solving the kernel alignment problem, then learn a linear classifier on\nthe features. However, since the ideal kernel in kernel alignment problem is\nnot necessarily optimal in classification tasks, the generalization performance\nof the random features learned in this two-stage manner can perhaps be further\nimproved. To address this issue, we propose an end-to-end, one-stage kernel\nlearning approach, called generative random Fourier features, which jointly\nlearns the features and the classifier. A generative network is involved to\nimplicitly learn and to sample from the distribution of the latent kernel.\nRandom features are then built via the generative weights and followed by a\nlinear classifier parameterized as a full-connected layer. We jointly train the\ngenerative network and the classifier by solving the empirical risk\nminimization problem for a one-stage solution. Straightly minimizing the loss\nbetween predictive and true labels brings better generalization performance.\nBesides, this end-to-end strategy allows us to increase the depth of features,\nresulting in multi-layer architecture and exhibiting strong linear-separable\npattern. Empirical results demonstrate the superiority of our method in\nclassification tasks over other two-stage kernel learning methods. Finally, we\ninvestigate the robustness of proposed method in defending adversarial attacks,\nwhich shows that the randomization and resampling mechanism associated with the\nlearned distribution can alleviate the performance decrease brought by\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 00:27:39 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Fang", "Kun", ""], ["Huang", "Xiaolin", ""], ["Liu", "Fanghui", ""], ["Yang", "Jie", ""]]}, {"id": "2009.04651", "submitter": "Donlapark Ponnoprat", "authors": "Donlapark Ponnoprat", "title": "Universal consistency of Wasserstein $k$-NN classifier", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein distance provides a notion of dissimilarities between\nprobability measures, which has recent applications in learning of structured\ndata with varying size such as images and text documents. In this work, we\nanalyze the $k$-nearest neighbor classifier ($k$-NN) under the Wasserstein\ndistance and establish the universal consistency on families of distributions.\nUsing previous known results on the consistency of the $k$-NN classifier on\ninfinite dimensional metric spaces, it suffices to show that the families is a\ncountable union of finite dimension sets. As a result, we show that the $k$-NN\nclassifier is universally consistent on spaces of finitely supported measures,\nthe space of Gaussian measures, and the space of measures with finite wavelet\ndensities. In addition, we give a counterexample to show that the universal\nconsistency does not hold on $\\mathcal{W}_p((0,1))$.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 03:05:05 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 07:51:21 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 18:39:18 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ponnoprat", "Donlapark", ""]]}, {"id": "2009.04674", "submitter": "Hengrui Wang", "authors": "Hengrui Wang, Yubo Zhang, Mingzhi Chen, Tong Yang", "title": "Spectral Clustering with Smooth Tiny Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most prominent clustering approaches. The\ndistance-based similarity is the most widely used method for spectral\nclustering. However, people have already noticed that this is not suitable for\nmulti-scale data, as the distance varies a lot for clusters with different\ndensities. State of the art(ROSC and CAST ) addresses this limitation by taking\nthe reachability similarity of objects into account. However, we observe that\nin real-world scenarios, data in the same cluster tend to present in a smooth\nmanner, and previous algorithms never take this into account. Based on this\nobservation, we propose a novel clustering algorithm, which con-siders the\nsmoothness of data for the first time. We first divide objects into a great\nmany tiny clusters. Our key idea is to cluster tiny clusters, whose centers\nconstitute smooth graphs. Theoretical analysis and experimental results show\nthat our clustering algorithm significantly outperforms state of the art.\nAlthough in this paper, we singly focus on multi-scale situations, the idea of\ndata smoothness can certainly be extended to any clustering algorithms\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 05:21:20 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wang", "Hengrui", ""], ["Zhang", "Yubo", ""], ["Chen", "Mingzhi", ""], ["Yang", "Tong", ""]]}, {"id": "2009.04681", "submitter": "Adora DSouza", "authors": "Axel Wism\\\"uller, Adora M. DSouza and Anas Z. Abidin", "title": "Large-scale nonlinear Granger causality: A data-driven, multivariate\n  approach to recovering directed networks from short time-series data", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To gain insight into complex systems it is a key challenge to infer nonlinear\ncausal directional relations from observational time-series data. Specifically,\nestimating causal relationships between interacting components in large systems\nwith only short recordings over few temporal observations remains an important,\nyet unresolved problem. Here, we introduce a large-scale Nonlinear Granger\nCausality (lsNGC) approach for inferring directional, nonlinear, multivariate\ncausal interactions between system components from short high-dimensional\ntime-series recordings. By modeling interactions with nonlinear state-space\ntransformations from limited observational data, lsNGC identifies casual\nrelations with no explicit a priori assumptions on functional interdependence\nbetween component time-series in a computationally efficient manner.\nAdditionally, our method provides a mathematical formulation revealing\nstatistical significance of inferred causal relations. We extensively study the\nability of lsNGC to recovering network structure from two-node to thirty-four\nnode chaotic time-series systems. Our results suggest that lsNGC captures\nmeaningful interactions from limited observational data, where it performs\nfavorably when compared to traditionally used methods. Finally, we demonstrate\nthe applicability of lsNGC to estimating causality in large, real-world systems\nby inferring directional nonlinear, multivariate causal relationships among a\nlarge number of relatively short time-series acquired from functional Magnetic\nResonance Imaging (fMRI) data of the human brain.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 06:27:57 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wism\u00fcller", "Axel", ""], ["DSouza", "Adora M.", ""], ["Abidin", "Anas Z.", ""]]}, {"id": "2009.04695", "submitter": "Diego Antognini", "authors": "Blagoj Mitrevski, Milena Filipovic, Diego Antognini, Emma Lejal\n  Glaude, Boi Faltings, Claudiu Musat", "title": "Momentum-based Gradient Methods in Multi-objective Recommender Systems", "comments": "Under review. 8 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective gradient methods are becoming the standard for solving\nmulti-objective problems. Among others, they show promising results in\ndeveloping multi-objective recommender systems with both correlated and\nuncorrelated objectives. Classic multi-gradient descent usually relies on the\ncombination of the gradients, not including the computation of first and second\nmoments of the gradients. This leads to a brittle behavior and misses important\nareas in the solution space.\n  In this work, we create a multi-objective Adamize method that leverage the\nbenefits of the Adam optimizer in single-objective problems. This corrects and\nstabilizes the gradients of every objective before calculating a common\ngradient descent vector that optimizes all the objectives simultaneously. We\nevaluate the benefits of Multi-objective Adamize on two multi-objective\nrecommender systems and for three different objective combinations, both\ncorrelated or uncorrelated. We report significant improvements, measured with\nthree different Pareto front metrics: hypervolume, coverage, and spacing.\nFinally, we show that the Adamized Pareto front strictly dominates the previous\none on multiple objective pairs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:12:21 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Mitrevski", "Blagoj", ""], ["Filipovic", "Milena", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.04709", "submitter": "Ricardo Bigolin Lanfredi", "authors": "Ricardo Bigolin Lanfredi, Joyce D. Schroeder, Tolga Tasdizen", "title": "Quantifying the Preferential Direction of the Model Gradient in\n  Adversarial Training With Projected Gradient Descent", "comments": "v3: new counting of Tables and Figures in the SM; fixed typo in eq.\n  of Lemma 1; new evaluation of linearity of models; new evaluation of\n  correlation of alignment metrics and robustness for a fixed training method;\n  new citations to python libraries; changed range of some graphs to simplify\n  the axes' digits; new comment about the difference of input gradient in\n  proposed and baseline metric; editing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, especially projected gradient descent (PGD), has been a\nsuccessful approach for improving robustness against adversarial attacks. After\nadversarial training, gradients of models with respect to their inputs have a\npreferential direction. However, the direction of alignment is not\nmathematically well established, making it difficult to evaluate\nquantitatively. We propose a novel definition of this direction as the\ndirection of the vector pointing toward the closest point of the support of the\nclosest inaccurate class in decision space. To evaluate the alignment with this\ndirection after adversarial training, we apply a metric that uses generative\nadversarial networks to produce the smallest residual needed to change the\nclass present in the image. We show that PGD-trained models have a higher\nalignment than the baseline according to our definition, that our metric\npresents higher alignment values than a competing metric formulation, and that\nenforcing this alignment increases the robustness of models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:48:42 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 07:58:22 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 23:49:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lanfredi", "Ricardo Bigolin", ""], ["Schroeder", "Joyce D.", ""], ["Tasdizen", "Tolga", ""]]}, {"id": "2009.04719", "submitter": "Fatme Hachem", "authors": "Maria Luisa Damiani, Andrea Acquaviva, Fatima Hachem, Matteo Rossini", "title": "Learning Behavioral Representations of Human Mobility", "comments": "ACM SIGSPATIAL 2020: 28th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems.November 2020 Seattle, Washington,\n  USA", "journal-ref": null, "doi": "10.1145/3397536.3422255", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the suitability of state-of-the-art\nrepresentation learning methods to the analysis of behavioral similarity of\nmoving individuals, based on CDR trajectories. The core of the contribution is\na novel methodological framework, mob2vec, centered on the combined use of a\nrecent symbolic trajectory segmentation method for the removal of noise, a\nnovel trajectory generalization method incorporating behavioral information,\nand an unsupervised technique for the learning of vector representations from\nsequential data. Mob2vec is the result of an empirical study conducted on real\nCDR data through an extensive experimentation. As a result, it is shown that\nmob2vec generates vector representations of CDR trajectories in low dimensional\nspaces which preserve the similarity of the mobility behavior of individuals.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 08:15:16 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 10:32:09 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Damiani", "Maria Luisa", ""], ["Acquaviva", "Andrea", ""], ["Hachem", "Fatima", ""], ["Rossini", "Matteo", ""]]}, {"id": "2009.04722", "submitter": "Qingbo Yin", "authors": "Liran Shen, Meng Joo Er, Qingbo Yin", "title": "Population structure-learned classifier for high-dimension\n  low-sample-size class-imbalanced problem", "comments": "41 pages,10 Figures,10 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Classification on high-dimension low-sample-size data (HDLSS) is a\nchallenging problem and it is common to have class-imbalanced data in most\napplication fields. We term this as Imbalanced HDLSS (IHDLSS). Recent\ntheoretical results reveal that the classification criterion and tolerance\nsimilarity are crucial to HDLSS, which emphasizes the maximization of\nwithin-class variance on the premise of class separability. Based on this idea,\na novel linear binary classifier, termed Population Structure-learned\nClassifier (PSC), is proposed. The proposed PSC can obtain better\ngeneralization performance on IHDLSS by maximizing the sum of inter-class\nscatter matrix and intra-class scatter matrix on the premise of class\nseparability and assigning different intercept values to majority and minority\nclasses. The salient features of the proposed approach are: (1) It works well\non IHDLSS; (2) The inverse of high dimensional matrix can be solved in low\ndimensional space; (3) It is self-adaptive in determining the intercept term\nfor each class; (4) It has the same computational complexity as the SVM. A\nseries of evaluations are conducted on one simulated data set and eight\nreal-world benchmark data sets on IHDLSS on gene analysis. Experimental results\ndemonstrate that the PSC is superior to the state-of-art methods in IHDLSS.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 08:33:39 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Shen", "Liran", ""], ["Er", "Meng Joo", ""], ["Yin", "Qingbo", ""]]}, {"id": "2009.04729", "submitter": "Xiaoyu Lei", "authors": "Xiaoyu Lei, Huiming Zhang", "title": "Non-asymptotic Optimal Prediction Error for RKHS-based Partially\n  Functional Linear Models", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.FA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the framework of reproducing kernel Hilbert space (RKHS), we consider\nthe penalized least-squares of the partially functional linear models (PFLM),\nwhose predictor contains both functional and traditional multivariate part, and\nthe multivariate part allows a divergent number of parameters. From the\nnon-asymptotic point of view, we focus on the rate-optimal upper and lower\nbounds of the prediction error. An exact upper bound for the excess prediction\nrisk is shown in a non-asymptotic form under a more general assumption known as\nthe effective dimension to the model, by which we also show the prediction\nconsistency when the number of multivariate covariates $p$ slightly increases\nwith the sample size $n$. Our new finding implies a trade-off between the\nnumber of non-functional predictors and the effective dimension of the kernel\nprincipal components to ensure the prediction consistency in the\nincreasing-dimensional setting. The analysis in our proof hinges on the\nspectral condition of the sandwich operator of the covariance operator and the\nreproducing kernel, and on the concentration inequalities for the random\nelements in Hilbert space. Finally, we derive the non-asymptotic minimax lower\nbound under the regularity assumption of Kullback-Leibler divergence of the\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 08:49:32 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 02:40:31 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lei", "Xiaoyu", ""], ["Zhang", "Huiming", ""]]}, {"id": "2009.04756", "submitter": "Daniel Jung", "authors": "Andreas Lundgren and Daniel Jung", "title": "Data-Driven Open Set Fault Classification and Fault Size Estimation\n  Using Quantitative Fault Diagnosis Analysis", "comments": "Preprint, 10 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven fault classification is complicated by imbalanced training data\nand unknown fault classes. Fault diagnosis of dynamic systems is done by\ndetecting changes in time-series data, for example residuals, caused by faults\nor system degradation. Different fault classes can result in similar residual\noutputs, especially for small faults which can be difficult to distinguish from\nnominal system operation. Analyzing how easy it is to distinguish data from\ndifferent fault classes is crucial during the design process of a diagnosis\nsystem to evaluate if classification performance requirements can be met. Here,\na data-driven model of different fault classes is used based on the\nKullback-Leibler divergence. This is used to develop a framework for\nquantitative fault diagnosis performance analysis and open set fault\nclassification. A data-driven fault classification algorithm is proposed which\ncan handle unknown faults and also estimate the fault size using training data\nfrom known fault scenarios. To illustrate the usefulness of the proposed\nmethods, data have been collected from an engine test bench to illustrate the\ndesign process of a data-driven diagnosis system, including quantitative fault\ndiagnosis analysis and evaluation of the developed open set fault\nclassification algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 09:53:13 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Lundgren", "Andreas", ""], ["Jung", "Daniel", ""]]}, {"id": "2009.04777", "submitter": "Pawe{\\l} Wawrzy\\'nski", "authors": "Marcin Szulc, Jakub {\\L}yskawa, Pawe{\\l} Wawrzy\\'nski", "title": "A framework for reinforcement learning with autocorrelated actions", "comments": "The 27th International Conference on Neural Information Processing\n  (ICONIP2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subject of this paper is reinforcement learning. Policies are considered\nhere that produce actions based on states and random elements autocorrelated in\nsubsequent time instants. Consequently, an agent learns from experiments that\nare distributed over time and potentially give better clues to policy\nimprovement. Also, physical implementation of such policies, e.g. in robotics,\nis less problematic, as it avoids making robots shake. This is in opposition to\nmost RL algorithms which add white noise to control causing unwanted shaking of\nthe robots. An algorithm is introduced here that approximately optimizes the\naforementioned policy. Its efficiency is verified for four simulated learning\ncontrol problems (Ant, HalfCheetah, Hopper, and Walker2D) against three other\nmethods (PPO, SAC, ACER). The algorithm outperforms others in three of these\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 11:23:09 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Szulc", "Marcin", ""], ["\u0141yskawa", "Jakub", ""], ["Wawrzy\u0144ski", "Pawe\u0142", ""]]}, {"id": "2009.04796", "submitter": "Kevin Fauvel", "authors": "Kevin Fauvel, Tao Lin, V\\'eronique Masson, \\'Elisa Fromont, Alexandre\n  Termier", "title": "XCM: An Explainable Convolutional Neural Network for Multivariate Time\n  Series Classification", "comments": "Another machine learning method for multivariate time series\n  classification providing faithful explanations is presented in\n  arXiv:2005.03645", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present XCM, an eXplainable Convolutional neural network for Multivariate\ntime series classification. XCM is a new compact convolutional neural network\nwhich extracts information relative to the observed variables and time directly\nfrom the input data. Thus, XCM architecture enables a good generalization\nability on both small and large datasets, while allowing the full exploitation\nof a faithful post-hoc model-specific explainability method (Gradient-weighted\nClass Activation Mapping) by precisely identifying the observed variables and\ntimestamps of the input data that are important for predictions. Our evaluation\nfirstly shows that XCM outperforms the state-of-the-art multivariate time\nseries classifiers on both the large and small public UEA datasets.\nFurthermore, following the illustration of the performance and explainability\nof XCM on a synthetic dataset, we present how XCM can outperform the current\nmost accurate state-of-the-art algorithm on a real-world application while\nenhancing explainability by providing faithful and more informative\nexplanations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 11:55:53 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 10:10:37 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Fauvel", "Kevin", ""], ["Lin", "Tao", ""], ["Masson", "V\u00e9ronique", ""], ["Fromont", "\u00c9lisa", ""], ["Termier", "Alexandre", ""]]}, {"id": "2009.04800", "submitter": "Nora L\\\"uthen", "authors": "Nora L\\\"uthen, Stefano Marelli, Bruno Sudret", "title": "Automatic selection of basis-adaptive sparse polynomial chaos expansions\n  for engineering applications", "comments": null, "journal-ref": null, "doi": null, "report-no": "RSUQ-2020-011C", "categories": "stat.CO cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse polynomial chaos expansions (PCE) are an efficient and widely used\nsurrogate modeling method in uncertainty quantification for engineering\nproblems with computationally expensive models. To make use of the available\ninformation in the most efficient way, several approaches for so-called\nbasis-adaptive sparse PCE have been proposed to determine the set of polynomial\nregressors (\"basis\") for PCE adaptively.\n  The goal of this paper is to help practitioners identify the most suitable\nmethods for constructing a surrogate PCE for their model. We describe three\nstate-of-the-art basis-adaptive approaches from the recent sparse PCE\nliterature and conduct an extensive benchmark in terms of global approximation\naccuracy on a large set of computational models. Investigating the synergies\nbetween sparse regression solvers and basis adaptivity schemes, we find that\nthe choice of the proper solver and basis-adaptive scheme is very important, as\nit can result in more than one order of magnitude difference in performance. No\nsingle method significantly outperforms the others, but dividing the analysis\ninto classes (regarding input dimension and experimental design size), we are\nable to identify specific sparse solver and basis adaptivity combinations for\neach class that show comparatively good performance.\n  To further improve on these findings, we introduce a novel solver and basis\nadaptivity selection scheme guided by cross-validation error. We demonstrate\nthat this automatic selection procedure provides close-to-optimal results in\nterms of accuracy, and significantly more robust solutions, while being more\ngeneral than the case-by-case recommendations obtained by the benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:13:57 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 11:25:17 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 16:44:02 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["L\u00fcthen", "Nora", ""], ["Marelli", "Stefano", ""], ["Sudret", "Bruno", ""]]}, {"id": "2009.04806", "submitter": "Alexander Wang", "authors": "Alexander Wang, Mengye Ren, Richard S. Zemel", "title": "SketchEmbedNet: Learning Novel Concepts by Imitating Drawings", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketch drawings capture the salient information of visual concepts. Previous\nwork has shown that neural networks are capable of producing sketches of\nnatural objects drawn from a small number of classes. While earlier approaches\nfocus on generation quality or retrieval, we explore properties of image\nrepresentations learned by training a model to produce sketches of images. We\nshow that this generative, class-agnostic model produces informative embeddings\nof images from novel examples, classes, and even novel datasets in a few-shot\nsetting. Additionally, we find that these learned representations exhibit\ninteresting structure and compositionality.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:43:28 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 17:15:39 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 18:51:51 GMT"}, {"version": "v4", "created": "Tue, 22 Jun 2021 19:45:09 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Wang", "Alexander", ""], ["Ren", "Mengye", ""], ["Zemel", "Richard S.", ""]]}, {"id": "2009.04822", "submitter": "Daniele Gammelli", "authors": "Daniele Gammelli, Kasper Pryds Rolsted, Dario Pacino, Filipe Rodrigues", "title": "Generalized Multi-Output Gaussian Process Censored Regression", "comments": "7 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When modelling censored observations, a typical approach in current\nregression methods is to use a censored-Gaussian (i.e. Tobit) model to describe\nthe conditional output distribution. In this paper, as in the case of missing\ndata, we argue that exploiting correlations between multiple outputs can enable\nmodels to better address the bias introduced by censored data. To do so, we\nintroduce a heteroscedastic multi-output Gaussian process model which combines\nthe non-parametric flexibility of GPs with the ability to leverage information\nfrom correlated outputs under input-dependent noise conditions. To address the\nresulting inference intractability, we further devise a variational bound to\nthe marginal log-likelihood suitable for stochastic optimization. We\nempirically evaluate our model against other generative models for censored\ndata on both synthetic and real world tasks and further show how it can be\ngeneralized to deal with arbitrary likelihood functions. Results show how the\nadded flexibility allows our model to better estimate the underlying\nnon-censored (i.e. true) process under potentially complex censoring dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:46:29 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Gammelli", "Daniele", ""], ["Rolsted", "Kasper Pryds", ""], ["Pacino", "Dario", ""], ["Rodrigues", "Filipe", ""]]}, {"id": "2009.04850", "submitter": "Hemant Tyagi", "authors": "Micha\\\"el Fanuel and Hemant Tyagi", "title": "Denoising modulo samples: k-NN regression and tightness of SDP\n  relaxation", "comments": "(i) 38 pages, 6 figures (ii) Revised the manuscript after receiving\n  reviews (iii) Removed Theorem 3(2) and Corollary 3 due to inaccuracies in the\n  proof, main results are unchanged (iv) Added Appendix B (v) Added Section 2.5\n  for estimating f (Theorem 5)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern applications involve the acquisition of noisy modulo samples of a\nfunction $f$, with the goal being to recover estimates of the original samples\nof $f$. For a Lipschitz function $f:[0,1]^d \\to \\mathbb{R}$, suppose we are\ngiven the samples $y_i = (f(x_i) + \\eta_i)\\bmod 1; \\quad i=1,\\dots,n$ where\n$\\eta_i$ denotes noise. Assuming $\\eta_i$ are zero-mean i.i.d Gaussian's, and\n$x_i$'s form a uniform grid, we derive a two-stage algorithm that recovers\nestimates of the samples $f(x_i)$ with a uniform error rate $O((\\frac{\\log\nn}{n})^{\\frac{1}{d+2}})$ holding with high probability. The first stage\ninvolves embedding the points on the unit complex circle, and obtaining\ndenoised estimates of $f(x_i)\\bmod 1$ via a $k$NN (nearest neighbor) estimator.\nThe second stage involves a sequential unwrapping procedure which unwraps the\ndenoised mod $1$ estimates from the first stage. The estimates of the samples\n$f(x_i)$ can be subsequently utilized to construct an estimate of the function\n$f$, with the aforementioned uniform error rate.\n  Recently, Cucuringu and Tyagi proposed an alternative way of denoising modulo\n$1$ data which works with their representation on the unit complex circle. They\nformulated a smoothness regularized least squares problem on the product\nmanifold of unit circles, where the smoothness is measured with respect to the\nLaplacian of a proximity graph $G$ involving the $x_i$'s. This is a nonconvex\nquadratically constrained quadratic program (QCQP) hence they proposed solving\nits semidefinite program (SDP) based relaxation. We derive sufficient\nconditions under which the SDP is a tight relaxation of the QCQP. Hence under\nthese conditions, the global solution of QCQP can be obtained in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:32:46 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 11:49:28 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Tyagi", "Hemant", ""]]}, {"id": "2009.04859", "submitter": "Hemant Tyagi", "authors": "Hemant Tyagi", "title": "Error analysis for denoising smooth modulo signals on a graph", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, we are given access to noisy modulo samples of a smooth\nfunction with the goal being to robustly unwrap the samples, i.e., to estimate\nthe original samples of the function. In a recent work, Cucuringu and Tyagi\nproposed denoising the modulo samples by first representing them on the unit\ncomplex circle and then solving a smoothness regularized least squares problem\n-- the smoothness measured w.r.t the Laplacian of a suitable proximity graph\n$G$ -- on the product manifold of unit circles. This problem is a quadratically\nconstrained quadratic program (QCQP) which is nonconvex, hence they proposed\nsolving its sphere-relaxation leading to a trust region subproblem (TRS). In\nterms of theoretical guarantees, $\\ell_2$ error bounds were derived for (TRS).\nThese bounds are however weak in general and do not really demonstrate the\ndenoising performed by (TRS).\n  In this work, we analyse the (TRS) as well as an unconstrained relaxation of\n(QCQP). For both these estimators we provide a refined analysis in the setting\nof Gaussian noise and derive noise regimes where they provably denoise the\nmodulo observations w.r.t the $\\ell_2$ norm. The analysis is performed in a\ngeneral setting where $G$ is any connected graph.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:45:21 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Tyagi", "Hemant", ""]]}, {"id": "2009.04872", "submitter": "Yang Zou", "authors": "Yang Zou, Zhikun Zhang, Michael Backes, Yang Zhang", "title": "Privacy Analysis of Deep Learning in the Wild: Membership Inference\n  Attacks against Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While being deployed in many critical applications as core components,\nmachine learning (ML) models are vulnerable to various security and privacy\nattacks. One major privacy attack in this domain is membership inference, where\nan adversary aims to determine whether a target data sample is part of the\ntraining set of a target ML model. So far, most of the current membership\ninference attacks are evaluated against ML models trained from scratch.\nHowever, real-world ML models are typically trained following the transfer\nlearning paradigm, where a model owner takes a pretrained model learned from a\ndifferent dataset, namely teacher model, and trains her own student model by\nfine-tuning the teacher model with her own data.\n  In this paper, we perform the first systematic evaluation of membership\ninference attacks against transfer learning models. We adopt the strategy of\nshadow model training to derive the data for training our membership inference\nclassifier. Extensive experiments on four real-world image datasets show that\nmembership inference can achieve effective performance. For instance, on the\nCIFAR100 classifier transferred from ResNet20 (pretrained with Caltech101), our\nmembership inference achieves $95\\%$ attack AUC. Moreover, we show that\nmembership inference is still effective when the architecture of target model\nis unknown. Our results shed light on the severity of membership risks stemming\nfrom machine learning models in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:14:22 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Zou", "Yang", ""], ["Zhang", "Zhikun", ""], ["Backes", "Michael", ""], ["Zhang", "Yang", ""]]}, {"id": "2009.04875", "submitter": "Alexandre Galashov", "authors": "Alexandre Galashov, Jakub Sygnowski, Guillaume Desjardins, Jan\n  Humplik, Leonard Hasenclever, Rae Jeong, Yee Whye Teh, Nicolas Heess", "title": "Importance Weighted Policy Learning and Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to exploit prior experience to solve novel problems rapidly is a\nhallmark of biological learning systems and of great practical importance for\nartificial ones. In the meta reinforcement learning literature much recent work\nhas focused on the problem of optimizing the learning process itself. In this\npaper we study a complementary approach which is conceptually simple, general,\nmodular and built on top of recent improvements in off-policy learning. The\nframework is inspired by ideas from the probabilistic inference literature and\ncombines robust off-policy learning with a behavior prior, or default behavior\nthat constrains the space of solutions and serves as a bias for exploration; as\nwell as a representation for the value function, both of which are easily\nlearned from a number of training tasks in a multi-task scenario. Our approach\nachieves competitive adaptation performance on hold-out tasks compared to meta\nreinforcement learning baselines and can scale to complex sparse-reward\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:16:58 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 13:21:40 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Galashov", "Alexandre", ""], ["Sygnowski", "Jakub", ""], ["Desjardins", "Guillaume", ""], ["Humplik", "Jan", ""], ["Hasenclever", "Leonard", ""], ["Jeong", "Rae", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "2009.04899", "submitter": "Jingyuan Xia", "authors": "Jingyuan Xia, Jun-Jie Huang, and Imad Jaimoukha", "title": "Meta-learning for Multi-variable Non-convex Optimization Problems:\n  Iterating Non-optimums Makes Optimum Possible", "comments": "15 pages, 8 figures, update content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to address the problem of solving a non-convex\noptimization problem over an intersection of multiple variable sets. This kind\nof problems is typically solved by using an alternating minimization (AM)\nstrategy which splits the overall problem into a set of sub-problems\ncorresponding to each variable, and then iteratively performs minimization over\neach sub-problem using a fixed updating rule. However, due to the intrinsic\nnon-convexity of the overall problem, the optimization can usually be trapped\ninto bad local minimum even when each sub-problem can be globally optimized at\neach iteration. To tackle this problem, we propose a meta-learning based Global\nScope Optimization (GSO) method. It adaptively generates optimizers for\nsub-problems via meta-learners and constantly updates these meta-learners with\nrespect to the global loss information of the overall problem. Therefore, the\nsub-problems are optimized with the objective of minimizing the global loss\nspecifically. We evaluate the proposed model on a number of simulations,\nincluding solving bi-linear inverse problems: matrix completion, and non-linear\nproblems: Gaussian mixture models. The experimental results show that our\nproposed approach outperforms AM-based methods in standard settings, and is\nable to achieve effective optimization in some challenging cases while other\nmethods would typically fail.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:45:00 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 11:55:47 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 16:37:35 GMT"}, {"version": "v4", "created": "Fri, 25 Jun 2021 02:54:45 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Xia", "Jingyuan", ""], ["Huang", "Jun-Jie", ""], ["Jaimoukha", "Imad", ""]]}, {"id": "2009.04923", "submitter": "Theodoros Tsiligkaridis", "authors": "Theodoros Tsiligkaridis, Jay Roberts", "title": "Second Order Optimization for Adversarial Robustness and\n  Interpretability", "comments": "7 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are easily fooled by small perturbations known as\nadversarial attacks. Adversarial Training (AT) is a technique aimed at learning\nfeatures robust to such attacks and is widely regarded as a very effective\ndefense. However, the computational cost of such training can be prohibitive as\nthe network size and input dimensions grow. Inspired by the relationship\nbetween robustness and curvature, we propose a novel regularizer which\nincorporates first and second order information via a quadratic approximation\nto the adversarial loss. The worst case quadratic loss is approximated via an\niterative scheme. It is shown that using only a single iteration in our\nregularizer achieves stronger robustness than prior gradient and curvature\nregularization schemes, avoids gradient obfuscation, and, with additional\niterations, achieves strong robustness with significantly lower training time\nthan AT. Further, it retains the interesting facet of AT that networks learn\nfeatures which are well-aligned with human perception. We demonstrate\nexperimentally that our method produces higher quality human-interpretable\nfeatures than other geometric regularization techniques. These robust features\nare then used to provide human-friendly explanations to model predictions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 15:05:14 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Tsiligkaridis", "Theodoros", ""], ["Roberts", "Jay", ""]]}, {"id": "2009.04950", "submitter": "Bingjia Wang", "authors": "Bingjia Wang, Alec Koppel and Vikram Krishnamurthy", "title": "A Markov Decision Process Approach to Active Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised learning, we fit a single statistical model to a given data\nset, assuming that the data is associated with a singular task, which yields\nwell-tuned models for specific use, but does not adapt well to new contexts. By\ncontrast, in meta-learning, the data is associated with numerous tasks, and we\nseek a model that may perform well on all tasks simultaneously, in pursuit of\ngreater generalization. One challenge in meta-learning is how to exploit\nrelationships between tasks and classes, which is overlooked by commonly used\nrandom or cyclic passes through data. In this work, we propose actively\nselecting samples on which to train by discerning covariates inside and between\nmeta-training sets. Specifically, we cast the problem of selecting a sample\nfrom a number of meta-training sets as either a multi-armed bandit or a Markov\nDecision Process (MDP), depending on how one encapsulates correlation across\ntasks. We develop scheduling schemes based on Upper Confidence Bound (UCB),\nGittins Index and tabular Markov Decision Problems (MDPs) solved with linear\nprogramming, where the reward is the scaled statistical accuracy to ensure it\nis a time-invariant function of state and action. Across a variety of\nexperimental contexts, we observe significant reductions in sample complexity\nof active selection scheme relative to cyclic or i.i.d. sampling, demonstrating\nthe merit of exploiting covariates in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 15:45:34 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wang", "Bingjia", ""], ["Koppel", "Alec", ""], ["Krishnamurthy", "Vikram", ""]]}, {"id": "2009.05027", "submitter": "Ois\\'in Carroll Mr.", "authors": "Ois\\'in Carroll, Joeran Beel", "title": "Finite Group Equivariant Neural Networks for Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Games such as go, chess and checkers have multiple equivalent game states,\ni.e. multiple board positions where symmetrical and opposite moves should be\nmade. These equivalences are not exploited by current state of the art neural\nagents which instead must relearn similar information, thereby wasting\ncomputing time. Group equivariant CNNs in existing work create networks which\ncan exploit symmetries to improve learning, however, they lack the\nexpressiveness to correctly reflect the move embeddings necessary for games. We\nintroduce Finite Group Neural Networks (FGNNs), a method for creating agents\nwith an innate understanding of these board positions. FGNNs are shown to\nimprove the performance of networks playing checkers (draughts), and can be\neasily adapted to other games and learning problems. Additionally, FGNNs can be\ncreated from existing network architectures. These include, for the first time,\nthose with skip connections and arbitrary layer types. We demonstrate that an\nequivariant version of U-Net (FGNN-U-Net) outperforms the unmodified network in\nimage segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:46:09 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Carroll", "Ois\u00edn", ""], ["Beel", "Joeran", ""]]}, {"id": "2009.05079", "submitter": "Miheer Dewaskar", "authors": "Miheer Dewaskar, John Palowitch, Mark He, Michael I. Love, Andrew\n  Nobel", "title": "Finding Stable Groups of Cross-Correlated Features in Multi-View data", "comments": "22 pages, 5 figures. R package: https://github.com/miheerdew/cbce", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view data, in which data of different types are obtained from a common\nset of samples, is now common in many scientific problems. An important problem\nin the analysis of multi-view data is identifying interactions between groups\nof features from different data types. A bimodule is a pair $(A,B)$ of feature\nsets from two different data types such that the aggregate cross-correlation\nbetween the features in $A$ and those in $B$ is large. A bimodule $(A,B)$ is\nstable if $A$ coincides with the set of features having significant aggregate\ncorrelation with the features in $B$, and vice-versa. At the population level,\nstable bimodules correspond to connected components of the cross-correlation\nnetwork, which is the bipartite graph whose edges are pairs of features with\nnon-zero cross-correlations.\n  We develop an iterative, testing-based procedure, called BSP, to identify\nstable bimodules in two moderate- to high-dimensional data sets. BSP relies on\npermutation-based p-values for sums of squared cross-correlations. We\nefficiently approximate the p-values using tail probabilities of gamma\ndistributions that are fit using analytical estimates of the permutation\nmoments of the test statistic. Our moment estimates depend on the eigenvalues\nof the intra-correlation matrices of $A$ and $B$ and as a result, the\nsignificance of observed cross-correlations accounts for the correlations\nwithin each data type.\n  We carry out a thorough simulation study to assess the performance of BSP,\nand present an extended application of BSP to the problem of expression\nquantitative trait loci (eQTL) analysis using recent data from the GTEx\nproject. In addition, we apply BSP to climatology data in order to identify\nregions in North America where annual temperature variation affects\nprecipitation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:27:35 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Dewaskar", "Miheer", ""], ["Palowitch", "John", ""], ["He", "Mark", ""], ["Love", "Michael I.", ""], ["Nobel", "Andrew", ""]]}, {"id": "2009.05102", "submitter": "Chenglizhao Chen", "authors": "Xuehao Wang, Shuai Li, Chenglizhao Chen, Yuming Fang, Aimin Hao, Hong\n  Qin", "title": "Data-Level Recombination and Lightweight Fusion Scheme for RGB-D Salient\n  Object Detection", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2020.3037470", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing RGB-D salient object detection methods treat depth information as an\nindependent component to complement its RGB part, and widely follow the\nbi-stream parallel network architecture. To selectively fuse the CNNs features\nextracted from both RGB and depth as a final result, the state-of-the-art\n(SOTA) bi-stream networks usually consist of two independent subbranches; i.e.,\none subbranch is used for RGB saliency and the other aims for depth saliency.\nHowever, its depth saliency is persistently inferior to the RGB saliency\nbecause the RGB component is intrinsically more informative than the depth\ncomponent. The bi-stream architecture easily biases its subsequent fusion\nprocedure to the RGB subbranch, leading to a performance bottleneck. In this\npaper, we propose a novel data-level recombination strategy to fuse RGB with D\n(depth) before deep feature extraction, where we cyclically convert the\noriginal 4-dimensional RGB-D into \\textbf{D}GB, R\\textbf{D}B and RG\\textbf{D}.\nThen, a newly lightweight designed triple-stream network is applied over these\nnovel formulated data to achieve an optimal channel-wise complementary fusion\nstatus between the RGB and D, achieving a new SOTA performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:13:05 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Wang", "Xuehao", ""], ["Li", "Shuai", ""], ["Chen", "Chenglizhao", ""], ["Fang", "Yuming", ""], ["Hao", "Aimin", ""], ["Qin", "Hong", ""]]}, {"id": "2009.05135", "submitter": "Sarah Ostadabbas", "authors": "Amirreza Farnoosh, Bahar Azari, Sarah Ostadabbas", "title": "Deep Switching Auto-Regressive Factorization:Application to Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep switching auto-regressive factorization (DSARF), a deep\ngenerative model for spatio-temporal data with the capability to unravel\nrecurring patterns in the data and perform robust short- and long-term\npredictions. Similar to other factor analysis methods, DSARF approximates high\ndimensional data by a product between time dependent weights and spatially\ndependent factors. These weights and factors are in turn represented in terms\nof lower dimensional latent variables that are inferred using stochastic\nvariational inference. DSARF is different from the state-of-the-art techniques\nin that it parameterizes the weights in terms of a deep switching vector\nauto-regressive likelihood governed with a Markovian prior, which is able to\ncapture the non-linear inter-dependencies among weights to characterize\nmultimodal temporal dynamics. This results in a flexible hierarchical deep\ngenerative factor analysis model that can be extended to (i) provide a\ncollection of potentially interpretable states abstracted from the process\ndynamics, and (ii) perform short- and long-term vector time series prediction\nin a complex multi-relational setting. Our extensive experiments, which include\nsimulated data and real data from a wide range of applications such as climate\nchange, weather forecasting, traffic, infectious disease spread and nonlinear\nphysical systems attest the superior performance of DSARF in terms of long- and\nshort-term prediction error, when compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 20:15:59 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Farnoosh", "Amirreza", ""], ["Azari", "Bahar", ""], ["Ostadabbas", "Sarah", ""]]}, {"id": "2009.05138", "submitter": "Negin Golrezaei", "authors": "Negin Golrezaei, Vahideh Manshadi, Jon Schneider, Shreyas Sekar", "title": "Learning Product Rankings Robust to Fake Users", "comments": "65 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many online platforms, customers' decisions are substantially influenced\nby product rankings as most customers only examine a few top-ranked products.\nConcurrently, such platforms also use the same data corresponding to customers'\nactions to learn how these products must be ranked or ordered. These\ninteractions in the underlying learning process, however, may incentivize\nsellers to artificially inflate their position by employing fake users, as\nexemplified by the emergence of click farms. Motivated by such fraudulent\nbehavior, we study the ranking problem of a platform that faces a mixture of\nreal and fake users who are indistinguishable from one another. We first show\nthat existing learning algorithms---that are optimal in the absence of fake\nusers---may converge to highly sub-optimal rankings under manipulation by fake\nusers. To overcome this deficiency, we develop efficient learning algorithms\nunder two informational environments: in the first setting, the platform is\naware of the number of fake users, and in the second setting, it is agnostic to\nthe number of fake users. For both these environments, we prove that our\nalgorithms converge to the optimal ranking, while being robust to the\naforementioned fraudulent behavior; we also present worst-case performance\nguarantees for our methods, and show that they significantly outperform\nexisting algorithms. At a high level, our work employs several novel approaches\nto guarantee robustness such as: (i) constructing product-ordering graphs that\nencode the pairwise relationships between products inferred from the customers'\nactions; and (ii) implementing multiple levels of learning with a judicious\namount of bi-directional cross-learning between levels.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 20:26:02 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Golrezaei", "Negin", ""], ["Manshadi", "Vahideh", ""], ["Schneider", "Jon", ""], ["Sekar", "Shreyas", ""]]}, {"id": "2009.05147", "submitter": "Andre Nguyen", "authors": "Andre T. Nguyen, Luke E. Richards, Gaoussou Youssouf Kebe, Edward\n  Raff, Kasra Darvish, Frank Ferraro, Cynthia Matuszek", "title": "Practical Cross-modal Manifold Alignment for Grounded Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cross-modality manifold alignment procedure that leverages\ntriplet loss to jointly learn consistent, multi-modal embeddings of\nlanguage-based concepts of real-world items. Our approach learns these\nembeddings by sampling triples of anchor, positive, and negative data points\nfrom RGB-depth images and their natural language descriptions. We show that our\napproach can benefit from, but does not require, post-processing steps such as\nProcrustes analysis, in contrast to some of our baselines which require it for\nreasonable performance. We demonstrate the effectiveness of our approach on two\ndatasets commonly used to develop robotic-based grounded language learning\nsystems, where our approach outperforms four baselines, including a\nstate-of-the-art approach, across five evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 04:16:48 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Nguyen", "Andre T.", ""], ["Richards", "Luke E.", ""], ["Kebe", "Gaoussou Youssouf", ""], ["Raff", "Edward", ""], ["Darvish", "Kasra", ""], ["Ferraro", "Frank", ""], ["Matuszek", "Cynthia", ""]]}, {"id": "2009.05148", "submitter": "Sabarish Vadarevu", "authors": "Sabarish Vadarevu and Vijay Karamcheti", "title": "A new heuristic algorithm for fast k-segmentation", "comments": "10 pages, 10 figures, 5 tables, and 1 pseudo-code. Submitted to IEEE\n  BigData 2020. Supplementary material (200 segmented videos) at\n  https://figshare.com/articles/media/7-segmentation of 200 scenes from\n  BDD100k/12859493/1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-segmentation of a video stream is used to partition it into $k$\npiecewise-linear segments, so that each linear segment has a meaningful\ninterpretation. Such segmentation may be used to summarize large videos using a\nsmall set of images, to identify anomalies within segments and change points\nbetween segments, and to select critical subsets for training machine learning\nmodels. Exact and approximate segmentation methods for $k$-segmentation exist\nin the literature. Each of these algorithms occupies a different spot in the\ntrade-off between computational complexity and accuracy. A novel heuristic\nalgorithm is proposed in this paper to improve upon existing methods. It is\nempirically found to provide accuracies competitive with exact methods at a\nfraction of the computational expense.\n  The new algorithm is inspired by Lloyd's algorithm for K-Means and Lloyd-Max\nalgorithm for scalar quantization, and is called the LM algorithm for\nconvenience. It works by iteratively minimizing a cost function from any given\ninitialisation; the commonly used $L_2$ cost is chosen in this paper. While the\ngreedy minimization makes the algorithm sensitive to initialisation, the\nability to converge from any initial guess to a local optimum allows the\nalgorithm to be integrated into other existing algorithms. Three variants of\nthe algorithm are tested over a large number of synthetic datasets, one being a\nstandalone LM implementation, and two others that combine with existing\nalgorithms. One of the latter two -- LM-enhanced-Bottom-Up segmentation -- is\nfound to have the best accuracy and the lowest computational complexity among\nall algorithms. This variant of LM can provide $k$-segmentations over data sets\nwith up to a million image frames within several seconds.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 04:50:17 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Vadarevu", "Sabarish", ""], ["Karamcheti", "Vijay", ""]]}, {"id": "2009.05176", "submitter": "Mario Michael Krell", "authors": "Mario Michael Krell and Bilal Wehbe", "title": "A First Step Towards Distribution Invariant Regression Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Regression evaluation has been performed for decades. Some metrics have been\nidentified to be robust against shifting and scaling of the data but\nconsidering the different distributions of data is much more difficult to\naddress (imbalance problem) even though it largely impacts the comparability\nbetween evaluations on different datasets. In classification, it has been\nstated repeatedly that performance metrics like the F-Measure and Accuracy are\nhighly dependent on the class distribution and that comparisons between\ndifferent datasets with different distributions are impossible. We show that\nthe same problem exists in regression. The distribution of odometry parameters\nin robotic applications can for example largely vary between different\nrecording sessions. Here, we need regression algorithms that either perform\nequally well for all function values, or that focus on certain boundary regions\nlike high speed. This has to be reflected in the evaluation metric. We propose\nthe modification of established regression metrics by weighting with the\ninverse distribution of function values $Y$ or the samples $X$ using an\nautomatically tuned Gaussian kernel density estimator. We show on synthetic and\nrobotic data in reproducible experiments that classical metrics behave wrongly,\nwhereas our new metrics are less sensitive to changing distributions,\nespecially when correcting by the marginal distribution in $X$. Our new\nevaluation concept enables the comparison of results between different datasets\nwith different distributions. Furthermore, it can reveal overfitting of a\nregression algorithm to overrepresented target values. As an outcome,\nnon-overfitting regression algorithms will be more likely chosen due to our\ncorrected metrics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 23:40:46 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Krell", "Mario Michael", ""], ["Wehbe", "Bilal", ""]]}, {"id": "2009.05199", "submitter": "Daniel Nemirovsky", "authors": "Daniel Nemirovsky, Nicolas Thiebaut, Ye Xu, Abhishek Gupta", "title": "CounteRGAN: Generating Realistic Counterfactuals with Residual\n  Generative Adversarial Nets", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of machine learning models in various industries has led to\ngrowing demands for model interpretability and for the ability to provide\nmeaningful recourse to users. For example, patients hoping to improve their\ndiagnoses or loan applicants seeking to increase their chances of approval.\nCounterfactuals can help in this regard by identifying input perturbations that\nwould result in more desirable prediction outcomes. Meaningful counterfactuals\nshould be able to achieve the desired outcome, but also be realistic,\nactionable, and efficient to compute. Current approaches achieve desired\noutcomes with moderate actionability but are severely limited in terms of\nrealism and latency. To tackle these limitations, we apply Generative\nAdversarial Nets (GANs) toward counterfactual search. We also introduce a novel\nResidual GAN (RGAN) that helps to improve counterfactual realism and\nactionability compared to regular GANs. The proposed CounteRGAN method utilizes\nan RGAN and a target classifier to produce counterfactuals capable of providing\nmeaningful recourse. Evaluations on two popular datasets highlight how the\nCounteRGAN is able to overcome the limitations of existing methods, including\nlatency improvements of >50x to >90,000x, making meaningful recourse available\nin real-time and applicable to a wide range of domains.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 02:08:19 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 06:25:33 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Nemirovsky", "Daniel", ""], ["Thiebaut", "Nicolas", ""], ["Xu", "Ye", ""], ["Gupta", "Abhishek", ""]]}, {"id": "2009.05204", "submitter": "Qi Zhu", "authors": "Qi Zhu, Yidan Xu, Haonan Wang, Chao Zhang, Jiawei Han, Carl Yang", "title": "Transfer Learning of Graph Neural Networks with Ego-graph Information\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been shown with superior performance in\nvarious applications, but training dedicated GNNs can be costly for large-scale\ngraphs. Some recent work started to study the pre-training of GNNs. However,\nnone of them provide theoretical insights into the design of their frameworks,\nor clear requirements and guarantees towards the transferability of GNNs. In\nthis work, we establish a theoretically grounded and practically useful\nframework for the transfer learning of GNNs. Firstly, we propose a novel view\ntowards the essential graph information and advocate the capturing of it as the\ngoal of transferable GNN training, which motivates the design of Ours, a novel\nGNN framework based on ego-graph information maximization to analytically\nachieve this goal. Secondly, we specify the requirement of structure-respecting\nnode features as the GNN input, and derive a rigorous bound of GNN\ntransferability based on the difference between the local graph Laplacians of\nthe source and target graphs. Finally, we conduct controlled synthetic\nexperiments to directly justify our theoretical conclusions. Extensive\nexperiments on real-world networks towards role identification show consistent\nresults in the rigorously analyzed setting of direct-transfering, while those\ntowards large-scale relation prediction show promising results in the more\ngeneralized and practical setting of transfering with fine-tuning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 02:31:18 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Zhu", "Qi", ""], ["Xu", "Yidan", ""], ["Wang", "Haonan", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""], ["Yang", "Carl", ""]]}, {"id": "2009.05226", "submitter": "Jiyue Wang", "authors": "Ji-Yue Wang, Pei Zhang, Wen-feng Pang, Jie Li", "title": "Extending Label Smoothing Regularization with Self-Knowledge\n  Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the strong correlation between the Label Smoothing\nRegularization(LSR) and Knowledge distillation(KD), we propose an algorithm\nLsrKD for training boost by extending the LSR method to the KD regime and\napplying a softer temperature. Then we improve the LsrKD by a Teacher\nCorrection(TC) method, which manually sets a constant larger proportion for the\nright class in the uniform distribution teacher. To further improve the\nperformance of LsrKD, we develop a self-distillation method named Memory-replay\nKnowledge Distillation (MrKD) that provides a knowledgeable teacher to replace\nthe uniform distribution one in LsrKD. The MrKD method penalizes the KD loss\nbetween the current model's output distributions and its copies' on the\ntraining trajectory. By preventing the model learning so far from its\nhistorical output distribution space, MrKD can stabilize the learning and find\na more robust minimum. Our experiments show that LsrKD can improve LSR\nperformance consistently at no cost, especially on several deep neural networks\nwhere LSR is ineffectual. Also, MrKD can significantly improve single model\ntraining. The experiment results confirm that the TC can help LsrKD and MrKD to\nboost training, especially on the networks they are failed. Overall, LsrKD,\nMrKD, and their TC variants are comparable to or outperform the LSR method,\nsuggesting the broad applicability of these KD methods.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 04:23:34 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Wang", "Ji-Yue", ""], ["Zhang", "Pei", ""], ["Pang", "Wen-feng", ""], ["Li", "Jie", ""]]}, {"id": "2009.05244", "submitter": "Shao-Yuan Lo", "authors": "Shao-Yuan Lo, Vishal M. Patel", "title": "Defending Against Multiple and Unforeseen Adversarial Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness of deep neural networks has been actively\ninvestigated. However, most existing defense approaches are limited to a\nspecific type of adversarial perturbations. Specifically, they often fail to\noffer resistance to multiple attack types simultaneously, i.e., they lack\nmulti-perturbation robustness. Furthermore, compared to image recognition\nproblems, the adversarial robustness of video recognition models is relatively\nunexplored. While several studies have proposed how to generate adversarial\nvideos, only a handful of approaches about the defense strategies have been\npublished in the literature. In this paper, we propose one of the first defense\nstrategies against multiple types of adversarial videos for video recognition.\nThe proposed method, referred to as MultiBN, performs adversarial training on\nmultiple adversarial video types using multiple independent batch normalization\n(BN) layers with a learning-based BN selection module. With a multiple BN\nstructure, each BN brach is responsible for learning the distribution of a\nsingle perturbation type and thus provides more precise distribution\nestimations. This mechanism benefits dealing with multiple perturbation types.\nThe BN selection module detects the attack type of an input video and sends it\nto the corresponding BN branch, making MultiBN fully automatic and allow\nend-to-end training. Compared to present adversarial training approaches, the\nproposed MultiBN exhibits stronger multi-perturbation robustness against\ndifferent and even unforeseen adversarial video types, ranging from Lp-bounded\nattacks and physically realizable attacks. This holds true on different\ndatasets and target models. Moreover, we conduct an extensive analysis to study\nthe properties of the multiple BN structure.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 06:07:14 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 01:18:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lo", "Shao-Yuan", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2009.05266", "submitter": "Yiming Li", "authors": "Yiming Li, Da Sun Handason Tam, Siyue Xie, Xiaxin Liu, Qiu Fang Ying,\n  Wing Cheong Lau, Dah Ming Chiu, Shou Zhi Chen", "title": "GTEA: Representation Learning for Temporal Interaction Graphs via Edge\n  Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of representation learning for temporal interaction\ngraphs where a network of entities with complex interactions over an extended\nperiod of time is modeled as a graph with a rich set of node and edge\nattributes. In particular, an edge between a node-pair within the graph\ncorresponds to a multi-dimensional time-series. To fully capture and model the\ndynamics of the network, we propose GTEA, a framework of representation\nlearning for temporal interaction graphs with per-edge time-based aggregation.\nUnder GTEA, a Graph Neural Network (GNN) is integrated with a state-of-the-art\nsequence model, such as LSTM, Transformer and their time-aware variants. The\nsequence model generates edge embeddings to encode temporal interaction\npatterns between each pair of nodes, while the GNN-based backbone learns the\ntopological dependencies and relationships among different nodes. GTEA also\nincorporates a sparsity-inducing self-attention mechanism to distinguish and\nfocus on the more important neighbors of each node during the aggregation\nprocess. By capturing temporal interactive dynamics together with\nmulti-dimensional node and edge attributes in a network, GTEA can learn\nfine-grained representations for a temporal interaction graph to enable or\nfacilitate other downstream data analytic tasks. Experimental results show that\nGTEA outperforms state-of-the-art schemes including GraphSAGE, APPNP, and TGAT\nby delivering higher accuracy (100.00%, 98.51%, 98.05% ,79.90%) and macro-F1\nscore (100.00%, 98.51%, 96.68% ,79.90%) over four large-scale real-world\ndatasets for binary/ multi-class node classification.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 07:52:05 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 08:43:48 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Li", "Yiming", ""], ["Tam", "Da Sun Handason", ""], ["Xie", "Siyue", ""], ["Liu", "Xiaxin", ""], ["Ying", "Qiu Fang", ""], ["Lau", "Wing Cheong", ""], ["Chiu", "Dah Ming", ""], ["Chen", "Shou Zhi", ""]]}, {"id": "2009.05303", "submitter": "Weijian Chen", "authors": "Weijian Chen, Fuli Feng, Qifan Wang, Xiangnan He, Chonggang Song,\n  Guohui Ling, Yongdong Zhang", "title": "CatGCN: Graph Convolutional Networks with Categorical Node Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on Graph Convolutional Networks (GCNs) reveal that the initial\nnode representations (i.e., the node representations before the first-time\ngraph convolution) largely affect the final model performance. However, when\nlearning the initial representation for a node, most existing work linearly\ncombines the embeddings of node features, without considering the interactions\namong the features (or feature embeddings). We argue that when the node\nfeatures are categorical, e.g., in many real-world applications like user\nprofiling and recommender system, feature interactions usually carry important\nsignals for predictive analytics. Ignoring them will result in suboptimal\ninitial node representation and thus weaken the effectiveness of the follow-up\ngraph convolution. In this paper, we propose a new GCN model named CatGCN,\nwhich is tailored for graph learning when the node features are categorical.\nSpecifically, we integrate two ways of explicit interaction modeling into the\nlearning of initial node representation, i.e., local interaction modeling on\neach pair of node features and global interaction modeling on an artificial\nfeature graph. We then refine the enhanced initial node representations with\nthe neighborhood aggregation-based graph convolution. We train CatGCN in an\nend-to-end fashion and demonstrate it on semi-supervised node classification.\nExtensive experiments on three tasks of user profiling (the prediction of user\nage, city, and purchase level) from Tencent and Alibaba datasets validate the\neffectiveness of CatGCN, especially the positive effect of performing feature\ninteraction modeling before graph convolution.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 09:25:17 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 07:41:55 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Chen", "Weijian", ""], ["Feng", "Fuli", ""], ["Wang", "Qifan", ""], ["He", "Xiangnan", ""], ["Song", "Chonggang", ""], ["Ling", "Guohui", ""], ["Zhang", "Yongdong", ""]]}, {"id": "2009.05322", "submitter": "Aditya Lahiri", "authors": "Aditya Lahiri, Narayanan Unny Edakunni", "title": "Accurate and Intuitive Contextual Explanations using Linear Model Trees", "comments": "KDD Workshop on ML in Finance 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing use of complex machine learning models in critical\napplications within the finance domain, explaining the decisions of the model\nhas become a necessity. With applications spanning from credit scoring to\ncredit marketing, the impact of these models is undeniable. Among the multiple\nways in which one can explain the decisions of these complicated models, local\npost hoc model agnostic explanations have gained massive adoption. These\nmethods allow one to explain each prediction independent of the modelling\ntechnique that was used while training. As explanations, they either give\nindividual feature attributions or provide sufficient rules that represent\nconditions for a prediction to be made. The current state of the art methods\nuse rudimentary methods to generate synthetic data around the point to be\nexplained. This is followed by fitting simple linear models as surrogates to\nobtain a local interpretation of the prediction. In this paper, we seek to\nsignificantly improve on both, the method used to generate the explanations and\nthe nature of explanations produced. We use a Generative Adversarial Network\nfor synthetic data generation and train a piecewise linear model in the form of\nLinear Model Trees to be used as the surrogate model.In addition to individual\nfeature attributions, we also provide an accompanying context to our\nexplanations by leveraging the structure and property of our surrogate model.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 10:13:12 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Lahiri", "Aditya", ""], ["Edakunni", "Narayanan Unny", ""]]}, {"id": "2009.05346", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo and Yang Gao", "title": "Disentangling Neural Architectures and Weights: A Case Study in\n  Supervised Classification", "comments": "22 pages and 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The history of deep learning has shown that human-designed problem-specific\nnetworks can greatly improve the classification performance of general neural\nmodels. In most practical cases, however, choosing the optimal architecture for\na given task remains a challenging problem. Recent architecture-search methods\nare able to automatically build neural models with strong performance but fail\nto fully appreciate the interaction between neural architecture and weights.\nThis work investigates the problem of disentangling the role of the neural\nstructure and its edge weights, by showing that well-trained architectures may\nnot need any link-specific fine-tuning of the weights. We compare the\nperformance of such weight-free networks (in our case these are binary networks\nwith {0, 1}-valued weights) with random, weight-agnostic, pruned and standard\nfully connected networks. To find the optimal weight-agnostic network, we use a\nnovel and computationally efficient method that translates the hard\narchitecture-search problem into a feasible optimization problem.More\nspecifically, we look at the optimal task-specific architectures as the optimal\nconfiguration of binary networks with {0, 1}-valued weights, which can be found\nthrough an approximate gradient descent strategy. Theoretical convergence\nguarantees of the proposed algorithm are obtained by bounding the error in the\ngradient approximation and its practical performance is evaluated on two\nreal-world data sets. For measuring the structural similarities between\ndifferent architectures, we use a novel spectral approach that allows us to\nunderline the intrinsic differences between real-valued networks and\nweight-free architectures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:22:22 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Colombo", "Nicolo", ""], ["Gao", "Yang", ""]]}, {"id": "2009.05418", "submitter": "Calum Hand", "authors": "James Hook, Calum Hand, Emma Whitfield", "title": "Bayesian Screening: Multi-test Bayesian Optimization Applied to in\n  silico Material Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present new multi-test Bayesian optimization models and algorithms for use\nin large scale material screening applications. Our screening problems are\ndesigned around two tests, one expensive and one cheap. This paper differs from\nother recent work on multi-test Bayesian optimization through use of a flexible\nmodel that allows for complex, non-linear relationships between the cheap and\nexpensive test scores. This additional modeling flexibility is essential in the\nmaterial screening applications which we describe. We demonstrate the power of\nour new algorithms on a family of synthetic toy problems as well as on real\ndata from two large scale screening studies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 13:07:51 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Hook", "James", ""], ["Hand", "Calum", ""], ["Whitfield", "Emma", ""]]}, {"id": "2009.05423", "submitter": "Ningyi Liao", "authors": "Shufan Wang, Ningyi Liao, Liyao Xiang, Nanyang Ye, Quanshi Zhang", "title": "Achieving Adversarial Robustness via Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning has been known to produce compact models without much\naccuracy degradation. However, how the pruning process affects a network's\nrobustness and the working mechanism behind remain unresolved. In this work, we\ntheoretically prove that the sparsity of network weights is closely associated\nwith model robustness. Through experiments on a variety of adversarial pruning\nmethods, we find that weights sparsity will not hurt but improve robustness,\nwhere both weights inheritance from the lottery ticket and adversarial training\nimprove model robustness in network pruning. Based on these findings, we\npropose a novel adversarial training method called inverse weights inheritance,\nwhich imposes sparse weights distribution on a large network by inheriting\nweights from a small network, thereby improving the robustness of the large\nnetwork.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 13:15:43 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Wang", "Shufan", ""], ["Liao", "Ningyi", ""], ["Xiang", "Liyao", ""], ["Ye", "Nanyang", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2009.05438", "submitter": "Ghada El-Khawaga", "authors": "Ghada Elkhawaga, Mervat Abuelkheir, Sherif I. Barakat, Alaa M. Riad\n  and Manfred Reichert", "title": "CONDA-PM -- A Systematic Review and Framework for Concept Drift Analysis\n  in Process Mining", "comments": "45 pages, 11 tables, 13 figures", "journal-ref": "Algorithms 2020, 13(7), 161", "doi": "10.3390/a13070161", "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business processes evolve over time to adapt to changing business\nenvironments. This requires continuous monitoring of business processes to gain\ninsights into whether they conform to the intended design or deviate from it.\nThe situation when a business process changes while being analysed is denoted\nas Concept Drift. Its analysis is concerned with studying how a business\nprocess changes, in terms of detecting and localising changes and studying the\neffects of the latter. Concept drift analysis is crucial to enable early\ndetection and management of changes, that is, whether to promote a change to\nbecome part of an improved process, or to reject the change and make decisions\nto mitigate its effects. Despite its importance, there exists no comprehensive\nframework for analysing concept drift types, affected process perspectives, and\ngranularity levels of a business process. This article proposes the CONcept\nDrift Analysis in Process Mining (CONDA-PM) framework describing phases and\nrequirements of a concept drift analysis approach. CONDA-PM was derived from a\nSystematic Literature Review (SLR) of current approaches analysing concept\ndrift. We apply the CONDA-PM framework on current approaches to concept drift\nanalysis and evaluate their maturity. Applying CONDA-PM framework highlights\nareas where research is needed to complement existing efforts.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:39:09 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Elkhawaga", "Ghada", ""], ["Abuelkheir", "Mervat", ""], ["Barakat", "Sherif I.", ""], ["Riad", "Alaa M.", ""], ["Reichert", "Manfred", ""]]}, {"id": "2009.05474", "submitter": "Antonio Emanuele Cin\\`a", "authors": "Antonio Emanuele Cin\\`a, Alessandro Torcinovich, Marcello Pelillo", "title": "A Black-box Adversarial Attack for Poisoning Clustering", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms play a fundamental role as tools in decision-making and\nsensible automation processes. Due to the widespread use of these applications,\na robustness analysis of this family of algorithms against adversarial noise\nhas become imperative. To the best of our knowledge, however, only a few works\nhave currently addressed this problem. In an attempt to fill this gap, in this\nwork, we propose a black-box adversarial attack for crafting adversarial\nsamples to test the robustness of clustering algorithms. We formulate the\nproblem as a constrained minimization program, general in its structure and\ncustomizable by the attacker according to her capability constraints. We do not\nassume any information about the internal structure of the victim clustering\nalgorithm, and we allow the attacker to query it as a service only. In the\nabsence of any derivative information, we perform the optimization with a\ncustom approach inspired by the Abstract Genetic Algorithm (AGA). In the\nexperimental part, we demonstrate the sensibility of different single and\nensemble clustering algorithms against our crafted adversarial samples on\ndifferent scenarios. Furthermore, we perform a comparison of our algorithm with\na state-of-the-art approach showing that we are able to reach or even\noutperform its performance. Finally, to highlight the general nature of the\ngenerated noise, we show that our attacks are transferable even against\nsupervised algorithms such as SVMs, random forests and neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 18:19:31 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Cin\u00e0", "Antonio Emanuele", ""], ["Torcinovich", "Alessandro", ""], ["Pelillo", "Marcello", ""]]}, {"id": "2009.05475", "submitter": "Alexia Jolicoeur-Martineau", "authors": "Alexia Jolicoeur-Martineau, R\\'emi Pich\\'e-Taillefer, R\\'emi Tachet\n  des Combes, Ioannis Mitliagkas", "title": "Adversarial score matching and improved sampling for image generation", "comments": "Code at\n  https://github.com/AlexiaJM/AdversarialConsistentScoreMatching", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising Score Matching with Annealed Langevin Sampling (DSM-ALS) has\nrecently found success in generative modeling. The approach works by first\ntraining a neural network to estimate the score of a distribution, and then\nusing Langevin dynamics to sample from the data distribution assumed by the\nscore network. Despite the convincing visual quality of samples, this method\nappears to perform worse than Generative Adversarial Networks (GANs) under the\nFr\\'echet Inception Distance, a standard metric for generative models.\n  We show that this apparent gap vanishes when denoising the final Langevin\nsamples using the score network. In addition, we propose two improvements to\nDSM-ALS: 1) Consistent Annealed Sampling as a more stable alternative to\nAnnealed Langevin Sampling, and 2) a hybrid training formulation, composed of\nboth Denoising Score Matching and adversarial objectives. By combining these\ntwo techniques and exploring different network architectures, we elevate score\nmatching methods and obtain results competitive with state-of-the-art image\ngeneration on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 14:49:53 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 19:47:12 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Jolicoeur-Martineau", "Alexia", ""], ["Pich\u00e9-Taillefer", "R\u00e9mi", ""], ["Combes", "R\u00e9mi Tachet des", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "2009.05478", "submitter": "Long Feng", "authors": "Long Feng and Junhui Wang", "title": "Projected Robust PCA with Application to Smooth Image Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most high-dimensional matrix recovery problems are studied under the\nassumption that the target matrix has certain intrinsic structures. For image\ndata related matrix recovery problems, approximate low-rankness and smoothness\nare the two most commonly imposed structures. For approximately low-rank matrix\nrecovery, the robust principal component analysis (PCA) is well-studied and\nproved to be effective. For smooth matrix problem, 2d fused Lasso and other\ntotal variation based approaches have played a fundamental role. Although both\nlow-rankness and smoothness are key assumptions for image data analysis, the\ntwo lines of research, however, have very limited interaction. Motivated by\ntaking advantage of both features, we in this paper develop a framework named\nprojected robust PCA (PRPCA), under which the low-rank matrices are projected\nonto a space of smooth matrices. Consequently, a large class of image matrices\ncan be decomposed as a low-rank and smooth component plus a sparse component. A\nkey advantage of this decomposition is that the dimension of the core low-rank\ncomponent can be significantly reduced. Consequently, our framework is able to\naddress a problematic bottleneck of many low-rank matrix problems: singular\nvalue decomposition (SVD) on large matrices. Theoretically, we provide explicit\nstatistical recovery guarantees of PRPCA and include classical robust PCA as a\nspecial case.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 11:23:30 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 12:45:27 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Feng", "Long", ""], ["Wang", "Junhui", ""]]}, {"id": "2009.05483", "submitter": "Francesco Alesiani", "authors": "Francesco Alesiani, Shujian Yu, Ammar Shaker and Wenzhe Yin", "title": "Towards Interpretable Multi-Task Learning Using Bilevel Programming", "comments": "Manuscript accepted at ECML PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable Multi-Task Learning can be expressed as learning a sparse graph\nof the task relationship based on the prediction performance of the learned\nmodels. Since many natural phenomenon exhibit sparse structures, enforcing\nsparsity on learned models reveals the underlying task relationship. Moreover,\ndifferent sparsification degrees from a fully connected graph uncover various\ntypes of structures, like cliques, trees, lines, clusters or fully disconnected\ngraphs. In this paper, we propose a bilevel formulation of multi-task learning\nthat induces sparse graphs, thus, revealing the underlying task relationships,\nand an efficient method for its computation. We show empirically how the\ninduced sparse graph improves the interpretability of the learned models and\ntheir relationship on synthetic and real data, without sacrificing\ngeneralization performance. Code at https://bit.ly/GraphGuidedMTL\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:04:27 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Alesiani", "Francesco", ""], ["Yu", "Shujian", ""], ["Shaker", "Ammar", ""], ["Yin", "Wenzhe", ""]]}, {"id": "2009.05484", "submitter": "Laura Nenzi", "authors": "Luca Bortolussi, Giuseppe Maria Gallo and Laura Nenzi", "title": "A kernel function for Signal Temporal Logic formulae", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss how to define a kernel for Signal Temporal Logic (STL) formulae.\nSuch a kernel allows us to embed the space of formulae into a Hilbert space,\nand opens up the use of kernel-based machine learning algorithms in the context\nof STL. We show an application of this idea to a regression problem in formula\nspace for probabilistic models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:06:25 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Bortolussi", "Luca", ""], ["Gallo", "Giuseppe Maria", ""], ["Nenzi", "Laura", ""]]}, {"id": "2009.05501", "submitter": "Divish Rengasamy", "authors": "Divish Rengasamy, Benjamin Rothwell, Grazziela Figueredo", "title": "Towards a More Reliable Interpretation of Machine Learning Outputs for\n  Safety-Critical Systems using Feature Importance Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When machine learning supports decision-making in safety-critical systems, it\nis important to verify and understand the reasons why a particular output is\nproduced. Although feature importance calculation approaches assist in\ninterpretation, there is a lack of consensus regarding how features' importance\nis quantified, which makes the explanations offered for the outcomes mostly\nunreliable. A possible solution to address the lack of agreement is to combine\nthe results from multiple feature importance quantifiers to reduce the variance\nof estimates. Our hypothesis is that this will lead to more robust and\ntrustworthy interpretations of the contribution of each feature to machine\nlearning predictions. To assist test this hypothesis, we propose an extensible\nFramework divided in four main parts: (i) traditional data pre-processing and\npreparation for predictive machine learning models; (ii) predictive machine\nlearning; (iii) feature importance quantification and (iv) feature importance\ndecision fusion using an ensemble strategy. We also introduce a novel fusion\nmetric and compare it to the state-of-the-art. Our approach is tested on\nsynthetic data, where the ground truth is known. We compare different fusion\napproaches and their results for both training and test sets. We also\ninvestigate how different characteristics within the datasets affect the\nfeature importance ensembles studied. Results show that our feature importance\nensemble Framework overall produces 15% less feature importance error compared\nto existing methods. Additionally, results reveal that different levels of\nnoise in the datasets do not affect the feature importance ensembles' ability\nto accurately quantify feature importance, whereas the feature importance\nquantification error increases with the number of features and number of\northogonal informative features.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:51:52 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Rengasamy", "Divish", ""], ["Rothwell", "Benjamin", ""], ["Figueredo", "Grazziela", ""]]}, {"id": "2009.05516", "submitter": "Andreas Groll", "authors": "Alexander Gerharz, Andreas Groll, Gunther Schauberger", "title": "Deducing neighborhoods of classes from a fitted model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In todays world the request for very complex models for huge data sets is\nrising steadily. The problem with these models is that by raising the\ncomplexity of the models, it gets much harder to interpret them. The growing\nfield of \\emph{interpretable machine learning} tries to make up for the lack of\ninterpretability in these complex (or even blackbox-)models by using specific\ntechniques that can help to understand those models better. In this article a\nnew kind of interpretable machine learning method is presented, which can help\nto understand the partitioning of the feature space into predicted classes in a\nclassification model using quantile shifts. To illustrate in which situations\nthis quantile shift method (QSM) could become beneficial, it is applied to a\ntheoretical medical example and a real data example. Basically, real data\npoints (or specific points of interest) are used and the changes of the\nprediction after slightly raising or decreasing specific features are observed.\nBy comparing the predictions before and after the manipulations, under certain\nconditions the observed changes in the predictions can be interpreted as\nneighborhoods of the classes with regard to the manipulated features.\nChordgraphs are used to visualize the observed changes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 16:35:53 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 09:47:20 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Gerharz", "Alexander", ""], ["Groll", "Andreas", ""], ["Schauberger", "Gunther", ""]]}, {"id": "2009.05530", "submitter": "Jonathan Brophy", "authors": "Jonathan Brophy and Daniel Lowd", "title": "TREX: Tree-Ensemble Representer-Point Explanations", "comments": "11 pages, 7 figures, and 4 tables. Submitted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we identify the training examples that contribute most to the\nprediction of a tree ensemble? In this paper, we introduce TREX, an explanation\nsystem that provides instance-attribution explanations for tree ensembles, such\nas random forests and gradient boosted trees. TREX builds on the representer\npoint framework previously developed for explaining deep neural networks. Since\ntree ensembles are non-differentiable, we define a kernel that captures the\nstructure of the specific tree ensemble. By using this kernel in kernel\nlogistic regression or a support vector machine, TREX builds a surrogate model\nthat approximates the original tree ensemble. The weights in the kernel\nexpansion of the surrogate model are used to define the global or local\nimportance of each training example.\n  Our experiments show that TREX's surrogate model accurately approximates the\ntree ensemble; its global importance weights are more effective in dataset\ndebugging than the previous state-of-the-art; its explanations identify the\nmost influential samples better than alternative methods under the remove and\nretrain evaluation framework; it runs orders of magnitude faster than\nalternative methods; and its local explanations can identify and explain errors\ndue to domain mismatch.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:06:40 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 04:57:03 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Brophy", "Jonathan", ""], ["Lowd", "Daniel", ""]]}, {"id": "2009.05537", "submitter": "Lichao Sun", "authors": "Lichao Sun, Lingjuan Lyu", "title": "Federated Model Distillation with Noise-Free Differential Privacy", "comments": "accepted by IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional federated learning directly averages model weights, which is\nonly possible for collaboration between models with homogeneous architectures.\nSharing prediction instead of weight removes this obstacle and eliminates the\nrisk of white-box inference attacks in conventional federated learning.\nHowever, the predictions from local models are sensitive and would leak\ntraining data privacy to the public. To address this issue, one naive approach\nis adding the differentially private random noise to the predictions, which\nhowever brings a substantial trade-off between privacy budget and model\nperformance. In this paper, we propose a novel framework called FEDMD-NFDP,\nwhich applies a Noise-Free Differential Privacy (NFDP) mechanism into a\nfederated model distillation framework. Our extensive experimental results on\nvarious datasets validate that FEDMD-NFDP can deliver not only comparable\nutility and communication efficiency but also provide a noise-free differential\nprivacy guarantee. We also demonstrate the feasibility of our FEDMD-NFDP by\nconsidering both IID and non-IID setting, heterogeneous model architectures,\nand unlabelled public datasets from a different distribution.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:19:56 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 11:16:47 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Sun", "Lichao", ""], ["Lyu", "Lingjuan", ""]]}, {"id": "2009.05567", "submitter": "Jonathan Brophy", "authors": "Jonathan Brophy and Daniel Lowd", "title": "Machine Unlearning for Random Forests", "comments": "29 pages, 5 figures, 9 tables, and 3 algorithms. Accepted at ICML\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responding to user data deletion requests, removing noisy examples, or\ndeleting corrupted training data are just a few reasons for wanting to delete\ninstances from a machine learning (ML) model. However, efficiently removing\nthis data from an ML model is generally difficult. In this paper, we introduce\ndata removal-enabled (DaRE) forests, a variant of random forests that enables\nthe removal of training data with minimal retraining. Model updates for each\nDaRE tree in the forest are exact, meaning that removing instances from a DaRE\nmodel yields exactly the same model as retraining from scratch on updated data.\n  DaRE trees use randomness and caching to make data deletion efficient. The\nupper levels of DaRE trees use random nodes, which choose split attributes and\nthresholds uniformly at random. These nodes rarely require updates because they\nonly minimally depend on the data. At the lower levels, splits are chosen to\ngreedily optimize a split criterion such as Gini index or mutual information.\nDaRE trees cache statistics at each node and training data at each leaf, so\nthat only the necessary subtrees are updated as data is removed. For numerical\nattributes, greedy nodes optimize over a random subset of thresholds, so that\nthey can maintain statistics while approximating the optimal threshold. By\nadjusting the number of thresholds considered for greedy nodes, and the number\nof random nodes, DaRE trees can trade off between more accurate predictions and\nmore efficient updates.\n  In experiments on 13 real-world datasets and one synthetic dataset, we find\nDaRE forests delete data orders of magnitude faster than retraining from\nscratch while sacrificing little to no predictive power.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:53:20 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 22:04:44 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Brophy", "Jonathan", ""], ["Lowd", "Daniel", ""]]}, {"id": "2009.05569", "submitter": "Katharina Rath", "authors": "Katharina Rath, Christopher G. Albert, Bernd Bischl, Udo von Toussaint", "title": "Symplectic Gaussian Process Regression of Hamiltonian Flow Maps", "comments": "24 pages, 9 figures", "journal-ref": null, "doi": "10.1063/5.0048129", "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an approach to construct appropriate and efficient emulators for\nHamiltonian flow maps. Intended future applications are long-term tracing of\nfast charged particles in accelerators and magnetic plasma confinement\nconfigurations. The method is based on multi-output Gaussian process regression\non scattered training data. To obtain long-term stability the symplectic\nproperty is enforced via the choice of the matrix-valued covariance function.\nBased on earlier work on spline interpolation we observe derivatives of the\ngenerating function of a canonical transformation. A product kernel produces an\naccurate implicit method, whereas a sum kernel results in a fast explicit\nmethod from this approach. Both correspond to a symplectic Euler method in\nterms of numerical integration. These methods are applied to the pendulum and\nthe H\\'enon-Heiles system and results compared to an symmetric regression with\northogonal polynomials. In the limit of small mapping times, the Hamiltonian\nfunction can be identified with a part of the generating function and thereby\nlearned from observed time-series data of the system's evolution. Besides\ncomparable performance of implicit kernel and spectral regression for\nsymplectic maps, we demonstrate a substantial increase in performance for\nlearning the Hamiltonian function compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:56:35 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Rath", "Katharina", ""], ["Albert", "Christopher G.", ""], ["Bischl", "Bernd", ""], ["von Toussaint", "Udo", ""]]}, {"id": "2009.05604", "submitter": "Yanmin Gong", "authors": "Rui Hu, Yanmin Gong", "title": "Trading Data For Learning: Incentive Mechanism For On-Device Federated\n  Learning", "comments": "Accepted by IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning rests on the notion of training a global model\ndistributedly on various devices. Under this setting, users' devices perform\ncomputations on their own data and then share the results with the cloud server\nto update the global model. A fundamental issue in such systems is to\neffectively incentivize user participation. The users suffer from privacy\nleakage of their local data during the federated model training process.\nWithout well-designed incentives, self-interested users will be unwilling to\nparticipate in federated learning tasks and contribute their private data. To\nbridge this gap, in this paper, we adopt the game theory to design an effective\nincentive mechanism, which selects users that are most likely to provide\nreliable data and compensates for their costs of privacy leakage. We formulate\nour problem as a two-stage Stackelberg game and solve the game's equilibrium.\nEffectiveness of the proposed mechanism is demonstrated by extensive\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:37:58 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hu", "Rui", ""], ["Gong", "Yanmin", ""]]}, {"id": "2009.05618", "submitter": "Shujian Yu", "authors": "Shujian Yu, Francesco Alesiani, Ammar Shaker, Wenzhe Yin", "title": "Learning an Interpretable Graph Structure in Multi-Task Learning", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology to jointly perform multi-task learning and\ninfer intrinsic relationship among tasks by an interpretable and sparse graph.\nUnlike existing multi-task learning methodologies, the graph structure is not\nassumed to be known a priori or estimated separately in a preprocessing step.\nInstead, our graph is learned simultaneously with model parameters of each\ntask, thus it reflects the critical relationship among tasks in the specific\nprediction problem. We characterize graph structure with its weighted adjacency\nmatrix and show that the overall objective can be optimized alternatively until\nconvergence. We also show that our methodology can be simply extended to a\nnonlinear form by being embedded into a multi-head radial basis function\nnetwork (RBFN). Extensive experiments, against six state-of-the-art\nmethodologies, on both synthetic data and real-world applications suggest that\nour methodology is able to reduce generalization error, and, at the same time,\nreveal a sparse graph over tasks that is much easier to interpret.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:58:14 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yu", "Shujian", ""], ["Alesiani", "Francesco", ""], ["Shaker", "Ammar", ""], ["Yin", "Wenzhe", ""]]}, {"id": "2009.05647", "submitter": "Murad Tukan", "authors": "Murad Tukan and Alaa Maalouf and Matan Weksler and Dan Feldman", "title": "Compressed Deep Networks: Goodbye SVD, Hello Robust Low-Rank\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common technique for compressing a neural network is to compute the\n$k$-rank $\\ell_2$ approximation $A_{k,2}$ of the matrix\n$A\\in\\mathbb{R}^{n\\times d}$ that corresponds to a fully connected layer (or\nembedding layer). Here, $d$ is the number of the neurons in the layer, $n$ is\nthe number in the next one, and $A_{k,2}$ can be stored in $O((n+d)k)$ memory\ninstead of $O(nd)$.\n  This $\\ell_2$-approximation minimizes the sum over every entry to the power\nof $p=2$ in the matrix $A - A_{k,2}$, among every matrix\n$A_{k,2}\\in\\mathbb{R}^{n\\times d}$ whose rank is $k$. While it can be computed\nefficiently via SVD, the $\\ell_2$-approximation is known to be very sensitive\nto outliers (\"far-away\" rows). Hence, machine learning uses e.g. Lasso\nRegression, $\\ell_1$-regularization, and $\\ell_1$-SVM that use the\n$\\ell_1$-norm.\n  This paper suggests to replace the $k$-rank $\\ell_2$ approximation by\n$\\ell_p$, for $p\\in [1,2]$. We then provide practical and provable\napproximation algorithms to compute it for any $p\\geq1$, based on modern\ntechniques in computational geometry.\n  Extensive experimental results on the GLUE benchmark for compressing BERT,\nDistilBERT, XLNet, and RoBERTa confirm this theoretical advantage. For example,\nour approach achieves $28\\%$ compression of RoBERTa's embedding layer with only\n$0.63\\%$ additive drop in the accuracy (without fine-tuning) in average over\nall tasks in GLUE, compared to $11\\%$ drop using the existing\n$\\ell_2$-approximation. Open code is provided for reproducing and extending our\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:21:42 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 12:24:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tukan", "Murad", ""], ["Maalouf", "Alaa", ""], ["Weksler", "Matan", ""], ["Feldman", "Dan", ""]]}, {"id": "2009.05660", "submitter": "Matthew Sotoudeh", "authors": "Matthew Sotoudeh and Aditya V. Thakur", "title": "Abstract Neural Networks", "comments": "Extended version of conference paper at the 27th Static Analysis\n  Symposium (SAS 2020). Code is available at\n  https://github.com/95616ARG/abstract_neural_networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are rapidly being applied to safety-critical\ndomains such as drone and airplane control, motivating techniques for verifying\nthe safety of their behavior. Unfortunately, DNN verification is NP-hard, with\ncurrent algorithms slowing exponentially with the number of nodes in the DNN.\nThis paper introduces the notion of Abstract Neural Networks (ANNs), which can\nbe used to soundly overapproximate DNNs while using fewer nodes. An ANN is like\na DNN except weight matrices are replaced by values in a given abstract domain.\nWe present a framework parameterized by the abstract domain and activation\nfunctions used in the DNN that can be used to construct a corresponding ANN. We\npresent necessary and sufficient conditions on the DNN activation functions for\nthe constructed ANN to soundly over-approximate the given DNN. Prior work on\nDNN abstraction was restricted to the interval domain and ReLU activation\nfunction. Our framework can be instantiated with other abstract domains such as\noctagons and polyhedra, as well as other activation functions such as Leaky\nReLU, Sigmoid, and Hyperbolic Tangent.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:17:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Thakur", "Aditya V.", ""]]}, {"id": "2009.05665", "submitter": "Qiyao Wang", "authors": "Aniruddha Rajendra Rao, Qiyao Wang, Haiyan Wang, Hamed Khorasgani,\n  Chetan Gupta", "title": "Spatio-Temporal Functional Neural Networks", "comments": "Accepted by 2020 IEEE International Conference on Data Science and\n  Advanced Analytics (DSAA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explosive growth in spatio-temporal data and its wide range of applications\nhave attracted increasing interests of researchers in the statistical and\nmachine learning fields. The spatio-temporal regression problem is of paramount\nimportance from both the methodology development and real-world application\nperspectives. Given the observed spatially encoded time series covariates and\nreal-valued response data samples, the goal of spatio-temporal regression is to\nleverage the temporal and spatial dependencies to build a mapping from\ncovariates to response with minimized prediction error. Prior arts, including\nthe convolutional Long Short-Term Memory (CovLSTM) and variations of the\nfunctional linear models, cannot learn the spatio-temporal information in a\nsimple and efficient format for proper model building. In this work, we propose\ntwo novel extensions of the Functional Neural Network (FNN), a temporal\nregression model whose effectiveness and superior performance over alternative\nsequential models have been proven by many researchers. The effectiveness of\nthe proposed spatio-temporal FNNs in handling varying spatial correlations is\ndemonstrated in comprehensive simulation studies. The proposed models are then\ndeployed to solve a practical and challenging precipitation prediction problem\nin the meteorology field.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:32:35 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Rao", "Aniruddha Rajendra", ""], ["Wang", "Qiyao", ""], ["Wang", "Haiyan", ""], ["Khorasgani", "Hamed", ""], ["Gupta", "Chetan", ""]]}, {"id": "2009.05669", "submitter": "Daniel Gibney", "authors": "Jason W. Bentley, Daniel Gibney, Gary Hoppenworth, Sumit Kumar Jha", "title": "Quantifying Membership Inference Vulnerability via Generalization Gap\n  and Other Model Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how a target model's generalization gap leads directly to an\neffective deterministic black box membership inference attack (MIA). This\nprovides an upper bound on how secure a model can be to MIA based on a simple\nmetric. Moreover, this attack is shown to be optimal in the expected sense\ngiven access to only certain likely obtainable metrics regarding the network's\ntraining and performance. Experimentally, this attack is shown to be comparable\nin accuracy to state-of-art MIAs in many cases.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:53:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bentley", "Jason W.", ""], ["Gibney", "Daniel", ""], ["Hoppenworth", "Gary", ""], ["Jha", "Sumit Kumar", ""]]}, {"id": "2009.05700", "submitter": "Syrine Belakaria", "authors": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "title": "Information-Theoretic Multi-Objective Bayesian Optimization with\n  Continuous Approximations", "comments": null, "journal-ref": "Workshop on machine learning for engineering modeling, simulation\n  and design @ NeurIPS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications involve black-box optimization of multiple\nobjectives using continuous function approximations that trade-off accuracy and\nresource cost of evaluation. For example, in rocket launching research, we need\nto find designs that trade-off return-time and angular distance using\ncontinuous-fidelity simulators (e.g., varying tolerance parameter to trade-off\nsimulation time and accuracy) for design evaluations. The goal is to\napproximate the optimal Pareto set by minimizing the cost for evaluations. In\nthis paper, we propose a novel approach referred to as information-Theoretic\nMulti-Objective Bayesian Optimization with Continuous Approximations (iMOCA)}\nto solve this problem. The key idea is to select the sequence of input and\nfunction approximations for multiple objectives which maximize the information\ngain per unit cost for the optimal Pareto front. Our experiments on diverse\nsynthetic and real-world benchmarks show that iMOCA significantly improves over\nexisting single-fidelity methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 01:46:03 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 17:33:38 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 01:46:09 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Belakaria", "Syrine", ""], ["Deshwal", "Aryan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2009.05739", "submitter": "Ze Cheng", "authors": "Ze Cheng, Juncheng Li, Chenxu Wang, Jixuan Gu, Hao Xu, Xinjian Li,\n  Florian Metze", "title": "Revisiting Factorizing Aggregated Posterior in Learning Disentangled\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of learning disentangled representations, one of the promising\nmethods is to factorize aggregated posterior by penalizing the total\ncorrelation of sampled latent variables. However, this well-motivated strategy\nhas a blind spot: there is a disparity between the sampled latent\nrepresentation and its corresponding mean representation. In this paper, we\nprovide a theoretical explanation that low total correlation of sampled\nrepresentation cannot guarantee low total correlation of the mean\nrepresentation. Indeed, we prove that for the multivariate normal\ndistributions, the mean representation with arbitrarily high total correlation\ncan have a corresponding sampled representation with bounded total correlation.\nWe also propose a method to eliminate this disparity. Experiments show that our\nmodel can learn a mean representation with much lower total correlation, hence\na factorized mean representation. Moreover, we offer a detailed explanation of\nthe limitations of factorizing aggregated posterior: factor disintegration. Our\nwork indicates a potential direction for future research of disentangled\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 07:31:30 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 05:14:21 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Cheng", "Ze", ""], ["Li", "Juncheng", ""], ["Wang", "Chenxu", ""], ["Gu", "Jixuan", ""], ["Xu", "Hao", ""], ["Li", "Xinjian", ""], ["Metze", "Florian", ""]]}, {"id": "2009.05786", "submitter": "Haoqing Wang", "authors": "Haoqing Wang, Zhi-Hong Deng", "title": "Few-shot Learning with LSSVM Base Learner and Transductive Modules", "comments": "9 pages,3 figures,3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of meta-learning approaches for few-shot learning generally\ndepends on three aspects: features suitable for comparison, the classifier (\nbase learner ) suitable for low-data scenarios, and valuable information from\nthe samples to classify. In this work, we make improvements for the last two\naspects: 1) although there are many effective base learners, there is a\ntrade-off between generalization performance and computational overhead, so we\nintroduce multi-class least squares support vector machine as our base learner\nwhich obtains better generation than existing ones with less computational\noverhead; 2) further, in order to utilize the information from the query\nsamples, we propose two simple and effective transductive modules which modify\nthe support set using the query samples, i.e., adjusting the support samples\nbasing on the attention mechanism and adding the prototypes of the query set\nwith pseudo labels to the support set as the pseudo support samples. These two\nmodules significantly improve the few-shot classification accuracy, especially\nfor the difficult 1-shot setting. Our model, denoted as FSLSTM (Few-Shot\nlearning with LSsvm base learner and Transductive Modules), achieves\nstate-of-the-art performance on miniImageNet and CIFAR-FS few-shot learning\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 13:16:55 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Haoqing", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "2009.05805", "submitter": "Ragunathan Mariappan", "authors": "Ragunathan Mariappan, Vaibhav Rajan", "title": "Multi-way Spectral Clustering of Augmented Multi-view Data through Deep\n  Collective Matrix Tri-factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present the first deep learning based architecture for collective matrix\ntri-factorization (DCMTF) of arbitrary collections of matrices, also known as\naugmented multi-view data. DCMTF can be used for multi-way spectral clustering\nof heterogeneous collections of relational data matrices to discover latent\nclusters in each input matrix, across both dimensions, as well as the strengths\nof association across clusters. The source code for DCMTF is available on our\npublic repository: https://bitbucket.org/cdal/dcmtf_generic\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 14:41:00 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mariappan", "Ragunathan", ""], ["Rajan", "Vaibhav", ""]]}, {"id": "2009.05837", "submitter": "Usman Khan", "authors": "Ran Xin, Shi Pu, Angelia Nedi\\'c, and Usman A. Khan", "title": "A general framework for decentralized optimization with first-order\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization to minimize a finite sum of functions over a\nnetwork of nodes has been a significant focus within control and signal\nprocessing research due to its natural relevance to optimal control and signal\nestimation problems. More recently, the emergence of sophisticated computing\nand large-scale data science needs have led to a resurgence of activity in this\narea. In this article, we discuss decentralized first-order gradient methods,\nwhich have found tremendous success in control, signal processing, and machine\nlearning problems, where such methods, due to their simplicity, serve as the\nfirst method of choice for many complex inference and training tasks. In\nparticular, we provide a general framework of decentralized first-order methods\nthat is applicable to undirected and directed communication networks alike, and\nshow that much of the existing work on optimization and consensus can be\nrelated explicitly to this framework. We further extend the discussion to\ndecentralized stochastic first-order methods that rely on stochastic gradients\nat each node and describe how local variance reduction schemes, previously\nshown to have promise in the centralized settings, are able to improve the\nperformance of decentralized methods when combined with what is known as\ngradient tracking. We motivate and demonstrate the effectiveness of the\ncorresponding methods in the context of machine learning and signal processing\nproblems that arise in decentralized environments.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:52:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Xin", "Ran", ""], ["Pu", "Shi", ""], ["Nedi\u0107", "Angelia", ""], ["Khan", "Usman A.", ""]]}, {"id": "2009.05847", "submitter": "Arash Hooshmand", "authors": "Arash Hooshmand", "title": "Machine Learning Against Cancer: Accurate Diagnosis of Cancer by Machine\n  Learning Classification of the Whole Genome Sequencing Data", "comments": "29 pages, 3 figures, 45 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can precisely identify different cancer tumors at any stage\nby classifying cancerous and healthy samples based on their genomic profile. We\nhave developed novel methods of MLAC (Machine Learning Against Cancer)\nachieving perfect results with perfect precision, sensitivity, and specificity.\nWe have used the whole genome sequencing data acquired by next-generation RNA\nsequencing techniques in The Cancer Genome Atlas and Genotype-Tissue Expression\nprojects for cancerous and healthy tissues respectively. Moreover, we have\nshown that unsupervised machine learning clustering has great potential to be\nused for cancer diagnosis. Indeed, a creative way to work with data and general\nalgorithms has resulted in perfect classification i.e. all precision,\nsensitivity, and specificity are equal to 1 for most of the different tumor\ntypes even with a modest amount of data, and the same method works well on a\nseries of cancers and results in great clustering of cancerous and healthy\nsamples too. Our system can be used in practice because once the classifier is\ntrained, it can be used to classify any new sample of new potential patients.\nOne advantage of our work is that the aforementioned perfect precision and\nrecall are obtained on samples of all stages including very early stages of\ncancer; therefore, it is a promising tool for diagnosis of cancers in early\nstages. Another advantage of our novel model is that it works with normalized\nvalues of RNA sequencing data, hence people's private sensitive medical data\nwill remain hidden, protected, and safe. This type of analysis will be\nwidespread and economical in the future and people can even learn to receive\ntheir RNA sequencing data and do their own preliminary cancer studies\nthemselves which have the potential to help the healthcare systems. It is a\ngreat step forward toward good health that is the main base of sustainable\nsocieties.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 18:51:47 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hooshmand", "Arash", ""]]}, {"id": "2009.05866", "submitter": "Nicholas Capel", "authors": "Nicholas Capel, Naifu Zhang", "title": "Extended Radial Basis Function Controller for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been attempts in reinforcement learning to exploit a priori\nknowledge about the structure of the system. This paper proposes a hybrid\nreinforcement learning controller which dynamically interpolates a model-based\nlinear controller and an arbitrary differentiable policy. The linear controller\nis designed based on local linearised model knowledge, and stabilises the\nsystem in a neighbourhood about an operating point. The coefficients of\ninterpolation between the two controllers are determined by a scaled distance\nfunction measuring the distance between the current state and the operating\npoint. The overall hybrid controller is proven to maintain the stability\nguarantee around the neighborhood of the operating point and still possess the\nuniversal function approximation property of the arbitrary non-linear policy.\nLearning has been done on both model-based (PILCO) and model-free (DDPG)\nframeworks. Simulation experiments performed in OpenAI gym demonstrate\nstability and robustness of the proposed hybrid controller. This paper thus\nintroduces a principled method allowing for the direct importing of control\nmethodology into reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 20:56:48 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 06:44:17 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Capel", "Nicholas", ""], ["Zhang", "Naifu", ""]]}, {"id": "2009.05870", "submitter": "Anru R. Zhang", "authors": "Yuetian Luo and Anru R. Zhang", "title": "Open Problem: Average-Case Hardness of Hypergraphic Planted Clique\n  Detection", "comments": "Published at Proceedings of Conference on Learning Theory, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We note the significance of hypergraphic planted clique (HPC) detection in\nthe investigation of computational hardness for a range of tensor problems. We\nask if more evidence for the computational hardness of HPC detection can be\ndeveloped. In particular, we conjecture if it is possible to establish the\nequivalence of the computational hardness between HPC and PC detection.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 21:55:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Luo", "Yuetian", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2009.05872", "submitter": "Yanmin Gong", "authors": "Zhidong Gao, Rui Hu, Yanmin Gong", "title": "Certified Robustness of Graph Classification against Topology Attack\n  with Randomized Smoothing", "comments": "Accepted to IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification has practical applications in diverse fields. Recent\nstudies show that graph-based machine learning models are especially vulnerable\nto adversarial perturbations due to the non i.i.d nature of graph data. By\nadding or deleting a small number of edges in the graph, adversaries could\ngreatly change the graph label predicted by a graph classification model. In\nthis work, we propose to build a smoothed graph classification model with\ncertified robustness guarantee. We have proven that the resulting graph\nclassification model would output the same prediction for a graph under $l_0$\nbounded adversarial perturbation. We also evaluate the effectiveness of our\napproach under graph convolutional network (GCN) based multi-class graph\nclassification model.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 22:18:54 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Gao", "Zhidong", ""], ["Hu", "Rui", ""], ["Gong", "Yanmin", ""]]}, {"id": "2009.05908", "submitter": "Anderson Tavares", "authors": "Anderson R. Tavares, Pedro Avelar, Jo\\~ao M. Flach, Marcio Nicolau,\n  Luis C. Lamb, Moshe Vardi", "title": "Understanding Boolean Function Learnability on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational learning theory states that many classes of boolean formulas\nare learnable in polynomial time. This paper addresses the understudied subject\nof how, in practice, such formulas can be learned by deep neural networks.\nSpecifically, we analyse boolean formulas associated with the decision version\nof combinatorial optimisation problems, model sampling benchmarks, and random\n3-CNFs with varying degrees of constrainedness. Our extensive experiments\nindicate that: (i) regardless of the combinatorial optimisation problem,\nrelatively small and shallow neural networks are very good approximators of the\nassociated formulas; (ii) smaller formulas seem harder to learn, possibly due\nto the fewer positive (satisfying) examples available; and (iii) interestingly,\nunderconstrained 3-CNF formulas are more challenging to learn than\noverconstrained ones. Source code and relevant datasets are publicly available\n(https://github.com/machine-reasoning-ufrgs/mlbf).\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 03:49:20 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 19:50:28 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Tavares", "Anderson R.", ""], ["Avelar", "Pedro", ""], ["Flach", "Jo\u00e3o M.", ""], ["Nicolau", "Marcio", ""], ["Lamb", "Luis C.", ""], ["Vardi", "Moshe", ""]]}, {"id": "2009.05923", "submitter": "Jiaqi Zeng", "authors": "Jiaqi Zeng, Pengtao Xie", "title": "Contrastive Self-supervised Learning for Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is a widely studied problem and has broad applications.\nIn many real-world problems, the number of labeled graphs available for\ntraining classification models is limited, which renders these models prone to\noverfitting. To address this problem, we propose two approaches based on\ncontrastive self-supervised learning (CSSL) to alleviate overfitting. In the\nfirst approach, we use CSSL to pretrain graph encoders on widely-available\nunlabeled graphs without relying on human-provided labels, then finetune the\npretrained encoders on labeled graphs. In the second approach, we develop a\nregularizer based on CSSL, and solve the supervised classification task and the\nunsupervised CSSL task simultaneously. To perform CSSL on graphs, given a\ncollection of original graphs, we perform data augmentation to create augmented\ngraphs out of the original graphs. An augmented graph is created by\nconsecutively applying a sequence of graph alteration operations. A contrastive\nloss is defined to learn graph encoders by judging whether two augmented graphs\nare from the same original graph. Experiments on various graph classification\ndatasets demonstrate the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 05:12:55 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zeng", "Jiaqi", ""], ["Xie", "Pengtao", ""]]}, {"id": "2009.05965", "submitter": "Khanh-Hung Tran", "authors": "Khanh-Hung Tran, Fred-Maurice Ngole-Mboula and Jean-Luc Starck", "title": "Manifold attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning in general and Deep Learning in particular has gained much\ninterest in the recent decade and has shown significant performance\nimprovements for many Computer Vision or Natural Language Processing tasks. In\norder to deal with databases which have just a small amount of training samples\nor to deal with models which have large amount of parameters, the\nregularization is indispensable. In this paper, we enforce the manifold\npreservation (manifold learning) from the original data into latent\npresentation by using \"manifold attack\". The later is inspired in a fashion of\nadversarial learning : finding virtual points that distort mostly the manifold\npreservation then using these points as supplementary samples to train the\nmodel. We show that our approach of regularization provides improvements for\nthe accuracy rate and for the robustness to adversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 09:39:32 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:17:34 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Tran", "Khanh-Hung", ""], ["Ngole-Mboula", "Fred-Maurice", ""], ["Starck", "Jean-Luc", ""]]}, {"id": "2009.05986", "submitter": "Aviv Rosenberg", "authors": "Aviv Rosenberg and Yishay Mansour", "title": "Oracle-Efficient Reinforcement Learning in Factored MDPs with Unknown\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study provably-efficient reinforcement learning in non-episodic factored\nMarkov decision processes (FMDPs). All previous regret minimization algorithms\nin this setting made the strong assumption that the factored structure of the\nFMDP is known to the learner in advance. In this paper, we provide the first\nalgorithm that learns the structure of the FMDP while minimizing the regret.\nOur algorithm is based on the optimism in face of uncertainty principle,\ncombined with a simple statistical method for structure learning, and can be\nimplemented efficiently given oracle-access to an FMDP planner. In addition, we\ngive a variant of our algorithm that remains efficient even when the oracle is\nlimited to non-factored actions, which is the case with almost all existing\napproximate planners. Finally, we also provide a novel lower bound for the\nknown structure case that matches the best known regret bound of Chen et al.\n(2020).\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 12:30:35 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 13:33:45 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 13:03:06 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Rosenberg", "Aviv", ""], ["Mansour", "Yishay", ""]]}, {"id": "2009.05990", "submitter": "Nived Rajaraman", "authors": "Nived Rajaraman, Lin F. Yang, Jiantao Jiao, Kannan Ramachandran", "title": "Toward the Fundamental Limits of Imitation Learning", "comments": "45 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning (IL) aims to mimic the behavior of an expert policy in a\nsequential decision-making problem given only demonstrations. In this paper, we\nfocus on understanding the minimax statistical limits of IL in episodic Markov\nDecision Processes (MDPs). We first consider the setting where the learner is\nprovided a dataset of $N$ expert trajectories ahead of time, and cannot\ninteract with the MDP. Here, we show that the policy which mimics the expert\nwhenever possible is in expectation $\\lesssim \\frac{|\\mathcal{S}| H^2 \\log\n(N)}{N}$ suboptimal compared to the value of the expert, even when the expert\nfollows an arbitrary stochastic policy. Here $\\mathcal{S}$ is the state space,\nand $H$ is the length of the episode. Furthermore, we establish a suboptimality\nlower bound of $\\gtrsim |\\mathcal{S}| H^2 / N$ which applies even if the expert\nis constrained to be deterministic, or if the learner is allowed to actively\nquery the expert at visited states while interacting with the MDP for $N$\nepisodes. To our knowledge, this is the first algorithm with suboptimality\nhaving no dependence on the number of actions, under no additional assumptions.\nWe then propose a novel algorithm based on minimum-distance functionals in the\nsetting where the transition model is given and the expert is deterministic.\nThe algorithm is suboptimal by $\\lesssim \\min \\{ H \\sqrt{|\\mathcal{S}| / N} ,\\\n|\\mathcal{S}| H^{3/2} / N \\}$, showing that knowledge of transition improves\nthe minimax rate by at least a $\\sqrt{H}$ factor.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 12:45:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Rajaraman", "Nived", ""], ["Yang", "Lin F.", ""], ["Jiao", "Jiantao", ""], ["Ramachandran", "Kannan", ""]]}, {"id": "2009.06002", "submitter": "Takashi Takekawa", "authors": "Takashi Takekawa", "title": "Clustering of non-Gaussian data by variational Bayes for normal inverse\n  Gaussian mixture models", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture models, typically Gaussian mixtures, are well known and widely\nused as model-based clustering. In practical situations, there are many\nnon-Gaussian data that are heavy-tailed and/or asymmetric. Normal inverse\nGaussian (NIG) distributions are normal-variance mean which mixing densities\nare inverse Gaussian distributions and can be used for both haavy-tail and\nasymmetry. For NIG mixture models, both expectation-maximization method and\nvariational Bayesian (VB) algorithms have been proposed. However, the existing\nVB algorithm for NIG mixture have a disadvantage that the shape of the mixing\ndensity is limited. In this paper, we propose another VB algorithm for NIG\nmixture that improves on the shortcomings. We also propose an extension of\nDirichlet process mixture models to overcome the difficulty in determining the\nnumber of clusters in finite mixture models. We evaluated the performance with\nartificial data and found that it outperformed Gaussian mixtures and existing\nimplementations for NIG mixtures, especially for highly non-normative data.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:13:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Takekawa", "Takashi", ""]]}, {"id": "2009.06005", "submitter": "Sudipta Paul Ms.", "authors": "Sudipta Paul, Poushali Sengupta and Subhankar Mishra", "title": "FLaPS: Federated Learning and Privately Scaling", "comments": "5 figures, 8 tables, Accepted to the SLICE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is a distributed learning process where the model\n(weights and checkpoints) is transferred to the devices that posses data rather\nthan the classical way of transferring and aggregating the data centrally. In\nthis way, sensitive data does not leave the user devices. FL uses the FedAvg\nalgorithm, which is trained in the iterative model averaging way, on the\nnon-iid and unbalanced distributed data, without depending on the data\nquantity. Some issues with the FL are, 1) no scalability, as the model is\niteratively trained over all the devices, which amplifies with device drops; 2)\nsecurity and privacy trade-off of the learning process still not robust enough\nand 3) overall communication efficiency and the cost are higher. To mitigate\nthese challenges we present Federated Learning and Privately Scaling (FLaPS)\narchitecture, which improves scalability as well as the security and privacy of\nthe system. The devices are grouped into clusters which further gives better\nprivacy scaled turn around time to finish a round of training. Therefore, even\nif a device gets dropped in the middle of training, the whole process can be\nstarted again after a definite amount of time. The data and model both are\ncommunicated using differentially private reports with iterative shuffling\nwhich provides a better privacy-utility trade-off. We evaluated FLaPS on MNIST,\nCIFAR10, and TINY-IMAGENET-200 dataset using various CNN models. Experimental\nresults prove FLaPS to be an improved, time and privacy scaled environment\nhaving better and comparable after-learning-parameters with respect to the\ncentral and FL models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:20:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Paul", "Sudipta", ""], ["Sengupta", "Poushali", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2009.06011", "submitter": "Berry Weinstein", "authors": "Berry Weinstein, Shai Fine, Yacov Hel-Or", "title": "Margin-Based Regularization and Selective Sampling in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new margin-based regularization formulation, termed multi-margin\nregularization (MMR), for deep neural networks (DNNs). The MMR is inspired by\nprinciples that were applied in margin analysis of shallow linear classifiers,\ne.g., support vector machine (SVM). Unlike SVM, MMR is continuously scaled by\nthe radius of the bounding sphere (i.e., the maximal norm of the feature vector\nin the data), which is constantly changing during training. We empirically\ndemonstrate that by a simple supplement to the loss function, our method\nachieves better results on various classification tasks across domains. Using\nthe same concept, we also derive a selective sampling scheme and demonstrate\naccelerated training of DNNs by selecting samples according to a minimal margin\nscore (MMS). This score measures the minimal amount of displacement an input\nshould undergo until its predicted classification is switched. We evaluate our\nproposed methods on three image classification tasks and six language text\nclassification tasks. Specifically, we show improved empirical results on\nCIFAR10, CIFAR100 and ImageNet using state-of-the-art convolutional neural\nnetworks (CNNs) and BERT-BASE architecture for the MNLI, QQP, QNLI, MRPC, SST-2\nand RTE benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 15:06:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Weinstein", "Berry", ""], ["Fine", "Shai", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "2009.06078", "submitter": "Andreas Groll", "authors": "Tobias Markus Krabel, Thi Ngoc Tien Tran, Andreas Groll, Daniel Horn,\n  Carsten Jentsch", "title": "Random boosting and random^2 forests -- A random tree depth injection\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The induction of additional randomness in parallel and sequential ensemble\nmethods has proven to be worthwhile in many aspects. In this manuscript, we\npropose and examine a novel random tree depth injection approach suitable for\nsequential and parallel tree-based approaches including Boosting and Random\nForests. The resulting methods are called \\emph{Random Boost} and\n\\emph{Random$^2$ Forest}. Both approaches serve as valuable extensions to the\nexisting literature on the gradient boosting framework and random forests. A\nMonte Carlo simulation, in which tree-shaped data sets with different numbers\nof final partitions are built, suggests that there are several scenarios where\n\\emph{Random Boost} and \\emph{Random$^2$ Forest} can improve the prediction\nperformance of conventional hierarchical boosting and random forest approaches.\nThe new algorithms appear to be especially successful in cases where there are\nmerely a few high-order interactions in the generated data. In addition, our\nsimulations suggest that our random tree depth injection approach can improve\ncomputation time by up to 40%, while at the same time the performance losses in\nterms of prediction accuracy turn out to be minor or even negligible in most\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 20:14:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Krabel", "Tobias Markus", ""], ["Tran", "Thi Ngoc Tien", ""], ["Groll", "Andreas", ""], ["Horn", "Daniel", ""], ["Jentsch", "Carsten", ""]]}, {"id": "2009.06086", "submitter": "Yuanyi Zhong", "authors": "Yuanyi Zhong, Yuan Zhou, Jian Peng", "title": "Efficient Competitive Self-Play Policy Optimization", "comments": "18 pages (10 for main text, 2 for reference, 8 for appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning from self-play has recently reported many successes.\nSelf-play, where the agents compete with themselves, is often used to generate\ntraining data for iterative policy improvement. In previous work, heuristic\nrules are designed to choose an opponent for the current learner. Typical rules\ninclude choosing the latest agent, the best agent, or a random historical\nagent. However, these rules may be inefficient in practice and sometimes do not\nguarantee convergence even in the simplest matrix games. In this paper, we\npropose a new algorithmic framework for competitive self-play reinforcement\nlearning in two-player zero-sum games. We recognize the fact that the Nash\nequilibrium coincides with the saddle point of the stochastic payoff function,\nwhich motivates us to borrow ideas from classical saddle point optimization\nliterature. Our method trains several agents simultaneously, and intelligently\ntakes each other as opponent based on simple adversarial rules derived from a\nprincipled perturbation-based saddle optimization method. We prove\ntheoretically that our algorithm converges to an approximate equilibrium with\nhigh probability in convex-concave games under standard assumptions. Beyond the\ntheory, we further show the empirical superiority of our method over baseline\nmethods relying on the aforementioned opponent-selection heuristics in matrix\ngames, grid-world soccer, Gomoku, and simulated robot sumo, with neural net\npolicy function approximators.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 21:01:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhong", "Yuanyi", ""], ["Zhou", "Yuan", ""], ["Peng", "Jian", ""]]}, {"id": "2009.06087", "submitter": "Alessandro Daniele", "authors": "Alessandro Daniele, Luciano Serafini", "title": "Neural Networks Enhancement through Prior Logical Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent past, there has been a growing interest in Neural-Symbolic\nIntegration frameworks, i.e., hybrid systems that integrate connectionist and\nsymbolic approaches: on the one hand, neural networks show remarkable abilities\nto learn from a large amount of data in presence of noise, on the other, pure\nsymbolic methods can perform reasoning as well as learning from few samples. By\ncombining the two paradigms, it should be possible to obtain a system that can\nboth learn from data and apply inference over some background knowledge. Here\nwe propose KENN (Knowledge Enhanced Neural Networks), a Neural-Symbolic\narchitecture that injects prior knowledge, codified in a set of universally\nquantified FOL clauses, into a neural network model. In KENN, clauses are used\nto generate a new final layer of the neural network which modifies the initial\npredictions based on the knowledge. Among the advantages of this strategy,\nthere is the possibility to include additional learnable parameters, the clause\nweights, each of which represents the strength of a specific clause. We\nevaluated KENN on two standard datasets for multi-label classification, showing\nthat the injection of clauses, automatically extracted from the training data,\nsensibly improves the performances. In a further experiment with manually\ncurated knowledge, KENN outperformed state-of-the-art methods on the VRD\nDataset, where the task is to classify relationships between detected objects\nin images. Finally, to evaluate how KENN deals with relational data, we tested\nit with different learning configurations on Citeseer, a standard dataset for\nCollective Classification. The obtained results show that KENN is capable of\nincreasing the performances of the underlying neural network even in the\npresence of relational data obtaining results in line with other methods that\ncombine learning with logic.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 21:12:20 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Daniele", "Alessandro", ""], ["Serafini", "Luciano", ""]]}, {"id": "2009.06107", "submitter": "Samuel Hopkins", "authors": "Matthew Brennan and Guy Bresler and Samuel B. Hopkins and Jerry Li and\n  Tselil Schramm", "title": "Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent", "comments": "Version 3 fixes typos and adds note on presentation at COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers currently use a number of approaches to predict and substantiate\ninformation-computation gaps in high-dimensional statistical estimation\nproblems. A prominent approach is to characterize the limits of restricted\nmodels of computation, which on the one hand yields strong computational lower\nbounds for powerful classes of algorithms and on the other hand helps guide the\ndevelopment of efficient algorithms. In this paper, we study two of the most\npopular restricted computational models, the statistical query framework and\nlow-degree polynomials, in the context of high-dimensional hypothesis testing.\nOur main result is that under mild conditions on the testing problem, the two\nclasses of algorithms are essentially equivalent in power. As corollaries, we\nobtain new statistical query lower bounds for sparse PCA, tensor PCA and\nseveral variants of the planted clique problem.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:55:18 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 05:28:15 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 17:06:23 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""], ["Hopkins", "Samuel B.", ""], ["Li", "Jerry", ""], ["Schramm", "Tselil", ""]]}, {"id": "2009.06108", "submitter": "Tongxin Zhou", "authors": "Tongxin Zhou, Yingfei Wang, Lu (Lucy) Yan, Yong Tan", "title": "Spoiled for Choice? Personalized Recommendation for Healthcare\n  Decisions: A Multi-Armed Bandit Approach", "comments": "39 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online healthcare communities provide users with various healthcare\ninterventions to promote healthy behavior and improve adherence. When faced\nwith too many intervention choices, however, individuals may find it difficult\nto decide which option to take, especially when they lack the experience or\nknowledge to evaluate different options. The choice overload issue may\nnegatively affect users' engagement in health management. In this study, we\ntake a design-science perspective to propose a recommendation framework that\nhelps users to select healthcare interventions. Taking into account that users'\nhealth behaviors can be highly dynamic and diverse, we propose a multi-armed\nbandit (MAB)-driven recommendation framework, which enables us to adaptively\nlearn users' preference variations while promoting recommendation diversity in\nthe meantime. To better adapt an MAB to the healthcare context, we synthesize\ntwo innovative model components based on prominent health theories. The first\ncomponent is a deep-learning-based feature engineering procedure, which is\ndesigned to learn crucial recommendation contexts in regard to users'\nsequential health histories, health-management experiences, preferences, and\nintrinsic attributes of healthcare interventions. The second component is a\ndiversity constraint, which structurally diversifies recommendations in\ndifferent dimensions to provide users with well-rounded support. We apply our\napproach to an online weight management context and evaluate it rigorously\nthrough a series of experiments. Our results demonstrate that each of the\ndesign components is effective and that our recommendation design outperforms a\nwide range of state-of-the-art recommendation systems. Our study contributes to\nthe research on the application of business intelligence and has implications\nfor multiple stakeholders, including online healthcare platforms, policymakers,\nand users.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:55:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhou", "Tongxin", "", "Lucy"], ["Wang", "Yingfei", "", "Lucy"], ["Lu", "", "", "Lucy"], ["Yan", "", ""], ["Tan", "Yong", ""]]}, {"id": "2009.06111", "submitter": "Viet Anh Nguyen", "authors": "Jose Blanchet and Yang Kang and Jose Luis Montiel Olea and Viet Anh\n  Nguyen and Xuhui Zhang", "title": "Machine Learning's Dropout Training is Distributionally Robust Optimal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper shows that dropout training in Generalized Linear Models is the\nminimax solution of a two-player, zero-sum game where an adversarial nature\ncorrupts a statistician's covariates using a multiplicative nonparametric\nerrors-in-variables model. In this game, nature's least favorable distribution\nis dropout noise, where nature independently deletes entries of the covariate\nvector with some fixed probability $\\delta$. This result implies that dropout\ntraining indeed provides out-of-sample expected loss guarantees for\ndistributions that arise from multiplicative perturbations of in-sample data.\nIn addition to the decision-theoretic analysis, the paper makes two more\ncontributions. First, there is a concrete recommendation on how to select the\ntuning parameter $\\delta$ to guarantee that, as the sample size grows large,\nthe in-sample loss after dropout training exceeds the true population loss with\nsome pre-specified probability. Second, the paper provides a novel,\nparallelizable, Unbiased Multi-Level Monte Carlo algorithm to speed-up the\nimplementation of dropout training. Our algorithm has a much smaller\ncomputational cost compared to the naive implementation of dropout, provided\nthe number of data points is much smaller than the dimension of the covariate\nvector.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:13:28 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 05:29:05 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Blanchet", "Jose", ""], ["Kang", "Yang", ""], ["Olea", "Jose Luis Montiel", ""], ["Nguyen", "Viet Anh", ""], ["Zhang", "Xuhui", ""]]}, {"id": "2009.06114", "submitter": "Peipei Xu", "authors": "Peipei Xu and Wenjie Ruan and Xiaowei Huang", "title": "Towards the Quantification of Safety Risks in Deep Neural Networks", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety concerns on the deep neural networks (DNNs) have been raised when they\nare applied to critical sectors. In this paper, we define safety risks by\nrequesting the alignment of the network's decision with human perception. To\nenable a general methodology for quantifying safety risks, we define a generic\nsafety property and instantiate it to express various safety risks. For the\nquantification of risks, we take the maximum radius of safe norm balls, in\nwhich no safety risk exists. The computation of the maximum safe radius is\nreduced to the computation of their respective Lipschitz metrics - the\nquantities to be computed. In addition to the known adversarial example,\nreachability example, and invariant example, in this paper we identify a new\nclass of risk - uncertainty example - on which humans can tell easily but the\nnetwork is unsure. We develop an algorithm, inspired by derivative-free\noptimization techniques and accelerated by tensor-based parallelization on\nGPUs, to support efficient computation of the metrics. We perform evaluations\non several benchmark neural networks, including ACSC-Xu, MNIST, CIFAR-10, and\nImageNet networks. The experiments show that, our method can achieve\ncompetitive performance on safety quantification in terms of the tightness and\nthe efficiency of computation. Importantly, as a generic approach, our method\ncan work with a broad class of safety risks and without restrictions on the\nstructure of neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:30:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Xu", "Peipei", ""], ["Ruan", "Wenjie", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2009.06125", "submitter": "Chao Ma", "authors": "Chao Ma, Lei Wu, Weinan E", "title": "A Qualitative Study of the Dynamic Behavior of Adaptive Gradient\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamic behavior of RMSprop and Adam algorithms is studied through a\ncombination of careful numerical experiments and theoretical explanations.\nThree types of qualitative features are observed in the training loss curve:\nfast initial convergence, oscillations and large spikes. The sign gradient\ndescent (signGD) algorithm, which is the limit of Adam when taking the learning\nrate to $0$ while keeping the momentum parameters fixed, is used to explain the\nfast initial convergence. For the late phase of Adam, three different types of\nqualitative patterns are observed depending on the choice of the\nhyper-parameters: oscillations, spikes and divergence. In particular, Adam\nconverges faster and smoother when the values of the two momentum factors are\nclose to each other.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 00:33:48 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ma", "Chao", ""], ["Wu", "Lei", ""], ["E", "Weinan", ""]]}, {"id": "2009.06132", "submitter": "Chao Ma", "authors": "Zhong Li and Chao Ma and Lei Wu", "title": "Complexity Measures for Neural Networks with General Activation\n  Functions Using Path-based Norms", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple approach is proposed to obtain complexity controls for neural\nnetworks with general activation functions. The approach is motivated by\napproximating the general activation functions with one-dimensional ReLU\nnetworks, which reduces the problem to the complexity controls of ReLU\nnetworks. Specifically, we consider two-layer networks and deep residual\nnetworks, for which path-based norms are derived to control complexities. We\nalso provide preliminary analyses of the function spaces induced by these norms\nand a priori estimates of the corresponding regularized estimators.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 01:15:11 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Li", "Zhong", ""], ["Ma", "Chao", ""], ["Wu", "Lei", ""]]}, {"id": "2009.06170", "submitter": "Qiaohui Lin", "authors": "Qiaohui Lin, Robert Lunde, Purnamrita Sarkar", "title": "Trading off Accuracy for Speedup: Multiplier Bootstraps for Subgraph\n  Counts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of multiplier bootstraps for count functionals. We\nconsider bootstrap procedures with linear and quadratic weights. These\ncorrespond to the first and second-order terms of the Hoeffding decomposition\nof the bootstrapped statistic arising from the multiplier bootstrap,\nrespectively. We show that the quadratic bootstrap procedure achieves\nhigher-order correctness for appropriately sparse graphs. The linear bootstrap\nprocedure requires fewer estimated network statistics, leading to improved\naccuracy over its higher-order correct counterpart in sparser regimes. To\nimprove the computational properties of the linear bootstrap further, we\nconsider fast sketching methods to conduct approximate subgraph counting and\nestablish consistency of the resulting bootstrap procedure. We complement our\ntheoretical results with a simulation study and real data analysis and verify\nthat our procedure offers state-of-the-art performance for several functionals.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 03:17:10 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 01:19:56 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 21:51:37 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Lin", "Qiaohui", ""], ["Lunde", "Robert", ""], ["Sarkar", "Purnamrita", ""]]}, {"id": "2009.06172", "submitter": "Nicholas Smith", "authors": "Nicholas Smith", "title": "The Shooting Regressor; Randomized Gradient-Based Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble method is introduced that utilizes randomization and loss\nfunction gradients to compute a prediction. Multiple weakly-correlated\nestimators approximate the gradient at randomly sampled points on the error\nsurface and are aggregated into a final solution. A scaling parameter is\ndescribed that controls a trade-off between ensemble correlation and precision.\nNumerical methods for estimating optimal values of the parameter are described.\nEmpirical results are computed over a popular dataset. Inferential statistics\non these results show that the method is capable of outperforming existing\ntechniques in terms of increased accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 03:20:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Smith", "Nicholas", ""]]}, {"id": "2009.06182", "submitter": "Matt Wand", "authors": "M.P. Wand and J.C.F. Yu", "title": "Density Estimation via Bayesian Inference Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain how effective automatic probability density function estimates can\nbe constructed using contemporary Bayesian inference engines such as those\nbased on no-U-turn sampling and expectation propagation. Extensive simulation\nstudies demonstrate that the proposed density estimates have excellent\ncomparative performance and scale well to very large sample sizes due a binning\nstrategy. Moreover, the approach is fully Bayesian and all estimates are\naccompanied by pointwise credible intervals. An accompanying package in the R\nlanguage facilitates easy use of the new density estimates.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 04:07:51 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 04:09:13 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 23:17:00 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Wand", "M. P.", ""], ["Yu", "J. C. F.", ""]]}, {"id": "2009.06183", "submitter": "Andrew Herren", "authors": "Andrew Herren, P. Richard Hahn", "title": "Semi-supervised learning and the question of true versus estimated\n  propensity scores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A straightforward application of semi-supervised machine learning to the\nproblem of treatment effect estimation would be to consider data as \"unlabeled\"\nif treatment assignment and covariates are observed but outcomes are\nunobserved. According to this formulation, large unlabeled data sets could be\nused to estimate a high dimensional propensity function and causal inference\nusing a much smaller labeled data set could proceed via weighted estimators\nusing the learned propensity scores. In the limiting case of infinite unlabeled\ndata, one may estimate the high dimensional propensity function exactly.\nHowever, longstanding advice in the causal inference community suggests that\nestimated propensity scores (from labeled data alone) are actually preferable\nto true propensity scores, implying that the unlabeled data is actually useless\nin this context. In this paper we examine this paradox and propose a simple\nprocedure that reconciles the strong intuition that a known propensity\nfunctions should be useful for estimating treatment effects with the previous\nliterature suggesting otherwise. Further, simulation studies suggest that\ndirect regression may be preferable to inverse-propensity weight estimators in\nmany circumstances.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 04:13:12 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Herren", "Andrew", ""], ["Hahn", "P. Richard", ""]]}, {"id": "2009.06190", "submitter": "Tao Zhang", "authors": "Tao Zhang, Tianqing Zhu, Mengde Han, Jing Li, Wanlei Zhou, Philip S.\n  Yu", "title": "Fairness Constraints in Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness in machine learning has received considerable attention. However,\nmost studies on fair learning focus on either supervised learning or\nunsupervised learning. Very few consider semi-supervised settings. Yet, in\nreality, most machine learning tasks rely on large datasets that contain both\nlabeled and unlabeled data. One of key issues with fair learning is the balance\nbetween fairness and accuracy. Previous studies arguing that increasing the\nsize of the training set can have a better trade-off. We believe that\nincreasing the training set with unlabeled data may achieve the similar result.\nHence, we develop a framework for fair semi-supervised learning, which is\nformulated as an optimization problem. This includes classifier loss to\noptimize accuracy, label propagation loss to optimize unlabled data prediction,\nand fairness constraints over labeled and unlabeled data to optimize the\nfairness level. The framework is conducted in logistic regression and support\nvector machines under the fairness metrics of disparate impact and disparate\nmistreatment. We theoretically analyze the source of discrimination in\nsemi-supervised learning via bias, variance and noise decomposition. Extensive\nexperiments show that our method is able to achieve fair semi-supervised\nlearning, and reach a better trade-off between accuracy and fairness than fair\nsupervised learning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 04:25:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Tianqing", ""], ["Han", "Mengde", ""], ["Li", "Jing", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2009.06192", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Johannes Rausch, Ce Zhang, Ruoxi Jia, Dawn Song", "title": "A Principled Approach to Data Valuation for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a popular technique to train machine learning (ML)\nmodels on decentralized data sources. In order to sustain long-term\nparticipation of data owners, it is important to fairly appraise each data\nsource and compensate data owners for their contribution to the training\nprocess. The Shapley value (SV) defines a unique payoff scheme that satisfies\nmany desiderata for a data value notion. It has been increasingly used for\nvaluing training data in centralized learning. However, computing the SV\nrequires exhaustively evaluating the model performance on every subset of data\nsources, which incurs prohibitive communication cost in the federated setting.\nBesides, the canonical SV ignores the order of data sources during training,\nwhich conflicts with the sequential nature of FL. This paper proposes a variant\nof the SV amenable to FL, which we call the federated Shapley value. The\nfederated SV preserves the desirable properties of the canonical SV while it\ncan be calculated without incurring extra communication cost and is also able\nto capture the effect of participation order on data value. We conduct a\nthorough empirical study of the federated SV on a range of tasks, including\nnoisy label detection, adversarial participant detection, and data\nsummarization on different benchmark datasets, and demonstrate that it can\nreflect the real utility of data sources for FL and has the potential to\nenhance system robustness, security, and efficiency. We also report and analyze\n\"failure cases\" and hope to stimulate future research.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 04:37:54 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Tianhao", ""], ["Rausch", "Johannes", ""], ["Zhang", "Ce", ""], ["Jia", "Ruoxi", ""], ["Song", "Dawn", ""]]}, {"id": "2009.06202", "submitter": "Johannes Lederer", "authors": "Johannes Lederer", "title": "Risk Bounds for Robust Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed that certain loss functions can render deep-learning\npipelines robust against flaws in the data. In this paper, we support these\nempirical findings with statistical theory. We especially show that\nempirical-risk minimization with unbounded, Lipschitz-continuous loss\nfunctions, such as the least-absolute deviation loss, Huber loss, Cauchy loss,\nand Tukey's biweight loss, can provide efficient prediction under minimal\nassumptions on the data. More generally speaking, our paper provides\ntheoretical evidence for the benefits of robust loss functions in deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 05:06:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lederer", "Johannes", ""]]}, {"id": "2009.06211", "submitter": "Fangda Gu", "authors": "Fangda Gu, Heng Chang, Wenwu Zhu, Somayeh Sojoudi, Laurent El Ghaoui", "title": "Implicit Graph Neural Networks", "comments": "Accepted by NeurIPS 2020 at:\n  https://papers.nips.cc/paper/2020/hash/8b5c8441a8ff8e151b191c53c1842a38-Abstract.html", "journal-ref": "Advances in Neural Information Processing Systems 33 (2020)\n  11984-11995", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) are widely used deep learning models that learn\nmeaningful representations from graph-structured data. Due to the finite nature\nof the underlying recurrent structure, current GNN methods may struggle to\ncapture long-range dependencies in underlying graphs. To overcome this\ndifficulty, we propose a graph learning framework, called Implicit Graph Neural\nNetworks (IGNN), where predictions are based on the solution of a fixed-point\nequilibrium equation involving implicitly defined \"state\" vectors. We use the\nPerron-Frobenius theory to derive sufficient conditions that ensure\nwell-posedness of the framework. Leveraging implicit differentiation, we derive\na tractable projected gradient descent method to train the framework.\nExperiments on a comprehensive range of tasks show that IGNNs consistently\ncapture long-range dependencies and outperform the state-of-the-art GNN models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:04:55 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 19:17:06 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 07:21:32 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Gu", "Fangda", ""], ["Chang", "Heng", ""], ["Zhu", "Wenwu", ""], ["Sojoudi", "Somayeh", ""], ["Ghaoui", "Laurent El", ""]]}, {"id": "2009.06218", "submitter": "Jing Ji", "authors": "Fanglan Zheng, Erihe, Kun Li, Jiang Tian, Xiaojia Xiang", "title": "A Vertical Federated Learning Method for Interpretable Scorecard and Its\n  Application in Credit Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of big data and artificial intelligence in many fields, the\napplications of big data driven models are expected in financial risk\nmanagement especially credit scoring and rating. Under the premise of data\nprivacy protection, we propose a projected gradient-based method in the\nvertical federated learning framework for the traditional scorecard, which is\nbased on logistic regression with bounded constraints, namely FL-LRBC. The\nlatter enables multiple agencies to jointly train an optimized scorecard model\nin a single training session. It leads to the formation of the model with\npositive coefficients, while the time-consuming parameter-tuning process can be\navoided. Moreover, the performance in terms of both AUC and the\nKolmogorov-Smirnov (KS) statistics is significantly improved due to data\nenrichment using FL-LRBC. At present, FL-LRBC has already been applied to\ncredit business in a China nation-wide financial holdings group.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:26:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zheng", "Fanglan", ""], ["Erihe", "", ""], ["Li", "Kun", ""], ["Tian", "Jiang", ""], ["Xiang", "Xiaojia", ""]]}, {"id": "2009.06227", "submitter": "Pierre-Alexandre Murena", "authors": "Mustafa Mert Celikok, Pierre-Alexandre Murena, Samuel Kaski", "title": "Teaching to Learn: Sequential Teaching of Agents with Inner States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequential machine teaching, a teacher's objective is to provide the\noptimal sequence of inputs to sequential learners in order to guide them\ntowards the best model. In this paper we extend this setting from current\nstatic one-data-set analyses to learners which change their learning algorithm\nor latent state to improve during learning, and to generalize to new datasets.\nWe introduce a multi-agent formulation in which learners' inner state may\nchange with the teaching interaction, which affects the learning performance in\nfuture tasks. In order to teach such learners, we propose an optimal control\napproach that takes the future performance of the learner after teaching into\naccount. This provides tools for modelling learners having inner states, and\nmachine teaching of meta-learning algorithms. Furthermore, we distinguish\nmanipulative teaching, which can be done by effectively hiding data and also\nused for indoctrination, from more general education which aims to help the\nlearner become better at generalization and learning in new datasets in the\nabsence of a teacher.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:03:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Celikok", "Mustafa Mert", ""], ["Murena", "Pierre-Alexandre", ""], ["Kaski", "Samuel", ""]]}, {"id": "2009.06228", "submitter": "Yijue Wang", "authors": "Yijue Wang, Jieren Deng, Dan Guo, Chenghong Wang, Xianrui Meng, Hang\n  Liu, Caiwen Ding, Sanguthevar Rajasekaran", "title": "SAPAG: A Self-Adaptive Privacy Attack From Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning such as federated learning or collaborative learning\nenables model training on decentralized data from users and only collects local\ngradients, where data is processed close to its sources for data privacy. The\nnature of not centralizing the training data addresses the privacy issue of\nprivacy-sensitive data. Recent studies show that a third party can reconstruct\nthe true training data in the distributed machine learning system through the\npublicly-shared gradients. However, existing reconstruction attack frameworks\nlack generalizability on different Deep Neural Network (DNN) architectures and\ndifferent weight distribution initialization, and can only succeed in the early\ntraining phase. To address these limitations, in this paper, we propose a more\ngeneral privacy attack from gradient, SAPAG, which uses a Gaussian kernel based\nof gradient difference as a distance measure. Our experiments demonstrate that\nSAPAG can construct the training data on different DNNs with different weight\ninitializations and on DNNs in any training phases.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:04:02 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Yijue", ""], ["Deng", "Jieren", ""], ["Guo", "Dan", ""], ["Wang", "Chenghong", ""], ["Meng", "Xianrui", ""], ["Liu", "Hang", ""], ["Ding", "Caiwen", ""], ["Rajasekaran", "Sanguthevar", ""]]}, {"id": "2009.06231", "submitter": "Jun Yin", "authors": "Jun Yin, Qian Li, Shaowu Liu, Zhiang Wu, Guandong Xu", "title": "Leveraging Multi-level Dependency of Relational Sequences for Social\n  Spammer Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent research has shed light on the development of the\nrelation-dependent but content-independent framework for social spammer\ndetection. This is largely because the relation among users is difficult to be\naltered when spammers attempt to conceal their malicious intents. Our study\ninvestigates the spammer detection problem in the context of multi-relation\nsocial networks, and makes an attempt to fully exploit the sequences of\nheterogeneous relations for enhancing the detection accuracy. Specifically, we\npresent the Multi-level Dependency Model (MDM). The MDM is able to exploit\nuser's long-term dependency hidden in their relational sequences along with\nshort-term dependency. Moreover, MDM fully considers short-term relational\nsequences from the perspectives of individual-level and union-level, due to the\nfact that the type of short-term sequences is multi-folds. Experimental results\non a real-world multi-relational social network demonstrate the effectiveness\nof our proposed MDM on multi-relational social spammer detection.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:11:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yin", "Jun", ""], ["Li", "Qian", ""], ["Liu", "Shaowu", ""], ["Wu", "Zhiang", ""], ["Xu", "Guandong", ""]]}, {"id": "2009.06237", "submitter": "Jinho Lee", "authors": "Kanghyun Choi, Deokki Hong, Hojae Yoon, Joonsang Yu, Youngsok Kim,\n  Jinho Lee", "title": "DANCE: Differentiable Accelerator/Network Co-Exploration", "comments": "Accepted to DAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the ever-increasing computational demand of the DNN execution,\nrecent neural architecture search (NAS) algorithms consider hardware cost\nmetrics into account, such as GPU latency. To further pursue a fast, efficient\nexecution, DNN-specialized hardware accelerators are being designed for\nmultiple purposes, which far-exceeds the efficiency of the GPUs. However, those\nhardware-related metrics have been proven to exhibit non-linear relationships\nwith the network architectures. Therefore it became a chicken-and-egg problem\nto optimize the network against the accelerator, or to optimize the accelerator\nagainst the network. In such circumstances, this work presents DANCE, a\ndifferentiable approach towards the co-exploration of the hardware accelerator\nand network architecture design. At the heart of DANCE is a differentiable\nevaluator network. By modeling the hardware evaluation software with a neural\nnetwork, the relation between the accelerator architecture and the hardware\nmetrics becomes differentiable, allowing the search to be performed with\nbackpropagation. Compared to the naive existing approaches, our method performs\nco-exploration in a significantly shorter time, while achieving superior\naccuracy and hardware cost metrics.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:43:27 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 12:14:17 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 04:41:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Choi", "Kanghyun", ""], ["Hong", "Deokki", ""], ["Yoon", "Hojae", ""], ["Yu", "Joonsang", ""], ["Kim", "Youngsok", ""], ["Lee", "Jinho", ""]]}, {"id": "2009.06303", "submitter": "Pengqian Yu", "authors": "Pengqian Yu, Achintya Kundu, Laura Wynter, Shiau Hong Lim", "title": "Fed+: A Unified Approach to Robust Personalized Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of methods for robust, personalized federated learning,\ncalled Fed+, that unifies many federated learning algorithms. The principal\nadvantage of this class of methods is to better accommodate the real-world\ncharacteristics found in federated training, such as the lack of IID data\nacross parties, the need for robustness to outliers or stragglers, and the\nrequirement to perform well on party-specific datasets. We achieve this through\na problem formulation that allows the central server to employ robust ways of\naggregating the local models while keeping the structure of local computation\nintact. Without making any statistical assumption on the degree of\nheterogeneity of local data across parties, we provide convergence guarantees\nfor Fed+ for convex and non-convex loss functions and robust aggregation. The\nFed+ theory is also equipped to handle heterogeneous computing environments\nincluding stragglers without additional assumptions; specifically, the\nconvergence results cover the general setting where the number of local update\nsteps across parties can vary. We demonstrate the benefits of Fed+ through\nextensive experiments across standard benchmark datasets as well as on a\nchallenging real-world problem in financial portfolio management where the\nheterogeneity of party-level data can lead to training failure in standard\nfederated learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 10:04:30 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 03:24:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yu", "Pengqian", ""], ["Kundu", "Achintya", ""], ["Wynter", "Laura", ""], ["Lim", "Shiau Hong", ""]]}, {"id": "2009.06304", "submitter": "Qi Tan", "authors": "Qi Tan, Yang Liu, Jiming Liu", "title": "Demystifying Deep Learning in Predictive Spatio-Temporal Analytics: An\n  Information-Theoretic Framework", "comments": "35 pages, 8 figures", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3015215", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved incredible success over the past years, especially\nin various challenging predictive spatio-temporal analytics (PSTA) tasks, such\nas disease prediction, climate forecast, and traffic prediction, where\nintrinsic dependency relationships among data exist and generally manifest at\nmultiple spatio-temporal scales. However, given a specific PSTA task and the\ncorresponding dataset, how to appropriately determine the desired configuration\nof a deep learning model, theoretically analyze the model's learning behavior,\nand quantitatively characterize the model's learning capacity remains a\nmystery. In order to demystify the power of deep learning for PSTA, in this\npaper, we provide a comprehensive framework for deep learning model design and\ninformation-theoretic analysis. First, we develop and demonstrate a novel\ninteractively- and integratively-connected deep recurrent neural network\n(I$^2$DRNN) model. I$^2$DRNN consists of three modules: an Input module that\nintegrates data from heterogeneous sources; a Hidden module that captures the\ninformation at different scales while allowing the information to flow\ninteractively between layers; and an Output module that models the integrative\neffects of information from various hidden layers to generate the output\npredictions. Second, to theoretically prove that our designed model can learn\nmulti-scale spatio-temporal dependency in PSTA tasks, we provide an\ninformation-theoretic analysis to examine the information-based learning\ncapacity (i-CAP) of the proposed model. Third, to validate the I$^2$DRNN model\nand confirm its i-CAP, we systematically conduct a series of experiments\ninvolving both synthetic datasets and real-world PSTA tasks. The experimental\nresults show that the I$^2$DRNN model outperforms both classical and\nstate-of-the-art models, and is able to capture meaningful multi-scale\nspatio-temporal dependency.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 10:05:14 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 09:21:27 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Tan", "Qi", ""], ["Liu", "Yang", ""], ["Liu", "Jiming", ""]]}, {"id": "2009.06332", "submitter": "Jiacheng Ruan", "authors": "Jiacheng Ruan and Jiahao Li", "title": "Adaptive Generation Model: A New Ensemble Method", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a common method in Machine Learning, Ensemble Method is used to train\nmultiple models from a data set and obtain better results through certain\ncombination strategies. Stacking method, as representatives of Ensemble\nLearning methods, is often used in Machine Learning Competitions such as\nKaggle. This paper proposes a variant of Stacking Model based on the idea of\ngcForest, namely Adaptive Generation Model (AGM). It means that the adaptive\ngeneration is performed not only in the horizontal direction to expand the\nwidth of each layer model, but also in the vertical direction to expand the\ndepth of the model. For base models of AGM, they all come from preset basic\nMachine Learning Models. In addition, a feature augmentation method is added\nbetween layers to further improve the overall accuracy of the model. Finally,\nthrough comparative experiments on 7 data sets, the results show that the\naccuracy of AGM are better than its previous models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 11:34:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ruan", "Jiacheng", ""], ["Li", "Jiahao", ""]]}, {"id": "2009.06342", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en and Alexander Schulz and Terrence C. Stewart and\n  Barbara Hammer", "title": "Reservoir Memory Machines as Neural Computers", "comments": "In print at the special issue 'New Frontiers in Extremely Efficient\n  Reservoir Computing' of IEEE TNNLS", "journal-ref": null, "doi": "10.1109/TNNLS.2021.3094139", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable neural computers extend artificial neural networks with an\nexplicit memory without interference, thus enabling the model to perform\nclassic computation tasks such as graph traversal. However, such models are\ndifficult to train, requiring long training times and large datasets. In this\nwork, we achieve some of the computational capabilities of differentiable\nneural computers with a model that can be trained very efficiently, namely an\necho state network with an explicit memory without interference. This extension\nenables echo state networks to recognize all regular languages, including those\nthat contractive echo state networks provably can not recognize. Further, we\ndemonstrate experimentally that our model performs comparably to its\nfully-trained deep version on several typical benchmark tasks for\ndifferentiable neural computers.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:01:30 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 08:57:42 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""], ["Schulz", "Alexander", ""], ["Stewart", "Terrence C.", ""], ["Hammer", "Barbara", ""]]}, {"id": "2009.06343", "submitter": "Selahattin Serdar Helli", "authors": "Selahattin Serdar Helli, \\c{C}a\\u{g}kan Dem\\.irc\\.i, Onur \\c{C}oban\n  and Anda\\c{c} Hamamci", "title": "Short-Term Forecasting COVID-19 Cases In Turkey Using Long Short-Term\n  Memory Network", "comments": "4 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has been one of the most severe diseases, causing a harsh pandemic\nall over the world, since December 2019. The aim of this study is to evaluate\nthe value of Long Short-Term Memory (LSTM) Networks in forecasting the total\nnumber of COVID-19 cases in Turkey. The COVID-19 data for 30 days, between\nMarch 24 and April 23, 2020, are used to estimate the next fifteen days. The\nmean absolute error of the LSTM Network for 15 days estimation is\n1,69$\\pm$1.35%. Whereas, for the same data, the error of the Box-Jenkins method\nis 3.24$\\pm$1.56%, Prophet method is 6.88$\\pm$4.96% and Holt-Winters Additive\nmethod with Damped Trend is 0.47$\\pm$0.28%. Additionally, when the number of\ndeaths data is also provided with the number of total cases to the input of\nLSTM Network, the mean error reduces to 0.99$\\pm$0.51%. Consequently, addition\nof the number of deaths data to the input, results a lower error in\nforecasting, compared to using only the number of total cases as the input.\nHowever, Holt-Winters Additive method with Damped Trend gives superior results\nto LSTM Networks in forecasting the total number of COVID-19 cases.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:01:40 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 12:10:32 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Helli", "Selahattin Serdar", ""], ["Demirci", "\u00c7a\u011fkan", ""], ["\u00c7oban", "Onur", ""], ["Hamamci", "Anda\u00e7", ""]]}, {"id": "2009.06356", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Adam Summerville, Sam Snodgrass, Gerard Bentley, Joseph\n  Osborn", "title": "Exploring Level Blending across Platformers via Paths and Affordances", "comments": "6 pages, 5 figures, 16th AAAI Conference on Artificial Intelligence\n  and Interactive Digital Entertainment (AIIDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for procedural content generation via machine learning (PCGML)\nhave been shown to be useful for generating novel game content. While used\nprimarily for producing new content in the style of the game domain used for\ntraining, recent works have increasingly started to explore methods for\ndiscovering and generating content in novel domains via techniques such as\nlevel blending and domain transfer. In this paper, we build on these works and\nintroduce a new PCGML approach for producing novel game content spanning\nmultiple domains. We use a new affordance and path vocabulary to encode data\nfrom six different platformer games and train variational autoencoders on this\ndata, enabling us to capture the latent level space spanning all the domains\nand generate new content with varying proportions of the different domains.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:43:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sarkar", "Anurag", ""], ["Summerville", "Adam", ""], ["Snodgrass", "Sam", ""], ["Bentley", "Gerard", ""], ["Osborn", "Joseph", ""]]}, {"id": "2009.06358", "submitter": "Mehrdad Yousefzadeh", "authors": "Ruixiao Sun, Jie Yang, Mehrdad Yousefzadeh", "title": "Improving Language Generation with Sentence Coherence Objective", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional story generation and contextual text continuation have become\nincreasingly popular topics in NLP community. Existing models are often prone\nto output paragraphs of texts that gradually diverge from the given prompt.\nAlthough the generated text may have a reasonable perplexity and diversity, it\ncould easily be identified by human as gibberish. The goal of our project is to\nimprove the coherence and consistency across sentences in a language-generation\nmodel. We aim to solve this issue by first training a sentence pair coherence\nclassifier with GPT-2 pretrained model, and then co-train the GPT-2 language\nmodel with this new coherence objective using a method analogous to the\nREINFORCE algorithm. This fine-tuned language model is able to generate lengthy\nparagraph conditioned on a given topic without diverging too much. The\nsimplicity of this model allows it to be applicable to a variety of underlying\nlanguage model architecture since it only modifies the final layer of the\npre-trained model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 06:10:03 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sun", "Ruixiao", ""], ["Yang", "Jie", ""], ["Yousefzadeh", "Mehrdad", ""]]}, {"id": "2009.06373", "submitter": "Huale Li", "authors": "Huale Li, Xuan Wang, Fengwei Jia, Yifan Li, Yulin Wu, Jiajia Zhang,\n  Shuhan Qi", "title": "RLCFR: Minimize Counterfactual Regret by Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual regret minimization (CFR) is a popular method to deal with\ndecision-making problems of two-player zero-sum games with imperfect\ninformation. Unlike existing studies that mostly explore for solving larger\nscale problems or accelerating solution efficiency, we propose a framework,\nRLCFR, which aims at improving the generalization ability of the CFR method. In\nthe RLCFR, the game strategy is solved by the CFR in a reinforcement learning\nframework. And the dynamic procedure of iterative interactive strategy updating\nis modeled as a Markov decision process (MDP). Our method, RLCFR, then learns a\npolicy to select the appropriate way of regret updating in the process of\niteration. In addition, a stepwise reward function is formulated to learn the\naction policy, which is proportional to how well the iteration strategy is at\neach step. Extensive experimental results on various games have shown that the\ngeneralization ability of our method is significantly improved compared with\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:20:33 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Li", "Huale", ""], ["Wang", "Xuan", ""], ["Jia", "Fengwei", ""], ["Li", "Yifan", ""], ["Wu", "Yulin", ""], ["Zhang", "Jiajia", ""], ["Qi", "Shuhan", ""]]}, {"id": "2009.06375", "submitter": "Nickil Maveli", "authors": "Nickil Maveli", "title": "EdinburghNLP at WNUT-2020 Task 2: Leveraging Transformers with\n  Generalized Augmentation for Identifying Informativeness in COVID-19 Tweets", "comments": "Accepted at W-NUT workshop of EMNLP 2020 (7 pages, 6 figures, 3\n  tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter and, in general, social media has become an indispensable\ncommunication channel in times of emergency. The ubiquitousness of smartphone\ngadgets enables people to declare an emergency observed in real-time. As a\nresult, more agencies are interested in programmatically monitoring Twitter\n(disaster relief organizations and news agencies). Therefore, recognizing the\ninformativeness of a Tweet can help filter noise from the large volumes of\nTweets. In this paper, we present our submission for WNUT-2020 Task 2:\nIdentification of informative COVID-19 English Tweets. Our most successful\nmodel is an ensemble of transformers, including RoBERTa, XLNet, and BERTweet\ntrained in a Semi-Supervised Learning (SSL) setting. The proposed system\nachieves an F1 score of 0.9011 on the test set (ranking 7th on the leaderboard)\nand shows significant gains in performance compared to a baseline system using\nFastText embeddings.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 15:57:28 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:47:10 GMT"}, {"version": "v3", "created": "Sun, 18 Apr 2021 12:28:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Maveli", "Nickil", ""]]}, {"id": "2009.06389", "submitter": "Sahib Singh", "authors": "Tom Farrand, Fatemehsadat Mireshghallah, Sahib Singh, Andrew Trask", "title": "Neither Private Nor Fair: Impact of Data Imbalance on Utility and\n  Fairness in Differential Privacy", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of deep learning in different fields and industries is growing day\nby day due to its performance, which relies on the availability of data and\ncompute. Data is often crowd-sourced and contains sensitive information about\nits contributors, which leaks into models that are trained on it. To achieve\nrigorous privacy guarantees, differentially private training mechanisms are\nused. However, it has recently been shown that differential privacy can\nexacerbate existing biases in the data and have disparate impacts on the\naccuracy of different subgroups of data. In this paper, we aim to study these\neffects within differentially private deep learning. Specifically, we aim to\nstudy how different levels of imbalance in the data affect the accuracy and the\nfairness of the decisions made by the model, given different levels of privacy.\nWe demonstrate that even small imbalances and loose privacy guarantees can\ncause disparate impacts.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:35:49 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 16:00:29 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 11:55:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Farrand", "Tom", ""], ["Mireshghallah", "Fatemehsadat", ""], ["Singh", "Sahib", ""], ["Trask", "Andrew", ""]]}, {"id": "2009.06402", "submitter": "Liesbeth Allein", "authors": "Liesbeth Allein, Isabelle Augenstein and Marie-Francine Moens", "title": "Time-Aware Evidence Ranking for Fact-Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truth can vary over time. Fact-checking decisions on claim veracity should\ntherefore take into account temporal information of both the claim and\nsupporting or refuting evidence. In this work, we investigate the hypothesis\nthat the timestamp of a Web page is crucial to how it should be ranked for a\ngiven claim. We delineate four temporal ranking methods that constrain evidence\nranking differently and simulate hypothesis-specific evidence rankings given\nthe evidence timestamps as gold standard. Evidence ranking in three\nfact-checking models is ultimately optimized using a learning-to-rank loss\nfunction. Our study reveals that time-aware evidence ranking not only surpasses\nrelevance assumptions based purely on semantic similarity or position in a\nsearch results list, but also improves veracity predictions of time-sensitive\nclaims in particular.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:39:49 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 09:15:20 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Allein", "Liesbeth", ""], ["Augenstein", "Isabelle", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2009.06403", "submitter": "Annika Pick", "authors": "Annika Pick, Sebastian Ginzel, Stefan R\\\"uping, Jil Sander, Ann\n  Christina Foldenauer, Michaela K\\\"ohm", "title": "Aligning Subjective Ratings in Clinical Decision Making", "comments": "Accepted at the ECML 2020 workshop on Machine Learning for Pharma and\n  Healthcare Applications (PharML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to objective indicators (e.g. laboratory values), clinical data\noften contain subjective evaluations by experts (e.g. disease severity\nassessments). While objective indicators are more transparent and robust, the\nsubjective evaluation contains a wealth of expert knowledge and intuition. In\nthis work, we demonstrate the potential of pairwise ranking methods to align\nthe subjective evaluation with objective indicators, creating a new score that\ncombines their advantages and facilitates diagnosis. In a case study on\npatients at risk for developing Psoriatic Arthritis, we illustrate that the\nresulting score (1) increases classification accuracy when detecting disease\npresence/absence, (2) is sparse and (3) provides a nuanced assessment of\nseverity for subsequent analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 12:32:35 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Pick", "Annika", ""], ["Ginzel", "Sebastian", ""], ["R\u00fcping", "Stefan", ""], ["Sander", "Jil", ""], ["Foldenauer", "Ann Christina", ""], ["K\u00f6hm", "Michaela", ""]]}, {"id": "2009.06419", "submitter": "Rahif Kassab", "authors": "Rahif Kassab and Osvaldo Simeone", "title": "Federated Generalized Bayesian Learning via Distributed Stein\n  Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Distributed Stein Variational Gradient Descent (DSVGD),\na non-parametric generalized Bayesian inference framework for federated\nlearning. DSVGD maintains a number of non-random and interacting particles at a\ncentral server to represent the current iterate of the model global posterior.\nThe particles are iteratively downloaded and updated by one of the agents with\nthe end goal of minimizing the global free energy. By varying the number of\nparticles, DSVGD enables a flexible trade-off between per-iteration\ncommunication load and number of communication rounds. DSVGD is shown to\ncompare favorably to benchmark frequentist and Bayesian federated learning\nstrategies, also scheduling a single device per iteration, in terms of accuracy\nand scalability with respect to the number of agents, while also providing\nwell-calibrated, and hence trustworthy, predictions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:33:22 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 17:31:29 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 17:35:45 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 09:34:17 GMT"}, {"version": "v5", "created": "Fri, 20 Nov 2020 08:22:57 GMT"}, {"version": "v6", "created": "Tue, 30 Mar 2021 13:14:24 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Kassab", "Rahif", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2009.06459", "submitter": "Jihong Park", "authors": "Chaouki Ben Issaid, Anis Elgabli, Jihong Park, Mehdi Bennis,\n  M\\'erouane Debbah", "title": "Communication Efficient Distributed Learning with Censored, Quantized,\n  and Generalized Group ADMM", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a communication-efficiently decentralized machine\nlearning framework that solves a consensus optimization problem defined over a\nnetwork of inter-connected workers. The proposed algorithm, Censored and\nQuantized Generalized GADMM (CQ-GGADMM), leverages the worker grouping and\ndecentralized learning ideas of Group Alternating Direction Method of\nMultipliers (GADMM), and pushes the frontier in communication efficiency by\nextending its applicability to generalized network topologies, while\nincorporating link censoring for negligible updates after quantization. We\ntheoretically prove that CQ-GGADMM achieves the linear convergence rate when\nthe local objective functions are strongly convex under some mild assumptions.\nNumerical simulations corroborate that CQ-GGADMM exhibits higher communication\nefficiency in terms of the number of communication rounds and transmit energy\nconsumption without compromising the accuracy and convergence speed, compared\nto the censored decentralized ADMM, and the worker grouping method of GADMM.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:18:19 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 05:37:15 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Issaid", "Chaouki Ben", ""], ["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "2009.06472", "submitter": "Alberto Caron", "authors": "Alberto Caron, Gianluca Baio and Ioanna Manolopoulou", "title": "Estimating Individual Treatment Effects using Non-Parametric Regression\n  Models: a Review", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large observational data are increasingly available in disciplines such as\nhealth, economic and social sciences, where researchers are interested in\ncausal questions rather than prediction. In this paper, we investigate the\nproblem of estimating heterogeneous treatment effects using non-parametric\nregression-based methods. Firstly, we introduce the setup and the issues\nrelated to conducting causal inference with observational or non-fully\nrandomized data, and how these issues can be tackled with the help of\nstatistical learning tools. Then, we provide a review of state-of-the-art\nmethods, with a particular focus on non-parametric modeling, and we cast them\nunder a unifying taxonomy. After presenting a brief overview on the problem of\nmodel selection, we illustrate the performance of some of the methods on three\ndifferent simulated studies and on a real world example to investigate the\neffect of participation in school meal programs on health indicators.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:26:55 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 10:14:48 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 20:50:50 GMT"}, {"version": "v4", "created": "Sun, 25 Apr 2021 23:29:04 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Caron", "Alberto", ""], ["Baio", "Gianluca", ""], ["Manolopoulou", "Ioanna", ""]]}, {"id": "2009.06492", "submitter": "Gouri Ginde Deshpande", "authors": "Gouri Deshpande and Guenther Ruhe", "title": "Beyond Accuracy: ROI-driven Data Analytics of Empirical Data", "comments": "6 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This vision paper demonstrates that it is crucial to consider\nReturn-on-Investment (ROI) when performing Data Analytics. Decisions on \"How\nmuch analytics is needed\"? are hard to answer. ROI could guide for decision\nsupport on the What?, How?, and How Much? analytics for a given problem.\nMethod: The proposed conceptual framework is validated through two empirical\nstudies that focus on requirements dependencies extraction in the Mozilla\nFirefox project. The two case studies are (i) Evaluation of fine-tuned BERT\nagainst Naive Bayes and Random Forest machine learners for binary dependency\nclassification and (ii) Active Learning against passive Learning (random\nsampling) for REQUIRES dependency extraction. For both the cases, their\nanalysis investment (cost) is estimated, and the achievable benefit from DA is\npredicted, to determine a break-even point of the investigation. Results: For\nthe first study, fine-tuned BERT performed superior to the Random Forest,\nprovided that more than 40% of training data is available. For the second,\nActive Learning achieved higher F1 accuracy within fewer iterations and higher\nROI compared to Baseline (Random sampling based RF classifier). In both the\nstudies, estimate on, How much analysis likely would pay off for the invested\nefforts?, was indicated by the break-even point. Conclusions: Decisions for the\ndepth and breadth of DA of empirical data should not be made solely based on\nthe accuracy measures. Since ROI-driven Data Analytics provides a simple yet\neffective direction to discover when to stop further investigation while\nconsidering the cost and value of the various types of analysis, it helps to\navoid over-analyzing empirical data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:49:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Deshpande", "Gouri", ""], ["Ruhe", "Guenther", ""]]}, {"id": "2009.06527", "submitter": "Joseph De Vilmarest", "authors": "David Obst, Joseph de Vilmarest, Yannig Goude", "title": "Adaptive Methods for Short-Term Electricity Load Forecasting During\n  COVID-19 Lockdown in France", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus disease 2019 (COVID-19) pandemic has urged many governments\nin the world to enforce a strict lockdown where all nonessential businesses are\nclosed and citizens are ordered to stay at home. One of the consequences of\nthis policy is a significant change in electricity consumption patterns. Since\nload forecasting models rely on calendar or meteorological information and are\ntrained on historical data, they fail to capture the significant break caused\nby the lockdown and have exhibited poor performances since the beginning of the\npandemic. This makes the scheduling of the electricity production challenging,\nand has a high cost for both electricity producers and grid operators. In this\npaper we introduce adaptive generalized additive models using Kalman filters\nand fine-tuning to adjust to new electricity consumption patterns.\nAdditionally, knowledge from the lockdown in Italy is transferred to anticipate\nthe change of behavior in France. The proposed methods are applied to forecast\nthe electricity demand during the French lockdown period, where they\ndemonstrate their ability to significantly reduce prediction errors compared to\ntraditional models. Finally expert aggregation is used to leverage the\nspecificities of each predictions and enhance results even further.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:41:36 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Obst", "David", ""], ["de Vilmarest", "Joseph", ""], ["Goude", "Yannig", ""]]}, {"id": "2009.06530", "submitter": "Ambar Pal", "authors": "Ambar Pal, Ren\\'e Vidal", "title": "A Game Theoretic Analysis of Additive Adversarial Attacks and Defenses", "comments": "Accepted at Neural Information Processing Systems (NeurIPS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in adversarial learning follows a cat and mouse game between\nattackers and defenders where attacks are proposed, they are mitigated by new\ndefenses, and subsequently new attacks are proposed that break earlier\ndefenses, and so on. However, it has remained unclear as to whether there are\nconditions under which no better attacks or defenses can be proposed. In this\npaper, we propose a game-theoretic framework for studying attacks and defenses\nwhich exist in equilibrium. Under a locally linear decision boundary model for\nthe underlying binary classifier, we prove that the Fast Gradient Method attack\nand the Randomized Smoothing defense form a Nash Equilibrium. We then show how\nthis equilibrium defense can be approximated given finitely many samples from a\ndata-generating distribution, and derive a generalization bound for the\nperformance of our approximation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:51:15 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 20:19:42 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Pal", "Ambar", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "2009.06540", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Themis Gouleakis and Daniel M. Kane and John\n  Peebles and Eric Price", "title": "Optimal Testing of Discrete Distributions with High Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing discrete distributions with a focus on the\nhigh probability regime. Specifically, given samples from one or more discrete\ndistributions, a property $\\mathcal{P}$, and parameters $0< \\epsilon, \\delta\n<1$, we want to distinguish {\\em with probability at least $1-\\delta$} whether\nthese distributions satisfy $\\mathcal{P}$ or are $\\epsilon$-far from\n$\\mathcal{P}$ in total variation distance. Most prior work in distribution\ntesting studied the constant confidence case (corresponding to $\\delta =\n\\Omega(1)$), and provided sample-optimal testers for a range of properties.\nWhile one can always boost the confidence probability of any such tester by\nblack-box amplification, this generic boosting method typically leads to\nsub-optimal sample bounds.\n  Here we study the following broad question: For a given property\n$\\mathcal{P}$, can we {\\em characterize} the sample complexity of testing\n$\\mathcal{P}$ as a function of all relevant problem parameters, including the\nerror probability $\\delta$? Prior to this work, uniformity testing was the only\nstatistical task whose sample complexity had been characterized in this\nsetting. As our main results, we provide the first algorithms for closeness and\nindependence testing that are sample-optimal, within constant factors, as a\nfunction of all relevant parameters. We also show matching\ninformation-theoretic lower bounds on the sample complexity of these problems.\nOur techniques naturally extend to give optimal testers for related problems.\nTo illustrate the generality of our methods, we give optimal algorithms for\ntesting collections of distributions and testing closeness with unequal sized\nsamples.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:09:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Kane", "Daniel M.", ""], ["Peebles", "John", ""], ["Price", "Eric", ""]]}, {"id": "2009.06546", "submitter": "Guillaume Salha", "authors": "Walid Bendada and Guillaume Salha and Th\\'eo Bontempelli", "title": "Carousel Personalization in Music Streaming Apps with Contextual Bandits", "comments": "14th ACM Conference on Recommender Systems (RecSys 2020, Best Short\n  Paper Candidate)", "journal-ref": null, "doi": "10.1145/3383313.3412217", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Media services providers, such as music streaming platforms, frequently\nleverage swipeable carousels to recommend personalized content to their users.\nHowever, selecting the most relevant items (albums, artists, playlists...) to\ndisplay in these carousels is a challenging task, as items are numerous and as\nusers have different preferences. In this paper, we model carousel\npersonalization as a contextual multi-armed bandit problem with multiple plays,\ncascade-based updates and delayed batch feedback. We empirically show the\neffectiveness of our framework at capturing characteristics of real-world\ncarousels by addressing a large-scale playlist recommendation task on a global\nmusic streaming mobile app. Along with this paper, we publicly release\nindustrial data from our experiments, as well as an open-source environment to\nsimulate comparable carousel personalization learning problems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:20:34 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 15:35:12 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Bendada", "Walid", ""], ["Salha", "Guillaume", ""], ["Bontempelli", "Th\u00e9o", ""]]}, {"id": "2009.06548", "submitter": "Daoming Lyu", "authors": "Daoming Lyu, Qi Qi, Mohammad Ghavamzadeh, Hengshuai Yao, Tianbao Yang,\n  Bo Liu", "title": "Variance-Reduced Off-Policy Memory-Efficient Policy Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy policy optimization is a challenging problem in reinforcement\nlearning (RL). The algorithms designed for this problem often suffer from high\nvariance in their estimators, which results in poor sample efficiency, and have\nissues with convergence. A few variance-reduced on-policy policy gradient\nalgorithms have been recently proposed that use methods from stochastic\noptimization to reduce the variance of the gradient estimate in the REINFORCE\nalgorithm. However, these algorithms are not designed for the off-policy\nsetting and are memory-inefficient, since they need to collect and store a\nlarge ``reference'' batch of samples from time to time. To achieve\nvariance-reduced off-policy-stable policy optimization, we propose an algorithm\nfamily that is memory-efficient, stochastically variance-reduced, and capable\nof learning from off-policy samples. Empirical studies validate the\neffectiveness of the proposed approaches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:22:46 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lyu", "Daoming", ""], ["Qi", "Qi", ""], ["Ghavamzadeh", "Mohammad", ""], ["Yao", "Hengshuai", ""], ["Yang", "Tianbao", ""], ["Liu", "Bo", ""]]}, {"id": "2009.06557", "submitter": "Guannan Liang", "authors": "Qianqian Tong, Guannan Liang and Jinbo Bi", "title": "Effective Federated Adaptive Gradient Methods with Non-IID Decentralized\n  Data", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows loads of edge computing devices to collaboratively\nlearn a global model without data sharing. The analysis with partial device\nparticipation under non-IID and unbalanced data reflects more reality. In this\nwork, we propose federated learning versions of adaptive gradient methods -\nFederated AGMs - which employ both the first-order and second-order momenta, to\nalleviate generalization performance deterioration caused by dissimilarity of\ndata population among devices. To further improve the test performance, we\ncompare several schemes of calibration for the adaptive learning rate,\nincluding the standard Adam calibrated by $\\epsilon$, $p$-Adam, and one\ncalibrated by an activation function. Our analysis provides the first set of\ntheoretical results that the proposed (calibrated) Federated AGMs converge to a\nfirst-order stationary point under non-IID and unbalanced data settings for\nnonconvex optimization. We perform extensive experiments to compare these\nfederated learning methods with the state-of-the-art FedAvg, FedMomentum and\nSCAFFOLD and to assess the different calibration schemes and the advantages of\nAGMs over the current federated learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:37:44 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 01:29:59 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Tong", "Qianqian", ""], ["Liang", "Guannan", ""], ["Bi", "Jinbo", ""]]}, {"id": "2009.06560", "submitter": "Lily Xu", "authors": "Lily Xu, Elizabeth Bondi, Fei Fang, Andrew Perrault, Kai Wang, Milind\n  Tambe", "title": "Dual-Mandate Patrols: Multi-Armed Bandits for Green Security", "comments": "Published at AAAI 2021. 9 pages (paper and references), 3 page\n  appendix. 6 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conservation efforts in green security domains to protect wildlife and\nforests are constrained by the limited availability of defenders (i.e.,\npatrollers), who must patrol vast areas to protect from attackers (e.g.,\npoachers or illegal loggers). Defenders must choose how much time to spend in\neach region of the protected area, balancing exploration of infrequently\nvisited regions and exploitation of known hotspots. We formulate the problem as\na stochastic multi-armed bandit, where each action represents a patrol\nstrategy, enabling us to guarantee the rate of convergence of the patrolling\npolicy. However, a naive bandit approach would compromise short-term\nperformance for long-term optimality, resulting in animals poached and forests\ndestroyed. To speed up performance, we leverage smoothness in the reward\nfunction and decomposability of actions. We show a synergy between\nLipschitz-continuity and decomposition as each aids the convergence of the\nother. In doing so, we bridge the gap between combinatorial and Lipschitz\nbandits, presenting a no-regret approach that tightens existing guarantees\nwhile optimizing for short-term performance. We demonstrate that our algorithm,\nLIZARD, improves performance on real-world poaching data from Cambodia.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:40:44 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 05:35:48 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Xu", "Lily", ""], ["Bondi", "Elizabeth", ""], ["Fang", "Fei", ""], ["Perrault", "Andrew", ""], ["Wang", "Kai", ""], ["Tambe", "Milind", ""]]}, {"id": "2009.06562", "submitter": "Guannan Liang", "authors": "Guannan Liang, Qianqian Tong, Jiahao Ding, Miao Pan and Jinbo Bi", "title": "Effective Proximal Methods for Non-convex Non-smooth Regularized\n  Learning", "comments": "Accepted by ICDM 2020, 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse learning is a very important tool for mining useful information and\npatterns from high dimensional data. Non-convex non-smooth regularized learning\nproblems play essential roles in sparse learning, and have drawn extensive\nattentions recently. We design a family of stochastic proximal gradient methods\nby applying arbitrary sampling to solve the empirical risk minimization problem\nwith a non-convex and non-smooth regularizer. These methods draw mini-batches\nof training examples according to an arbitrary probability distribution when\ncomputing stochastic gradients. A unified analytic approach is developed to\nexamine the convergence and computational complexity of these methods, allowing\nus to compare the different sampling schemes. We show that the independent\nsampling scheme tends to improve performance over the commonly-used uniform\nsampling scheme. Our new analysis also derives a tighter bound on convergence\nspeed for the uniform sampling than the best one available so far. Empirical\nevaluations demonstrate that the proposed algorithms converge faster than the\nstate of the art.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:41:32 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 22:42:26 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 14:43:05 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Liang", "Guannan", ""], ["Tong", "Qianqian", ""], ["Ding", "Jiahao", ""], ["Pan", "Miao", ""], ["Bi", "Jinbo", ""]]}, {"id": "2009.06571", "submitter": "Waleed Mustafa", "authors": "Waleed Mustafa, Robert A. Vandermeulen, Marius Kloft", "title": "Input Hessian Regularization of Neural Networks", "comments": "Workshop on \"Beyond first-order methods in ML systems\" at the 37th\n  International Conference on Machine Learning, Vienna, Austria, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularizing the input gradient has shown to be effective in promoting the\nrobustness of neural networks. The regularization of the input's Hessian is\ntherefore a natural next step. A key challenge here is the computational\ncomplexity. Computing the Hessian of inputs is computationally infeasible. In\nthis paper we propose an efficient algorithm to train deep neural networks with\nHessian operator-norm regularization. We analyze the approach theoretically and\nprove that the Hessian operator norm relates to the ability of a neural network\nto withstand an adversarial attack. We give a preliminary experimental\nevaluation on the MNIST and FMNIST datasets, which demonstrates that the new\nregularizer can, indeed, be feasible and, furthermore, that it increases the\nrobustness of neural networks over input gradient regularization.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:58:16 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mustafa", "Waleed", ""], ["Vandermeulen", "Robert A.", ""], ["Kloft", "Marius", ""]]}, {"id": "2009.06573", "submitter": "Runze Su", "authors": "Runze Su, Fei Tao, Xudong Liu, Haoran Wei, Xiaorong Mei, Zhiyao Duan,\n  Lei Yuan, Ji Liu, Yuying Xie", "title": "Themes Informed Audio-visual Correspondence Learning", "comments": "Submitting to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The applications of short-term user-generated video (UGV), such as Snapchat,\nand Youtube short-term videos, booms recently, raising lots of multimodal\nmachine learning tasks. Among them, learning the correspondence between audio\nand visual information from videos is a challenging one. Most previous work of\nthe audio-visual correspondence(AVC) learning only investigated constrained\nvideos or simple settings, which may not fit the application of UGV. In this\npaper, we proposed new principles for AVC and introduced a new framework to set\nsight of videos' themes to facilitate AVC learning. We also released the\nKWAI-AD-AudVis corpus which contained 85432 short advertisement videos (around\n913 hours) made by users. We evaluated our proposed approach on this corpus,\nand it was able to outperform the baseline by 23.15% absolute difference.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:03:04 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 06:40:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Su", "Runze", ""], ["Tao", "Fei", ""], ["Liu", "Xudong", ""], ["Wei", "Haoran", ""], ["Mei", "Xiaorong", ""], ["Duan", "Zhiyao", ""], ["Yuan", "Lei", ""], ["Liu", "Ji", ""], ["Xie", "Yuying", ""]]}, {"id": "2009.06589", "submitter": "Wenqi Wei", "authors": "Wenqi Wei and Ling Liu", "title": "Robust Deep Learning Ensemble against Deception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) models are known to be vulnerable to maliciously\ncrafted adversarial examples and to out-of-distribution inputs drawn\nsufficiently far away from the training data. How to protect a machine learning\nmodel against deception of both types of destructive inputs remains an open\nchallenge. This paper presents XEnsemble, a diversity ensemble verification\nmethodology for enhancing the adversarial robustness of DNN models against\ndeception caused by either adversarial examples or out-of-distribution inputs.\nXEnsemble by design has three unique capabilities. First, XEnsemble builds\ndiverse input denoising verifiers by leveraging different data cleaning\ntechniques. Second, XEnsemble develops a disagreement-diversity ensemble\nlearning methodology for guarding the output of the prediction model against\ndeception. Third, XEnsemble provides a suite of algorithms to combine input\nverification and output verification to protect the DNN prediction models from\nboth adversarial examples and out of distribution inputs. Evaluated using\neleven popular adversarial attacks and two representative out-of-distribution\ndatasets, we show that XEnsemble achieves a high defense success rate against\nadversarial examples and a high detection success rate against\nout-of-distribution data inputs, and outperforms existing representative\ndefense methods with respect to robustness and defensibility.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:20:01 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wei", "Wenqi", ""], ["Liu", "Ling", ""]]}, {"id": "2009.06606", "submitter": "Arghyadip Roy", "authors": "Arghyadip Roy, Sanjay Shakkottai, R. Srikant", "title": "Hellinger KL-UCB based Bandit Algorithms for Markovian and i.i.d.\n  Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the regret-based formulation of multi-armed bandit (MAB) problems, except\nin rare instances, much of the literature focuses on arms with i.i.d. rewards.\nIn this paper, we consider the problem of obtaining regret guarantees for MAB\nproblems in which the rewards of each arm form a Markov chain which may not\nbelong to a single parameter exponential family. To achieve logarithmic regret\nin such problems is not difficult: a variation of standard KL-UCB does the job.\nHowever, the constants obtained from such an analysis are poor for the\nfollowing reason: i.i.d. rewards are a special case of Markov rewards and it is\ndifficult to design an algorithm that works well independent of whether the\nunderlying model is truly Markovian or i.i.d. To overcome this issue, we\nintroduce a novel algorithm that identifies whether the rewards from each arm\nare truly Markovian or i.i.d. using a Hellinger distance-based test. Our\nalgorithm then switches from using a standard KL-UCB to a specialized version\nof KL-UCB when it determines that the arm reward is Markovian, thus resulting\nin low regret for both i.i.d. and Markovian settings.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:44:23 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Roy", "Arghyadip", ""], ["Shakkottai", "Sanjay", ""], ["Srikant", "R.", ""]]}, {"id": "2009.06615", "submitter": "Ales Zahorski", "authors": "Ales Zahorski", "title": "Multilevel regression with poststratification for the national level\n  Viber/Street poll on the 2020 presidential election in Belarus", "comments": "45 pages, 23 figures, 18 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent sociological polls are forbidden in Belarus. Online polls\nperformed without sound scientific rigour do not yield representative results.\nYet, both inside and outside Belarus it is of great importance to obtain\nprecise estimates of the ratings of all candidates. These ratings could\nfunction as reliable proxies for the election's outcomes. We conduct an\nindependent poll based on the combination of the data collected via Viber and\non the streets of Belarus. The Viber and the street data samples consist of\nalmost 45000 and 1150 unique observations respectively. Bayesian regressions\nwith poststratification were build to estimate ratings of the candidates and\nrates of early voting turnout for the population as a whole and within various\nfocus subgroups. We show that both the officially announced results of the\nelection and early voting rates are highly improbable. With a probability of at\nleast 95%, Sviatlana Tikhanouskaya's rating lies between 75% and 80%, whereas\nAliaksandr Lukashenka's rating lies between 13% and 18% and early voting rate\npredicted by the method ranges from 9% to 13% of those who took part in the\nelection. These results contradict the officially announced outcomes, which are\n10.12%, 80.11%, and 49.54% respectively and lie far outside even the 99.9%\ncredible intervals predicted by our model. The only marginal groups of people\nwhere the upper bounds of the 99.9% credible intervals of the rating of\nLukashenka are above 50% are people older than 60 and uneducated people. For\nall other marginal subgroups, including rural residents, even the upper bounds\nof 99.9% credible intervals for Lukashenka are far below 50%. The same is true\nfor the population as a whole. Thus, with a probability of at least 99.9%\nLukashenka could not have had enough electoral support to win the 2020\npresidential election in Belarus.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:55:04 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zahorski", "Ales", ""]]}, {"id": "2009.06639", "submitter": "Bryan Ostdiek", "authors": "Bryan Ostdiek, Ana Diaz Rivero, and Cora Dvorkin", "title": "Extracting the Subhalo Mass Function from Strong Lens Images with Image\n  Segmentation", "comments": "23 + 5 pages, 12 + 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO astro-ph.IM hep-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting substructure within strongly lensed images is a promising route to\nshed light on the nature of dark matter. It is a challenging task, which\ntraditionally requires detailed lens modeling and source reconstruction, taking\nweeks to analyze each system. We use machine learning to circumvent the need\nfor lens and source modeling and develop a method to both locate subhalos in an\nimage as well as determine their mass using the technique of image\nsegmentation. The network is trained on images with a single subhalo located\nnear the Einstein ring. Training in this way allows the network to learn the\ngravitational lensing of light and it is then able to accurately detect entire\npopulations of substructure, even far from the Einstein ring. In images with a\nsingle subhalo and without noise, the network detects subhalos of mass $10^6\nM_{\\odot}$ 62% of the time and 78% of these detected subhalos are predicted in\nthe correct mass bin. The detection accuracy increases for heavier masses. When\nrandom noise at the level of 1% of the mean brightness of the image is included\n(which is a realistic approximation HST, for sources brighter than magnitude\n20), the network loses sensitivity to the low-mass subhalos; with noise, the\n$10^{8.5}M_{\\odot}$ subhalos are detected 86% of the time, but the $10^8\nM_{\\odot}$ subhalos are only detected 38% of the time. The false-positive rate\nis around 2 false subhalos per 100 images with and without noise, coming mostly\nfrom masses $\\leq10^8 M_{\\odot}$. With good accuracy and a low false-positive\nrate, counting the number of pixels assigned to each subhalo class over\nmultiple images allows for a measurement of the subhalo mass function (SMF).\nWhen measured over five mass bins from $10^8 M_{\\odot}$ to $10^{10} M_{\\odot}$\nthe SMF slope is recovered with an error of 14.2 (16.3)% for 10 images, and\nthis improves to 2.1 (2.6)% for 1000 images without (with 1%) noise.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:00:01 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ostdiek", "Bryan", ""], ["Rivero", "Ana Diaz", ""], ["Dvorkin", "Cora", ""]]}, {"id": "2009.06681", "submitter": "Yasar Sinan Nasir", "authors": "Yasar Sinan Nasir and Dongning Guo", "title": "Deep Actor-Critic Learning for Distributed Power Control in Wireless\n  Mobile Networks", "comments": "5 pages, 4 figures, to appear in the 54th Annual IEEE Asilomar\n  Conference on Signals, Systems, and Computers, Nov 2020. This is an invited\n  paper to the session Reinforcement Learning and Bandits for Communication\n  Systems. To reproduce the results please see\n  https://github.com/sinannasir/Power-Control-asilomar", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning offers a model-free alternative to supervised\ndeep learning and classical optimization for solving the transmit power control\nproblem in wireless networks. The multi-agent deep reinforcement learning\napproach considers each transmitter as an individual learning agent that\ndetermines its transmit power level by observing the local wireless\nenvironment. Following a certain policy, these agents learn to collaboratively\nmaximize a global objective, e.g., a sum-rate utility function. This\nmulti-agent scheme is easily scalable and practically applicable to large-scale\ncellular networks. In this work, we present a distributively executed\ncontinuous power control algorithm with the help of deep actor-critic learning,\nand more specifically, by adapting deep deterministic policy gradient.\nFurthermore, we integrate the proposed power control algorithm to a\ntime-slotted system where devices are mobile and channel conditions change\nrapidly. We demonstrate the functionality of the proposed algorithm using\nsimulation results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:29:12 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Nasir", "Yasar Sinan", ""], ["Guo", "Dongning", ""]]}, {"id": "2009.06719", "submitter": "Ming Min", "authors": "Ming Min, Tomoyuki Ichiba", "title": "Convolutional Signature for Sequential Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signature is an infinite graded sequence of statistics known to characterize\ngeometric rough paths, which includes the paths with bounded variation. This\nobject has been studied successfully for machine learning with mostly\napplications in low dimensional cases. In the high dimensional case, it suffers\nfrom exponential growth in the number of features in truncated signature\ntransform. We propose a novel neural network based model which borrows the idea\nfrom Convolutional Neural Network to address this problem. Our model reduces\nthe number of features efficiently in a data dependent way. Some empirical\nexperiments are provided to support our model.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 20:01:56 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Min", "Ming", ""], ["Ichiba", "Tomoyuki", ""]]}, {"id": "2009.06747", "submitter": "Youbang Sun", "authors": "Youbang Sun, Shahin Shahrampour", "title": "Distributed Mirror Descent with Integral Feedback: Asymptotic\n  Convergence Analysis of Continuous-time Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses distributed optimization, where a network of agents wants\nto minimize a global strongly convex objective function. The global function\ncan be written as a sum of local convex functions, each of which is associated\nwith an agent. We propose a continuous-time distributed mirror descent\nalgorithm that uses purely local information to converge to the global optimum.\nUnlike previous work on distributed mirror descent, we incorporate an integral\nfeedback in the update, allowing the algorithm to converge with a constant\nstep-size when discretized. We establish the asymptotic convergence of the\nalgorithm using Lyapunov stability analysis. We further illustrate numerical\nexperiments that verify the advantage of adopting integral feedback for\nimproving the convergence rate of distributed mirror descent.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 21:11:42 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Sun", "Youbang", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2009.06762", "submitter": "Esteban Vilca", "authors": "Esteban Wilfredo Vilca Zu\\~niga", "title": "New complex network building methodology for High Level Classification\n  based on attribute-attribute interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-level classification algorithms focus on the interactions between\ninstances. These produce a new form to evaluate and classify data. In this\nprocess, the core is the complex network building methodology because it\ndetermines the metrics to be used for classification. The current methodologies\nuse variations of kNN to produce these graphs. However, this technique ignores\nsome hidden pattern between attributes and require normalization to be\naccurate. In this paper, we propose a new methodology for network building\nbased on attribute-attribute interactions that do not require normalization and\ncapture the hidden patterns of the attributes. The current results show us that\ncould be used to improve some current high-level techniques.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 21:58:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zu\u00f1iga", "Esteban Wilfredo Vilca", ""]]}, {"id": "2009.06764", "submitter": "Jean-Francois Rajotte", "authors": "Jean-Francois Rajotte, Raymond T Ng", "title": "Private data sharing between decentralized users through the privGAN\n  architecture", "comments": "6 pages, 9 figures, to be in the proceedings of International\n  Workshop on Privacy and Security in Enterprise Modeling (PriSEM'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More data is almost always beneficial for analysis and machine learning\ntasks. In many realistic situations however, an enterprise cannot share its\ndata, either to keep a competitive advantage or to protect the privacy of the\ndata sources, the enterprise's clients for example. We propose a method for\ndata owners to share synthetic or fake versions of their data without sharing\nthe actual data, nor the parameters of models that have direct access to the\ndata. The method proposed is based on the privGAN architecture where local GANs\nare trained on their respective data subsets with an extra penalty from a\ncentral discriminator aiming to discriminate the origin of a given fake sample.\nWe demonstrate that this approach, when applied to subsets of various sizes,\nleads to better utility for the owners than the utility from their real small\ndatasets. The only shared pieces of information are the parameter updates of\nthe central discriminator. The privacy is demonstrated with white-box attacks\non the most vulnerable elments of the architecture and the results are close to\nrandom guessing. This method would apply naturally in a federated learning\nsetting.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 22:06:13 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Rajotte", "Jean-Francois", ""], ["Ng", "Raymond T", ""]]}, {"id": "2009.06784", "submitter": "Cheng Mao", "authors": "Cheng Mao and Yihong Wu", "title": "Learning Mixtures of Permutations: Groups of Pairwise Comparisons and\n  Combinatorial Method of Moments", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications such as rank aggregation, mixture models for permutations are\nfrequently used when the population exhibits heterogeneity. In this work, we\nstudy the widely used Mallows mixture model. In the high-dimensional setting,\nwe propose a polynomial-time algorithm that learns a Mallows mixture of\npermutations on $n$ elements with the optimal sample complexity that is\nproportional to $\\log n$, improving upon previous results that scale\npolynomially with $n$. In the high-noise regime, we characterize the optimal\ndependency of the sample complexity on the noise parameter. Both objectives are\naccomplished by first studying demixing permutations under a noiseless query\nmodel using groups of pairwise comparisons, which can be viewed as moments of\nthe mixing distribution, and then extending these results to the noisy Mallows\nmodel by simulating the noiseless oracle.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 23:11:46 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mao", "Cheng", ""], ["Wu", "Yihong", ""]]}, {"id": "2009.06795", "submitter": "Huajie Shao", "authors": "Huajie Shao, Haohong Lin, Qinmin Yang, Shuochao Yao, Han Zhao, Tarek\n  Abdelzaher", "title": "DynamicVAE: Decoupling Reconstruction Error and Disentangled\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper challenges the common assumption that the weight $\\beta$, in\n$\\beta$-VAE, should be larger than $1$ in order to effectively disentangle\nlatent factors. We demonstrate that $\\beta$-VAE, with $\\beta < 1$, can not only\nattain good disentanglement but also significantly improve reconstruction\naccuracy via dynamic control. The paper removes the inherent trade-off between\nreconstruction accuracy and disentanglement for $\\beta$-VAE. Existing methods,\nsuch as $\\beta$-VAE and FactorVAE, assign a large weight to the KL-divergence\nterm in the objective function, leading to high reconstruction errors for the\nsake of better disentanglement. To mitigate this problem, a ControlVAE has\nrecently been developed that dynamically tunes the KL-divergence weight in an\nattempt to control the trade-off to more a favorable point. However, ControlVAE\nfails to eliminate the conflict between the need for a large $\\beta$ (for\ndisentanglement) and the need for a small $\\beta$. Instead, we propose\nDynamicVAE that maintains a different $\\beta$ at different stages of training,\nthereby decoupling disentanglement and reconstruction accuracy. In order to\nevolve the weight, $\\beta$, along a trajectory that enables such decoupling,\nDynamicVAE leverages a modified incremental PI (proportional-integral)\ncontroller, and employs a moving average as well as a hybrid annealing method\nto evolve the value of KL-divergence smoothly in a tightly controlled fashion.\nWe theoretically prove the stability of the proposed approach. Evaluation\nresults on three benchmark datasets demonstrate that DynamicVAE significantly\nimproves the reconstruction accuracy while achieving disentanglement comparable\nto the best of existing methods. The results verify that our method can\nseparate disentangled representation learning and reconstruction, removing the\ninherent tension between the two.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:01:11 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 22:11:07 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Shao", "Huajie", ""], ["Lin", "Haohong", ""], ["Yang", "Qinmin", ""], ["Yao", "Shuochao", ""], ["Zhao", "Han", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2009.06797", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Eva Zhang, Yongchan Kwon, James Zou", "title": "Competing AI: How does competition feedback affect machine learning?", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This papers studies how competition affects machine learning (ML) predictors.\nAs ML becomes more ubiquitous, it is often deployed by companies to compete\nover customers. For example, digital platforms like Yelp use ML to predict user\npreference and make recommendations. A service that is more often queried by\nusers, perhaps because it more accurately anticipates user preferences, is also\nmore likely to obtain additional user data (e.g. in the form of a Yelp review).\nThus, competing predictors cause feedback loops whereby a predictor's\nperformance impacts what training data it receives and biases its predictions\nover time. We introduce a flexible model of competing ML predictors that\nenables both rapid experimentation and theoretical tractability. We show with\nempirical and mathematical analysis that competition causes predictors to\nspecialize for specific sub-populations at the cost of worse performance over\nthe general population. We further analyze the impact of predictor\nspecialization on the overall prediction quality experienced by users. We show\nthat having too few or too many competing predictors in a market can hurt the\noverall prediction quality. Our theory is complemented by experiments on\nseveral real datasets using popular learning algorithms, such as neural\nnetworks and nearest neighbor methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:13:32 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:12:49 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 05:01:12 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 04:04:22 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Ginart", "Antonio", ""], ["Zhang", "Eva", ""], ["Kwon", "Yongchan", ""], ["Zou", "James", ""]]}, {"id": "2009.06798", "submitter": "Julio Omar Palacio Ni\\~no", "authors": "Julio-Omar Palacio-Ni\\~no and Fernando Berzal", "title": "On the use of local structural properties for improving the efficiency\n  of hierarchical community detection methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Community detection is a fundamental problem in the analysis of complex\nnetworks. It is the analogue of clustering in network data mining. Within\ncommunity detection methods, hierarchical algorithms are popular. However,\ntheir iterative nature and the need to recompute the structural properties used\nto split the network (i.e. edge betweenness in Girvan and Newman's algorithm),\nmake them unsuitable for large network data sets. In this paper, we study how\nlocal structural network properties can be used as proxies to improve the\nefficiency of hierarchical community detection while, at the same time,\nachieving competitive results in terms of modularity. In particular, we study\nthe potential use of the structural properties commonly used to perform local\nlink prediction, a supervised learning problem where community structure is\nrelevant, as nodes are prone to establish new links with other nodes within\ntheir communities. In addition, we check the performance impact of network\npruning heuristics as an ancillary tactic to make hierarchical community\ndetection more efficient\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:16:12 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Palacio-Ni\u00f1o", "Julio-Omar", ""], ["Berzal", "Fernando", ""]]}, {"id": "2009.06828", "submitter": "Zhixuan Chu", "authors": "Zhixuan Chu, Stephen L. Rathbun, and Sheng Li", "title": "Matching in Selective and Balanced Representation Space for Treatment\n  Effects Estimation", "comments": "Proceedings of the 29th ACM International Conference on Information\n  and Knowledge Management (CIKM '20)", "journal-ref": null, "doi": "10.1145/3340531.3412037", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dramatically growing availability of observational data is being\nwitnessed in various domains of science and technology, which facilitates the\nstudy of causal inference. However, estimating treatment effects from\nobservational data is faced with two major challenges, missing counterfactual\noutcomes and treatment selection bias. Matching methods are among the most\nwidely used and fundamental approaches to estimating treatment effects, but\nexisting matching methods have poor performance when facing data with high\ndimensional and complicated variables. We propose a feature selection\nrepresentation matching (FSRM) method based on deep representation learning and\nmatching, which maps the original covariate space into a selective, nonlinear,\nand balanced representation space, and then conducts matching in the learned\nrepresentation space. FSRM adopts deep feature selection to minimize the\ninfluence of irrelevant variables for estimating treatment effects and\nincorporates a regularizer based on the Wasserstein distance to learn balanced\nrepresentations. We evaluate the performance of our FSRM method on three\ndatasets, and the results demonstrate superiority over the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:07:34 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 09:12:23 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chu", "Zhixuan", ""], ["Rathbun", "Stephen L.", ""], ["Li", "Sheng", ""]]}, {"id": "2009.06847", "submitter": "Guansong Pang", "authors": "Guansong Pang, Anton van den Hengel, Chunhua Shen, Longbing Cao", "title": "Toward Deep Supervised Anomaly Detection: Reinforcement Learning from\n  Partially Labeled Anomaly Data", "comments": "Accepted to KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467417", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of anomaly detection with a small set of partially\nlabeled anomaly examples and a large-scale unlabeled dataset. This is a common\nscenario in many important applications. Existing related methods either\nexclusively fit the limited anomaly examples that typically do not span the\nentire set of anomalies, or proceed with unsupervised learning from the\nunlabeled data. We propose here instead a deep reinforcement learning-based\napproach that enables an end-to-end optimization of the detection of both\nlabeled and unlabeled anomalies. This approach learns the known abnormality by\nautomatically interacting with an anomaly-biased simulation environment, while\ncontinuously extending the learned abnormality to novel classes of anomaly\n(i.e., unknown anomalies) by actively exploring possible anomalies in the\nunlabeled data. This is achieved by jointly optimizing the exploitation of the\nsmall labeled anomaly data and the exploration of the rare unlabeled anomalies.\nExtensive experiments on 48 real-world datasets show that our model\nsignificantly outperforms five state-of-the-art competing methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 03:05:39 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 13:40:11 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Pang", "Guansong", ""], ["Hengel", "Anton van den", ""], ["Shen", "Chunhua", ""], ["Cao", "Longbing", ""]]}, {"id": "2009.06851", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang, Ruiyi Zhang, Manzil Zaheer, Amr Ahmed", "title": "Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-quality dialogue-summary paired data is expensive to produce and\ndomain-sensitive, making abstractive dialogue summarization a challenging task.\nIn this work, we propose the first unsupervised abstractive dialogue\nsummarization model for tete-a-tetes (SuTaT). Unlike standard text\nsummarization, a dialogue summarization method should consider the\nmulti-speaker scenario where the speakers have different roles, goals, and\nlanguage styles. In a tete-a-tete, such as a customer-agent conversation, SuTaT\naims to summarize for each speaker by modeling the customer utterances and the\nagent utterances separately while retaining their correlations. SuTaT consists\nof a conditional generative module and two unsupervised summarization modules.\nThe conditional generative module contains two encoders and two decoders in a\nvariational autoencoder framework where the dependencies between two latent\nspaces are captured. With the same encoders and decoders, two unsupervised\nsummarization modules equipped with sentence-level self-attention mechanisms\ngenerate summaries without using any annotations. Experimental results show\nthat SuTaT is superior on unsupervised dialogue summarization for both\nautomatic and human evaluations, and is capable of dialogue classification and\nsingle-turn conversation generation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 03:27:52 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Zhang", "Xinyuan", ""], ["Zhang", "Ruiyi", ""], ["Zaheer", "Manzil", ""], ["Ahmed", "Amr", ""]]}, {"id": "2009.06858", "submitter": "Yubo Huang", "authors": "Yubo Huang, Xuechun Wang, Luobao Zou, Zhiwei Zhuang, Weidong Zhang", "title": "Soft policy optimization using dual-track advantage estimator", "comments": "This is the accepted version of my manuscript (ICDM2020). Due to I\n  should curtail my paper within 6 pages in this conference, now, I want to\n  upload the complete version of my draft to readers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), we always expect the agent to explore as many\nstates as possible in the initial stage of training and exploit the explored\ninformation in the subsequent stage to discover the most returnable trajectory.\nBased on this principle, in this paper, we soften the proximal policy\noptimization by introducing the entropy and dynamically setting the temperature\ncoefficient to balance the opportunity of exploration and exploitation. While\nmaximizing the expected reward, the agent will also seek other trajectories to\navoid the local optimal policy. Nevertheless, the increase of randomness\ninduced by entropy will reduce the train speed in the early stage. Integrating\nthe temporal-difference (TD) method and the general advantage estimator (GAE),\nwe propose the dual-track advantage estimator (DTAE) to accelerate the\nconvergence of value functions and further enhance the performance of the\nalgorithm. Compared with other on-policy RL algorithms on the Mujoco\nenvironment, the proposed method not only significantly speeds up the training\nbut also achieves the most advanced results in cumulative return.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 04:09:29 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Huang", "Yubo", ""], ["Wang", "Xuechun", ""], ["Zou", "Luobao", ""], ["Zhuang", "Zhiwei", ""], ["Zhang", "Weidong", ""]]}, {"id": "2009.06918", "submitter": "Kyle Robert Steffen", "authors": "Steven Mattis and Kyle Robert Steffen and Troy Butler and Clint N.\n  Dawson and Donald Estep", "title": "Learning Quantities of Interest from Dynamical Systems for\n  Observation-Consistent Inversion", "comments": "38 pages, 14 figures. Submitted to Computer Methods in Applied\n  Mechanics and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems arise in a wide variety of mathematical models from science\nand engineering. A common challenge is to quantify uncertainties on model\ninputs (parameters) that correspond to a quantitative characterization of\nuncertainties on observable Quantities of Interest (QoI). To this end, we\nconsider a stochastic inverse problem (SIP) with a solution described by a\npullback probability measure. We call this an observation-consistent solution,\nas its subsequent push-forward through the QoI map matches the observed\nprobability distribution on model outputs. A distinction is made between QoI\nuseful for solving the SIP and arbitrary model output data. In dynamical\nsystems, model output data are often given as a series of state variable\nresponses recorded over a particular time window. Consequently, the dimension\nof output data can easily exceed $\\mathcal{O}(1E4)$ or more due to the\nfrequency of observations, and the correct choice or construction of a QoI from\nthis data is not self-evident. We present a new framework, Learning Uncertain\nQuantities (LUQ), that facilitates the tractable solution of SIPs for dynamical\nsystems. Given ensembles of predicted (simulated) time series and (noisy)\nobserved data, LUQ provides routines for filtering data, unsupervised learning\nof the underlying dynamics, classifying observations, and feature extraction to\nlearn the QoI map. Subsequently, time series data are transformed into samples\nof the underlying predicted and observed distributions associated with the QoI\nso that solutions to the SIP are computable. Following the introduction and\ndemonstration of LUQ, numerical results from several SIPs are presented for a\nvariety of dynamical systems arising in the life and physical sciences. For\nscientific reproducibility, we provide links to our Python implementation of\nLUQ and to all data and scripts required to reproduce the results in this\nmanuscript.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 08:27:27 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 00:26:57 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 17:08:10 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Mattis", "Steven", ""], ["Steffen", "Kyle Robert", ""], ["Butler", "Troy", ""], ["Dawson", "Clint N.", ""], ["Estep", "Donald", ""]]}, {"id": "2009.06921", "submitter": "Emir Demirovi\\'c", "authors": "Emir Demirovi\\'c, Peter J. Stuckey", "title": "Optimal Decision Trees for Nonlinear Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear metrics, such as the F1-score, Matthews correlation coefficient,\nand Fowlkes-Mallows index, are often used to evaluate the performance of\nmachine learning models, in particular, when facing imbalanced datasets that\ncontain more samples of one class than the other. Recent optimal decision tree\nalgorithms have shown remarkable progress in producing trees that are optimal\nwith respect to linear criteria, such as accuracy, but unfortunately nonlinear\nmetrics remain a challenge. To address this gap, we propose a novel algorithm\nbased on bi-objective optimisation, which treats misclassifications of each\nbinary class as a separate objective. We show that, for a large class of\nmetrics, the optimal tree lies on the Pareto frontier. Consequently, we obtain\nthe optimal tree by using our method to generate the set of all nondominated\ntrees. To the best of our knowledge, this is the first method to compute\nprovably optimal decision trees for nonlinear metrics. Our approach leads to a\ntrade-off when compared to optimising linear metrics: the resulting trees may\nbe more desirable according to the given nonlinear metric at the expense of\nhigher runtimes. Nevertheless, the experiments illustrate that runtimes are\nreasonable for majority of the tested datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 08:30:56 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Demirovi\u0107", "Emir", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "2009.06946", "submitter": "Konstantinos Mavromatis", "authors": "Costas Mavromatis, George Karypis", "title": "Graph InfoClust: Leveraging cluster-level node information for\n  unsupervised graph representation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised (or self-supervised) graph representation learning is essential\nto facilitate various graph data mining tasks when external supervision is\nunavailable. The challenge is to encode the information about the graph\nstructure and the attributes associated with the nodes and edges into a low\ndimensional space. Most existing unsupervised methods promote similar\nrepresentations across nodes that are topologically close. Recently, it was\nshown that leveraging additional graph-level information, e.g., information\nthat is shared among all nodes, encourages the representations to be mindful of\nthe global properties of the graph, which greatly improves their quality.\nHowever, in most graphs, there is significantly more structure that can be\ncaptured, e.g., nodes tend to belong to (multiple) clusters that represent\nstructurally similar nodes. Motivated by this observation, we propose a graph\nrepresentation learning method called Graph InfoClust (GIC), that seeks to\nadditionally capture cluster-level information content. These clusters are\ncomputed by a differentiable K-means method and are jointly optimized by\nmaximizing the mutual information between nodes of the same clusters. This\noptimization leads the node representations to capture richer information and\nnodal interactions, which improves their quality. Experiments show that GIC\noutperforms state-of-art methods in various downstream tasks (node\nclassification, link prediction, and node clustering) with a 0.9% to 6.1% gain\nover the best competing approach, on average.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 09:33:20 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mavromatis", "Costas", ""], ["Karypis", "George", ""]]}, {"id": "2009.06962", "submitter": "Jang-Hyun Kim", "authors": "Jang-Hyun Kim, Wonho Choo, Hyun Oh Song", "title": "Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup", "comments": "Published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks achieve great performance on fitting the training\ndistribution, the learned networks are prone to overfitting and are susceptible\nto adversarial attacks. In this regard, a number of mixup based augmentation\nmethods have been recently proposed. However, these approaches mainly focus on\ncreating previously unseen virtual examples and can sometimes provide\nmisleading supervisory signal to the network. To this end, we propose Puzzle\nMix, a mixup method for explicitly utilizing the saliency information and the\nunderlying statistics of the natural examples. This leads to an interesting\noptimization problem alternating between the multi-label objective for optimal\nmixing mask and saliency discounted optimal transport objective. Our\nexperiments show Puzzle Mix achieves the state of the art generalization and\nthe adversarial robustness results compared to other mixup methods on\nCIFAR-100, Tiny-ImageNet, and ImageNet datasets. The source code is available\nat https://github.com/snu-mllab/PuzzleMix.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:10:23 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 10:45:39 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kim", "Jang-Hyun", ""], ["Choo", "Wonho", ""], ["Song", "Hyun Oh", ""]]}, {"id": "2009.06966", "submitter": "Sattar Vakili", "authors": "Sattar Vakili, Kia Khezeli, Victor Picheny", "title": "On Information Gain and Regret Bounds in Gaussian Process Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider the sequential optimization of an expensive to evaluate and possibly\nnon-convex objective function $f$ from noisy feedback, that can be considered\nas a continuum-armed bandit problem. Upper bounds on the regret performance of\nseveral learning algorithms (GP-UCB, GP-TS, and their variants) are known under\nboth a Bayesian (when $f$ is a sample from a Gaussian process (GP)) and a\nfrequentist (when $f$ lives in a reproducing kernel Hilbert space) setting. The\nregret bounds often rely on the maximal information gain $\\gamma_T$ between $T$\nobservations and the underlying GP (surrogate) model. We provide general bounds\non $\\gamma_T$ based on the decay rate of the eigenvalues of the GP kernel,\nwhose specialisation for commonly used kernels, improves the existing bounds on\n$\\gamma_T$, and subsequently the regret bounds relying on $\\gamma_T$ under\nnumerous settings. For the Mat\\'ern family of kernels, where the lower bounds\non $\\gamma_T$, and regret under the frequentist setting, are known, our results\nclose a huge polynomial in $T$ gap between the upper and lower bounds (up to\nlogarithmic in $T$ factors).\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:15:29 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 14:28:46 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 22:46:52 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Vakili", "Sattar", ""], ["Khezeli", "Kia", ""], ["Picheny", "Victor", ""]]}, {"id": "2009.07008", "submitter": "Nicolas Michael M\\\"uller", "authors": "Nicolas Michael M\\\"uller, Daniel Kowatsch, Konstantin B\\\"ottinger", "title": "Data Poisoning Attacks on Regression Learning and Corresponding Defenses", "comments": "Accepted for Publication at PRDC2020, Copyright by IEEE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial data poisoning is an effective attack against machine learning\nand threatens model integrity by introducing poisoned data into the training\ndataset. So far, it has been studied mostly for classification, even though\nregression learning is used in many mission critical systems (such as dosage of\nmedication, control of cyber-physical systems and managing power supply).\nTherefore, in the present research, we aim to evaluate all aspects of data\npoisoning attacks on regression learning, exceeding previous work both in terms\nof breadth and depth. We present realistic scenarios in which data poisoning\nattacks threaten production systems and introduce a novel black-box attack,\nwhich is then applied to a real-word medical use-case. As a result, we observe\nthat the mean squared error (MSE) of the regressor increases to 150 percent due\nto inserting only two percent of poison samples. Finally, we present a new\ndefense strategy against the novel and previous attacks and evaluate it\nthoroughly on 26 datasets. As a result of the conducted experiments, we\nconclude that the proposed defence strategy effectively mitigates the\nconsidered attacks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 12:14:54 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["M\u00fcller", "Nicolas Michael", ""], ["Kowatsch", "Daniel", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2009.07013", "submitter": "Dominique Vaufreydaz", "authors": "Anastasia Petrova (PERVASIVE), Dominique Vaufreydaz (PERVASIVE),\n  Philippe Dessus (LaRAC)", "title": "Group-Level Emotion Recognition Using a Unimodal Privacy-Safe\n  Non-Individual Approach", "comments": null, "journal-ref": "EmotiW2020 Challenge at the 22nd ACM International Conference on\n  Multimodal Interaction (ICMI2020), Oct 2020, Utrecht, Netherlands", "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents our unimodal privacy-safe and non-individual proposal\nfor the audio-video group emotion recognition subtask at the Emotion\nRecognition in the Wild (EmotiW) Challenge 2020 1. This sub challenge aims to\nclassify in the wild videos into three categories: Positive, Neutral and\nNegative. Recent deep learning models have shown tremendous advances in\nanalyzing interactions between people, predicting human behavior and affective\nevaluation. Nonetheless, their performance comes from individual-based\nanalysis, which means summing up and averaging scores from individual\ndetections, which inevitably leads to some privacy issues. In this research, we\ninvestigated a frugal approach towards a model able to capture the global moods\nfrom the whole image without using face or pose detection, or any\nindividual-based feature as input. The proposed methodology mixes\nstate-of-the-art and dedicated synthetic corpora as training sources. With an\nin-depth exploration of neural network architectures for group-level emotion\nrecognition, we built a VGG-based model achieving 59.13% accuracy on the VGAF\ntest set (eleventh place of the challenge). Given that the analysis is unimodal\nbased only on global features and that the performance is evaluated on a\nreal-world dataset, these results are promising and let us envision extending\nthis model to multimodality for classroom ambiance evaluation, our final target\napplication.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 12:25:33 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Petrova", "Anastasia", "", "PERVASIVE"], ["Vaufreydaz", "Dominique", "", "PERVASIVE"], ["Dessus", "Philippe", "", "LaRAC"]]}, {"id": "2009.07022", "submitter": "Ningyu Zhang", "authors": "Haiyang Yu, Ningyu Zhang, Shumin Deng, Zonggang Yuan, Yantao Jia,\n  Huajun Chen", "title": "The Devil is the Classifier: Investigating Long Tail Relation\n  Classification with Decoupling Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-tailed relation classification is a challenging problem as the head\nclasses may dominate the training phase, thereby leading to the deterioration\nof the tail performance. Existing solutions usually address this issue via\nclass-balancing strategies, e.g., data re-sampling and loss re-weighting, but\nall these methods adhere to the schema of entangling learning of the\nrepresentation and classifier. In this study, we conduct an in-depth empirical\ninvestigation into the long-tailed problem and found that pre-trained models\nwith instance-balanced sampling already capture the well-learned\nrepresentations for all classes; moreover, it is possible to achieve better\nlong-tailed classification ability at low cost by only adjusting the\nclassifier. Inspired by this observation, we propose a robust classifier with\nattentive relation routing, which assigns soft weights by automatically\naggregating the relations. Extensive experiments on two datasets demonstrate\nthe effectiveness of our proposed approach. Code and datasets are available in\nhttps://github.com/zjunlp/deepke.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 12:47:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Yu", "Haiyang", ""], ["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Yuan", "Zonggang", ""], ["Jia", "Yantao", ""], ["Chen", "Huajun", ""]]}, {"id": "2009.07044", "submitter": "Ilianna Kollia", "authors": "D. Kollias, N. Bouas, Y. Vlaxos, V. Brillakis, M. Seferis, I. Kollia,\n  L. Sukissian, J. Wingate, and S. Kollias", "title": "Deep Transparent Prediction through Latent Representation Analysis", "comments": "16 pages, 8 figures, to be published at Foundations of Trustworthy AI\n  integrating Learning, Optimisation and Reasoning (TAILOR) Workshop of\n  European Conference on Artificial Intelligence (ECAI) 2020. arXiv admin note:\n  substantial text overlap with arXiv:1911.10653", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a novel deep learning approach, which extracts latent\ninformation from trained Deep Neural Networks (DNNs) and derives concise\nrepresentations that are analyzed in an effective, unified way for prediction\npurposes. It is well known that DNNs are capable of analyzing complex data;\nhowever, they lack transparency in their decision making, in the sense that it\nis not straightforward to justify their prediction, or to visualize the\nfeatures on which the decision was based. Moreover, they generally require\nlarge amounts of data in order to learn and become able to adapt to different\nenvironments. This makes their use difficult in healthcare, where trust and\npersonalization are key issues. Transparency combined with high prediction\naccuracy are the targeted goals of the proposed approach. It includes both\nsupervised DNN training and unsupervised learning of latent variables extracted\nfrom the trained DNNs. Domain Adaptation from multiple sources is also\npresented as an extension, where the extracted latent variable representations\nare used to generate predictions in other, non-annotated, environments.\nSuccessful application is illustrated through a large experimental study in\nvarious fields: prediction of Parkinson's disease from MRI and DaTScans;\nprediction of COVID-19 and pneumonia from CT scans and X-rays; optical\ncharacter verification in retail food packaging.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 19:21:40 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 22:06:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kollias", "D.", ""], ["Bouas", "N.", ""], ["Vlaxos", "Y.", ""], ["Brillakis", "V.", ""], ["Seferis", "M.", ""], ["Kollia", "I.", ""], ["Sukissian", "L.", ""], ["Wingate", "J.", ""], ["Kollias", "S.", ""]]}, {"id": "2009.07052", "submitter": "Felix Wick", "authors": "F. Wick and U. Kerzel and M. Hahn and M. Wolf and T. Singhal and D.\n  Stemmer and J. Ernst and M. Feindt", "title": "Demand Forecasting of Individual Probability Density Functions with\n  Machine Learning", "comments": "final version published in Springer Nature Operations Research Forum", "journal-ref": "SN Oper. Res. Forum 2, 37 (2021)", "doi": "10.1007/s43069-021-00079-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand forecasting is a central component of the replenishment process for\nretailers, as it provides crucial input for subsequent decision making like\nordering processes. In contrast to point estimates, such as the conditional\nmean of the underlying probability distribution, or confidence intervals,\nforecasting complete probability density functions allows to investigate the\nimpact on operational metrics, which are important to define the business\nstrategy, over the full range of the expected demand. Whereas metrics\nevaluating point estimates are widely used, methods for assessing the accuracy\nof predicted distributions are rare, and this work proposes new techniques for\nboth qualitative and quantitative evaluation methods. Using the supervised\nmachine learning method \"Cyclic Boosting\", complete individual probability\ndensity functions can be predicted such that each prediction is fully\nexplainable. This is of particular importance for practitioners, as it allows\nto avoid \"black-box\" models and understand the contributing factors for each\nindividual prediction. Another crucial aspect in terms of both explainability\nand generalizability of demand forecasting methods is the limitation of the\ninfluence of temporal confounding, which is prevalent in most state of the art\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:05:05 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 09:12:38 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 07:12:16 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wick", "F.", ""], ["Kerzel", "U.", ""], ["Hahn", "M.", ""], ["Wolf", "M.", ""], ["Singhal", "T.", ""], ["Stemmer", "D.", ""], ["Ernst", "J.", ""], ["Feindt", "M.", ""]]}, {"id": "2009.07055", "submitter": "Zheng Zhang", "authors": "Xiaohong Chen, Ying Liu, Shujie Ma, Zheng Zhang", "title": "Efficient Estimation of General Treatment Effects using Neural Networks\n  with A Diverging Number of Confounders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of causal effects is a primary goal of behavioral, social,\neconomic and biomedical sciences. Under the unconfounded treatment assignment\ncondition, adjustment for confounders requires estimating the nuisance\nfunctions relating outcome and/or treatment to confounders. The conventional\napproaches rely on either a parametric or a nonparametric modeling strategy to\napproximate the nuisance functions. Parametric methods can introduce serious\nbias into casual effect estimation due to possible mis-specification, while\nnonparametric estimation suffers from the \"curse of dimensionality\". This paper\nproposes a new unified approach for efficient estimation of treatment effects\nusing feedforward artificial neural networks when the number of covariates is\nallowed to increase with the sample size. We consider a general optimization\nframework that includes the average, quantile and asymmetric least squares\ntreatment effects as special cases. Under this unified setup, we develop a\ngeneralized optimization estimator for the treatment effect with the nuisance\nfunction estimated by neural networks. We further establish the consistency and\nasymptotic normality of the proposed estimator and show that it attains the\nsemiparametric efficiency bound. The proposed methods are illustrated via\nsimulation studies and a real data application.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:07:24 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 02:38:23 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 03:56:02 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Chen", "Xiaohong", ""], ["Liu", "Ying", ""], ["Ma", "Shujie", ""], ["Zhang", "Zheng", ""]]}, {"id": "2009.07098", "submitter": "Siyuan Shen", "authors": "Siyuan Shen, Tianjia Shao, Kun Zhou, Chenfanfu Jiang, Feng Luo, Yin\n  Yang", "title": "Second-order Neural Network Training Using Complex-step Directional\n  Derivative", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the superior performance of second-order optimization methods such as\nNewton's method is well known, they are hardly used in practice for deep\nlearning because neither assembling the Hessian matrix nor calculating its\ninverse is feasible for large-scale problems. Existing second-order methods\nresort to various diagonal or low-rank approximations of the Hessian, which\noften fail to capture necessary curvature information to generate a substantial\nimprovement. On the other hand, when training becomes batch-based (i.e.,\nstochastic), noisy second-order information easily contaminates the training\nprocedure unless expensive safeguard is employed. In this paper, we adopt a\nnumerical algorithm for second-order neural network training. We tackle the\npractical obstacle of Hessian calculation by using the complex-step finite\ndifference (CSFD) -- a numerical procedure adding an imaginary perturbation to\nthe function for derivative computation. CSFD is highly robust, efficient, and\naccurate (as accurate as the analytic result). This method allows us to\nliterally apply any known second-order optimization methods for deep learning\ntraining. Based on it, we design an effective Newton Krylov procedure. The key\nmechanism is to terminate the stochastic Krylov iteration as soon as a\ndisturbing direction is found so that unnecessary computation can be avoided.\nDuring the optimization, we monitor the approximation error in the Taylor\nexpansion to adjust the step size. This strategy combines advantages of line\nsearch and trust region methods making our method preserves good local and\nglobal convergency at the same time. We have tested our methods in various deep\nlearning tasks. The experiments show that our method outperforms exiting\nmethods, and it often converges one-order faster. We believe our method will\ninspire a wide-range of new algorithms for deep learning and numerical\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:46:57 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Shen", "Siyuan", ""], ["Shao", "Tianjia", ""], ["Zhou", "Kun", ""], ["Jiang", "Chenfanfu", ""], ["Luo", "Feng", ""], ["Yang", "Yin", ""]]}, {"id": "2009.07101", "submitter": "Kazuhisa Fujita Dr.", "authors": "Kazuhisa Fujita", "title": "Approximate spectral clustering using both reference vectors and\n  topology of the network generated by growing neural gas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering (SC) is one of the most popular clustering methods and\noften outperforms traditional clustering methods. SC uses the eigenvectors of a\nLaplacian matrix calculated from a similarity matrix of a dataset. SC has\nserious drawbacks: the significant increases in the time complexity derived\nfrom the computation of eigenvectors and the memory space complexity to store\nthe similarity matrix. To address the issues, I develop a new approximate\nspectral clustering using the network generated by growing neural gas (GNG),\ncalled ASC with GNG in this study. ASC with GNG uses not only reference vectors\nfor vector quantization but also the topology of the network for extraction of\nthe topological relationship between data points in a dataset. ASC with GNG\ncalculates the similarity matrix from both the reference vectors and the\ntopology of the network generated by GNG. Using the network generated from a\ndataset by GNG, ASC with GNG achieves to reduce the computational and space\ncomplexities and improve clustering quality. In this study, I demonstrate that\nASC with GNG effectively reduces the computational time. Moreover, this study\nshows that ASC with GNG provides equal to or better clustering performance than\nSC.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:49:24 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 13:55:19 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 02:23:16 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Fujita", "Kazuhisa", ""]]}, {"id": "2009.07110", "submitter": "Wei Chen", "authors": "Wei Chen and Faez Ahmed", "title": "MO-PaDGAN: Reparameterizing Engineering Designs for Augmented\n  Multi-objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective optimization is key to solving many Engineering Design\nproblems, where design parameters are optimized for several performance\nindicators. However, optimization results are highly dependent on how the\ndesigns are parameterized. Researchers have shown that deep generative models\ncan learn compact design representations, providing a new way of parameterizing\ndesigns to achieve faster convergence and improved optimization performance.\nDespite their success in capturing complex distributions, existing generative\nmodels face three challenges when used for design problems: 1) generated\ndesigns have limited design space coverage, 2) the generator ignores design\nperformance, and 3) the new parameterization is unable to represent designs\nbeyond training data. To address these challenges, we propose MO-PaDGAN, which\nadds a Determinantal Point Processes based loss function to the generative\nadversarial network to simultaneously model diversity and (multi-variate)\nperformance. MO-PaDGAN can thus improve the performances and coverage of\ngenerated designs, and even generate designs with performances exceeding those\nfrom training data. When using MO-PaDGAN as a new parameterization in\nmulti-objective optimization, we can discover much better Pareto fronts even\nthough the training data do not cover those Pareto fronts. In a real-world\nmulti-objective airfoil design example, we demonstrate that MO-PaDGAN achieves,\non average, a 186% improvement in the hypervolume indicator when compared to\nthe vanilla GAN or other state-of-the-art parameterization methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:58:31 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Chen", "Wei", ""], ["Ahmed", "Faez", ""]]}, {"id": "2009.07111", "submitter": "Sheng Wan", "authors": "Sheng Wan and Shirui Pan and Jian Yang and Chen Gong", "title": "Contrastive and Generative Graph Convolutional Networks for Graph-based\n  Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based Semi-Supervised Learning (SSL) aims to transfer the labels of a\nhandful of labeled data to the remaining massive unlabeled data via a graph. As\none of the most popular graph-based SSL approaches, the recently proposed Graph\nConvolutional Networks (GCNs) have gained remarkable progress by combining the\nsound expressiveness of neural networks with graph structure. Nevertheless, the\nexisting graph-based methods do not directly address the core problem of SSL,\ni.e., the shortage of supervision, and thus their performances are still very\nlimited. To accommodate this issue, a novel GCN-based SSL algorithm is\npresented in this paper to enrich the supervision signals by utilizing both\ndata similarities and graph structure. Firstly, by designing a semi-supervised\ncontrastive loss, improved node representations can be generated via maximizing\nthe agreement between different views of the same data or the data from the\nsame class. Therefore, the rich unlabeled data and the scarce yet valuable\nlabeled data can jointly provide abundant supervision information for learning\ndiscriminative node representations, which helps improve the subsequent\nclassification result. Secondly, the underlying determinative relationship\nbetween the data features and input graph topology is extracted as\nsupplementary supervision signals for SSL via using a graph generative loss\nrelated to the input features. Intensive experimental results on a variety of\nreal-world datasets firmly verify the effectiveness of our algorithm compared\nwith other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:59:28 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 02:06:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wan", "Sheng", ""], ["Pan", "Shirui", ""], ["Yang", "Jian", ""], ["Gong", "Chen", ""]]}, {"id": "2009.07139", "submitter": "Vikram Venkatraghavan", "authors": "Vikram Venkatraghavan, Stefan Klein, Lana Fani, Leontine S. Ham, Henri\n  Vrooman, M. Kamran Ikram, Wiro J. Niessen, Esther E. Bron (for the\n  Alzheimer's Disease Neuroimaging Initiative)", "title": "Analyzing the effect of APOE on Alzheimer's disease progression using an\n  event-based model for stratified populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Alzheimer's disease (AD) is the most common form of dementia and is\nphenotypically heterogeneous. APOE is a triallelic gene which correlates with\nphenotypic heterogeneity in AD. In this work, we determined the effect of APOE\nalleles on the disease progression timeline of AD using a discriminative\nevent-based model (DEBM). Since DEBM is a data-driven model, stratification\ninto smaller disease subgroups would lead to more inaccurate models as compared\nto fitting the model on the entire dataset. Hence our secondary aim is to\npropose and evaluate novel approaches in which we split the different steps of\nDEBM into group-aspecific and group-specific parts, where the entire dataset is\nused to train the group-aspecific parts and only the data from a specific group\nis used to train the group-specific parts of the DEBM. We performed simulation\nexperiments to benchmark the accuracy of the proposed approaches and to select\nthe optimal approach. Subsequently, the chosen approach was applied to the\nbaseline data of 417 cognitively normal, 235 mild cognitively impaired who\nconvert to AD within 3 years, and 342 AD patients from the Alzheimer's Disease\nNeuroimaging Initiative (ADNI) dataset to gain new insights into the effect of\nAPOE carriership on the disease progression timeline of AD. The presented\nmodels could aid understanding of the disease, and in selecting homogeneous\ngroup of presymptomatic subjects at-risk of developing symptoms for clinical\ntrials.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:46:10 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Venkatraghavan", "Vikram", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Klein", "Stefan", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Fani", "Lana", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Ham", "Leontine S.", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Vrooman", "Henri", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Ikram", "M. Kamran", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Niessen", "Wiro J.", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Bron", "Esther E.", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"]]}, {"id": "2009.07165", "submitter": "Kaivalya Rawal", "authors": "Kaivalya Rawal, Himabindu Lakkaraju", "title": "Beyond Individualized Recourse: Interpretable and Interactive Summaries\n  of Actionable Recourses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As predictive models are increasingly being deployed in high-stakes\ndecision-making, there has been a lot of interest in developing algorithms\nwhich can provide recourses to affected individuals. While developing such\ntools is important, it is even more critical to analyse and interpret a\npredictive model, and vet it thoroughly to ensure that the recourses it offers\nare meaningful and non-discriminatory before it is deployed in the real world.\nTo this end, we propose a novel model agnostic framework called Actionable\nRecourse Summaries (AReS) to construct global counterfactual explanations which\nprovide an interpretable and accurate summary of recourses for the entire\npopulation. We formulate a novel objective which simultaneously optimizes for\ncorrectness of the recourses and interpretability of the explanations, while\nminimizing overall recourse costs across the entire population. More\nspecifically, our objective enables us to learn, with optimality guarantees on\nrecourse correctness, a small number of compact rule sets each of which capture\nrecourses for well defined subpopulations within the data. We also demonstrate\ntheoretically that several of the prior approaches proposed to generate\nrecourses for individuals are special cases of our framework. Experimental\nevaluation with real world datasets and user studies demonstrate that our\nframework can provide decision makers with a comprehensive overview of\nrecourses corresponding to any black box model, and consequently help detect\nundesirable model biases and discrimination.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:14:08 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 01:51:06 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 19:22:25 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Rawal", "Kaivalya", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2009.07173", "submitter": "Thosini Bamunu Mudiyanselage", "authors": "Thosini Bamunu Mudiyanselage, Xiujuan Lei, Nipuna Senanayake, Yanqing\n  Zhang, Yi Pan", "title": "Graph Convolution Networks Using Message Passing and Multi-Source\n  Similarity Features for Predicting circRNA-Disease Association", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs can be used to effectively represent complex data structures. Learning\nthese irregular data in graphs is challenging and still suffers from shallow\nlearning. Applying deep learning on graphs has recently showed good performance\nin many applications in social analysis, bioinformatics etc. A message passing\ngraph convolution network is such a powerful method which has expressive power\nto learn graph structures. Meanwhile, circRNA is a type of non-coding RNA which\nplays a critical role in human diseases. Identifying the associations between\ncircRNAs and diseases is important to diagnosis and treatment of complex\ndiseases. However, there are limited number of known associations between them\nand conducting biological experiments to identify new associations is time\nconsuming and expensive. As a result, there is a need of building efficient and\nfeasible computation methods to predict potential circRNA-disease associations.\nIn this paper, we propose a novel graph convolution network framework to learn\nfeatures from a graph built with multi-source similarity information to predict\ncircRNA-disease associations. First we use multi-source information of circRNA\nsimilarity, disease and circRNA Gaussian Interaction Profile (GIP) kernel\nsimilarity to extract the features using first graph convolution. Then we\npredict disease associations for each circRNA with second graph convolution.\nProposed framework with five-fold cross validation on various experiments shows\npromising results in predicting circRNA-disease association and outperforms\nother existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:22:42 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mudiyanselage", "Thosini Bamunu", ""], ["Lei", "Xiujuan", ""], ["Senanayake", "Nipuna", ""], ["Zhang", "Yanqing", ""], ["Pan", "Yi", ""]]}, {"id": "2009.07184", "submitter": "Yu Duan", "authors": "Yu Duan, Matthew Eaton, and Michael Bluck", "title": "Fixed Inducing Points Online Bayesian Calibration for Computer Models\n  with an Application to a Scale-Resolving CFD Simulation", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2021.110243", "report-no": null, "categories": "physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel fixed inducing points online Bayesian calibration\n(FIPO-BC) algorithm to efficiently learn the model parameters using a benchmark\ndatabase. The standard Bayesian calibration (STD-BC) algorithm provides a\nstatistical method to calibrate the parameters of computationally expensive\nmodels. However, the STD-BC algorithm scales very badly with the number of data\npoints and lacks online learning capability. The proposed FIPO-BC algorithm\ngreatly improves the computational efficiency and enables the online\ncalibration by executing the calibration on a set of predefined inducing\npoints.\n  To demonstrate the procedure of the FIPO-BC algorithm, two tests are\nperformed, finding the optimal value and exploring the posterior distribution\nof 1) the parameter in a simple function, and 2) the high-wave number damping\nfactor in a scale-resolving turbulence model (SAS-SST). The results (such as\nthe calibrated model parameter and its posterior distribution) of FIPO-BC with\ndifferent inducing points are compared to those of STD-BC. It is found that\nFIPO-BC and STD-BC can provide very similar results, once the predefined set of\ninducing point in FIPO-BC is sufficiently fine. But, the FIPO-BC algorithm is\nat least ten times faster than the STD-BC algorithm. Meanwhile, the online\nfeature of the FIPO-BC allows continuous updating of the calibration outputs\nand potentially reduces the workload on generating the database.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:48:22 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Duan", "Yu", ""], ["Eaton", "Matthew", ""], ["Bluck", "Michael", ""]]}, {"id": "2009.07200", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, David Saltiel, Jean-Jacques Ohana, and Jamal Atif", "title": "Detecting and adapting to crisis pattern with context based Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has reached super human levels in complex\ntasks like game solving (Go and autonomous driving). However, it remains an\nopen question whether DRL can reach human level in applications to financial\nproblems and in particular in detecting pattern crisis and consequently\ndis-investing. In this paper, we present an innovative DRL framework consisting\nin two sub-networks fed respectively with portfolio strategies past\nperformances and standard deviations as well as additional contextual features.\nThe second sub network plays an important role as it captures dependencies with\ncommon financial indicators features like risk aversion, economic surprise\nindex and correlations between assets that allows taking into account context\nbased information. We compare different network architectures either using\nlayers of convolutions to reduce network's complexity or LSTM block to capture\ntime dependency and whether previous allocations is important in the modeling.\nWe also use adversarial training to make the final model more robust. Results\non test set show this approach substantially over-performs traditional\nportfolio optimization methods like Markowitz and is able to detect and\nanticipate crisis like the current Covid one.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 12:11:08 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:49:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ohana", "Jean-Jacques", ""], ["Atif", "Jamal", ""]]}, {"id": "2009.07241", "submitter": "Laurent Callot", "authors": "Luyang Kong, Lifan Chen, Ming Chen, Parminder Bhatia, Laurent Callot", "title": "Improve black-box sequential anomaly detector relevancy with limited\n  user feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detectors are often designed to catch statistical anomalies.\nEnd-users typically do not have interest in all of the detected outliers, but\nonly those relevant to their application. Given an existing black-box\nsequential anomaly detector, this paper proposes a method to improve its user\nrelevancy using a small number of human feedback. As our first contribution,\nthe method is agnostic to the detector: it only assumes access to its anomaly\nscores, without requirement on any additional information inside it. Inspired\nby a fact that anomalies are of different types, our approach identifies these\ntypes and utilizes user feedback to assign relevancy to types. This relevancy\nscore, as our second contribution, is used to adjust the subsequent anomaly\nselection process. Empirical results on synthetic and real-world datasets show\nthat our approach yields significant improvements on precision and recall over\na range of anomaly detectors.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:26:38 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Kong", "Luyang", ""], ["Chen", "Lifan", ""], ["Chen", "Ming", ""], ["Bhatia", "Parminder", ""], ["Callot", "Laurent", ""]]}, {"id": "2009.07327", "submitter": "Przemys{\\l}aw Spurek", "authors": "Szymon Knop, Marcin Mazur, Przemys{\\l}aw Spurek, Jacek Tabor, Igor\n  Podolak", "title": "Generative models with kernel distance in data space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models dealing with modeling a~joint data distribution are\ngenerally either autoencoder or GAN based. Both have their pros and cons,\ngenerating blurry images or being unstable in training or prone to mode\ncollapse phenomenon, respectively. The objective of this paper is to construct\na~model situated between above architectures, one that does not inherit their\nmain weaknesses. The proposed LCW generator (Latent Cramer-Wold generator)\nresembles a classical GAN in transforming Gaussian noise into data space. What\nis of utmost importance, instead of a~discriminator, LCW generator uses kernel\ndistance. No adversarial training is utilized, hence the name generator. It is\ntrained in two phases. First, an autoencoder based architecture, using kernel\nmeasures, is built to model a manifold of data. We propose a Latent Trick\nmapping a Gaussian to latent in order to get the final model. This results in\nvery competitive FID values.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 19:11:47 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Knop", "Szymon", ""], ["Mazur", "Marcin", ""], ["Spurek", "Przemys\u0142aw", ""], ["Tabor", "Jacek", ""], ["Podolak", "Igor", ""]]}, {"id": "2009.07330", "submitter": "Alp Dener", "authors": "Alp Dener, Marco Andres Miller, Randy Michael Churchill, Todd Munson,\n  Choong-Seock Chang", "title": "Training neural networks under physical constraints using a stochastic\n  augmented Lagrangian approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG math.OC physics.plasm-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the physics-constrained training of an encoder-decoder neural\nnetwork for approximating the Fokker-Planck-Landau collision operator in the\n5-dimensional kinetic fusion simulation in XGC. To train this network, we\npropose a stochastic augmented Lagrangian approach that utilizes pyTorch's\nnative stochastic gradient descent method to solve the inner unconstrained\nminimization subproblem, paired with a heuristic update for the penalty factor\nand Lagrange multipliers in the outer augmented Lagrangian loop. Our training\nresults for a single ion species case, with self-collisions and collision\nagainst electrons, show that the proposed stochastic augmented Lagrangian\napproach can achieve higher model prediction accuracy than training with a\nfixed penalty method for our application problem, with the accuracy high enough\nfor practical applications in kinetic simulations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 19:20:29 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Dener", "Alp", ""], ["Miller", "Marco Andres", ""], ["Churchill", "Randy Michael", ""], ["Munson", "Todd", ""], ["Chang", "Choong-Seock", ""]]}, {"id": "2009.07346", "submitter": "Georgios Theocharous", "authors": "Georgios Theocharous, Yash Chandak, Philip S. Thomas, Frits de Nijs", "title": "Reinforcement Learning for Strategic Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic recommendations (SR) refer to the problem where an intelligent\nagent observes the sequential behaviors and activities of users and decides\nwhen and how to interact with them to optimize some long-term objectives, both\nfor the user and the business. These systems are in their infancy in the\nindustry and in need of practical solutions to some fundamental research\nchallenges. At Adobe research, we have been implementing such systems for\nvarious use-cases, including points of interest recommendations, tutorial\nrecommendations, next step guidance in multi-media editing software, and ad\nrecommendation for optimizing lifetime value. There are many research\nchallenges when building these systems, such as modeling the sequential\nbehavior of users, deciding when to intervene and offer recommendations without\nannoying the user, evaluating policies offline with high confidence, safe\ndeployment, non-stationarity, building systems from passive data that do not\ncontain past recommendations, resource constraint optimization in multi-user\nsystems, scaling to large and dynamic actions spaces, and handling and\nincorporating human cognitive biases. In this paper we cover various use-cases\nand research challenges we solved to make these systems practical.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 20:45:48 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Theocharous", "Georgios", ""], ["Chandak", "Yash", ""], ["Thomas", "Philip S.", ""], ["de Nijs", "Frits", ""]]}, {"id": "2009.07349", "submitter": "Robert Susik", "authors": "Robert Susik", "title": "Recurrent autoencoder with sequence-aware encoding", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-77964-1_4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) received a vast amount of attention last\ndecade. Recently, the architectures of Recurrent AutoEncoders (RAE) found many\napplications in practice. RAE can extract the semantically valuable\ninformation, called context that represents a latent space useful for further\nprocessing. Nevertheless, recurrent autoencoders are hard to train, and the\ntraining process takes much time. In this paper, we propose an autoencoder\narchitecture with sequence-aware encoding, which employs 1D convolutional layer\nto improve its performance in terms of model training time. We prove that the\nrecurrent autoencoder with sequence-aware encoding outperforms a standard RAE\nin terms of training speed in most cases. The preliminary results show that the\nproposed solution dominates over the standard RAE, and the training process is\norder of magnitude faster.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 20:51:20 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 09:56:25 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 14:22:43 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Susik", "Robert", ""]]}, {"id": "2009.07360", "submitter": "Chidubem Arachie", "authors": "Chidubem Arachie, Bert Huang", "title": "Constrained Labeling for Weakly Supervised Learning", "comments": "Accepted at UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Curation of large fully supervised datasets has become one of the major\nroadblocks for machine learning. Weak supervision provides an alternative to\nsupervised learning by training with cheap, noisy, and possibly correlated\nlabeling functions from varying sources. The key challenge in weakly supervised\nlearning is combining the different weak supervision signals while navigating\nmisleading correlations in their errors. In this paper, we propose a simple\ndata-free approach for combining weak supervision signals by defining a\nconstrained space for the possible labels of the weak signals and training with\na random labeling within this constrained space. Our method is efficient and\nstable, converging after a few iterations of gradient descent. We prove\ntheoretical conditions under which the worst-case error of the randomized label\ndecreases with the rank of the linear constraints. We show experimentally that\nour method outperforms other weak supervision methods on various text- and\nimage-classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:30:53 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 02:32:49 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 02:48:45 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 17:35:46 GMT"}, {"version": "v5", "created": "Sat, 29 May 2021 19:51:20 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Arachie", "Chidubem", ""], ["Huang", "Bert", ""]]}, {"id": "2009.07367", "submitter": "Matthew Charles Edwards", "authors": "Matthew C. Edwards", "title": "Classifying the Equation of State from Rotating Core Collapse\n  Gravitational Waves with Deep Learning", "comments": "10 pages, 5 figures", "journal-ref": "Phys. Rev. D 103, 024025 (2021)", "doi": "10.1103/PhysRevD.103.024025", "report-no": null, "categories": "astro-ph.IM gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we seek to answer the question \"given a rotating core collapse\ngravitational wave signal, can we determine its nuclear equation of state?\". To\nanswer this question, we employ deep convolutional neural networks to learn\nvisual and temporal patterns embedded within rotating core collapse\ngravitational wave (GW) signals in order to predict the nuclear equation of\nstate (EOS). Using the 1824 rotating core collapse GW simulations by Richers et\nal. (2017), which has 18 different nuclear EOS, we consider this to be a\nclassic multi-class image classification and sequence classification problem.\nWe attain up to 72\\% correct classifications in the test set, and if we\nconsider the \"top 5\" most probable labels, this increases to up to 97\\%,\ndemonstrating that there is a moderate and measurable dependence of the\nrotating core collapse GW signal on the nuclear EOS.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 22:04:59 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 23:04:38 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 06:28:03 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Edwards", "Matthew C.", ""]]}, {"id": "2009.07368", "submitter": "William Whitney", "authors": "William F. Whitney, Min Jae Song, David Brandfonbrener, Jaan Altosaar,\n  Kyunghyun Cho", "title": "Evaluating representations by the complexity of learning low-loss\n  predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of evaluating representations of data for use in\nsolving a downstream task. We propose to measure the quality of a\nrepresentation by the complexity of learning a predictor on top of the\nrepresentation that achieves low loss on a task of interest, and introduce two\nmethods, surplus description length (SDL) and $\\varepsilon$ sample complexity\n($\\varepsilon$SC). In contrast to prior methods, which measure the amount of\ninformation about the optimal predictor that is present in a specific amount of\ndata, our methods measure the amount of information needed from the data to\nrecover an approximation of the optimal predictor up to a specified tolerance.\nWe present a framework to compare these methods based on plotting the\nvalidation loss versus evaluation dataset size (the \"loss-data\" curve).\nExisting measures, such as mutual information and minimum description length\nprobes, correspond to slices and integrals along the data axis of the loss-data\ncurve, while ours correspond to slices and integrals along the loss axis. We\nprovide experiments on real data to compare the behavior of each of these\nmethods over datasets of varying size along with a high performance open source\nlibrary for representation evaluation at\nhttps://github.com/willwhitney/reprieve.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 22:06:58 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:50:13 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Whitney", "William F.", ""], ["Song", "Min Jae", ""], ["Brandfonbrener", "David", ""], ["Altosaar", "Jaan", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2009.07385", "submitter": "Siavash Ameli", "authors": "Siavash Ameli, Shawn C. Shadden", "title": "Interpolating the Trace of the Inverse of Matrix $\\mathbf{A} + t\n  \\mathbf{B}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop heuristic interpolation methods for the function $t \\mapsto\n\\operatorname{trace}\\left( (\\mathbf{A} + t \\mathbf{B})^{-1} \\right)$, where the\nmatrices $\\mathbf{A}$ and $\\mathbf{B}$ are symmetric and positive definite and\n$t$ is a real variable. This function is featured in many applications in\nstatistics, machine learning, and computational physics. The presented\ninterpolation functions are based on the modification of a sharp upper bound\nthat we derive for this function, which is a new trace inequality for matrices.\nWe demonstrate the accuracy and performance of the proposed method with\nnumerical examples, namely, the marginal maximum likelihood estimation for\nlinear Gaussian process regression and the estimation of the regularization\nparameter of ridge regression with the generalized cross-validation method.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 23:11:17 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ameli", "Siavash", ""], ["Shadden", "Shawn C.", ""]]}, {"id": "2009.07415", "submitter": "Daochen Zha", "authors": "Daochen Zha, Kwei-Herng Lai, Mingyang Wan, Xia Hu", "title": "Meta-AAD: Active Anomaly Detection with Deep Reinforcement Learning", "comments": "Accepted by ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High false-positive rate is a long-standing challenge for anomaly detection\nalgorithms, especially in high-stake applications. To identify the true\nanomalies, in practice, analysts or domain experts will be employed to\ninvestigate the top instances one by one in a ranked list of anomalies\nidentified by an anomaly detection system. This verification procedure\ngenerates informative labels that can be leveraged to re-rank the anomalies so\nas to help the analyst to discover more true anomalies given a time budget.\nSome re-ranking strategies have been proposed to approximate the above\nsequential decision process. Specifically, existing strategies have been\nfocused on making the top instances more likely to be anomalous based on the\nfeedback. Then they greedily select the top-1 instance for query. However,\nthese greedy strategies could be sub-optimal since some low-ranked instances\ncould be more helpful in the long-term. In this work, we propose Active Anomaly\nDetection with Meta-Policy (Meta-AAD), a novel framework that learns a\nmeta-policy for query selection. Specifically, Meta-AAD leverages deep\nreinforcement learning to train the meta-policy to select the most proper\ninstance to explicitly optimize the number of discovered anomalies throughout\nthe querying process. Meta-AAD is easy to deploy since a trained meta-policy\ncan be directly applied to any new datasets without further tuning. Extensive\nexperiments on 24 benchmark datasets demonstrate that Meta-AAD significantly\noutperforms the state-of-the-art re-ranking strategies and the unsupervised\nbaseline. The empirical analysis shows that the trained meta-policy is\ntransferable and inherently achieves a balance between long-term and short-term\nrewards.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:47:42 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zha", "Daochen", ""], ["Lai", "Kwei-Herng", ""], ["Wan", "Mingyang", ""], ["Hu", "Xia", ""]]}, {"id": "2009.07417", "submitter": "Yicheng Xu", "authors": "Yicheng Xu, Vincent Chau, Chenchen Wu, Yong Zhang, Vassilis\n  Zissimopoulos, Yifei Zou", "title": "Too Much Information Kills Information: A Clustering Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most fundamental tools in the artificial\nintelligence area, particularly in the pattern recognition and learning theory.\nIn this paper, we propose a simple, but novel approach for variance-based\nk-clustering tasks, included in which is the widely known k-means clustering.\nThe proposed approach picks a sampling subset from the given dataset and makes\ndecisions based on the data information in the subset only. With certain\nassumptions, the resulting clustering is provably good to estimate the optimum\nof the variance-based objective with high probability. Extensive experiments on\nsynthetic datasets and real-world datasets show that to obtain competitive\nresults compared with k-means method (Llyod 1982) and k-means++ method (Arthur\nand Vassilvitskii 2007), we only need 7% information of the dataset. If we have\nup to 15% information of the dataset, then our algorithm outperforms both the\nk-means method and k-means++ method in at least 80% of the clustering tasks, in\nterms of the quality of clustering. Also, an extended algorithm based on the\nsame idea guarantees a balanced k-clustering result.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:54:26 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Xu", "Yicheng", ""], ["Chau", "Vincent", ""], ["Wu", "Chenchen", ""], ["Zhang", "Yong", ""], ["Zissimopoulos", "Vassilis", ""], ["Zou", "Yifei", ""]]}, {"id": "2009.07419", "submitter": "Achintya Gopal", "authors": "Achintya Gopal", "title": "Quasi-Autoregressive Residual (QuAR) Flows", "comments": "Appeared in ICML Workshop on Invertible Neural Networks, Normalizing\n  Flows, and Explicit Likelihood Models 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing Flows are a powerful technique for learning and modeling\nprobability distributions given samples from those distributions. The current\nstate of the art results are built upon residual flows as these can model a\nlarger hypothesis space than coupling layers. However, residual flows are\nextremely computationally expensive both to train and to use, which limits\ntheir applicability in practice. In this paper, we introduce a simplification\nto residual flows using a Quasi-Autoregressive (QuAR) approach. Compared to the\nstandard residual flow approach, this simplification retains many of the\nbenefits of residual flows while dramatically reducing the compute time and\nmemory requirements, thus making flow-based modeling approaches far more\ntractable and broadening their potential applicability.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:56:24 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Gopal", "Achintya", ""]]}, {"id": "2009.07430", "submitter": "Alex G. C.  de S\\'a", "authors": "M\\'arcio P. Basgalupp, Rodrigo C. Barros, Alex G. C. de S\\'a, Gisele\n  L. Pappa, Rafael G. Mantovani, Andr\\'e C. P. L. F. de Carvalho, Alex A.\n  Freitas", "title": "An Extensive Experimental Evaluation of Automated Machine Learning\n  Methods for Recommending Classification Algorithms (Extended Version)", "comments": "Accepted at Evolutionary Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an experimental comparison among four Automated Machine\nLearning (AutoML) methods for recommending the best classification algorithm\nfor a given input dataset. Three of these methods are based on Evolutionary\nAlgorithms (EAs), and the other is Auto-WEKA, a well-known AutoML method based\non the Combined Algorithm Selection and Hyper-parameter optimisation (CASH)\napproach. The EA-based methods build classification algorithms from a single\nmachine learning paradigm: either decision-tree induction, rule induction, or\nBayesian network classification. Auto-WEKA combines algorithm selection and\nhyper-parameter optimisation to recommend classification algorithms from\nmultiple paradigms. We performed controlled experiments where these four AutoML\nmethods were given the same runtime limit for different values of this limit.\nIn general, the difference in predictive accuracy of the three best AutoML\nmethods was not statistically significant. However, the EA evolving\ndecision-tree induction algorithms has the advantage of producing algorithms\nthat generate interpretable classification models and that are more scalable to\nlarge datasets, by comparison with many algorithms from other learning\nparadigms that can be recommended by Auto-WEKA. We also observed that Auto-WEKA\nhas shown meta-overfitting, a form of overfitting at the meta-learning level,\nrather than at the base-learning level.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 02:36:43 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Basgalupp", "M\u00e1rcio P.", ""], ["Barros", "Rodrigo C.", ""], ["de S\u00e1", "Alex G. C.", ""], ["Pappa", "Gisele L.", ""], ["Mantovani", "Rafael G.", ""], ["de Carvalho", "Andr\u00e9 C. P. L. F.", ""], ["Freitas", "Alex A.", ""]]}, {"id": "2009.07439", "submitter": "Dachao Lin", "authors": "Dachao Lin, Ruoyu Sun, Zhihua Zhang", "title": "On the Landscape of One-hidden-layer Sparse Networks and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse neural networks have received increasing interests due to their small\nsize compared to dense networks. Nevertheless, most existing works on neural\nnetwork theory have focused on dense neural networks, and our understanding of\nsparse networks is very limited. In this paper, we study the loss landscape of\none-hidden-layer sparse networks. We first consider sparse networks with linear\nactivations. We show that sparse linear networks can have spurious strict\nminima, which is in sharp contrast to dense linear networks which do not even\nhave spurious minima. Second, we show that spurious valleys can exist for wide\nsparse non-linear networks. This is different from wide dense networks which do\nnot have spurious valleys under mild assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:02:13 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 12:29:35 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 03:49:33 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lin", "Dachao", ""], ["Sun", "Ruoyu", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2009.07453", "submitter": "Se Jung Kwon", "authors": "Insoo Chung, Byeongwook Kim, Yoonjung Choi, Se Jung Kwon, Yongkweon\n  Jeon, Baeseong Park, Sangha Kim and Dongsoo Lee", "title": "Extremely Low Bit Transformer Quantization for On-Device Neural Machine\n  Translation", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of widely used Transformer architecture is challenging because\nof heavy computation load and memory overhead during inference, especially when\nthe target device is limited in computational resources such as mobile or edge\ndevices. Quantization is an effective technique to address such challenges. Our\nanalysis shows that for a given number of quantization bits, each block of\nTransformer contributes to translation quality and inference computations in\ndifferent manners. Moreover, even inside an embedding block, each word presents\nvastly different contributions. Correspondingly, we propose a mixed precision\nquantization strategy to represent Transformer weights by an extremely low\nnumber of bits (e.g., under 3 bits). For example, for each word in an embedding\nblock, we assign different quantization bits based on statistical property. Our\nquantized Transformer model achieves 11.8$\\times$ smaller model size than the\nbaseline model, with less than -0.5 BLEU. We achieve 8.3$\\times$ reduction in\nrun-time memory footprints and 3.5$\\times$ speed up (Galaxy N10+) such that our\nproposed compression strategy enables efficient implementation for on-device\nNMT.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:58:01 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 05:23:31 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Chung", "Insoo", ""], ["Kim", "Byeongwook", ""], ["Choi", "Yoonjung", ""], ["Kwon", "Se Jung", ""], ["Jeon", "Yongkweon", ""], ["Park", "Baeseong", ""], ["Kim", "Sangha", ""], ["Lee", "Dongsoo", ""]]}, {"id": "2009.07455", "submitter": "Jianzong Wang", "authors": "Anxun He, Jianzong Wang, Zhangcheng Huang and Jing Xiao", "title": "FedSmart: An Auto Updating Federated Learning Optimization Mechanism", "comments": "has been presented in APWeb-WAIM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has made an important contribution to data\nprivacy-preserving. Many previous works are based on the assumption that the\ndata are independently identically distributed (IID). As a result, the model\nperformance on non-identically independently distributed (non-IID) data is\nbeyond expectation, which is the concrete situation. Some existing methods of\nensuring the model robustness on non-IID data, like the data-sharing strategy\nor pretraining, may lead to privacy leaking. In addition, there exist some\nparticipants who try to poison the model with low-quality data. In this paper,\na performance-based parameter return method for optimization is introduced, we\nterm it FederatedSmart (FedSmart). It optimizes different model for each client\nthrough sharing global gradients, and it extracts the data from each client as\na local validation set, and the accuracy that model achieves in round t\ndetermines the weights of the next round. The experiment results show that\nFedSmart enables the participants to allocate a greater weight to the ones with\nsimilar data distribution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:59:33 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["He", "Anxun", ""], ["Wang", "Jianzong", ""], ["Huang", "Zhangcheng", ""], ["Xiao", "Jing", ""]]}, {"id": "2009.07476", "submitter": "Ryo Yonetani", "authors": "Ryo Yonetani and Tatsunori Taniai and Mohammadamin Barekatain and Mai\n  Nishimura and Asako Kanezaki", "title": "Path Planning using Neural A* Search", "comments": "To appear in the International Conference on Machine Learning (ICML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Neural A*, a novel data-driven search method for path planning\nproblems. Despite the recent increasing attention to data-driven path planning,\nmachine learning approaches to search-based planning are still challenging due\nto the discrete nature of search algorithms. In this work, we reformulate a\ncanonical A* search algorithm to be differentiable and couple it with a\nconvolutional encoder to form an end-to-end trainable neural network planner.\nNeural A* solves a path planning problem by encoding a problem instance to a\nguidance map and then performing the differentiable A* search with the guidance\nmap. By learning to match the search results with ground-truth paths provided\nby experts, Neural A* can produce a path consistent with the ground truth\naccurately and efficiently. Our extensive experiments confirmed that Neural A*\noutperformed state-of-the-art data-driven planners in terms of the search\noptimality and efficiency trade-off. Furthermore, Neural A* successfully\npredicted realistic human trajectories by directly performing search-based\nplanning on natural image inputs. Project page:\nhttps://omron-sinicx.github.io/neural-astar/\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 05:22:44 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 03:38:06 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 13:27:47 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yonetani", "Ryo", ""], ["Taniai", "Tatsunori", ""], ["Barekatain", "Mohammadamin", ""], ["Nishimura", "Mai", ""], ["Kanezaki", "Asako", ""]]}, {"id": "2009.07509", "submitter": "Anushree Rankawat", "authors": "Anushree Rankawat, Mansi Rankawat, Harshal B. Oza", "title": "A priori guarantees of finite-time convergence for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we perform Lyapunov based analysis of the loss function to\nderive an a priori upper bound on the settling time of deep neural networks.\nWhile previous studies have attempted to understand deep learning using control\ntheory framework, there is limited work on a priori finite time convergence\nanalysis. Drawing from the advances in analysis of finite-time control of\nnon-linear systems, we provide a priori guarantees of finite-time convergence\nin a deterministic control theoretic setting. We formulate the supervised\nlearning framework as a control problem where weights of the network are\ncontrol inputs and learning translates into a tracking problem. An analytical\nformula for finite-time upper bound on settling time is computed a priori under\nthe assumptions of boundedness of input. Finally, we prove the robustness and\nsensitivity of the loss function against input perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:13:16 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Rankawat", "Anushree", ""], ["Rankawat", "Mansi", ""], ["Oza", "Harshal B.", ""]]}, {"id": "2009.07518", "submitter": "Alexandre Letard", "authors": "Alexandre Letard, Tassadit Amghar, Olivier Camp, Nicolas Gutowski", "title": "Partial Bandit and Semi-Bandit: Making the Most Out of Scarce Users'\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on Multi-Armed Bandits (MAB) and Combinatorial Multi-Armed\nBandits (COM-MAB) show good results on a global accuracy metric. This can be\nachieved, in the case of recommender systems, with personalization. However,\nwith a combinatorial online learning approach, personalization implies a large\namount of user feedbacks. Such feedbacks can be hard to acquire when users need\nto be directly and frequently solicited. For a number of fields of activities\nundergoing the digitization of their business, online learning is unavoidable.\nThus, a number of approaches allowing implicit user feedback retrieval have\nbeen implemented. Nevertheless, this implicit feedback can be misleading or\ninefficient for the agent's learning. Herein, we propose a novel approach\nreducing the number of explicit feedbacks required by Combinatorial Multi Armed\nbandit (COM-MAB) algorithms while providing similar levels of global accuracy\nand learning efficiency to classical competitive methods. In this paper we\npresent a novel approach for considering user feedback and evaluate it using\nthree distinct strategies. Despite a limited number of feedbacks returned by\nusers (as low as 20% of the total), our approach obtains similar results to\nthose of state of the art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:32:51 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Letard", "Alexandre", ""], ["Amghar", "Tassadit", ""], ["Camp", "Olivier", ""], ["Gutowski", "Nicolas", ""]]}, {"id": "2009.07520", "submitter": "Johannes Hertrich", "authors": "Johannes Hertrich, Dang Phoung Lan Nguyen, Jean-Fancois Aujol,\n  Dominique Bernard, Yannick Berthoumieu, Abdellatif Saadaldin, Gabriele Steidl", "title": "PCA Reduced Gaussian Mixture Models with Applications in Superresolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the rapid development of computational hardware, the treatment of\nlarge and high dimensional data sets is still a challenging problem. This paper\nprovides a twofold contribution to the topic. First, we propose a Gaussian\nMixture Model in conjunction with a reduction of the dimensionality of the data\nin each component of the model by principal component analysis, called PCA-GMM.\nTo learn the (low dimensional) parameters of the mixture model we propose an EM\nalgorithm whose M-step requires the solution of constrained optimization\nproblems. Fortunately, these constrained problems do not depend on the usually\nlarge number of samples and can be solved efficiently by an (inertial) proximal\nalternating linearized minimization algorithm. Second, we apply our PCA-GMM for\nthe superresolution of 2D and 3D material images based on the approach of\nSandeep and Jacob. Numerical results confirm the moderate influence of the\ndimensionality reduction on the overall superresolution result.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:33:56 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:33:52 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 11:40:57 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hertrich", "Johannes", ""], ["Nguyen", "Dang Phoung Lan", ""], ["Aujol", "Jean-Fancois", ""], ["Bernard", "Dominique", ""], ["Berthoumieu", "Yannick", ""], ["Saadaldin", "Abdellatif", ""], ["Steidl", "Gabriele", ""]]}, {"id": "2009.07525", "submitter": "Michael Schaub", "authors": "Leto Peel and Michael T. Schaub", "title": "Detectability of hierarchical communities in networks", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering a planted hierarchy of partitions in a\nnetwork. The detectability of a single planted partition has previously been\nanalysed in detail and a phase transition has been identified below which the\npartition cannot be detected. Here we show that, in the hierarchical setting,\nthere exist additional phases in which the presence of multiple consistent\npartitions can either help or hinder detection. Accordingly, the detectability\nlimit for non-hierarchical partitions typically provides insufficient\ninformation about the detectability of the complete hierarchical structure, as\nwe highlight with several constructive examples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:44:27 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Peel", "Leto", ""], ["Schaub", "Michael T.", ""]]}, {"id": "2009.07530", "submitter": "Luca Parisi", "authors": "Luca Parisi", "title": "m-arcsinh: An Efficient and Reliable Function for SVM and MLP in\n  scikit-learn", "comments": "20 pages, 4 listings/Python code snippets, 2 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the 'm-arcsinh', a modified ('m-') version of the\ninverse hyperbolic sine function ('arcsinh'). Kernel and activation functions\nenable Machine Learning (ML)-based algorithms, such as Support Vector Machine\n(SVM) and Multi-Layer Perceptron (MLP), to learn from data in a supervised\nmanner. m-arcsinh, implemented in the open source Python library\n'scikit-learn', is hereby presented as an efficient and reliable kernel and\nactivation function for SVM and MLP respectively. Improvements in reliability\nand speed to convergence in classification tasks on fifteen (N = 15) datasets\navailable from scikit-learn and the University California Irvine (UCI) Machine\nLearning repository are discussed. Experimental results demonstrate the overall\ncompetitive classification performance of both SVM and MLP, achieved via the\nproposed function. This function is compared to gold standard kernel and\nactivation functions, demonstrating its overall competitive reliability\nregardless of the complexity of the classification tasks involved.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:59:15 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Parisi", "Luca", ""]]}, {"id": "2009.07547", "submitter": "Ketson Roberto Maximiano dos Santos", "authors": "K. R. M. dos Santos, D. G. Giovanis, M. D. Shields", "title": "Grassmannian diffusion maps based dimension reduction and classification\n  for high-dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces the Grassmannian Diffusion Maps, a novel nonlinear\ndimensionality reduction technique that defines the affinity between points\nthrough their representation as low-dimensional subspaces corresponding to\npoints on the Grassmann manifold. The method is designed for applications, such\nas image recognition and data-based classification of high-dimensional data\nthat can be compactly represented in a lower dimensional subspace. The GDMaps\nis composed of two stages. The first is a pointwise linear dimensionality\nreduction wherein each high-dimensional object is mapped onto the Grassmann.\nThe second stage is a multi-point nonlinear kernel-based dimension reduction\nusing Diffusion maps to identify the subspace structure of the points on the\nGrassmann manifold. To this aim, an appropriate Grassmannian kernel is used to\nconstruct the transition matrix of a random walk on a graph connecting points\non the Grassmann manifold. Spectral analysis of the transition matrix yields\nlow-dimensional Grassmannian diffusion coordinates embedding the data into a\nlow-dimensional reproducing kernel Hilbert space. Further, a novel data\nclassification/recognition technique is developed based on the construction of\nan overcomplete dictionary of reduced dimension whose atoms are given by the\nGrassmannian diffusion coordinates. Three examples are considered. First, a\n\"toy\" example shows that the GDMaps can identify an appropriate parametrization\nof structured points on the unit sphere. The second example demonstrates the\nability of the GDMaps to reveal the intrinsic subspace structure of\nhigh-dimensional random field data. In the last example, a face recognition\nproblem is solved considering face images subject to varying illumination\nconditions, changes in face expressions, and occurrence of occlusions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:32:02 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 18:55:56 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 19:51:41 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Santos", "K. R. M. dos", ""], ["Giovanis", "D. G.", ""], ["Shields", "M. D.", ""]]}, {"id": "2009.07554", "submitter": "Arun Verma Mr.", "authors": "Arun Verma, Manjesh K. Hanawal, Nandyala Hemachandra", "title": "Thompson Sampling for Unsupervised Sequential Selection", "comments": "Accepted to ACML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thompson Sampling has generated significant interest due to its better\nempirical performance than upper confidence bound based algorithms. In this\npaper, we study Thompson Sampling based algorithm for Unsupervised Sequential\nSelection (USS) problem. The USS problem is a variant of the stochastic\nmulti-armed bandits problem, where the loss of an arm can not be inferred from\nthe observed feedback. In the USS setup, arms are associated with fixed costs\nand are ordered, forming a cascade. In each round, the learner selects an arm\nand observes the feedback from arms up to the selected arm. The learner's goal\nis to find the arm that minimizes the expected total loss. The total loss is\nthe sum of the cost incurred for selecting the arm and the stochastic loss\nassociated with the selected arm. The problem is challenging because, without\nknowing the mean loss, one cannot compute the total loss for the selected arm.\nClearly, learning is feasible only if the optimal arm can be inferred from the\nproblem structure. As shown in the prior work, learning is possible when the\nproblem instance satisfies the so-called `Weak Dominance' (WD) property. Under\nWD, we show that our Thompson Sampling based algorithm for the USS problem\nachieves near optimal regret and has better numerical performance than existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:48:17 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Hemachandra", "Nandyala", ""]]}, {"id": "2009.07558", "submitter": "Shao-Bo Lin", "authors": "Yao Wang, Xin Guo, Shao-Bo Lin", "title": "Kernel-based L_2-Boosting with Structure Constraints", "comments": "33pages, 8figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient kernel methods for regression is very popular in the\npast decade. In this paper, utilizing boosting on kernel-based weaker learners,\nwe propose a novel kernel-based learning algorithm called kernel-based\nre-scaled boosting with truncation, dubbed as KReBooT. The proposed KReBooT\nbenefits in controlling the structure of estimators and producing sparse\nestimate, and is near overfitting resistant. We conduct both theoretical\nanalysis and numerical simulations to illustrate the power of KReBooT.\nTheoretically, we prove that KReBooT can achieve the almost optimal numerical\nconvergence rate for nonlinear approximation. Furthermore, using the recently\ndeveloped integral operator approach and a variant of Talagrand's concentration\ninequality, we provide fast learning rates for KReBooT, which is a new record\nof boosting-type algorithms. Numerically, we carry out a series of simulations\nto show the promising performance of KReBooT in terms of its good\ngeneralization, near over-fitting resistance and structure constraints.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:55:30 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Yao", ""], ["Guo", "Xin", ""], ["Lin", "Shao-Bo", ""]]}, {"id": "2009.07578", "submitter": "Stephan Robert-Nicoud", "authors": "Giulia Moschini, R\\'egis Houssou, J\\'er\\^ome Bovay, Stephan\n  Robert-Nicoud", "title": "Anomaly and Fraud Detection in Credit Card Transactions Using the ARIMA\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of unsupervised approach of credit card\nfraud detection in unbalanced dataset using the ARIMA model. The ARIMA model is\nfitted on the regular spending behaviour of the customer and is used to detect\nfraud if some deviations or discrepancies appear. Our model is applied to\ncredit card datasets and is compared to 4 anomaly detection approaches such as\nK-Means, Box-Plot, Local Outlier Factor and Isolation Forest. The results show\nthat the ARIMA model presents a better detecting power than the benchmark\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 09:48:26 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Moschini", "Giulia", ""], ["Houssou", "R\u00e9gis", ""], ["Bovay", "J\u00e9r\u00f4me", ""], ["Robert-Nicoud", "Stephan", ""]]}, {"id": "2009.07612", "submitter": "Hanbaek Lyu", "authors": "Christopher Strohmeier and Hanbaek Lyu and Deanna Needell", "title": "Online tensor factorization and CP-dictionary learning for Markovian\n  data", "comments": "31 pages, 5 figures. Major revision in the convergence analysis.\n  Preliminary version appeared in NeurIPS 2020 Workshop on Optimization for\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online Tensor Factorization (OTF) is a fundamental tool in learning\nlow-dimensional interpretable features from streaming multi-modal data. While\nvarious algorithmic and theoretical aspects of OTF have been investigated\nrecently, general convergence guarantee to stationary points of the objective\nfunction without any incoherence or sparsity assumptions is still lacking even\nfor the i.i.d. case. In this work, we introduce a novel OTF algorithm that\nlearns a CANDECOMP/PARAFAC (CP) basis from a given stream of tensor-valued data\nunder general constraints, including nonnegativity constraints that induce\ninterpretability of learned CP basis. We prove that our algorithm converges\nalmost surely to the set of stationary points of the objective function under\nthe hypothesis that the sequence of data tensors is generated by some\nunderlying Markov chain. Our setting covers the classical i.i.d. case as well\nas a wide range of application contexts including data streams generated by\nindependent or MCMC sampling. Our result closes a gap between OTF and Online\nMatrix Factorization in global convergence analysis. Experimentally, we show\nthat our OTF algorithm converges much faster than standard algorithms for\nnonnegative tensor factorization tasks on both synthetic and real-world data.\nAlso, we demonstrate the utility of our algorithm on a diverse set of examples\nfrom image, video, and time-series data, illustrating how one may learn\nqualitatively different CP-dictionaries from the same tensor data by exploiting\nthe tensor structure in multiple ways.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:41:01 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 13:07:32 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Strohmeier", "Christopher", ""], ["Lyu", "Hanbaek", ""], ["Needell", "Deanna", ""]]}, {"id": "2009.07624", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Xingjian Li, Dejing Dou, Ji Wu", "title": "Measuring Information Transfer in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the information content in a neural network model is essentially\nestimating the model's Kolmogorov complexity. Recent success of prequential\ncoding on neural networks points to a promising path of deriving an efficient\ndescription length of a model. We propose a practical measure of the\ngeneralizable information in a neural network model based on prequential\ncoding, which we term Information Transfer ($L_{IT}$). Theoretically, $L_{IT}$\nis an estimation of the generalizable part of a model's information content. In\nexperiments, we show that $L_{IT}$ is consistently correlated with\ngeneralizable information and can be used as a measure of patterns or\n\"knowledge\" in a model or a dataset. Consequently, $L_{IT}$ can serve as a\nuseful analysis tool in deep learning. In this paper, we apply $L_{IT}$ to\ncompare and dissect information in datasets, evaluate representation models in\ntransfer learning, and analyze catastrophic forgetting and continual learning\nalgorithms. $L_{IT}$ provides an information perspective which helps us\ndiscover new insights into neural network learning.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:06:42 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 07:16:10 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Zhang", "Xiao", ""], ["Li", "Xingjian", ""], ["Dou", "Dejing", ""], ["Wu", "Ji", ""]]}, {"id": "2009.07664", "submitter": "Abdelhak Lemkhenter", "authors": "Abdelhak Lemkhenter and Paolo Favaro", "title": "Boosting Generalization in Bio-Signal Classification by Learning the\n  Phase-Amplitude Coupling", "comments": "Accepted at GCPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various hand-crafted features representations of bio-signals rely primarily\non the amplitude or power of the signal in specific frequency bands. The phase\ncomponent is often discarded as it is more sample specific, and thus more\nsensitive to noise, than the amplitude. However, in general, the phase\ncomponent also carries information relevant to the underlying biological\nprocesses. In fact, in this paper we show the benefits of learning the coupling\nof both phase and amplitude components of a bio-signal. We do so by introducing\na novel self-supervised learning task, which we call Phase-Swap, that detects\nif bio-signals have been obtained by merging the amplitude and phase from\ndifferent sources. We show in our evaluation that neural networks trained on\nthis task generalize better across subjects and recording sessions than their\nfully supervised counterpart.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 13:07:00 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:07:05 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Lemkhenter", "Abdelhak", ""], ["Favaro", "Paolo", ""]]}, {"id": "2009.07701", "submitter": "Casper Solheim Bojer", "authors": "Casper Solheim Bojer and Jens Peder Meldgaard", "title": "Kaggle forecasting competitions: An overlooked learning opportunity", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijforecast.2020.07.007", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competitions play an invaluable role in the field of forecasting, as\nexemplified through the recent M4 competition. The competition received\nattention from both academics and practitioners and sparked discussions around\nthe representativeness of the data for business forecasting. Several\ncompetitions featuring real-life business forecasting tasks on the Kaggle\nplatform has, however, been largely ignored by the academic community. We\nbelieve the learnings from these competitions have much to offer to the\nforecasting community and provide a review of the results from six Kaggle\ncompetitions. We find that most of the Kaggle datasets are characterized by\nhigher intermittence and entropy than the M-competitions and that global\nensemble models tend to outperform local single models. Furthermore, we find\nthe strong performance of gradient boosted decision trees, increasing success\nof neural networks for forecasting, and a variety of techniques for adapting\nmachine learning models to the forecasting task.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:14:41 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Bojer", "Casper Solheim", ""], ["Meldgaard", "Jens Peder", ""]]}, {"id": "2009.07703", "submitter": "Hang Yu", "authors": "Hang Yu, Songwei Wu, and Justin Dauwels", "title": "Efficient Variational Bayesian Structure Learning of Dynamic Graphical\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating time-varying graphical models are of paramount importance in\nvarious social, financial, biological, and engineering systems, since the\nevolution of such networks can be utilized for example to spot trends, detect\nanomalies, predict vulnerability, and evaluate the impact of interventions.\nExisting methods require extensive tuning of parameters that control the graph\nsparsity and temporal smoothness. Furthermore, these methods are\ncomputationally burdensome with time complexity O(NP^3) for P variables and N\ntime points. As a remedy, we propose a low-complexity tuning-free Bayesian\napproach, named BADGE. Specifically, we impose temporally-dependent\nspike-and-slab priors on the graphs such that they are sparse and varying\nsmoothly across time. A variational inference algorithm is then derived to\nlearn the graph structures from the data automatically. Owning to the\npseudo-likelihood and the mean-field approximation, the time complexity of\nBADGE is only O(NP^2). Additionally, by identifying the frequency-domain\nresemblance to the time-varying graphical models, we show that BADGE can be\nextended to learning frequency-varying inverse spectral density matrices, and\nyields graphical models for multivariate stationary time series. Numerical\nresults on both synthetic and real data show that that BADGE can better recover\nthe underlying true graphs, while being more efficient than the existing\nmethods, especially for high-dimensional cases.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:19:23 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 15:59:08 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Yu", "Hang", ""], ["Wu", "Songwei", ""], ["Dauwels", "Justin", ""]]}, {"id": "2009.07708", "submitter": "Fan Fang", "authors": "Fan Fang, Carmine Ventre, Lingbo Li, Leslie Kanthan, Fan Wu, Michail\n  Basios", "title": "Better Model Selection with a new Definition of Feature Importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature importance aims at measuring how crucial each input feature is for\nmodel prediction. It is widely used in feature engineering, model selection and\nexplainable artificial intelligence (XAI). In this paper, we propose a new\ntree-model explanation approach for model selection. Our novel concept\nleverages the Coefficient of Variation of a feature weight (measured in terms\nof the contribution of the feature to the prediction) to capture the dispersion\nof importance over samples. Extensive experimental results show that our novel\nfeature explanation performs better than general cross validation method in\nmodel selection both in terms of time efficiency and accuracy performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:32:22 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Fang", "Fan", ""], ["Ventre", "Carmine", ""], ["Li", "Lingbo", ""], ["Kanthan", "Leslie", ""], ["Wu", "Fan", ""], ["Basios", "Michail", ""]]}, {"id": "2009.07712", "submitter": "Shaoxiong Feng", "authors": "Shaoxiong Feng, Hongshen Chen, Xuancheng Ren, Zhuoye Ding, Kan Li, Xu\n  Sun", "title": "Collaborative Group Learning", "comments": "Accepted by AAAI 2021; Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative learning has successfully applied knowledge transfer to guide a\npool of small student networks towards robust local minima. However, previous\napproaches typically struggle with drastically aggravated student\nhomogenization when the number of students rises. In this paper, we propose\nCollaborative Group Learning, an efficient framework that aims to diversify the\nfeature representation and conduct an effective regularization. Intuitively,\nsimilar to the human group study mechanism, we induce students to learn and\nexchange different parts of course knowledge as collaborative groups. First,\neach student is established by randomly routing on a modular neural network,\nwhich facilitates flexible knowledge communication between students due to\nrandom levels of representation sharing and branching. Second, to resist the\nstudent homogenization, students first compose diverse feature sets by\nexploiting the inductive bias from sub-sets of training data, and then\naggregate and distill different complementary knowledge by imitating a random\nsub-group of students at each time step. Overall, the above mechanisms are\nbeneficial for maximizing the student population to further improve the model\ngeneralization without sacrificing computational efficiency. Empirical\nevaluations on both image and text tasks indicate that our method significantly\noutperforms various state-of-the-art collaborative approaches whilst enhancing\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:34:39 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 11:48:43 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 10:46:46 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 04:57:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Feng", "Shaoxiong", ""], ["Chen", "Hongshen", ""], ["Ren", "Xuancheng", ""], ["Ding", "Zhuoye", ""], ["Li", "Kan", ""], ["Sun", "Xu", ""]]}, {"id": "2009.07717", "submitter": "Sara Ahmed", "authors": "Sara Atito Ali Ahmed, Berrin Yanikoglu", "title": "Relative Attribute Classification with Deep Rank SVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relative attributes indicate the strength of a particular attribute between\nimage pairs. We introduce a deep Siamese network with rank SVM loss function,\ncalled Deep Rank SVM (DRSVM), in order to decide which one of a pair of images\nhas a stronger presence of a specific attribute. The network is trained in an\nend-to-end fashion to jointly learn the visual features and the ranking\nfunction. We demonstrate the effectiveness of our approach against the\nstate-of-the-art methods on four image benchmark datasets: LFW-10, PubFig,\nUTZap50K-lexi and UTZap50K-2 datasets. DRSVM surpasses state-of-art in terms of\nthe average accuracy across attributes, on three of the four image benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 09:21:39 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ahmed", "Sara Atito Ali", ""], ["Yanikoglu", "Berrin", ""]]}, {"id": "2009.07738", "submitter": "Alexander Lavin", "authors": "Alexander Lavin", "title": "Neuro-symbolic Neurodegenerative Disease Modeling as Probabilistic\n  Programmed Deep Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic programmed deep kernel learning approach to\npersonalized, predictive modeling of neurodegenerative diseases. Our analysis\nconsiders a spectrum of neural and symbolic machine learning approaches, which\nwe assess for predictive performance and important medical AI properties such\nas interpretability, uncertainty reasoning, data-efficiency, and leveraging\ndomain knowledge. Our Bayesian approach combines the flexibility of Gaussian\nprocesses with the structural power of neural networks to model biomarker\nprogressions, without needing clinical labels for training. We run evaluations\non the problem of Alzheimer's disease prediction, yielding results that surpass\ndeep learning in both accuracy and timeliness of predicting neurodegeneration,\nand with the practical advantages of Bayesian nonparametrics and probabilistic\nprogramming.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:16:03 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 13:20:28 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 15:54:14 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Lavin", "Alexander", ""]]}, {"id": "2009.07753", "submitter": "Erick Galinkin", "authors": "Erick Galinkin", "title": "Malicious Network Traffic Detection via Deep Learning: An Information\n  Theoretic View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The attention that deep learning has garnered from the academic community and\nindustry continues to grow year over year, and it has been said that we are in\na new golden age of artificial intelligence research. However, neural networks\nare still often seen as a \"black box\" where learning occurs but cannot be\nunderstood in a human-interpretable way. Since these machine learning systems\nare increasingly being adopted in security contexts, it is important to explore\nthese interpretations. We consider an Android malware traffic dataset for\napproaching this problem. Then, using the information plane, we explore how\nhomeomorphism affects learned representation of the data and the invariance of\nthe mutual information captured by the parameters on that data. We empirically\nvalidate these results, using accuracy as a second measure of similarity of\nlearned representations.\n  Our results suggest that although the details of learned representations and\nthe specific coordinate system defined over the manifold of all parameters\ndiffer slightly, the functional approximations are the same. Furthermore, our\nresults show that since mutual information remains invariant under\nhomeomorphism, only feature engineering methods that alter the entropy of the\ndataset will change the outcome of the neural network. This means that for some\ndatasets and tasks, neural networks require meaningful, human-driven feature\nengineering or changes in architecture to provide enough information for the\nneural network to generate a sufficient statistic. Applying our results can\nserve to guide analysis methods for machine learning engineers and suggests\nthat neural networks that can exploit the convolution theorem are equally\naccurate as standard convolutional neural networks, and can be more\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:37:44 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Galinkin", "Erick", ""]]}, {"id": "2009.07769", "submitter": "Sarah Alnegheimish", "authors": "Alexander Geiger, Dongyu Liu, Sarah Alnegheimish, Alfredo\n  Cuesta-Infante, Kalyan Veeramachaneni", "title": "TadGAN: Time Series Anomaly Detection Using Generative Adversarial\n  Networks", "comments": "Alexander Geiger and Dongyu Liu contributed equally. To appear in the\n  proceedings of IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series anomalies can offer information relevant to critical situations\nfacing various fields, from finance and aerospace to the IT, security, and\nmedical domains. However, detecting anomalies in time series data is\nparticularly challenging due to the vague definition of anomalies and said\ndata's frequent lack of labels and highly complex temporal correlations.\nCurrent state-of-the-art unsupervised machine learning methods for anomaly\ndetection suffer from scalability and portability issues, and may have high\nfalse positive rates. In this paper, we propose TadGAN, an unsupervised anomaly\ndetection approach built on Generative Adversarial Networks (GANs). To capture\nthe temporal correlations of time series distributions, we use LSTM Recurrent\nNeural Networks as base models for Generators and Critics. TadGAN is trained\nwith cycle consistency loss to allow for effective time-series data\nreconstruction. We further propose several novel methods to compute\nreconstruction errors, as well as different approaches to combine\nreconstruction errors and Critic outputs to compute anomaly scores. To\ndemonstrate the performance and generalizability of our approach, we test\nseveral anomaly scoring techniques and report the best-suited one. We compare\nour approach to 8 baseline anomaly detection methods on 11 datasets from\nmultiple reputable sources such as NASA, Yahoo, Numenta, Amazon, and Twitter.\nThe results show that our approach can effectively detect anomalies and\noutperform baseline methods in most cases (6 out of 11). Notably, our method\nhas the highest averaged F1 score across all the datasets. Our code is open\nsource and is available as a benchmarking tool.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:52:04 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 23:25:06 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 23:05:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Geiger", "Alexander", ""], ["Liu", "Dongyu", ""], ["Alnegheimish", "Sarah", ""], ["Cuesta-Infante", "Alfredo", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "2009.07793", "submitter": "Himanshu Pradeep Aswani", "authors": "Himanshu Pradeep Aswani, Amit Sethi", "title": "Activation Functions: Do They Represent A Trade-Off Between Modular\n  Nature of Neural Networks And Task Performance", "comments": "5 pages, 1 figure, 2 tables, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research suggests that the key factors in designing neural network\narchitectures involve choosing number of filters for every convolution layer,\nnumber of hidden neurons for every fully connected layer, dropout and pruning.\nThe default activation function in most cases is the ReLU, as it has\nempirically shown faster training convergence. We explore whether ReLU is the\nbest choice if one is aiming to desire better modularity structure within a\nneural network.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:38:16 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Aswani", "Himanshu Pradeep", ""], ["Sethi", "Amit", ""]]}, {"id": "2009.07799", "submitter": "Qianxiao Li", "authors": "Zhong Li, Jiequn Han, Weinan E, Qianxiao Li", "title": "On the Curse of Memory in Recurrent Neural Networks: Approximation and\n  Optimization Analysis", "comments": "Published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation properties and optimization dynamics of recurrent\nneural networks (RNNs) when applied to learn input-output relationships in\ntemporal data. We consider the simple but representative setting of using\ncontinuous-time linear RNNs to learn from data generated by linear\nrelationships. Mathematically, the latter can be understood as a sequence of\nlinear functionals. We prove a universal approximation theorem of such linear\nfunctionals, and characterize the approximation rate and its relation with\nmemory. Moreover, we perform a fine-grained dynamical analysis of training\nlinear RNNs, which further reveal the intricate interactions between memory and\nlearning. A unifying theme uncovered is the non-trivial effect of memory, a\nnotion that can be made precise in our framework, on approximation and\noptimization: when there is long term memory in the target, it takes a large\nnumber of neurons to approximate it. Moreover, the training process will suffer\nfrom slow downs. In particular, both of these effects become exponentially more\npronounced with memory - a phenomenon we call the \"curse of memory\". These\nanalyses represent a basic step towards a concrete mathematical understanding\nof new phenomenon that may arise in learning temporal relationships using\nrecurrent architectures.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:48:28 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 03:36:21 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Zhong", ""], ["Han", "Jiequn", ""], ["E", "Weinan", ""], ["Li", "Qianxiao", ""]]}, {"id": "2009.07801", "submitter": "Mingyuan Zhang", "authors": "Mingyuan Zhang, Harish G. Ramaswamy, Shivani Agarwal", "title": "Convex Calibrated Surrogates for the Multi-Label F-Measure", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The F-measure is a widely used performance measure for multi-label\nclassification, where multiple labels can be active in an instance\nsimultaneously (e.g. in image tagging, multiple tags can be active in any\nimage). In particular, the F-measure explicitly balances recall (fraction of\nactive labels predicted to be active) and precision (fraction of labels\npredicted to be active that are actually so), both of which are important in\nevaluating the overall performance of a multi-label classifier. As with most\ndiscrete prediction problems, however, directly optimizing the F-measure is\ncomputationally hard. In this paper, we explore the question of designing\nconvex surrogate losses that are calibrated for the F-measure -- specifically,\nthat have the property that minimizing the surrogate loss yields (in the limit\nof sufficient data) a Bayes optimal multi-label classifier for the F-measure.\nWe show that the F-measure for an $s$-label problem, when viewed as a $2^s\n\\times 2^s$ loss matrix, has rank at most $s^2+1$, and apply a result of\nRamaswamy et al. (2014) to design a family of convex calibrated surrogates for\nthe F-measure. The resulting surrogate risk minimization algorithms can be\nviewed as decomposing the multi-label F-measure learning problem into $s^2+1$\nbinary class probability estimation problems. We also provide a quantitative\nregret transfer bound for our surrogates, which allows any regret guarantees\nfor the binary problems to be transferred to regret guarantees for the overall\nF-measure problem, and discuss a connection with the algorithm of Dembczynski\net al. (2013). Our experiments confirm our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:50:55 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhang", "Mingyuan", ""], ["Ramaswamy", "Harish G.", ""], ["Agarwal", "Shivani", ""]]}, {"id": "2009.07806", "submitter": "Dustin Wright", "authors": "Dustin Wright and Isabelle Augenstein", "title": "Transformer Based Multi-Source Domain Adaptation", "comments": "12 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical machine learning settings, the data on which a model must make\npredictions often come from a different distribution than the data it was\ntrained on. Here, we investigate the problem of unsupervised multi-source\ndomain adaptation, where a model is trained on labelled data from multiple\nsource domains and must make predictions on a domain for which no labelled data\nhas been seen. Prior work with CNNs and RNNs has demonstrated the benefit of\nmixture of experts, where the predictions of multiple domain expert classifiers\nare combined; as well as domain adversarial training, to induce a domain\nagnostic representation space. Inspired by this, we investigate how such\nmethods can be effectively applied to large pretrained transformer models. We\nfind that domain adversarial training has an effect on the learned\nrepresentations of these models while having little effect on their\nperformance, suggesting that large transformer-based models are already\nrelatively robust across domains. Additionally, we show that mixture of experts\nleads to significant performance improvements by comparing several variants of\nmixing functions, including one novel mixture based on attention. Finally, we\ndemonstrate that the predictions of large pretrained transformer based domain\nexperts are highly homogenous, making it challenging to learn effective\nfunctions for mixing their predictions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:56:23 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wright", "Dustin", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.07819", "submitter": "Matthew Klimek", "authors": "I-Kai Chen, Matthew D. Klimek, Maxim Perelstein", "title": "Improved Neural Network Monte Carlo Simulation", "comments": "19 pages, 11 figures; v2: minor clarifications, results unchanged, 21\n  pages", "journal-ref": "SciPost Phys. 10, 023 (2021)", "doi": "10.21468/SciPostPhys.10.1.023", "report-no": null, "categories": "hep-ph hep-ex physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algorithm for Monte Carlo simulation of parton-level events based on an\nArtificial Neural Network (ANN) proposed in arXiv:1810.11509 is used to perform\na simulation of $H\\to 4\\ell$ decay. Improvements in the training algorithm have\nbeen implemented to avoid numerical instabilities. The integrated decay width\nevaluated by the ANN is within 0.7% of the true value and unweighting\nefficiency of 26% is reached. While the ANN is not automatically bijective\nbetween input and output spaces, which can lead to issues with simulation\nquality, we argue that the training procedure naturally prefers bijective maps,\nand demonstrate that the trained ANN is bijective to a very good approximation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:21:03 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 03:18:21 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "I-Kai", ""], ["Klimek", "Matthew D.", ""], ["Perelstein", "Maxim", ""]]}, {"id": "2009.07842", "submitter": "Sarthak Consul", "authors": "Kumar Ashutosh, Sarthak Consul, Bhishma Dedhia, Parthasarathi\n  Khirwadkar, Sahil Shah, Shivaram Kalyanakrishnan", "title": "Lower Bounds for Policy Iteration on Multi-action MDPs", "comments": "8 pages, 3 diagrams, 2 tables. Paper in IEEE CDC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy Iteration (PI) is a classical family of algorithms to compute an\noptimal policy for any given Markov Decision Problem (MDP). The basic idea in\nPI is to begin with some initial policy and to repeatedly update the policy to\none from an improving set, until an optimal policy is reached. Different\nvariants of PI result from the (switching) rule used for improvement. An\nimportant theoretical question is how many iterations a specified PI variant\nwill take to terminate as a function of the number of states $n$ and the number\nof actions $k$ in the input MDP. While there has been considerable progress\ntowards upper-bounding this number, there are fewer results on lower bounds. In\nparticular, existing lower bounds primarily focus on the special case of $k =\n2$ actions. We devise lower bounds for $k \\geq 3$. Our main result is that a\nparticular variant of PI can take $\\Omega(k^{n/2})$ iterations to terminate. We\nalso generalise existing constructions on $2$-action MDPs to scale lower bounds\nby a factor of $k$ for some common deterministic variants of PI, and by\n$\\log(k)$ for corresponding randomised variants.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:59:25 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Ashutosh", "Kumar", ""], ["Consul", "Sarthak", ""], ["Dedhia", "Bhishma", ""], ["Khirwadkar", "Parthasarathi", ""], ["Shah", "Sahil", ""], ["Kalyanakrishnan", "Shivaram", ""]]}, {"id": "2009.07888", "submitter": "Zhuangdi Zhu", "authors": "Zhuangdi Zhu, Kaixiang Lin, and Jiayu Zhou", "title": "Transfer Learning in Deep Reinforcement Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is a key technique to address sequential\ndecision-making problems and is crucial to realize advanced artificial\nintelligence. Recent years have witnessed remarkable progress in RL by virtue\nof the fast development of deep neural networks. Along with the promising\nprospects of RL in numerous domains, such as robotics and game-playing,\ntransfer learning has arisen as an important technique to tackle various\nchallenges faced by RL, by transferring knowledge from external expertise to\naccelerate the learning process. In this survey, we systematically investigate\nthe recent progress of transfer learning approaches in the context of deep\nreinforcement learning. Specifically, we provide a framework for categorizing\nthe state-of-the-art transfer learning approaches, under which we analyze their\ngoals, methodologies, compatible RL backbones, and practical applications. We\nalso draw connections between transfer learning and other relevant topics from\nthe RL perspective and explore their potential challenges as well as open\nquestions that await future research progress.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:38:54 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 02:22:54 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 23:28:31 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 16:46:02 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhu", "Zhuangdi", ""], ["Lin", "Kaixiang", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2009.07896", "submitter": "Narine Kokhlikyan", "authors": "Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal\n  Alsallakh, Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos\n  Araya, Siqi Yan, Orion Reblitz-Richardson", "title": "Captum: A unified and generic model interpretability library for PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel, unified, open-source model\ninterpretability library for PyTorch [12]. The library contains generic\nimplementations of a number of gradient and perturbation-based attribution\nalgorithms, also known as feature, neuron and layer importance algorithms, as\nwell as a set of evaluation metrics for these algorithms. It can be used for\nboth classification and non-classification models including graph-structured\nmodels built on Neural Networks (NN). In this paper we give a high-level\noverview of supported attribution algorithms and show how to perform\nmemory-efficient and scalable computations. We emphasize that the three main\ncharacteristics of the library are multimodality, extensibility and ease of\nuse. Multimodality supports different modality of inputs such as image, text,\naudio or video. Extensibility allows adding new algorithms and features. The\nlibrary is also designed for easy understanding and use. Besides, we also\nintroduce an interactive visualization tool called Captum Insights that is\nbuilt on top of Captum library and allows sample-based model debugging and\nvisualization using feature importance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:57:57 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Kokhlikyan", "Narine", ""], ["Miglani", "Vivek", ""], ["Martin", "Miguel", ""], ["Wang", "Edward", ""], ["Alsallakh", "Bilal", ""], ["Reynolds", "Jonathan", ""], ["Melnikov", "Alexander", ""], ["Kliushkina", "Natalia", ""], ["Araya", "Carlos", ""], ["Yan", "Siqi", ""], ["Reblitz-Richardson", "Orion", ""]]}, {"id": "2009.07899", "submitter": "Harikesh Nair", "authors": "Tong Geng, Xiliang Lin, Harikesh S. Nair, Jun Hao, Bin Xiang, Shurui\n  Fan", "title": "Comparison Lift: Bandit-based Experimentation System for Online\n  Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparison Lift is an experimentation-as-a-service (EaaS) application for\ntesting online advertising audiences and creatives at JD.com. Unlike many other\nEaaS tools that focus primarily on fixed sample A/B testing, Comparison Lift\ndeploys a custom bandit-based experimentation algorithm. The advantages of the\nbandit-based approach are two-fold. First, it aligns the randomization induced\nin the test with the advertiser's goals from testing. Second, by adapting\nexperimental design to information acquired during the test, it reduces\nsubstantially the cost of experimentation to the advertiser. Since launch in\nMay 2019, Comparison Lift has been utilized in over 1,500 experiments. We\nestimate that utilization of the product has helped increase click-through\nrates of participating advertising campaigns by 46% on average. We estimate\nthat the adaptive design in the product has generated 27% more clicks on\naverage during testing compared to a fixed sample A/B design. Both suggest\nsignificant value generation and cost savings to advertisers from the product.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:08:44 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Geng", "Tong", ""], ["Lin", "Xiliang", ""], ["Nair", "Harikesh S.", ""], ["Hao", "Jun", ""], ["Xiang", "Bin", ""], ["Fan", "Shurui", ""]]}, {"id": "2009.07907", "submitter": "Sara Alaee", "authors": "Sara Alaee, Kaveh Kamgar, Eamonn Keogh", "title": "Matrix Profile XXII: Exact Discovery of Time Series Motifs under DTW", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, time series motif discovery has emerged as a useful\nprimitive for many downstream analytical tasks, including clustering,\nclassification, rule discovery, segmentation, and summarization. In parallel,\nthere has been an increased understanding that Dynamic Time Warping (DTW) is\nthe best time series similarity measure in a host of settings. Surprisingly\nhowever, there has been virtually no work on using DTW to discover motifs. The\nmost obvious explanation of this is the fact that both motif discovery and the\nuse of DTW can be computationally challenging, and the current best mechanisms\nto address their lethargy are mutually incompatible. In this work, we present\nthe first scalable exact method to discover time series motifs under DTW. Our\nmethod automatically performs the best trade-off between time-to-compute and\ntightness-of-lower-bounds for a novel hierarchy of lower bounds representation\nwe introduce. We show that under realistic settings, our algorithm can\nadmissibly prune up to 99.99% of the DTW computations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:35:43 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Alaee", "Sara", ""], ["Kamgar", "Kaveh", ""], ["Keogh", "Eamonn", ""]]}, {"id": "2009.07928", "submitter": "Felix K\\\"oster", "authors": "Felix K\\\"oster, Serhiy Yanchuk, Kathy L\\\"udge", "title": "Insight into Delay Based Reservoir Computing via Eigenvalue Analysis", "comments": "New Journal Submission", "journal-ref": null, "doi": "10.1088/2515-7647/abf237", "report-no": null, "categories": "cs.LG math.DS nlin.AO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a profound insight into the computation capability of\ndelay-based reservoir computing via an eigenvalue analysis. We concentrate on\nthe task-independent memory capacity to quantify the reservoir performance and\ncompare these with the eigenvalue spectrum of the dynamical system. We show\nthat these two quantities are deeply connected, and thus the reservoir\ncomputing performance is predictable by analyzing the small signal response of\nthe reservoir. Our results suggest that any dynamical system used as a\nreservoir can be analyzed in this way. We apply our method exemplarily to a\nphotonic laser system with feedback and compare the numerically computed recall\ncapabilities with the eigenvalue spectrum. Optimal performance is found for a\nsystem with the eigenvalues having real parts close to zero and off-resonant\nimaginary parts.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 20:41:47 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:46:14 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 20:25:02 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["K\u00f6ster", "Felix", ""], ["Yanchuk", "Serhiy", ""], ["L\u00fcdge", "Kathy", ""]]}, {"id": "2009.07938", "submitter": "Zijun Cui", "authors": "Zijun Cui, Pavan Kapanipathi, Kartik Talamadupula, Tian Gao, Qiang Ji", "title": "Type-augmented Relation Prediction in Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) are of great importance to many real world\napplications, but they generally suffer from incomplete information in the form\nof missing relations between entities. Knowledge graph completion (also known\nas relation prediction) is the task of inferring missing facts given existing\nones. Most of the existing work is proposed by maximizing the likelihood of\nobserved instance-level triples. Not much attention, however, is paid to the\nontological information, such as type information of entities and relations. In\nthis work, we propose a type-augmented relation prediction (TaRP) method, where\nwe apply both the type information and instance-level information for relation\nprediction. In particular, type information and instance-level information are\nencoded as prior probabilities and likelihoods of relations respectively, and\nare combined by following Bayes' rule. Our proposed TaRP method achieves\nsignificantly better performance than state-of-the-art methods on four\nbenchmark datasets: FB15K, FB15K-237, YAGO26K-906, and DB111K-174. In addition,\nwe show that TaRP achieves significantly improved data efficiency. More\nimportantly, the type information extracted from a specific dataset can\ngeneralize well to other datasets through the proposed TaRP model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:14:18 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 01:59:56 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 22:57:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Cui", "Zijun", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""], ["Gao", "Tian", ""], ["Ji", "Qiang", ""]]}, {"id": "2009.07943", "submitter": "Kouame Kouassi", "authors": "Kouame Hermann Kouassi and Deshendran Moodley", "title": "An analysis of deep neural networks for predicting trends in time series\n  data", "comments": null, "journal-ref": "SACAIR CCIS Springer proceedings, 2021 Feb", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a hybrid Deep Neural Network (DNN) algorithm, TreNet was proposed\nfor predicting trends in time series data. While TreNet was shown to have\nsuperior performance for trend prediction to other DNN and traditional ML\napproaches, the validation method used did not take into account the sequential\nnature of time series data sets and did not deal with model update. In this\nresearch we replicated the TreNet experiments on the same data sets using a\nwalk-forward validation method and tested our optimal model over multiple\nindependent runs to evaluate model stability. We compared the performance of\nthe hybrid TreNet algorithm, on four data sets to vanilla DNN algorithms that\ntake in point data, and also to traditional ML algorithms. We found that in\ngeneral TreNet still performs better than the vanilla DNN models, but not on\nall data sets as reported in the original TreNet study. This study highlights\nthe importance of using an appropriate validation method and evaluating model\nstability for evaluating and developing machine learning models for trend\nprediction in time series data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:24:20 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 20:44:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kouassi", "Kouame Hermann", ""], ["Moodley", "Deshendran", ""]]}, {"id": "2009.07971", "submitter": "Esteban Vilca", "authors": "Esteban Vilca, Liang Zhao", "title": "A Network-Based High-Level Data Classification Algorithm Using\n  Betweenness Centrality", "comments": null, "journal-ref": null, "doi": "10.5753/eniac.2020.12128", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data classification is a major machine learning paradigm, which has been\nwidely applied to solve a large number of real-world problems. Traditional data\nclassification techniques consider only physical features (e.g., distance,\nsimilarity, or distribution) of the input data. For this reason, those are\ncalled \\textit{low-level} classification. On the other hand, the human (animal)\nbrain performs both low and high orders of learning and it has a facility in\nidentifying patterns according to the semantic meaning of the input data. Data\nclassification that considers not only physical attributes but also the pattern\nformation is referred to as \\textit{high-level} classification. Several\nhigh-level classification techniques have been developed, which make use of\ncomplex networks to characterize data patterns and have obtained promising\nresults. In this paper, we propose a pure network-based high-level\nclassification technique that uses the betweenness centrality measure. We test\nthis model in nine different real datasets and compare it with other nine\ntraditional and well-known classification models. The results show us a\ncompetent classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 23:14:13 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Vilca", "Esteban", ""], ["Zhao", "Liang", ""]]}, {"id": "2009.07974", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew", "title": "Analysis of Generalizability of Deep Neural Networks Based on the\n  Complexity of Decision Boundary", "comments": "7 pages, 11 figures. Accepted by ICMLA 2020", "journal-ref": "19th IEEE International Conference on Machine Learning and\n  Applications (ICMLA), 2020, pp. 101-106", "doi": "10.1109/ICMLA51294.2020.00025", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For supervised learning models, the analysis of generalization ability\n(generalizability) is vital because the generalizability expresses how well a\nmodel will perform on unseen data. Traditional generalization methods, such as\nthe VC dimension, do not apply to deep neural network (DNN) models. Thus, new\ntheories to explain the generalizability of DNNs are required. In this study,\nwe hypothesize that the DNN with a simpler decision boundary has better\ngeneralizability by the law of parsimony (Occam's Razor). We create the\ndecision boundary complexity (DBC) score to define and measure the complexity\nof decision boundary of DNNs. The idea of the DBC score is to generate data\npoints (called adversarial examples) on or near the decision boundary. Our new\napproach then measures the complexity of the boundary using the entropy of\neigenvalues of these data. The method works equally well for high-dimensional\ndata. We use training data and the trained model to compute the DBC score. And,\nthe ground truth for model's generalizability is its test accuracy. Experiments\nbased on the DBC score have verified our hypothesis. The DBC is shown to\nprovide an effective method to measure the complexity of a decision boundary\nand gives a quantitative measure of the generalizability of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 23:25:52 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""]]}, {"id": "2009.07988", "submitter": "Xiang Deng", "authors": "Xiang Deng and Zhongfei (Mark) Zhang", "title": "Deep Collective Learning: Learning Optimal Inputs and Weights Jointly in\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well observed that in deep learning and computer vision literature,\nvisual data are always represented in a manually designed coding scheme (eg.,\nRGB images are represented as integers ranging from 0 to 255 for each channel)\nwhen they are input to an end-to-end deep neural network (DNN) for any learning\ntask. We boldly question whether the manually designed inputs are good for DNN\ntraining for different tasks and study whether the input to a DNN can be\noptimally learned end-to-end together with learning the weights of the DNN. In\nthis paper, we propose the paradigm of {\\em deep collective learning} which\naims to learn the weights of DNNs and the inputs to DNNs simultaneously for\ngiven tasks. We note that collective learning has been implicitly but widely\nused in natural language processing while it has almost never been studied in\ncomputer vision. Consequently, we propose the lookup vision networks\n(Lookup-VNets) as a solution to deep collective learning in computer vision.\nThis is achieved by associating each color in each channel with a vector in\nlookup tables. As learning inputs in computer vision has almost never been\nstudied in the existing literature, we explore several aspects of this question\nthrough varieties of experiments on image classification tasks. Experimental\nresults on four benchmark datasets, i.e., CIFAR-10, CIFAR-100, Tiny ImageNet,\nand ImageNet (ILSVRC2012) have shown several surprising characteristics of\nLookup-VNets and have demonstrated the advantages and promise of Lookup-VNets\nand deep collective learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:33:04 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Deng", "Xiang", "", "Mark"], ["Zhongfei", "", "", "Mark"], ["Zhang", "", ""]]}, {"id": "2009.07999", "submitter": "George Pu", "authors": "Yanlin Zhou, George Pu, Xiyao Ma, Xiaolin Li, Dapeng Wu", "title": "Distilled One-Shot Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current federated learning algorithms take tens of communication rounds\ntransmitting unwieldy model weights under ideal circumstances and hundreds when\ndata is poorly distributed. Inspired by recent work on dataset distillation and\ndistributed one-shot learning, we propose Distilled One-Shot Federated Learning\n(DOSFL) to significantly reduce the communication cost while achieving\ncomparable performance. In just one round, each client distills their private\ndataset, sends the synthetic data (e.g. images or sentences) to the server, and\ncollectively trains a global model. The distilled data look like noise and are\nonly useful to the specific model weights, i.e., become useless after the model\nupdates. With this weight-less and gradient-less design, the total\ncommunication cost of DOSFL is up to three orders of magnitude less than FedAvg\nwhile preserving between 93% to 99% performance of a centralized counterpart.\nAfterwards, clients could switch to traditional methods such as FedAvg to\nfinetune the last few percent to fit personalized local models with local\ndatasets. Through comprehensive experiments, we show the accuracy and\ncommunication performance of DOSFL on both vision and language tasks with\ndifferent models including CNN, LSTM, Transformer, etc. We demonstrate that an\neavesdropping attacker cannot properly train a good model using the leaked\ndistilled data, without knowing the initial model weights. DOSFL serves as an\ninexpensive method to quickly converge on a performant pre-trained model with\nless than 0.1% communication cost of traditional methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 01:14:47 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 21:10:36 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 06:55:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhou", "Yanlin", ""], ["Pu", "George", ""], ["Ma", "Xiyao", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2009.08039", "submitter": "Jaewoong Choi", "authors": "Jaewoong Choi, Geonho Hwang, Myungjoo Kang", "title": "Discond-VAE: Disentangling Continuous Factors from the Discrete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real-world data, there are common variations shared by all classes\n(e.g. category label) and exclusive variations of each class. We propose a\nvariant of VAE capable of disentangling both of these variations. To represent\nthese generative factors of data, we introduce two sets of continuous latent\nvariables, private variable and public variable. Our proposed framework models\nthe private variable as a Mixture of Gaussian and the public variable as a\nGaussian, respectively. Each mode of the private variable is responsible for a\nclass of the discrete variable.\n  Most of the previous attempts to integrate the discrete generative factors to\ndisentanglement assume statistical independence between the continuous and\ndiscrete variables. Our proposed model, which we call Discond-VAE, DISentangles\nthe class-dependent CONtinuous factors from the Discrete factors by introducing\nthe private variables. The experiments show that Discond-VAE can discover the\nprivate and public factors from data. Moreover, even under the dataset with\nonly public factors, Discond-VAE does not fail and adapts the private variables\nto represent the public factors.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:19:03 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 01:45:45 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Choi", "Jaewoong", ""], ["Hwang", "Geonho", ""], ["Kang", "Myungjoo", ""]]}, {"id": "2009.08052", "submitter": "Chang Liu", "authors": "Chang Liu, Huichu Zhang, Weinan Zhang, Guanjie Zheng, Yong Yu", "title": "GeneraLight: Improving Environment Generalization of Traffic Signal\n  Control via Meta Reinforcement Learning", "comments": "Proceedings of the 29th ACM International on Conference on\n  Information and Knowledge Management (CIKM). ACM, 2020", "journal-ref": null, "doi": "10.1145/3340531.3411859", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heavy traffic congestion problem has always been a concern for modern\ncities. To alleviate traffic congestion, researchers use reinforcement learning\n(RL) to develop better traffic signal control (TSC) algorithms in recent years.\nHowever, most RL models are trained and tested in the same traffic flow\nenvironment, which results in a serious overfitting problem. Since the traffic\nflow environment in the real world keeps varying, these models can hardly be\napplied due to the lack of generalization ability. Besides, the limited number\nof accessible traffic flow data brings extra difficulty in testing the\ngeneralization ability of the models. In this paper, we design a novel traffic\nflow generator based on Wasserstein generative adversarial network to generate\nsufficient diverse and quality traffic flows and use them to build proper\ntraining and testing environments. Then we propose a meta-RL TSC framework\nGeneraLight to improve the generalization ability of TSC models. GeneraLight\nboosts the generalization performance by combining the idea of flow clustering\nand model-agnostic meta-learning. We conduct extensive experiments on multiple\nreal-world datasets to show the superior performance of GeneraLight on\ngeneralizing to different traffic flows.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:14:28 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Liu", "Chang", ""], ["Zhang", "Huichu", ""], ["Zhang", "Weinan", ""], ["Zheng", "Guanjie", ""], ["Yu", "Yong", ""]]}, {"id": "2009.08058", "submitter": "Shao-Yuan Lo", "authors": "Shao-Yuan Lo, Vishal M. Patel", "title": "MultAV: Multiplicative Adversarial Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of adversarial machine learning research focuses on additive\nthreat models, which add adversarial perturbation to input data. On the other\nhand, unlike image recognition problems, only a handful of threat models have\nbeen explored in the video domain. In this paper, we propose a novel\nadversarial attack against video recognition models, Multiplicative Adversarial\nVideos (MultAV), which imposes perturbation on video data by multiplication.\nMultAV has different noise distributions to the additive counterparts and thus\nchallenges the defense methods tailored to resisting additive attacks.\nMoreover, it can be generalized to not only Lp-norm attacks with a new\nadversary constraint called ratio bound, but also different types of physically\nrealizable attacks. Experimental results show that the model adversarially\ntrained against additive attack is less robust to MultAV.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:34:39 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lo", "Shao-Yuan", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2009.08061", "submitter": "Aounon Kumar", "authors": "Aounon Kumar, Alexander Levine, Soheil Feizi, Tom Goldstein", "title": "Certifying Confidence via Randomized Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing has been shown to provide good certified-robustness\nguarantees for high-dimensional classification problems. It uses the\nprobabilities of predicting the top two most-likely classes around an input\npoint under a smoothing distribution to generate a certified radius for a\nclassifier's prediction. However, most smoothing methods do not give us any\ninformation about the confidence with which the underlying classifier (e.g.,\ndeep neural network) makes a prediction. In this work, we propose a method to\ngenerate certified radii for the prediction confidence of the smoothed\nclassifier. We consider two notions for quantifying confidence: average\nprediction score of a class and the margin by which the average prediction\nscore of one class exceeds that of another. We modify the Neyman-Pearson lemma\n(a key theorem in randomized smoothing) to design a procedure for computing the\ncertified radius where the confidence is guaranteed to stay above a certain\nthreshold. Our experimental results on CIFAR-10 and ImageNet datasets show that\nusing information about the distribution of the confidence scores allows us to\nachieve a significantly better certified radius than ignoring it. Thus, we\ndemonstrate that extra information about the base classifier at the input point\ncan help improve certified guarantees for the smoothed classifier. Code for the\nexperiments is available at https://github.com/aounon/cdf-smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:37:26 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 21:15:50 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Kumar", "Aounon", ""], ["Levine", "Alexander", ""], ["Feizi", "Soheil", ""], ["Goldstein", "Tom", ""]]}, {"id": "2009.08062", "submitter": "Ori Katz", "authors": "Ori Katz, Roy R. Lederman and Ronen Talmon", "title": "Spectral Flow on the Manifold of SPD Matrices for Multimodal Data\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider data acquired by multimodal sensors capturing\ncomplementary aspects and features of a measured phenomenon. We focus on a\nscenario in which the measurements share mutual sources of variability but\nmight also be contaminated by other measurement-specific sources such as\ninterferences or noise. Our approach combines manifold learning, which is a\nclass of nonlinear data-driven dimension reduction methods, with the well-known\nRiemannian geometry of symmetric and positive-definite (SPD) matrices. Manifold\nlearning typically includes the spectral analysis of a kernel built from the\nmeasurements. Here, we take a different approach, utilizing the Riemannian\ngeometry of the kernels. In particular, we study the way the spectrum of the\nkernels changes along geodesic paths on the manifold of SPD matrices. We show\nthat this change enables us, in a purely unsupervised manner, to derive a\ncompact, yet informative, description of the relations between the\nmeasurements, in terms of their underlying components. Based on this result, we\npresent new algorithms for extracting the common latent components and for\nidentifying common and measurement-specific components.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:38:57 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Katz", "Ori", ""], ["Lederman", "Roy R.", ""], ["Talmon", "Ronen", ""]]}, {"id": "2009.08063", "submitter": "Ruixuan Liu", "authors": "Ruixuan Liu, Yang Cao, Hong Chen, Ruoyang Guo, Masatoshi Yoshikawa", "title": "FLAME: Differentially Private Federated Learning in the Shuffle Model", "comments": "accepted by AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a promising machine learning paradigm that enables\nthe analyzer to train a model without collecting users' raw data. To ensure\nusers' privacy, differentially private federated learning has been intensively\nstudied. The existing works are mainly based on the \\textit{curator model} or\n\\textit{local model} of differential privacy. However, both of them have pros\nand cons. The curator model allows greater accuracy but requires a trusted\nanalyzer. In the local model where users randomize local data before sending\nthem to the analyzer, a trusted analyzer is not required but the accuracy is\nlimited. In this work, by leveraging the \\textit{privacy amplification} effect\nin the recently proposed shuffle model of differential privacy, we achieve the\nbest of two worlds, i.e., accuracy in the curator model and strong privacy\nwithout relying on any trusted party. We first propose an FL framework in the\nshuffle model and a simple protocol (SS-Simple) extended from existing work. We\nfind that SS-Simple only provides an insufficient privacy amplification effect\nin FL since the dimension of the model parameter is quite large. To solve this\nchallenge, we propose an enhanced protocol (SS-Double) to increase the privacy\namplification effect by subsampling. Furthermore, for boosting the utility when\nthe model size is greater than the user population, we propose an advanced\nprotocol (SS-Topk) with gradient sparsification techniques. We also provide\ntheoretical analysis and numerical evaluations of the privacy amplification of\nthe proposed protocols. Experiments on real-world dataset validate that SS-Topk\nimproves the testing accuracy by 60.7\\% than the local model based FL.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:44:27 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 02:40:56 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2020 05:55:16 GMT"}, {"version": "v4", "created": "Sat, 20 Mar 2021 09:05:39 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Liu", "Ruixuan", ""], ["Cao", "Yang", ""], ["Chen", "Hong", ""], ["Guo", "Ruoyang", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2009.08071", "submitter": "Yunyi Zhang", "authors": "Yunyi Zhang and Dimitris N. Politis", "title": "Ridge Regression Revisited: Debiasing, Thresholding and Bootstrap", "comments": "2 figures, 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of the Lasso in the era of high-dimensional data can be\nattributed to its conducting an implicit model selection, i.e., zeroing out\nregression coefficients that are not significant. By contrast, classical ridge\nregression can not reveal a potential sparsity of parameters, and may also\nintroduce a large bias under the high-dimensional setting. Nevertheless, recent\nwork on the Lasso involves debiasing and thresholding, the latter in order to\nfurther enhance the model selection. As a consequence, ridge regression may be\nworth another look since -- after debiasing and thresholding -- it may offer\nsome advantages over the Lasso, e.g., it can be easily computed using a\nclosed-form expression. % and it has similar performance to threshold Lasso. In\nthis paper, we define a debiased and thresholded ridge regression method, and\nprove a consistency result and a Gaussian approximation theorem. We further\nintroduce a wild bootstrap algorithm to construct confidence regions and\nperform hypothesis testing for a linear combination of parameters. In addition\nto estimation, we consider the problem of prediction, and present a novel,\nhybrid bootstrap algorithm tailored for prediction intervals. Extensive\nnumerical simulations further show that the debiased and thresholded ridge\nregression has favorable finite sample performance and may be preferable in\nsome settings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 05:04:10 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 17:38:30 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zhang", "Yunyi", ""], ["Politis", "Dimitris N.", ""]]}, {"id": "2009.08072", "submitter": "Nhat Tran", "authors": "Nhat Tran, Jean Gao", "title": "Layer-stacked Attention for Heterogeneous Network Embedding", "comments": "Technical appendix in last pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The heterogeneous network is a robust data abstraction that can model\nentities of different types interacting in various ways. Such heterogeneity\nbrings rich semantic information but presents nontrivial challenges in\naggregating the heterogeneous relationships between objects - especially those\nof higher-order indirect relations. Recent graph neural network approaches for\nrepresentation learning on heterogeneous networks typically employ the\nattention mechanism, which is often only optimized for predictions based on\ndirect links. Furthermore, even though most deep learning methods can aggregate\nhigher-order information by building deeper models, such a scheme can diminish\nthe degree of interpretability. To overcome these challenges, we explore an\narchitecture - Layer-stacked ATTention Embedding (LATTE) - that automatically\ndecomposes higher-order meta relations at each layer to extract the relevant\nheterogeneous neighborhood structures for each node. Additionally, by\nsuccessively stacking layer representations, the learned node embedding offers\na more interpretable aggregation scheme for nodes of different types at\ndifferent neighborhood ranges. We conducted experiments on several benchmark\nheterogeneous network datasets. In both transductive and inductive node\nclassification tasks, LATTE can achieve state-of-the-art performance compared\nto existing approaches, all while offering a lightweight model. With extensive\nexperimental analyses and visualizations, the framework can demonstrate the\nability to extract informative insights on heterogeneous networks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 05:13:41 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Tran", "Nhat", ""], ["Gao", "Jean", ""]]}, {"id": "2009.08092", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Yamini Bansal", "title": "Distributional Generalization: A New Kind of Generalization", "comments": "Co-first authors. V2: Intro shortened; no new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new notion of generalization -- Distributional Generalization\n-- which roughly states that outputs of a classifier at train and test time are\nclose *as distributions*, as opposed to close in just their average error. For\nexample, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then\na ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as\ncats on the *test set* as well, while leaving other classes unaffected. This\nbehavior is not captured by classical generalization, which would only consider\nthe average error and not the distribution of errors over the input domain. Our\nformal conjectures, which are much more general than this example, characterize\nthe form of distributional generalization that can be expected in terms of\nproblem parameters: model architecture, training procedure, number of samples,\nand data distribution. We give empirical evidence for these conjectures across\na variety of domains in machine learning, including neural networks, kernel\nmachines, and decision trees. Our results thus advance our empirical\nunderstanding of interpolating classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:26:17 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 02:41:52 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Bansal", "Yamini", ""]]}, {"id": "2009.08093", "submitter": "Zhixiang Li", "authors": "Yuqi Meng, Ying Zhao, Zhixiang Li", "title": "An early prediction of covid-19 associated hospitalization surge using\n  deep learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The global pandemic caused by COVID-19 affects our lives in all aspects. As\nof September 11, more than 28 million people have tested positive for COVID-19\ninfection, and more than 911,000 people have lost their lives in this virus\nbattle. Some patients can not receive appropriate medical treatment due the\nlimits of hospitalization volume and shortage of ICU beds. An estimated future\nhospitalization is critical so that medical resources can be allocated as\nneeded. In this study, we propose to use 4 recurrent neural networks to infer\nhospitalization change for the following week compared with the current week.\nResults show that sequence to sequence model with attention achieves a high\naccuracy of 0.938 and AUC of 0.850 in the hospitalization prediction. Our work\nhas the potential to predict the hospitalization need and send a warning to\nmedical providers and other stakeholders when a re-surge initializes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:26:50 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Meng", "Yuqi", ""], ["Zhao", "Ying", ""], ["Li", "Zhixiang", ""]]}, {"id": "2009.08097", "submitter": "Sumit Kumar Jha", "authors": "Sumit Kumar Jha, Susmit Jha, Rickard Ewetz, Sunny Raj, Alvaro\n  Velasquez, Laura L. Pullum, Ananthram Swami", "title": "An Extension of Fano's Inequality for Characterizing Model\n  Susceptibility to Membership Inference Attacks", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be vulnerable to membership inference\nattacks wherein the attacker aims to detect whether specific input data were\nused to train the model. These attacks can potentially leak private or\nproprietary data. We present a new extension of Fano's inequality and employ it\nto theoretically establish that the probability of success for a membership\ninference attack on a deep neural network can be bounded using the mutual\ninformation between its inputs and its activations. This enables the use of\nmutual information to measure the susceptibility of a DNN model to membership\ninference attacks. In our empirical evaluation, we show that the correlation\nbetween the mutual information and the susceptibility of the DNN model to\nmembership inference attacks is 0.966, 0.996, and 0.955 for CIFAR-10, SVHN and\nGTSRB models, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:37:15 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Jha", "Sumit Kumar", ""], ["Jha", "Susmit", ""], ["Ewetz", "Rickard", ""], ["Raj", "Sunny", ""], ["Velasquez", "Alvaro", ""], ["Pullum", "Laura L.", ""], ["Swami", "Ananthram", ""]]}, {"id": "2009.08102", "submitter": "Giorgio Corani", "authors": "Giorgio Corani, Alessio Benavoli, Marco Zaffalon", "title": "Time series forecasting with Gaussian Processes needs priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic forecasting is the task of receiving a time series and returning a\nforecast for the next time steps without any human intervention. Gaussian\nProcesses (GPs) are a powerful tool for modeling time series, but so far there\nare no competitive approaches for automatic forecasting based on GPs. We\npropose practical solutions to two problems: automatic selection of the optimal\nkernel and reliable estimation of the hyperparameters. We propose a fixed\ncomposition of kernels, which contains the components needed to model most time\nseries: linear trend, periodic patterns, and other flexible kernel for modeling\nthe non-linear trend. Not all components are necessary to model each time\nseries; during training the unnecessary components are automatically made\nirrelevant via automatic relevance determination (ARD). We moreover assign\npriors to the hyperparameters, in order to keep the inference within a\nplausible range; we design such priors through an empirical Bayes approach. We\npresent results on many time series of different types; our GP model is more\naccurate than state-of-the-art time series models. Thanks to the priors, a\nsingle restart is enough the estimate the hyperparameters; hence the model is\nalso fast to train.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:46:51 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 10:10:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Corani", "Giorgio", ""], ["Benavoli", "Alessio", ""], ["Zaffalon", "Marco", ""]]}, {"id": "2009.08107", "submitter": "Alessia Bertugli", "authors": "Alessia Bertugli, Stefano Vincenzi, Simone Calderara, Andrea Passerini", "title": "Few-Shot Unsupervised Continual Learning through Meta-Examples", "comments": "Accepted at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), 4th Workshop on Meta-Learning, 16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications, data do not reflect the ones commonly used for\nneural networks training, since they are usually few, unlabeled and can be\navailable as a stream. Hence many existing deep learning solutions suffer from\na limited range of applications, in particular in the case of online streaming\ndata that evolve over time. To narrow this gap, in this work we introduce a\nnovel and complex setting involving unsupervised meta-continual learning with\nunbalanced tasks. These tasks are built through a clustering procedure applied\nto a fitted embedding space. We exploit a meta-learning scheme that\nsimultaneously alleviates catastrophic forgetting and favors the generalization\nto new tasks. Moreover, to encourage feature reuse during the\nmeta-optimization, we exploit a single inner loop taking advantage of an\naggregated representation achieved through the use of a self-attention\nmechanism. Experimental results on few-shot learning benchmarks show\ncompetitive performance even compared to the supervised case. Additionally, we\nempirically observe that in an unsupervised scenario, the small tasks and the\nvariability in the clusters pooling play a crucial role in the generalization\ncapability of the network. Further, on complex datasets, the exploitation of\nmore clusters than the true number of classes leads to higher results, even\ncompared to the ones obtained with full supervision, suggesting that a\npredefined partitioning into classes can miss relevant structural information.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:02:07 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 13:01:57 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 13:38:40 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bertugli", "Alessia", ""], ["Vincenzi", "Stefano", ""], ["Calderara", "Simone", ""], ["Passerini", "Andrea", ""]]}, {"id": "2009.08120", "submitter": "Kim Hammar", "authors": "Kim Hammar and Rolf Stadler", "title": "Finding Effective Security Strategies through Reinforcement Learning and\n  Self-Play", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.14128.38405", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to automatically find security strategies for the use\ncase of intrusion prevention. Following this method, we model the interaction\nbetween an attacker and a defender as a Markov game and let attack and defense\nstrategies evolve through reinforcement learning and self-play without human\nintervention. Using a simple infrastructure configuration, we demonstrate that\neffective security strategies can emerge from self-play. This shows that\nself-play, which has been applied in other domains with great success, can be\neffective in the context of network security. Inspection of the converged\npolicies show that the emerged policies reflect common-sense knowledge and are\nsimilar to strategies of humans. Moreover, we address known challenges of\nreinforcement learning in this domain and present an approach that uses\nfunction approximation, an opponent pool, and an autoregressive policy\nrepresentation. Through evaluations we show that our method is superior to two\nbaseline methods but that policy convergence in self-play remains a challenge.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:41:27 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 16:22:54 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hammar", "Kim", ""], ["Stadler", "Rolf", ""]]}, {"id": "2009.08136", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Multidimensional Scaling, Sammon Mapping, and Isomap: Tutorial and\n  Survey", "comments": "To appear as a part of an upcoming academic book on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional Scaling (MDS) is one of the first fundamental manifold\nlearning methods. It can be categorized into several methods, i.e., classical\nMDS, kernel classical MDS, metric MDS, and non-metric MDS. Sammon mapping and\nIsomap can be considered as special cases of metric MDS and kernel classical\nMDS, respectively. In this tutorial and survey paper, we review the theory of\nMDS, Sammon mapping, and Isomap in detail. We explain all the mentioned\ncategories of MDS. Then, Sammon mapping, Isomap, and kernel Isomap are\nexplained. Out-of-sample embedding for MDS and Isomap using eigenfunctions and\nkernel mapping are introduced. Then, Nystrom approximation and its use in\nlandmark MDS and landmark Isomap are introduced for big data embedding. We also\nprovide some simulations for illustrating the embedding by these methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:12:25 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2009.08142", "submitter": "Konstantin Avrachenkov", "authors": "Konstantin Avrachenkov, Kishor Patil, Gugan Thoppe", "title": "Online Algorithms for Estimating Change Rates of Web Pages", "comments": "A significantly extended version of ValueTools 2020 conference paper\n  [arXiv:2004.02167]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For providing quick and accurate search results, a search engine maintains a\nlocal snapshot of the entire web. And, to keep this local cache fresh, it\nemploys a crawler for tracking changes across various web pages. It would have\nbeen ideal if the crawler managed to update the local snapshot as soon as a\npage changed on the web. However, finite bandwidth availability and server\nrestrictions mean that there is a bound on how frequently the different pages\ncan be crawled. This then brings forth the following optimisation problem:\nmaximise the freshness of the local cache subject to the crawling frequency\nbeing within the prescribed bounds. Recently, tractable algorithms have been\nproposed to solve this optimisation problem under different cost criteria.\nHowever, these assume the knowledge of exact page change rates, which is\nunrealistic in practice. We address this issue here. Specifically, we provide\nthree novel schemes for online estimation of page change rates. All these\nschemes only need partial information about the page change process, i.e., they\nonly need to know if the page has changed or not since the last crawl instance.\nOur first scheme is based on the law of large numbers, the second on the theory\nof stochastic approximation, while the third is an extension of the second and\ninvolves an additional momentum term. For all of these schemes, we prove\nconvergence and, also, provide their convergence rates. As far as we know, the\nresults concerning the third estimator is quite novel. Specifically, this is\nthe first convergence type result for a stochastic approximation algorithm with\nmomentum. Finally, we provide some numerical experiments (on real as well as\nsynthetic data) to compare the performance of our proposed estimators with the\nexisting ones (e.g., MLE).\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:25:02 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Avrachenkov", "Konstantin", ""], ["Patil", "Kishor", ""], ["Thoppe", "Gugan", ""]]}, {"id": "2009.08155", "submitter": "Antonio Liguori", "authors": "Antonio Liguori, Romana Markovic, Thi Thu Ha Dam, J\\'er\\^ome Frisch,\n  Christoph van Treeck, Francesco Causone", "title": "Indoor environment data time-series reconstruction using autoencoder\n  neural networks", "comments": "Accepted in Building and Environment", "journal-ref": "Building and Environment 191 (2021) 107623", "doi": "10.1016/j.buildenv.2021.107623", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of installed meters in buildings increases, there is a growing\nnumber of data time-series that could be used to develop data-driven models to\nsupport and optimize building operation. However, building data sets are often\ncharacterized by errors and missing values, which are considered, by the recent\nresearch, among the main limiting factors on the performance of the proposed\nmodels. Motivated by the need to address the problem of missing data in\nbuilding operation, this work presents a data-driven approach to fill these\ngaps. In this study, three different autoencoder neural networks are trained to\nreconstruct missing short-term indoor environment data time-series in a data\nset collected in an office building in Aachen, Germany. This consisted of a\nfour year-long monitoring campaign in and between the years 2014 and 2017, of\n84 different rooms. The models are applicable for different time-series\nobtained from room automation, such as indoor air temperature, relative\nhumidity and $CO_{2}$ data streams. The results prove that the proposed methods\noutperform classic numerical approaches and they result in reconstructing the\ncorresponding variables with average RMSEs of 0.42 {\\deg}C, 1.30 % and 78.41\nppm, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:05:40 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 09:36:37 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Liguori", "Antonio", ""], ["Markovic", "Romana", ""], ["Dam", "Thi Thu Ha", ""], ["Frisch", "J\u00e9r\u00f4me", ""], ["van Treeck", "Christoph", ""], ["Causone", "Francesco", ""]]}, {"id": "2009.08161", "submitter": "Jie Peng", "authors": "Jie Peng, Zhaoxian Wu, Qing Ling", "title": "Byzantine-Robust Variance-Reduced Federated Learning over Distributed\n  Non-i.i.d. Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Byzantine-robust variance-reduced stochastic gradient descent\n(SGD) method to solve the distributed finite-sum minimization problem when the\ndata on the workers are not independent and identically distributed (i.i.d.).\nDuring the learning process, an unknown number of Byzantine workers may send\nmalicious messages to the master node, leading to remarkable learning error.\nMost of the Byzantine-robust methods address this issue by using robust\naggregation rules to aggregate the received messages, but rely on the\nassumption that all the regular workers have i.i.d. data, which is not the case\nin many federated learning applications. In light of the significance of\nreducing stochastic gradient noise for mitigating the effect of Byzantine\nattacks, we use a resampling strategy to reduce the impact of both inner\nvariation (that describes the sample heterogeneity on every regular worker) and\nouter variation (that describes the sample heterogeneity among the regular\nworkers), along with a stochastic average gradient algorithm (SAGA) to fully\neliminate the inner variation. The variance-reduced messages are then\naggregated with a robust geometric median operator. Under certain conditions,\nwe prove that the proposed method reaches a neighborhood of the optimal\nsolution with linear convergence rate, and the learning error is much smaller\nthan those given by the state-of-the-art methods in the non-i.i.d. setting.\nNumerical experiments corroborate the theoretical results and show satisfactory\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:09:23 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Peng", "Jie", ""], ["Wu", "Zhaoxian", ""], ["Ling", "Qing", ""]]}, {"id": "2009.08166", "submitter": "Shogo Iwazaki", "authors": "Shogo Iwazaki, Yu Inatsu, Ichiro Takeuchi", "title": "Mean-Variance Analysis in Bayesian Optimization under Uncertainty", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider active learning (AL) in an uncertain environment in which\ntrade-off between multiple risk measures need to be considered. As an AL\nproblem in such an uncertain environment, we study Mean-Variance Analysis in\nBayesian Optimization (MVA-BO) setting. Mean-variance analysis was developed in\nthe field of financial engineering and has been used to make decisions that\ntake into account the trade-off between the average and variance of investment\nuncertainty. In this paper, we specifically focus on BO setting with an\nuncertain component and consider multi-task, multi-objective, and constrained\noptimization scenarios for the mean-variance trade-off of the uncertain\ncomponent. When the target blackbox function is modeled by Gaussian Process\n(GP), we derive the bounds of the two risk measures and propose AL algorithm\nfor each of the above three problems based on the risk measure bounds. We show\nthe effectiveness of the proposed AL algorithms through theoretical analysis\nand numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:21:46 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Iwazaki", "Shogo", ""], ["Inatsu", "Yu", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2009.08169", "submitter": "Fabian Timm", "authors": "Lukas Enderich and Fabian Timm and Wolfram Burgard", "title": "Holistic Filter Pruning for Efficient Deep Neural Networks", "comments": "preprint, accepted at WACV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are usually over-parameterized to increase the\nlikelihood of getting adequate initial weights by random initialization.\nConsequently, trained DNNs have many redundancies which can be pruned from the\nmodel to reduce complexity and improve the ability to generalize. Structural\nsparsity, as achieved by filter pruning, directly reduces the tensor sizes of\nweights and activations and is thus particularly effective for reducing\ncomplexity. We propose \"Holistic Filter Pruning\" (HFP), a novel approach for\ncommon DNN training that is easy to implement and enables to specify accurate\npruning rates for the number of both parameters and multiplications. After each\nforward pass, the current model complexity is calculated and compared to the\ndesired target size. By gradient descent, a global solution can be found that\nallocates the pruning budget over the individual layers such that the desired\ntarget size is fulfilled. In various experiments, we give insights into the\ntraining and achieve state-of-the-art performance on CIFAR-10 and ImageNet (HFP\nprunes 60% of the multiplications of ResNet-50 on ImageNet with no significant\nloss in the accuracy). We believe our simple and powerful pruning approach to\nconstitute a valuable contribution for users of DNNs in low-cost applications.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:23:36 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Enderich", "Lukas", ""], ["Timm", "Fabian", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2009.08198", "submitter": "Lorenzo Mandow", "authors": "L. Mandow, J. L. P\\'erez de la Cruz, N. Pozas", "title": "Multi-objective dynamic programming with limited precision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of approximating the set of all solutions\nfor Multi-objective Markov Decision Processes. We show that in the vast\nmajority of interesting cases, the number of solutions is exponential or even\ninfinite. In order to overcome this difficulty we propose to approximate the\nset of all solutions by means of a limited precision approach based on White's\nmulti-objective value-iteration dynamic programming algorithm. We prove that\nthe number of calculated solutions is tractable and show experimentally that\nthe solutions obtained are a good approximation of the true Pareto front.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 10:34:01 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mandow", "L.", ""], ["de la Cruz", "J. L. P\u00e9rez", ""], ["Pozas", "N.", ""]]}, {"id": "2009.08265", "submitter": "Ningyuan Chen", "authors": "Wenhao Li, Ningyuan Chen, L. Jeff Hong", "title": "Dimension Reduction in Contextual Online Learning via Nonparametric\n  Variable Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a contextual online learning (multi-armed bandit) problem with\nhigh-dimensional covariate $\\mathbf{x}$ and decision $\\mathbf{y}$. The reward\nfunction to learn, $f(\\mathbf{x},\\mathbf{y})$, does not have a particular\nparametric form. The literature has shown that the optimal regret is\n$\\tilde{O}(T^{(d_x+d_y+1)/(d_x+d_y+2)})$, where $d_x$ and $d_y$ are the\ndimensions of $\\mathbf x$ and $\\mathbf y$, and thus it suffers from the curse\nof dimensionality. In many applications, only a small subset of variables in\nthe covariate affect the value of $f$, which is referred to as\n\\textit{sparsity} in statistics. To take advantage of the sparsity structure of\nthe covariate, we propose a variable selection algorithm called\n\\textit{BV-LASSO}, which incorporates novel ideas such as binning and voting to\napply LASSO to nonparametric settings. Our algorithm achieves the regret\n$\\tilde{O}(T^{(d_x^*+d_y+1)/(d_x^*+d_y+2)})$, where $d_x^*$ is the effective\ncovariate dimension. The regret matches the optimal regret when the covariate\nis $d^*_x$-dimensional and thus cannot be improved. Our algorithm may serve as\na general recipe to achieve dimension reduction via variable selection in\nnonparametric settings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:08:45 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Li", "Wenhao", ""], ["Chen", "Ningyuan", ""], ["Hong", "L. Jeff", ""]]}, {"id": "2009.08267", "submitter": "Viatcheslav Gurev", "authors": "Jaimit Parikh, James Kozloski, and Viatcheslav Gurev", "title": "Integration of AI and mechanistic modeling in generative adversarial\n  networks for stochastic inverse problems", "comments": "New appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic inverse problems (SIP) address the behavior of a set of objects of\nthe same kind but with variable properties, such as a population of cells.\nUsing a population of mechanistic models from a single parametric family, SIP\nexplains population variability by transferring real-world observations into\nthe latent space of model parameters. Previous research in SIP focused on\nsolving the parameter inference problem for a single population using Markov\nchain Monte Carlo methods. Here we extend SIP to address multiple related\npopulations simultaneously. Specifically, we simulate control and treatment\npopulations in experimental protocols by discovering two related latent spaces\nof model parameters. Instead of taking a Bayesian approach, our two-population\nSIP is reformulated as the constrained-optimization problem of finding\ndistributions of model parameters. To minimize the divergence between\ndistributions of experimental observations and model outputs, we developed\nnovel deep learning models based on generative adversarial networks (GANs)\nwhich have the structure of our underlying constrained-optimization problem.\nThe flexibility of GANs allowed us to build computationally scalable solutions\nand tackle complex model input parameter inference scenarios, which appear\nroutinely in physics, biophysics, economics and other areas, and which can not\nbe handled with existing methods. Specifically, we demonstrate two scenarios of\nparameter inference over a control population and a treatment population whose\ntreatment either selectively affects only a subset of model parameters with\nsome uncertainty or has a deterministic effect on all model parameters.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:13:21 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 23:16:26 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Parikh", "Jaimit", ""], ["Kozloski", "James", ""], ["Gurev", "Viatcheslav", ""]]}, {"id": "2009.08273", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "When compressive learning fails: blame the decoder or the sketch?", "comments": "in Proceedings of iTWIST'20, Paper-ID: 22, Nantes, France, December,\n  2-4, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressive learning, a mixture model (a set of centroids or a Gaussian\nmixture) is learned from a sketch vector, that serves as a highly compressed\nrepresentation of the dataset. This requires solving a non-convex optimization\nproblem, hence in practice approximate heuristics (such as CLOMPR) are used. In\nthis work we explore, by numerical simulations, properties of this non-convex\noptimization landscape and those heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:53:03 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "2009.08295", "submitter": "James Morrill Mr", "authors": "James Morrill and Cristopher Salvi and Patrick Kidger and James Foster\n  and Terry Lyons", "title": "Neural Rough Differential Equations for Long Time Series", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural controlled differential equations (CDEs) are the continuous-time\nanalogue of recurrent neural networks, as Neural ODEs are to residual networks,\nand offer a memory-efficient continuous-time way to model functions of\npotentially irregular time series. Existing methods for computing the forward\npass of a Neural CDE involve embedding the incoming time series into path\nspace, often via interpolation, and using evaluations of this path to drive the\nhidden state. Here, we use rough path theory to extend this formulation.\nInstead of directly embedding into path space, we instead represent the input\nsignal over small time intervals through its \\textit{log-signature}, which are\nstatistics describing how the signal drives a CDE. This is the approach for\nsolving \\textit{rough differential equations} (RDEs), and correspondingly we\ndescribe our main contribution as the introduction of Neural RDEs. This\nextension has a purpose: by generalising the Neural CDE approach to a broader\nclass of driving signals, we demonstrate particular advantages for tackling\nlong time series. In this regime, we demonstrate efficacy on problems of length\nup to 17k observations and observe significant training speed-ups, improvements\nin model performance, and reduced memory requirements compared to existing\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:43:47 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 19:08:20 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 11:28:41 GMT"}, {"version": "v4", "created": "Mon, 21 Jun 2021 12:04:06 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Morrill", "James", ""], ["Salvi", "Cristopher", ""], ["Kidger", "Patrick", ""], ["Foster", "James", ""], ["Lyons", "Terry", ""]]}, {"id": "2009.08299", "submitter": "Pietro Barbiero", "authors": "Pietro Barbiero, Ramon Vi\\~nas Torn\\'e, Pietro Li\\'o", "title": "Graph representation forecasting of patient's medical conditions:\n  towards a digital twin", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Modern medicine needs to shift from a wait and react, curative\ndiscipline to a preventative, interdisciplinary science aiming at providing\npersonalised, systemic and precise treatment plans to patients. The aim of this\nwork is to present how the integration of machine learning approaches with\nmechanistic computational modelling could yield a reliable infrastructure to\nrun probabilistic simulations where the entire organism is considered as a\nwhole. Methods: We propose a general framework that composes advanced AI\napproaches and integrates mathematical modelling in order to provide a\npanoramic view over current and future physiological conditions. The proposed\narchitecture is based on a graph neural network (GNNs) forecasting clinically\nrelevant endpoints (such as blood pressure) and a generative adversarial\nnetwork (GANs) providing a proof of concept of transcriptomic integrability.\nResults: We show the results of the investigation of pathological effects of\noverexpression of ACE2 across different signalling pathways in multiple tissues\non cardiovascular functions. We provide a proof of concept of integrating a\nlarge set of composable clinical models using molecular data to drive local and\nglobal clinical parameters and derive future trajectories representing the\nevolution of the physiological state of the patient. Significance: We argue\nthat the graph representation of a computational patient has potential to solve\nimportant technological challenges in integrating multiscale computational\nmodelling with AI. We believe that this work represents a step forward towards\na healthcare digital twin.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:49:48 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Barbiero", "Pietro", ""], ["Torn\u00e9", "Ramon Vi\u00f1as", ""], ["Li\u00f3", "Pietro", ""]]}, {"id": "2009.08311", "submitter": "Wenhao Ding", "authors": "Wenhao Ding, Baiming Chen, Bo Li, Kim Ji Eun, Ding Zhao", "title": "Multimodal Safety-Critical Scenarios Generation for Decision-Making\n  Algorithms Evaluation", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural network-based autonomous systems are shown to be vulnerable\nagainst adversarial attacks, therefore sophisticated evaluation on their\nrobustness is of great importance. However, evaluating the robustness only\nunder the worst-case scenarios based on known attacks is not comprehensive, not\nto mention that some of them even rarely occur in the real world. In addition,\nthe distribution of safety-critical data is usually multimodal, while most\ntraditional attacks and evaluation methods focus on a single modality. To solve\nthe above challenges, we propose a flow-based multimodal safety-critical\nscenario generator for evaluating decisionmaking algorithms. The proposed\ngenerative model is optimized with weighted likelihood maximization and a\ngradient-based sampling procedure is integrated to improve the sampling\nefficiency. The safety-critical scenarios are generated by querying the task\nalgorithms and the log-likelihood of the generated scenarios is in proportion\nto the risk level. Experiments on a self-driving task demonstrate our\nadvantages in terms of testing efficiency and multimodal modeling capability.\nWe evaluate six Reinforcement Learning algorithms with our generated traffic\nscenarios and provide empirical conclusions about their robustness.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:16:43 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 00:16:13 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 16:54:12 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ding", "Wenhao", ""], ["Chen", "Baiming", ""], ["Li", "Bo", ""], ["Eun", "Kim Ji", ""], ["Zhao", "Ding", ""]]}, {"id": "2009.08313", "submitter": "Mar\\'ia \\'Oskarsd\\'ottir", "authors": "Mar\\'ia \\'Oskarsd\\'ottir, Waqas Ahmed, Katrien Antonio, Bart Baesens,\n  R\\'emi Dendievel, Tom Donas, Tom Reynkens", "title": "Social network analytics for supervised fraud detection in insurance", "comments": "37 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insurance fraud occurs when policyholders file claims that are exaggerated or\nbased on intentional damages. This contribution develops a fraud detection\nstrategy by extracting insightful information from the social network of a\nclaim. First, we construct a network by linking claims with all their involved\nparties, including the policyholders, brokers, experts, and garages. Next, we\nestablish fraud as a social phenomenon in the network and use the BiRank\nalgorithm with a fraud specific query vector to compute a fraud score for each\nclaim. From the network, we extract features related to the fraud scores as\nwell as the claims' neighborhood structure. Finally, we combine these network\nfeatures with the claim-specific features and build a supervised model with\nfraud in motor insurance as the target variable. Although we build a model for\nonly motor insurance, the network includes claims from all available lines of\nbusiness. Our results show that models with features derived from the network\nperform well when detecting fraud and even outperform the models using only the\nclassical claim-specific features. Combining network and claim-specific\nfeatures further improves the performance of supervised learning models to\ndetect fraud. The resulting model flags highly suspicions claims that need to\nbe further investigated. Our approach provides a guided and intelligent\nselection of claims and contributes to a more effective fraud investigation\nprocess.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:40:15 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["\u00d3skarsd\u00f3ttir", "Mar\u00eda", ""], ["Ahmed", "Waqas", ""], ["Antonio", "Katrien", ""], ["Baesens", "Bart", ""], ["Dendievel", "R\u00e9mi", ""], ["Donas", "Tom", ""], ["Reynkens", "Tom", ""]]}, {"id": "2009.08319", "submitter": "Michael Laskin", "authors": "Adam Stooke, Kimin Lee, Pieter Abbeel, and Michael Laskin", "title": "Decoupling Representation Learning from Reinforcement Learning", "comments": "Improved related works and fixed code hyperlink", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an effort to overcome limitations of reward-driven feature learning in\ndeep reinforcement learning (RL) from images, we propose decoupling\nrepresentation learning from policy learning. To this end, we introduce a new\nunsupervised learning (UL) task, called Augmented Temporal Contrast (ATC),\nwhich trains a convolutional encoder to associate pairs of observations\nseparated by a short time difference, under image augmentations and using a\ncontrastive loss. In online RL experiments, we show that training the encoder\nexclusively using ATC matches or outperforms end-to-end RL in most\nenvironments. Additionally, we benchmark several leading UL algorithms by\npre-training encoders on expert demonstrations and using them, with weights\nfrozen, in RL agents; we find that agents using ATC-trained encoders outperform\nall others. We also train multi-task encoders on data from multiple\nenvironments and show generalization to different downstream RL tasks. Finally,\nwe ablate components of ATC, and introduce a new data augmentation to enable\nreplay of (compressed) latent images from pre-trained encoders when RL requires\naugmentation. Our experiments span visually diverse RL benchmarks in DeepMind\nControl, DeepMind Lab, and Atari, and our complete code is available at\nhttps://github.com/astooke/rlpyt/tree/master/rlpyt/ul.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 19:11:13 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 16:35:40 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 20:44:18 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Stooke", "Adam", ""], ["Lee", "Kimin", ""], ["Abbeel", "Pieter", ""], ["Laskin", "Michael", ""]]}, {"id": "2009.08326", "submitter": "Abolfazl Taghribi", "authors": "Abolfazl Taghribi, Kerstin Bunte, Rory Smith, Jihye Shin, Michele\n  Mastropietro, Reynier F. Peletier and Peter Tino", "title": "LAAT: Locally Aligned Ant Technique for detecting manifolds of varying\n  density", "comments": "Submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction and clustering are often used as preliminary steps\nfor many complex machine learning tasks. The presence of noise and outliers can\ndeteriorate the performance of such preprocessing and therefore impair the\nsubsequent analysis tremendously. In manifold learning, several studies\nindicate solutions for removing background noise or noise close to the\nstructure when the density is substantially higher than that exhibited by the\nnoise. However, in many applications, including astronomical datasets, the\ndensity varies alongside manifolds that are buried in a noisy background. We\npropose a novel method to extract manifolds in the presence of noise based on\nthe idea of Ant colony optimization. In contrast to the existing random walk\nsolutions, our technique captures points which are locally aligned with major\ndirections of the manifold. Moreover, we empirically show that the biologically\ninspired formulation of ant pheromone reinforces this behavior enabling it to\nrecover multiple manifolds embedded in extremely noisy data clouds. The\nalgorithm's performance is demonstrated in comparison to the state-of-the-art\napproaches, such as Markov Chain, LLPD, and Disperse, on several synthetic and\nreal astronomical datasets stemming from an N-body simulation of a cosmological\nvolume.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:22:50 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Taghribi", "Abolfazl", ""], ["Bunte", "Kerstin", ""], ["Smith", "Rory", ""], ["Shin", "Jihye", ""], ["Mastropietro", "Michele", ""], ["Peletier", "Reynier F.", ""], ["Tino", "Peter", ""]]}, {"id": "2009.08340", "submitter": "Jean-Philippe Ovarlez", "authors": "Jose Agustin Barrachina and Chenfang Ren and Christele Morisseau and\n  Gilles Vieillard and Jean-Philippe Ovarlez", "title": "Complex-Valued vs. Real-Valued Neural Networks for Classification\n  Perspectives: An Example on Non-Circular Data", "comments": "6 pages, 5 figures, conference, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contributions of this paper are twofold. First, we show the potential\ninterest of Complex-Valued Neural Network (CVNN) on classification tasks for\ncomplex-valued datasets. To highlight this assertion, we investigate an example\nof complex-valued data in which the real and imaginary parts are statistically\ndependent through the property of non-circularity. In this context, the\nperformance of fully connected feed-forward CVNNs is compared against a\nreal-valued equivalent model. The results show that CVNN performs better for a\nwide variety of architectures and data structures. CVNN accuracy presents a\nstatistically higher mean and median and lower variance than Real-Valued Neural\nNetwork (RVNN). Furthermore, if no regularization technique is used, CVNN\nexhibits lower overfitting. The second contribution is the release of a Python\nlibrary (Barrachina 2019) using Tensorflow as back-end that enables the\nimplementation and training of CVNNs in the hopes of motivating further\nresearch on this area.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:39:35 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 12:20:21 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Barrachina", "Jose Agustin", ""], ["Ren", "Chenfang", ""], ["Morisseau", "Christele", ""], ["Vieillard", "Gilles", ""], ["Ovarlez", "Jean-Philippe", ""]]}, {"id": "2009.08372", "submitter": "Emmanuel de B\\'ezenac", "authors": "Skander Karkar, Ibrahim Ayed, Emmanuel de B\\'ezenac, Patrick Gallinari", "title": "A Principle of Least Action for the Training of Neural Networks", "comments": "ECML PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been achieving high generalization performance on many\ntasks despite being highly over-parameterized. Since classical statistical\nlearning theory struggles to explain this behavior, much effort has recently\nbeen focused on uncovering the mechanisms behind it, in the hope of developing\na more adequate theoretical framework and having a better control over the\ntrained models. In this work, we adopt an alternate perspective, viewing the\nneural network as a dynamical system displacing input particles over time. We\nconduct a series of experiments and, by analyzing the network's behavior\nthrough its displacements, we show the presence of a low kinetic energy\ndisplacement bias in the transport map of the network, and link this bias with\ngeneralization performance. From this observation, we reformulate the learning\nproblem as follows: finding neural networks which solve the task while\ntransporting the data as efficiently as possible. This offers a novel\nformulation of the learning problem which allows us to provide regularity\nresults for the solution network, based on Optimal Transport theory. From a\npractical viewpoint, this allows us to propose a new learning algorithm, which\nautomatically adapts to the complexity of the given task, and leads to networks\nwith a high generalization ability even in low data regimes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:37:34 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 13:37:31 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 05:28:48 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 09:42:46 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Karkar", "Skander", ""], ["Ayed", "Ibrahim", ""], ["de B\u00e9zenac", "Emmanuel", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2009.08387", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Weidong Shi", "title": "Towards Stable Imbalanced Data Classification via Virtual Big Data\n  Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual Big Data (VBD) proved to be effective to alleviate mode collapse and\nvanishing generator gradient as two major problems of Generative Adversarial\nNeural Networks (GANs) very recently. In this paper, we investigate the\ncapability of VBD to address two other major challenges in Machine Learning\nincluding deep autoencoder training and imbalanced data classification. First,\nwe prove that, VBD can significantly decrease the validation loss of\nautoencoders via providing them a huge diversified training data which is the\nkey to reach better generalization to minimize the over-fitting problem.\nSecond, we use the VBD to propose the first projection-based method called\ncross-concatenation to balance the skewed class distributions without\nover-sampling. We prove that, cross-concatenation can solve uncertainty problem\nof data driven methods for imbalanced classification.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 04:01:51 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Shi", "Weidong", ""]]}, {"id": "2009.08388", "submitter": "George Panagopoulos", "authors": "George Panagopoulos and Giannis Nikolentzos and Michalis Vazirgiannis", "title": "Transfer Graph Neural Networks for Pandemic Forecasting", "comments": "9 pages, AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent outbreak of COVID-19 has affected millions of individuals around\nthe world and has posed a significant challenge to global healthcare. From the\nearly days of the pandemic, it became clear that it is highly contagious and\nthat human mobility contributes significantly to its spread. In this paper, we\nstudy the impact of population movement on the spread of COVID-19, and we\ncapitalize on recent advances in the field of representation learning on graphs\nto capture the underlying dynamics. Specifically, we create a graph where nodes\ncorrespond to a country's regions and the edge weights denote human mobility\nfrom one region to another. Then, we employ graph neural networks to predict\nthe number of future cases, encoding the underlying diffusion patterns that\ngovern the spread into our learning model. Furthermore, to account for the\nlimited amount of training data, we capitalize on the pandemic's asynchronous\noutbreaks across countries and use a model-agnostic meta-learning based method\nto transfer knowledge from one country's model to another's. We compare the\nproposed approach against simple baselines and more traditional forecasting\ntechniques in 3 European countries. Experimental results demonstrate the\nsuperiority of our method, highlighting the usefulness of GNNs in\nepidemiological prediction. Transfer learning provides the best model,\nhighlighting its potential to improve the accuracy of the predictions in case\nof secondary waves, if data from past/parallel outbreaks is utilized.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:23:52 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 16:00:31 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 18:43:17 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 10:32:36 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 14:53:57 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Panagopoulos", "George", ""], ["Nikolentzos", "Giannis", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2009.08390", "submitter": "Julio Omar Palacio Ni\\~no", "authors": "Julio Omar Palacio Ni\\~no", "title": "Detecci\\'on de comunidades en redes: Algoritmos y aplicaciones", "comments": "Master's Thesis", "journal-ref": "University of Granada (2013)", "doi": "10.13140/RG.2.2.15213.82400", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This master's thesis work has the objective of performing an analysis of the\nmethods for detecting communities in networks. As an initial part, I study of\nthe main features of graph theory and communities, as well as common measures\nin this problem. Subsequently, I was performed a review of the main methods of\ndetecting communities, developing a classification, taking into account its\ncharacteristics and computational complexity for the detection of strengths and\nweaknesses in the methods, as well as later works. Then, study the problem of\nclassification of a clustering method, this in order to evaluate the quality of\nthe communities detected by analyzing different measures. Finally conclusions\nare elaborated and possible lines of work that can be derived.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:18:06 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Ni\u00f1o", "Julio Omar Palacio", ""]]}, {"id": "2009.08420", "submitter": "Jonne Pohjankukka Dr.", "authors": "Jonne Pohjankukka, Sakari Tuominen, Jukka Heikkonen", "title": "Utilizing remote sensing data in forest inventory sampling via Bayesian\n  optimization", "comments": "36 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-area forest inventories a trade-off between the amount of data to be\nsampled and the costs of collecting the data is necessary. It is not always\npossible to have a very large data sample when dealing with sampling-based\ninventories. It is therefore necessary to optimize the sampling design in order\nto achieve optimal population parameter estimation. On the contrary, the\navailability of remote sensing (RS) data correlated with the forest inventory\nvariables is usually much higher. The combination of RS and the sampled field\nmeasurement data is often used for improving the forest inventory parameter\nestimation. In addition, it is also reasonable to study the utilization of RS\ndata in inventory sampling, which can further improve the estimation of forest\nvariables. In this study, we propose a data sampling method based on Bayesian\noptimization which uses RS data in forest inventory sample selection. The\npresented method applies the learned functional relationship between the RS and\ninventory data in new sampling decisions. We evaluate our method by conducting\nsimulated sampling experiments with both synthetic data and measured data from\nthe Aland region in Finland. The proposed method is benchmarked against two\nbaseline methods: simple random sampling and the local pivotal method. The\nresults of the simulated experiments show the best results in terms of MSE\nvalues for the proposed method when the functional relationship between RS and\ninventory data is correctly learned from the available training data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:05:16 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Pohjankukka", "Jonne", ""], ["Tuominen", "Sakari", ""], ["Heikkonen", "Jukka", ""]]}, {"id": "2009.08435", "submitter": "Youwei Liang", "authors": "Youwei Liang, Dong Huang", "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness", "comments": "15 pages, 4 figures; v5: corrected typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the Lipschitz properties of CNN are widely considered to be related to\nadversarial robustness, we theoretically characterize the $\\ell_1$ norm and\n$\\ell_\\infty$ norm of 2D multi-channel convolutional layers and provide\nefficient methods to compute the exact $\\ell_1$ norm and $\\ell_\\infty$ norm.\nBased on our theorem, we propose a novel regularization method termed norm\ndecay, which can effectively reduce the norms of convolutional layers and\nfully-connected layers. Experiments show that norm-regularization methods,\nincluding norm decay, weight decay, and singular value clipping, can improve\ngeneralization of CNNs. However, they can slightly hurt adversarial robustness.\nObserving this unexpected phenomenon, we compute the norms of layers in the\nCNNs trained with three different adversarial training frameworks and\nsurprisingly find that adversarially robust CNNs have comparable or even larger\nlayer norms than their non-adversarially robust counterparts. Furthermore, we\nprove that under a mild assumption, adversarially robust classifiers can be\nachieved, and can have an arbitrarily large Lipschitz constant. For this\nreason, enforcing small norms on CNN layers may be neither necessary nor\neffective in achieving adversarial robustness. The code is available at\nhttps://github.com/youweiliang/norm_robustness.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:33:50 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 06:28:59 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 07:34:27 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 02:58:32 GMT"}, {"version": "v5", "created": "Thu, 10 Jun 2021 06:21:01 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Liang", "Youwei", ""], ["Huang", "Dong", ""]]}, {"id": "2009.08449", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Matthias Schonlau", "title": "'Less Than One'-Shot Learning: Learning N Classes From M<N Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks require large training sets but suffer from high\ncomputational cost and long training times. Training on much smaller training\nsets while maintaining nearly the same accuracy would be very beneficial. In\nthe few-shot learning setting, a model must learn a new class given only a\nsmall number of samples from that class. One-shot learning is an extreme form\nof few-shot learning where the model must learn a new class from a single\nexample. We propose the `less than one'-shot learning task where models must\nlearn $N$ new classes given only $M<N$ examples and we show that this is\nachievable with the help of soft labels. We use a soft-label generalization of\nthe k-Nearest Neighbors classifier to explore the intricate decision landscapes\nthat can be created in the `less than one'-shot learning setting. We analyze\nthese decision landscapes to derive theoretical lower bounds for separating $N$\nclasses using $M<N$ soft-label samples and investigate the robustness of the\nresulting systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:55:29 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Schonlau", "Matthias", ""]]}, {"id": "2009.08451", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Arjit Jain, Pan Li, Ritesh Kumar, Bryan Hooi", "title": "MSTREAM: Fast Anomaly Detection in Multi-Aspect Streams", "comments": "The Web Conference (WWW), 2021", "journal-ref": null, "doi": "10.1145/3442381.3450023", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of entries in a multi-aspect data setting i.e., entries having\nmultiple dimensions, how can we detect anomalous activities in an unsupervised\nmanner? For example, in the intrusion detection setting, existing work seeks to\ndetect anomalous events or edges in dynamic graph streams, but this does not\nallow us to take into account additional attributes of each entry. Our work\naims to define a streaming multi-aspect data anomaly detection framework,\ntermed MSTREAM which can detect unusual group anomalies as they occur, in a\ndynamic manner. MSTREAM has the following properties: (a) it detects anomalies\nin multi-aspect data including both categorical and numeric attributes; (b) it\nis online, thus processing each record in constant time and constant memory;\n(c) it can capture the correlation between multiple aspects of the data.\nMSTREAM is evaluated over the KDDCUP99, CICIDS-DoS, UNSW-NB 15 and CICIDS-DDoS\ndatasets, and outperforms state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:16 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 14:11:06 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 23:42:21 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 14:49:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Jain", "Arjit", ""], ["Li", "Pan", ""], ["Kumar", "Ritesh", ""], ["Hooi", "Bryan", ""]]}, {"id": "2009.08452", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Rui Liu, Bryan Hooi, Minji Yoon, Kijung Shin and\n  Christos Faloutsos", "title": "Real-Time Anomaly Detection in Edge Streams", "comments": "Extended Journal Version of arXiv:1911.04464", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of graph edges from a dynamic graph, how can we assign anomaly\nscores to edges in an online manner, for the purpose of detecting unusual\nbehavior, using constant time and memory? Existing approaches aim to detect\nindividually surprising edges. In this work, we propose MIDAS, which focuses on\ndetecting microcluster anomalies, or suddenly arriving groups of suspiciously\nsimilar edges, such as lockstep behavior, including denial of service attacks\nin network traffic data. We further propose MIDAS-F, to solve the problem by\nwhich anomalies are incorporated into the algorithm's internal states, creating\na `poisoning' effect that can allow future anomalies to slip through\nundetected. MIDAS-F introduces two modifications: 1) We modify the anomaly\nscoring function, aiming to reduce the `poisoning' effect of newly arriving\nedges; 2) We introduce a conditional merge step, which updates the algorithm's\ndata structures after each time tick, but only if the anomaly score is below a\nthreshold value, also to reduce the `poisoning' effect. Experiments show that\nMIDAS-F has significantly higher accuracy than MIDAS. MIDAS has the following\nproperties: (a) it detects microcluster anomalies while providing theoretical\nguarantees about its false positive probability; (b) it is online, thus\nprocessing each edge in constant time and constant memory, and also processes\nthe data orders-of-magnitude faster than state-of-the-art approaches; (c) it\nprovides up to 62% higher ROC-AUC than state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:27 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 11:38:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Liu", "Rui", ""], ["Hooi", "Bryan", ""], ["Yoon", "Minji", ""], ["Shin", "Kijung", ""], ["Faloutsos", "Christos", ""]]}, {"id": "2009.08454", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Arjit Jain, Bryan Hooi", "title": "ExGAN: Adversarial Generation of Extreme Samples", "comments": "AAAI Conference on Artificial Intelligence (AAAI), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitigating the risk arising from extreme events is a fundamental goal with\nmany applications, such as the modelling of natural disasters, financial\ncrashes, epidemics, and many others. To manage this risk, a vital step is to be\nable to understand or generate a wide range of extreme scenarios. Existing\napproaches based on Generative Adversarial Networks (GANs) excel at generating\nrealistic samples, but seek to generate typical samples, rather than extreme\nsamples. Hence, in this work, we propose ExGAN, a GAN-based approach to\ngenerate realistic and extreme samples. To model the extremes of the training\ndistribution in a principled way, our work draws from Extreme Value Theory\n(EVT), a probabilistic approach for modelling the extreme tails of\ndistributions. For practical utility, our framework allows the user to specify\nboth the desired extremeness measure, as well as the desired extremeness\nprobability they wish to sample at. Experiments on real US Precipitation data\nshow that our method generates realistic samples, based on visual inspection\nand quantitative measures, in an efficient manner. Moreover, generating\nincreasingly extreme examples using ExGAN can be done in constant time (with\nrespect to the extremeness probability $\\tau$), as opposed to the\n$\\mathcal{O}(\\frac{1}{\\tau})$ time required by the baseline approach.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:36 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 11:17:31 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 15:49:39 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Jain", "Arjit", ""], ["Hooi", "Bryan", ""]]}, {"id": "2009.08457", "submitter": "Baihan Lin", "authors": "Baihan Lin", "title": "Online Semi-Supervised Learning in Contextual Bandits with Episodic\n  Reward", "comments": "Proceeding of AJCAI 2020. This article supersedes our work\n  arXiv:1802.00981 on contextual bandits in nonstationary setting, introduces a\n  new problem setting with episodically revealed reward, and provides a novel\n  solution by propagating pseudo-feedbacks to un-rewarded cases from\n  self-supervision. Also check out our speaker diarization application of this\n  algorithm at arXiv:2006.04376", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We considered a novel practical problem of online learning with episodically\nrevealed rewards, motivated by several real-world applications, where the\ncontexts are nonstationary over different episodes and the reward feedbacks are\nnot always available to the decision making agents. For this online\nsemi-supervised learning setting, we introduced Background Episodic Reward\nLinUCB (BerlinUCB), a solution that easily incorporates clustering as a\nself-supervision module to provide useful side information when rewards are not\nobserved. Our experiments on a variety of datasets, both in stationary and\nnonstationary environments of six different scenarios, demonstrated clear\nadvantages of the proposed approach over the standard contextual bandit.\nLastly, we introduced a relevant real-life example where this problem setting\nis especially useful.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 20:41:02 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 03:29:56 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lin", "Baihan", ""]]}, {"id": "2009.08496", "submitter": "Elchanan Solomon", "authors": "Elchanan Solomon, Alexander Wagner, Paul Bendich", "title": "A Fast and Robust Method for Global Topological Functional Optimization", "comments": "Added new experiments: one on robustness, the other a cell\n  segmentation task. Other parts of the paper were clarified by including more\n  background exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Topological statistics, in the form of persistence diagrams, are a class of\nshape descriptors that capture global structural information in data. The\nmapping from data structures to persistence diagrams is almost everywhere\ndifferentiable, allowing for topological gradients to be backpropagated to\nordinary gradients. However, as a method for optimizing a topological\nfunctional, this backpropagation method is expensive, unstable, and produces\nvery fragile optima. Our contribution is to introduce a novel backpropagation\nscheme that is significantly faster, more stable, and produces more robust\noptima. Moreover, this scheme can also be used to produce a stable\nvisualization of dots in a persistence diagram as a distribution over critical,\nand near-critical, simplices in the data structure.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:46:16 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:59:39 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 21:25:35 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Solomon", "Elchanan", ""], ["Wagner", "Alexander", ""], ["Bendich", "Paul", ""]]}, {"id": "2009.08541", "submitter": "Zidi Xiu", "authors": "Zidi Xiu, Chenyang Tao, Michael Gao, Connor Davis, Benjamin A.\n  Goldstein, Ricardo Henao", "title": "Variational Disentanglement for Rare Event Modeling", "comments": "Accepted to AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining the increasing availability and abundance of healthcare data and\nthe current advances in machine learning methods have created renewed\nopportunities to improve clinical decision support systems. However, in\nhealthcare risk prediction applications, the proportion of cases with the\ncondition (label) of interest is often very low relative to the available\nsample size. Though very prevalent in healthcare, such imbalanced\nclassification settings are also common and challenging in many other\nscenarios. So motivated, we propose a variational disentanglement approach to\nsemi-parametrically learn from rare events in heavily imbalanced classification\nproblems. Specifically, we leverage the imposed extreme-distribution behavior\non a latent space to extract information from low-prevalence events, and\ndevelop a robust prediction arm that joins the merits of the generalized\nadditive model and isotonic neural nets. Results on synthetic studies and\ndiverse real-world datasets, including mortality prediction on a COVID-19\ncohort, demonstrate that the proposed approach outperforms existing\nalternatives.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 21:35:36 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 02:29:41 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 23:13:43 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 20:28:29 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 14:50:43 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Xiu", "Zidi", ""], ["Tao", "Chenyang", ""], ["Gao", "Michael", ""], ["Davis", "Connor", ""], ["Goldstein", "Benjamin A.", ""], ["Henao", "Ricardo", ""]]}, {"id": "2009.08559", "submitter": "Abhinav Aggarwal", "authors": "Abhinav Aggarwal, Zekun Xu, Oluwaseyi Feyisetan, Nathanael Teissier", "title": "On Primes, Log-Loss Scores and (No) Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership Inference Attacks exploit the vulnerabilities of exposing models\ntrained on customer data to queries by an adversary. In a recently proposed\nimplementation of an auditing tool for measuring privacy leakage from sensitive\ndatasets, more refined aggregates like the Log-Loss scores are exposed for\nsimulating inference attacks as well as to assess the total privacy leakage\nbased on the adversary's predictions. In this paper, we prove that this\nadditional information enables the adversary to infer the membership of any\nnumber of datapoints with full accuracy in a single query, causing complete\nmembership privacy breach. Our approach obviates any attack model training or\naccess to side knowledge with the adversary. Moreover, our algorithms are\nagnostic to the model under attack and hence, enable perfect membership\ninference even for models that do not memorize or overfit. In particular, our\nobservations provide insight into the extent of information leakage from\nstatistical aggregates and how they can be exploited.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 23:35:12 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Aggarwal", "Abhinav", ""], ["Xu", "Zekun", ""], ["Feyisetan", "Oluwaseyi", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2009.08574", "submitter": "Adityanarayanan Radhakrishnan", "authors": "Adityanarayanan Radhakrishnan and Mikhail Belkin and Caroline Uhler", "title": "Linear Convergence and Implicit Regularization of Generalized Mirror\n  Descent with Time-Dependent Mirrors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following questions are fundamental to understanding the properties of\nover-parameterization in modern machine learning: (1) Under what conditions and\nat what rate does training converge to a global minimum? (2) What form of\nimplicit regularization occurs through training? While significant progress has\nbeen made in answering both of these questions for gradient descent, they have\nyet to be answered more completely for general optimization methods. In this\nwork, we establish sufficient conditions for linear convergence and obtain\napproximate implicit regularization results for generalized mirror descent\n(GMD), a generalization of mirror descent with a possibly time-dependent\nmirror. GMD subsumes popular first order optimization methods including\ngradient descent, mirror descent, and preconditioned gradient descent methods\nsuch as Adagrad. By using the Polyak-Lojasiewicz inequality, we first present a\nsimple analysis under which non-stochastic GMD converges linearly to a global\nminimum. We then present a novel, Taylor-series based analysis to establish\nsufficient conditions for linear convergence of stochastic GMD. As a corollary,\nour result establishes sufficient conditions and provides learning rates for\nlinear convergence of stochastic mirror descent and Adagrad. Lastly, we obtain\napproximate implicit regularization results for GMD by proving that GMD\nconverges to an interpolating solution that is approximately the closest\ninterpolating solution to the initialization in l2-norm in the dual space,\nthereby generalizing the result of Azizan, Lale, and Hassibi (2019) in the full\nbatch setting.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 01:05:14 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Radhakrishnan", "Adityanarayanan", ""], ["Belkin", "Mikhail", ""], ["Uhler", "Caroline", ""]]}, {"id": "2009.08576", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M. Roy, Michael\n  Carbin", "title": "Pruning Neural Networks at Initialization: Why are We Missing the Mark?", "comments": "Published in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has explored the possibility of pruning neural networks at\ninitialization. We assess proposals for doing so: SNIP (Lee et al., 2019),\nGraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude\npruning. Although these methods surpass the trivial baseline of random pruning,\nthey remain below the accuracy of magnitude pruning after training, and we\nendeavor to understand why. We show that, unlike pruning after training,\nrandomly shuffling the weights these methods prune within each layer or\nsampling new initial values preserves or improves accuracy. As such, the\nper-weight pruning decisions made by these methods can be replaced by a\nper-layer choice of the fraction of weights to prune. This property suggests\nbroader challenges with the underlying pruning heuristics, the desire to prune\nat initialization, or both.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 01:13:38 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 21:38:32 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Frankle", "Jonathan", ""], ["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""], ["Carbin", "Michael", ""]]}, {"id": "2009.08578", "submitter": "Rodolfo Lobo", "authors": "Rodolfo Anibal Lobo and Marcos Eduardo Valle", "title": "Ensemble of Binary Classifiers Combined Using Recurrent Correlation\n  Associative Memories", "comments": "14 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble method should cleverly combine a group of base classifiers to\nyield an improved classifier. The majority vote is an example of a methodology\nused to combine classifiers in an ensemble method. In this paper, we propose to\ncombine classifiers using an associative memory model. Precisely, we introduce\nensemble methods based on recurrent correlation associative memories (RCAMs)\nfor binary classification problems. We show that an RCAM-based ensemble\nclassifier can be viewed as a majority vote classifier whose weights depend on\nthe similarity between the base classifiers and the resulting ensemble method.\nMore precisely, the RCAM-based ensemble combines the classifiers using a\nrecurrent consult and vote scheme. Furthermore, computational experiments\nconfirm the potential application of the RCAM-based ensemble method for binary\nclassification problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 01:16:53 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lobo", "Rodolfo Anibal", ""], ["Valle", "Marcos Eduardo", ""]]}, {"id": "2009.08586", "submitter": "Ting-Han Fan", "authors": "Ting-Han Fan, Peter J. Ramadge", "title": "A Contraction Approach to Model-based Reinforcement Learning", "comments": "The 24th International Conference on Artificial Intelligence and\n  Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its experimental success, Model-based Reinforcement Learning still\nlacks a complete theoretical understanding. To this end, we analyze the error\nin the cumulative reward using a contraction approach. We consider both\nstochastic and deterministic state transitions for continuous (non-discrete)\nstate and action spaces. This approach doesn't require strong assumptions and\ncan recover the typical quadratic error to the horizon. We prove that branched\nrollouts can reduce this error and are essential for deterministic transitions\nto have a Bellman contraction. Our analysis of policy mismatch error also\napplies to Imitation Learning. In this case, we show that GAN-type learning has\nan advantage over Behavioral Cloning when its discriminator is well-trained.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:03:14 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 11:35:48 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Fan", "Ting-Han", ""], ["Ramadge", "Peter J.", ""]]}, {"id": "2009.08592", "submitter": "Ciaran Evans", "authors": "Ciaran Evans and Max G'Sell", "title": "Sequential changepoint detection for label shift in classification", "comments": "34 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifier predictions often rely on the assumption that new observations\ncome from the same distribution as training data. When the underlying\ndistribution changes, so does the optimal classifier rule, and predictions may\nno longer be valid. We consider the problem of detecting a change to the\noverall fraction of positive cases, known as label shift, in\nsequentially-observed binary classification data. We reduce this problem to the\nproblem of detecting a change in the one-dimensional classifier scores, which\nallows us to develop simple nonparametric sequential changepoint detection\nprocedures. Our procedures leverage classifier training data to estimate the\ndetection statistic, and converge to their parametric counterparts in the size\nof the training data. In simulations, we show that our method compares\nfavorably to other detection procedures in the label shift setting.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:26:46 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Evans", "Ciaran", ""], ["G'Sell", "Max", ""]]}, {"id": "2009.08606", "submitter": "Shuyan Wang", "authors": "Shuyan Wang", "title": "Causal Clustering for 1-Factor Measurement Models on Data with Various\n  Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tetrad constraint is a condition of which the satisfaction signals a rank\nreduction of a covariance submatrix and is used to design causal discovery\nalgorithms that detects the existence of latent (unmeasured) variables, such as\nFOFC. Initially such algorithms only work for cases where the measured and\nlatent variables are all Gaussian and have linear relations (Gaussian-Gaussian\nCase). It has been shown that a unidimentional latent variable model implies\ntetrad constraints when the measured and latent variables are all binary\n(Binary-Binary case). This paper proves that the tetrad constraint can also be\nentailed when the measured variables are of mixed data types and when the\nmeasured variables are discrete and the latent common causes are continuous,\nwhich implies that any clustering algorithm relying on this constraint can work\non those cases. Each case is shown with an example and a proof. The performance\nof FOFC on mixed data is shown by simulation studies and is compared with some\nalgorithms with similar functions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 03:15:14 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Shuyan", ""]]}, {"id": "2009.08607", "submitter": "Jiaqi Lv", "authors": "Jiaqi Lv, Tianran Wu, Chenglun Peng, Yunpeng Liu, Ning Xu, Xin Geng", "title": "Compact Learning for Multi-Label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) studies the problem where each instance is\nassociated with multiple relevant labels, which leads to the exponential growth\nof output space. MLC encourages a popular framework named label compression\n(LC) for capturing label dependency with dimension reduction. Nevertheless,\nmost existing LC methods failed to consider the influence of the feature space\nor misguided by original problematic features, so that may result in\nperformance degeneration. In this paper, we present a compact learning (CL)\nframework to embed the features and labels simultaneously and with mutual\nguidance. The proposal is a versatile concept, hence the embedding way is\narbitrary and independent of the subsequent learning process. Following its\nspirit, a simple yet effective implementation called compact multi-label\nlearning (CMLL) is proposed to learn a compact low-dimensional representation\nfor both spaces. CMLL maximizes the dependence between the embedded spaces of\nthe labels and features, and minimizes the loss of label space recovery\nconcurrently. Theoretically, we provide a general analysis for different\nembedding methods. Practically, we conduct extensive experiments to validate\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 03:19:14 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lv", "Jiaqi", ""], ["Wu", "Tianran", ""], ["Peng", "Chenglun", ""], ["Liu", "Yunpeng", ""], ["Xu", "Ning", ""], ["Geng", "Xin", ""]]}, {"id": "2009.08661", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Hirokazu Kameoka", "title": "X-DC: Explainable Deep Clustering based on Learnable Spectrogram\n  Templates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved substantial predictive performance\nin various speech processing tasks. Particularly, it has been shown that a\nmonaural speech separation task can be successfully solved with a DNN-based\nmethod called deep clustering (DC), which uses a DNN to describe the process of\nassigning a continuous vector to each time-frequency (TF) bin and measure how\nlikely each pair of TF bins is to be dominated by the same speaker. In DC, the\nDNN is trained so that the embedding vectors for the TF bins dominated by the\nsame speaker are forced to get close to each other. One concern regarding DC is\nthat the embedding process described by a DNN has a black-box structure, which\nis usually very hard to interpret. The potential weakness owing to the\nnon-interpretable black-box structure is that it lacks the flexibility of\naddressing the mismatch between training and test conditions (caused by\nreverberation, for instance). To overcome this limitation, in this paper, we\npropose the concept of explainable deep clustering (X-DC), whose network\narchitecture can be interpreted as a process of fitting learnable spectrogram\ntemplates to an input spectrogram followed by Wiener filtering. During\ntraining, the elements of the spectrogram templates and their activations are\nconstrained to be non-negative, which facilitates the sparsity of their values\nand thus improves interpretability. The main advantage of this framework is\nthat it naturally allows us to incorporate a model adaptation mechanism into\nthe network thanks to its physically interpretable structure. We experimentally\nshow that the proposed X-DC enables us to visualize and understand the clues\nfor the model to determine the embedding vectors while achieving speech\nseparation performance comparable to that of the original DC models.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 07:26:52 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 06:44:20 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 06:53:09 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Kameoka", "Hirokazu", ""]]}, {"id": "2009.08685", "submitter": "Trista Chen", "authors": "Yu-Sheng Lin, Hung Chang Lu, Yang-Bin Tsao, Yi-Min Chih, Wei-Chao\n  Chen, Shao-Yi Chien", "title": "GrateTile: Efficient Sparse Tensor Tiling for CNN Processing", "comments": "To be published at IEEE Workshop on Signal Processing System (SiPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose GrateTile, an efficient, hardwarefriendly data storage scheme for\nsparse CNN feature maps (activations). It divides data into uneven-sized\nsubtensors and, with small indexing overhead, stores them in a compressed yet\nrandomly accessible format. This design enables modern CNN accelerators to\nfetch and decompressed sub-tensors on-the-fly in a tiled processing manner.\nGrateTile is suitable for architectures that favor aligned, coalesced data\naccess, and only requires minimal changes to the overall architectural design.\nWe simulate GrateTile with state-of-the-art CNNs and show an average of 55%\nDRAM bandwidth reduction while using only 0.6% of feature map size for indexing\nstorage.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 08:31:41 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lin", "Yu-Sheng", ""], ["Lu", "Hung Chang", ""], ["Tsao", "Yang-Bin", ""], ["Chih", "Yi-Min", ""], ["Chen", "Wei-Chao", ""], ["Chien", "Shao-Yi", ""]]}, {"id": "2009.08697", "submitter": "Shangwei Guo", "authors": "Shangwei Guo, Tianwei Zhang, Han Qiu, Yi Zeng, Tao Xiang, and Yang Liu", "title": "Fine-tuning Is Not Enough: A Simple yet Effective Watermark Removal\n  Attack for DNN Models", "comments": "7 pages, 4 figures, accpeted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watermarking has become the tendency in protecting the intellectual property\nof DNN models. Recent works, from the adversary's perspective, attempted to\nsubvert watermarking mechanisms by designing watermark removal attacks.\nHowever, these attacks mainly adopted sophisticated fine-tuning techniques,\nwhich have certain fatal drawbacks or unrealistic assumptions. In this paper,\nwe propose a novel watermark removal attack from a different perspective.\nInstead of just fine-tuning the watermarked models, we design a simple yet\npowerful transformation algorithm by combining imperceptible pattern embedding\nand spatial-level transformations, which can effectively and blindly destroy\nthe memorization of watermarked models to the watermark samples. We also\nintroduce a lightweight fine-tuning strategy to preserve the model performance.\nOur solution requires much less resource or knowledge about the watermarking\nscheme than prior works. Extensive experimental results indicate that our\nattack can bypass state-of-the-art watermarking solutions with very high\nsuccess rates. Based on our attack, we propose watermark augmentation\ntechniques to enhance the robustness of existing watermarks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:14:54 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 06:23:29 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Guo", "Shangwei", ""], ["Zhang", "Tianwei", ""], ["Qiu", "Han", ""], ["Zeng", "Yi", ""], ["Xiang", "Tao", ""], ["Liu", "Yang", ""]]}, {"id": "2009.08716", "submitter": "Zhengjie Yang", "authors": "Zhengjie Yang, Wei Bao, Dong Yuan, Nguyen H. Tran, and Albert Y.\n  Zomaya", "title": "Federated Learning with Nesterov Accelerated Gradient Momentum Method", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a fast-developing technique that allows multiple\nworkers to train a global model based on a distributed dataset. Conventional FL\nemploys gradient descent algorithm, which may not be efficient enough. It is\nwell known that Nesterov Accelerated Gradient (NAG) is more advantageous in\ncentralized training environment, but it is not clear how to quantify the\nbenefits of NAG in FL so far. In this work, we focus on a version of FL based\non NAG (FedNAG) and provide a detailed convergence analysis. The result is\ncompared with conventional FL based on gradient descent. One interesting\nconclusion is that as long as the learning step size is sufficiently small,\nFedNAG outperforms FedAvg. Extensive experiments based on real-world datasets\nare conducted, verifying our conclusions and confirming the better convergence\nperformance of FedNAG.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:38:11 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Yang", "Zhengjie", ""], ["Bao", "Wei", ""], ["Yuan", "Dong", ""], ["Tran", "Nguyen H.", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "2009.08727", "submitter": "Yao Lei Xu", "authors": "Yao Lei Xu, Danilo P. Mandic", "title": "Recurrent Graph Tensor Networks: A Low-Complexity Framework for\n  Modelling High-Dimensional Multi-Way Sequence", "comments": "29th European Signal Processing Conference (EUSIPCO) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are among the most successful machine\nlearning models for sequence modelling, but tend to suffer from an exponential\nincrease in the number of parameters when dealing with large multidimensional\ndata. To this end, we develop a multi-linear graph filter framework for\napproximating the modelling of hidden states in RNNs, which is embedded in a\ntensor network architecture to improve modelling power and reduce parameter\ncomplexity, resulting in a novel Recurrent Graph Tensor Network (RGTN). The\nproposed framework is validated through several multi-way sequence modelling\ntasks and benchmarked against traditional RNNs. By virtue of the domain aware\ninformation processing of graph filters and the expressive power of tensor\nnetworks, we show that the proposed RGTN is capable of not only out-performing\nstandard RNNs, but also mitigating the Curse of Dimensionality associated with\ntraditional RNNs, demonstrating superior properties in terms of performance and\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 10:13:36 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 14:00:01 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 14:18:30 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 12:35:31 GMT"}, {"version": "v5", "created": "Tue, 11 May 2021 12:40:23 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Xu", "Yao Lei", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "2009.08739", "submitter": "Ruoxin Chen", "authors": "Ruoxin Chen, Jie Li, Chentao Wu, Bin Sheng, Ping Li", "title": "A Framework of Randomized Selection Based Certified Defenses Against\n  Data Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network classifiers are vulnerable to data poisoning attacks, as\nattackers can degrade or even manipulate their predictions thorough poisoning\nonly a few training samples. However, the robustness of heuristic defenses is\nhard to measure. Random selection based defenses can achieve certified\nrobustness by averaging the classifiers' predictions on the sub-datasets\nsampled from the training set. This paper proposes a framework of random\nselection based certified defenses against data poisoning attacks.\nSpecifically, we prove that the random selection schemes that satisfy certain\nconditions are robust against data poisoning attacks. We also derive the\nanalytical form of the certified radius for the qualified random selection\nschemes. The certified radius of bagging derived by our framework is tighter\nthan the previous work. Our framework allows users to improve robustness by\nleveraging prior knowledge about the training set and the poisoning model.\nGiven higher level of prior knowledge, we can achieve higher certified accuracy\nboth theoretically and practically. According to the experiments on three\nbenchmark datasets: MNIST 1/7, MNIST, and CIFAR-10, our method outperforms the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 10:38:12 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 09:33:36 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Chen", "Ruoxin", ""], ["Li", "Jie", ""], ["Wu", "Chentao", ""], ["Sheng", "Bin", ""], ["Li", "Ping", ""]]}, {"id": "2009.08801", "submitter": "Marco Anteghini", "authors": "Marco Anteghini, Jennifer D'Souza, Vitor A. P. Martins dos Santos,\n  S\\\"oren Auer", "title": "SciBERT-based Semantification of Bioassays in the Open Research\n  Knowledge Graph", "comments": "In proceedings of the '22nd International Conference on Knowledge\n  Engineering and Knowledge Management' 'Demo and Poster section'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a novel contribution to the problem of semantifying biological assays, in\nthis paper, we propose a neural-network-based approach to automatically\nsemantify, thereby structure, unstructured bioassay text descriptions.\nExperimental evaluations, to this end, show promise as the neural-based\nsemantification significantly outperforms a naive frequency-based baseline\napproach. Specifically, the neural method attains 72% F1 versus 47% F1 from the\nfrequency-based method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:36:35 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Anteghini", "Marco", ""], ["D'Souza", "Jennifer", ""], ["Santos", "Vitor A. P. Martins dos", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "2009.08835", "submitter": "David Schedl", "authors": "David C. Schedl and Indrajit Kurmi and Oliver Bimber", "title": "Search and Rescue with Airborne Optical Sectioning", "comments": "11 pages, 5 figures, 3 tables, Nature Machine Intelligence (under\n  review)", "journal-ref": null, "doi": "10.1038/s42256-020-00261-3", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that automated person detection under occlusion conditions can be\nsignificantly improved by combining multi-perspective images before\nclassification. Here, we employed image integration by Airborne Optical\nSectioning (AOS)---a synthetic aperture imaging technique that uses camera\ndrones to capture unstructured thermal light fields---to achieve this with a\nprecision/recall of 96/93%. Finding lost or injured people in dense forests is\nnot generally feasible with thermal recordings, but becomes practical with use\nof AOS integral images. Our findings lay the foundation for effective future\nsearch and rescue technologies that can be applied in combination with\nautonomous or manned aircraft. They can also be beneficial for other fields\nthat currently suffer from inaccurate classification of partially occluded\npeople, animals, or objects.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 13:40:19 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Schedl", "David C.", ""], ["Kurmi", "Indrajit", ""], ["Bimber", "Oliver", ""]]}, {"id": "2009.08848", "submitter": "Stefan Richter", "authors": "Nathawut Phandoidaen, Stefan Richter", "title": "Forecasting time series with encoder-decoder neural networks", "comments": "69 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider high-dimensional stationary processes where a new\nobservation is generated from a compressed version of past observations. The\nspecific evolution is modeled by an encoder-decoder structure. We estimate the\nevolution with an encoder-decoder neural network and give upper bounds for the\nexpected forecast error under specific structural and sparsity assumptions. The\nresults are shown separately for conditions either on the absolutely regular\nmixing coefficients or the functional dependence measure of the observed\nprocess. In a quantitative simulation we discuss the behavior of the network\nestimator under different model assumptions. We corroborate our theory by a\nreal data example where we consider forecasting temperature data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:07:38 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Phandoidaen", "Nathawut", ""], ["Richter", "Stefan", ""]]}, {"id": "2009.08868", "submitter": "Qi Zhao", "authors": "Qi Zhao, Zheng Zhao, Xiaoya Fan, Zhengwei Yuan, Qian Mao, Yudong Yao", "title": "Review of Machine-Learning Methods for RNA Secondary Structure\n  Prediction", "comments": "25 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Secondary structure plays an important role in determining the function of\nnon-coding RNAs. Hence, identifying RNA secondary structures is of great value\nto research. Computational prediction is a mainstream approach for predicting\nRNA secondary structure. Unfortunately, even though new methods have been\nproposed over the past 40 years, the performance of computational prediction\nmethods has stagnated in the last decade. Recently, with the increasing\navailability of RNA structure data, new methods based on machine-learning\ntechnologies, especially deep learning, have alleviated the issue. In this\nreview, we provide a comprehensive overview of RNA secondary structure\nprediction methods based on machine-learning technologies and a tabularized\nsummary of the most important methods in this field. The current pending issues\nin the field of RNA secondary structure prediction and future trends are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 03:17:15 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Zhao", "Qi", ""], ["Zhao", "Zheng", ""], ["Fan", "Xiaoya", ""], ["Yuan", "Zhengwei", ""], ["Mao", "Qian", ""], ["Yao", "Yudong", ""]]}, {"id": "2009.08869", "submitter": "Wajid Arshad Abbasi", "authors": "Wajid Arshad Abbasi, Syed Ali Abbas, Saiqa Andleeb", "title": "PANDA: Predicting the change in proteins binding affinity upon mutations\n  using sequence information", "comments": null, "journal-ref": "Journal of Bioinformatics and Computational Biology, 2021", "doi": "10.1142/S0219720021500153", "report-no": null, "categories": "q-bio.BM cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurately determining a change in protein binding affinity upon mutations is\nimportant for the discovery and design of novel therapeutics and to assist\nmutagenesis studies. Determination of change in binding affinity upon mutations\nrequires sophisticated, expensive, and time-consuming wet-lab experiments that\ncan be aided with computational methods. Most of the computational prediction\ntechniques require protein structures that limit their applicability to protein\ncomplexes with known structures. In this work, we explore the sequence-based\nprediction of change in protein binding affinity upon mutation. We have used\nprotein sequence information instead of protein structures along with machine\nlearning techniques to accurately predict the change in protein binding\naffinity upon mutation. Our proposed sequence-based novel change in protein\nbinding affinity predictor called PANDA gives better accuracy than existing\nmethods over the same validation set as well as on an external independent test\ndataset. On an external test dataset, our proposed method gives a maximum\nPearson correlation coefficient of 0.52 in comparison to the state-of-the-art\nexisting protein structure-based method called MutaBind which gives a maximum\nPearson correlation coefficient of 0.59. Our proposed protein sequence-based\nmethod, to predict a change in binding affinity upon mutations, has wide\napplicability and comparable performance in comparison to existing protein\nstructure-based methods. A cloud-based webserver implementation of PANDA and\nits python code is available at\nhttps://sites.google.com/view/wajidarshad/software and\nhttps://github.com/wajidarshad/panda.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:12:25 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Abbasi", "Wajid Arshad", ""], ["Abbas", "Syed Ali", ""], ["Andleeb", "Saiqa", ""]]}, {"id": "2009.08880", "submitter": "Jakob Struye", "authors": "Jakob Struye, Kevin Mets, Steven Latr\\'e", "title": "HTMRL: Biologically Plausible Reinforcement Learning with Hierarchical\n  Temporal Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building Reinforcement Learning (RL) algorithms which are able to adapt to\ncontinuously evolving tasks is an open research challenge. One technology that\nis known to inherently handle such non-stationary input patterns well is\nHierarchical Temporal Memory (HTM), a general and biologically plausible\ncomputational model for the human neocortex. As the RL paradigm is inspired by\nhuman learning, HTM is a natural framework for an RL algorithm supporting\nnon-stationary environments. In this paper, we present HTMRL, the first\nstrictly HTM-based RL algorithm. We empirically and statistically show that\nHTMRL scales to many states and actions, and demonstrate that HTM's ability for\nadapting to changing patterns extends to RL. Specifically, HTMRL performs well\non a 10-armed bandit after 750 steps, but only needs a third of that to adapt\nto the bandit suddenly shuffling its arms. HTMRL is the first iteration of a\nnovel RL approach, with the potential of extending to a capable algorithm for\nMeta-RL.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:05:17 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Struye", "Jakob", ""], ["Mets", "Kevin", ""], ["Latr\u00e9", "Steven", ""]]}, {"id": "2009.08886", "submitter": "Zixiang Ding", "authors": "Zixiang Ding, Yaran Chen, Nannan Li and Dongbin Zhao", "title": "BNAS-v2: Memory-efficient and Performance-collapse-prevented Broad\n  Neural Architecture Search", "comments": "12 pages, 11 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose BNAS-v2 to further improve the efficiency of NAS,\nembodying both superiorities of BCNN simultaneously. To mitigate the unfair\ntraining issue of BNAS, we employ continuous relaxation strategy to make each\nedge of cell in BCNN relevant to all candidate operations for\nover-parameterized BCNN construction. Moreover, the continuous relaxation\nstrategy relaxes the choice of a candidate operation as a softmax over all\npredefined operations. Consequently, BNAS-v2 employs the gradient-based\noptimization algorithm to simultaneously update every possible path of\nover-parameterized BCNN, rather than the single sampled one as BNAS. However,\ncontinuous relaxation leads to another issue named performance collapse, in\nwhich those weight-free operations are prone to be selected by the search\nstrategy. For this consequent issue, two solutions are given: 1) we propose\nConfident Learning Rate (CLR) that considers the confidence of gradient for\narchitecture weights update, increasing with the training time of\nover-parameterized BCNN; 2) we introduce the combination of partial channel\nconnections and edge normalization that also can improve the memory efficiency\nfurther. Moreover, we denote differentiable BNAS (i.e. BNAS with continuous\nrelaxation) as BNAS-D, BNAS-D with CLR as BNAS-v2-CLR, and partial-connected\nBNAS-D as BNAS-v2-PC. Experimental results on CIFAR-10 and ImageNet show that\n1) BNAS-v2 delivers state-of-the-art search efficiency on both CIFAR-10 (0.05\nGPU days that is 4x faster than BNAS) and ImageNet (0.19 GPU days); and 2) the\nproposed CLR is effective to alleviate the performance collapse issue in both\nBNAS-D and vanilla differentiable NAS framework.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:25:08 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 07:09:31 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 02:59:21 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 09:05:02 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Ding", "Zixiang", ""], ["Chen", "Yaran", ""], ["Li", "Nannan", ""], ["Zhao", "Dongbin", ""]]}, {"id": "2009.08900", "submitter": "Mehak Gupta", "authors": "Mehak Gupta, Rahmatollah Beheshti", "title": "Time-series Imputation and Prediction with Bi-Directional Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time-series data are used in many classification and regression\npredictive tasks, and recurrent models have been widely used for such tasks.\nMost common recurrent models assume that time-series data elements are of equal\nlength and the ordered observations are recorded at regular intervals. However,\nreal-world time-series data have neither a similar length nor a same number of\nobservations. They also have missing entries, which hinders the performance of\npredictive tasks. In this paper, we approach these issues by presenting a model\nfor the combined task of imputing and predicting values for the irregularly\nobserved and varying length time-series data with missing entries. Our proposed\nmodel (Bi-GAN) uses a bidirectional recurrent network in a generative\nadversarial setting. The generator is a bidirectional recurrent network that\nreceives actual incomplete data and imputes the missing values. The\ndiscriminator attempts to discriminate between the actual and the imputed\nvalues in the output of the generator. Our model learns how to impute missing\nelements in-between (imputation) or outside of the input time steps\n(prediction), hence working as an effective any-time prediction tool for\ntime-series data. Our method has three advantages to the state-of-the-art\nmethods in the field: (a) single model can be used for both imputation and\nprediction tasks; (b) it can perform prediction task for time-series of varying\nlength with missing data; (c) it does not require to know the observation and\nprediction time window during training which provides a flexible length of\nprediction window for both long-term and short-term predictions. We evaluate\nour model on two public datasets and on another large real-world electronic\nhealth records dataset to impute and predict body mass index (BMI) values in\nchildren and show its superior performance in both settings.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:47:51 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Gupta", "Mehak", ""], ["Beheshti", "Rahmatollah", ""]]}, {"id": "2009.08905", "submitter": "R\\'emy Garnier", "authors": "R\\'emy Garnier and Rapha\\\"el Langhendries", "title": "Deviation bound for non-causal machine learning", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concentration inequalities are widely used for analyzing machine learning\nalgorithms. However, current concentration inequalities cannot be applied to\nsome of the most popular deep neural networks, notably in natural language\nprocessing. This is mostly due to the non-causal nature of such involved data,\nin the sense that each data point depends on other neighbor data points. In\nthis paper, a framework for modeling non-causal random fields is provided and a\nHoeffding-type concentration inequality is obtained for this framework. The\nproof of this result relies on a local approximation of the non-causal random\nfield by a function of a finite number of i.i.d. random variables.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:57:59 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 16:55:42 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Garnier", "R\u00e9my", ""], ["Langhendries", "Rapha\u00ebl", ""]]}, {"id": "2009.08934", "submitter": "Serkan Kiranyaz", "authors": "Serkan Kiranyaz, Junaid Malik, Habib Ben Abdallah, Turker Ince,\n  Alexandros Iosifidis, Moncef Gabbouj", "title": "Exploiting Heterogeneity in Operational Neural Networks by Synaptic\n  Plasticity", "comments": "15 pages, 19 figures, journal manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed network model, Operational Neural Networks (ONNs), can\ngeneralize the conventional Convolutional Neural Networks (CNNs) that are\nhomogenous only with a linear neuron model. As a heterogenous network model,\nONNs are based on a generalized neuron model that can encapsulate any set of\nnon-linear operators to boost diversity and to learn highly complex and\nmulti-modal functions or spaces with minimal network complexity and training\ndata. However, the default search method to find optimal operators in ONNs, the\nso-called Greedy Iterative Search (GIS) method, usually takes several training\nsessions to find a single operator set per layer. This is not only\ncomputationally demanding, also the network heterogeneity is limited since the\nsame set of operators will then be used for all neurons in each layer. To\naddress this deficiency and exploit a superior level of heterogeneity, in this\nstudy the focus is drawn on searching the best-possible operator set(s) for the\nhidden neurons of the network based on the Synaptic Plasticity paradigm that\nposes the essential learning theory in biological neurons. During training,\neach operator set in the library can be evaluated by their synaptic plasticity\nlevel, ranked from the worst to the best, and an elite ONN can then be\nconfigured using the top ranked operator sets found at each hidden layer.\nExperimental results over highly challenging problems demonstrate that the\nelite ONNs even with few neurons and layers can achieve a superior learning\nperformance than GIS-based ONNs and as a result the performance gap over the\nCNNs further widens.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 19:03:23 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Kiranyaz", "Serkan", ""], ["Malik", "Junaid", ""], ["Abdallah", "Habib Ben", ""], ["Ince", "Turker", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2009.08947", "submitter": "Markus Viljanen", "authors": "Markus Viljanen, Jukka Vahlo, Aki Koponen, Tapio Pahikkala", "title": "Content Based Player and Game Interaction Model for Game Recommendation\n  in the Cold Start setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game recommendation is an important application of recommender systems.\nRecommendations are made possible by data sets of historical player and game\ninteractions, and sometimes the data sets include features that describe games\nor players. Collaborative filtering has been found to be the most accurate\npredictor of past interactions. However, it can only be applied to predict new\ninteractions for those games and players where a significant number of past\ninteractions are present. In other words, predictions for completely new games\nand players is not possible. In this paper, we use a survey data set of game\nlikes to present content based interaction models that generalize into new\ngames, new players, and both new games and players simultaneously. We find that\nthe models outperform collaborative filtering in these tasks, which makes them\nuseful for real world game recommendation. The content models also provide\ninterpretations of why certain games are liked by certain players for game\nanalytics purposes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:10:49 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Viljanen", "Markus", ""], ["Vahlo", "Jukka", ""], ["Koponen", "Aki", ""], ["Pahikkala", "Tapio", ""]]}, {"id": "2009.08950", "submitter": "Karthik Raja Kalaiselvi Bhaskar", "authors": "Karthik Raja Kalaiselvi Bhaskar, Deepa Kundur, Yuri Lawryshyn", "title": "Implicit Feedback Deep Collaborative Filtering Product Recommendation\n  System", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, several Collaborative Filtering (CF) approaches with latent\nvariable methods were studied using user-item interactions to capture important\nhidden variations of the sparse customer purchasing behaviours. The latent\nfactors are used to generalize the purchasing pattern of the customers and to\nprovide product recommendations. CF with Neural Collaborative Filtering(NCF)\nwas shown to produce the highest Normalized Discounted Cumulative Gain (NDCG)\nperformance on the real-world proprietary dataset provided by a large parts\nsupply company. Different hyperparameters were tested using Bayesian\nOptimization (BO) for applicability in the CF framework. External data sources\nlike click-data and metrics like Clickthrough Rate (CTR) were reviewed for\npotential extensions to the work presented. The work shown in this paper\nprovides techniques the Company can use to provide product recommendations to\nenhance revenues, attract new customers, and gain advantages over competitors.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:30:14 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 15:08:40 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Bhaskar", "Karthik Raja Kalaiselvi", ""], ["Kundur", "Deepa", ""], ["Lawryshyn", "Yuri", ""]]}, {"id": "2009.08952", "submitter": "Charles Dickens", "authors": "Charles Dickens, Rishika Singh, Lise Getoor", "title": "HyperFair: A Soft Approach to Integrating Fairness Criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are being employed across an increasingly diverse set of\ndomains that can potentially make a significant social and individual impact.\nFor this reason, considering fairness is a critical step in the design and\nevaluation of such systems. In this paper, we introduce HyperFair, a general\nframework for enforcing soft fairness constraints in a hybrid recommender\nsystem. HyperFair models integrate variations of fairness metrics as a\nregularization of a joint inference objective function. We implement our\napproach using probabilistic soft logic and show that it is particularly\nwell-suited for this task as it is expressive and structural constraints can be\nadded to the system in a concise and interpretable manner. We propose two ways\nto employ the methods we introduce: first as an extension of a probabilistic\nsoft logic recommender system template; second as a fair retrofitting technique\nthat can be used to improve the fairness of predictions from a black-box model.\nWe empirically validate our approach by implementing multiple HyperFair hybrid\nrecommenders and compare them to a state-of-the-art fair recommender. We also\nrun experiments showing the effectiveness of our methods for the task of\nretrofitting a black-box model and the trade-off between the amount of fairness\nenforced and the prediction performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 05:00:06 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Dickens", "Charles", ""], ["Singh", "Rishika", ""], ["Getoor", "Lise", ""]]}, {"id": "2009.08955", "submitter": "Rashidul Islam", "authors": "Rashidul Islam, Kamrun Naher Keya, Ziqian Zeng, Shimei Pan, James\n  Foulds", "title": "Neural Fair Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing proportion of human interactions are digitized on social media\nplatforms and subjected to algorithmic decision-making, and it has become\nincreasingly important to ensure fair treatment from these algorithms. In this\nwork, we investigate gender bias in collaborative-filtering recommender systems\ntrained on social media data. We develop neural fair collaborative filtering\n(NFCF), a practical framework for mitigating gender bias in recommending\nsensitive items (e.g. jobs, academic concentrations, or courses of study) using\na pre-training and fine-tuning approach to neural collaborative filtering,\naugmented with bias correction techniques. We show the utility of our methods\nfor gender de-biased career and college major recommendations on the MovieLens\ndataset and a Facebook dataset, respectively, and achieve better performance\nand fairer behavior than several state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 05:11:11 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Islam", "Rashidul", ""], ["Keya", "Kamrun Naher", ""], ["Zeng", "Ziqian", ""], ["Pan", "Shimei", ""], ["Foulds", "James", ""]]}, {"id": "2009.08956", "submitter": "Jiri Hron", "authors": "Jiri Hron and Karl Krauth and Michael I. Jordan and Niki Kilbertus", "title": "Exploration in two-stage recommender systems", "comments": "Published at the REVEAL 2020 workshop (RecSys 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-stage recommender systems are widely adopted in industry due to their\nscalability and maintainability. These systems produce recommendations in two\nsteps: (i) multiple nominators preselect a small number of items from a large\npool using cheap-to-compute item embeddings; (ii) with a richer set of\nfeatures, a ranker rearranges the nominated items and serves them to the user.\nA key challenge of this setup is that optimal performance of each stage in\nisolation does not imply optimal global performance. In response to this issue,\nMa et al. (2020) proposed a nominator training objective importance weighted by\nthe ranker's probability of recommending each item. In this work, we focus on\nthe complementary issue of exploration. Modeled as a contextual bandit problem,\nwe find LinUCB (a near optimal exploration strategy for single-stage systems)\nmay lead to linear regret when deployed in two-stage recommenders. We therefore\npropose a method of synchronising the exploration strategies between the ranker\nand the nominators. Our algorithm only relies on quantities already computed by\nstandard LinUCB at each stage and can be implemented in three lines of\nadditional code. We end by demonstrating the effectiveness of our algorithm\nexperimentally.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:52:51 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Hron", "Jiri", ""], ["Krauth", "Karl", ""], ["Jordan", "Michael I.", ""], ["Kilbertus", "Niki", ""]]}, {"id": "2009.08957", "submitter": "Sheng-Chieh Lin", "authors": "Sheng-Chieh Lin, Ting-Wei Lin, Jing-Kai Lou, Ming-Feng Tsai, Chuan-Ju\n  Wang", "title": "Personalized TV Recommendation: Fusing User Behavior and Preferences", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a two-stage ranking approach for recommending\nlinear TV programs. The proposed approach first leverages user viewing patterns\nregarding time and TV channels to identify potential candidates for\nrecommendation and then further leverages user preferences to rank these\ncandidates given textual information about programs. To evaluate the method, we\nconduct empirical studies on a real-world TV dataset, the results of which\ndemonstrate the superior performance of our model in terms of both\nrecommendation accuracy and time efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 16:05:53 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lin", "Sheng-Chieh", ""], ["Lin", "Ting-Wei", ""], ["Lou", "Jing-Kai", ""], ["Tsai", "Ming-Feng", ""], ["Wang", "Chuan-Ju", ""]]}, {"id": "2009.08962", "submitter": "Meimei Liu", "authors": "Meimei Liu, Hongxia Yang", "title": "DVE: Dynamic Variational Embeddings with Applications in Recommender\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding is a useful technique to project a high-dimensional feature into a\nlow-dimensional space, and it has many successful applications including link\nprediction, node classification and natural language processing. Current\napproaches mainly focus on static data, which usually lead to unsatisfactory\nperformance in applications involving large changes over time. How to\ndynamically characterize the variation of the embedded features is still\nlargely unexplored. In this paper, we introduce a dynamic variational embedding\n(DVE) approach for sequence-aware data based on recent advances in recurrent\nneural networks. DVE can model the node's intrinsic nature and temporal\nvariation explicitly and simultaneously, which are crucial for exploration. We\nfurther apply DVE to sequence-aware recommender systems, and develop an\nend-to-end neural architecture for link prediction.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 20:05:56 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Liu", "Meimei", ""], ["Yang", "Hongxia", ""]]}, {"id": "2009.08973", "submitter": "Lin Shao", "authors": "Lin Shao, Yifan You, Mengyuan Yan, Qingyun Sun, Jeannette Bohg", "title": "GRAC: Self-Guided and Self-Regularized Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) algorithms have successfully been\ndemonstrated on a range of challenging decision making and control tasks. One\ndominant component of recent deep reinforcement learning algorithms is the\ntarget network which mitigates the divergence when learning the Q function.\nHowever, target networks can slow down the learning process due to delayed\nfunction updates. Our main contribution in this work is a self-regularized\nTD-learning method to address divergence without requiring a target network.\nAdditionally, we propose a self-guided policy improvement method by combining\npolicy-gradient with zero-order optimization to search for actions associated\nwith higher Q-values in a broad neighborhood. This makes learning more robust\nto local noise in the Q function approximation and guides the updates of our\nactor network. Taken together, these components define GRAC, a novel\nself-guided and self-regularized actor critic algorithm. We evaluate GRAC on\nthe suite of OpenAI gym tasks, achieving or outperforming state of the art in\nevery environment tested.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 17:58:29 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 02:26:15 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shao", "Lin", ""], ["You", "Yifan", ""], ["Yan", "Mengyuan", ""], ["Sun", "Qingyun", ""], ["Bohg", "Jeannette", ""]]}, {"id": "2009.08978", "submitter": "Diego Antognini", "authors": "Milena Filipovic, Blagoj Mitrevski, Diego Antognini, Emma Lejal\n  Glaude, Boi Faltings, Claudiu Musat", "title": "Modeling Online Behavior in Recommender Systems: The Importance of\n  Temporal Context", "comments": "Under review. 8 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating online recommender system performance is notoriously difficult and\nthe discrepancy between the online and offline behaviors is typically not\naccounted for in offline evaluations. Recommender systems research tends to\nevaluate model performance on randomly sampled targets, yet the same systems\nare later used to predict user behavior sequentially from a fixed point in\ntime. This disparity permits weaknesses to go unnoticed until the model is\ndeployed in a production setting. We first demonstrate how omitting temporal\ncontext when evaluating recommender system performance leads to false\nconfidence. To overcome this, we propose an offline evaluation protocol\nmodeling the real-life use-case that simultaneously accounts for temporal\ncontext.\n  Next, we propose a training procedure to further embed the temporal context\nin existing models: we introduce it in a multi-objective approach to\ntraditionally time-unaware recommender systems. We confirm the advantage of\nadding a temporal objective via the proposed evaluation protocol. Finally, we\nvalidate that the Pareto Fronts obtained with the added objective dominate\nthose produced by state-of-the-art models that are only optimized for accuracy\non three real-world publicly available datasets. The results show that\nincluding our temporal objective can improve recall@20 by up to 20%.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:36:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Filipovic", "Milena", ""], ["Mitrevski", "Blagoj", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.09026", "submitter": "Jun Wu", "authors": "Yao Zhou and Jun Wu and Jingrui He", "title": "Robust Decentralized Learning for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized learning, data is distributed among local clients which\ncollaboratively train a shared prediction model using secure aggregation. To\npreserve the privacy of the clients, modern decentralized learning paradigms\nrequire each client to maintain a private local training data set and only\nupload their summarized model updates to the server. However, this can quickly\nlead to a degenerate model and collapse in performance when corrupted updates\n(e.g., adversarial manipulations) are aggregated at the server. In this work,\nwe present a robust decentralized learning framework, Decent_BVA, using\nbias-variance based adversarial training via asymmetrical communications\nbetween each client and the server. The experiments are conducted on neural\nnetworks with cross-entropy loss. Nevertheless, the proposed framework allows\nthe use of various classification loss functions (e.g., cross-entropy loss,\nmean squared error loss) where the gradients of the bias and variance are\ntractable to be estimated from local clients' models. In this case, any\ngradient-based adversarial training strategies could be used by taking the\nbias-variance oriented adversarial examples into consideration, e.g.,\nbias-variance based FGSM and PGD proposed in this paper. Experiments show that\nDecent_BVA is robust to the classical adversarial attacks when the level of\ncorruption is high while being competitive compared with conventional\ndecentralized learning in terms of the model's accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:58:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhou", "Yao", ""], ["Wu", "Jun", ""], ["He", "Jingrui", ""]]}, {"id": "2009.09028", "submitter": "Kapil Ahuja", "authors": "Aditya A. Shastri, Kapil Ahuja, Milind B. Ratnaparkhe, and Yann Busnel", "title": "Probabilistically Sampled and Spectrally Clustered Plant Genotypes using\n  Phenotypic Characteristics", "comments": "16 Pages, 3 Figures, and 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering genotypes based upon their phenotypic characteristics is used to\nobtain diverse sets of parents that are useful in their breeding programs. The\nHierarchical Clustering (HC) algorithm is the current standard in clustering of\nphenotypic data. This algorithm suffers from low accuracy and high\ncomputational complexity issues. To address the accuracy challenge, we propose\nthe use of Spectral Clustering (SC) algorithm. To make the algorithm\ncomputationally cheap, we propose using sampling, specifically, Pivotal\nSampling that is probability based. Since application of samplings to\nphenotypic data has not been explored much, for effective comparison, another\nsampling technique called Vector Quantization (VQ) is adapted for this data as\nwell. VQ has recently given promising results for genome data.\n  The novelty of our SC with Pivotal Sampling algorithm is in constructing the\ncrucial similarity matrix for the clustering algorithm and defining\nprobabilities for the sampling technique. Although our algorithm can be applied\nto any plant genotypes, we test it on the phenotypic data obtained from about\n2400 Soybean genotypes. SC with Pivotal Sampling achieves substantially more\naccuracy (in terms of Silhouette Values) than all the other proposed\ncompetitive clustering with sampling algorithms (i.e. SC with VQ, HC with\nPivotal Sampling, and HC with VQ). The complexities of our SC with Pivotal\nSampling algorithm and these three variants are almost same because of the\ninvolved sampling. In addition to this, SC with Pivotal Sampling outperforms\nthe standard HC algorithm in both accuracy and computational complexity. We\nexperimentally show that we are up to 45% more accurate than HC in terms of\nclustering accuracy. The computational complexity of our algorithm is more than\na magnitude lesser than HC.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:59:00 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Shastri", "Aditya A.", ""], ["Ahuja", "Kapil", ""], ["Ratnaparkhe", "Milind B.", ""], ["Busnel", "Yann", ""]]}, {"id": "2009.09031", "submitter": "YooJung Choi", "authors": "YooJung Choi, Meihua Dang, Guy Van den Broeck", "title": "Group Fairness by Probabilistic Modeling with Latent Fair Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems are increasingly being used to make impactful\ndecisions such as loan applications and criminal justice risk assessments, and\nas such, ensuring fairness of these systems is critical. This is often\nchallenging as the labels in the data are biased. This paper studies learning\nfair probability distributions from biased data by explicitly modeling a latent\nvariable that represents a hidden, unbiased label. In particular, we aim to\nachieve demographic parity by enforcing certain independencies in the learned\nmodel. We also show that group fairness guarantees are meaningful only if the\ndistribution used to provide those guarantees indeed captures the real-world\ndata. In order to closely model the data distribution, we employ probabilistic\ncircuits, an expressive and tractable probabilistic model, and propose an\nalgorithm to learn them from incomplete data. We evaluate our approach on a\nsynthetic dataset in which observed labels indeed come from fair labels but\nwith added bias, and demonstrate that the fair labels are successfully\nretrieved. Moreover, we show on real-world datasets that our approach not only\nis a better model than existing methods of how the data was generated but also\nachieves competitive accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:13:23 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 00:28:37 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Choi", "YooJung", ""], ["Dang", "Meihua", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2009.09036", "submitter": "Falco J. Bargagli Stoffi", "authors": "Kwonsang Lee, Falco J. Bargagli-Stoffi, Francesca Dominici", "title": "Causal Rule Ensemble: Interpretable Inference of Heterogeneous Treatment\n  Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social and health sciences, it is critically important to identify\nsubgroups of the study population where a treatment has a notably larger or\nsmaller causal effect compared to the population average. In recent years,\nthere have been many methodological developments for addressing heterogeneity\nof causal effects. A common approach is to estimate the conditional average\ntreatment effect (CATE) given a pre-specified set of covariates. However, this\napproach does not allow to discover new subgroups. Recent causal machine\nlearning (ML) approaches estimate the CATE at an individual level in presence\nof large number of observations and covariates with great accuracy.\nNevertheless, the bulk of these ML approaches do not provide an interpretable\ncharacterization of the heterogeneous subgroups. In this paper, we propose a\nnew Causal Rule Ensemble (CRE) method that: 1) discovers de novo subgroups with\nsignificantly heterogeneous treatment effects (causal rules); 2) ensures\ninterpretability of these subgroups because they are defined in terms of\ndecision rules; and 3) estimates the CATE for each of these newly discovered\nsubgroups with small bias and high statistical precision. We provide\ntheoretical results that guarantee consistency of the estimated causal effects\nfor the newly discovered causal rules. A nice feature of CRE is that it is\nagnostic to the choices of the ML algorithms that can be used to discover the\ncausal rules, and the estimation methods for the causal effects within the\ndiscovered causal rules. Via simulations, we show that the CRE method has\ncompetitive performance as compared to existing approaches while providing\nenhanced interpretability. We also introduce a new sensitivity analysis to\nunmeasured confounding bias. We apply the CRE method to discover subgroups that\nare more vulnerable to the causal effects of long-term exposure to air\npollution on mortality.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:28:57 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 13:18:06 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 20:28:40 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Lee", "Kwonsang", ""], ["Bargagli-Stoffi", "Falco J.", ""], ["Dominici", "Francesca", ""]]}, {"id": "2009.09043", "submitter": "Robert Moss", "authors": "Robert J. Moss", "title": "Cross-Entropy Method Variants for Optimization", "comments": "9 pages, 6 figures, code available at\n  https://github.com/mossr/CrossEntropyVariants.jl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cross-entropy (CE) method is a popular stochastic method for optimization\ndue to its simplicity and effectiveness. Designed for rare-event simulations\nwhere the probability of a target event occurring is relatively small, the\nCE-method relies on enough objective function calls to accurately estimate the\noptimal parameters of the underlying distribution. Certain objective functions\nmay be computationally expensive to evaluate, and the CE-method could\npotentially get stuck in local minima. This is compounded with the need to have\nan initial covariance wide enough to cover the design space of interest. We\nintroduce novel variants of the CE-method to address these concerns. To\nmitigate expensive function calls, during optimization we use every sample to\nbuild a surrogate model to approximate the objective function. The surrogate\nmodel augments the belief of the objective function with less expensive\nevaluations. We use a Gaussian process for our surrogate model to incorporate\nuncertainty in the predictions which is especially helpful when dealing with\nsparse data. To address local minima convergence, we use Gaussian mixture\nmodels to encourage exploration of the design space. We experiment with\nevaluation scheduling techniques to reallocate true objective function calls\nearlier in the optimization when the covariance is the largest. To test our\napproach, we created a parameterized test objective function with many local\nminima and a single global minimum. Our test function can be adjusted to\ncontrol the spread and distinction of the minima. Experiments were run to\nstress the cross-entropy method variants and results indicate that the\nsurrogate model-based approach reduces local minima convergence using the same\nnumber of function evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:51:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moss", "Robert J.", ""]]}, {"id": "2009.09051", "submitter": "Ian Fox", "authors": "Ian Fox, Joyce Lee, Rodica Pop-Busui, Jenna Wiens", "title": "Deep Reinforcement Learning for Closed-Loop Blood Glucose Control", "comments": "Accepted to MLHC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  People with type 1 diabetes (T1D) lack the ability to produce the insulin\ntheir bodies need. As a result, they must continually make decisions about how\nmuch insulin to self-administer to adequately control their blood glucose\nlevels. Longitudinal data streams captured from wearables, like continuous\nglucose monitors, can help these individuals manage their health, but currently\nthe majority of the decision burden remains on the user. To relieve this\nburden, researchers are working on closed-loop solutions that combine a\ncontinuous glucose monitor and an insulin pump with a control algorithm in an\n`artificial pancreas.' Such systems aim to estimate and deliver the appropriate\namount of insulin. Here, we develop reinforcement learning (RL) techniques for\nautomated blood glucose control. Through a series of experiments, we compare\nthe performance of different deep RL approaches to non-RL approaches. We\nhighlight the flexibility of RL approaches, demonstrating how they can adapt to\nnew individuals with little additional data. On over 2.1 million hours of data\nfrom 30 simulated patients, our RL approach outperforms baseline control\nalgorithms: leading to a decrease in median glycemic risk of nearly 50% from\n8.34 to 4.24 and a decrease in total time hypoglycemic of 99.8%, from 4,610\ndays to 6. Moreover, these approaches are able to adapt to predictable meal\ntimes (decreasing average risk by an additional 24% as meals increase in\npredictability). This work demonstrates the potential of deep RL to help people\nwith T1D manage their blood glucose levels without requiring expert knowledge.\nAll of our code is publicly available, allowing for replication and extension.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 20:15:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Fox", "Ian", ""], ["Lee", "Joyce", ""], ["Pop-Busui", "Rodica", ""], ["Wiens", "Jenna", ""]]}, {"id": "2009.09052", "submitter": "Giuseppe Vietri", "authors": "Giuseppe Vietri, Borja Balle, Akshay Krishnamurthy, Zhiwei Steven Wu", "title": "Private Reinforcement Learning with PAC and Regret Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by high-stakes decision-making domains like personalized medicine\nwhere user information is inherently sensitive, we design privacy preserving\nexploration policies for episodic reinforcement learning (RL). We first provide\na meaningful privacy formulation using the notion of joint differential privacy\n(JDP)--a strong variant of differential privacy for settings where each user\nreceives their own sets of output (e.g., policy recommendations). We then\ndevelop a private optimism-based learning algorithm that simultaneously\nachieves strong PAC and regret bounds, and enjoys a JDP guarantee. Our\nalgorithm only pays for a moderate privacy cost on exploration: in comparison\nto the non-private bounds, the privacy parameter only appears in lower-order\nterms. Finally, we present lower bounds on sample complexity and regret for\nreinforcement learning subject to JDP.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 20:18:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Vietri", "Giuseppe", ""], ["Balle", "Borja", ""], ["Krishnamurthy", "Akshay", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2009.09074", "submitter": "Xia Li", "authors": "Rachel Grotheer, Yihuan Huang, Pengyu Li, Elizaveta Rebrova, Deanna\n  Needell, Longxiu Huang, Alona Kryshchenko, Xia Li, Kyung Ha, Oleksandr\n  Kryshchenko", "title": "COVID-19 Literature Topic-Based Search via Hierarchical NMF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dataset of COVID-19-related scientific literature is compiled, combining\nthe articles from several online libraries and selecting those with open access\nand full text available. Then, hierarchical nonnegative matrix factorization is\nused to organize literature related to the novel coronavirus into a tree\nstructure that allows researchers to search for relevant literature based on\ndetected topics. We discover eight major latent topics and 52 granular\nsubtopics in the body of literature, related to vaccines, genetic structure and\nmodeling of the disease and patient studies, as well as related diseases and\nvirology. In order that our tool may help current researchers, an interactive\nwebsite is created that organizes available literature using this hierarchical\nstructure.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 05:45:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Grotheer", "Rachel", ""], ["Huang", "Yihuan", ""], ["Li", "Pengyu", ""], ["Rebrova", "Elizaveta", ""], ["Needell", "Deanna", ""], ["Huang", "Longxiu", ""], ["Kryshchenko", "Alona", ""], ["Li", "Xia", ""], ["Ha", "Kyung", ""], ["Kryshchenko", "Oleksandr", ""]]}, {"id": "2009.09078", "submitter": "Tharindu Bandaragoda", "authors": "Tharindu Bandaragoda", "title": "Beyond Social Media Analytics: Understanding Human Behaviour and Deep\n  Emotion using Self Structuring Incremental Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis develops a conceptual framework considering social data as\nrepresenting the surface layer of a hierarchy of human social behaviours, needs\nand cognition which is employed to transform social data into representations\nthat preserve social behaviours and their causalities. Based on this framework\ntwo platforms were built to capture insights from fast-paced and slow-paced\nsocial data. For fast-paced, a self-structuring and incremental learning\ntechnique was developed to automatically capture salient topics and\ncorresponding dynamics over time. An event detection technique was developed to\nautomatically monitor those identified topic pathways for significant\nfluctuations in social behaviours using multiple indicators such as volume and\nsentiment. This platform is demonstrated using two large datasets with over 1\nmillion tweets. The separated topic pathways were representative of the key\ntopics of each entity and coherent against topic coherence measures. Identified\nevents were validated against contemporary events reported in news. Secondly\nfor the slow-paced social data, a suite of new machine learning and natural\nlanguage processing techniques were developed to automatically capture\nself-disclosed information of the individuals such as demographics, emotions\nand timeline of personal events. This platform was trialled on a large text\ncorpus of over 4 million posts collected from online support groups. This was\nfurther extended to transform prostate cancer related online support group\ndiscussions into a multidimensional representation and investigated the\nself-disclosed quality of life of patients (and partners) against time,\ndemographics and clinical factors. The capabilities of this extended platform\nhave been demonstrated using a text corpus collected from 10 prostate cancer\nonline support groups comprising of 609,960 prostate cancer discussions and\n22,233 patients.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:53:26 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bandaragoda", "Tharindu", ""]]}, {"id": "2009.09087", "submitter": "Joshua Vendrow", "authors": "Joshua Vendrow, Jamie Haddock, Deanna Needell, and Lorraine Johnson", "title": "Feature Selection on Lyme Disease Patient Survey Data", "comments": "9 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lyme disease is a rapidly growing illness that remains poorly understood\nwithin the medical community. Critical questions about when and why patients\nrespond to treatment or stay ill, what kinds of treatments are effective, and\neven how to properly diagnose the disease remain largely unanswered. We\ninvestigate these questions by applying machine learning techniques to a large\nscale Lyme disease patient registry, MyLymeData, developed by the nonprofit\nLymeDisease.org. We apply various machine learning methods in order to measure\nthe effect of individual features in predicting participants' answers to the\nGlobal Rating of Change (GROC) survey questions that assess the self-reported\ndegree to which their condition improved, worsened, or remained unchanged\nfollowing antibiotic treatment. We use basic linear regression, support vector\nmachines, neural networks, entropy-based decision tree models, and $k$-nearest\nneighbors approaches. We first analyze the general performance of the model and\nthen identify the most important features for predicting participant answers to\nGROC. After we identify the \"key\" features, we separate them from the dataset\nand demonstrate the effectiveness of these features at identifying GROC. In\ndoing so, we highlight possible directions for future study both mathematically\nand clinically.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 22:35:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Vendrow", "Joshua", ""], ["Haddock", "Jamie", ""], ["Needell", "Deanna", ""], ["Johnson", "Lorraine", ""]]}, {"id": "2009.09092", "submitter": "Mucahit Cevik", "authors": "Ozan Ozyegen and Igor Ilic and Mucahit Cevik", "title": "Evaluation of Local Explanation Methods for Multivariate Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to interpret a machine learning model is a crucial task in many\napplications of machine learning. Specifically, local interpretability is\nimportant in determining why a model makes particular predictions. Despite the\nrecent focus on AI interpretability, there has been a lack of research in local\ninterpretability methods for time series forecasting while the few\ninterpretable methods that exist mainly focus on time series classification\ntasks. In this study, we propose two novel evaluation metrics for time series\nforecasting: Area Over the Perturbation Curve for Regression and Ablation\nPercentage Threshold. These two metrics can measure the local fidelity of local\nexplanation models. We extend the theoretical foundation to collect\nexperimental results on two popular datasets, \\textit{Rossmann sales} and\n\\textit{electricity}. Both metrics enable a comprehensive comparison of\nnumerous local explanation models and find which metrics are more sensitive.\nLastly, we provide heuristical reasoning for this analysis.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:15:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ozyegen", "Ozan", ""], ["Ilic", "Igor", ""], ["Cevik", "Mucahit", ""]]}, {"id": "2009.09110", "submitter": "Mucahit Cevik", "authors": "Igor Ilic and Berk Gorgulu and Mucahit Cevik and Mustafa Gokce\n  Baydogan", "title": "Explainable boosted linear regression for time series forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting involves collecting and analyzing past observations\nto develop a model to extrapolate such observations into the future.\nForecasting of future events is important in many fields to support decision\nmaking as it contributes to reducing the future uncertainty. We propose\nexplainable boosted linear regression (EBLR) algorithm for time series\nforecasting, which is an iterative method that starts with a base model, and\nexplains the model's errors through regression trees. At each iteration, the\npath leading to highest error is added as a new variable to the base model. In\nthis regard, our approach can be considered as an improvement over general time\nseries models since it enables incorporating nonlinear features by residuals\nexplanation. More importantly, use of the single rule that contributes to the\nerror most allows for interpretable results. The proposed approach extends to\nprobabilistic forecasting through generating prediction intervals based on the\nempirical error distribution. We conduct a detailed numerical study with EBLR\nand compare against various other approaches. We observe that EBLR\nsubstantially improves the base model performance through extracted features,\nand provide a comparable performance to other well established approaches. The\ninterpretability of the model predictions and high predictive accuracy of EBLR\nmakes it a promising method for time series forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 22:31:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ilic", "Igor", ""], ["Gorgulu", "Berk", ""], ["Cevik", "Mucahit", ""], ["Baydogan", "Mustafa Gokce", ""]]}, {"id": "2009.09111", "submitter": "Barinder Thind", "authors": "Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao", "title": "FuncNN: An R Package to Fit Deep Neural Networks Using Generalized Input\n  Spaces", "comments": "23 pages, 5 figures, submitted to JSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have excelled at regression and classification problems when\nthe input space consists of scalar variables. As a result of this proficiency,\nseveral popular packages have been developed that allow users to easily fit\nthese kinds of models. However, the methodology has excluded the use of\nfunctional covariates and to date, there exists no software that allows users\nto build deep learning models with this generalized input space. To the best of\nour knowledge, the functional neural network (FuncNN) library is the first such\npackage in any programming language; the library has been developed for R and\nis built on top of the keras architecture. Throughout this paper, several\nfunctions are introduced that provide users an avenue to easily build models,\ngenerate predictions, and run cross-validations. A summary of the underlying\nmethodology is also presented. The ultimate contribution is a package that\nprovides a set of general modelling and diagnostic tools for data problems in\nwhich there exist both functional and scalar covariates.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 22:32:29 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 04:41:36 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Thind", "Barinder", ""], ["Wu", "Sidi", ""], ["Groenewald", "Richard", ""], ["Cao", "Jiguo", ""]]}, {"id": "2009.09136", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Farhad Pourkamali-Anaraki, Mohammad Amin Hariri-Ardebili, Lydia\n  Morawiec", "title": "Kernel Ridge Regression Using Importance Sampling with Application to\n  Seismic Response Prediction", "comments": "Accepted for publication in IEEE International Conference on Machine\n  Learning and Applications (ICMLA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable kernel methods, including kernel ridge regression, often rely on\nlow-rank matrix approximations using the Nystrom method, which involves\nselecting landmark points from large data sets. The existing approaches to\nselecting landmarks are typically computationally demanding as they require\nmanipulating and performing computations with large matrices in the input or\nfeature space. In this paper, our contribution is twofold. The first\ncontribution is to propose a novel landmark selection method that promotes\ndiversity using an efficient two-step approach. Our landmark selection\ntechnique follows a coarse to fine strategy, where the first step computes\nimportance scores with a single pass over the whole data. The second step\nperforms K-means clustering on the constructed coreset to use the obtained\ncentroids as landmarks. Hence, the introduced method provides tunable\ntrade-offs between accuracy and efficiency. Our second contribution is to\ninvestigate the performance of several landmark selection techniques using a\nnovel application of kernel methods for predicting structural responses due to\nearthquake load and material uncertainties. Our experiments exhibit the merits\nof our proposed landmark selection scheme against baselines.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 01:44:56 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pourkamali-Anaraki", "Farhad", ""], ["Hariri-Ardebili", "Mohammad Amin", ""], ["Morawiec", "Lydia", ""]]}, {"id": "2009.09139", "submitter": "Jonathan Pilault", "authors": "Jonathan Pilault, Amine Elhattami, Christopher Pal", "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning\n  in NLP Using Fewer Parameters & Less Data", "comments": "ICLR 2021 (Reprint)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-Task Learning (MTL) networks have emerged as a promising method for\ntransferring learned knowledge across different tasks. However, MTL must deal\nwith challenges such as: overfitting to low resource tasks, catastrophic\nforgetting, and negative task transfer, or learning interference. Often, in\nNatural Language Processing (NLP), a separate model per task is needed to\nobtain the best performance. However, many fine-tuning approaches are both\nparameter inefficient, i.e., potentially involving one new model per task, and\nhighly susceptible to losing knowledge acquired during pretraining. We propose\na novel Transformer architecture consisting of a new conditional attention\nmechanism as well as a set of task-conditioned modules that facilitate weight\nsharing. Through this construction, we achieve more efficient parameter sharing\nand mitigate forgetting by keeping half of the weights of a pretrained model\nfixed. We also use a new multi-task data sampling strategy to mitigate the\nnegative effects of data imbalance across tasks. Using this approach, we are\nable to surpass single task fine-tuning methods while being parameter and data\nefficient (using around 66% of the data for weight updates). Compared to other\nBERT Large methods on GLUE, our 8-task model surpasses other Adapter methods by\n2.8% and our 24-task model outperforms by 0.7-1.0% models that use MTL and\nsingle task fine-tuning. We show that a larger variant of our single multi-task\nmodel approach performs competitively across 26 NLP tasks and yields\nstate-of-the-art results on a number of test and development sets. Our code is\npublicly available at https://github.com/CAMTL/CA-MTL.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 02:04:34 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 15:09:41 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Pilault", "Jonathan", ""], ["Elhattami", "Amine", ""], ["Pal", "Christopher", ""]]}, {"id": "2009.09153", "submitter": "David Krueger", "authors": "David Krueger, Tegan Maharaj, Jan Leike", "title": "Hidden Incentives for Auto-Induced Distributional Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions made by machine learning systems have increasing influence on the\nworld, yet it is common for machine learning algorithms to assume that no such\ninfluence exists. An example is the use of the i.i.d. assumption in content\nrecommendation. In fact, the (choice of) content displayed can change users'\nperceptions and preferences, or even drive them away, causing a shift in the\ndistribution of users. We introduce the term auto-induced distributional shift\n(ADS) to describe the phenomenon of an algorithm causing a change in the\ndistribution of its own inputs. Our goal is to ensure that machine learning\nsystems do not leverage ADS to increase performance when doing so could be\nundesirable. We demonstrate that changes to the learning algorithm, such as the\nintroduction of meta-learning, can cause hidden incentives for auto-induced\ndistributional shift (HI-ADS) to be revealed. To address this issue, we\nintroduce `unit tests' and a mitigation strategy for HI-ADS, as well as a toy\nenvironment for modelling real-world issues with HI-ADS in content\nrecommendation, where we demonstrate that strong meta-learners achieve gains in\nperformance via ADS. We show meta-learning and Q-learning both sometimes fail\nunit tests, but pass when using our mitigation strategy.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 03:31:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Krueger", "David", ""], ["Maharaj", "Tegan", ""], ["Leike", "Jan", ""]]}, {"id": "2009.09155", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Matthias Schonlau", "title": "SecDD: Efficient and Secure Method for Remotely Training Neural Networks", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage what are typically considered the worst qualities of deep\nlearning algorithms - high computational cost, requirement for large data, no\nexplainability, high dependence on hyper-parameter choice, overfitting, and\nvulnerability to adversarial perturbations - in order to create a method for\nthe secure and efficient training of remotely deployed neural networks over\nunsecured channels.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 03:37:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Schonlau", "Matthias", ""]]}, {"id": "2009.09161", "submitter": "Chenguang Zhang", "authors": "Chenguang Zhang and Yuexian Hou and Dawei Song and Liangzhu Ge and\n  Yaoshuai Yao", "title": "Label-Based Diversity Measure Among Hidden Units of Deep Neural\n  Networks: A Regularization Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the deep structure guarantees the powerful expressivity of deep\nnetworks (DNNs), it also triggers serious overfitting problem. To improve the\ngeneralization capacity of DNNs, many strategies were developed to improve the\ndiversity among hidden units. However, most of these strategies are empirical\nand heuristic in absence of either a theoretical derivation of the diversity\nmeasure or a clear connection from the diversity to the generalization\ncapacity. In this paper, from an information theoretic perspective, we\nintroduce a new definition of redundancy to describe the diversity of hidden\nunits under supervised learning settings by formalizing the effect of hidden\nlayers on the generalization capacity as the mutual information. We prove an\nopposite relationship existing between the defined redundancy and the\ngeneralization capacity, i.e., the decrease of redundancy generally improving\nthe generalization capacity. The experiments show that the DNNs using the\nredundancy as the regularizer can effectively reduce the overfitting and\ndecrease the generalization error, which well supports above points.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 04:27:44 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 12:32:54 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Zhang", "Chenguang", ""], ["Hou", "Yuexian", ""], ["Song", "Dawei", ""], ["Ge", "Liangzhu", ""], ["Yao", "Yaoshuai", ""]]}, {"id": "2009.09171", "submitter": "Kohei Numata", "authors": "Kohei Numata and Kenichi Tanaka", "title": "Stochastic Threshold Model Trees: A Tree-Based Ensemble Method for\n  Dealing with Extrapolation", "comments": "Code is available at\n  https://github.com/funatsu-lab/Stochastic-Threshold-Model-Trees", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the field of chemistry, there have been many attempts to predict the\nproperties of unknown compounds from statistical models constructed using\nmachine learning. In an area where many known compounds are present (the\ninterpolation area), an accurate model can be constructed. In contrast, data in\nareas where there are no known compounds (the extrapolation area) are generally\ndifficult to predict. However, in the development of new materials, it is\ndesirable to search this extrapolation area and discover compounds with\nunprecedented physical properties. In this paper, we propose Stochastic\nThreshold Model Trees (STMT), an extrapolation method that reflects the trend\nof the data, while maintaining the accuracy of conventional interpolation\nmethods. The behavior of STMT is confirmed through experiments using both\nartificial and real data. In the case of the real data, although there is no\nsignificant overall improvement in accuracy, there is one compound for which\nthe prediction accuracy is notably improved, suggesting that STMT reflects the\ndata trends in the extrapolation area. We believe that the proposed method will\ncontribute to more efficient searches in situations such as new material\ndevelopment.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 05:48:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Numata", "Kohei", ""], ["Tanaka", "Kenichi", ""]]}, {"id": "2009.09176", "submitter": "Yan Zeng", "authors": "Yan Zeng, Shohei Shimizu, Ruichu Cai, Feng Xie, Michio Yamamoto,\n  Zhifeng Hao", "title": "Causal Discovery with Multi-Domain LiNGAM for Latent Factors", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering causal structures among latent factors from observed data is a\nparticularly challenging problem. Despite some efforts for this problem,\nexisting methods focus on the single-domain data only. In this paper, we\npropose Multi-Domain Linear Non-Gaussian Acyclic Models for Latent Factors\n(MD-LiNA), where the causal structure among latent factors of interest is\nshared for all domains, and we provide its identification results. The model\nenriches the causal representation for multi-domain data. We propose an\nintegrated two-phase algorithm to estimate the model. In particular, we first\nlocate the latent factors and estimate the factor loading matrix. Then to\nuncover the causal structure among shared latent factors of interest, we derive\na score function based on the characterization of independence relations\nbetween external influences and the dependence relations between multi-domain\nlatent factors and latent factors of interest. We show that the proposed method\nprovides locally consistent estimators. Experimental results on both synthetic\nand real-world data demonstrate the efficacy and robustness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 06:44:03 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 13:36:41 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zeng", "Yan", ""], ["Shimizu", "Shohei", ""], ["Cai", "Ruichu", ""], ["Xie", "Feng", ""], ["Yamamoto", "Michio", ""], ["Hao", "Zhifeng", ""]]}, {"id": "2009.09187", "submitter": "Matthias Karlbauer", "authors": "Matthias Karlbauer, Sebastian Otte, Hendrik P.A. Lensch, Thomas\n  Scholten, Volker Wulfmeyer, and Martin V. Butz", "title": "Inferring, Predicting, and Denoising Causal Wave Dynamics", "comments": "As accepted by the 29th International Conference on Artificial Neural\n  Networks (ICANN20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel DISTributed Artificial neural Network Architecture (DISTANA) is a\ngenerative, recurrent graph convolution neural network. It implements a grid or\nmesh of locally parameterizable laterally connected network modules. DISTANA is\nspecifically designed to identify the causality behind spatially distributed,\nnon-linear dynamical processes. We show that DISTANA is very well-suited to\ndenoise data streams, given that re-occurring patterns are observed,\nsignificantly outperforming alternative approaches, such as temporal\nconvolution networks and ConvLSTMs, on a complex spatial wave propagation\nbenchmark. It produces stable and accurate closed-loop predictions even over\nhundreds of time steps. Moreover, it is able to effectively filter noise -- an\nability that can be improved further by applying denoising autoencoder\nprinciples or by actively tuning latent neural state activities\nretrospectively. Results confirm that DISTANA is ready to model real-world\nspatio-temporal dynamics such as brain imaging, supply networks, water flow, or\nsoil and weather data patterns.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 08:33:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Karlbauer", "Matthias", ""], ["Otte", "Sebastian", ""], ["Lensch", "Hendrik P. A.", ""], ["Scholten", "Thomas", ""], ["Wulfmeyer", "Volker", ""], ["Butz", "Martin V.", ""]]}, {"id": "2009.09206", "submitter": "Ayush Mangal", "authors": "Ayush Mangal, Jitesh Jain, Keerat Kaur Guliani, Omkar Bhalerao", "title": "DEAP Cache: Deep Eviction Admission and Prefetching for Cache", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches for learning policies to improve caching, target just one\nout of the prefetching, admission and eviction processes. In contrast, we\npropose an end to end pipeline to learn all three policies using machine\nlearning. We also take inspiration from the success of pretraining on large\ncorpora to learn specialized embeddings for the task. We model prefetching as a\nsequence prediction task based on past misses. Following previous works\nsuggesting that frequency and recency are the two orthogonal fundamental\nattributes for caching, we use an online reinforcement learning technique to\nlearn the optimal policy distribution between two orthogonal eviction\nstrategies based on them. While previous approaches used the past as an\nindicator of the future, we instead explicitly model the future frequency and\nrecency in a multi-task fashion with prefetching, leveraging the abilities of\ndeep networks to capture futuristic trends and use them for learning eviction\nand admission. We also model the distribution of the data in an online fashion\nusing Kernel Density Estimation in our approach, to deal with the problem of\ncaching non-stationary data. We present our approach as a \"proof of concept\" of\nlearning all three components of cache strategies using machine learning and\nleave improving practical deployment for future work.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 10:23:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mangal", "Ayush", ""], ["Jain", "Jitesh", ""], ["Guliani", "Keerat Kaur", ""], ["Bhalerao", "Omkar", ""]]}, {"id": "2009.09217", "submitter": "Luca Martino", "authors": "Luca Martino, Jesse Read", "title": "A Joint introduction to Gaussian Processes and Relevance Vector Machines\n  with Connections to Kalman filtering and other Kernel Smoothers", "comments": null, "journal-ref": "Information Fusion, Volume 74, Pages 17-38, 2021", "doi": "10.1016/j.inffus.2021.03.002", "report-no": null, "categories": "cs.LG cs.AI cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressive power of Bayesian kernel-based methods has led them to become\nan important tool across many different facets of artificial intelligence, and\nuseful to a plethora of modern application domains, providing both power and\ninterpretability via uncertainty analysis. This article introduces and\ndiscusses two methods which straddle the areas of probabilistic Bayesian\nschemes and kernel methods for regression: Gaussian Processes and Relevance\nVector Machines. Our focus is on developing a common framework with which to\nview these methods, via intermediate methods a probabilistic version of the\nwell-known kernel ridge regression, and drawing connections among them, via\ndual formulations, and discussion of their application in the context of major\ntasks: regression, smoothing, interpolation, and filtering. Overall, we provide\nunderstanding of the mathematical concepts behind these models, and we\nsummarize and discuss in depth different interpretations and highlight the\nrelationship to other methods, such as linear kernel smoothers, Kalman\nfiltering and Fourier approximations. Throughout, we provide numerous figures\nto promote understanding, and we make numerous recommendations to\npractitioners. Benefits and drawbacks of the different techniques are\nhighlighted. To our knowledge, this is the most in-depth study of its kind to\ndate focused on these two methods, and will be relevant to theoretical\nunderstanding and practitioners throughout the domains of data-science, signal\nprocessing, machine learning, and artificial intelligence in general.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 12:22:41 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 20:03:15 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 17:02:30 GMT"}, {"version": "v4", "created": "Sun, 11 Jul 2021 19:28:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Martino", "Luca", ""], ["Read", "Jesse", ""]]}, {"id": "2009.09230", "submitter": "Xiaosa Zhao", "authors": "Xiaosa Zhao, Kunpeng Liu, Wei Fan, Lu Jiang, Xiaowei Zhao, Minghao\n  Yin, and Yanjie Fu", "title": "Simplifying Reinforced Feature Selection via Restructured Choice\n  Strategy of Single Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection aims to select a subset of features to optimize the\nperformances of downstream predictive tasks. Recently, multi-agent reinforced\nfeature selection (MARFS) has been introduced to automate feature selection, by\ncreating agents for each feature to select or deselect corresponding features.\nAlthough MARFS enjoys the automation of the selection process, MARFS suffers\nfrom not just the data complexity in terms of contents and dimensionality, but\nalso the exponentially-increasing computational costs with regard to the number\nof agents. The raised concern leads to a new research question: Can we simplify\nthe selection process of agents under reinforcement learning context so as to\nimprove the efficiency and costs of feature selection? To address the question,\nwe develop a single-agent reinforced feature selection approach integrated with\nrestructured choice strategy. Specifically, the restructured choice strategy\nincludes: 1) we exploit only one single agent to handle the selection task of\nmultiple features, instead of using multiple agents. 2) we develop a scanning\nmethod to empower the single agent to make multiple selection/deselection\ndecisions in each round of scanning. 3) we exploit the relevance to predictive\nlabels of features to prioritize the scanning orders of the agent for multiple\nfeatures. 4) we propose a convolutional auto-encoder algorithm, integrated with\nthe encoded index information of features, to improve state representation. 5)\nwe design a reward scheme that take into account both prediction accuracy and\nfeature redundancy to facilitate the exploration process. Finally, we present\nextensive experimental results to demonstrate the efficiency and effectiveness\nof the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 13:41:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Xiaosa", ""], ["Liu", "Kunpeng", ""], ["Fan", "Wei", ""], ["Jiang", "Lu", ""], ["Zhao", "Xiaowei", ""], ["Yin", "Minghao", ""], ["Fu", "Yanjie", ""]]}, {"id": "2009.09249", "submitter": "Hakan G\\\"okcesu", "authors": "Kaan Gokcesu, Hakan Gokcesu", "title": "Recursive Experts: An Efficient Optimal Mixture of Learning Systems in\n  Dynamic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential learning systems are used in a wide variety of problems from\ndecision making to optimization, where they provide a 'belief' (opinion) to\nnature, and then update this belief based on the feedback (result) to minimize\n(or maximize) some cost or loss (conversely, utility or gain). The goal is to\nreach an objective by exploiting the temporal relation inherent to the nature's\nfeedback (state). By exploiting this relation, specific learning systems can be\ndesigned that perform asymptotically optimal for various applications. However,\nif the framework of the problem is not stationary, i.e., the nature's state\nsometimes changes arbitrarily, the past cumulative belief revision done by the\nsystem may become useless and the system may fail if it lacks adaptivity. While\nthis adaptivity can be directly implemented in specific cases (e.g., convex\noptimization), it is mostly not straightforward for general learning tasks. To\nthis end, we propose an efficient optimal mixture framework for general\nsequential learning systems, which we call the recursive experts for dynamic\nenvironments. For this purpose, we design hyper-experts that incorporate the\nlearning systems at our disposal and recursively merge in a specific way to\nachieve minimax optimal regret bounds up to constant factors. The\nmultiplicative increases in computational complexity from the initial system to\nour adaptive system are only logarithmic-in-time factors.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 15:02:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Gokcesu", "Kaan", ""], ["Gokcesu", "Hakan", ""]]}, {"id": "2009.09259", "submitter": "Shengjun Pan", "authors": "Shengjun Pan, Brendan Kitts, Tian Zhou, Hao He, Bharatbhushan Shetty,\n  Aaron Flores, Djordje Gligorijevic, Junwei Pan, Tingyu Mao, San Gultekin and\n  Jianlong Zhang", "title": "Bid Shading by Win-Rate Estimation and Surplus Maximization", "comments": "AdKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new win-rate based bid shading algorithm (WR) that\ndoes not rely on the minimum-bid-to-win feedback from a Sell-Side Platform\n(SSP). The method uses a modified logistic regression to predict the profit\nfrom each possible shaded bid price. The function form allows fast maximization\nat run-time, a key requirement for Real-Time Bidding (RTB) systems. We report\nproduction results from this method along with several other algorithms. We\nfound that bid shading, in general, can deliver significant value to\nadvertisers, reducing price per impression to about 55% of the unshaded cost.\nFurther, the particular approach described in this paper captures 7% more\nprofit for advertisers, than do benchmark methods of just bidding the most\nprobable winning price. We also report 4.3% higher surplus than an industry\nSell-Side Platform shading service. Furthermore, we observed 3% - 7% lower\neCPM, eCPC and eCPA when the algorithm was integrated with budget controllers.\nWe attribute the gains above as being mainly due to the explicit maximization\nof the surplus function, and note that other algorithms can take advantage of\nthis same approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 15:46:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pan", "Shengjun", ""], ["Kitts", "Brendan", ""], ["Zhou", "Tian", ""], ["He", "Hao", ""], ["Shetty", "Bharatbhushan", ""], ["Flores", "Aaron", ""], ["Gligorijevic", "Djordje", ""], ["Pan", "Junwei", ""], ["Mao", "Tingyu", ""], ["Gultekin", "San", ""], ["Zhang", "Jianlong", ""]]}, {"id": "2009.09271", "submitter": "Negar Foroutan", "authors": "Negar Foroutan Eghlidi and Martin Jaggi", "title": "Sparse Communication for Training Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronous stochastic gradient descent (SGD) is the most common method used\nfor distributed training of deep learning models. In this algorithm, each\nworker shares its local gradients with others and updates the parameters using\nthe average gradients of all workers. Although distributed training reduces the\ncomputation time, the communication overhead associated with the gradient\nexchange forms a scalability bottleneck for the algorithm. There are many\ncompression techniques proposed to reduce the number of gradients that needs to\nbe communicated. However, compressing the gradients introduces yet another\noverhead to the problem. In this work, we study several compression schemes and\nidentify how three key parameters affect the performance. We also provide a set\nof insights on how to increase performance and introduce a simple\nsparsification scheme, random-block sparsification, that reduces communication\nwhile keeping the performance close to standard SGD.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 17:28:11 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Eghlidi", "Negar Foroutan", ""], ["Jaggi", "Martin", ""]]}, {"id": "2009.09283", "submitter": "Kang Liu", "authors": "Kang Liu, Benjamin Tan, Siddharth Garg", "title": "Subverting Privacy-Preserving GANs: Hiding Secrets in Sanitized Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unprecedented data collection and sharing have exacerbated privacy concerns\nand led to increasing interest in privacy-preserving tools that remove\nsensitive attributes from images while maintaining useful information for other\ntasks. Currently, state-of-the-art approaches use privacy-preserving generative\nadversarial networks (PP-GANs) for this purpose, for instance, to enable\nreliable facial expression recognition without leaking users' identity.\nHowever, PP-GANs do not offer formal proofs of privacy and instead rely on\nexperimentally measuring information leakage using classification accuracy on\nthe sensitive attributes of deep learning (DL)-based discriminators. In this\nwork, we question the rigor of such checks by subverting existing\nprivacy-preserving GANs for facial expression recognition. We show that it is\npossible to hide the sensitive identification data in the sanitized output\nimages of such PP-GANs for later extraction, which can even allow for\nreconstruction of the entire input images, while satisfying privacy checks. We\ndemonstrate our approach via a PP-GAN-based architecture and provide\nqualitative and quantitative evaluations using two public datasets. Our\nexperimental results raise fundamental questions about the need for more\nrigorous privacy checks of PP-GANs, and we provide insights into the social\nimpact of these.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:02:17 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Liu", "Kang", ""], ["Tan", "Benjamin", ""], ["Garg", "Siddharth", ""]]}, {"id": "2009.09304", "submitter": "Nikita Zhivotovskiy", "authors": "Tomas Va\\v{s}kevi\\v{c}ius and Nikita Zhivotovskiy", "title": "Suboptimality of Constrained Least Squares and Improvements via\n  Non-Linear Predictors", "comments": "37 pages, extended discussion, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of predicting as well as the best linear predictor in a\nbounded Euclidean ball with respect to the squared loss. When only boundedness\nof the data generating distribution is assumed, we establish that the least\nsquares estimator constrained to a bounded Euclidean ball does not attain the\nclassical $O(d/n)$ excess risk rate, where $d$ is the dimension of the\ncovariates and $n$ is the number of samples. In particular, we construct a\nbounded distribution such that the constrained least squares estimator incurs\nan excess risk of order $\\Omega(d^{3/2}/n)$ hence refuting a recent conjecture\nof Ohad Shamir [JMLR 2015]. In contrast, we observe that non-linear predictors\ncan achieve the optimal rate $O(d/n)$ with no assumptions on the distribution\nof the covariates. We discuss additional distributional assumptions sufficient\nto guarantee an $O(d/n)$ excess risk rate for the least squares estimator.\nAmong them are certain moment equivalence assumptions often used in the robust\nstatistics literature. While such assumptions are central in the analysis of\nunbounded and heavy-tailed settings, our work indicates that in some cases,\nthey also rule out unfavorable bounded distributions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 21:39:46 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 16:24:01 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Va\u0161kevi\u010dius", "Tomas", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2009.09318", "submitter": "Anian Ruoss", "authors": "Anian Ruoss, Maximilian Baader, Mislav Balunovi\\'c, Martin Vechev", "title": "Efficient Certification of Spatial Robustness", "comments": "Conference Paper at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has exposed the vulnerability of computer vision models to vector\nfield attacks. Due to the widespread usage of such models in safety-critical\napplications, it is crucial to quantify their robustness against such spatial\ntransformations. However, existing work only provides empirical robustness\nquantification against vector field deformations via adversarial attacks, which\nlack provable guarantees. In this work, we propose novel convex relaxations,\nenabling us, for the first time, to provide a certificate of robustness against\nvector field transformations. Our relaxations are model-agnostic and can be\nleveraged by a wide range of neural network verifiers. Experiments on various\nnetwork architectures and different datasets demonstrate the effectiveness and\nscalability of our method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 23:09:11 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:24:32 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ruoss", "Anian", ""], ["Baader", "Maximilian", ""], ["Balunovi\u0107", "Mislav", ""], ["Vechev", "Martin", ""]]}, {"id": "2009.09321", "submitter": "Vincent Lostanlen", "authors": "Christopher Ick and Vincent Lostanlen", "title": "Learning a Lie Algebra from Unlabeled Data Pairs", "comments": "2 pages, 1 figure. Presented at the first DeepMath conference, New\n  York City, NY, USA, November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep convolutional networks (convnets) show a remarkable ability to learn\ndisentangled representations. In recent years, the generalization of deep\nlearning to Lie groups beyond rigid motion in $\\mathbb{R}^n$ has allowed to\nbuild convnets over datasets with non-trivial symmetries, such as patterns over\nthe surface of a sphere. However, one limitation of this approach is the need\nto explicitly define the Lie group underlying the desired invariance property\nbefore training the convnet. Whereas rotations on the sphere have a well-known\nsymmetry group ($\\mathrm{SO}(3)$), the same cannot be said of many real-world\nfactors of variability. For example, the disentanglement of pitch, intensity\ndynamics, and playing technique remains a challenging task in music information\nretrieval.\n  This article proposes a machine learning method to discover a nonlinear\ntransformation of the space $\\mathbb{R}^n$ which maps a collection of\n$n$-dimensional vectors $(\\boldsymbol{x}_i)_i$ onto a collection of target\nvectors $(\\boldsymbol{y}_i)_i$. The key idea is to approximate every target\n$\\boldsymbol{y}_i$ by a matrix--vector product of the form\n$\\boldsymbol{\\widetilde{y}}_i = \\boldsymbol{\\phi}(t_i) \\boldsymbol{x}_i$, where\nthe matrix $\\boldsymbol{\\phi}(t_i)$ belongs to a one-parameter subgroup of\n$\\mathrm{GL}_n (\\mathbb{R})$. Crucially, the value of the parameter $t_i \\in\n\\mathbb{R}$ may change between data pairs $(\\boldsymbol{x}_i,\n\\boldsymbol{y}_i)$ and does not need to be known in advance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 23:23:52 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 02:08:00 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 09:29:36 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ick", "Christopher", ""], ["Lostanlen", "Vincent", ""]]}, {"id": "2009.09358", "submitter": "Egor Klevak", "authors": "Egor Klevak and Sangdi Lin and Andy Martin and Ondrej Linda and Eric\n  Ringger", "title": "Out-Of-Bag Anomaly Detection", "comments": "13 pages, 4 figures, KDD 2020 TrueFact Workshop: Making a Credible\n  Web for Tomorrow", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data anomalies are ubiquitous in real world datasets, and can have an adverse\nimpact on machine learning (ML) systems, such as automated home valuation.\nDetecting anomalies could make ML applications more responsible and\ntrustworthy. However, the lack of labels for anomalies and the complex nature\nof real-world datasets make anomaly detection a challenging unsupervised\nlearning problem. In this paper, we propose a novel model-based anomaly\ndetection method, that we call Out-of- Bag anomaly detection, which handles\nmulti-dimensional datasets consisting of numerical and categorical features.\nThe proposed method decomposes the unsupervised problem into the training of a\nset of ensemble models. Out-of-Bag estimates are leveraged to derive an\neffective measure for anomaly detection. We not only demonstrate the\nstate-of-the-art performance of our method through comprehensive experiments on\nbenchmark datasets, but also show our model can improve the accuracy and\nreliability of an ML system as data pre-processing step via a case study on\nhome valuation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:01:52 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Klevak", "Egor", ""], ["Lin", "Sangdi", ""], ["Martin", "Andy", ""], ["Linda", "Ondrej", ""], ["Ringger", "Eric", ""]]}, {"id": "2009.09364", "submitter": "Bang An", "authors": "Bang An, Jie Lyu, Zhenyi Wang, Chunyuan Li, Changwei Hu, Fei Tan,\n  Ruiyi Zhang, Yifan Hu, Changyou Chen", "title": "Repulsive Attention: Rethinking Multi-head Attention as Bayesian\n  Inference", "comments": "accepted by EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural attention mechanism plays an important role in many natural\nlanguage processing applications. In particular, the use of multi-head\nattention extends single-head attention by allowing a model to jointly attend\ninformation from different perspectives. Without explicit constraining,\nhowever, multi-head attention may suffer from attention collapse, an issue that\nmakes different heads extract similar attentive features, thus limiting the\nmodel's representation power. In this paper, for the first time, we provide a\nnovel understanding of multi-head attention from a Bayesian perspective. Based\non the recently developed particle-optimization sampling techniques, we propose\na non-parametric approach that explicitly improves the repulsiveness in\nmulti-head attention and consequently strengthens model's expressiveness.\nRemarkably, our Bayesian interpretation provides theoretical inspirations on\nthe not-well-understood questions: why and how one uses multi-head attention.\nExtensive experiments on various attention models and applications demonstrate\nthat the proposed repulsive attention can improve the learned feature\ndiversity, leading to more informative representations with consistent\nperformance improvement on various tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:32:23 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:22:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["An", "Bang", ""], ["Lyu", "Jie", ""], ["Wang", "Zhenyi", ""], ["Li", "Chunyuan", ""], ["Hu", "Changwei", ""], ["Tan", "Fei", ""], ["Zhang", "Ruiyi", ""], ["Hu", "Yifan", ""], ["Chen", "Changyou", ""]]}, {"id": "2009.09382", "submitter": "Lukasz Korycki", "authors": "{\\L}ukasz Korycki and Bartosz Krawczyk", "title": "Instance exploitation for learning temporary concepts from sparsely\n  labeled drifting data streams", "comments": "35 pages, 17 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning from streaming data sources becomes more and more popular\ndue to the increasing number of online tools and systems. Dealing with dynamic\nand everlasting problems poses new challenges for which traditional batch-based\noffline algorithms turn out to be insufficient in terms of computational time\nand predictive performance. One of the most crucial limitations is that we\ncannot assume having access to a finite and complete data set - we always have\nto be ready for new data that may complement our model. This poses a critical\nproblem of providing labels for potentially unbounded streams. In the real\nworld, we are forced to deal with very strict budget limitations, therefore, we\nwill most likely face the scarcity of annotated instances, which are essential\nin supervised learning. In our work, we emphasize this problem and propose a\nnovel instance exploitation technique. We show that when: (i) data is\ncharacterized by temporary non-stationary concepts, and (ii) there are very few\nlabels spanned across a long time horizon, it is actually better to risk\noverfitting and adapt models more aggressively by exploiting the only labeled\ninstances we have, instead of sticking to a standard learning mode and\nsuffering from severe underfitting. We present different strategies and\nconfigurations for our methods, as well as an ensemble algorithm that attempts\nto maintain a sweet spot between risky and normal adaptation. Finally, we\nconduct a complex in-depth comparative analysis of our methods, using\nstate-of-the-art streaming algorithms relevant to the given problem.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 08:11:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Korycki", "\u0141ukasz", ""], ["Krawczyk", "Bartosz", ""]]}, {"id": "2009.09386", "submitter": "Yunxia Lin", "authors": "Yunxia Lin, Songcan Chen", "title": "Convex Subspace Clustering by Adaptive Block Diagonal Representation", "comments": "13 pages, 11 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering is a class of extensively studied clustering methods and\nthe spectral-type approaches are its important subclass whose key first step is\nto learn a coefficient matrix with block diagonal structure. To realize this\nstep, sparse subspace clustering (SSC), low rank representation (LRR) and block\ndiagonal representation (BDR) were successively proposed and have become the\nstate-of-the-arts (SOTAs). Among them, the former two minimize their convex\nobjectives by imposing sparsity and low rankness on the coefficient matrix\nrespectively, but so-desired block diagonality cannot neccesarily be guaranteed\npractically while the latter designs a block diagonal matrix induced\nregularizer but sacrifices convexity. For solving this dilemma, inspired by\nConvex Biclustering, in this paper, we propose a simple yet efficient\nspectral-type subspace clustering method named Adaptive Block Diagonal\nRepresentation (ABDR) which strives to pursue so-desired block diagonality as\nBDR by coercively fusing the columns/rows of the coefficient matrix via a\nspecially designed convex regularizer, consequently, ABDR naturally enjoys\ntheir merits and can adaptively form more desired block diagonality than the\nSOTAs without needing to prefix the number of blocks as done in BDR. Finally,\nexperimental results on synthetic and real benchmarks demonstrate the\nsuperiority of ABDR.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 08:31:43 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 13:10:47 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lin", "Yunxia", ""], ["Chen", "Songcan", ""]]}, {"id": "2009.09431", "submitter": "Goffredo Chirco", "authors": "Goffredo Chirco, Luigi Malag\\`o, Giovanni Pistone", "title": "Lagrangian and Hamiltonian Mechanics for Probabilities on the\n  Statistical Manifold", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT hep-th math.IT math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an Information-Geometric formulation of Classical Mechanics on the\nRiemannian manifold of probability distributions, which is an affine manifold\nendowed with a dually-flat connection. In a non-parametric formalism, we\nconsider the full set of positive probability functions on a finite sample\nspace, and we provide a specific expression for the tangent and cotangent\nspaces over the statistical manifold, in terms of a Hilbert bundle structure\nthat we call the Statistical Bundle. In this setting, we compute velocities and\naccelerations of a one-dimensional statistical model using the canonical dual\npair of parallel transports and define a coherent formalism for Lagrangian and\nHamiltonian mechanics on the bundle. Finally, in a series of examples, we show\nhow our formalism provides a consistent framework for accelerated natural\ngradient dynamics on the probability simplex, paving the way for direct\napplications in optimization, game theory and neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:03:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chirco", "Goffredo", ""], ["Malag\u00f2", "Luigi", ""], ["Pistone", "Giovanni", ""]]}, {"id": "2009.09439", "submitter": "Hlynur Dav{\\i}{\\dh} Hlynsson", "authors": "Hlynur Dav\\'i{\\dh} Hlynsson, Merlin Sch\\\"uler, Robin Schiewer, Tobias\n  Glasmachers, Laurenz Wiskott", "title": "Latent Representation Prediction Networks", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deeply-learned planning methods are often based on learning representations\nthat are optimized for unrelated tasks. For example, they might be trained on\nreconstructing the environment. These representations are then combined with\npredictor functions for simulating rollouts to navigate the environment. We\nfind this principle of learning representations unsatisfying and propose to\nlearn them such that they are directly optimized for the task at hand: to be\nmaximally predictable for the predictor function. This results in\nrepresentations that are by design optimal for the downstream task of planning,\nwhere the learned predictor function is used as a forward model.\n  To this end, we propose a new way of jointly learning this representation\nalong with the prediction function, a system we dub Latent Representation\nPrediction Network (LARP). The prediction function is used as a forward model\nfor search on a graph in a viewpoint-matching task and the representation\nlearned to maximize predictability is found to outperform a pre-trained\nrepresentation. Our approach is shown to be more sample-efficient than standard\nreinforcement learning methods and our learned representation transfers\nsuccessfully to dissimilar objects.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:26:03 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 13:42:06 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hlynsson", "Hlynur Dav\u00ed\u00f0", ""], ["Sch\u00fcler", "Merlin", ""], ["Schiewer", "Robin", ""], ["Glasmachers", "Tobias", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "2009.09463", "submitter": "Yue Zhao", "authors": "Zheng Li, Yue Zhao, Nicola Botta, Cezar Ionescu, Xiyang Hu", "title": "COPOD: Copula-Based Outlier Detection", "comments": "Proceedings of the 2020 International Conference on Data Mining\n  (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection refers to the identification of rare items that are deviant\nfrom the general data distribution. Existing approaches suffer from high\ncomputational complexity, low predictive capability, and limited\ninterpretability. As a remedy, we present a novel outlier detection algorithm\ncalled COPOD, which is inspired by copulas for modeling multivariate data\ndistribution. COPOD first constructs an empirical copula, and then uses it to\npredict tail probabilities of each given data point to determine its level of\n\"extremeness\". Intuitively, we think of this as calculating an anomalous\np-value. This makes COPOD both parameter-free, highly interpretable, and\ncomputationally efficient. In this work, we make three key contributions, 1)\npropose a novel, parameter-free outlier detection algorithm with both great\nperformance and interpretability, 2) perform extensive experiments on 30\nbenchmark datasets to show that COPOD outperforms in most cases and is also one\nof the fastest algorithms, and 3) release an easy-to-use Python implementation\nfor reproducibility.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 16:06:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Zheng", ""], ["Zhao", "Yue", ""], ["Botta", "Nicola", ""], ["Ionescu", "Cezar", ""], ["Hu", "Xiyang", ""]]}, {"id": "2009.09467", "submitter": "Rohit Jena", "authors": "Rohit Jena, Siddharth Agrawal, Katia Sycara", "title": "Addressing reward bias in Adversarial Imitation Learning with neutral\n  reward functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Imitation Learning suffers from the fundamental\nproblem of reward bias stemming from the choice of reward functions used in the\nalgorithm. Different types of biases also affect different types of\nenvironments - which are broadly divided into survival and task-based\nenvironments. We provide a theoretical sketch of why existing reward functions\nwould fail in imitation learning scenarios in task based environments with\nmultiple terminal states. We also propose a new reward function for GAIL which\noutperforms existing GAIL methods on task based environments with single and\nmultiple terminal states and effectively overcomes both survival and\ntermination bias.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 16:24:10 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jena", "Rohit", ""], ["Agrawal", "Siddharth", ""], ["Sycara", "Katia", ""]]}, {"id": "2009.09471", "submitter": "Yue Zhao", "authors": "Zheng Li, Yue Zhao, Jialin Fu", "title": "SYNC: A Copula based Framework for Generating Synthetic Data from\n  Aggregated Sources", "comments": "Proceedings of the 2020 IEEE International Conference on Data Mining\n  Workshops (ICDMW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A synthetic dataset is a data object that is generated programmatically, and\nit may be valuable to creating a single dataset from multiple sources when\ndirect collection is difficult or costly. Although it is a fundamental step for\nmany data science tasks, an efficient and standard framework is absent. In this\npaper, we study a specific synthetic data generation task called downscaling, a\nprocedure to infer high-resolution, harder-to-collect information (e.g.,\nindividual level records) from many low-resolution, easy-to-collect sources,\nand propose a multi-stage framework called SYNC (Synthetic Data Generation via\nGaussian Copula). For given low-resolution datasets, the central idea of SYNC\nis to fit Gaussian copula models to each of the low-resolution datasets in\norder to correctly capture dependencies and marginal distributions, and then\nsample from the fitted models to obtain the desired high-resolution subsets.\nPredictive models are then used to merge sampled subsets into one, and finally,\nsampled datasets are scaled according to low-resolution marginal constraints.\nWe make four key contributions in this work: 1) propose a novel framework for\ngenerating individual level data from aggregated data sources by combining\nstate-of-the-art machine learning and statistical techniques, 2) perform\nsimulation studies to validate SYNC's performance as a synthetic data\ngeneration algorithm, 3) demonstrate its value as a feature engineering tool,\nas well as an alternative to data collection in situations where gathering is\ndifficult through two real-world datasets, 4) release an easy-to-use framework\nimplementation for reproducibility and scalability at the production level that\neasily incorporates new data.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 16:36:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Zheng", ""], ["Zhao", "Yue", ""], ["Fu", "Jialin", ""]]}, {"id": "2009.09496", "submitter": "Nidhi Kaushik Vyas", "authors": "Nidhi Vyas, Shreyas Saxena, Thomas Voice", "title": "Learning Soft Labels via Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-hot labels do not represent soft decision boundaries among concepts, and\nhence, models trained on them are prone to overfitting. Using soft labels as\ntargets provide regularization, but different soft labels might be optimal at\ndifferent stages of optimization. Also, training with fixed labels in the\npresence of noisy annotations leads to worse generalization. To address these\nlimitations, we propose a framework, where we treat the labels as learnable\nparameters, and optimize them along with model parameters. The learned labels\ncontinuously adapt themselves to the model's state, thereby providing dynamic\nregularization. When applied to the task of supervised image-classification,\nour method leads to consistent gains across different datasets and\narchitectures. For instance, dynamically learned labels improve ResNet18 by\n2.1% on CIFAR100. When applied to dataset containing noisy labels, the learned\nlabels correct the annotation mistakes, and improves over state-of-the-art by a\nsignificant margin. Finally, we show that learned labels capture semantic\nrelationship between classes, and thereby improve teacher models for the\ndownstream task of distillation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 18:42:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Vyas", "Nidhi", ""], ["Saxena", "Shreyas", ""], ["Voice", "Thomas", ""]]}, {"id": "2009.09497", "submitter": "Lukasz Korycki", "authors": "{\\L}ukasz Korycki and Bartosz Krawczyk", "title": "Adversarial Concept Drift Detection under Poisoning Attacks for Robust\n  Data Stream Mining", "comments": "42 pages, 13 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous learning from streaming data is among the most challenging topics\nin the contemporary machine learning. In this domain, learning algorithms must\nnot only be able to handle massive volumes of rapidly arriving data, but also\nadapt themselves to potential emerging changes. The phenomenon of the evolving\nnature of data streams is known as concept drift. While there is a plethora of\nmethods designed for detecting its occurrence, all of them assume that the\ndrift is connected with underlying changes in the source of data. However, one\nmust consider the possibility of a malicious injection of false data that\nsimulates a concept drift. This adversarial setting assumes a poisoning attack\nthat may be conducted in order to damage the underlying classification system\nby forcing adaptation to false data. Existing drift detectors are not capable\nof differentiating between real and adversarial concept drift. In this paper,\nwe propose a framework for robust concept drift detection in the presence of\nadversarial and poisoning attacks. We introduce the taxonomy for two types of\nadversarial concept drifts, as well as a robust trainable drift detector. It is\nbased on the augmented Restricted Boltzmann Machine with improved gradient\ncomputation and energy function. We also introduce Relative Loss of Robustness\n- a novel measure for evaluating the performance of concept drift detectors\nunder poisoning attacks. Extensive computational experiments, conducted on both\nfully and sparsely labeled data streams, prove the high robustness and efficacy\nof the proposed drift detection framework in adversarial scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 18:46:31 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Korycki", "\u0141ukasz", ""], ["Krawczyk", "Bartosz", ""]]}, {"id": "2009.09521", "submitter": "Yashesh Dhebar", "authors": "Yashesh Dhebar, Kalyanmoy Deb, Subramanya Nageshrao, Ling Zhu and\n  Dimitar Filev", "title": "Towards Interpretable-AI Policies Induction using Evolutionary Nonlinear\n  Decision Trees for Discrete Action Systems", "comments": "main paper: 12 pages (pages 1-12), Supplementary Document: 5 pages\n  (from pages 13-17). Video link: https://youtu.be/DByYWTQ6X3E", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box AI induction methods such as deep reinforcement learning (DRL) are\nincreasingly being used to find optimal policies for a given control task.\nAlthough policies represented using a black-box AI are capable of efficiently\nexecuting the underlying control task and achieving optimal closed-loop\nperformance, the developed control rules are often complex and neither\ninterpretable nor explainable. In this paper, we use a recently proposed\nnonlinear decision-tree (NLDT) approach to find a hierarchical set of control\nrules in an attempt to maximize the open-loop performance for approximating and\nexplaining the pre-trained black-box DRL (oracle) agent using the labelled\nstate-action dataset. Recent advances in nonlinear optimization approaches\nusing evolutionary computation facilitates finding a hierarchical set of\nnonlinear control rules as a function of state variables using a\ncomputationally fast bilevel optimization procedure at each node of the\nproposed NLDT. Additionally, we propose a re-optimization procedure for\nenhancing closed-loop performance of an already derived NLDT. We evaluate our\nproposed methodologies (open and closed-loop NLDTs) on different control\nproblems having multiple discrete actions. In all these problems our proposed\napproach is able to find relatively simple and interpretable rules involving\none to four non-linear terms per rule, while simultaneously achieving on par\nclosed-loop performance when compared to a trained black-box DRL agent. A\npost-processing approach for simplifying the NLDT is also suggested. The\nobtained results are inspiring as they suggest the replacement of complicated\nblack-box DRL policies involving thousands of parameters (making them\nnon-interpretable) with relatively simple interpretable policies. Results are\nencouraging and motivating to pursue further applications of proposed approach\nin solving more complex control tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 20:41:57 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 17:28:51 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Dhebar", "Yashesh", ""], ["Deb", "Kalyanmoy", ""], ["Nageshrao", "Subramanya", ""], ["Zhu", "Ling", ""], ["Filev", "Dimitar", ""]]}, {"id": "2009.09525", "submitter": "Romain Cosentino Mr", "authors": "Romain Cosentino, Randall Balestriero, Richard Baraniuk, Behnaam\n  Aazhang", "title": "Deep Autoencoders: From Understanding to Generalization Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A big mystery in deep learning continues to be the ability of methods to\ngeneralize when the number of model parameters is larger than the number of\ntraining examples. In this work, we take a step towards a better understanding\nof the underlying phenomena of Deep Autoencoders (AEs), a mainstream deep\nlearning solution for learning compressed, interpretable, and structured data\nrepresentations. In particular, we interpret how AEs approximate the data\nmanifold by exploiting their continuous piecewise affine structure. Our\nreformulation of AEs provides new insights into their mapping, reconstruction\nguarantees, as well as an interpretation of commonly used regularization\ntechniques. We leverage these findings to derive two new regularizations that\nenable AEs to capture the inherent symmetry in the data. Our regularizations\nleverage recent advances in the group of transformation learning to enable AEs\nto better approximate the data manifold without explicitly defining the group\nunderlying the manifold. Under the assumption that the symmetry of the data can\nbe explained by a Lie group, we prove that the regularizations ensure the\ngeneralization of the corresponding AEs. A range of experimental evaluations\ndemonstrate that our methods outperform other state-of-the-art regularization\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 21:01:18 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 02:15:43 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Cosentino", "Romain", ""], ["Balestriero", "Randall", ""], ["Baraniuk", "Richard", ""], ["Aazhang", "Behnaam", ""]]}, {"id": "2009.09535", "submitter": "Sehwan Kim", "authors": "Sehwan Kim, Qifan Song, and Faming Liang", "title": "Stochastic Gradient Langevin Dynamics Algorithms with Adaptive Drifts", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian deep learning offers a principled way to address many issues\nconcerning safety of artificial intelligence (AI), such as model\nuncertainty,model interpretability, and prediction bias. However, due to the\nlack of efficient Monte Carlo algorithms for sampling from the posterior of\ndeep neural networks (DNNs), Bayesian deep learning has not yet powered our AI\nsystem. We propose a class of adaptive stochastic gradient Markov chain Monte\nCarlo (SGMCMC) algorithms, where the drift function is biased to enhance escape\nfrom saddle points and the bias is adaptively adjusted according to the\ngradient of past samples. We establish the convergence of the proposed\nalgorithms under mild conditions, and demonstrate via numerical examples that\nthe proposed algorithms can significantly outperform the existing SGMCMC\nalgorithms, such as stochastic gradient Langevin dynamics (SGLD), stochastic\ngradient Hamiltonian Monte Carlo (SGHMC) and preconditioned SGLD, in both\nsimulation and optimization tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 22:03:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kim", "Sehwan", ""], ["Song", "Qifan", ""], ["Liang", "Faming", ""]]}, {"id": "2009.09538", "submitter": "Mengfan Xu", "authors": "Mengfan Xu and Diego Klabjan", "title": "Regret Bounds and Reinforcement Learning Exploration of EXP-based\n  Algorithms", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EXP-based algorithms are often used for exploration in multi-armed bandit. We\nrevisit the EXP3.P algorithm and establish both the lower and upper bounds of\nregret in the Gaussian multi-armed bandit setting, as well as a more general\ndistribution option. The analyses do not require bounded rewards compared to\nclassical regret assumptions. We also extend EXP4 from multi-armed bandit to\nreinforcement learning to incentivize exploration by multiple agents. The\nresulting algorithm has been tested on hard-to-explore games and it shows an\nimprovement on exploration compared to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 22:31:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Xu", "Mengfan", ""], ["Klabjan", "Diego", ""]]}, {"id": "2009.09545", "submitter": "Mirko Pieropan", "authors": "Alfredo Braunstein, Thomas Gueudr\\'e, Andrea Pagnani and Mirko\n  Pieropan", "title": "Expectation propagation on the diluted Bayesian classifier", "comments": "24 pages, 6 figures", "journal-ref": "Phys. Rev. E 103, 043301 (2021)", "doi": "10.1103/PhysRevE.103.043301", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient feature selection from high-dimensional datasets is a very\nimportant challenge in many data-driven fields of science and engineering. We\nintroduce a statistical mechanics inspired strategy that addresses the problem\nof sparse feature selection in the context of binary classification by\nleveraging a computational scheme known as expectation propagation (EP). The\nalgorithm is used in order to train a continuous-weights perceptron learning a\nclassification rule from a set of (possibly partly mislabeled) examples\nprovided by a teacher perceptron with diluted continuous weights. We test the\nmethod in the Bayes optimal setting under a variety of conditions and compare\nit to other state-of-the-art algorithms based on message passing and on\nexpectation maximization approximate inference schemes. Overall, our\nsimulations show that EP is a robust and competitive algorithm in terms of\nvariable selection properties, estimation accuracy and computational\ncomplexity, especially when the student perceptron is trained from correlated\npatterns that prevent other iterative methods from converging. Furthermore, our\nnumerical tests demonstrate that the algorithm is capable of learning online\nthe unknown values of prior parameters, such as the dilution level of the\nweights of the teacher perceptron and the fraction of mislabeled examples,\nquite accurately. This is achieved by means of a simple maximum likelihood\nstrategy that consists in minimizing the free energy associated with the EP\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 23:59:44 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:46:21 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Braunstein", "Alfredo", ""], ["Gueudr\u00e9", "Thomas", ""], ["Pagnani", "Andrea", ""], ["Pieropan", "Mirko", ""]]}, {"id": "2009.09577", "submitter": "Yongcan Cao", "authors": "Feng Tao and Yongcan Cao", "title": "Learn to Exceed: Stereo Inverse Reinforcement Learning with Concurrent\n  Policy Optimization", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of obtaining a control policy that can\nmimic and then outperform expert demonstrations in Markov decision processes\nwhere the reward function is unknown to the learning agent. One main relevant\napproach is the inverse reinforcement learning (IRL), which mainly focuses on\ninferring a reward function from expert demonstrations. The obtained control\npolicy by IRL and the associated algorithms, however, can hardly outperform\nexpert demonstrations. To overcome this limitation, we propose a novel method\nthat enables the learning agent to outperform the demonstrator via a new\nconcurrent reward and action policy learning approach. In particular, we first\npropose a new stereo utility definition that aims to address the bias in the\ninterpretation of expert demonstrations. We then propose a loss function for\nthe learning agent to learn reward and action policies concurrently such that\nthe learning agent can outperform expert demonstrations. The performance of the\nproposed method is first demonstrated in OpenAI environments. Further efforts\nare conducted to experimentally validate the proposed method via an indoor\ndrone flight scenario.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:16:21 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 23:04:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Tao", "Feng", ""], ["Cao", "Yongcan", ""]]}, {"id": "2009.09583", "submitter": "Mel McCurrie", "authors": "Mel McCurrie, Hamish Nicholson, Walter J. Scheirer, Samuel Anthony", "title": "Modeling Score Distributions and Continuous Covariates: A Bayesian\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer Vision practitioners must thoroughly understand their model's\nperformance, but conditional evaluation is complex and error-prone. In\nbiometric verification, model performance over continuous\ncovariates---real-number attributes of images that affect performance---is\nparticularly challenging to study. We develop a generative model of the match\nand non-match score distributions over continuous covariates and perform\ninference with modern Bayesian methods. We use mixture models to capture\narbitrary distributions and local basis functions to capture non-linear,\nmultivariate trends. Three experiments demonstrate the accuracy and\neffectiveness of our approach. First, we study the relationship between age and\nface verification performance and find previous methods may overstate\nperformance and confidence. Second, we study preprocessing for CNNs and find a\nhighly non-linear, multivariate surface of model performance. Our method is\naccurate and data efficient when evaluated against previous synthetic methods.\nThird, we demonstrate the novel application of our method to pedestrian\ntracking and calculate variable thresholds and expected performance while\ncontrolling for multiple covariates.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:41:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["McCurrie", "Mel", ""], ["Nicholson", "Hamish", ""], ["Scheirer", "Walter J.", ""], ["Anthony", "Samuel", ""]]}, {"id": "2009.09590", "submitter": "Lirong Wu", "authors": "Lirong Wu, Zicheng Liu, Zelin Zang, Jun Xia, Siyuan Li, Stan. Z Li", "title": "Deep Clustering and Representation Learning with Geometric Structure\n  Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework for Deep Clustering and\nmulti-manifold Representation Learning (DCRL) that preserves the geometric\nstructure of data. In the proposed framework, manifold clustering is done in\nthe latent space guided by a clustering loss. To overcome the problem that\nclustering-oriented losses may deteriorate the geometric structure of\nembeddings in the latent space, an isometric loss is proposed for preserving\nintra-manifold structure locally and a ranking loss for inter-manifold\nstructure globally. Experimental results on various datasets show that DCRL\nleads to performances comparable to current state-of-the-art deep clustering\nalgorithms, yet exhibits superior performance for manifold representation. Our\nresults also demonstrate the importance and effectiveness of the proposed\nlosses in preserving geometric structure in terms of visualization and\nperformance metrics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:04:57 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 00:56:18 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 14:59:56 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Wu", "Lirong", ""], ["Liu", "Zicheng", ""], ["Zang", "Zelin", ""], ["Xia", "Jun", ""], ["Li", "Siyuan", ""], ["Li", "Stan. Z", ""]]}, {"id": "2009.09604", "submitter": "Badih Ghazi", "authors": "Lijie Chen, Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "On Distributed Differential Privacy and Counting Distinct Elements", "comments": "68 pages, 4 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the setup where each of $n$ users holds an element from a discrete\nset, and the goal is to count the number of distinct elements across all users,\nunder the constraint of $(\\epsilon, \\delta)$-differentially privacy:\n  - In the non-interactive local setting, we prove that the additive error of\nany protocol is $\\Omega(n)$ for any constant $\\epsilon$ and for any $\\delta$\ninverse polynomial in $n$.\n  - In the single-message shuffle setting, we prove a lower bound of\n$\\Omega(n)$ on the error for any constant $\\epsilon$ and for some $\\delta$\ninverse quasi-polynomial in $n$. We do so by building on the moment-matching\nmethod from the literature on distribution estimation.\n  - In the multi-message shuffle setting, we give a protocol with at most one\nmessage per user in expectation and with an error of $\\tilde{O}(\\sqrt(n))$ for\nany constant $\\epsilon$ and for any $\\delta$ inverse polynomial in $n$. Our\nprotocol is also robustly shuffle private, and our error of $\\sqrt(n)$ matches\na known lower bound for such protocols.\n  Our proof technique relies on a new notion, that we call dominated protocols,\nand which can also be used to obtain the first non-trivial lower bounds against\nmulti-message shuffle protocols for the well-studied problems of selection and\nlearning parity.\n  Our first lower bound for estimating the number of distinct elements provides\nthe first $\\omega(\\sqrt(n))$ separation between global sensitivity and error in\nlocal differential privacy, thus answering an open question of Vadhan (2017).\nWe also provide a simple construction that gives $\\tilde{\\Omega}(n)$ separation\nbetween global sensitivity and error in two-party differential privacy, thereby\nanswering an open question of McGregor et al. (2011).\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:13:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chen", "Lijie", ""], ["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2009.09618", "submitter": "Weikai Yang", "authors": "Weikai Yang, Xiting Wang, Jie Lu, Wenwen Dou, Shixia Liu", "title": "Interactive Steering of Hierarchical Clustering", "comments": "Accepted for IEEE Transactions on Visualization and Computer Graphics\n  (TVCG)", "journal-ref": null, "doi": "10.1109/TVCG.2020.2995100", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is an important technique to organize big data for\nexploratory data analysis. However, existing one-size-fits-all hierarchical\nclustering methods often fail to meet the diverse needs of different users. To\naddress this challenge, we present an interactive steering method to visually\nsupervise constrained hierarchical clustering by utilizing both public\nknowledge (e.g., Wikipedia) and private knowledge from users. The novelty of\nour approach includes 1) automatically constructing constraints for\nhierarchical clustering using knowledge (knowledge-driven) and intrinsic data\ndistribution (data-driven), and 2) enabling the interactive steering of\nclustering through a visual interface (user-driven). Our method first maps each\ndata item to the most relevant items in a knowledge base. An initial constraint\ntree is then extracted using the ant colony optimization algorithm. The\nalgorithm balances the tree width and depth and covers the data items with high\nconfidence. Given the constraint tree, the data items are hierarchically\nclustered using evolutionary Bayesian rose tree. To clearly convey the\nhierarchical clustering results, an uncertainty-aware tree visualization has\nbeen developed to enable users to quickly locate the most uncertain\nsub-hierarchies and interactively improve them. The quantitative evaluation and\ncase study demonstrate that the proposed approach facilitates the building of\ncustomized clustering trees in an efficient and effective manner.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 05:26:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yang", "Weikai", ""], ["Wang", "Xiting", ""], ["Lu", "Jie", ""], ["Dou", "Wenwen", ""], ["Liu", "Shixia", ""]]}, {"id": "2009.09663", "submitter": "Yu Li", "authors": "Yu Li, Min Li, Bo Luo, Ye Tian, and Qiang Xu", "title": "DeepDyve: Dynamic Verification for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3372297.3423338", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become one of the enabling technologies in\nmany safety-critical applications, e.g., autonomous driving and medical image\nanalysis. DNN systems, however, suffer from various kinds of threats, such as\nadversarial example attacks and fault injection attacks. While there are many\ndefense methods proposed against maliciously crafted inputs, solutions against\nfaults presented in the DNN system itself (e.g., parameters and calculations)\nare far less explored. In this paper, we develop a novel lightweight\nfault-tolerant solution for DNN-based systems, namely DeepDyve, which employs\npre-trained neural networks that are far simpler and smaller than the original\nDNN for dynamic verification. The key to enabling such lightweight checking is\nthat the smaller neural network only needs to produce approximate results for\nthe initial task without sacrificing fault coverage much. We develop efficient\nand effective architecture and task exploration techniques to achieve optimized\nrisk/overhead trade-off in DeepDyve. Experimental results show that DeepDyve\ncan reduce 90% of the risks at around 10% overhead.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 07:58:18 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:00:09 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Li", "Yu", ""], ["Li", "Min", ""], ["Luo", "Bo", ""], ["Tian", "Ye", ""], ["Xu", "Qiang", ""]]}, {"id": "2009.09677", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Javier Del Ser, Eneko Osaba, Albert Bifet, Francisco\n  Herrera", "title": "CURIE: A Cellular Automaton for Concept Drift Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Data stream mining extracts information from large quantities of data flowing\nfast and continuously (data streams). They are usually affected by changes in\nthe data distribution, giving rise to a phenomenon referred to as concept\ndrift. Thus, learning models must detect and adapt to such changes, so as to\nexhibit a good predictive performance after a drift has occurred. In this\nregard, the development of effective drift detection algorithms becomes a key\nfactor in data stream mining. In this work we propose CU RIE, a drift detector\nrelying on cellular automata. Specifically, in CU RIE the distribution of the\ndata stream is represented in the grid of a cellular automata, whose\nneighborhood rule can then be utilized to detect possible distribution changes\nover the stream. Computer simulations are presented and discussed to show that\nCU RIE, when hybridized with other base learners, renders a competitive\nbehavior in terms of detection metrics and classification accuracy. CU RIE is\ncompared with well-established drift detectors over synthetic datasets with\nvarying drift characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 08:28:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Osaba", "Eneko", ""], ["Bifet", "Albert", ""], ["Herrera", "Francisco", ""]]}, {"id": "2009.09687", "submitter": "Xi Peng", "authors": "Yunfan Li, Peng Hu, Zitao Liu, Dezhong Peng, Joey Tianyi Zhou, Xi Peng", "title": "Contrastive Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a one-stage online clustering method called\nContrastive Clustering (CC) which explicitly performs the instance- and\ncluster-level contrastive learning. To be specific, for a given dataset, the\npositive and negative instance pairs are constructed through data augmentations\nand then projected into a feature space. Therein, the instance- and\ncluster-level contrastive learning are respectively conducted in the row and\ncolumn space by maximizing the similarities of positive pairs while minimizing\nthose of negative ones. Our key observation is that the rows of the feature\nmatrix could be regarded as soft labels of instances, and accordingly the\ncolumns could be further regarded as cluster representations. By simultaneously\noptimizing the instance- and cluster-level contrastive loss, the model jointly\nlearns representations and cluster assignments in an end-to-end manner.\nExtensive experimental results show that CC remarkably outperforms 17\ncompetitive clustering methods on six challenging image benchmarks. In\nparticular, CC achieves an NMI of 0.705 (0.431) on the CIFAR-10 (CIFAR-100)\ndataset, which is an up to 19\\% (39\\%) performance improvement compared with\nthe best baseline.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 08:54:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Yunfan", ""], ["Hu", "Peng", ""], ["Liu", "Zitao", ""], ["Peng", "Dezhong", ""], ["Zhou", "Joey Tianyi", ""], ["Peng", "Xi", ""]]}, {"id": "2009.09706", "submitter": "Johannes Dornheim", "authors": "Johannes Dornheim, Lukas Morand, Samuel Zeitvogel, Tarek Iraki,\n  Norbert Link, Dirk Helm", "title": "Deep Reinforcement Learning Methods for Structure-Guided Processing Path\n  Optimization", "comments": null, "journal-ref": "Journal of Intelligent Manufacturing (2021)", "doi": "10.1007/s10845-021-01805-z", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major goal of materials design is to find material structures with desired\nproperties and in a second step to find a processing path to reach one of these\nstructures. In this paper, we propose and investigate a deep reinforcement\nlearning approach for the optimization of processing paths. The goal is to find\noptimal processing paths in the material structure space that lead to\ntarget-structures, which have been identified beforehand to result in desired\nmaterial properties. There exists a target set containing one or multiple\ndifferent structures. Our proposed methods can find an optimal path from a\nstart structure to a single target structure, or optimize the processing paths\nto one of the equivalent target-structures in the set. In the latter case, the\nalgorithm learns during processing to simultaneously identify the best\nreachable target structure and the optimal path to it. The proposed methods\nbelong to the family of model-free deep reinforcement learning algorithms. They\nare guided by structure representations as features of the process state and by\na reward signal, which is formulated based on a distance function in the\nstructure space. Model-free reinforcement learning algorithms learn through\ntrial and error while interacting with the process. Thereby, they are not\nrestricted to information from a priori sampled processing data and are able to\nadapt to the specific process. The optimization itself is model-free and does\nnot require any prior knowledge about the process itself. We instantiate and\nevaluate the proposed methods by optimizing paths of a generic metal forming\nprocess. We show the ability of both methods to find processing paths leading\nclose to target structures and the ability of the extended method to identify\ntarget-structures that can be reached effectively and efficiently and to focus\non these targets for sample efficient processing path optimization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:20:24 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 10:47:15 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 12:55:49 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 23:00:33 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Dornheim", "Johannes", ""], ["Morand", "Lukas", ""], ["Zeitvogel", "Samuel", ""], ["Iraki", "Tarek", ""], ["Link", "Norbert", ""], ["Helm", "Dirk", ""]]}, {"id": "2009.09723", "submitter": "Stefano Teso", "authors": "Teodora Popordanoska, Mohit Kumar, Stefano Teso", "title": "Machine Guides, Human Supervises: Interactive Learning with Global\n  Explanations", "comments": "Preliminary version. Submitted to AAAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce explanatory guided learning (XGL), a novel interactive learning\nstrategy in which a machine guides a human supervisor toward selecting\ninformative examples for a classifier. The guidance is provided by means of\nglobal explanations, which summarize the classifier's behavior on different\nregions of the instance space and expose its flaws. Compared to other\nexplanatory interactive learning strategies, which are machine-initiated and\nrely on local explanations, XGL is designed to be robust against cases in which\nthe explanations supplied by the machine oversell the classifier's quality.\nMoreover, XGL leverages global explanations to open up the black-box of\nhuman-initiated interaction, enabling supervisors to select informative\nexamples that challenge the learned model. By drawing a link to interactive\nmachine teaching, we show theoretically that global explanations are a viable\napproach for guiding supervisors. Our simulations show that explanatory guided\nlearning avoids overselling the model's quality and performs comparably or\nbetter than machine- and human-initiated interactive learning strategies in\nterms of model quality.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:55:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Popordanoska", "Teodora", ""], ["Kumar", "Mohit", ""], ["Teso", "Stefano", ""]]}, {"id": "2009.09748", "submitter": "Resul Tugay", "authors": "Muhammet cakir, sule gunduz oguducu, resul tugay", "title": "A Deep Hybrid Model for Recommendation Systems", "comments": "International Conference of the Italian Association for Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation has been a long-standing problem in many areas ranging from\ne-commerce to social websites. Most current studies focus only on traditional\napproaches such as content-based or collaborative filtering while there are\nrelatively fewer studies in hybrid recommender systems. Due to the latest\nadvances of deep learning achieved in different fields including computer\nvision and natural language processing, deep learning has also gained much\nattention in Recommendation Systems. There are several studies that utilize ID\nembeddings of users and items to implement collaborative filtering with deep\nneural networks. However, such studies do not take advantage of other\ncategorical or continuous features of inputs. In this paper, we propose a new\ndeep neural network architecture which consists of not only ID embeddings but\nalso auxiliary information such as features of job postings and candidates for\njob recommendation system which is a reciprocal recommendation system.\nExperimental results on the dataset from a job-site show that the proposed\nmethod improves recommendation results over deep learning models utilizing ID\nembeddings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:41:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["cakir", "Muhammet", ""], ["oguducu", "sule gunduz", ""], ["tugay", "resul", ""]]}, {"id": "2009.09756", "submitter": "Resul Tugay", "authors": "Resul Tugay, Sule Gunduz Oguducu", "title": "Demand Prediction Using Machine Learning Methods and Stacked\n  Generalization", "comments": "Proceedings of the 6th International Conference on Data Science,\n  Technology and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply and demand are two fundamental concepts of sellers and customers.\nPredicting demand accurately is critical for organizations in order to be able\nto make plans. In this paper, we propose a new approach for demand prediction\non an e-commerce web site. The proposed model differs from earlier models in\nseveral ways. The business model used in the e-commerce web site, for which the\nmodel is implemented, includes many sellers that sell the same product at the\nsame time at different prices where the company operates a market place model.\nThe demand prediction for such a model should consider the price of the same\nproduct sold by competing sellers along the features of these sellers. In this\nstudy we first applied different regression algorithms for specific set of\nproducts of one department of a company that is one of the most popular online\ne-commerce companies in Turkey. Then we used stacked generalization or also\nknown as stacking ensemble learning to predict demand. Finally, all the\napproaches are evaluated on a real world data set obtained from the e-commerce\ncompany. The experimental results show that some of the machine learning\nmethods do produce almost as good results as the stacked generalization method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:58:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tugay", "Resul", ""], ["Oguducu", "Sule Gunduz", ""]]}, {"id": "2009.09758", "submitter": "Marie-Anne Lachaux", "authors": "Marie-Anne Lachaux, Armand Joulin, Guillaume Lample", "title": "Target Conditioning for One-to-Many Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) models often lack diversity in their\ngenerated translations, even when paired with search algorithm, like beam\nsearch. A challenge is that the diversity in translations are caused by the\nvariability in the target language, and cannot be inferred from the source\nsentence alone. In this paper, we propose to explicitly model this one-to-many\nmapping by conditioning the decoder of a NMT model on a latent variable that\nrepresents the domain of target sentences. The domain is a discrete variable\ngenerated by a target encoder that is jointly trained with the NMT model. The\npredicted domain of target sentences are given as input to the decoder during\ntraining. At inference, we can generate diverse translations by decoding with\ndifferent domains. Unlike our strongest baseline (Shen et al., 2019), our\nmethod can scale to any number of domains without affecting the performance or\nthe training time. We assess the quality and diversity of translations\ngenerated by our model with several metrics, on three different datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:01:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lachaux", "Marie-Anne", ""], ["Joulin", "Armand", ""], ["Lample", "Guillaume", ""]]}, {"id": "2009.09761", "submitter": "Wei Ping", "authors": "Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, Bryan Catanzaro", "title": "DiffWave: A Versatile Diffusion Model for Audio Synthesis", "comments": "ICLR 2021 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose DiffWave, a versatile diffusion probabilistic model\nfor conditional and unconditional waveform generation. The model is\nnon-autoregressive, and converts the white noise signal into structured\nwaveform through a Markov chain with a constant number of steps at synthesis.\nIt is efficiently trained by optimizing a variant of variational bound on the\ndata likelihood. DiffWave produces high-fidelity audios in different waveform\ngeneration tasks, including neural vocoding conditioned on mel spectrogram,\nclass-conditional generation, and unconditional generation. We demonstrate that\nDiffWave matches a strong WaveNet vocoder in terms of speech quality (MOS: 4.44\nversus 4.43), while synthesizing orders of magnitude faster. In particular, it\nsignificantly outperforms autoregressive and GAN-based waveform models in the\nchallenging unconditional generation task in terms of audio quality and sample\ndiversity from various automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:20:38 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 09:47:28 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 19:48:38 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Kong", "Zhifeng", ""], ["Ping", "Wei", ""], ["Huang", "Jiaji", ""], ["Zhao", "Kexin", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2009.09767", "submitter": "Resul Tugay", "authors": "Resul Tugay, Sule Gunduz Oguducu", "title": "Ranky : An Approach to Solve Distributed SVD on Large Sparse Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular Value Decomposition (SVD) is a well studied research topic in many\nfields and applications from data mining to image processing. Data arising from\nthese applications can be represented as a matrix where it is large and sparse.\nMost existing algorithms are used to calculate singular values, left and right\nsingular vectors of a large-dense matrix but not large and sparse matrix. Even\nif they can find SVD of a large matrix, calculation of large-dense matrix has\nhigh time complexity due to sequential algorithms. Distributed approaches are\nproposed for computing SVD of large matrices. However, rank of the matrix is\nstill being a problem when solving SVD with these distributed algorithms. In\nthis paper we propose Ranky, set of methods to solve rank problem on large and\nsparse matrices in a distributed manner. Experimental results show that the\nRanky approach recovers singular values, singular left and right vectors of a\ngiven large and sparse matrix with negligible error.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:36:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tugay", "Resul", ""], ["Oguducu", "Sule Gunduz", ""]]}, {"id": "2009.09796", "submitter": "Michael Crawshaw", "authors": "Michael Crawshaw", "title": "Multi-Task Learning with Deep Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) is a subfield of machine learning in which multiple\ntasks are simultaneously learned by a shared model. Such approaches offer\nadvantages like improved data efficiency, reduced overfitting through shared\nrepresentations, and fast learning by leveraging auxiliary information.\nHowever, the simultaneous learning of multiple tasks presents new design and\noptimization challenges, and choosing which tasks should be learned jointly is\nin itself a non-trivial problem. In this survey, we give an overview of\nmulti-task learning methods for deep neural networks, with the aim of\nsummarizing both the well-established and most recent directions within the\nfield. Our discussion is structured according to a partition of the existing\ndeep MTL techniques into three groups: architectures, optimization methods, and\ntask relationship learning. We also provide a summary of common multi-task\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 19:31:04 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Crawshaw", "Michael", ""]]}, {"id": "2009.09811", "submitter": "Anurag Sarkar", "authors": "Zhihan Yang, Anurag Sarkar, Seth Cooper", "title": "Game Level Clustering and Generation using Gaussian Mixture VAEs", "comments": "6 pages, 5 figures, 16th AAAI Conference on Artificial Intelligence\n  and Interactive Digital Entertainment (AIIDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) have been shown to be able to generate game\nlevels but require manual exploration of the learned latent space to generate\noutputs with desired attributes. While conditional VAEs address this by\nallowing generation to be conditioned on labels, such labels have to be\nprovided during training and thus require prior knowledge which may not always\nbe available. In this paper, we apply Gaussian Mixture VAEs (GMVAEs), a variant\nof the VAE which imposes a mixture of Gaussians (GM) on the latent space,\nunlike regular VAEs which impose a unimodal Gaussian. This allows GMVAEs to\ncluster levels in an unsupervised manner using the components of the GM and\nthen generate new levels using the learned components. We demonstrate our\napproach with levels from Super Mario Bros., Kid Icarus and Mega Man. Our\nresults show that the learned components discover and cluster level structures\nand patterns and can be used to generate levels with desired characteristics.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 15:07:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yang", "Zhihan", ""], ["Sarkar", "Anurag", ""], ["Cooper", "Seth", ""]]}, {"id": "2009.09822", "submitter": "Kwei-Herng Lai", "authors": "Kwei-Herng Lai, Daochen Zha, Guanchu Wang, Junjie Xu, Yue Zhao, Devesh\n  Kumar, Yile Chen, Purav Zumkhawaka, Minyang Wan, Diego Martinez, Xia Hu", "title": "TODS: An Automated Time Series Outlier Detection System", "comments": "Accepted by AAAI'21 demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TODS, an automated Time Series Outlier Detection System for\nresearch and industrial applications. TODS is a highly modular system that\nsupports easy pipeline construction. The basic building block of TODS is\nprimitive, which is an implementation of a function with hyperparameters. TODS\ncurrently supports 70 primitives, including data processing, time series\nprocessing, feature analysis, detection algorithms, and a reinforcement module.\nUsers can freely construct a pipeline using these primitives and perform end-\nto-end outlier detection with the constructed pipeline. TODS provides a\nGraphical User Interface (GUI), where users can flexibly design a pipeline with\ndrag-and-drop. Moreover, a data-driven searcher is provided to automatically\ndiscover the most suitable pipelines given a dataset. TODS is released under\nApache 2.0 license at https://github.com/datamllab/tods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:36:43 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:21:31 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 00:00:47 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lai", "Kwei-Herng", ""], ["Zha", "Daochen", ""], ["Wang", "Guanchu", ""], ["Xu", "Junjie", ""], ["Zhao", "Yue", ""], ["Kumar", "Devesh", ""], ["Chen", "Yile", ""], ["Zumkhawaka", "Purav", ""], ["Wan", "Minyang", ""], ["Martinez", "Diego", ""], ["Hu", "Xia", ""]]}, {"id": "2009.09823", "submitter": "Matthias Karlbauer", "authors": "Matthias Karlbauer, Tobias Menge, Sebastian Otte, Hendrik P.A. Lensch,\n  Thomas Scholten, Volker Wulfmeyer, and Martin V. Butz", "title": "Hidden Latent State Inference in a Spatio-Temporal Generative Model", "comments": "As submitted to the 35th conference of the Association for the\n  Advancement of Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of the hidden factors that determine particular system dynamics is\ncrucial for both explaining them and pursuing goal-directed, interventional\nactions. The inference of these factors without supervision given time series\ndata remains an open challenge. Here, we focus on spatio-temporal processes,\nincluding wave propagations and weather dynamics, and assume that universal\ncauses (e.g. physics) apply throughout space and time. We apply a novel\nDIstributed, Spatio-Temporal graph Artificial Neural network Architecture,\nDISTANA, which learns a generative model in such domains. DISTANA requires\nfewer parameters, and yields more accurate predictions than temporal\nconvolutional neural networks and other related approaches on a 2D circular\nwave prediction task. We show that DISTANA, when combined with a retrospective\nlatent state inference principle called active tuning, can reliably derive\nhidden local causal factors. In a current weather prediction benchmark, DISTANA\ninfers our planet's land-sea mask solely by observing temperature dynamics and\nuses the self inferred information to improve its own prediction of\ntemperature. We are convinced that the retrospective inference of latent states\nin generative RNN architectures will play an essential role in future research\non causal inference and explainable systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:59:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Karlbauer", "Matthias", ""], ["Menge", "Tobias", ""], ["Otte", "Sebastian", ""], ["Lensch", "Hendrik P. A.", ""], ["Scholten", "Thomas", ""], ["Wulfmeyer", "Volker", ""], ["Butz", "Martin V.", ""]]}, {"id": "2009.09827", "submitter": "Lukas Hirsch", "authors": "Lukas Hirsch, MS, Yu Huang, PhD, Shaojun Luo, PhD, Carolina Rossi\n  Saccarelli, MD, Roberto Lo Gullo, MD, Isaac Daimiel Naranjo, MD, Almir G.V.\n  Bitencourt, PhD, Natsuko Onishi, MD, PhD, Eun Sook Ko, PhD, Dortis Leithner,\n  MD, Daly Avendano, MD, Sarah Eskreis-Winkler, MD, PhD, Mary Hughes, MD, Danny\n  F. Martinez, MS, Katja Pinker, MD, PhD, Krishna Juluru, MD, Amin E.\n  El-Rowmeim, MS, MA, Pierre Elnajjar, MS, Hedvig Hricak, MD, Elizabeth A.\n  Morris, MD, Hernan A. Makse, PhD, Lucas C Parra, PhD, Elizabeth J. Sutton, MD", "title": "Deep learning achieves radiologist-level performance of tumor\n  segmentation in breast MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.med-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Purpose: The goal of this research was to develop a deep network architecture\nthat achieves fully-automated radiologist-level segmentation of breast tumors\nin MRI.\n  Materials and Methods: We leveraged 38,229 clinical MRI breast exams\ncollected retrospectively from women aged 12-94 (mean age 54) who presented\nbetween 2002 and 2014 at a single clinical site. The training set for the\nnetwork consisted of 2,555 malignant breasts that were segmented in 2D by\nexperienced radiologists, as well as 60,108 benign breasts that served as\nnegative controls. The test set consisted of 250 exams with tumors segmented\nindependently by four radiologists. We selected among several 3D deep\nconvolutional neural network architectures, input modalities and harmonization\nmethods. The outcome measure was the Dice score for 2D segmentation, and was\ncompared between the network and radiologists using the Wilcoxon signed-rank\ntest and the TOST procedure.\n  Results: The best-performing network on the training set was a volumetric\nU-Net with contrast enhancement dynamic as input and with intensity normalized\nfor each exam. In the test set the median Dice score of this network was 0.77.\nThe performance of the network was equivalent to that of the radiologists (TOST\nprocedure with radiologist performance of 0.69-0.84 as equivalence bounds: p =\n5e-10 and p = 2e-5, respectively; N = 250) and compares favorably with\npublished state of the art (0.6-0.77).\n  Conclusion: When trained on a dataset of over 60 thousand breasts, a\nvolumetric U-Net performs as well as expert radiologists at segmenting\nmalignant breast lesions in MRI.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:07:00 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Hirsch", "Lukas", ""], ["MS", "", ""], ["Huang", "Yu", ""], ["PhD", "", ""], ["Luo", "Shaojun", ""], ["PhD", "", ""], ["Saccarelli", "Carolina Rossi", ""], ["MD", "", ""], ["Gullo", "Roberto Lo", ""], ["MD", "", ""], ["Naranjo", "Isaac Daimiel", ""], ["MD", "", ""], ["Bitencourt", "Almir G. V.", ""], ["PhD", "", ""], ["Onishi", "Natsuko", ""], ["MD", "", ""], ["PhD", "", ""], ["Ko", "Eun Sook", ""], ["PhD", "", ""], ["Leithner", "Dortis", ""], ["MD", "", ""], ["Avendano", "Daly", ""], ["MD", "", ""], ["Eskreis-Winkler", "Sarah", ""], ["MD", "", ""], ["PhD", "", ""], ["Hughes", "Mary", ""], ["MD", "", ""], ["Martinez", "Danny F.", ""], ["MS", "", ""], ["Pinker", "Katja", ""], ["MD", "", ""], ["PhD", "", ""], ["Juluru", "Krishna", ""], ["MD", "", ""], ["El-Rowmeim", "Amin E.", ""], ["MS", "", ""], ["MA", "", ""], ["Elnajjar", "Pierre", ""], ["MS", "", ""], ["Hricak", "Hedvig", ""], ["MD", "", ""], ["Morris", "Elizabeth A.", ""], ["MD", "", ""], ["Makse", "Hernan A.", ""], ["PhD", "", ""], ["Parra", "Lucas C", ""], ["PhD", "", ""], ["Sutton", "Elizabeth J.", ""], ["MD", "", ""]]}, {"id": "2009.09829", "submitter": "Zhao Song", "authors": "Jason D. Lee, Ruoqi Shen, Zhao Song, Mengdi Wang, Zheng Yu", "title": "Generalized Leverage Score Sampling for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Leverage score sampling is a powerful technique that originates from\ntheoretical computer science, which can be used to speed up a large number of\nfundamental questions, e.g. linear regression, linear programming,\nsemi-definite programming, cutting plane method, graph sparsification, maximum\nmatching and max-flow. Recently, it has been shown that leverage score sampling\nhelps to accelerate kernel methods [Avron, Kapralov, Musco, Musco, Velingker\nand Zandieh 17].\n  In this work, we generalize the results in [Avron, Kapralov, Musco, Musco,\nVelingker and Zandieh 17] to a broader class of kernels. We further bring the\nleverage score sampling into the field of deep learning theory.\n  $\\bullet$ We show the connection between the initialization for neural\nnetwork training and approximating the neural tangent kernel with random\nfeatures.\n  $\\bullet$ We prove the equivalence between regularized neural network and\nneural tangent kernel ridge regression under the initialization of both\nclassical random Gaussian and leverage score sampling.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:46:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lee", "Jason D.", ""], ["Shen", "Ruoqi", ""], ["Song", "Zhao", ""], ["Wang", "Mengdi", ""], ["Yu", "Zheng", ""]]}, {"id": "2009.09835", "submitter": "Pan Zhou", "authors": "Pan Zhou, Xiaotong Yuan", "title": "Hybrid Stochastic-Deterministic Minibatch Proximal Gradient:\n  Less-Than-Single-Pass Optimization with Nearly Optimal Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance-reduced gradient (SVRG) algorithms have been shown to\nwork favorably in solving large-scale learning problems. Despite the remarkable\nsuccess, the stochastic gradient complexity of SVRG-type algorithms usually\nscales linearly with data size and thus could still be expensive for huge data.\nTo address this deficiency, we propose a hybrid stochastic-deterministic\nminibatch proximal gradient (HSDMPG) algorithm for strongly-convex problems\nthat enjoys provably improved data-size-independent complexity guarantees. More\nprecisely, for quadratic loss $F(\\theta)$ of $n$ components, we prove that\nHSDMPG can attain an $\\epsilon$-optimization-error\n$\\mathbb{E}[F(\\theta)-F(\\theta^*)]\\leq\\epsilon$ within\n$\\mathcal{O}\\Big(\\frac{\\kappa^{1.5}\\epsilon^{0.75}\\log^{1.5}(\\frac{1}{\\epsilon})+1}{\\epsilon}\\wedge\\Big(\\kappa\n\\sqrt{n}\\log^{1.5}\\big(\\frac{1}{\\epsilon}\\big)+n\\log\\big(\\frac{1}{\\epsilon}\\big)\\Big)\\Big)$\nstochastic gradient evaluations, where $\\kappa$ is condition number. For\ngeneric strongly convex loss functions, we prove a nearly identical complexity\nbound though at the cost of slightly increased logarithmic factors. For\nlarge-scale learning problems, our complexity bounds are superior to those of\nthe prior state-of-the-art SVRG algorithms with or without dependence on data\nsize. Particularly, in the case of $\\epsilon=\\mathcal{O}\\big(1/\\sqrt{n}\\big)$\nwhich is at the order of intrinsic excess error bound of a learning model and\nthus sufficient for generalization, the stochastic gradient complexity bounds\nof HSDMPG for quadratic and generic loss functions are respectively\n$\\mathcal{O} (n^{0.875}\\log^{1.5}(n))$ and $\\mathcal{O}\n(n^{0.875}\\log^{2.25}(n))$, which to our best knowledge, for the first time\nachieve optimal generalization in less than a single pass over data. Extensive\nnumerical results demonstrate the computational advantages of our algorithm\nover the prior ones.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:18:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhou", "Pan", ""], ["Yuan", "Xiaotong", ""]]}, {"id": "2009.09842", "submitter": "Karush Suri", "authors": "Karush Suri, Xiao Qi Shi, Konstantinos Plataniotis, Yuri Lawryshyn", "title": "Energy-based Surprise Minimization for Multi-Agent Value Factorization", "comments": "Preprint, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) has demonstrated significant\nsuccess in training decentralised policies in a centralised manner by making\nuse of value factorization methods. However, addressing surprise across\nspurious states and approximation bias remain open problems for multi-agent\nsettings. Towards this goal, we introduce the Energy-based MIXer (EMIX), an\nalgorithm which minimizes surprise utilizing the energy across agents. Our\ncontributions are threefold; (1) EMIX introduces a novel surprise minimization\ntechnique across multiple agents in the case of multi-agent\npartially-observable settings. (2) EMIX highlights a practical use of energy\nfunctions in MARL with theoretical guarantees and experiment validations of the\nenergy operator. Lastly, (3) EMIX extends Maxmin Q-learning for addressing\noverestimation bias across agents in MARL. In a study of challenging StarCraft\nII micromanagement scenarios, EMIX demonstrates consistent stable performance\nfor multiagent surprise minimization. Moreover, our ablation study highlights\nthe necessity of the energy-based scheme and the need for elimination of\noverestimation bias in MARL. Our implementation of EMIX can be found at\nkarush17.github.io/emix-web/.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:42:42 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 16:26:43 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 16:10:26 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 03:06:32 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Suri", "Karush", ""], ["Shi", "Xiao Qi", ""], ["Plataniotis", "Konstantinos", ""], ["Lawryshyn", "Yuri", ""]]}, {"id": "2009.09849", "submitter": "Marcus Kalander", "authors": "Marcus Kalander, Min Zhou, Chengzhi Zhang, Hanling Yi, Lujia Pan", "title": "Spatio-Temporal Hybrid Graph Convolutional Network for Traffic\n  Forecasting in Telecommunication Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telecommunication networks play a critical role in modern society. With the\narrival of 5G networks, these systems are becoming even more diversified,\nintegrated, and intelligent. Traffic forecasting is one of the key components\nin such a system, however, it is particularly challenging due to the complex\nspatial-temporal dependency. In this work, we consider this problem from the\naspect of a cellular network and the interactions among its base stations. We\nthoroughly investigate the characteristics of cellular network traffic and shed\nlight on the dependency complexities based on data collected from a densely\npopulated metropolis area. Specifically, we observe that the traffic shows both\ndynamic and static spatial dependencies as well as diverse cyclic temporal\npatterns. To address these complexities, we propose an effective\ndeep-learning-based approach, namely, Spatio-Temporal Hybrid Graph\nConvolutional Network (STHGCN). It employs GRUs to model the temporal\ndependency, while capturing the complex spatial dependency through a hybrid-GCN\nfrom three perspectives: spatial proximity, functional similarity, and recent\ntrend similarity. We conduct extensive experiments on real-world traffic\ndatasets collected from telecommunication networks. Our experimental results\ndemonstrate the superiority of the proposed model in that it consistently\noutperforms both classical methods and state-of-the-art deep learning models,\nwhile being more robust and stable.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:54:16 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kalander", "Marcus", ""], ["Zhou", "Min", ""], ["Zhang", "Chengzhi", ""], ["Yi", "Hanling", ""], ["Pan", "Lujia", ""]]}, {"id": "2009.09893", "submitter": "R. Ian Etheredge", "authors": "R. Ian Etheredge, Manfred Schartl, Alex Jordan", "title": "Decontextualized learning for interpretable hierarchical representations\n  of visual patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apart from discriminative models for classification and object detection\ntasks, the application of deep convolutional neural networks to basic research\nutilizing natural imaging data has been somewhat limited; particularly in cases\nwhere a set of interpretable features for downstream analysis is needed, a key\nrequirement for many scientific investigations. We present an algorithm and\ntraining paradigm designed specifically to address this: decontextualized\nhierarchical representation learning (DHRL). By combining a generative model\nchaining procedure with a ladder network architecture and latent space\nregularization for inference, DHRL address the limitations of small datasets\nand encourages a disentangled set of hierarchically organized features. In\naddition to providing a tractable path for analyzing complex hierarchal\npatterns using variation inference, this approach is generative and can be\ndirectly combined with empirical and theoretical approaches. To highlight the\nextensibility and usefulness of DHRL, we demonstrate this method in application\nto a question from evolutionary biology.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:47:55 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Etheredge", "R. Ian", ""], ["Schartl", "Manfred", ""], ["Jordan", "Alex", ""]]}, {"id": "2009.09899", "submitter": "Jacob Householder", "authors": "Jacob Householder, Andrew Householder, John Paul Gomez-Reed, Fredrick\n  Park, Shuai Zhang", "title": "Clustering COVID-19 Lung Scans", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent outbreak of COVID-19, creating a means to stop it's spread\nand eventually develop a vaccine are the most important and challenging tasks\nthat the scientific community is facing right now. The first step towards these\ngoals is to correctly identify a patient that is infected with the virus. Our\ngroup applied an unsupervised machine learning technique to identify COVID-19\ncases. This is an important topic as COVID-19 is a novel disease currently\nbeing studied in detail and our methodology has the potential to reveal\nimportant differences between it and other viral pneumonia. This could then, in\nturn, enable doctors to more confidently help each patient. Our experiments\nutilize Principal Component Analysis (PCA), t-distributed Stochastic Neighbor\nEmbedding (t-SNE), and the recently developed Robust Continuous Clustering\nalgorithm (RCC). We display the performance of RCC in identifying COVID-19\npatients and its ability to compete with other unsupervised algorithms, namely\nK-Means++ (KM++). Using a COVID-19 Radiography dataset, we found that RCC\noutperformed KM++; we used the Adjusted Mutual Information Score (AMI) in order\nto measure the effectiveness of both algorithms. The AMI for the two and three\nclass cases of KM++ were 0.0250 and 0.054, respectively. In comparison, RCC\nscored 0.5044 in the two class case and 0.267 in the three class case, clearly\nshowing RCC as the superior algorithm. This not only opens new possible\napplications of RCC, but it could potentially aid in the creation of a new tool\nfor COVID-19 identification.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 00:21:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Householder", "Jacob", ""], ["Householder", "Andrew", ""], ["Gomez-Reed", "John Paul", ""], ["Park", "Fredrick", ""], ["Zhang", "Shuai", ""]]}, {"id": "2009.09919", "submitter": "Eric Alcaide", "authors": "Eric Alcaide", "title": "Improving Graph Property Prediction with Generalized Readout Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph property prediction is drawing increasing attention in the recent years\ndue to the fact that graphs are one of the most general data structures since\nthey can contain an arbitrary number of nodes and connections between them, and\nit is the backbone for many different tasks like classification and regression\non such kind of data (networks, molecules, knowledge bases, ...). We introduce\na novel generalized global pooling layer to mitigate the information loss that\ntypically occurs at the Readout phase in Message-Passing Neural Networks. This\nnovel layer is parametrized by two values ($\\beta$ and $p$) which can\noptionally be learned, and the transformation it performs can revert to several\nalready popular readout functions (mean, max and sum) under certain settings,\nwhich can be specified. To showcase the superior expressiveness and performance\nof this novel technique, we test it in a popular graph property prediction task\nby taking the current best-performing architecture and using our readout layer\nas a drop-in replacement and we report new state of the art results. The code\nto reproduce the experiments can be accessed here:\nhttps://github.com/EricAlcaide/generalized-readout-phase\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:41:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Alcaide", "Eric", ""]]}, {"id": "2009.09922", "submitter": "Tao Bai", "authors": "Tao Bai, Jinnan Chen, Jun Zhao, Bihan Wen, Xudong Jiang, Alex Kot", "title": "Feature Distillation With Guided Adversarial Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are shown to be vulnerable to adversarial examples.\nThough adversarial training can enhance model robustness, typical approaches\nare computationally expensive. Recent works proposed to transfer the robustness\nto adversarial attacks across different tasks or models with soft\nlabels.Compared to soft labels, feature contains rich semantic information and\nholds the potential to be applied to different downstream tasks. In this paper,\nwe propose a novel approach called Guided Adversarial Contrastive Distillation\n(GACD), to effectively transfer adversarial robustness from teacher to student\nwith features. We first formulate this objective as contrastive learning and\nconnect it with mutual information. With a well-trained teacher model as an\nanchor, students are expected to extract features similar to the teacher. Then\nconsidering the potential errors made by teachers, we propose sample reweighted\nestimation to eliminate the negative effects from teachers. With GACD, the\nstudent not only learns to extract robust features, but also captures\nstructural knowledge from the teacher. By extensive experiments evaluating over\npopular datasets such as CIFAR-10, CIFAR-100 and STL-10, we demonstrate that\nour approach can effectively transfer robustness across different models and\neven different tasks, and achieve comparable or better results than existing\nmethods. Besides, we provide a detailed analysis of various methods, showing\nthat students produced by our approach capture more structural knowledge from\nteachers and learn more robust features under adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:46:17 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bai", "Tao", ""], ["Chen", "Jinnan", ""], ["Zhao", "Jun", ""], ["Wen", "Bihan", ""], ["Jiang", "Xudong", ""], ["Kot", "Alex", ""]]}, {"id": "2009.09925", "submitter": "Yongcan Cao", "authors": "Feng Tao, Rengan Suresh, Johnathan Votion, and Yongcan Cao", "title": "Graph Based Multi-layer K-means++ (G-MLKM) for Sensory Pattern Analysis\n  in Constrained Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on developing a novel unsupervised machine learning\nalgorithm, named graph based multi-layer k-means++ (G-MLKM), to solve\ndata-target association problem when targets move on a constrained space and\nminimal information of the targets can be obtained by sensors. Instead of\nemploying the traditional data-target association methods that are based on\nstatistical probabilities, the G-MLKM solves the problem via data clustering.\nWe first will develop the Multi-layer K-means++ (MLKM) method for data-target\nassociation at local space given a simplified constrained space situation. Then\na p-dual graph is proposed to represent the general constrained space when\nlocal spaces are interconnected. Based on the dual graph and graph theory, we\nthen generalize MLKM to G-MLKM by first understanding local data-target\nassociation and then extracting cross-local data-target association\nmathematically analyze the data association at intersections of that space. To\nexclude potential data-target association errors that disobey physical rules,\nwe also develop error correction mechanisms to further improve the accuracy.\nNumerous simulation examples are conducted to demonstrate the performance of\nG-MLKM.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:52:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tao", "Feng", ""], ["Suresh", "Rengan", ""], ["Votion", "Johnathan", ""], ["Cao", "Yongcan", ""]]}, {"id": "2009.09929", "submitter": "Vincenzo Lomonaco PhD", "authors": "Vincenzo Lomonaco, Lorenzo Pellegrini, Pau Rodriguez, Massimo Caccia,\n  Qi She, Yu Chen, Quentin Jodelet, Ruiping Wang, Zheda Mai, David Vazquez,\n  German I. Parisi, Nikhil Churamani, Marc Pickett, Issam Laradji, Davide\n  Maltoni", "title": "CVPR 2020 Continual Learning in Computer Vision Competition: Approaches,\n  Results, Current Challenges and Future Directions", "comments": "Pre-print v1: 12 pages, 3 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, we have witnessed a renewed and fast-growing interest\nin continual learning with deep neural networks with the shared objective of\nmaking current AI systems more adaptive, efficient and autonomous. However,\ndespite the significant and undoubted progress of the field in addressing the\nissue of catastrophic forgetting, benchmarking different continual learning\napproaches is a difficult task by itself. In fact, given the proliferation of\ndifferent settings, training and evaluation protocols, metrics and\nnomenclature, it is often tricky to properly characterize a continual learning\nalgorithm, relate it to other solutions and gauge its real-world applicability.\nThe first Continual Learning in Computer Vision challenge held at CVPR in 2020\nhas been one of the first opportunities to evaluate different continual\nlearning algorithms on a common hardware with a large set of shared evaluation\nmetrics and 3 different settings based on the realistic CORe50 video benchmark.\nIn this paper, we report the main results of the competition, which counted\nmore than 79 teams registered, 11 finalists and 2300$ in prizes. We also\nsummarize the winning approaches, current challenges and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 08:53:05 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lomonaco", "Vincenzo", ""], ["Pellegrini", "Lorenzo", ""], ["Rodriguez", "Pau", ""], ["Caccia", "Massimo", ""], ["She", "Qi", ""], ["Chen", "Yu", ""], ["Jodelet", "Quentin", ""], ["Wang", "Ruiping", ""], ["Mai", "Zheda", ""], ["Vazquez", "David", ""], ["Parisi", "German I.", ""], ["Churamani", "Nikhil", ""], ["Pickett", "Marc", ""], ["Laradji", "Issam", ""], ["Maltoni", "Davide", ""]]}, {"id": "2009.09930", "submitter": "Mohammad Hadi", "authors": "Mohammad Abdul Hadi and Fatemeh H Fard", "title": "AOBTM: Adaptive Online Biterm Topic Modeling for Version Sensitive\n  Short-texts Analysis", "comments": "13 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of mobile app reviews has shown its important role in requirement\nengineering, software maintenance and evolution of mobile apps. Mobile app\ndevelopers check their users' reviews frequently to clarify the issues\nexperienced by users or capture the new issues that are introduced due to a\nrecent app update. App reviews have a dynamic nature and their discussed topics\nchange over time. The changes in the topics among collected reviews for\ndifferent versions of an app can reveal important issues about the app update.\nA main technique in this analysis is using topic modeling algorithms. However,\napp reviews are short texts and it is challenging to unveil their latent topics\nover time. Conventional topic models suffer from the sparsity of word\nco-occurrence patterns while inferring topics for short texts. Furthermore,\nthese algorithms cannot capture topics over numerous consecutive time-slices.\nOnline topic modeling algorithms speed up the inference of topic models for the\ntexts collected in the latest time-slice by saving a fraction of data from the\nprevious time-slice. But these algorithms do not analyze the statistical-data\nof all the previous time-slices, which can confer contributions to the topic\ndistribution of the current time-slice.\n  We propose Adaptive Online Biterm Topic Model (AOBTM) to model topics in\nshort texts adaptively. AOBTM alleviates the sparsity problem in short-texts\nand considers the statistical-data for an optimal number of previous\ntime-slices. We also propose parallel algorithms to automatically determine the\noptimal number of topics and the best number of previous versions that should\nbe considered in topic inference phase. Automatic evaluation on collections of\napp reviews and real-world short text datasets confirm that AOBTM can find more\ncoherent topics and outperforms the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 09:50:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Hadi", "Mohammad Abdul", ""], ["Fard", "Fatemeh H", ""]]}, {"id": "2009.09931", "submitter": "Harshit Pande", "authors": "Harshit Pande", "title": "Field-Embedded Factorization Machines for Click-through rate prediction", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction models are common in many online\napplications such as digital advertising and recommender systems. Field-Aware\nFactorization Machine (FFM) and Field-weighted Factorization Machine (FwFM) are\nstate-of-the-art among the shallow models for CTR prediction. Recently, many\ndeep learning-based models have also been proposed. Among deeper models,\nDeepFM, xDeepFM, AutoInt+, and FiBiNet are state-of-the-art models. The deeper\nmodels combine a core architectural component, which learns explicit feature\ninteractions, with a deep neural network (DNN) component. We propose a novel\nshallow Field-Embedded Factorization Machine (FEFM) and its deep counterpart\nDeep Field-Embedded Factorization Machine (DeepFEFM). FEFM learns symmetric\nmatrix embeddings for each field pair along with the usual single vector\nembeddings for each feature. FEFM has significantly lower model complexity than\nFFM and roughly the same complexity as FwFM. FEFM also has insightful\nmathematical properties about important fields and field interactions. DeepFEFM\ncombines the FEFM interaction vectors learned by the FEFM component with a DNN\nand is thus able to learn higher order interactions. We conducted comprehensive\nexperiments over a wide range of hyperparameters on two large publicly\navailable real-world datasets. When comparing test AUC and log loss, the\nresults show that FEFM and DeepFEFM outperform the existing state-of-the-art\nshallow and deep models for CTR prediction tasks. We have made the code of FEFM\nand DeepFEFM available in the DeepCTR library\n(https://github.com/shenweichen/DeepCTR).\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 15:32:42 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 18:45:02 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Pande", "Harshit", ""]]}, {"id": "2009.09932", "submitter": "Song Cheng", "authors": "Song Cheng, Lei Wang, Pan Zhang", "title": "Supervised Learning with Projected Entangled Pair States", "comments": "7 pages, 4 figures, 1 table", "journal-ref": "Phys. Rev. B 103, 125117 (2021)", "doi": "10.1103/PhysRevB.103.125117", "report-no": null, "categories": "cs.CV cond-mat.str-el cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor networks, a model that originated from quantum physics, has been\ngradually generalized as efficient models in machine learning in recent years.\nHowever, in order to achieve exact contraction, only tree-like tensor networks\nsuch as the matrix product states and tree tensor networks have been\nconsidered, even for modeling two-dimensional data such as images. In this\nwork, we construct supervised learning models for images using the projected\nentangled pair states (PEPS), a two-dimensional tensor network having a similar\nstructure prior to natural images. Our approach first performs a feature map,\nwhich transforms the image data to a product state on a grid, then contracts\nthe product state to a PEPS with trainable parameters to predict image labels.\nThe tensor elements of PEPS are trained by minimizing differences between\ntraining labels and predicted labels. The proposed model is evaluated on image\nclassifications using the MNIST and the Fashion-MNIST datasets. We show that\nour model is significantly superior to existing models using tree-like tensor\nnetworks. Moreover, using the same input features, our method performs as well\nas the multilayer perceptron classifier, but with much fewer parameters and is\nmore stable. Our results shed light on potential applications of\ntwo-dimensional tensor network models in machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 09:15:00 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Cheng", "Song", ""], ["Wang", "Lei", ""], ["Zhang", "Pan", ""]]}, {"id": "2009.09943", "submitter": "Brandon Paulsen", "authors": "Brandon Paulsen, Jingbo Wang, Jiawei Wang, Chao Wang", "title": "NeuroDiff: Scalable Differential Verification of Neural Networks using\n  Fine-Grained Approximation", "comments": "Published as a conference paper at ASE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks make their way into safety-critical systems, where\nmisbehavior can lead to catastrophes, there is a growing interest in certifying\nthe equivalence of two structurally similar neural networks. For example,\ncompression techniques are often used in practice for deploying trained neural\nnetworks on computationally- and energy-constrained devices, which raises the\nquestion of how faithfully the compressed network mimics the original network.\nUnfortunately, existing methods either focus on verifying a single network or\nrely on loose approximations to prove the equivalence of two networks. Due to\noverly conservative approximation, differential verification lacks scalability\nin terms of both accuracy and computational cost. To overcome these problems,\nwe propose NeuroDiff, a symbolic and fine-grained approximation technique that\ndrastically increases the accuracy of differential verification while achieving\nmany orders-of-magnitude speedup. NeuroDiff has two key contributions. The\nfirst one is new convex approximations that more accurately bound the\ndifference neurons of two networks under all possible inputs. The second one is\njudicious use of symbolic variables to represent neurons whose difference\nbounds have accumulated significant error. We also find that these two\ntechniques are complementary, i.e., when combined, the benefit is greater than\nthe sum of their individual benefits. We have evaluated NeuroDiff on a variety\nof differential verification tasks. Our results show that NeuroDiff is up to\n1000X faster and 5X more accurate than the state-of-the-art tool.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:00:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Paulsen", "Brandon", ""], ["Wang", "Jingbo", ""], ["Wang", "Jiawei", ""], ["Wang", "Chao", ""]]}, {"id": "2009.09988", "submitter": "Yinglun Zhu", "authors": "Yinglun Zhu, Sumeet Katariya and Robert Nowak", "title": "Robust Outlier Arm Identification", "comments": "Full version of our ICML 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of Robust Outlier Arm Identification (ROAI), where the\ngoal is to identify arms whose expected rewards deviate substantially from the\nmajority, by adaptively sampling from their reward distributions. We compute\nthe outlier threshold using the median and median absolute deviation of the\nexpected rewards. This is a robust choice for the threshold compared to using\nthe mean and standard deviation, since it can identify outlier arms even in the\npresence of extreme outlier values. Our setting is different from existing pure\nexploration problems where the threshold is pre-specified as a given value or\nrank. This is useful in applications where the goal is to identify the set of\npromising items but the cardinality of this set is unknown, such as finding\npromising drugs for a new disease or identifying items favored by a population.\nWe propose two $\\delta$-PAC algorithms for ROAI, which includes the first\nUCB-style algorithm for outlier detection, and derive upper bounds on their\nsample complexity. We also prove a matching, up to logarithmic factors, worst\ncase lower bound for the problem, indicating that our upper bounds are\ngenerally unimprovable. Experimental results show that our algorithms are both\nrobust and about $5$x sample efficient compared to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:13:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhu", "Yinglun", ""], ["Katariya", "Sumeet", ""], ["Nowak", "Robert", ""]]}, {"id": "2009.09991", "submitter": "Sebastian Bruch", "authors": "Mathieu Guillame-Bert, Sebastian Bruch, Petr Mitrichev, Petr Mikheev,\n  Jan Pfeifer", "title": "Modeling Text with Decision Forests using Categorical-Set Splits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision forest algorithms typically model data by learning a binary tree\nstructure recursively where every node splits the feature space into two\nsub-regions, sending examples into the left or right branch as a result. In\naxis-aligned decision forests, the \"decision\" to route an input example is the\nresult of the evaluation of a condition on a single dimension in the feature\nspace. Such conditions are learned using efficient, often greedy algorithms\nthat optimize a local loss function. For example, a node's condition may be a\nthreshold function applied to a numerical feature, and its parameter may be\nlearned by sweeping over the set of values available at that node and choosing\na threshold that maximizes some measure of purity. Crucially, whether an\nalgorithm exists to learn and evaluate conditions for a feature type determines\nwhether a decision forest algorithm can model that feature type at all. For\nexample, decision forests today cannot consume textual features directly --\nsuch features must be transformed to summary statistics instead. In this work,\nwe set out to bridge that gap. We define a condition that is specific to\ncategorical-set features -- defined as an unordered set of categorical\nvariables -- and present an algorithm to learn it, thereby equipping decision\nforests with the ability to directly model text, albeit without preserving\nsequential order. Our algorithm is efficient during training and the resulting\nconditions are fast to evaluate with our extension of the QuickScorer inference\nalgorithm. Experiments on benchmark text classification datasets demonstrate\nthe utility and effectiveness of our proposal.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:16:35 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 18:29:59 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 11:44:02 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Guillame-Bert", "Mathieu", ""], ["Bruch", "Sebastian", ""], ["Mitrichev", "Petr", ""], ["Mikheev", "Petr", ""], ["Pfeifer", "Jan", ""]]}, {"id": "2009.10007", "submitter": "Konstantinos Nikolaidis", "authors": "Konstantinos Nikolaidis, Stein Kristiansen, Thomas Plagemann, Vera\n  Goebel, Knut Liest{\\o}l, Mohan Kankanhalli, Gunn Marit Traaen, Britt\n  {\\O}verland, Harriet Akre, Lars Aaker{\\o}y, Sigurd Steinshamn", "title": "Learning Realistic Patterns from Unrealistic Stimuli: Generalization and\n  Data Anonymization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Good training data is a prerequisite to develop useful ML applications.\nHowever, in many domains existing data sets cannot be shared due to privacy\nregulations (e.g., from medical studies). This work investigates a simple yet\nunconventional approach for anonymized data synthesis to enable third parties\nto benefit from such private data. We explore the feasibility of learning\nimplicitly from unrealistic, task-relevant stimuli, which are synthesized by\nexciting the neurons of a trained deep neural network (DNN). As such, neuronal\nexcitation serves as a pseudo-generative model. The stimuli data is used to\ntrain new classification models. Furthermore, we extend this framework to\ninhibit representations that are associated with specific individuals. We use\nsleep monitoring data from both an open and a large closed clinical study and\nevaluate whether (1) end-users can create and successfully use customized\nclassification models for sleep apnea detection, and (2) the identity of\nparticipants in the study is protected. Extensive comparative empirical\ninvestigation shows that different algorithms trained on the stimuli are able\ngeneralize successfully on the same task as the original model. However,\narchitectural and algorithmic similarity between new and original models play\nan important role in performance. For similar architectures, the performance is\nclose to that of using the true data (e.g., Accuracy difference of 0.56\\%,\nKappa coefficient difference of 0.03-0.04). Further experiments show that the\nstimuli can to a large extent successfully anonymize participants of the\nclinical studies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:31:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Nikolaidis", "Konstantinos", ""], ["Kristiansen", "Stein", ""], ["Plagemann", "Thomas", ""], ["Goebel", "Vera", ""], ["Liest\u00f8l", "Knut", ""], ["Kankanhalli", "Mohan", ""], ["Traaen", "Gunn Marit", ""], ["\u00d8verland", "Britt", ""], ["Akre", "Harriet", ""], ["Aaker\u00f8y", "Lars", ""], ["Steinshamn", "Sigurd", ""]]}, {"id": "2009.10008", "submitter": "Tom Tirer", "authors": "Tom Tirer, Joan Bruna, Raja Giryes", "title": "Kernel-Based Smoothness Analysis of Residual Networks", "comments": "Accepted to MSML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major factor in the success of deep neural networks is the use of\nsophisticated architectures rather than the classical multilayer perceptron\n(MLP). Residual networks (ResNets) stand out among these powerful modern\narchitectures. Previous works focused on the optimization advantages of deep\nResNets over deep MLPs. In this paper, we show another distinction between the\ntwo models, namely, a tendency of ResNets to promote smoother interpolations\nthan MLPs. We analyze this phenomenon via the neural tangent kernel (NTK)\napproach. First, we compute the NTK for a considered ResNet model and prove its\nstability during gradient descent training. Then, we show by various evaluation\nmethodologies that for ReLU activations the NTK of ResNet, and its kernel\nregression results, are smoother than the ones of MLP. The better smoothness\nobserved in our analysis may explain the better generalization ability of\nResNets and the practice of moderately attenuating the residual blocks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:32:04 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 18:44:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tirer", "Tom", ""], ["Bruna", "Joan", ""], ["Giryes", "Raja", ""]]}, {"id": "2009.10017", "submitter": "Ryan Rossi", "authors": "Di Jin, Sungchul Kim, Ryan A. Rossi, Danai Koutra", "title": "From Static to Dynamic Node Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general framework for leveraging graph stream data for\ntemporal prediction-based applications. Our proposed framework includes novel\nmethods for learning an appropriate graph time-series representation, modeling\nand weighting the temporal dependencies, and generalizing existing embedding\nmethods for such data. While previous work on dynamic modeling and embedding\nhas focused on representing a stream of timestamped edges using a time-series\nof graphs based on a specific time-scale (e.g., 1 month), we propose the notion\nof an $\\epsilon$-graph time-series that uses a fixed number of edges for each\ngraph, and show its superiority over the time-scale representation used in\nprevious work. In addition, we propose a number of new temporal models based on\nthe notion of temporal reachability graphs and weighted temporal summary\ngraphs. These temporal models are then used to generalize existing base\n(static) embedding methods by enabling them to incorporate and appropriately\nmodel temporal dependencies in the data. From the 6 temporal network models\ninvestigated (for each of the 7 base embedding methods), we find that the top-3\ntemporal models are always those that leverage the new $\\epsilon$-graph\ntime-series representation. Furthermore, the dynamic embedding methods from the\nframework almost always achieve better predictive performance than existing\nstate-of-the-art dynamic node embedding methods that are developed specifically\nfor such temporal prediction tasks. Finally, the findings of this work are\nuseful for designing better dynamic embedding methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:48:29 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jin", "Di", ""], ["Kim", "Sungchul", ""], ["Rossi", "Ryan A.", ""], ["Koutra", "Danai", ""]]}, {"id": "2009.10031", "submitter": "Om Thakkar", "authors": "Swaroop Ramaswamy, Om Thakkar, Rajiv Mathews, Galen Andrew, H. Brendan\n  McMahan, Fran\\c{c}oise Beaufays", "title": "Training Production Language Models without Memorizing User Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents the first consumer-scale next-word prediction (NWP) model\ntrained with Federated Learning (FL) while leveraging the Differentially\nPrivate Federated Averaging (DP-FedAvg) technique. There has been prior work on\nbuilding practical FL infrastructure, including work demonstrating the\nfeasibility of training language models on mobile devices using such\ninfrastructure. It has also been shown (in simulations on a public corpus) that\nit is possible to train NWP models with user-level differential privacy using\nthe DP-FedAvg algorithm. Nevertheless, training production-quality NWP models\nwith DP-FedAvg in a real-world production environment on a heterogeneous fleet\nof mobile phones requires addressing numerous challenges. For instance, the\ncoordinating central server has to keep track of the devices available at the\nstart of each round and sample devices uniformly at random from them, while\nensuring \\emph{secrecy of the sample}, etc. Unlike all prior privacy-focused FL\nwork of which we are aware, for the first time we demonstrate the deployment of\na differentially private mechanism for the training of a production neural\nnetwork in FL, as well as the instrumentation of the production training\ninfrastructure to perform an end-to-end empirical measurement of unintended\nmemorization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:12:33 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ramaswamy", "Swaroop", ""], ["Thakkar", "Om", ""], ["Mathews", "Rajiv", ""], ["Andrew", "Galen", ""], ["McMahan", "H. Brendan", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "2009.10064", "submitter": "Maurice Weber", "authors": "Maurice Weber, Nana Liu, Bo Li, Ce Zhang, Zhikuan Zhao", "title": "Optimal Provable Robustness of Quantum Classification via Quantum\n  Hypothesis Testing", "comments": "28 pages, 5 figures", "journal-ref": "npj Quantum Information 7, 76 (2021)", "doi": "10.1038/s41534-021-00410-5", "report-no": null, "categories": "quant-ph cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum machine learning models have the potential to offer speedups and\nbetter predictive accuracy compared to their classical counterparts. However,\nthese quantum algorithms, like their classical counterparts, have been shown to\nalso be vulnerable to input perturbations, in particular for classification\nproblems. These can arise either from noisy implementations or, as a worst-case\ntype of noise, adversarial attacks. In order to develop defence mechanisms and\nto better understand the reliability of these algorithms, it is crucial to\nunderstand their robustness properties in presence of natural noise sources or\nadversarial manipulation. From the observation that measurements involved in\nquantum classification algorithms are naturally probabilistic, we uncover and\nformalize a fundamental link between binary quantum hypothesis testing and\nprovably robust quantum classification. This link leads to a tight robustness\ncondition which puts constraints on the amount of noise a classifier can\ntolerate, independent of whether the noise source is natural or adversarial.\nBased on this result, we develop practical protocols to optimally certify\nrobustness. Finally, since this is a robustness condition against worst-case\ntypes of noise, our result naturally extends to scenarios where the noise\nsource is known. Thus, we also provide a framework to study the reliability of\nquantum classification protocols beyond the adversarial, worst-case noise\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:55:28 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 09:07:35 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Weber", "Maurice", ""], ["Liu", "Nana", ""], ["Li", "Bo", ""], ["Zhang", "Ce", ""], ["Zhao", "Zhikuan", ""]]}, {"id": "2009.10065", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov and Ikhlaas Gurrib", "title": "Machine learning based forecasting of significant daily returns in\n  foreign exchange markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asset value forecasting has always attracted an enormous amount of interest\namong researchers in quantitative analysis. The advent of modern machine\nlearning models has introduced new tools to tackle this classical problem. In\nthis paper, we apply machine learning algorithms to hitherto unexplored\nquestion of forecasting instances of significant fluctuations in currency\nexchange rates. We perform analysis of nine modern machine learning algorithms\nusing data on four major currency pairs over a 10 year period. A key\ncontribution is the novel use of outlier detection methods for this purpose.\nNumerical experiments show that outlier detection methods substantially\noutperform traditional machine learning and finance techniques. In addition, we\nshow that a recently proposed new outlier detection method PKDE produces best\noverall results. Our findings hold across different currency pairs,\nsignificance levels, and time horizons indicating the robustness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:56:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kamalov", "Firuz", ""], ["Gurrib", "Ikhlaas", ""]]}, {"id": "2009.10071", "submitter": "Denisa Roberts", "authors": "Denisa A.O. Roberts and Lucas R. Roberts", "title": "QR and LQ Decomposition Matrix Backpropagation Algorithms for Square,\n  Wide, and Deep -- Real or Complex -- Matrices and Their Software\n  Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.MS cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents matrix backpropagation algorithms for the QR\ndecomposition of matrices $A_{m, n}$, that are either square (m = n), wide (m <\nn), or deep (m > n), with rank $k = min(m, n)$. Furthermore, we derive novel\nmatrix backpropagation results for the pivoted (full-rank) QR decomposition and\nfor the LQ decomposition of deep input matrices. Differentiable QR\ndecomposition offers a numerically stable, computationally efficient method to\nsolve least squares problems frequently encountered in machine learning and\ncomputer vision. Other use cases such as graph learning and network compression\nare listed in the article. Software implementation across popular deep learning\nframeworks (PyTorch, TensorFlow, MXNet) incorporate the methods for general use\nwithin the deep learning community. Furthermore, this article aids the\npractitioner in understanding the matrix backpropagation methodology as part of\nlarger computational graphs.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 21:03:37 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 13:43:04 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 21:18:53 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 12:54:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Roberts", "Denisa A. O.", ""], ["Roberts", "Lucas R.", ""]]}, {"id": "2009.10103", "submitter": "Yuan Liao", "authors": "Jianqing Fan, Kunpeng Li, Yuan Liao", "title": "Recent Developments on Factor Models and its Applications in Econometric\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1146/annurev-financial-091420-011735", "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes a selective survey on the recent development of the factor\nmodel and its application on statistical learnings. We focus on the perspective\nof the low-rank structure of factor models, and particularly draws attentions\nto estimating the model from the low-rank recovery point of view. The survey\nmainly consists of three parts: the first part is a review on new factor\nestimations based on modern techniques on recovering low-rank structures of\nhigh-dimensional models. The second part discusses statistical inferences of\nseveral factor-augmented models and applications in econometric learning\nmodels. The final part summarizes new developments dealing with unbalanced\npanels from the matrix completion perspective.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 18:02:20 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Fan", "Jianqing", ""], ["Li", "Kunpeng", ""], ["Liao", "Yuan", ""]]}, {"id": "2009.10135", "submitter": "Silviu Maniu", "authors": "Silviu Maniu, Stratis Ioannidis, Bogdan Cautis", "title": "Bandits Under The Influence (Extended Version)", "comments": "27 pages, 4 figures, 6 tables. Extended version of accepted ICDM 2020\n  conference article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems should adapt to user interests as the latter evolve. A\nprevalent cause for the evolution of user interests is the influence of their\nsocial circle. In general, when the interests are not known, online algorithms\nthat explore the recommendation space while also exploiting observed\npreferences are preferable. We present online recommendation algorithms rooted\nin the linear multi-armed bandit literature. Our bandit algorithms are tailored\nprecisely to recommendation scenarios where user interests evolve under social\ninfluence. In particular, we show that our adaptations of the classic LinREL\nand Thompson Sampling algorithms maintain the same asymptotic regret bounds as\nin the non-social case. We validate our approach experimentally using both\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:02:00 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Maniu", "Silviu", ""], ["Ioannidis", "Stratis", ""], ["Cautis", "Bogdan", ""]]}, {"id": "2009.10149", "submitter": "Khaza Anuarul Hoque", "authors": "Gautam Raj Mode, Khaza Anuarul Hoque", "title": "Crafting Adversarial Examples for Deep Learning Based Prognostics\n  (Extended Version)", "comments": "This is the extended version of the paper \"Crafting Adversarial\n  Examples for Deep Learning Based Prognostics\" accepted for publication in the\n  IEEE International Conference on Machine Learning and Applications (ICMLA\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In manufacturing, unexpected failures are considered a primary operational\nrisk, as they can hinder productivity and can incur huge losses.\nState-of-the-art Prognostics and Health Management (PHM) systems incorporate\nDeep Learning (DL) algorithms and Internet of Things (IoT) devices to ascertain\nthe health status of equipment, and thus reduce the downtime, maintenance cost\nand increase the productivity. Unfortunately, IoT sensors and DL algorithms,\nboth are vulnerable to cyber attacks, and hence pose a significant threat to\nPHM systems. In this paper, we adopt the adversarial example crafting\ntechniques from the computer vision domain and apply them to the PHM domain.\nSpecifically, we craft adversarial examples using the Fast Gradient Sign Method\n(FGSM) and Basic Iterative Method (BIM) and apply them on the Long Short-Term\nMemory (LSTM), Gated Recurrent Unit (GRU), and Convolutional Neural Network\n(CNN) based PHM models. We evaluate the impact of adversarial attacks using\nNASA's turbofan engine dataset. The obtained results show that all the\nevaluated PHM models are vulnerable to adversarial attacks and can cause a\nserious defect in the remaining useful life estimation. The obtained results\nalso show that the crafted adversarial examples are highly transferable and may\ncause significant damages to PHM systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:43:38 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 15:26:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mode", "Gautam Raj", ""], ["Hoque", "Khaza Anuarul", ""]]}, {"id": "2009.10195", "submitter": "Nathan Ng", "authors": "Nathan Ng, Kyunghyun Cho, Marzyeh Ghassemi", "title": "SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving\n  Out-of-Domain Robustness", "comments": "16 pages, 8 figures, to be published in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that perform well on a training domain often fail to generalize to\nout-of-domain (OOD) examples. Data augmentation is a common method used to\nprevent overfitting and improve OOD generalization. However, in natural\nlanguage, it is difficult to generate new examples that stay on the underlying\ndata manifold. We introduce SSMBA, a data augmentation method for generating\nsynthetic training examples by using a pair of corruption and reconstruction\nfunctions to move randomly on a data manifold. We investigate the use of SSMBA\nin the natural language domain, leveraging the manifold assumption to\nreconstruct corrupted text with masked language models. In experiments on\nrobustness benchmarks across 3 tasks and 9 datasets, SSMBA consistently\noutperforms existing data augmentation methods and baseline models on both\nin-domain and OOD data, achieving gains of 0.8% accuracy on OOD Amazon reviews,\n1.8% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 German-English.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 22:02:33 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 22:47:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ng", "Nathan", ""], ["Cho", "Kyunghyun", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2009.10233", "submitter": "Boyuan Feng", "authors": "Boyuan Feng, Yuke Wang, Xu Li, and Yufei Ding", "title": "Scalable Adversarial Attack on Graph Neural Networks with Alternating\n  Direction Method of Multipliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved high performance in analyzing\ngraph-structured data and have been widely deployed in safety-critical areas,\nsuch as finance and autonomous driving. However, only a few works have explored\nGNNs' robustness to adversarial attacks, and their designs are usually limited\nby the scale of input datasets (i.e., focusing on small graphs with only\nthousands of nodes). In this work, we propose, SAG, the first scalable\nadversarial attack method with Alternating Direction Method of Multipliers\n(ADMM). We first decouple the large-scale graph into several smaller graph\npartitions and cast the original problem into several subproblems. Then, we\npropose to solve these subproblems using projected gradient descent on both the\ngraph topology and the node features that lead to considerably lower memory\nconsumption compared to the conventional attack methods. Rigorous experiments\nfurther demonstrate that SAG can significantly reduce the computation and\nmemory overhead compared with the state-of-the-art approach, making SAG\napplicable towards graphs with large size of nodes and edges.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:33:36 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Feng", "Boyuan", ""], ["Wang", "Yuke", ""], ["Li", "Xu", ""], ["Ding", "Yufei", ""]]}, {"id": "2009.10235", "submitter": "Boyuan Feng", "authors": "Boyuan Feng, Yuke Wang, Zheng Wang, and Yufei Ding", "title": "Uncertainty-aware Attention Graph Neural Network for Defending\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of graph-based learning, graph neural networks\n(GNNs) emerge as the essential tool for gaining insights from graphs. However,\nunlike the conventional CNNs that have been extensively explored and\nexhaustively tested, people are still worrying about the GNNs' robustness under\nthe critical settings, such as financial services. The main reason is that\nexisting GNNs usually serve as a black-box in predicting and do not provide the\nuncertainty on the predictions. On the other side, the recent advancement of\nBayesian deep learning on CNNs has demonstrated its success of quantifying and\nexplaining such uncertainties to fortify CNN models. Motivated by these\nobservations, we propose UAG, the first systematic solution to defend\nadversarial attacks on GNNs through identifying and exploiting hierarchical\nuncertainties in GNNs. UAG develops a Bayesian Uncertainty Technique (BUT) to\nexplicitly capture uncertainties in GNNs and further employs an\nUncertainty-aware Attention Technique (UAT) to defend adversarial attacks on\nGNNs. Intensive experiments show that our proposed defense approach outperforms\nthe state-of-the-art solutions by a significant margin.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:46:40 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Feng", "Boyuan", ""], ["Wang", "Yuke", ""], ["Wang", "Zheng", ""], ["Ding", "Yufei", ""]]}, {"id": "2009.10273", "submitter": "Yizhu Jiao", "authors": "Yizhu Jiao, Yun Xiong, Jiawei Zhang, Yao Zhang, Tianqi Zhang, Yangyong\n  Zhu", "title": "Sub-graph Contrast for Scalable Self-Supervised Graph Representation\n  Learning", "comments": "Best Student Paper Runner-up Award at ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has attracted lots of attention recently.\nExisting graph neural networks fed with the complete graph data are not\nscalable due to limited computation and memory costs. Thus, it remains a great\nchallenge to capture rich information in large-scale graph data. Besides, these\nmethods mainly focus on supervised learning and highly depend on node label\ninformation, which is expensive to obtain in the real world. As to unsupervised\nnetwork embedding approaches, they overemphasize node proximity instead, whose\nlearned representations can hardly be used in downstream application tasks\ndirectly. In recent years, emerging self-supervised learning provides a\npotential solution to address the aforementioned problems. However, existing\nself-supervised works also operate on the complete graph data and are biased to\nfit either global or very local (1-hop neighborhood) graph structures in\ndefining the mutual information based loss terms.\n  In this paper, a novel self-supervised representation learning method via\nSubgraph Contrast, namely \\textsc{Subg-Con}, is proposed by utilizing the\nstrong correlation between central nodes and their sampled subgraphs to capture\nregional structure information. Instead of learning on the complete input graph\ndata, with a novel data augmentation strategy, \\textsc{Subg-Con} learns node\nrepresentations through a contrastive loss defined based on subgraphs sampled\nfrom the original graph instead. Compared with existing graph representation\nlearning approaches, \\textsc{Subg-Con} has prominent performance advantages in\nweaker supervision requirements, model learning scalability, and\nparallelization. Extensive experiments verify both the effectiveness and the\nefficiency of our work compared with both classic and state-of-the-art graph\nrepresentation learning approaches on multiple real-world large-scale benchmark\ndatasets from different domains.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:58:19 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 06:45:16 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 06:32:34 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jiao", "Yizhu", ""], ["Xiong", "Yun", ""], ["Zhang", "Jiawei", ""], ["Zhang", "Yao", ""], ["Zhang", "Tianqi", ""], ["Zhu", "Yangyong", ""]]}, {"id": "2009.10301", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Stochastic Neighbor Embedding with Gaussian and Student-t Distributions:\n  Tutorial and Survey", "comments": "To appear as a part of an upcoming academic book on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Neighbor Embedding (SNE) is a manifold learning and dimensionality\nreduction method with a probabilistic approach. In SNE, every point is consider\nto be the neighbor of all other points with some probability and this\nprobability is tried to be preserved in the embedding space. SNE considers\nGaussian distribution for the probability in both the input and embedding\nspaces. However, t-SNE uses the Student-t and Gaussian distributions in these\nspaces, respectively. In this tutorial and survey paper, we explain SNE,\nsymmetric SNE, t-SNE (or Cauchy-SNE), and t-SNE with general degrees of\nfreedom. We also cover the out-of-sample extension and acceleration for these\nmethods. Some simulations to visualize the embeddings are also provided.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 03:32:05 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2009.10303", "submitter": "Ricardo Baptista", "authors": "Ricardo Baptista, Olivier Zahm, Youssef Marzouk", "title": "An adaptive transport framework for joint and conditional density\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework to robustly characterize joint and conditional\nprobability distributions via transport maps. Transport maps or \"flows\"\ndeterministically couple two distributions via an expressive monotone\ntransformation. Yet, learning the parameters of such transformations in high\ndimensions is challenging given few samples from the unknown target\ndistribution, and structural choices for these transformations can have a\nsignificant impact on performance. Here we formulate a systematic framework for\nrepresenting and learning monotone maps, via invertible transformations of\nsmooth functions, and demonstrate that the associated minimization problem has\na unique global optimum. Given a hierarchical basis for the appropriate\nfunction space, we propose a sample-efficient adaptive algorithm that estimates\na sparse approximation for the map. We demonstrate how this framework can learn\ndensities with stable generalization performance across a wide range of sample\nsizes on real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 03:41:45 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Baptista", "Ricardo", ""], ["Zahm", "Olivier", ""], ["Marzouk", "Youssef", ""]]}, {"id": "2009.10318", "submitter": "Yuanda Zhu", "authors": "Yuanda Zhu, Ying Sha, Hang Wu, Mai Li, Ryan A. Hoffman and May D. Wang", "title": "Public Health Informatics: Proposing Causal Sequence of Death Using\n  Neural Machine Translation", "comments": "11 pages, 8 figures, 8 tables. Updates: (1) Added Section II: Recent\n  Work (2) Added three accuracy evaluation criteria (3) Re-run experiments of\n  OpenNMT and updated the results and discussion in Section VI: Results and\n  Discussion (4) Finished FHIR mobile app and updated Section VII: FHIR\n  Interface (5) Revised Section VIII: Conclusion accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each year there are nearly 57 million deaths around the world, with over 2.7\nmillion in the United States. Timely, accurate and complete death reporting is\ncritical in public health, as institutions and government agencies rely on\ndeath reports to analyze vital statistics and to formulate responses to\ncommunicable diseases. Inaccurate death reporting may result in potential\nmisdirection of public health policies. Determining the causes of death is,\nnevertheless, challenging even for experienced physicians. To facilitate\nphysicians in accurately reporting causes of death, we present an advanced AI\napproach to determine a chronically ordered sequence of clinical conditions\nthat lead to death, based on decedent's last hospital discharge record. The\nsequence of clinical codes on the death report is named as causal chain of\ndeath, coded in the tenth revision of International Statistical Classification\nof Diseases (ICD-10); in line with the ICD-9-CM Official Guidelines for Coding\nand Reporting, the priority-ordered clinical conditions on the discharge record\nare coded in ICD-9. We identify three challenges in proposing the causal chain\nof death: two versions of coding system in clinical codes, medical domain\nknowledge conflict, and data interoperability. To overcome the first challenge\nin this sequence-to-sequence problem, we apply neural machine translation\nmodels to generate target sequence. Along with three accuracy metrics, we\nevaluate the quality of generated sequences with the BLEU (BiLingual Evaluation\nUnderstudy) score and achieve 16.04 out of 100. To address the second\nchallenge, we incorporate expert-verified medical domain knowledge as\nconstraint in generating output sequence to exclude infeasible causal chains.\nLastly, we demonstrate the usability of our work in a Fast Healthcare\nInteroperability Resources (FHIR) interface to address the third challenge.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 04:56:23 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 19:43:37 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Zhu", "Yuanda", ""], ["Sha", "Ying", ""], ["Wu", "Hang", ""], ["Li", "Mai", ""], ["Hoffman", "Ryan A.", ""], ["Wang", "May D.", ""]]}, {"id": "2009.10333", "submitter": "Aanchal Mongia", "authors": "Aanchal Mongia, Stuti Jain, Emilie Chouzenoux and Angshul Majumda", "title": "DeepVir -- Graphical Deep Matrix Factorization for \"In Silico\" Antiviral\n  Repositioning: Application to COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work formulates antiviral repositioning as a matrix completion problem\nwhere the antiviral drugs are along the rows and the viruses along the columns.\nThe input matrix is partially filled, with ones in positions where the\nantiviral has been known to be effective against a virus. The curated metadata\nfor antivirals (chemical structure and pathways) and viruses (genomic structure\nand symptoms) is encoded into our matrix completion framework as graph\nLaplacian regularization. We then frame the resulting multiple graph\nregularized matrix completion problem as deep matrix factorization. This is\nsolved by using a novel optimization method called HyPALM (Hybrid Proximal\nAlternating Linearized Minimization). Results on our curated RNA drug virus\nassociation (DVA) dataset shows that the proposed approach excels over\nstate-of-the-art graph regularized matrix completion techniques. When applied\nto \"in silico\" prediction of antivirals for COVID-19, our approach returns\nantivirals that are either used for treating patients or are under for trials\nfor the same.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 05:57:03 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mongia", "Aanchal", ""], ["Jain", "Stuti", ""], ["Chouzenoux", "Emilie", ""], ["Majumda", "Angshul", ""]]}, {"id": "2009.10337", "submitter": "Amin Babadi", "authors": "Amin Babadi, Michiel van de Panne, C. Karen Liu, Perttu\n  H\\\"am\\\"al\\\"ainen", "title": "Learning Task-Agnostic Action Spaces for Movement Optimization", "comments": "Accepted as a regular paper by IEEE Transactions on Visualization and\n  Computer Graphics (TVCG) in July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for exploring the dynamics of physically based\nanimated characters, and learning a task-agnostic action space that makes\nmovement optimization easier. Like several previous papers, we parameterize\nactions as target states, and learn a short-horizon goal-conditioned low-level\ncontrol policy that drives the agent's state towards the targets. Our novel\ncontribution is that with our exploration data, we are able to learn the\nlow-level policy in a generic manner and without any reference movement data.\nTrained once for each agent or simulation environment, the policy improves the\nefficiency of optimizing both trajectories and high-level policies across\nmultiple tasks and optimization algorithms. We also contribute novel\nvisualizations that show how using target states as actions makes optimized\ntrajectories more robust to disturbances; this manifests as wider optima that\nare easy to find. Due to its simplicity and generality, our proposed approach\nshould provide a building block that can improve a large variety of movement\noptimization methods and applications.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 06:18:56 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 13:48:13 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Babadi", "Amin", ""], ["van de Panne", "Michiel", ""], ["Liu", "C. Karen", ""], ["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""]]}, {"id": "2009.10343", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov and Dmitry Denisov", "title": "Gamma distribution-based sampling for imbalanced data", "comments": "Preprint of the paper that was published in Knowledge-Based Systems", "journal-ref": "Knowledge-Based Systems (2020)", "doi": "10.1016/j.knosys.2020.106368", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced class distribution is a common problem in a number of fields\nincluding medical diagnostics, fraud detection, and others. It causes bias in\nclassification algorithms leading to poor performance on the minority class\ndata. In this paper, we propose a novel method for balancing the class\ndistribution in data through intelligent resampling of the minority class\ninstances. The proposed method is based on generating new minority instances in\nthe neighborhood of the existing minority points via a gamma distribution. Our\nmethod offers a natural and coherent approach to balancing the data. We conduct\na comprehensive numerical analysis of the new sampling technique. The\nexperimental results show that the proposed method outperforms the existing\nstate-of-the-art methods for imbalanced data. Concretely, the new sampling\ntechnique produces the best results on 12 out of 24 real life as well as\nsynthetic datasets. For comparison, the SMOTE method achieves the top score on\nonly 1 dataset. We conclude that the new technique offers a simple yet\neffective sampling approach to balance data.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 06:39:13 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Kamalov", "Firuz", ""], ["Denisov", "Dmitry", ""]]}, {"id": "2009.10365", "submitter": "Diego Alvarez-Estevez", "authors": "Diego Alvarez-Estevez and Roselyne M. Rijsman", "title": "Inter-database validation of a deep learning approach for automatic\n  sleep scoring", "comments": "Original submission manuscript, 19 pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe a new deep learning approach for automatic sleep\nstaging, and carry out its validation by addressing its generalization\ncapabilities on a wide range of sleep staging databases. Prediction\ncapabilities are evaluated in the context of independent local and external\ngeneralization scenarios. Effectively, by comparing both procedures it is\npossible to better extrapolate the expected performance of the method on the\ngeneral reference task of sleep staging, regardless of data from a specific\ndatabase. In addition, we examine the suitability of a novel approach based on\nthe use of an ensemble of individual local models and evaluate its impact on\nthe resulting inter-database generalization performance. Validation results\nshow good general performance, as compared to the expected levels of human\nexpert agreement, as well as state-of-the-art automatic sleep staging\napproaches\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:46:43 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Alvarez-Estevez", "Diego", ""], ["Rijsman", "Roselyne M.", ""]]}, {"id": "2009.10367", "submitter": "Ping-En Lu", "authors": "Ping-En Lu and Cheng-Shang Chang", "title": "Explainable, Stable, and Scalable Graph Convolutional Networks for\n  Learning Graph Representation", "comments": "This manuscript was submitted to IEEE Transactions on Neural Networks\n  and Learning Systems (IEEE TNNLS) on September 22, 2020, and is being under\n  reviewed. This work was supported by the Ministry of Science and Technology\n  (MOST) of Taiwan (R.O.C.) under Project MOST108-2221-E007-016-MY3.\n  (Corresponding author: Ping-En Lu.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network embedding problem that maps nodes in a graph to vectors in\nEuclidean space can be very useful for addressing several important tasks on a\ngraph. Recently, graph neural networks (GNNs) have been proposed for solving\nsuch a problem. However, most embedding algorithms and GNNs are difficult to\ninterpret and do not scale well to handle millions of nodes. In this paper, we\ntackle the problem from a new perspective based on the equivalence of three\nconstrained optimization problems: the network embedding problem, the trace\nmaximization problem of the modularity matrix in a sampled graph, and the\nmatrix factorization problem of the modularity matrix in a sampled graph. The\noptimal solutions to these three problems are the dominant eigenvectors of the\nmodularity matrix. We proposed two algorithms that belong to a special class of\ngraph convolutional networks (GCNs) for solving these problems: (i) Clustering\nAs Feature Embedding GCN (CAFE-GCN) and (ii) sphere-GCN. Both algorithms are\nstable trace maximization algorithms, and they yield good approximations of\ndominant eigenvectors. Moreover, there are linear-time implementations for\nsparse graphs. In addition to solving the network embedding problem, both\nproposed GCNs are capable of performing dimensionality reduction. Various\nexperiments are conducted to evaluate our proposed GCNs and show that our\nproposed GCNs outperform almost all the baseline methods. Moreover, CAFE-GCN\ncould be benefited from the labeled data and have tremendous improvements in\nvarious performance metrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:49:46 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lu", "Ping-En", ""], ["Chang", "Cheng-Shang", ""]]}, {"id": "2009.10380", "submitter": "Md. Aminur Rab Ratul", "authors": "Md Aminur Rab Ratul, Maryam Tavakol Elahi, M. Hamed Mozaffari and\n  WonSook Lee", "title": "PS8-Net: A Deep Convolutional Neural Network to Predict the Eight-State\n  Protein Secondary Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Protein secondary structure is crucial to creating an information bridge\nbetween the primary and tertiary (3D) structures. Precise prediction of\neight-state protein secondary structure (PSS) has significantly utilized in the\nstructural and functional analysis of proteins in bioinformatics. Deep learning\ntechniques have been recently applied in this research area and raised the\neight-state (Q8) protein secondary structure prediction accuracy remarkably.\nNevertheless, from a theoretical standpoint, there are still lots of rooms for\nimprovement, specifically in the eight-state PSS prediction. In this study, we\nhave presented a new deep convolutional neural network (DCNN), namely PS8-Net,\nto enhance the accuracy of eight-class PSS prediction. The input of this\narchitecture is a carefully constructed feature matrix from the proteins\nsequence features and profile features. We introduce a new PS8 module in the\nnetwork, which is applied with skip connection to extracting the long-term\ninter-dependencies from higher layers, obtaining local contexts in earlier\nlayers, and achieving global information during secondary structure prediction.\nOur proposed PS8-Net achieves 76.89%, 71.94%, 76.86%, and 75.26% Q8 accuracy\nrespectively on benchmark CullPdb6133, CB513, CASP10, and CASP11 datasets. This\narchitecture enables the efficient processing of local and global\ninterdependencies between amino acids to make an accurate prediction of each\nclass. To the best of our knowledge, PS8-Net experiment results demonstrate\nthat it outperforms all the state-of-the-art methods on the aforementioned\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 08:19:10 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ratul", "Md Aminur Rab", ""], ["Elahi", "Maryam Tavakol", ""], ["Mozaffari", "M. Hamed", ""], ["Lee", "WonSook", ""]]}, {"id": "2009.10395", "submitter": "Ryan Cory-Wright", "authors": "Dimitris Bertsimas, Ryan Cory-Wright, Jean Pauphilet", "title": "Mixed-Projection Conic Optimization: A New Paradigm for Modeling Rank\n  Constraints", "comments": "major revision submitted to Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for modeling and solving low-rank optimization\nproblems to certifiable optimality. We introduce symmetric projection matrices\nthat satisfy $Y^2=Y$, the matrix analog of binary variables that satisfy\n$z^2=z$, to model rank constraints. By leveraging regularization and strong\nduality, we prove that this modeling paradigm yields tractable convex\noptimization problems over the non-convex set of orthogonal projection\nmatrices. Furthermore, we design outer-approximation algorithms to solve\nlow-rank problems to certifiable optimality, compute lower bounds via their\nsemidefinite relaxations, and provide near-optimal solutions through rounding\nand local search techniques. We implement these numerical ingredients and, for\nthe first time, solve low-rank optimization problems to certifiable optimality.\nUsing currently available spatial branch-and-bound codes, not tailored to\nprojection matrices, we can scale our exact (resp. near-exact) algorithms to\nmatrices with up to 30 (resp. 600) rows/columns. Our algorithms also supply\ncertifiably near-optimal solutions for larger problem sizes and outperform\nexisting heuristics, by deriving an alternative to the popular nuclear norm\nrelaxation which generalizes the perspective relaxation from vectors to\nmatrices. All in all, our framework, which we name Mixed-Projection Conic\nOptimization, solves low-rank problems to certifiable optimality in a tractable\nand unified fashion.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 08:59:06 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 20:45:08 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Cory-Wright", "Ryan", ""], ["Pauphilet", "Jean", ""]]}, {"id": "2009.10396", "submitter": "Fabrice Harel-Canada", "authors": "Kushagra Rastogi and Jonathan Lee and Fabrice Harel-Canada and Aditya\n  Joglekar", "title": "Is Q-Learning Provably Efficient? An Extended Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work extends the analysis of the theoretical results presented within\nthe paper Is Q-Learning Provably Efficient? by Jin et al. We include a survey\nof related research to contextualize the need for strengthening the theoretical\nguarantees related to perhaps the most important threads of model-free\nreinforcement learning. We also expound upon the reasoning used in the proofs\nto highlight the critical steps leading to the main result showing that\nQ-learning with UCB exploration achieves a sample efficiency that matches the\noptimal regret that can be achieved by any model-based approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 09:00:25 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Rastogi", "Kushagra", ""], ["Lee", "Jonathan", ""], ["Harel-Canada", "Fabrice", ""], ["Joglekar", "Aditya", ""]]}, {"id": "2009.10453", "submitter": "Daniel Hurtado", "authors": "Daniel Hurtado Ram\\'irez, J. M. Au\\~n\\'on", "title": "Privacy Preserving K-Means Clustering: A Secure Multi-Party Computation\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge discovery is one of the main goals of Artificial Intelligence. This\nKnowledge is usually stored in databases spread in different environments,\nbeing a tedious (or impossible) task to access and extract data from them. To\nthis difficulty we must add that these datasources may contain private data,\ntherefore the information can never leave the source. Privacy Preserving\nMachine Learning (PPML) helps to overcome this difficulty, employing\ncryptographic techniques, allowing knowledge discovery while ensuring data\nprivacy. K-means is one of the data mining techniques used in order to discover\nknowledge, grouping data points in clusters that contain similar features. This\npaper focuses in Privacy Preserving Machine Learning applied to K-means using\nrecent protocols from the field of criptography. The algorithm is applied to\ndifferent scenarios where data may be distributed either horizontally or\nvertically.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 11:19:24 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ram\u00edrez", "Daniel Hurtado", ""], ["Au\u00f1\u00f3n", "J. M.", ""]]}, {"id": "2009.10498", "submitter": "Weijian Luo", "authors": "Weijian Luo and Yongxian Long", "title": "ABM: an automatic supervised feature engineering method for loss based\n  models based on group and fused lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vital problem in solving classification or regression problem is to apply\nfeature engineering and variable selection on data before fed into models.One\nof a most popular feature engineering method is to discretisize continous\nvariable with some cutting points,which is refered to as bining processing.Good\ncutting points are important for improving model's ability, because wonderful\nbining may ignore some noisy variance in continous variable range and keep\nuseful leveled information with good ordered encodings.However, to our best\nknowledge a majority of cutting point selection is done via researchers domain\nknownledge or some naive methods like equal-width cutting or equal-frequency\ncutting.In this paper we propose an end-to-end supervised cutting point\nselection method based on group and fused lasso along with the automatically\nvariable selection effect.We name our method \\textbf{ABM}(automatic bining\nmachine). We firstly cut each variable range into fine grid bins and train\nmodel with our group and group fused lasso regularization on each successive\nbins.It is a method that integrates feature engineering,variable selection and\nmodel training simultanously.And one more inspiring thing is that the method is\nflexible such that it can be taken into a bunch of loss function based model\nincluding deep neural networks.We have also implemented the method in R and\nopen the source code to other researchers.A Python version will also meet the\ncommunity in days.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 12:42:22 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Luo", "Weijian", ""], ["Long", "Yongxian", ""]]}, {"id": "2009.10513", "submitter": "Nijat Mehdiyev", "authors": "Nijat Mehdiyev and Peter Fettke", "title": "Local Post-Hoc Explanations for Predictive Process Monitoring in\n  Manufacturing", "comments": "Accepted for publication in ECIS-2021 Proceedings (initial submission\n  November 18, 2020). This version is an extension of the previous arXiv\n  version", "journal-ref": "ECIS 2021 Research Papers. 35 (2021)\n  https://aisel.aisnet.org/ecis2021_rp/35", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an innovative explainable predictive quality analytics\nsolution to facilitate data-driven decision-making for process planning in\nmanufacturing by combining process mining, machine learning, and explainable\nartificial intelligence (XAI) methods. For this purpose, after integrating the\ntop-floor and shop-floor data obtained from various enterprise information\nsystems, a deep learning model was applied to predict the process outcomes.\nSince this study aims to operationalize the delivered predictive insights by\nembedding them into decision-making processes, it is essential to generate\nrelevant explanations for domain experts. To this end, two complementary local\npost-hoc explanation approaches, Shapley values and Individual Conditional\nExpectation (ICE) plots are adopted, which are expected to enhance the\ndecision-making capabilities by enabling experts to examine explanations from\ndifferent perspectives. After assessing the predictive strength of the applied\ndeep neural network with relevant binary classification evaluation measures, a\ndiscussion of the generated explanations is provided.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 13:07:17 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 08:58:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mehdiyev", "Nijat", ""], ["Fettke", "Peter", ""]]}, {"id": "2009.10524", "submitter": "Javad Hassannataj Joloudari", "authors": "Javad Hassannataj Joloudari, Mojtaba Haderbadi, Amir Mashmool,\n  Mohammad GhasemiGol, Shahab S., Amir Mosavi", "title": "Early detection of the advanced persistent threat attack using\n  performance analysis of deep learning", "comments": "38 pages, 15 figures, 5 tables", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3029202", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most common and important destructive attacks on the victim system\nis Advanced Persistent Threat (APT)-attack. The APT attacker can achieve his\nhostile goals by obtaining information and gaining financial benefits regarding\nthe infrastructure of a network. One of the solutions to detect a secret APT\nattack is using network traffic. Due to the nature of the APT attack in terms\nof being on the network for a long time and the fact that the network may crash\nbecause of high traffic, it is difficult to detect this type of attack. Hence,\nin this study, machine learning methods such as C5.0 decision tree, Bayesian\nnetwork and deep neural network are used for timely detection and\nclassification of APT-attacks on the NSL-KDD dataset. Moreover, 10-fold cross\nvalidation method is used to experiment these models. As a result, the accuracy\n(ACC) of the C5.0 decision tree, Bayesian network and 6-layer deep learning\nmodels is obtained as 95.64%, 88.37% and 98.85%, respectively, and also, in\nterms of the important criterion of the false positive rate (FPR), the FPR\nvalue for the C5.0 decision tree, Bayesian network and 6-layer deep learning\nmodels is obtained as 2.56, 10.47 and 1.13, respectively. Other criterions such\nas sensitivity, specificity, accuracy, false negative rate and F-measure are\nalso investigated for the models, and the experimental results show that the\ndeep learning model with automatic multi-layered extraction of features has the\nbest performance for timely detection of an APT-attack comparing to other\nclassification models.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:27:35 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Joloudari", "Javad Hassannataj", ""], ["Haderbadi", "Mojtaba", ""], ["Mashmool", "Amir", ""], ["GhasemiGol", "Mohammad", ""], ["S.", "Shahab", ""], ["Mosavi", "Amir", ""]]}, {"id": "2009.10526", "submitter": "Joong-Won Hwang", "authors": "Joong-Won Hwang, Youngwan Lee, Sungchan Oh, Yuseok Bae", "title": "Adversarial Training with Stochastic Weight Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training deep neural networks often experience serious\noverfitting problem. Recently, it is explained that the overfitting happens\nbecause the sample complexity of training data is insufficient to generalize\nrobustness. In traditional machine learning, one way to relieve overfitting\nfrom the lack of data is to use ensemble methods. However, adversarial training\nmultiple networks is extremely expensive. Moreover, we found that there is a\ndilemma on choosing target model to generate adversarial examples. Optimizing\nattack to the members of ensemble will be suboptimal attack to the ensemble and\nincurs covariate shift, while attack to ensemble will weaken the members and\nlose the benefit from ensembling. In this paper, we propose adversarial\ntraining with Stochastic weight average (SWA); while performing adversarial\ntraining, we aggregate the temporal weight states in the trajectory of\ntraining. By adopting SWA, the benefit of ensemble can be gained without\ntremendous computational increment and without facing the dilemma. Moreover, we\nfurther improved SWA to be adequate to adversarial training. The empirical\nresults on CIFAR-10, CIFAR-100 and SVHN show that our method can improve the\nrobustness of models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:47:20 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hwang", "Joong-Won", ""], ["Lee", "Youngwan", ""], ["Oh", "Sungchan", ""], ["Bae", "Yuseok", ""]]}, {"id": "2009.10537", "submitter": "Yaguan Qian", "authors": "Yaguan Qian, Qiqi Shao, Jiamin Wang, Xiang Lin, Yankai Guo, Zhaoquan\n  Gu, Bin Wang, Chunming Wu", "title": "EI-MTD:Moving Target Defense for Edge Intelligence against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the boom of edge intelligence, its vulnerability to adversarial attacks\nbecomes an urgent problem. The so-called adversarial example can fool a deep\nlearning model on the edge node to misclassify. Due to the property of\ntransferability, the adversary can easily make a black-box attack using a local\nsubstitute model. Nevertheless, the limitation of resource of edge nodes cannot\nafford a complicated defense mechanism as doing on the cloud data center. To\novercome the challenge, we propose a dynamic defense mechanism, namely EI-MTD.\nIt first obtains robust member models with small size through differential\nknowledge distillation from a complicated teacher model on the cloud data\ncenter. Then, a dynamic scheduling policy based on a Bayesian Stackelberg game\nis applied to the choice of a target model for service. This dynamic defense\ncan prohibit the adversary from selecting an optimal substitute model for\nblack-box attacks. Our experimental result shows that this dynamic scheduling\ncan effectively protect edge intelligence against adversarial attacks under the\nblack-box setting.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 09:04:18 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 02:44:15 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 01:13:39 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Qian", "Yaguan", ""], ["Shao", "Qiqi", ""], ["Wang", "Jiamin", ""], ["Lin", "Xiang", ""], ["Guo", "Yankai", ""], ["Gu", "Zhaoquan", ""], ["Wang", "Bin", ""], ["Wu", "Chunming", ""]]}, {"id": "2009.10562", "submitter": "Anjukan Kathirgamanathan", "authors": "Anjukan Kathirgamanathan, Kacper Twardowski, Eleni Mangina, Donal Finn", "title": "A Centralised Soft Actor Critic Deep Reinforcement Learning Approach to\n  District Demand Side Management through CityLearn", "comments": "Accepted for ACM BuildSys2020 RLEM'20 Workshop", "journal-ref": null, "doi": "10.1145/3427773.3427869", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising model-free and adaptive controller for\ndemand side management, as part of the future smart grid, at the district\nlevel. This paper presents the results of the algorithm that was submitted for\nthe CityLearn Challenge, which was hosted in early 2020 with the aim of\ndesigning and tuning a reinforcement learning agent to flatten and smooth the\naggregated curve of electrical demand of a district of diverse buildings. The\nproposed solution secured second place in the challenge using a centralised\n'Soft Actor Critic' deep reinforcement learning agent that was able to handle\ncontinuous action spaces. The controller was able to achieve an averaged score\nof 0.967 on the challenge dataset comprising of different buildings and\nclimates. This highlights the potential application of deep reinforcement\nlearning as a plug-and-play style controller, that is capable of handling\ndifferent climates and a heterogenous building stock, for district demand side\nmanagement of buildings.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:03:11 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kathirgamanathan", "Anjukan", ""], ["Twardowski", "Kacper", ""], ["Mangina", "Eleni", ""], ["Finn", "Donal", ""]]}, {"id": "2009.10588", "submitter": "Guozhang Chen", "authors": "Guozhang Chen, Cheng Kevin Qu, Pulin Gong", "title": "Anomalous diffusion dynamics of learning in deep neural networks", "comments": "10 pages, 8 figures, a new angle to unravel the learning dynamics of\n  SGD in DNNs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in deep neural networks (DNNs) is implemented through minimizing a\nhighly non-convex loss function, typically by a stochastic gradient descent\n(SGD) method. This learning process can effectively find good wide minima\nwithout being trapped in poor local ones. We present a novel account of how\nsuch effective deep learning emerges through the interactions of the SGD and\nthe geometrical structure of the loss landscape. Rather than being a normal\ndiffusion process (i.e. Brownian motion) as often assumed, we find that the SGD\nexhibits rich, complex dynamics when navigating through the loss landscape;\ninitially, the SGD exhibits anomalous superdiffusion, which attenuates\ngradually and changes to subdiffusion at long times when the solution is\nreached. Such learning dynamics happen ubiquitously in different DNNs such as\nResNet and VGG-like networks and are insensitive to batch size and learning\nrate. The anomalous superdiffusion process during the initial learning phase\nindicates that the motion of SGD along the loss landscape possesses\nintermittent, big jumps; this non-equilibrium property enables the SGD to\nescape from sharp local minima. By adapting the methods developed for studying\nenergy landscapes in complex physical systems, we find that such superdiffusive\nlearning dynamics are due to the interactions of the SGD and the fractal-like\nstructure of the loss landscape. We further develop a simple model to\ndemonstrate the mechanistic role of the fractal loss landscape in enabling the\nSGD to effectively find global minima. Our results thus reveal the\neffectiveness of deep learning from a novel perspective and have implications\nfor designing efficient deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:57:59 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 08:13:24 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chen", "Guozhang", ""], ["Qu", "Cheng Kevin", ""], ["Gong", "Pulin", ""]]}, {"id": "2009.10606", "submitter": "Yue Zhao", "authors": "Yue Zhao, Ryan A. Rossi, Leman Akoglu", "title": "Automating Outlier Detection via Meta-Learning", "comments": "21 pages. The code is available at http://github.com/yzhao062/MetaOD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an unsupervised outlier detection (OD) task on a new dataset, how can\nwe automatically select a good outlier detection method and its\nhyperparameter(s) (collectively called a model)? Thus far, model selection for\nOD has been a \"black art\"; as any model evaluation is infeasible due to the\nlack of (i) hold-out data with labels, and (ii) a universal objective function.\nIn this work, we develop the first principled data-driven approach to model\nselection for OD, called MetaOD, based on meta-learning. MetaOD capitalizes on\nthe past performances of a large body of detection models on existing outlier\ndetection benchmark datasets, and carries over this prior experience to\nautomatically select an effective model to be employed on a new dataset without\nusing any labels. To capture task similarity, we introduce specialized\nmeta-features that quantify outlying characteristics of a dataset. Through\ncomprehensive experiments, we show the effectiveness of MetaOD in selecting a\ndetection model that significantly outperforms the most popular outlier\ndetectors (e.g., LOF and iForest) as well as various state-of-the-art\nunsupervised meta-learners while being extremely fast. To foster\nreproducibility and further research on this new problem, we open-source our\nentire meta-learning system, benchmark environment, and testbed datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:14:45 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:44:35 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Zhao", "Yue", ""], ["Rossi", "Ryan A.", ""], ["Akoglu", "Leman", ""]]}, {"id": "2009.10610", "submitter": "Daniel Neider", "authors": "Igor Khmelnitsky, Daniel Neider, Rajarshi Roy, Beno\\^it Barbot,\n  Benedikt Bollig, Alain Finkel, Serge Haddad, Martin Leucker, Lina Ye", "title": "Property-Directed Verification of Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a property-directed approach to verifying recurrent\nneural networks (RNNs). To this end, we learn a deterministic finite automaton\nas a surrogate model from a given RNN using active automata learning. This\nmodel may then be analyzed using model checking as verification technique. The\nterm property-directed reflects the idea that our procedure is guided and\ncontrolled by the given property rather than performing the two steps\nseparately. We show that this not only allows us to discover small\ncounterexamples fast, but also to generalize them by pumping towards faulty\nflows hinting at the underlying error in the RNN.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:15:20 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Khmelnitsky", "Igor", ""], ["Neider", "Daniel", ""], ["Roy", "Rajarshi", ""], ["Barbot", "Beno\u00eet", ""], ["Bollig", "Benedikt", ""], ["Finkel", "Alain", ""], ["Haddad", "Serge", ""], ["Leucker", "Martin", ""], ["Ye", "Lina", ""]]}, {"id": "2009.10619", "submitter": "Chongshou Li Dr", "authors": "Chongshou Li, Brenda Cheang, Zhixing Luo and Andrew Lim", "title": "An Exponential Factorization Machine with Percentage Error Minimization\n  to Retail Sales Forecasting", "comments": "Accepted by ACM Transactions on Knowledge Discovery from Data (ACM\n  TKDD)", "journal-ref": "ACM Transactions on Knowledge Discovery from Data 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new approach to sales forecasting for new products with\nlong lead time but short product life cycle. These SKUs are usually sold for\none season only, without any replenishments. An exponential factorization\nmachine (EFM) sales forecast model is developed to solve this problem which not\nonly considers SKU attributes, but also pairwise interactions. The EFM model is\nsignificantly different from the original Factorization Machines (FM) from\ntwo-fold: (1) the attribute-level formulation for explanatory variables and (2)\nexponential formulation for the positive response variable. The attribute-level\nformation excludes infeasible intra-attribute interactions and results in more\nefficient feature engineering comparing with the conventional one-hot encoding,\nwhile the exponential formulation is demonstrated more effective than the\nlog-transformation for the positive but not skewed distributed responses. In\norder to estimate the parameters, percentage error squares (PES) and error\nsquares (ES) are minimized by a proposed adaptive batch gradient descent method\nover the training set. Real-world data provided by a footwear retailer in\nSingapore is used for testing the proposed approach. The forecasting\nperformance in terms of both mean absolute percentage error (MAPE) and mean\nabsolute error (MAE) compares favourably with not only off-the-shelf models but\nalso results reported by extant sales and demand forecasting studies. The\neffectiveness of the proposed approach is also demonstrated by two external\npublic datasets. Moreover, we prove the theoretical relationships between PES\nand ES minimization, and present an important property of the PES minimization\nfor regression models; that it trains models to underestimate data. This\nproperty fits the situation of sales forecasting where unit-holding cost is\nmuch greater than the unit-shortage cost.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:21:38 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Li", "Chongshou", ""], ["Cheang", "Brenda", ""], ["Luo", "Zhixing", ""], ["Lim", "Andrew", ""]]}, {"id": "2009.10622", "submitter": "TrungTin Nguyen", "authors": "TrungTin Nguyen, Hien D Nguyen, Faicel Chamroukhi and Geoffrey J\n  McLachlan", "title": "An $l_1$-oracle inequality for the Lasso in mixture-of-experts\n  regression models", "comments": "Corrected typos. Added new Section 4. Discussion and comparisons", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture-of-experts (MoE) models are a popular framework for modeling\nheterogeneity in data, for both regression and classification problems in\nstatistics and machine learning, due to their flexibility and the abundance of\nstatistical estimation and model choice tools. Such flexibility comes from\nallowing the mixture weights (or gating functions) in the MoE model to depend\non the explanatory variables, along with the experts (or component densities).\nThis permits the modeling of data arising from more complex data generating\nprocesses, compared to the classical finite mixtures and finite mixtures of\nregression models, whose mixing parameters are independent of the covariates.\nThe use of MoE models in a high-dimensional setting, when the number of\nexplanatory variables can be much larger than the sample size (i.e., $p\\gg n$),\nis challenging from a computational point of view, and in particular from a\ntheoretical point of view, where the literature is still lacking results in\ndealing with the curse of dimensionality, in both the statistical estimation\nand feature selection. We consider the finite mixture-of-experts model with\nsoft-max gating functions and Gaussian experts for high-dimensional regression\non heterogeneous data, and its $l_1$-regularized estimation via the Lasso. We\nfocus on the Lasso estimation properties rather than its feature selection\nproperties. We provide a lower bound on the regularization parameter of the\nLasso function that ensures an $l_1$-oracle inequality satisfied by the Lasso\nestimator according to the Kullback-Leibler loss.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:23:35 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 17:28:26 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Nguyen", "TrungTin", ""], ["Nguyen", "Hien D", ""], ["Chamroukhi", "Faicel", ""], ["McLachlan", "Geoffrey J", ""]]}, {"id": "2009.10623", "submitter": "Ferran Alet", "authors": "Ferran Alet, Maria Bauza, Kenji Kawaguchi, Nurullah Giray Kuru, Tomas\n  Lozano-Perez, Leslie Pack Kaelbling", "title": "Tailoring: encoding inductive biases by optimizing unsupervised\n  objectives at prediction time", "comments": "NeurIPS 2020 workshops on Interpretable Inductive Biases and\n  Meta-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From CNNs to attention mechanisms, encoding inductive biases into neural\nnetworks has been a fruitful source of improvement in machine learning. Adding\nauxiliary losses to the main objective function is a general way of encoding\nbiases that can help networks learn better representations. However, since\nauxiliary losses are minimized only on training data, they suffer from the same\ngeneralization gap as regular task losses. Moreover, by adding a term to the\nloss function, the model optimizes a different objective than the one we care\nabout. In this work we address both problems: first, we take inspiration from\ntransductive learning and note that, after receiving an input but before making\na prediction, we can fine-tune our networks on any unsupervised loss. We call\nthis process tailoring, because we customize the model to each input to ensure\nour prediction satisfies the inductive bias. Second, we formulate\nmeta-tailoring, a nested optimization similar to that in meta-learning, and\ntrain our models to perform well on the task objective after adapting them\nusing an unsupervised loss.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:26:24 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 00:43:24 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 18:43:40 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Alet", "Ferran", ""], ["Bauza", "Maria", ""], ["Kawaguchi", "Kenji", ""], ["Kuru", "Nurullah Giray", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "2009.10629", "submitter": "Kai Yang", "authors": "Kai Yang, Masoud Asgharian, Sahir Bhatnagar", "title": "Improving Convergence for Nonconvex Composite Programming", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional nonconvex problems are popular in today's machine learning\nand statistical genetics research. Recently, Ghadimi and Lan [1] proposed an\nalgorithm to optimize nonconvex high-dimensional problems. There are several\nparameters in their algorithm that are to be set before running the algorithm.\nIt is not trivial how to choose these parameters nor there is, to the best of\nour knowledge, an explicit rule on how to select the parameters to make the\nalgorithm converges faster. We analyze Ghadimi and Lan's algorithm to gain an\ninterpretation based on the inequality constraints for convergence and the\nupper bound for the norm of the gradient analogue. Our interpretation of their\nalgorithm suggests this to be a damped Nesterov's acceleration scheme. Based on\nthis, we propose an approach on how to select the parameters to improve\nconvergence of the algorithm. Our numerical studies using high-dimensional\nnonconvex sparse learning problems, motivated by image denoising and\nstatistical genetics applications, show that convergence can be made, on\naverage, considerably faster than that of the conventional ISTA algorithm for\nsuch optimization problems with over $10000$ variables should the parameters be\nchosen using our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:37:09 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 14:56:25 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yang", "Kai", ""], ["Asgharian", "Masoud", ""], ["Bhatnagar", "Sahir", ""]]}, {"id": "2009.10641", "submitter": "Jes\\'us Daniel Arroyo Reli\\'on", "authors": "Jes\\'us Arroyo, Elizaveta Levina", "title": "Overlapping community detection in networks via sparse spectral\n  decomposition", "comments": null, "journal-ref": null, "doi": "10.1007/s13171-021-00245-4", "report-no": null, "categories": "cs.SI cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating overlapping community memberships in a\nnetwork, where each node can belong to multiple communities. More than a few\ncommunities per node are difficult to both estimate and interpret, so we focus\non sparse node membership vectors. Our algorithm is based on sparse principal\nsubspace estimation with iterative thresholding. The method is computationally\nefficient, with a computational cost equivalent to estimating the leading\neigenvectors of the adjacency matrix, and does not require an additional\nclustering step, unlike spectral clustering methods. We show that a fixed point\nof the algorithm corresponds to correct node memberships under a version of the\nstochastic block model. The methods are evaluated empirically on simulated and\nreal-world networks, showing good statistical performance and computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:31:09 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 06:43:18 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Arroyo", "Jes\u00fas", ""], ["Levina", "Elizaveta", ""]]}, {"id": "2009.10644", "submitter": "Daniel Dunlavy", "authors": "Alexis Cooper and Xin Zhou and Scott Heidbrink and Daniel M. Dunlavy", "title": "Using Neural Architecture Search for Improving Software Flaw Detection\n  in Multimodal Deep Learning Models", "comments": "10 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": "SAND2020-10141R", "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software flaw detection using multimodal deep learning models has been\ndemonstrated as a very competitive approach on benchmark problems. In this\nwork, we demonstrate that even better performance can be achieved using neural\narchitecture search (NAS) combined with multimodal learning models. We adapt a\nNAS framework aimed at investigating image classification to the problem of\nsoftware flaw detection and demonstrate improved results on the Juliet Test\nSuite, a popular benchmarking data set for measuring performance of machine\nlearning models in this problem domain.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:59:21 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Cooper", "Alexis", ""], ["Zhou", "Xin", ""], ["Heidbrink", "Scott", ""], ["Dunlavy", "Daniel M.", ""]]}, {"id": "2009.10645", "submitter": "Chen Zhang", "authors": "Jie Guo, Hao Yan, Chen Zhang, Steven Hoi", "title": "Partially Observable Online Change Detection via Smooth-Sparse\n  Decomposition", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online change detection of high dimensional data streams with\nsparse changes, where only a subset of data streams can be observed at each\nsensing time point due to limited sensing capacities. On the one hand, the\ndetection scheme should be able to deal with partially observable data and\nmeanwhile have efficient detection power for sparse changes. On the other, the\nscheme should be able to adaptively and actively select the most important\nvariables to observe to maximize the detection power. To address these two\npoints, in this paper, we propose a novel detection scheme called CDSSD. In\nparticular, it describes the structure of high dimensional data with sparse\nchanges by smooth-sparse decomposition, whose parameters can be learned via\nspike-slab variational Bayesian inference. Then the posterior Bayes factor,\nwhich incorporates the learned parameters and sparse change information, is\nformulated as a detection statistic. Finally, by formulating the statistic as\nthe reward of a combinatorial multi-armed bandit problem, an adaptive sampling\nstrategy based on Thompson sampling is proposed. The efficacy and applicability\nof our method in practice are demonstrated with numerical studies and a real\ncase study.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:03:04 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Guo", "Jie", ""], ["Yan", "Hao", ""], ["Zhang", "Chen", ""], ["Hoi", "Steven", ""]]}, {"id": "2009.10670", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Vidya Muthukumar, Ji Xu", "title": "On the proliferation of support vectors in high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machine (SVM) is a well-established classification method\nwhose name refers to the particular training examples, called support vectors,\nthat determine the maximum margin separating hyperplane. The SVM classifier is\nknown to enjoy good generalization properties when the number of support\nvectors is small compared to the number of training examples. However, recent\nresearch has shown that in sufficiently high-dimensional linear classification\nproblems, the SVM can generalize well despite a proliferation of support\nvectors where all training examples are support vectors. In this paper, we\nidentify new deterministic equivalences for this phenomenon of support vector\nproliferation, and use them to (1) substantially broaden the conditions under\nwhich the phenomenon occurs in high-dimensional settings, and (2) prove a\nnearly matching converse result.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:45:06 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hsu", "Daniel", ""], ["Muthukumar", "Vidya", ""], ["Xu", "Ji", ""]]}, {"id": "2009.10683", "submitter": "Lin Chen", "authors": "Lin Chen, Sheng Xu", "title": "Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the reproducing kernel Hilbert spaces (RKHS) of a deep neural\ntangent kernel and the Laplace kernel include the same set of functions, when\nboth kernels are restricted to the sphere $\\mathbb{S}^{d-1}$. Additionally, we\nprove that the exponential power kernel with a smaller power (making the kernel\nless smooth) leads to a larger RKHS, when it is restricted to the sphere\n$\\mathbb{S}^{d-1}$ and when it is defined on the entire $\\mathbb{R}^d$.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:58:26 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 01:32:06 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 17:49:40 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 06:45:23 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 14:56:31 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Chen", "Lin", ""], ["Xu", "Sheng", ""]]}, {"id": "2009.10713", "submitter": "Stephan Wojtowytsch", "authors": "Weinan E, Chao Ma, Stephan Wojtowytsch and Lei Wu", "title": "Towards a Mathematical Understanding of Neural Network-Based Machine\n  Learning: what we know and what we don't", "comments": "Review article. Feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this article is to review the achievements made in the last\nfew years towards the understanding of the reasons behind the success and\nsubtleties of neural network-based machine learning. In the tradition of good\nold applied mathematics, we will not only give attention to rigorous\nmathematical results, but also the insight we have gained from careful\nnumerical experiments as well as the analysis of simplified models. Along the\nway, we also list the open problems which we believe to be the most important\ntopics for further study. This is not a complete overview over this quickly\nmoving field, but we hope to provide a perspective which may be helpful\nespecially to new researchers in the area.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 17:55:47 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 17:51:11 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 23:36:20 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wojtowytsch", "Stephan", ""], ["Wu", "Lei", ""]]}, {"id": "2009.10717", "submitter": "Margalit Glasgow", "authors": "Margalit Glasgow, Mary Wootters", "title": "Asynchronous Distributed Optimization with Stochastic Delays", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.09638", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asynchronous finite sum minimization in a distributed-data setting\nwith a central parameter server. While asynchrony is well understood in\nparallel settings where the data is accessible by all machines -- e.g.,\nmodifications of variance-reduced gradient algorithms like SAGA work well --\nlittle is known for the distributed-data setting. We develop an algorithm\nADSAGA based on SAGA for the distributed-data setting, in which the data is\npartitioned between many machines. We show that with $m$ machines, under a\nnatural stochastic delay model with an mean delay of $m$, ADSAGA converges in\n$\\tilde{O}\\left(\\left(n + \\sqrt{m}\\kappa\\right)\\log(1/\\epsilon)\\right)$\niterations, where $n$ is the number of component functions, and $\\kappa$ is a\ncondition number. This complexity sits squarely between the complexity\n$\\tilde{O}\\left(\\left(n + \\kappa\\right)\\log(1/\\epsilon)\\right)$ of SAGA\n\\textit{without delays} and the complexity $\\tilde{O}\\left(\\left(n +\nm\\kappa\\right)\\log(1/\\epsilon)\\right)$ of parallel asynchronous algorithms\nwhere the delays are \\textit{arbitrary} (but bounded by $O(m)$), and the data\nis accessible by all. Existing asynchronous algorithms with distributed-data\nsetting and arbitrary delays have only been shown to converge in\n$\\tilde{O}(n^2\\kappa\\log(1/\\epsilon))$ iterations. We empirically compare on\nleast-squares problems the iteration complexity and wallclock performance of\nADSAGA to existing parallel and distributed algorithms, including synchronous\nminibatch algorithms. Our results demonstrate the wallclock advantage of\nvariance-reduced asynchronous approaches over SGD or synchronous approaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 17:59:06 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 05:13:23 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 05:35:10 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Glasgow", "Margalit", ""], ["Wootters", "Mary", ""]]}, {"id": "2009.10748", "submitter": "Ziyi Chen", "authors": "Cheng Chen, Ziyi Chen, Yi Zhou, Bhavya Kailkhura", "title": "FedCluster: Boosting the Convergence of Federated Learning via\n  Cluster-Cycling", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop FedCluster--a novel federated learning framework with improved\noptimization efficiency, and investigate its theoretical convergence\nproperties. The FedCluster groups the devices into multiple clusters that\nperform federated learning cyclically in each learning round. Therefore, each\nlearning round of FedCluster consists of multiple cycles of meta-update that\nboost the overall convergence. In nonconvex optimization, we show that\nFedCluster with the devices implementing the local {stochastic gradient descent\n(SGD)} algorithm achieves a faster convergence rate than the conventional\n{federated averaging (FedAvg)} algorithm in the presence of device-level data\nheterogeneity. We conduct experiments on deep learning applications and\ndemonstrate that FedCluster converges significantly faster than the\nconventional federated learning under diverse levels of device-level data\nheterogeneity for a variety of local optimizers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 18:04:01 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Chen", "Cheng", ""], ["Chen", "Ziyi", ""], ["Zhou", "Yi", ""], ["Kailkhura", "Bhavya", ""]]}, {"id": "2009.10780", "submitter": "Tin Nguyen", "authors": "Tin D. Nguyen, Jonathan Huggins, Lorenzo Masoero, Lester Mackey,\n  Tamara Broderick", "title": "Independent finite approximations for Bayesian nonparametric inference", "comments": "Updated funding acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian nonparametric priors based on completely random measures (CRMs)\noffer a flexible modeling approach when the number of latent components in a\ndataset is unknown. However, managing the infinite dimensionality of CRMs\ntypically requires practitioners to derive ad-hoc algorithms, preventing the\nuse of general-purpose inference methods and often leading to long compute\ntimes. We propose a general but explicit recipe to construct a simple\nfinite-dimensional approximation that can replace the infinite-dimensional\nCRMs. Our independent finite approximation (IFA) is a generalization of\nimportant cases that are used in practice. The independence of atom weights in\nour approximation (i) makes the construction well-suited for parallel and\ndistributed computation and (ii) facilitates more convenient inference schemes.\nWe quantify the approximation error between IFAs and the target nonparametric\nprior. We compare IFAs with an alternative approximation scheme -- truncated\nfinite approximations (TFAs), where the atom weights are constructed\nsequentially. We prove that, for worst-case choices of observation likelihoods,\nTFAs are a more efficient approximation than IFAs. However, in real-data\nexperiments with image denoising and topic modeling, we find that IFAs perform\nvery similarly to TFAs in terms of task-specific accuracy metrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:37:21 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 20:33:53 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 22:36:57 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Nguyen", "Tin D.", ""], ["Huggins", "Jonathan", ""], ["Masoero", "Lorenzo", ""], ["Mackey", "Lester", ""], ["Broderick", "Tamara", ""]]}, {"id": "2009.10835", "submitter": "Morteza Haghir Chehreghani", "authors": "John Daniel Boss\\'er, Erik S\\\"orstadius, Morteza Haghir Chehreghani", "title": "Model-Centric and Data-Centric Aspects of Active Learning for Neural\n  Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study different data-centric and model-centric aspects of active learning\nwith neural network models. i) We investigate incremental and cumulative\ntraining modes that specify how the currently labeled data are used for\ntraining. ii) Neural networks are models with a large capacity. Thus, we study\nhow active learning depends on the number of epochs and neurons as well as the\nchoice of batch size. iii) We analyze in detail the behavior of query\nstrategies and their corresponding informativeness measures and accordingly\npropose more efficient querying and active learning paradigms. iv) We perform\nstatistical analyses, e.g., on actively learned classes and test error\nestimation, that reveal several insights about active learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 21:58:03 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 22:09:41 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Boss\u00e9r", "John Daniel", ""], ["S\u00f6rstadius", "Erik", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2009.10847", "submitter": "Mikhail Galkin", "authors": "Mikhail Galkin, Priyansh Trivedi, Gaurav Maheshwari, Ricardo Usbeck,\n  Jens Lehmann", "title": "Message Passing for Hyper-Relational Knowledge Graphs", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating\nadditional key-value pairs along with the main triple to disambiguate, or\nrestrict the validity of a fact. In this work, we propose a message passing\nbased graph encoder - StarE capable of modeling such hyper-relational KGs.\nUnlike existing approaches, StarE can encode an arbitrary number of additional\ninformation (qualifiers) along with the main triple while keeping the semantic\nroles of qualifiers and triples intact. We also demonstrate that existing\nbenchmarks for evaluating link prediction (LP) performance on hyper-relational\nKGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset\n- WD50K. Our experiments demonstrate that StarE based LP model outperforms\nexisting approaches across multiple benchmarks. We also confirm that leveraging\nqualifiers is vital for link prediction with gains up to 25 MRR points compared\nto triple-based representations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 22:38:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Galkin", "Mikhail", ""], ["Trivedi", "Priyansh", ""], ["Maheshwari", "Gaurav", ""], ["Usbeck", "Ricardo", ""], ["Lehmann", "Jens", ""]]}, {"id": "2009.10862", "submitter": "Jie Wang", "authors": "Jie Wang", "title": "An Intuitive Tutorial to Gaussian Processes Regression", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial aims to provide an intuitive understanding of the Gaussian\nprocesses regression. Gaussian processes regression (GPR) models have been\nwidely used in machine learning applications because of their representation\nflexibility and inherently uncertainty measures over predictions. The basic\nconcepts that a Gaussian process is built on, including multivariate normal\ndistribution, kernels, non-parametric models, joint and conditional probability\nwere explained first. Next, the GPR was described concisely together with an\nimplementation of a standard GPR algorithm. Beyond the standard GPR, packages\nto implement state-of-the-art Gaussian processes algorithms were reviewed. This\ntutorial was written in an accessible way to make sure readers without a\nmachine learning background can obtain a good understanding of the GPR basics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 23:57:30 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 17:47:30 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 01:55:41 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Jie", ""]]}, {"id": "2009.10867", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Yiming Ying, Steven Skiena", "title": "Online AUC Optimization for Sparse High-Dimensional Datasets", "comments": "20th IEEE International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Area Under the ROC Curve (AUC) is a widely used performance measure for\nimbalanced classification arising from many application domains where\nhigh-dimensional sparse data is abundant. In such cases, each $d$ dimensional\nsample has only $k$ non-zero features with $k \\ll d$, and data arrives\nsequentially in a streaming form. Current online AUC optimization algorithms\nhave high per-iteration cost $\\mathcal{O}(d)$ and usually produce non-sparse\nsolutions in general, and hence are not suitable for handling the data\nchallenge mentioned above.\n  In this paper, we aim to directly optimize the AUC score for high-dimensional\nsparse datasets under online learning setting and propose a new algorithm,\n\\textsc{FTRL-AUC}. Our proposed algorithm can process data in an online fashion\nwith a much cheaper per-iteration cost $\\mathcal{O}(k)$, making it amenable for\nhigh-dimensional sparse streaming data analysis. Our new algorithmic design\ncritically depends on a novel reformulation of the U-statistics AUC objective\nfunction as the empirical saddle point reformulation, and the innovative\nintroduction of the \"lazy update\" rule so that the per-iteration complexity is\ndramatically reduced from $\\mathcal{O}(d)$ to $\\mathcal{O}(k)$. Furthermore,\n\\textsc{FTRL-AUC} can inherently capture sparsity more effectively by applying\na generalized Follow-The-Regularized-Leader (FTRL) framework.\n  Experiments on real-world datasets demonstrate that \\textsc{FTRL-AUC}\nsignificantly improves both run time and model sparsity while achieving\ncompetitive AUC scores compared with the state-of-the-art methods. Comparison\nwith the online learning method for logistic loss demonstrates that\n\\textsc{FTRL-AUC} achieves higher AUC scores especially when datasets are\nimbalanced.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 00:50:01 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhou", "Baojian", ""], ["Ying", "Yiming", ""], ["Skiena", "Steven", ""]]}, {"id": "2009.10893", "submitter": "Najeeb Khan", "authors": "Najeeb Khan and Ian Stavness", "title": "Pruning Convolutional Filters using Batch Bridgeout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art computer vision models are rapidly increasing in capacity,\nwhere the number of parameters far exceeds the number required to fit the\ntraining set. This results in better optimization and generalization\nperformance. However, the huge size of contemporary models results in large\ninference costs and limits their use on resource-limited devices. In order to\nreduce inference costs, convolutional filters in trained neural networks could\nbe pruned to reduce the run-time memory and computational requirements during\ninference. However, severe post-training pruning results in degraded\nperformance if the training algorithm results in dense weight vectors. We\npropose the use of Batch Bridgeout, a sparsity inducing stochastic\nregularization scheme, to train neural networks so that they could be pruned\nefficiently with minimal degradation in performance. We evaluate the proposed\nmethod on common computer vision models VGGNet, ResNet, and Wide-ResNet on the\nCIFAR image classification task. For all the networks, experimental results\nshow that Batch Bridgeout trained networks achieve higher accuracy across a\nwide range of pruning intensities compared to Dropout and weight decay\nregularization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:51:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Khan", "Najeeb", ""], ["Stavness", "Ian", ""]]}, {"id": "2009.10897", "submitter": "Chloe Hsu", "authors": "Chloe Ching-Yun Hsu, Celestine Mendler-D\\\"unner, Moritz Hardt", "title": "Revisiting Design Choices in Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal Policy Optimization (PPO) is a popular deep policy gradient\nalgorithm. In standard implementations, PPO regularizes policy updates with\nclipped probability ratios, and parameterizes policies with either continuous\nGaussian distributions or discrete Softmax distributions. These design choices\nare widely accepted, and motivated by empirical performance comparisons on\nMuJoCo and Atari benchmarks.\n  We revisit these practices outside the regime of current benchmarks, and\nexpose three failure modes of standard PPO. We explain why standard design\nchoices are problematic in these cases, and show that alternative choices of\nsurrogate objectives and policy parameterizations can prevent the failure\nmodes. We hope that our work serves as a reminder that many algorithmic design\nchoices in reinforcement learning are tied to specific simulation environments.\nWe should not implicitly accept these choices as a standard part of a more\ngeneral algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 02:00:34 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hsu", "Chloe Ching-Yun", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Hardt", "Moritz", ""]]}, {"id": "2009.10951", "submitter": "Junshan Wang", "authors": "Junshan Wang, Guojie Song, Yi Wu, Liang Wang", "title": "Streaming Graph Neural Networks via Continual Learning", "comments": "10 pages, 4 figures, CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411963", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved strong performance in various\napplications. In the real world, network data is usually formed in a streaming\nfashion. The distributions of patterns that refer to neighborhood information\nof nodes may shift over time. The GNN model needs to learn the new patterns\nthat cannot yet be captured. But learning incrementally leads to the\ncatastrophic forgetting problem that historical knowledge is overwritten by\nnewly learned knowledge. Therefore, it is important to train GNN model to learn\nnew patterns and maintain existing patterns simultaneously, which few works\nfocus on. In this paper, we propose a streaming GNN model based on continual\nlearning so that the model is trained incrementally and up-to-date node\nrepresentations can be obtained at each time step. Firstly, we design an\napproximation algorithm to detect new coming patterns efficiently based on\ninformation propagation. Secondly, we combine two perspectives of data\nreplaying and model regularization for existing pattern consolidation.\nSpecially, a hierarchy-importance sampling strategy for nodes is designed and a\nweighted regularization term for GNN parameters is derived, achieving greater\nstability and generalization of knowledge consolidation. Our model is evaluated\non real and synthetic data sets and compared with multiple baselines. The\nresults of node classification prove that our model can efficiently update\nmodel parameters and achieve comparable performance to model retraining. In\naddition, we also conduct a case study on the synthetic data, and carry out\nsome specific analysis for each part of our model, illustrating its ability to\nlearn new knowledge and maintain existing knowledge from different\nperspectives.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 06:52:30 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 06:56:16 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Wang", "Junshan", ""], ["Song", "Guojie", ""], ["Wu", "Yi", ""], ["Wang", "Liang", ""]]}, {"id": "2009.10978", "submitter": "Wonseok Lee", "authors": "Wonseok Lee, Hanbit Lee, Sang-goo Lee", "title": "Semantics-Preserving Adversarial Training", "comments": "Preprint. Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a defense technique that improves adversarial\nrobustness of a deep neural network (DNN) by including adversarial examples in\nthe training data. In this paper, we identify an overlooked problem of\nadversarial training in that these adversarial examples often have different\nsemantics than the original data, introducing unintended biases into the model.\nWe hypothesize that such non-semantics-preserving (and resultingly ambiguous)\nadversarial data harm the robustness of the target models. To mitigate such\nunintended semantic changes of adversarial examples, we propose\nsemantics-preserving adversarial training (SPAT) which encourages perturbation\non the pixels that are shared among all classes when generating adversarial\nexamples in the training stage. Experiment results show that SPAT improves\nadversarial robustness and achieves state-of-the-art results in CIFAR-10 and\nCIFAR-100.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 07:42:14 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lee", "Wonseok", ""], ["Lee", "Hanbit", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2009.10989", "submitter": "Chin-Chia Michael Yeh", "authors": "Chin-Chia Michael Yeh, Dhruv Gelda, Zhongfang Zhuang, Yan Zheng, Liang\n  Gou, Wei Zhang", "title": "Towards a Flexible Embedding Learning Framework", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a fundamental building block for analyzing\nentities in a database. While the existing embedding learning methods are\neffective in various data mining problems, their applicability is often limited\nbecause these methods have pre-determined assumptions on the type of semantics\ncaptured by the learned embeddings, and the assumptions may not well align with\nspecific downstream tasks. In this work, we propose an embedding learning\nframework that 1) uses an input format that is agnostic to input data type, 2)\nis flexible in terms of the relationships that can be embedded into the learned\nrepresentations, and 3) provides an intuitive pathway to incorporate domain\nknowledge into the embedding learning process. Our proposed framework utilizes\na set of entity-relation-matrices as the input, which quantifies the affinities\namong different entities in the database. Moreover, a sampling mechanism is\ncarefully designed to establish a direct connection between the input and the\ninformation captured by the output embeddings. To complete the representation\nlearning toolbox, we also outline a simple yet effective post-processing\ntechnique to properly visualize the learned embeddings. Our empirical results\ndemonstrate that the proposed framework, in conjunction with a set of relevant\nentity-relation-matrices, outperforms the existing state-of-the-art approaches\nin various data mining tasks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:00:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Yeh", "Chin-Chia Michael", ""], ["Gelda", "Dhruv", ""], ["Zhuang", "Zhongfang", ""], ["Zheng", "Yan", ""], ["Gou", "Liang", ""], ["Zhang", "Wei", ""]]}, {"id": "2009.10990", "submitter": "Rohun Kshirsagar", "authors": "Rohun Kshirsagar, Li-Yen Hsu, Vatshank Chaturvedi, Charles H.\n  Greenberg, Matthew McClelland, Anushadevi Mohan, Wideet Shende, Nicolas P.\n  Tilmans, Renzo Frigato, Min Guo, Ankit Chheda, Meredith Trotter, Shonket Ray,\n  Arnold Lee, Miguel Alvarado", "title": "Accurate and Interpretable Machine Learning for Transparent Pricing of\n  Health Insurance Plans", "comments": "Accepted for publication in The Thirty-Fifth AAAI Conference on\n  Artificial Intelligence (AAAI-21), in the Innovative Applications of\n  Artificial Intelligence track. This is the extended version with some\n  stylistic fixes from the first posting and complete author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health insurance companies cover half of the United States population through\ncommercial employer-sponsored health plans and pay 1.2 trillion US dollars\nevery year to cover medical expenses for their members. The actuary and\nunderwriter roles at a health insurance company serve to assess which risks to\ntake on and how to price those risks to ensure profitability of the\norganization. While Bayesian hierarchical models are the current standard in\nthe industry to estimate risk, interest in machine learning as a way to improve\nupon these existing methods is increasing. Lumiata, a healthcare analytics\ncompany, ran a study with a large health insurance company in the United\nStates. We evaluated the ability of machine learning models to predict the per\nmember per month cost of employer groups in their next renewal period,\nespecially those groups who will cost less than 95\\% of what an actuarial model\npredicts (groups with \"concession opportunities\"). We developed a sequence of\ntwo models, an individual patient-level and an employer-group-level model, to\npredict the annual per member per month allowed amount for employer groups,\nbased on a population of 14 million patients. Our models performed 20\\% better\nthan the insurance carrier's existing pricing model, and identified 84\\% of the\nconcession opportunities. This study demonstrates the application of a machine\nlearning system to compute an accurate and fair price for health insurance\nproducts and analyzes how explainable machine learning models can exceed\nactuarial models' predictive accuracy while maintaining interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:07:33 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 22:47:22 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kshirsagar", "Rohun", ""], ["Hsu", "Li-Yen", ""], ["Chaturvedi", "Vatshank", ""], ["Greenberg", "Charles H.", ""], ["McClelland", "Matthew", ""], ["Mohan", "Anushadevi", ""], ["Shende", "Wideet", ""], ["Tilmans", "Nicolas P.", ""], ["Frigato", "Renzo", ""], ["Guo", "Min", ""], ["Chheda", "Ankit", ""], ["Trotter", "Meredith", ""], ["Ray", "Shonket", ""], ["Lee", "Arnold", ""], ["Alvarado", "Miguel", ""]]}, {"id": "2009.10991", "submitter": "Darshana Priyasad Madduma Kankanamalage Don Mr", "authors": "Darshana Priyasad, Tharindu Fernando, Simon Denman, Clinton Fookes,\n  Sridha Sridharan", "title": "Attention Driven Fusion for Multi-Modal Emotion Recognition", "comments": "An updated version of the ICASSP 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a powerful alternative to hand-crafted methods\nfor emotion recognition on combined acoustic and text modalities. Baseline\nsystems model emotion information in text and acoustic modes independently\nusing Deep Convolutional Neural Networks (DCNN) and Recurrent Neural Networks\n(RNN), followed by applying attention, fusion, and classification. In this\npaper, we present a deep learning-based approach to exploit and fuse text and\nacoustic data for emotion classification. We utilize a SincNet layer, based on\nparameterized sinc functions with band-pass filters, to extract acoustic\nfeatures from raw audio followed by a DCNN. This approach learns filter banks\ntuned for emotion recognition and provides more effective features compared to\ndirectly applying convolutions over the raw speech signal. For text processing,\nwe use two branches (a DCNN and a Bi-direction RNN followed by a DCNN) in\nparallel where cross attention is introduced to infer the N-gram level\ncorrelations on hidden representations received from the Bi-RNN. Following\nexisting state-of-the-art, we evaluate the performance of the proposed system\non the IEMOCAP dataset. Experimental results indicate that the proposed system\noutperforms existing methods, achieving 3.5% improvement in weighted accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:07:58 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 22:25:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Priyasad", "Darshana", ""], ["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["Fookes", "Clinton", ""], ["Sridharan", "Sridha", ""]]}, {"id": "2009.11054", "submitter": "Islem Rekik", "authors": "Islem Mhiri, Mohamed Ali Mahjoub and Islem Rekik", "title": "Supervised Multi-topology Network Cross-diffusion for Population-driven\n  Brain Network Atlas Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating a representative and discriminative brain network atlas (BNA) is a\nnascent research field in mapping a population of brain networks in health and\ndisease. Although limited, existing BNA estimation methods have several\nlimitations. First, they primarily rely on a similarity network diffusion and\nfusion technique, which only considers node degree as a topological measure in\nthe cross-network diffusion process, thereby overlooking rich topological\nmeasures of the brain network (e.g., centrality). Second, both diffusion and\nfusion techniques are implemented in fully unsupervised manner, which might\ndecrease the discriminative power of the estimated BNAs. To fill these gaps, we\npropose a supervised multi-topology network cross-diffusion (SM-netFusion)\nframework for estimating a BNA satisfying : (i) well-representativeness\n(captures shared traits across subjects), (ii) well-centeredness (optimally\nclose to all subjects), and (iii) high discriminativeness (can easily and\nefficiently identify discriminative brain connections that distinguish between\ntwo populations). For a specific class, given the cluster labels of the\ntraining data, we learn a weighted combination of the topological diffusion\nkernels derived from degree, closeness and eigenvector centrality measures in a\nsupervised manner. Specifically, we learn the cross-diffusion process by\nnormalizing the training brain networks using the learned diffusion kernels.\nOur SM-netFusion produces the most centered and representative template in\ncomparison with its variants and state-of-the-art methods and further boosted\nthe classification of autistic subjects by 5-15%. SM-netFusion presents the\nfirst work for supervised network cross-diffusion based on graph topological\nmeasures, which can be further leveraged to design an efficient graph feature\nselection method for training predictive learners in network neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:17:41 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Mhiri", "Islem", ""], ["Mahjoub", "Mohamed Ali", ""], ["Rekik", "Islem", ""]]}, {"id": "2009.11058", "submitter": "Islem Rekik", "authors": "Alaa Bessadok, Mohamed Ali Mahjoub and Islem Rekik", "title": "Topology-Aware Generative Adversarial Network for Joint Prediction of\n  Multiple Brain Graphs from a Single Brain Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works based on Generative Adversarial Networks (GAN) have been\nrecently proposed to predict a set of medical images from a single modality\n(e.g, FLAIR MRI from T1 MRI). However, such frameworks are primarily designed\nto operate on images, limiting their generalizability to non-Euclidean\ngeometric data such as brain graphs. While a growing number of connectomic\nstudies has demonstrated the promise of including brain graphs for diagnosing\nneurological disorders, no geometric deep learning work was designed for\nmultiple target brain graphs prediction from a source brain graph. Despite the\nmomentum the field of graph generation has gained in the last two years,\nexisting works have two critical drawbacks. First, the bulk of such works aims\nto learn one model for each target domain to generate from a source domain.\nThus, they have a limited scalability in jointly predicting multiple target\ndomains. Second, they merely consider the global topological scale of a graph\n(i.e., graph connectivity structure) and overlook the local topology at the\nnode scale of a graph (e.g., how central a node is in the graph). To meet these\nchallenges, we introduce MultiGraphGAN architecture, which not only predicts\nmultiple brain graphs from a single brain graph but also preserves the\ntopological structure of each target graph to predict. Its three core\ncontributions lie in: (i) designing a graph adversarial auto-encoder for\njointly predicting brain graphs from a single one, (ii) handling the mode\ncollapse problem of GAN by clustering the encoded source graphs and proposing a\ncluster-specific decoder, (iii) introducing a topological loss to force the\nreconstruction of topologically sound target brain graphs. Our MultiGraphGAN\nsignificantly outperformed its variants thereby showing its great potential in\nmulti-view brain graph generation from a single graph.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:23:08 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Bessadok", "Alaa", ""], ["Mahjoub", "Mohamed Ali", ""], ["Rekik", "Islem", ""]]}, {"id": "2009.11087", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Shalmali Joshi, Marzyeh Ghassemi, and Rajesh Ranganath", "title": "Probabilistic Machine Learning for Healthcare", "comments": "Annual Reviews of Biomedical Data Science 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning can be used to make sense of healthcare data. Probabilistic\nmachine learning models help provide a complete picture of observed data in\nhealthcare. In this review, we examine how probabilistic machine learning can\nadvance healthcare. We consider challenges in the predictive model building\npipeline where probabilistic models can be beneficial including calibration and\nmissing data. Beyond predictive models, we also investigate the utility of\nprobabilistic machine learning models in phenotyping, in generative models for\nclinical use cases, and in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:14:05 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Chen", "Irene Y.", ""], ["Joshi", "Shalmali", ""], ["Ghassemi", "Marzyeh", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2009.11094", "submitter": "Tianle Cai", "authors": "Jingtong Su, Yihang Chen, Tianle Cai, Tianhao Wu, Ruiqi Gao, Liwei\n  Wang, Jason D. Lee", "title": "Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot", "comments": "Accepted by NeurIPS 2020. Code available at\n  https://github.com/JingtongSu/sanity-checking-pruning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning is a method for reducing test-time computational resource\nrequirements with minimal performance degradation. Conventional wisdom of\npruning algorithms suggests that: (1) Pruning methods exploit information from\ntraining data to find good subnetworks; (2) The architecture of the pruned\nnetwork is crucial for good performance. In this paper, we conduct sanity\nchecks for the above beliefs on several recent unstructured pruning methods and\nsurprisingly find that: (1) A set of methods which aims to find good\nsubnetworks of the randomly-initialized network (which we call \"initial\ntickets\"), hardly exploits any information from the training data; (2) For the\npruned networks obtained by these methods, randomly changing the preserved\nweights in each layer, while keeping the total number of preserved weights\nunchanged per layer, does not affect the final performance. These findings\ninspire us to choose a series of simple \\emph{data-independent} prune ratios\nfor each layer, and randomly prune each layer accordingly to get a subnetwork\n(which we call \"random tickets\"). Experimental results show that our zero-shot\nrandom tickets outperform or attain a similar performance compared to existing\n\"initial tickets\". In addition, we identify one existing pruning method that\npasses our sanity checks. We hybridize the ratios in our random ticket with\nthis method and propose a new method called \"hybrid tickets\", which achieves\nfurther improvement. (Our code is publicly available at\nhttps://github.com/JingtongSu/sanity-checking-pruning)\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 17:36:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 13:23:09 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Su", "Jingtong", ""], ["Chen", "Yihang", ""], ["Cai", "Tianle", ""], ["Wu", "Tianhao", ""], ["Gao", "Ruiqi", ""], ["Wang", "Liwei", ""], ["Lee", "Jason D.", ""]]}, {"id": "2009.11116", "submitter": "Vahid Shahrivari", "authors": "Vahid Shahrivari, Mohammad Mahdi Darabi, Mohammad Izadi", "title": "Phishing Detection Using Machine Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has become an indispensable part of our life, However, It also\nhas provided opportunities to anonymously perform malicious activities like\nPhishing. Phishers try to deceive their victims by social engineering or\ncreating mock-up websites to steal information such as account ID, username,\npassword from individuals and organizations. Although many methods have been\nproposed to detect phishing websites, Phishers have evolved their methods to\nescape from these detection methods. One of the most successful methods for\ndetecting these malicious activities is Machine Learning. This is because most\nPhishing attacks have some common characteristics which can be identified by\nmachine learning methods. In this paper, we compared the results of multiple\nmachine learning methods for predicting phishing websites.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 11:52:52 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Shahrivari", "Vahid", ""], ["Darabi", "Mohammad Mahdi", ""], ["Izadi", "Mohammad", ""]]}, {"id": "2009.11119", "submitter": "Qi Qin", "authors": "Qi Qin, Wenpeng Hu, Bing Liu", "title": "Text Classification with Novelty Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of detecting novel or unexpected instances in\ntext classification. In traditional text classification, the classes appeared\nin testing must have been seen in training. However, in many applications, this\nis not the case because in testing, we may see unexpected instances that are\nnot from any of the training classes. In this paper, we propose a significantly\nmore effective approach that converts the original problem to a pair-wise\nmatching problem and then outputs how probable two instances belong to the same\nclass. Under this approach, we present two models. The more effective model\nuses two embedding matrices of a pair of instances as two channels of a CNN.\nThe output probabilities from such pairs are used to judge whether a test\ninstance is from a seen class or is novel/unexpected. Experimental results show\nthat the proposed method substantially outperforms the state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:54:34 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Qin", "Qi", ""], ["Hu", "Wenpeng", ""], ["Liu", "Bing", ""]]}, {"id": "2009.11128", "submitter": "Konstantinos Nikolaidis", "authors": "Konstantinos Nikolaidis, Thomas Plagemann, Stein Kristiansen, Vera\n  Goebel, Mohan Kankanhalli", "title": "Using Under-trained Deep Ensembles to Learn Under Extreme Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improper or erroneous labelling can pose a hindrance to reliable\ngeneralization for supervised learning. This can have negative consequences,\nespecially for critical fields such as healthcare. We propose an effective new\napproach for learning under extreme label noise, based on under-trained deep\nensembles. Each ensemble member is trained with a subset of the training data,\nto acquire a general overview of the decision boundary separation, without\nfocusing on potentially erroneous details. The accumulated knowledge of the\nensemble is combined to form new labels, that determine a better class\nseparation than the original labels. A new model is trained with these labels\nto generalize reliably despite the label noise. We focus on a healthcare\nsetting and extensively evaluate our approach on the task of sleep apnea\ndetection. For comparison with related work, we additionally evaluate on the\ntask of digit recognition. In our experiments, we observed performance\nimprovement in accuracy from 6.7\\% up-to 49.3\\% for the task of digit\nclassification and in kappa from 0.02 up-to 0.55 for the task of sleep apnea\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:12:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Nikolaidis", "Konstantinos", ""], ["Plagemann", "Thomas", ""], ["Kristiansen", "Stein", ""], ["Goebel", "Vera", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2009.11162", "submitter": "Benoit Dherin", "authors": "David G.T. Barrett and Benoit Dherin", "title": "Implicit Gradient Regularization", "comments": null, "journal-ref": "Published as a conference paper at ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent can be surprisingly good at optimizing deep neural networks\nwithout overfitting and without explicit regularization. We find that the\ndiscrete steps of gradient descent implicitly regularize models by penalizing\ngradient descent trajectories that have large loss gradients. We call this\nImplicit Gradient Regularization (IGR) and we use backward error analysis to\ncalculate the size of this regularization. We confirm empirically that implicit\ngradient regularization biases gradient descent toward flat minima, where test\nerrors are small and solutions are robust to noisy parameter perturbations.\nFurthermore, we demonstrate that the implicit gradient regularization term can\nbe used as an explicit regularizer, allowing us to control this gradient\nregularization directly. More broadly, our work indicates that backward error\nanalysis is a useful theoretical approach to the perennial question of how\nlearning rate, model size, and parameter regularization interact to determine\nthe properties of overparameterized models optimized with gradient descent.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 14:17:53 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 12:27:21 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Barrett", "David G. T.", ""], ["Dherin", "Benoit", ""]]}, {"id": "2009.11218", "submitter": "Kalina Jasinska-Kobus", "authors": "Kalina Jasinska-Kobus, Marek Wydmuch, Krzysztof Dembczynski, Mikhail\n  Kuznetsov, Robert Busa-Fekete", "title": "Probabilistic Label Trees for Extreme Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification (XMLC) is a learning task of tagging\ninstances with a small subset of relevant labels chosen from an extremely large\npool of possible labels. Problems of this scale can be efficiently handled by\norganizing labels as a tree, like in hierarchical softmax used for multi-class\nproblems. In this paper, we thoroughly investigate probabilistic label trees\n(PLTs) which can be treated as a generalization of hierarchical softmax for\nmulti-label problems. We first introduce the PLT model and discuss training and\ninference procedures and their computational costs. Next, we prove the\nconsistency of PLTs for a wide spectrum of performance metrics. To this end, we\nupperbound their regret by a function of surrogate-loss regrets of node\nclassifiers. Furthermore, we consider a problem of training PLTs in a fully\nonline setting, without any prior knowledge of training instances, their\nfeatures, or labels. In this case, both node classifiers and the tree structure\nare trained online. We prove a specific equivalence between the fully online\nalgorithm and an algorithm with a tree structure given in advance. Finally, we\ndiscuss several implementations of PLTs and introduce a new one, napkinXC,\nwhich we empirically evaluate and compare with state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:30:00 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jasinska-Kobus", "Kalina", ""], ["Wydmuch", "Marek", ""], ["Dembczynski", "Krzysztof", ""], ["Kuznetsov", "Mikhail", ""], ["Busa-Fekete", "Robert", ""]]}, {"id": "2009.11222", "submitter": "Zitao Liu", "authors": "Wentao Wang, Guowei Xu, Wenbiao Ding, Gale Yan Huang, Guoliang Li,\n  Jiliang Tang and Zitao Liu", "title": "Representation Learning from Limited Educational Data with Crowdsourced\n  Labels", "comments": "IEEE Transactions on Knowledge and Data Engineering (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning has been proven to play an important role in the\nunprecedented success of machine learning models in numerous tasks, such as\nmachine translation, face recognition and recommendation. The majority of\nexisting representation learning approaches often require a large number of\nconsistent and noise-free labels. However, due to various reasons such as\nbudget constraints and privacy concerns, labels are very limited in many\nreal-world scenarios. Directly applying standard representation learning\napproaches on small labeled data sets will easily run into over-fitting\nproblems and lead to sub-optimal solutions. Even worse, in some domains such as\neducation, the limited labels are usually annotated by multiple workers with\ndiverse expertise, which yields noises and inconsistency in such crowdsourcing\nsettings. In this paper, we propose a novel framework which aims to learn\neffective representations from limited data with crowdsourced labels.\nSpecifically, we design a grouping based deep neural network to learn\nembeddings from a limited number of training samples and present a Bayesian\nconfidence estimator to capture the inconsistency among crowdsourced labels.\nFurthermore, to expedite the training process, we develop a hard example\nselection procedure to adaptively pick up training examples that are\nmisclassified by the model. Extensive experiments conducted on three real-world\ndata sets demonstrate the superiority of our framework on learning\nrepresentations from limited data with crowdsourced labels, comparing with\nvarious state-of-the-art baselines. In addition, we provide a comprehensive\nanalysis on each of the main components of our proposed framework and also\nintroduce the promising results it achieved in our real production to fully\nunderstand the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:34:40 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wang", "Wentao", ""], ["Xu", "Guowei", ""], ["Ding", "Wenbiao", ""], ["Huang", "Gale Yan", ""], ["Li", "Guoliang", ""], ["Tang", "Jiliang", ""], ["Liu", "Zitao", ""]]}, {"id": "2009.11239", "submitter": "Siamak Mehrkanoon", "authors": "Ismail Alaoui Abdellaoui and Siamak Mehrkanoon", "title": "Deep multi-stations weather forecasting: explainable recurrent\n  convolutional neural networks", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep learning applied to weather forecasting has started gaining popularity\nbecause of the progress achieved by data-driven models. The present paper\ncompares two different deep learning architectures to perform weather\nprediction on daily data gathered from 18 cities across Europe and spanned over\na period of 15 years. We propose the Deep Attention Unistream Multistream\n(DAUM) networks that investigate different types of input representations (i.e.\ntensorial unistream vs. multistream ) as well as the incorporation of the\nattention mechanism. In particular, we show that adding a self-attention block\nwithin the models increases the overall forecasting performance. Furthermore,\nvisualization techniques such as occlusion analysis and score maximization are\nused to give an additional insight on the most important features and cities\nfor predicting a particular target feature of target cities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 16:22:25 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 14:09:25 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 12:55:24 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 22:09:20 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 15:42:35 GMT"}, {"version": "v6", "created": "Wed, 10 Feb 2021 00:05:10 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Abdellaoui", "Ismail Alaoui", ""], ["Mehrkanoon", "Siamak", ""]]}, {"id": "2009.11243", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, C. Daniel Freeman, Ben Poole, Jascha\n  Sohl-Dickstein", "title": "Tasks, stability, architecture, and compute: Training more effective\n  learned optimizers, and using them to train themselves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much as replacing hand-designed features with learned functions has\nrevolutionized how we solve perceptual tasks, we believe learned algorithms\nwill transform how we train models. In this work we focus on general-purpose\nlearned optimizers capable of training a wide variety of problems with no\nuser-specified hyperparameters. We introduce a new, neural network\nparameterized, hierarchical optimizer with access to additional features such\nas validation loss to enable automatic regularization. Most learned optimizers\nhave been trained on only a single task, or a small number of tasks. We train\nour optimizers on thousands of tasks, making use of orders of magnitude more\ncompute, resulting in optimizers that generalize better to unseen tasks. The\nlearned optimizers not only perform well, but learn behaviors that are distinct\nfrom existing first order optimizers. For instance, they generate update steps\nthat have implicit regularization and adapt as the problem hyperparameters\n(e.g. batch size) or architecture (e.g. neural network width) change. Finally,\nthese learned optimizers show evidence of being useful for out of distribution\ntasks such as training themselves from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 16:35:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Freeman", "C. Daniel", ""], ["Poole", "Ben", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2009.11248", "submitter": "Swanand Kadhe", "authors": "Swanand Kadhe, Nived Rajaraman, O. Ozan Koyluoglu, Kannan Ramchandran", "title": "FastSecAgg: Scalable Secure Aggregation for Privacy-Preserving Federated\n  Learning", "comments": "Shorter version accepted in ICML Workshop on Federated Learning, July\n  2020, and CCS Workshop on Privacy-Preserving Machine Learning in Practice,\n  November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent attacks on federated learning demonstrate that keeping the training\ndata on clients' devices does not provide sufficient privacy, as the model\nparameters shared by clients can leak information about their training data. A\n'secure aggregation' protocol enables the server to aggregate clients' models\nin a privacy-preserving manner. However, existing secure aggregation protocols\nincur high computation/communication costs, especially when the number of model\nparameters is larger than the number of clients participating in an iteration\n-- a typical scenario in federated learning.\n  In this paper, we propose a secure aggregation protocol, FastSecAgg, that is\nefficient in terms of computation and communication, and robust to client\ndropouts. The main building block of FastSecAgg is a novel multi-secret sharing\nscheme, FastShare, based on the Fast Fourier Transform (FFT), which may be of\nindependent interest. FastShare is information-theoretically secure, and\nachieves a trade-off between the number of secrets, privacy threshold, and\ndropout tolerance. Riding on the capabilities of FastShare, we prove that\nFastSecAgg is (i) secure against the server colluding with 'any' subset of some\nconstant fraction (e.g. $\\sim10\\%$) of the clients in the honest-but-curious\nsetting; and (ii) tolerates dropouts of a 'random' subset of some constant\nfraction (e.g. $\\sim10\\%$) of the clients. FastSecAgg achieves significantly\nsmaller computation cost than existing schemes while achieving the same\n(orderwise) communication cost. In addition, it guarantees security against\nadaptive adversaries, which can perform client corruptions dynamically during\nthe execution of the protocol.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 16:49:02 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kadhe", "Swanand", ""], ["Rajaraman", "Nived", ""], ["Koyluoglu", "O. Ozan", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2009.11253", "submitter": "Henry Kvinge", "authors": "Henry Kvinge, Zachary New, Nico Courts, Jung H. Lee, Lauren A.\n  Phillips, Courtney D. Corley, Aaron Tuor, Andrew Avila, Nathan O. Hodas", "title": "Fuzzy Simplicial Networks: A Topology-Inspired Model to Improve Task\n  Generalization in Few-shot Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown great success in settings with massive amounts of\ndata but has struggled when data is limited. Few-shot learning algorithms,\nwhich seek to address this limitation, are designed to generalize well to new\ntasks with limited data. Typically, models are evaluated on unseen classes and\ndatasets that are defined by the same fundamental task as they are trained for\n(e.g. category membership). One can also ask how well a model can generalize to\nfundamentally different tasks within a fixed dataset (for example: moving from\ncategory membership to tasks that involve detecting object orientation or\nquantity). To formalize this kind of shift we define a notion of \"independence\nof tasks\" and identify three new sets of labels for established computer vision\ndatasets that test a model's ability to generalize to tasks which draw on\northogonal attributes in the data. We use these datasets to investigate the\nfailure modes of metric-based few-shot models. Based on our findings, we\nintroduce a new few-shot model called Fuzzy Simplicial Networks (FSN) which\nleverages a construction from topology to more flexibly represent each class\nfrom limited data. In particular, FSN models can not only form multiple\nrepresentations for a given class but can also begin to capture the\nlow-dimensional structure which characterizes class manifolds in the encoded\nspace of deep networks. We show that FSN outperforms state-of-the-art models on\nthe challenging tasks we introduce in this paper while remaining competitive on\nstandard few-shot benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:01:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kvinge", "Henry", ""], ["New", "Zachary", ""], ["Courts", "Nico", ""], ["Lee", "Jung H.", ""], ["Phillips", "Lauren A.", ""], ["Corley", "Courtney D.", ""], ["Tuor", "Aaron", ""], ["Avila", "Andrew", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "2009.11282", "submitter": "Yuxin Chen", "authors": "Yanxi Chen, Cong Ma, H. Vincent Poor, Yuxin Chen", "title": "Learning Mixtures of Low-Rank Models", "comments": null, "journal-ref": "IEEE Transactions on Information Theory, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning mixtures of low-rank models, i.e.\nreconstructing multiple low-rank matrices from unlabelled linear measurements\nof each. This problem enriches two widely studied settings -- low-rank matrix\nsensing and mixed linear regression -- by bringing latent variables (i.e.\nunknown labels) and structural priors (i.e. low-rank structures) into\nconsideration. To cope with the non-convexity issues arising from unlabelled\nheterogeneous data and low-complexity structure, we develop a three-stage\nmeta-algorithm that is guaranteed to recover the unknown matrices with\nnear-optimal sample and computational complexities under Gaussian designs. In\naddition, the proposed algorithm is provably stable against random noise. We\ncomplement the theoretical studies with empirical evidence that confirms the\nefficacy of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:53:48 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 21:36:55 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Chen", "Yanxi", ""], ["Ma", "Cong", ""], ["Poor", "H. Vincent", ""], ["Chen", "Yuxin", ""]]}, {"id": "2009.11285", "submitter": "Kazuma Tsuji", "authors": "Kazuma Tsuji and Taiji Suzuki", "title": "Estimation error analysis of deep learning on the regression problem on\n  the variable exponent Besov space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved notable success in various fields, including image\nand speech recognition. One of the factors in the successful performance of\ndeep learning is its high feature extraction ability. In this study, we focus\non the adaptivity of deep learning; consequently, we treat the variable\nexponent Besov space, which has a different smoothness depending on the input\nlocation $x$. In other words, the difficulty of the estimation is not uniform\nwithin the domain. We analyze the general approximation error of the variable\nexponent Besov space and the approximation and estimation errors of deep\nlearning. We note that the improvement based on adaptivity is remarkable when\nthe region upon which the target function has less smoothness is small and the\ndimension is large. Moreover, the superiority to linear estimators is shown\nwith respect to the convergence rate of the estimation error.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:56:24 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 13:55:47 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 14:14:45 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2021 14:23:53 GMT"}, {"version": "v5", "created": "Thu, 25 Mar 2021 15:23:23 GMT"}, {"version": "v6", "created": "Wed, 31 Mar 2021 13:24:34 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Tsuji", "Kazuma", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2009.11330", "submitter": "Farzana Beente Yusuf", "authors": "Farzana Beente Yusuf, Vitalii Stebliankin, Giuseppe Vietri, Giri\n  Narasimhan", "title": "Cache Replacement as a MAB with Delayed Feedback and Decaying Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the cache replacement problem, we propose and solve a new variant\nof the well-known multi-armed bandit (MAB), thus providing a solution for\nimproving existing state-of-the-art cache management methods. Each arm (or\nexpert) represents a distinct cache replacement policy, which advises on the\npage to evict from the cache when needed. Feedback on the eviction comes in the\nform of a \"miss\", but at an indeterminate time after the action is taken, and\nthe cost of the eviction is set to be inversely proportional to the response\ntime. The feedback is ignored if it comes after a threshold value for the\ndelay, which we set to be equal to the size of the page eviction history. Thus,\nfor delays beyond the threshold, its cost is assumed to be zero. Consequently,\nwe call this problem with delayed feedback and decaying costs. We introduce an\nadaptive reinforcement learning algorithm EXP4-DFDC that provides a solution to\nthe problem. We derive an optimal learning rate for EXP4-DFDC that defines the\nbalance between exploration and exploitation and proves theoretically that the\nexpected regret of our algorithm is a vanishing quantity as a function of time.\nAs an application, we show that LeCaR, a recent top-performing machine learning\nalgorithm for cache replacement, can be enhanced with adaptive learning using\nour formulations. We present an improved adaptive version of LeCaR, called\nOLeCaR, with the learning rate set as determined by the theoretical derivation\npresented here to minimize regret for EXP4-DFDC. It then follows that LeCaR and\nOLeCaR are theoretically guaranteed to have vanishing regret over time.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 18:26:48 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 04:46:15 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 16:52:38 GMT"}, {"version": "v4", "created": "Wed, 19 May 2021 04:32:39 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Yusuf", "Farzana Beente", ""], ["Stebliankin", "Vitalii", ""], ["Vietri", "Giuseppe", ""], ["Narasimhan", "Giri", ""]]}, {"id": "2009.11347", "submitter": "Ivan Letteri", "authors": "Ivan Letteri, Antonio Di Cecco, Giuseppe Della Penna", "title": "Dataset Optimization Strategies for MalwareTraffic Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is rapidly becoming one of the most important technology for\nmalware traffic detection, since the continuous evolution of malware requires a\nconstant adaptation and the ability to generalize. However, network traffic\ndatasets are usually oversized and contain redundant and irrelevant\ninformation, and this may dramatically increase the computational cost and\ndecrease the accuracy of most classifiers, with the risk to introduce further\nnoise.\n  We propose two novel dataset optimization strategies which exploit and\ncombine several state-of-the-art approaches in order to achieve an effective\noptimization of the network traffic datasets used to train malware detectors.\nThe first approach is a feature selection technique based on mutual information\nmeasures and sensibility enhancement. The second is a dimensional reduction\ntechnique based autoencoders. Both these approaches have been experimentally\napplied on the MTA-KDD'19 dataset, and the optimized results evaluated and\ncompared using a Multi Layer Perceptron as machine learning model for malware\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:27:22 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Letteri", "Ivan", ""], ["Di Cecco", "Antonio", ""], ["Della Penna", "Giuseppe", ""]]}, {"id": "2009.11348", "submitter": "Krishna Chaitanya Kalagarla", "authors": "Krishna C. Kalagarla, Rahul Jain, Pierluigi Nuzzo", "title": "A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Markov Decision Processes (CMDPs) formalize sequential\ndecision-making problems whose objective is to minimize a cost function while\nsatisfying constraints on various cost functions. In this paper, we consider\nthe setting of episodic fixed-horizon CMDPs. We propose an online algorithm\nwhich leverages the linear programming formulation of finite-horizon CMDP for\nrepeated optimistic planning to provide a probably approximately correct (PAC)\nguarantee on the number of episodes needed to ensure an $\\epsilon$-optimal\npolicy, i.e., with resulting objective value within $\\epsilon$ of the optimal\nvalue and satisfying the constraints within $\\epsilon$-tolerance, with\nprobability at least $1-\\delta$. The number of episodes needed is shown to be\nof the order\n$\\tilde{\\mathcal{O}}\\big(\\frac{|S||A|C^{2}H^{2}}{\\epsilon^{2}}\\log\\frac{1}{\\delta}\\big)$,\nwhere $C$ is the upper bound on the number of possible successor states for a\nstate-action pair. Therefore, if $C \\ll |S|$, the number of episodes needed\nhave a linear dependence on the state and action space sizes $|S|$ and $|A|$,\nrespectively, and quadratic dependence on the time horizon $H$.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:30:46 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kalagarla", "Krishna C.", ""], ["Jain", "Rahul", ""], ["Nuzzo", "Pierluigi", ""]]}, {"id": "2009.11353", "submitter": "Konstantin Avrachenkov", "authors": "Konstantin Avrachenkov, Andrei Bobu, Maximilien Dreveton", "title": "Higher-Order Spectral Clustering for Geometric Graphs", "comments": "23 pages, 6 figures", "journal-ref": "Journal of Fourier Analysis and Applications, 27:22, 2021", "doi": "10.1007/s00041-021-09825-2", "report-no": null, "categories": "cs.LG cs.SI math.PR math.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The present paper is devoted to clustering geometric graphs. While the\nstandard spectral clustering is often not effective for geometric graphs, we\npresent an effective generalization, which we call higher-order spectral\nclustering. It resembles in concept the classical spectral clustering method\nbut uses for partitioning the eigenvector associated with a higher-order\neigenvalue. We establish the weak consistency of this algorithm for a wide\nclass of geometric graphs which we call Soft Geometric Block Model. A small\nadjustment of the algorithm provides strong consistency. We also show that our\nmethod is effective in numerical experiments even for graphs of modest size.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:51:55 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 16:57:43 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Avrachenkov", "Konstantin", ""], ["Bobu", "Andrei", ""], ["Dreveton", "Maximilien", ""]]}, {"id": "2009.11355", "submitter": "Yasmin Salehi", "authors": "Kian Ahrabian, Aarash Feizi, Yasmin Salehi, William L. Hamilton and\n  Avishek Joey Bose", "title": "Structure Aware Negative Sampling in Knowledge Graphs", "comments": "Accepted to EMNLP 2020. Camera-ready submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning low-dimensional representations for entities and relations in\nknowledge graphs using contrastive estimation represents a scalable and\neffective method for inferring connectivity patterns. A crucial aspect of\ncontrastive learning approaches is the choice of corruption distribution that\ngenerates hard negative samples, which force the embedding model to learn\ndiscriminative representations and find critical characteristics of observed\ndata. While earlier methods either employ too simple corruption distributions,\ni.e. uniform, yielding easy uninformative negatives or sophisticated\nadversarial distributions with challenging optimization schemes, they do not\nexplicitly incorporate known graph structure resulting in suboptimal negatives.\nIn this paper, we propose Structure Aware Negative Sampling (SANS), an\ninexpensive negative sampling strategy that utilizes the rich graph structure\nby selecting negative samples from a node's k-hop neighborhood. Empirically, we\ndemonstrate that SANS finds semantically meaningful negatives and is\ncompetitive with SOTA approaches while requires no additional parameters nor\ndifficult adversarial optimization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:57:00 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 02:23:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Ahrabian", "Kian", ""], ["Feizi", "Aarash", ""], ["Salehi", "Yasmin", ""], ["Hamilton", "William L.", ""], ["Bose", "Avishek Joey", ""]]}, {"id": "2009.11359", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Xuchan Bao, Laurent Lessard, Roger Grosse", "title": "A Unified Analysis of First-Order Methods for Smooth Games via Integral\n  Quadratic Constraints", "comments": "Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of integral quadratic constraints (IQCs) allows the certification\nof exponential convergence of interconnected systems containing nonlinear or\nuncertain elements. In this work, we adapt the IQC theory to study first-order\nmethods for smooth and strongly-monotone games and show how to design tailored\nquadratic constraints to get tight upper bounds of convergence rates. Using\nthis framework, we recover the existing bound for the gradient method~(GD),\nderive sharper bounds for the proximal point method~(PPM) and optimistic\ngradient method~(OG), and provide \\emph{for the first time} a global\nconvergence rate for the negative momentum method~(NM) with an iteration\ncomplexity $\\mathcal{O}(\\kappa^{1.5})$, which matches its known lower bound. In\naddition, for time-varying systems, we prove that the gradient method with\noptimal step size achieves the fastest provable worst-case convergence rate\nwith quadratic Lyapunov functions. Finally, we further extend our analysis to\nstochastic games and study the impact of multiplicative noise on different\nalgorithms. We show that it is impossible for an algorithm with one step of\nmemory to achieve acceleration if it only queries the gradient once per batch\n(in contrast with the stochastic strongly-convex optimization setting, where\nsuch acceleration has been demonstrated). However, we exhibit an algorithm\nwhich achieves acceleration with two gradient queries per batch.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 20:02:00 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 00:58:13 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 05:48:47 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 00:53:41 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Zhang", "Guodong", ""], ["Bao", "Xuchan", ""], ["Lessard", "Laurent", ""], ["Grosse", "Roger", ""]]}, {"id": "2009.11360", "submitter": "Duy Minh Ho Nguyen", "authors": "Thu Nguyen, Duy H. M. Nguyen, Huy Nguyen, Binh T. Nguyen, Bruce A.\n  Wade", "title": "EPEM: Efficient Parameter Estimation for Multiple Class Monotone Missing\n  Data", "comments": "version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of monotone missing data has been broadly studied during the last\ntwo decades and has many applications in different fields such as\nbioinformatics or statistics. Commonly used imputation techniques require\nmultiple iterations through the data before yielding convergence. Moreover,\nthose approaches may introduce extra noises and biases to the subsequent\nmodeling. In this work, we derive exact formulas and propose a novel algorithm\nto compute the maximum likelihood estimators (MLEs) of a multiple class,\nmonotone missing dataset when all the covariance matrices of all categories are\nassumed to be equal, namely EPEM. We then illustrate an application of our\nproposed methods in Linear Discriminant Analysis (LDA). As the computation is\nexact, our EPEM algorithm does not require multiple iterations through the data\nas other imputation approaches, thus promising to handle much less\ntime-consuming than other methods. This effectiveness was validated by\nempirical results when EPEM reduced the error rates significantly and required\na short computation time compared to several imputation-based approaches. We\nalso release all codes and data of our experiments in one GitHub repository to\ncontribute to the research community related to this problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 20:07:53 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Nguyen", "Thu", ""], ["Nguyen", "Duy H. M.", ""], ["Nguyen", "Huy", ""], ["Nguyen", "Binh T.", ""], ["Wade", "Bruce A.", ""]]}, {"id": "2009.11397", "submitter": "Matthias Rottmann", "authors": "Matthias Rottmann, Kira Maag, Mathis Peyron, Natasa Krejic and Hanno\n  Gottschalk", "title": "Detection of Iterative Adversarial Attacks via Counter Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have proven to be powerful tools for processing\nunstructured data. However for high-dimensional data, like images, they are\ninherently vulnerable to adversarial attacks. Small almost invisible\nperturbations added to the input can be used to fool DNNs. Various attacks,\nhardening methods and detection methods have been introduced in recent years.\nNotoriously, Carlini-Wagner (CW) type attacks computed by iterative\nminimization belong to those that are most difficult to detect. In this work we\noutline a mathematical proof that the CW attack can be used as a detector\nitself. That is, under certain assumptions and in the limit of attack\niterations this detector provides asymptotically optimal separation of original\nand attacked images. In numerical experiments, we experimentally validate this\nstatement and furthermore obtain AUROC values up to 99.73% on CIFAR10 and\nImageNet. This is in the upper part of the spectrum of current state-of-the-art\ndetection rates for CW attacks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 21:54:36 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 14:21:02 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Rottmann", "Matthias", ""], ["Maag", "Kira", ""], ["Peyron", "Mathis", ""], ["Krejic", "Natasa", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "2009.11405", "submitter": "Chen Zhao", "authors": "Chen Zhao, Feng Chen", "title": "Rank-Based Multi-task Learning for Fair Regression", "comments": "2019 IEEE International Conference on Data Mining (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a novel fairness learning approach for multi-task\nregression models based on a biased training dataset, using a popular\nrank-based non-parametric independence test, i.e., Mann Whitney U statistic,\nfor measuring the dependency between target variable and protected variables.\nTo solve this learning problem efficiently, we first reformulate the problem as\na new non-convex optimization problem, in which a non-convex constraint is\ndefined based on group-wise ranking functions of individual objects. We then\ndevelop an efficient model-training algorithm based on the framework of\nnon-convex alternating direction method of multipliers (NC-ADMM), in which one\nof the main challenges is to implement an efficient projection oracle to the\npreceding non-convex set defined based on ranking functions. Through the\nextensive experiments on both synthetic and real-world datasets, we validated\nthe out-performance of our new approach against several state-of-the-art\ncompetitive methods on several popular metrics relevant to fairness learning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:32:57 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhao", "Chen", ""], ["Chen", "Feng", ""]]}, {"id": "2009.11406", "submitter": "Chen Zhao", "authors": "Chen Zhao, Feng Chen", "title": "Unfairness Discovery and Prevention For Few-Shot Regression", "comments": "2020 IEEE International Conference on Knowledge Graph (ICKG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fairness in supervised few-shot meta-learning models that are\nsensitive to discrimination (or bias) in historical data. A machine learning\nmodel trained based on biased data tends to make unfair predictions for users\nfrom minority groups. Although this problem has been studied before, existing\nmethods mainly aim to detect and control the dependency effect of the protected\nvariables (e.g. race, gender) on target prediction based on a large amount of\ntraining data. These approaches carry two major drawbacks that (1) lacking\nshowing a global cause-effect visualization for all variables; (2) lacking\ngeneralization of both accuracy and fairness to unseen tasks. In this work, we\nfirst discover discrimination from data using a causal Bayesian knowledge graph\nwhich not only demonstrates the dependency of the protected variable on target\nbut also indicates causal effects between all variables. Next, we develop a\nnovel algorithm based on risk difference in order to quantify the\ndiscriminatory influence for each protected variable in the graph. Furthermore,\nto protect prediction from unfairness, a fast-adapted bias-control approach in\nmeta-learning is proposed, which efficiently mitigates statistical disparity\nfor each task and it thus ensures independence of protected attributes on\npredictions based on biased and few-shot data samples. Distinct from existing\nmeta-learning models, group unfairness of tasks are efficiently reduced by\nleveraging the mean difference between (un)protected groups for regression\nproblems. Through extensive experiments on both synthetic and real-world data\nsets, we demonstrate that our proposed unfairness discovery and prevention\napproaches efficiently detect discrimination and mitigate biases on model\noutput as well as generalize both accuracy and fairness to unseen tasks with a\nlimited amount of training samples.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:34:06 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhao", "Chen", ""], ["Chen", "Feng", ""]]}, {"id": "2009.11416", "submitter": "Prashnna Gyawali", "authors": "Prashnna Kumar Gyawali, Sandesh Ghimire, Linwei Wang", "title": "Enhancing Mixup-based Semi-Supervised Learning with Explicit Lipschitz\n  Regularization", "comments": "A shorter version of this work will appear in the ICDM 2020\n  conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The success of deep learning relies on the availability of large-scale\nannotated data sets, the acquisition of which can be costly, requiring expert\ndomain knowledge. Semi-supervised learning (SSL) mitigates this challenge by\nexploiting the behavior of the neural function on large unlabeled data. The\nsmoothness of the neural function is a commonly used assumption exploited in\nSSL. A successful example is the adoption of mixup strategy in SSL that\nenforces the global smoothness of the neural function by encouraging it to\nbehave linearly when interpolating between training examples. Despite its\nempirical success, however, the theoretical underpinning of how mixup\nregularizes the neural function has not been fully understood. In this paper,\nwe offer a theoretically substantiated proposition that mixup improves the\nsmoothness of the neural function by bounding the Lipschitz constant of the\ngradient function of the neural networks. We then propose that this can be\nstrengthened by simultaneously constraining the Lipschitz constant of the\nneural function itself through adversarial Lipschitz regularization,\nencouraging the neural function to behave linearly while also constraining the\nslope of this linear function. On three benchmark data sets and one real-world\nbiomedical data set, we demonstrate that this combined regularization results\nin improved generalization performance of SSL when learning from a small amount\nof labeled data. We further demonstrate the robustness of the presented method\nagainst single-step adversarial attacks. Our code is available at\nhttps://github.com/Prasanna1991/Mixup-LR.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 23:19:19 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Gyawali", "Prashnna Kumar", ""], ["Ghimire", "Sandesh", ""], ["Wang", "Linwei", ""]]}, {"id": "2009.11428", "submitter": "Shiqing Yu", "authors": "Shiqing Yu, Mathias Drton, Ali Shojaie", "title": "Generalized Score Matching for General Domains", "comments": "50 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of density functions supported on general domains arises when the\ndata is naturally restricted to a proper subset of the real space. This problem\nis complicated by typically intractable normalizing constants. Score matching\nprovides a powerful tool for estimating densities with such intractable\nnormalizing constants, but as originally proposed is limited to densities on\n$\\mathbb{R}^m$ and $\\mathbb{R}_+^m$. In this paper, we offer a natural\ngeneralization of score matching that accommodates densities supported on a\nvery general class of domains. We apply the framework to truncated graphical\nand pairwise interaction models, and provide theoretical guarantees for the\nresulting estimators. We also generalize a recently proposed method from\nbounded to unbounded domains, and empirically demonstrate the advantages of our\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 00:53:04 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Yu", "Shiqing", ""], ["Drton", "Mathias", ""], ["Shojaie", "Ali", ""]]}, {"id": "2009.11469", "submitter": "Hongwei Zhang", "authors": "Hongwei Zhang, Tijin Yan, Zenjun Xie, Yuanqing Xia, Yuan Zhang", "title": "Revisiting Graph Convolutional Network on Semi-Supervised Node\n  Classification from an Optimization Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have achieved promising performance on\nvarious graph-based tasks. However they suffer from over-smoothing when\nstacking more layers. In this paper, we present a quantitative study on this\nobservation and develop novel insights towards the deeper GCN. First, we\ninterpret the current graph convolutional operations from an optimization\nperspective and argue that over-smoothing is mainly caused by the naive\nfirst-order approximation of the solution to the optimization problem.\nSubsequently, we introduce two metrics to measure the over-smoothing on\nnode-level tasks. Specifically, we calculate the fraction of the pairwise\ndistance between connected and disconnected nodes to the overall distance\nrespectively. Based on our theoretical and empirical analysis, we establish a\nuniversal theoretical framework of GCN from an optimization perspective and\nderive a novel convolutional kernel named GCN+ which has lower parameter amount\nwhile relieving the over-smoothing inherently. Extensive experiments on\nreal-world datasets demonstrate the superior performance of GCN+ over\nstate-of-the-art baseline methods on the node classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 03:36:43 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 02:00:16 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhang", "Hongwei", ""], ["Yan", "Tijin", ""], ["Xie", "Zenjun", ""], ["Xia", "Yuanqing", ""], ["Zhang", "Yuan", ""]]}, {"id": "2009.11479", "submitter": "Yasushi Esaki", "authors": "Yasushi Esaki and Yuta Nakahara and Toshiyasu Matsushima", "title": "Theoretical Analysis of the Advantage of Deepening Neural Networks", "comments": "9 pages, 7 figures; accepted in 19th IEEE International Conference on\n  Machine Learning and Applications (IEEE ICMLA 2020)", "journal-ref": "2020 19th IEEE International Conference on Machine Learning and\n  Applications (ICMLA), pages 479-484", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two new criteria to understand the advantage of deepening neural\nnetworks. It is important to know the expressivity of functions computable by\ndeep neural networks in order to understand the advantage of deepening neural\nnetworks. Unless deep neural networks have enough expressivity, they cannot\nhave good performance even though learning is successful. In this situation,\nthe proposed criteria contribute to understanding the advantage of deepening\nneural networks since they can evaluate the expressivity independently from the\nefficiency of learning. The first criterion shows the approximation accuracy of\ndeep neural networks to the target function. This criterion has the background\nthat the goal of deep learning is approximating the target function by deep\nneural networks. The second criterion shows the property of linear regions of\nfunctions computable by deep neural networks. This criterion has the background\nthat deep neural networks whose activation functions are piecewise linear are\nalso piecewise linear. Furthermore, by the two criteria, we show that to\nincrease layers is more effective than to increase units at each layer on\nimproving the expressivity of deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 04:10:50 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Esaki", "Yasushi", ""], ["Nakahara", "Yuta", ""], ["Matsushima", "Toshiyasu", ""]]}, {"id": "2009.11499", "submitter": "Dorota Toczydlowska", "authors": "Dorota Toczydlowska, Gareth W. Peters, Pavel V. Shevchenko", "title": "Parsimonious Feature Extraction Methods: Extending Robust Probabilistic\n  Projections with Generalized Skew-t", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel generalisation to the Student-t Probabilistic Principal\nComponent methodology which: (1) accounts for an asymmetric distribution of the\nobservation data; (2) is a framework for grouped and generalised\nmultiple-degree-of-freedom structures, which provides a more flexible approach\nto modelling groups of marginal tail dependence in the observation data; and\n(3) separates the tail effect of the error terms and factors. The new feature\nextraction methods are derived in an incomplete data setting to efficiently\nhandle the presence of missing values in the observation vector. We discuss\nvarious special cases of the algorithm being a result of simplified assumptions\non the process generating the data. The applicability of the new framework is\nillustrated on a data set that consists of crypto currencies with the highest\nmarket capitalisation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 05:53:41 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Toczydlowska", "Dorota", ""], ["Peters", "Gareth W.", ""], ["Shevchenko", "Pavel V.", ""]]}, {"id": "2009.11508", "submitter": "Yang Bai", "authors": "Yang Bai and Yuyuan Zeng and Yong Jiang and Yisen Wang and Shu-Tao Xia\n  and Weiwei Guo", "title": "Improving Query Efficiency of Black-box Adversarial Attack", "comments": "Accepted to ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated excellent performance on\nvarious tasks, however they are under the risk of adversarial examples that can\nbe easily generated when the target model is accessible to an attacker\n(white-box setting). As plenty of machine learning models have been deployed\nvia online services that only provide query outputs from inaccessible models\n(e.g. Google Cloud Vision API2), black-box adversarial attacks (inaccessible\ntarget model) are of critical security concerns in practice rather than\nwhite-box ones. However, existing query-based black-box adversarial attacks\noften require excessive model queries to maintain a high attack success rate.\nTherefore, in order to improve query efficiency, we explore the distribution of\nadversarial examples around benign inputs with the help of image structure\ninformation characterized by a Neural Process, and propose a Neural Process\nbased black-box adversarial attack (NP-Attack) in this paper. Extensive\nexperiments show that NP-Attack could greatly decrease the query counts under\nthe black-box setting.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 06:22:56 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 07:09:25 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Bai", "Yang", ""], ["Zeng", "Yuyuan", ""], ["Jiang", "Yong", ""], ["Wang", "Yisen", ""], ["Xia", "Shu-Tao", ""], ["Guo", "Weiwei", ""]]}, {"id": "2009.11510", "submitter": "Junshan Wang", "authors": "Junshan Wang, Yilun Jin, Guojie Song, Xiaojun Ma", "title": "EPNE: Evolutionary Pattern Preserving Network Embedding", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information networks are ubiquitous and are ideal for modeling relational\ndata. Networks being sparse and irregular, network embedding algorithms have\ncaught the attention of many researchers, who came up with numerous embeddings\nalgorithms in static networks. Yet in real life, networks constantly evolve\nover time. Hence, evolutionary patterns, namely how nodes develop itself over\ntime, would serve as a powerful complement to static structures in embedding\nnetworks, on which relatively few works focus. In this paper, we propose EPNE,\na temporal network embedding model preserving evolutionary patterns of the\nlocal structure of nodes. In particular, we analyze evolutionary patterns with\nand without periodicity and design strategies correspondingly to model such\npatterns in time-frequency domains based on causal convolutions. In addition,\nwe propose a temporal objective function which is optimized simultaneously with\nproximity ones such that both temporal and structural information are\npreserved. With the adequate modeling of temporal information, our model is\nable to outperform other competitive methods in various prediction tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 06:31:14 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Wang", "Junshan", ""], ["Jin", "Yilun", ""], ["Song", "Guojie", ""], ["Ma", "Xiaojun", ""]]}, {"id": "2009.11598", "submitter": "Jihed Khiari", "authors": "Jihed Khiari and Cristina Olaverri-Monreal", "title": "Boosting Algorithms for Delivery Time Prediction in Transportation\n  Logistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel time is a crucial measure in transportation. Accurate travel time\nprediction is also fundamental for operation and advanced information systems.\nA variety of solutions exist for short-term travel time predictions such as\nsolutions that utilize real-time GPS data and optimization methods to track the\npath of a vehicle. However, reliable long-term predictions remain challenging.\nWe show in this paper the applicability and usefulness of travel time i.e.\ndelivery time prediction for postal services. We investigate several methods\nsuch as linear regression models and tree based ensembles such as random\nforest, bagging, and boosting, that allow to predict delivery time by\nconducting extensive experiments and considering many usability scenarios.\nResults reveal that travel time prediction can help mitigate high delays in\npostal services. We show that some boosting algorithms, such as light gradient\nboosting and catboost, have a higher performance in terms of accuracy and\nruntime efficiency than other baselines such as linear regression models,\nbagging regressor and random forest.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 11:01:22 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Khiari", "Jihed", ""], ["Olaverri-Monreal", "Cristina", ""]]}, {"id": "2009.11612", "submitter": "Haitao Lin", "authors": "Zhangyang Gao, Haitao Lin, Stan. Z Li", "title": "Clustering Based on Graph of Density Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data clustering with uneven distribution in high level noise is challenging.\nCurrently, HDBSCAN is considered as the SOTA algorithm for this problem. In\nthis paper, we propose a novel clustering algorithm based on what we call graph\nof density topology (GDT). GDT jointly considers the local and global\nstructures of data samples: firstly forming local clusters based on a density\ngrowing process with a strategy for properly noise handling as well as cluster\nboundary detection; and then estimating a GDT from relationship between local\nclusters in terms of a connectivity measure, givingglobal topological graph.\nThe connectivity, measuring similarity between neighboring local clusters, is\nbased on local clusters rather than individual points, ensuring its robustness\nto even very large noise. Evaluation results on both toy and real-world\ndatasets show that GDT achieves the SOTA performance by far on almost all the\npopular datasets, and has a low time complexity of O(nlogn). The code is\navailable at https://github.com/gaozhangyang/DGC.git.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 11:40:24 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Gao", "Zhangyang", ""], ["Lin", "Haitao", ""], ["Li", "Stan. Z", ""]]}, {"id": "2009.11677", "submitter": "Gavin Leech", "authors": "Dylan Holden-Sim and Gavin Leech and Laurence Aitchison", "title": "Legally grounded fairness objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has identified a number of formally incompatible operational\nmeasures for the unfairness of a machine learning (ML) system. As these\nmeasures all capture intuitively desirable aspects of a fair system, choosing\n\"the one true\" measure is not possible, and instead a reasonable approach is to\nminimize a weighted combination of measures. However, this simply raises the\nquestion of how to choose the weights. Here, we formulate Legally Grounded\nFairness Objectives (LGFO), which uses signals from the legal system to\nnon-arbitrarily measure the social cost of a specific degree of unfairness. The\nLGFO is the expected damages under a putative lawsuit that might be awarded to\nthose who were wrongly classified, in the sense that the ML system made a\ndecision different to that which would have be made under the court's preferred\nmeasure. Notably, the two quantities necessary to compute the LGFO, the court's\npreferences about fairness measures, and the expected damages, are unknown but\nwell-defined, and can be estimated by legal advice. Further, as the damages\nawarded by the legal system are designed to measure and compensate for the harm\ncaused to an individual by an unfair classification, the LGFO aligns closely\nwith society's estimate of the social cost.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:30:03 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Holden-Sim", "Dylan", ""], ["Leech", "Gavin", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2009.11680", "submitter": "Bin Zhang", "authors": "Bin Zhang, Cen Chen, Li Wang", "title": "Privacy-preserving Transfer Learning via Secure Maximum Mean Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of machine learning algorithms often relies on a large amount of\nhigh-quality data to train well-performed models. However, data is a valuable\nresource and are always held by different parties in reality. An effective\nsolution to such a data isolation problem is to employ federated learning,\nwhich allows multiple parties to collaboratively train a model. In this paper,\nwe propose a Secure version of the widely used Maximum Mean Discrepancy (SMMD)\nbased on homomorphic encryption to enable effective knowledge transfer under\nthe data federation setting without compromising the data privacy. The proposed\nSMMD is able to avoid the potential information leakage in transfer learning\nwhen aligning the source and target data distribution. As a result, both the\nsource domain and target domain can fully utilize their data to build more\nscalable models. Experimental results demonstrate that our proposed SMMD is\nsecure and effective.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:34:32 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 03:22:15 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhang", "Bin", ""], ["Chen", "Cen", ""], ["Wang", "Li", ""]]}, {"id": "2009.11693", "submitter": "Kristian Gundersen", "authors": "Kristian Gundersen, Seyyed A. Hosseini, Anna Oleynik, Guttorm Alendal", "title": "A Variational Auto-Encoder for Reservoir Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carbon dioxide Capture and Storage (CCS) is an important strategy in\nmitigating anthropogenic CO$_2$ emissions. In order for CCS to be successful,\nlarge quantities of CO$_2$ must be stored and the storage site conformance must\nbe monitored. Here we present a deep learning method to reconstruct pressure\nfields and classify the flux out of the storage formation based on the pressure\ndata from Above Zone Monitoring Interval (AZMI) wells. The deep learning method\nis a version of a semi conditional variational auto-encoder tailored to solve\ntwo tasks: reconstruction of an incremental pressure field and leakage rate\nclassification. The method, predictions and associated uncertainty estimates\nare illustrated on the synthetic data from a high-fidelity heterogeneous 2D\nnumerical reservoir model, which was used to simulate subsurface CO$_2$\nmovement and pressure changes in the AZMI due to a CO$_2$ leakage.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:33:09 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 10:13:04 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Gundersen", "Kristian", ""], ["Hosseini", "Seyyed A.", ""], ["Oleynik", "Anna", ""], ["Alendal", "Guttorm", ""]]}, {"id": "2009.11697", "submitter": "Nathan Zhao", "authors": "Nathan Zhao, Beicheng Lou", "title": "Compressed imitation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In analogy to compressed sensing, which allows sample-efficient signal\nreconstruction given prior knowledge of its sparsity in frequency domain, we\npropose to utilize policy simplicity (Occam's Razor) as a prior to enable\nsample-efficient imitation learning. We first demonstrated the feasibility of\nthis scheme on linear case where state-value function can be sampled directly.\nWe also extended the scheme to scenarios where only actions are visible and\nscenarios where the policy is obtained from nonlinear network. The method is\nbenchmarked against behavior cloning and results in significantly higher scores\nwith limited expert demonstrations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:50:33 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhao", "Nathan", ""], ["Lou", "Beicheng", ""]]}, {"id": "2009.11698", "submitter": "Vaishak Belle", "authors": "Vaishak Belle and Ioannis Papantonis", "title": "Principles and Practice of Explainable Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) provides many opportunities to improve private\nand public life. Discovering patterns and structures in large troves of data in\nan automated manner is a core component of data science, and currently drives\napplications in diverse areas such as computational biology, law and finance.\nHowever, such a highly positive impact is coupled with significant challenges:\nhow do we understand the decisions suggested by these systems in order that we\ncan trust them? In this report, we focus specifically on data-driven methods --\nmachine learning (ML) and pattern recognition models in particular -- so as to\nsurvey and distill the results and observations from the literature. The\npurpose of this report can be especially appreciated by noting that ML models\nare increasingly deployed in a wide range of businesses. However, with the\nincreasing prevalence and complexity of methods, business stakeholders in the\nvery least have a growing number of concerns about the drawbacks of models,\ndata-specific biases, and so on. Analogously, data science practitioners are\noften not aware about approaches emerging from the academic literature, or may\nstruggle to appreciate the differences between different methods, so end up\nusing industry standards such as SHAP. Here, we have undertaken a survey to\nhelp industry practitioners (but also data scientists more broadly) understand\nthe field of explainable machine learning better and apply the right tools. Our\nlatter sections build a narrative around a putative data scientist, and discuss\nhow she might go about explaining her models by asking the right questions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:50:27 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Belle", "Vaishak", ""], ["Papantonis", "Ioannis", ""]]}, {"id": "2009.11710", "submitter": "Benedikt Pf\\\"ulb", "authors": "Alexander Gepperth, Benedikt Pf\\\"ulb", "title": "A Rigorous Link Between Self-Organizing Maps and Gaussian Mixture Models", "comments": "10 pages, 2 figures, submitted and accepted at International\n  Conference on Artificial Neural Networks (ICANN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a mathematical treatment of the relation between\nSelf-Organizing Maps (SOMs) and Gaussian Mixture Models (GMMs). We show that\nenergy-based SOM models can be interpreted as performing gradient descent,\nminimizing an approximation to the GMM log-likelihood that is particularly\nvalid for high data dimensionalities. The SOM-like decrease of the neighborhood\nradius can be understood as an annealing procedure ensuring that gradient\ndescent does not get stuck in undesirable local minima. This link allows to\ntreat SOMs as generative probabilistic models, giving a formal justification\nfor using SOMs, e.g., to detect outliers, or for sampling.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:09:04 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Gepperth", "Alexander", ""], ["Pf\u00fclb", "Benedikt", ""]]}, {"id": "2009.11713", "submitter": "Ruiyu Xu", "authors": "Ruiyu Xu, Jianguo Wu, Xiaowei Yue and Yongxiang Li", "title": "Online Structural Change-point Detection of High-dimensional Streaming\n  Data via Dynamic Sparse Subspace Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional streaming data are becoming increasingly ubiquitous in many\nfields. They often lie in multiple low-dimensional subspaces, and the manifold\nstructures may change abruptly on the time scale due to pattern shift or\noccurrence of anomalies. However, the problem of detecting the structural\nchanges in a real-time manner has not been well studied. To fill this gap, we\npropose a dynamic sparse subspace learning (DSSL) approach for online\nstructural change-point detection of high-dimensional streaming data. A novel\nmultiple structural change-point model is proposed and it is shown to be\nequivalent to maximizing a posterior under certain conditions. The asymptotic\nproperties of the estimators are investigated. The penalty coefficients in our\nmodel can be selected by AMDL criterion based on some historical data. An\nefficient Pruned Exact Linear Time (PELT) based method is proposed for online\noptimization and change-point detection. The effectiveness of the proposed\nmethod is demonstrated through a simulation study and a real case study using\ngesture data for motion tracking.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:16:18 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 11:45:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Xu", "Ruiyu", ""], ["Wu", "Jianguo", ""], ["Yue", "Xiaowei", ""], ["Li", "Yongxiang", ""]]}, {"id": "2009.11729", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Sen Li, Yinchao Ma, Mingjie Li, Yichen Xie, Quanshi Zhang", "title": "Interpreting and Boosting Dropout from a Game-Theoretic View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to understand and improve the utility of the dropout\noperation from the perspective of game-theoretic interactions. We prove that\ndropout can suppress the strength of interactions between input variables of\ndeep neural networks (DNNs). The theoretic proof is also verified by various\nexperiments. Furthermore, we find that such interactions were strongly related\nto the over-fitting problem in deep learning. Thus, the utility of dropout can\nbe regarded as decreasing interactions to alleviate the significance of\nover-fitting. Based on this understanding, we propose an interaction loss to\nfurther improve the utility of dropout. Experimental results have shown that\nthe interaction loss can effectively improve the utility of dropout and boost\nthe performance of DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:39:42 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 16:45:35 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 10:30:51 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 10:42:04 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Zhang", "Hao", ""], ["Li", "Sen", ""], ["Ma", "Yinchao", ""], ["Li", "Mingjie", ""], ["Xie", "Yichen", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2009.11732", "submitter": "Lukas Ruff", "authors": "Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, Gr\\'egoire\n  Montavon, Wojciech Samek, Marius Kloft, Thomas G. Dietterich, Klaus-Robert\n  M\\\"uller", "title": "A Unifying Review of Deep and Shallow Anomaly Detection", "comments": "40 pages; accepted for publication in the Proceedings of the IEEE;", "journal-ref": "Proceedings of the IEEE (2021) 1-40", "doi": "10.1109/JPROC.2021.3052449", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches to anomaly detection have recently improved the\nstate of the art in detection performance on complex datasets such as large\ncollections of images or text. These results have sparked a renewed interest in\nthe anomaly detection problem and led to the introduction of a great variety of\nnew methods. With the emergence of numerous such methods, including approaches\nbased on generative models, one-class classification, and reconstruction, there\nis a growing need to bring methods of this field into a systematic and unified\nperspective. In this review we aim to identify the common underlying principles\nas well as the assumptions that are often made implicitly by various methods.\nIn particular, we draw connections between classic 'shallow' and novel deep\napproaches and show how this relation might cross-fertilize or extend both\ndirections. We further provide an empirical assessment of major existing\nmethods that is enriched by the use of recent explainability techniques, and\npresent specific worked-through examples together with practical advice.\nFinally, we outline critical open challenges and identify specific paths for\nfuture research in anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:47:54 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 07:46:38 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 12:43:59 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ruff", "Lukas", ""], ["Kauffmann", "Jacob R.", ""], ["Vandermeulen", "Robert A.", ""], ["Montavon", "Gr\u00e9goire", ""], ["Samek", "Wojciech", ""], ["Kloft", "Marius", ""], ["Dietterich", "Thomas G.", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2009.11751", "submitter": "Miguel Araujo", "authors": "Miguel Araujo, Miguel Almeida, Jaime Ferreira, Luis Silva, Pedro\n  Bizarro", "title": "BreachRadar: Automatic Detection of Points-of-Compromise", "comments": "9 pages, 10 figures, published in SIAM's 2017 International\n  Conference on Data Mining (SDM17)", "journal-ref": null, "doi": "10.1137/1.9781611974973.63", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bank transaction fraud results in over $13B annual losses for banks,\nmerchants, and card holders worldwide. Much of this fraud starts with a\nPoint-of-Compromise (a data breach or a skimming operation) where credit and\ndebit card digital information is stolen, resold, and later used to perform\nfraud. We introduce this problem and present an automatic Points-of-Compromise\n(POC) detection procedure. BreachRadar is a distributed alternating algorithm\nthat assigns a probability of being compromised to the different possible\nlocations. We implement this method using Apache Spark and show its linear\nscalability in the number of machines and transactions. BreachRadar is applied\nto two datasets with billions of real transaction records and fraud labels\nwhere we provide multiple examples of real Points-of-Compromise we are able to\ndetect. We further show the effectiveness of our method when injecting\nPoints-of-Compromise in one of these datasets, simultaneously achieving over\n90% precision and recall when only 10% of the cards have been victims of fraud.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:25:14 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Araujo", "Miguel", ""], ["Almeida", "Miguel", ""], ["Ferreira", "Jaime", ""], ["Silva", "Luis", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2009.11762", "submitter": "Chenzhuang Du", "authors": "Chenwei Wu, Chenzhuang Du, Yang Yuan", "title": "Secure Data Sharing With Flow Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classical multi-party computation setting, multiple parties jointly\ncompute a function without revealing their own input data. We consider a\nvariant of this problem, where the input data can be shared for machine\nlearning training purposes, but the data are also encrypted so that they cannot\nbe recovered by other parties. We present a rotation based method using flow\nmodel, and theoretically justified its security. We demonstrate the\neffectiveness of our method in different scenarios, including supervised secure\nmodel training, and unsupervised generative model training. Our code is\navailable at https://github.com/ duchenzhuang/flowencrypt.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:40:14 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Wu", "Chenwei", ""], ["Du", "Chenzhuang", ""], ["Yuan", "Yang", ""]]}, {"id": "2009.11763", "submitter": "Yunbo Wang", "authors": "Zhiyu Yao, Yunbo Wang, Mingsheng Long, Jianmin Wang", "title": "Unsupervised Transfer Learning for Spatiotemporal Predictive Networks", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new research problem of unsupervised transfer learning\nacross multiple spatiotemporal prediction tasks. Unlike most existing transfer\nlearning methods that focus on fixing the discrepancy between supervised tasks,\nwe study how to transfer knowledge from a zoo of unsupervisedly learned models\ntowards another predictive network. Our motivation is that models from\ndifferent sources are expected to understand the complex spatiotemporal\ndynamics from different perspectives, thereby effectively supplementing the new\ntask, even if the task has sufficient training samples. Technically, we propose\na differentiable framework named transferable memory. It adaptively distills\nknowledge from a bank of memory states of multiple pretrained RNNs, and applies\nit to the target network via a novel recurrent structure called the\nTransferable Memory Unit (TMU). Compared with finetuning, our approach yields\nsignificant improvements on three benchmarks for spatiotemporal prediction, and\nbenefits the target task even from less relevant pretext ones.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:40:55 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Yao", "Zhiyu", ""], ["Wang", "Yunbo", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""]]}, {"id": "2009.11811", "submitter": "Bruno Klaus De Aquino Afonso", "authors": "Bruno Klaus de Aquino Afonso, Lilian Berton", "title": "Identifying noisy labels with a transductive semi-supervised\n  leave-one-out filter", "comments": null, "journal-ref": "Pattern Recognition Letters, 2020, ISSN 0167-8655", "doi": "10.1016/j.patrec.2020.09.024", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining data with meaningful labels is often costly and error-prone. In\nthis situation, semi-supervised learning (SSL) approaches are interesting, as\nthey leverage assumptions about the unlabeled data to make up for the limited\namount of labels. However, in real-world situations, we cannot assume that the\nlabeling process is infallible, and the accuracy of many SSL classifiers\ndecreases significantly in the presence of label noise. In this work, we\nintroduce the LGC_LVOF, a leave-one-out filtering approach based on the Local\nand Global Consistency (LGC) algorithm. Our method aims to detect and remove\nwrong labels, and thus can be used as a preprocessing step to any SSL\nclassifier. Given the propagation matrix, detecting noisy labels takes O(cl)\nper step, with c the number of classes and l the number of labels. Moreover,\none does not need to compute the whole propagation matrix, but only an $l$ by\n$l$ submatrix corresponding to interactions between labeled instances. As a\nresult, our approach is best suited to datasets with a large amount of\nunlabeled data but not many labels. Results are provided for a number of\ndatasets, including MNIST and ISOLET. LGCLVOF appears to be equally or more\nprecise than the adapted gradient-based filter. We show that the best-case\naccuracy of the embedding of LGCLVOF into LGC yields performance comparable to\nthe best-case of $\\ell_1$-based classifiers designed to be robust to label\nnoise. We provide a heuristic to choose the number of removed instances.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:50:06 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Afonso", "Bruno Klaus de Aquino", ""], ["Berton", "Lilian", ""]]}, {"id": "2009.11829", "submitter": "Nauman Ahad", "authors": "Nauman Ahad, Mark A. Davenport", "title": "Semi-supervised sequence classification through change point detection", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential sensor data is generated in a wide variety of practical\napplications. A fundamental challenge involves learning effective classifiers\nfor such sequential data. While deep learning has led to impressive performance\ngains in recent years in domains such as speech, this has relied on the\navailability of large datasets of sequences with high-quality labels. In many\napplications, however, the associated class labels are often extremely limited,\nwith precise labelling/segmentation being too expensive to perform at a high\nvolume. However, large amounts of unlabeled data may still be available. In\nthis paper we propose a novel framework for semi-supervised learning in such\ncontexts. In an unsupervised manner, change point detection methods can be used\nto identify points within a sequence corresponding to likely class changes. We\nshow that change points provide examples of similar/dissimilar pairs of\nsequences which, when coupled with labeled, can be used in a semi-supervised\nclassification setting. Leveraging the change points and labeled data, we form\nexamples of similar/dissimilar sequences to train a neural network to learn\nimproved representations for classification. We provide extensive synthetic\nsimulations and show that the learned representations are superior to those\nlearned through an autoencoder and obtain improved results on both simulated\nand real-world human activity recognition datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:23:13 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 15:50:39 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Ahad", "Nauman", ""], ["Davenport", "Mark A.", ""]]}, {"id": "2009.11835", "submitter": "Andre Beckus", "authors": "Andre Beckus and George K. Atia", "title": "Sketch-based community detection in evolving networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an approach for community detection in time-varying networks. At\nits core, this approach maintains a small sketch graph to capture the essential\ncommunity structure found in each snapshot of the full network. We demonstrate\nhow the sketch can be used to explicitly identify six key community events\nwhich typically occur during network evolution: growth, shrinkage, merging,\nsplitting, birth and death. Based on these detection techniques, we formulate a\ncommunity detection algorithm which can process a network concurrently\nexhibiting all processes. One advantage afforded by the sketch-based algorithm\nis the efficient handling of large networks. Whereas detecting events in the\nfull graph may be computationally expensive, the small size of the sketch\nallows changes to be quickly assessed. A second advantage occurs in networks\ncontaining clusters of disproportionate size. The sketch is constructed such\nthat there is equal representation of each cluster, thus reducing the\npossibility that the small clusters are lost in the estimate. We present a new\nstandardized benchmark based on the stochastic block model which models the\naddition and deletion of nodes, as well as the birth and death of communities.\nWhen coupled with existing benchmarks, this new benchmark provides a\ncomprehensive suite of tests encompassing all six community events. We provide\na set of numerical results demonstrating the advantages of our approach both in\nrun time and in the handling of small clusters.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:32:57 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Beckus", "Andre", ""], ["Atia", "George K.", ""]]}, {"id": "2009.11839", "submitter": "Ekdeep Singh Lubana", "authors": "Ekdeep Singh Lubana and Robert P. Dick", "title": "A Gradient Flow Framework For Analyzing Network Pruning", "comments": "Accepted at ICLR, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent network pruning methods focus on pruning models early-on in training.\nTo estimate the impact of removing a parameter, these methods use importance\nmeasures that were originally designed to prune trained models. Despite lacking\njustification for their use early-on in training, such measures result in\nsurprisingly low accuracy loss. To better explain this behavior, we develop a\ngeneral framework that uses gradient flow to unify state-of-the-art importance\nmeasures through the norm of model parameters. We use this framework to\ndetermine the relationship between pruning measures and evolution of model\nparameters, establishing several results related to pruning models early-on in\ntraining: (i) magnitude-based pruning removes parameters that contribute least\nto reduction in loss, resulting in models that converge faster than\nmagnitude-agnostic methods; (ii) loss-preservation based pruning preserves\nfirst-order model evolution dynamics and is therefore appropriate for pruning\nminimally trained models; and (iii) gradient-norm based pruning affects\nsecond-order model evolution dynamics, such that increasing gradient norm via\npruning can produce poorly performing models. We validate our claims on several\nVGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100. Code\navailable at https://github.com/EkdeepSLubana/flowandprune.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:37:32 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 04:51:58 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 03:16:32 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lubana", "Ekdeep Singh", ""], ["Dick", "Robert P.", ""]]}, {"id": "2009.11848", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Mozhi Zhang, Jingling Li, Simon S. Du, Ken-ichi\n  Kawarabayashi, Stefanie Jegelka", "title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how neural networks trained by gradient descent extrapolate, i.e.,\nwhat they learn outside the support of the training distribution. Previous\nworks report mixed empirical results when extrapolating with neural networks:\nwhile feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not\nextrapolate well in certain simple tasks, Graph Neural Networks (GNNs) --\nstructured networks with MLP modules -- have shown some success in more complex\ntasks. Working towards a theoretical explanation, we identify conditions under\nwhich MLPs and GNNs extrapolate well. First, we quantify the observation that\nReLU MLPs quickly converge to linear functions along any direction from the\norigin, which implies that ReLU MLPs do not extrapolate most nonlinear\nfunctions. But, they can provably learn a linear target function when the\ntraining distribution is sufficiently \"diverse\". Second, in connection to\nanalyzing the successes and limitations of GNNs, these results suggest a\nhypothesis for which we provide theoretical and empirical evidence: the success\nof GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or\nedge weights) relies on encoding task-specific non-linearities in the\narchitecture or features. Our theoretical analysis builds on a connection of\nover-parameterized networks to the neural tangent kernel. Empirically, our\ntheory holds across different training settings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:48:59 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 03:54:28 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 23:54:16 GMT"}, {"version": "v4", "created": "Sun, 21 Feb 2021 19:42:02 GMT"}, {"version": "v5", "created": "Tue, 2 Mar 2021 23:05:49 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Xu", "Keyulu", ""], ["Zhang", "Mozhi", ""], ["Li", "Jingling", ""], ["Du", "Simon S.", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "2009.11858", "submitter": "Yazhen Wang", "authors": "Victor Luo and Yazhen Wang", "title": "How Many Factors Influence Minima in SGD?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is often applied to train Deep Neural\nNetworks (DNNs), and research efforts have been devoted to investigate the\nconvergent dynamics of SGD and minima found by SGD. The influencing factors\nidentified in the literature include learning rate, batch size, Hessian, and\ngradient covariance, and stochastic differential equations are used to model\nSGD and establish the relationships among these factors for characterizing\nminima found by SGD. It has been found that the ratio of batch size to learning\nrate is a main factor in highlighting the underlying SGD dynamics; however, the\ninfluence of other important factors such as the Hessian and gradient\ncovariance is not entirely agreed upon. This paper describes the factors and\nrelationships in the recent literature and presents numerical findings on the\nrelationships. In particular, it confirms the four-factor and general\nrelationship results obtained in Wang (2019), while the three-factor and\nassociated relationship results found in Jastrz\\c{e}bski et al. (2018) may not\nhold beyond the considered special case.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:58:46 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Luo", "Victor", ""], ["Wang", "Yazhen", ""]]}, {"id": "2009.11891", "submitter": "Wanrong Zhang", "authors": "Wanrong Zhang, Yajun Mei", "title": "Bandit Change-Point Detection for Real-Time Monitoring High-Dimensional\n  Data Under Sampling Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world problems of real-time monitoring high-dimensional\nstreaming data, one wants to detect an undesired event or change quickly once\nit occurs, but under the sampling control constraint in the sense that one\nmight be able to only observe or use selected components data for\ndecision-making per time step in the resource-constrained environments. In this\npaper, we propose to incorporate multi-armed bandit approaches into sequential\nchange-point detection to develop an efficient bandit change-point detection\nalgorithm. Our proposed algorithm, termed\nThompson-Sampling-Shiryaev-Roberts-Pollak (TSSRP), consists of two policies per\ntime step: the adaptive sampling policy applies the Thompson Sampling algorithm\nto balance between exploration for acquiring long-term knowledge and\nexploitation for immediate reward gain, and the statistical decision policy\nfuses the local Shiryaev-Roberts-Pollak statistics to determine whether to\nraise a global alarm by sum shrinkage techniques. Extensive numerical\nsimulations and case studies demonstrate the statistical and computational\nefficiency of our proposed TSSRP algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:30:55 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhang", "Wanrong", ""], ["Mei", "Yajun", ""]]}, {"id": "2009.11896", "submitter": "Subhajit Chaudhury", "authors": "Subhajit Chaudhury, Daiki Kimura, Kartik Talamadupula, Michiaki\n  Tatsubori, Asim Munawar and Ryuki Tachibana", "title": "Bootstrapped Q-learning with Context Relevant Observation Pruning to\n  Generalize in Text-based Games", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Reinforcement Learning (RL) methods for solving Text-Based Games\n(TBGs) often fail to generalize on unseen games, especially in small data\nregimes. To address this issue, we propose Context Relevant Episodic State\nTruncation (CREST) for irrelevant token removal in observation text for\nimproved generalization. Our method first trains a base model using Q-learning,\nwhich typically overfits the training games. The base model's action token\ndistribution is used to perform observation pruning that removes irrelevant\ntokens. A second bootstrapped model is then retrained on the pruned observation\ntext. Our bootstrapped agent shows improved generalization in solving unseen\nTextWorld games, using 10x-20x fewer training games compared to previous\nstate-of-the-art methods despite requiring less number of training episodes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:38:30 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chaudhury", "Subhajit", ""], ["Kimura", "Daiki", ""], ["Talamadupula", "Kartik", ""], ["Tatsubori", "Michiaki", ""], ["Munawar", "Asim", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "2009.11911", "submitter": "Khaza Anuarul Hoque", "authors": "Gautam Raj Mode, Khaza Anuarul Hoque", "title": "Adversarial Examples in Deep Learning for Multivariate Time Series\n  Regression", "comments": "Accepted for publication in the 49th Annual IEEE Applied Imagery\n  Pattern Recognition (AIPR) workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) regression tasks are common in many real-world\ndata mining applications including finance, cybersecurity, energy, healthcare,\nprognostics, and many others. Due to the tremendous success of deep learning\n(DL) algorithms in various domains including image recognition and computer\nvision, researchers started adopting these techniques for solving MTS data\nmining problems, many of which are targeted for safety-critical and\ncost-critical applications. Unfortunately, DL algorithms are known for their\nsusceptibility to adversarial examples which also makes the DL regression\nmodels for MTS forecasting also vulnerable to those attacks. To the best of our\nknowledge, no previous work has explored the vulnerability of DL MTS regression\nmodels to adversarial time series examples, which is an important step,\nspecifically when the forecasting from such models is used in safety-critical\nand cost-critical applications. In this work, we leverage existing adversarial\nattack generation techniques from the image classification domain and craft\nadversarial multivariate time series examples for three state-of-the-art deep\nlearning regression models, specifically Convolutional Neural Network (CNN),\nLong Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). We evaluate our\nstudy using Google stock and household power consumption dataset. The obtained\nresults show that all the evaluated DL regression models are vulnerable to\nadversarial attacks, transferable, and thus can lead to catastrophic\nconsequences in safety-critical and cost-critical domains, such as energy and\nfinance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 19:09:37 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Mode", "Gautam Raj", ""], ["Hoque", "Khaza Anuarul", ""]]}, {"id": "2009.11921", "submitter": "Hossein Souri", "authors": "Pirazh Khorramshahi, Hossein Souri, Rama Chellappa, and Soheil Feizi", "title": "GANs with Variational Entropy Regularizers: Applications in Mitigating\n  the Mode-Collapse Issue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the success of deep learning, Generative Adversarial Networks\n(GANs) provide a modern approach to learn a probability distribution from\nobserved samples. GANs are often formulated as a zero-sum game between two sets\nof functions; the generator and the discriminator. Although GANs have shown\ngreat potentials in learning complex distributions such as images, they often\nsuffer from the mode collapse issue where the generator fails to capture all\nexisting modes of the input distribution. As a consequence, the diversity of\ngenerated samples is lower than that of the observed ones. To tackle this\nissue, we take an information-theoretic approach and maximize a variational\nlower bound on the entropy of the generated samples to increase their\ndiversity. We call this approach GANs with Variational Entropy Regularizers\n(GAN+VER). Existing remedies for the mode collapse issue in GANs can be easily\ncoupled with our proposed variational entropy regularization. Through extensive\nexperimentation on standard benchmark datasets, we show all the existing\nevaluation metrics highlighting difference of real and generated samples are\nsignificantly improved with GAN+VER.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 19:34:37 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Khorramshahi", "Pirazh", ""], ["Souri", "Hossein", ""], ["Chellappa", "Rama", ""], ["Feizi", "Soheil", ""]]}, {"id": "2009.11942", "submitter": "Kleanthis Malialis", "authors": "Kleanthis Malialis and Christos G. Panayiotou and Marios M. Polycarpou", "title": "Online Learning With Adaptive Rebalancing in Nonstationary Environments", "comments": "Keywords: class imbalance, concept drift, neural networks,\n  nonstationary environments, online learning. in IEEE Transactions on Neural\n  Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3017863", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An enormous and ever-growing volume of data is nowadays becoming available in\na sequential fashion in various real-world applications. Learning in\nnonstationary environments constitutes a major challenge, and this problem\nbecomes orders of magnitude more complex in the presence of class imbalance. We\nprovide new insights into learning from nonstationary and imbalanced data in\nonline learning, a largely unexplored area. We propose the novel Adaptive\nREBAlancing (AREBA) algorithm that selectively includes in the training set a\nsubset of the majority and minority examples that appeared so far, while at its\nheart lies an adaptive mechanism to continually maintain the class balance\nbetween the selected examples. We compare AREBA with strong baselines and other\nstate-of-the-art algorithms and perform extensive experimental work in\nscenarios with various class imbalance rates and different concept drift types\non both synthetic and real-world data. AREBA significantly outperforms the rest\nwith respect to both learning speed and learning quality. Our code is made\npublicly available to the scientific community.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 20:40:04 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Malialis", "Kleanthis", ""], ["Panayiotou", "Christos G.", ""], ["Polycarpou", "Marios M.", ""]]}, {"id": "2009.11974", "submitter": "Farzana Nasrin", "authors": "Vasileios Maroulas, Cassie Putman Micucci, and Farzana Nasrin", "title": "Bayesian Topological Learning for Classifying the Structure of\n  Biological Networks", "comments": "30 pages and 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actin cytoskeleton networks generate local topological signatures due to the\nnatural variations in the number, size, and shape of holes of the networks.\nPersistent homology is a method that explores these topological properties of\ndata and summarizes them as persistence diagrams. In this work, we analyze and\nclassify these filament networks by transforming them into persistence diagrams\nwhose variability is quantified via a Bayesian framework on the space of\npersistence diagrams. The proposed generalized Bayesian framework adopts an\nindependent and identically distributed cluster point process characterization\nof persistence diagrams and relies on a substitution likelihood argument. This\nframework provides the flexibility to estimate the posterior cardinality\ndistribution of points in a persistence diagram and the posterior spatial\ndistribution simultaneously. We present a closed form of the posteriors under\nthe assumption of Gaussian mixtures and binomials for prior intensity and\ncardinality respectively. Using this posterior calculation, we implement a\nBayes factor algorithm to classify the actin filament networks and benchmark it\nagainst several state-of-the-art classification methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 22:43:03 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Maroulas", "Vasileios", ""], ["Micucci", "Cassie Putman", ""], ["Nasrin", "Farzana", ""]]}, {"id": "2009.11992", "submitter": "Ravi Patel", "authors": "Ravi G. Patel, Nathaniel A. Trask, Mitchell A. Wood, Eric C. Cyr", "title": "A physics-informed operator regression framework for extracting\n  data-driven continuum models", "comments": "37 pages, 15 figures", "journal-ref": null, "doi": "10.1016/j.cma.2020.113500", "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning toward discovery of data-driven models\nrequires careful application of inductive biases to obtain a description of\nphysics which is both accurate and robust. We present here a framework for\ndiscovering continuum models from high fidelity molecular simulation data. Our\napproach applies a neural network parameterization of governing physics in\nmodal space, allowing a characterization of differential operators while\nproviding structure which may be used to impose biases related to symmetry,\nisotropy, and conservation form. We demonstrate the effectiveness of our\nframework for a variety of physics, including local and nonlocal diffusion\nprocesses and single and multiphase flows. For the flow physics we demonstrate\nthis approach leads to a learned operator that generalizes to system\ncharacteristics not included in the training sets, such as variable particle\nsizes, densities, and concentration.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 01:13:51 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Patel", "Ravi G.", ""], ["Trask", "Nathaniel A.", ""], ["Wood", "Mitchell A.", ""], ["Cyr", "Eric C.", ""]]}, {"id": "2009.12007", "submitter": "Sayak Paul", "authors": "Souradip Chakraborty, Aritra Roy Gosthipaty, Sayak Paul", "title": "G-SimCLR : Self-Supervised Contrastive Learning with Guided Projection\n  via Pseudo Labelling", "comments": "Code available at this URL: https://github.com/ariG23498/G-SimCLR.\n  This paper is accepeted as a workshop paper at\n  https://fuzhenzhuang.github.io/DLKT2020/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the realms of computer vision, it is evident that deep neural networks\nperform better in a supervised setting with a large amount of labeled data. The\nrepresentations learned with supervision are not only of high quality but also\nhelps the model in enhancing its accuracy. However, the collection and\nannotation of a large dataset are costly and time-consuming. To avoid the same,\nthere has been a lot of research going on in the field of unsupervised visual\nrepresentation learning especially in a self-supervised setting. Amongst the\nrecent advancements in self-supervised methods for visual recognition, in\nSimCLR Chen et al. shows that good quality representations can indeed be\nlearned without explicit supervision. In SimCLR, the authors maximize the\nsimilarity of augmentations of the same image and minimize the similarity of\naugmentations of different images. A linear classifier trained with the\nrepresentations learned using this approach yields 76.5% top-1 accuracy on the\nImageNet ILSVRC-2012 dataset. In this work, we propose that, with the\nnormalized temperature-scaled cross-entropy (NT-Xent) loss function (as used in\nSimCLR), it is beneficial to not have images of the same category in the same\nbatch. In an unsupervised setting, the information of images pertaining to the\nsame category is missing. We use the latent space representation of a denoising\nautoencoder trained on the unlabeled dataset and cluster them with k-means to\nobtain pseudo labels. With this apriori information we batch images, where no\ntwo images from the same category are to be found. We report comparable\nperformance enhancements on the CIFAR10 dataset and a subset of the ImageNet\ndataset. We refer to our method as G-SimCLR.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 02:25:37 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chakraborty", "Souradip", ""], ["Gosthipaty", "Aritra Roy", ""], ["Paul", "Sayak", ""]]}, {"id": "2009.12027", "submitter": "Krishanu Sarker", "authors": "Krishanu Sarker, Xiulong Yang, Yang Li, Saeid Belkasim and Shihao Ji", "title": "A Unified Plug-and-Play Framework for Effective Data Denoising and\n  Robust Abstention", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Neural Networks (DNNs) highly depends on data quality.\nMoreover, predictive uncertainty makes high performing DNNs risky for\nreal-world deployment. In this paper, we aim to address these two issues by\nproposing a unified filtering framework leveraging underlying data density,\nthat can effectively denoise training data as well as avoid predicting\nuncertain test data points. Our proposed framework leverages underlying data\ndistribution to differentiate between noise and clean data samples without\nrequiring any modification to existing DNN architectures or loss functions.\nExtensive experiments on multiple image classification datasets and multiple\nCNN architectures demonstrate that our simple yet effective framework can\noutperform the state-of-the-art techniques in denoising training data and\nabstaining uncertain test data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 04:18:08 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Sarker", "Krishanu", ""], ["Yang", "Xiulong", ""], ["Li", "Yang", ""], ["Belkasim", "Saeid", ""], ["Ji", "Shihao", ""]]}, {"id": "2009.12040", "submitter": "Tao Zhang", "authors": "Tao Zhang, Tianqing Zhu, Jing Li, Mengde Han, Wanlei Zhou, and Philip\n  S. Yu", "title": "Fairness in Semi-supervised Learning: Unlabeled Data Help to Reduce\n  Discrimination", "comments": "This paper has been published in IEEE Transactions on Knowledge and\n  Data Engineering", "journal-ref": null, "doi": "10.1109/TKDE.2020.3002567", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing specter in the rise of machine learning is whether the decisions\nmade by machine learning models are fair. While research is already underway to\nformalize a machine-learning concept of fairness and to design frameworks for\nbuilding fair models with sacrifice in accuracy, most are geared toward either\nsupervised or unsupervised learning. Yet two observations inspired us to wonder\nwhether semi-supervised learning might be useful to solve discrimination\nproblems. First, previous study showed that increasing the size of the training\nset may lead to a better trade-off between fairness and accuracy. Second, the\nmost powerful models today require an enormous of data to train which, in\npractical terms, is likely possible from a combination of labeled and unlabeled\ndata. Hence, in this paper, we present a framework of fair semi-supervised\nlearning in the pre-processing phase, including pseudo labeling to predict\nlabels for unlabeled data, a re-sampling method to obtain multiple fair\ndatasets and lastly, ensemble learning to improve accuracy and decrease\ndiscrimination. A theoretical decomposition analysis of bias, variance and\nnoise highlights the different sources of discrimination and the impact they\nhave on fairness in semi-supervised learning. A set of experiments on\nreal-world and synthetic datasets show that our method is able to use unlabeled\ndata to achieve a better trade-off between accuracy and discrimination.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 05:48:56 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Tianqing", ""], ["Li", "Jing", ""], ["Han", "Mengde", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2009.12042", "submitter": "Yohei Kawaguchi", "authors": "Harsh Purohit, Ryo Tanabe, Takashi Endo, Kaori Suefusa, Yuki Nikaido,\n  and Yohei Kawaguchi", "title": "Deep Autoencoding GMM-based Unsupervised Anomaly Detection in Acoustic\n  Signals and its Hyper-parameter Optimization", "comments": "5 pages, to appear in DCASE 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failures or breakdowns in factory machinery can be costly to companies, so\nthere is an increasing demand for automatic machine inspection. Existing\napproaches to acoustic signal-based unsupervised anomaly detection, such as\nthose using a deep autoencoder (DA) or Gaussian mixture model (GMM), have poor\nanomaly-detection performance. In this work, we propose a new method based on a\ndeep autoencoding Gaussian mixture model with hyper-parameter optimization\n(DAGMM-HO). In our method, the DAGMM-HO applies the conventional DAGMM to the\naudio domain for the first time, with the idea that its total optimization on\nreduction of dimensions and statistical modelling will improve the\nanomaly-detection performance. In addition, the DAGMM-HO solves the\nhyper-parameter sensitivity problem of the conventional DAGMM by performing\nhyper-parameter optimization based on the gap statistic and the cumulative\neigenvalues. Our evaluation of the proposed method with experimental data of\nthe industrial fans showed that it significantly outperforms previous\napproaches and achieves up to a 20% improvement based on the standard AUC\nscore.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 06:14:59 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Purohit", "Harsh", ""], ["Tanabe", "Ryo", ""], ["Endo", "Takashi", ""], ["Suefusa", "Kaori", ""], ["Nikaido", "Yuki", ""], ["Kawaguchi", "Yohei", ""]]}, {"id": "2009.12075", "submitter": "Andrea Bommert", "authors": "Andrea Bommert and J\\\"org Rahnenf\\\"uhrer", "title": "Adjusted Measures for Feature Selection Stability for Data Sets with\n  Similar Features", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-64583-0_19", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For data sets with similar features, for example highly correlated features,\nmost existing stability measures behave in an undesired way: They consider\nfeatures that are almost identical but have different identifiers as different\nfeatures. Existing adjusted stability measures, that is, stability measures\nthat take into account the similarities between features, have major\ntheoretical drawbacks. We introduce new adjusted stability measures that\novercome these drawbacks. We compare them to each other and to existing\nstability measures based on both artificial and real sets of selected features.\nBased on the results, we suggest using one new stability measure that considers\nhighly similar features as exchangeable.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:52:19 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Bommert", "Andrea", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2009.12098", "submitter": "Lukas Heppe", "authors": "Lukas Heppe and Michael Kamp and Linara Adilova and Danny Heinrich and\n  Nico Piatkowski and Katharina Morik", "title": "Resource-Constrained On-Device Learning by Dynamic Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The communication between data-generating devices is partially responsible\nfor a growing portion of the world's power consumption. Thus reducing\ncommunication is vital, both, from an economical and an ecological perspective.\nFor machine learning, on-device learning avoids sending raw data, which can\nreduce communication substantially. Furthermore, not centralizing the data\nprotects privacy-sensitive data. However, most learning algorithms require\nhardware with high computation power and thus high energy consumption. In\ncontrast, ultra-low-power processors, like FPGAs or micro-controllers, allow\nfor energy-efficient learning of local models. Combined with\ncommunication-efficient distributed learning strategies, this reduces the\noverall energy consumption and enables applications that were yet impossible\ndue to limited energy on local devices. The major challenge is then, that the\nlow-power processors typically only have integer processing capabilities. This\npaper investigates an approach to communication-efficient on-device learning of\ninteger exponential families that can be executed on low-power processors, is\nprivacy-preserving, and effectively minimizes communication. The empirical\nevaluation shows that the approach can reach a model quality comparable to a\ncentrally learned regular model with an order of magnitude less communication.\nComparing the overall energy consumption, this reduces the required energy for\nsolving the machine learning task by a significant amount.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 09:29:10 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Heppe", "Lukas", ""], ["Kamp", "Michael", ""], ["Adilova", "Linara", ""], ["Heinrich", "Danny", ""], ["Piatkowski", "Nico", ""], ["Morik", "Katharina", ""]]}, {"id": "2009.12132", "submitter": "Joris Tavernier", "authors": "Joris Tavernier, Jaak Simm, Adam Arany, Karl Meerbergen, Yves Moreau", "title": "Multilevel Gibbs Sampling for Bayesian Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian regression remains a simple but effective tool based on Bayesian\ninference techniques. For large-scale applications, with complicated posterior\ndistributions, Markov Chain Monte Carlo methods are applied. To improve the\nwell-known computational burden of Markov Chain Monte Carlo approach for\nBayesian regression, we developed a multilevel Gibbs sampler for Bayesian\nregression of linear mixed models. The level hierarchy of data matrices is\ncreated by clustering the features and/or samples of data matrices.\nAdditionally, the use of correlated samples is investigated for variance\nreduction to improve the convergence of the Markov Chain. Testing on a diverse\nset of data sets, speed-up is achieved for almost all of them without\nsignificant loss in predictive performance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 11:18:17 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Tavernier", "Joris", ""], ["Simm", "Jaak", ""], ["Arany", "Adam", ""], ["Meerbergen", "Karl", ""], ["Moreau", "Yves", ""]]}, {"id": "2009.12141", "submitter": "Thomas Pinder", "authors": "Thomas Pinder, Christopher Nemeth, David Leslie", "title": "Stein Variational Gaussian Processes", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to use Stein variational gradient descent (SVGD) to carry out\ninference in Gaussian process (GP) models with non-Gaussian likelihoods and\nlarge data volumes. Markov chain Monte Carlo (MCMC) is extremely\ncomputationally intensive for these situations, but the parametric assumptions\nrequired for efficient variational inference (VI) result in incorrect inference\nwhen they encounter the multi-modal posterior distributions that are common for\nsuch models. SVGD provides a non-parametric alternative to variational\ninference which is substantially faster than MCMC. We prove that for GP models\nwith Lipschitz gradients the SVGD algorithm monotonically decreases the\nKullback-Leibler divergence from the sampling distribution to the true\nposterior. Our method is demonstrated on benchmark problems in both regression\nand classification, a multimodal posterior, and an air quality example with\n550,134 spatiotemporal observations, showing substantial performance\nimprovements over MCMC and VI.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 11:47:44 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 09:15:39 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Pinder", "Thomas", ""], ["Nemeth", "Christopher", ""], ["Leslie", "David", ""]]}, {"id": "2009.12146", "submitter": "Tri Minh Nguyen", "authors": "Tri Minh Nguyen, Thin Nguyen, Thao Minh Le, Truyen Tran", "title": "GEFA: Early Fusion Approach in Drug-Target Affinity Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the interaction between a compound and a target is crucial for\nrapid drug repurposing. Deep learning has been successfully applied in\ndrug-target affinity (DTA) problem. However, previous deep learning-based\nmethods ignore modeling the direct interactions between drug and protein\nresidues. This would lead to inaccurate learning of target representation which\nmay change due to the drug binding effects. In addition, previous DTA methods\nlearn protein representation solely based on a small number of protein\nsequences in DTA datasets while neglecting the use of proteins outside of the\nDTA datasets. We propose GEFA (Graph Early Fusion Affinity), a novel\ngraph-in-graph neural network with attention mechanism to address the changes\nin target representation because of the binding effects. Specifically, a drug\nis modeled as a graph of atoms, which then serves as a node in a larger graph\nof residues-drug complex. The resulting model is an expressive deep nested\ngraph neural network. We also use pre-trained protein representation powered by\nthe recent effort of learning contextualized protein representation. The\nexperiments are conducted under different settings to evaluate scenarios such\nas novel drugs or targets. The results demonstrate the effectiveness of the\npre-trained protein embedding and the advantages our GEFA in modeling the\nnested graph for drug-target interaction.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 11:54:15 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 01:47:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Nguyen", "Tri Minh", ""], ["Nguyen", "Thin", ""], ["Le", "Thao Minh", ""], ["Tran", "Truyen", ""]]}, {"id": "2009.12196", "submitter": "Bi-Cun Xu", "authors": "Kai Ming Ting, Bi-Cun Xu, Takashi Washio and Zhi-Hua Zhou", "title": "Isolation Distributional Kernel: A New Tool for Point & Group Anomaly\n  Detection", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Isolation Distributional Kernel as a new way to measure the\nsimilarity between two distributions. Existing approaches based on kernel mean\nembedding, which convert a point kernel to a distributional kernel, have two\nkey issues: the point kernel employed has a feature map with intractable\ndimensionality; and it is {\\em data independent}. This paper shows that\nIsolation Distributional Kernel (IDK), which is based on a {\\em data dependent}\npoint kernel, addresses both key issues. We demonstrate IDK's efficacy and\nefficiency as a new tool for kernel based anomaly detection for both point and\ngroup anomalies. Without explicit learning, using IDK alone outperforms\nexisting kernel based point anomaly detector OCSVM and other kernel mean\nembedding methods that rely on Gaussian kernel. For group anomaly detection,we\nintroduce an IDK based detector called IDK$^2$. It reformulates the problem of\ngroup anomaly detection in input space into the problem of point anomaly\ndetection in Hilbert space, without the need for learning. IDK$^2$ runs orders\nof magnitude faster than group anomaly detector OCSMM.We reveal for the first\ntime that an effective kernel based anomaly detector based on kernel mean\nembedding must employ a characteristic kernel which is data dependent.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 12:25:43 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Ting", "Kai Ming", ""], ["Xu", "Bi-Cun", ""], ["Washio", "Takashi", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2009.12228", "submitter": "Tor Lattimore", "authors": "Tor Lattimore and Andr\\'as Gy\\\"orgy", "title": "Mirror Descent and the Information Ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a connection between the stability of mirror descent and the\ninformation ratio by Russo and Van Roy [2014]. Our analysis shows that mirror\ndescent with suitable loss estimators and exploratory distributions enjoys the\nsame bound on the adversarial regret as the bounds on the Bayesian regret for\ninformation-directed sampling. Along the way, we develop the theory for\ninformation-directed sampling and provide an efficient algorithm for\nadversarial bandits for which the regret upper bound matches exactly the best\nknown information-theoretic upper bound.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 13:17:38 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Lattimore", "Tor", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""]]}, {"id": "2009.12280", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan, Silas {\\O}rting, Erik B Dam", "title": "Locally orderless tensor networks for classifying two- and\n  three-dimensional medical images", "comments": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) (see https://melba-journal.org). Source code at\n  https://github.com/raghavian/LoTeNet_pytorch/", "journal-ref": "Journal of Machine Learning for Biomedical Imaging. 2021:5. pp\n  1-21. Special Issue: Medical Imaging with Deep Learning (MIDL) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tensor networks are factorisations of high rank tensors into networks of\nlower rank tensors and have primarily been used to analyse quantum many-body\nproblems. Tensor networks have seen a recent surge of interest in relation to\nsupervised learning tasks with a focus on image classification. In this work,\nwe improve upon the matrix product state (MPS) tensor networks that can operate\non one-dimensional vectors to be useful for working with 2D and 3D medical\nimages. We treat small image regions as orderless, squeeze their spatial\ninformation into feature dimensions and then perform MPS operations on these\nlocally orderless regions. These local representations are then aggregated in a\nhierarchical manner to retain global structure. The proposed locally orderless\ntensor network (LoTeNet) is compared with relevant methods on three datasets.\nThe architecture of LoTeNet is fixed in all experiments and we show it requires\nlesser computational resources to attain performance on par or superior to the\ncompared methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:05:02 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 20:45:47 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Selvan", "Raghavendra", ""], ["\u00d8rting", "Silas", ""], ["Dam", "Erik B", ""]]}, {"id": "2009.12326", "submitter": "Yuxuan Zhao", "authors": "Yuxuan Zhao, Eric Landgrebe, Eliot Shekhtman and Madeleine Udell", "title": "Online Missing Value Imputation and Correlation Change Detection for\n  Mixed-type Data via Gaussian Copula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most data science algorithms require complete observations, yet many datasets\ncontain missing values. Hence missing value imputation is crucial for\nreal-world data science workflows. For practical applications, imputation\nalgorithms should produce imputations that match the true data distribution,\nhandle mixed data containing ordinal, boolean, and continuous variables, and\nscale to large datasets. In this work we develop a new online imputation\nalgorithm for mixed data using the Gaussian copula. The online Gaussian copula\nmodel produces meets all the desiderata: its imputations match the data\ndistribution even for mixed data, and it scales well, achieving up to an order\nof magnitude speedup over its offline counterpart. The online algorithm can\nhandle streaming or sequential data and can adapt to a changing data\ndistribution. By fitting the copula model to online data, we also provide a new\nmethod to detect a change in the correlational structure of multivariate mixed\ndata with missing values. Experimental results on synthetic and real world data\nvalidate the performance of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:27:47 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhao", "Yuxuan", ""], ["Landgrebe", "Eric", ""], ["Shekhtman", "Eliot", ""], ["Udell", "Madeleine", ""]]}, {"id": "2009.12362", "submitter": "Xiaojun Chang", "authors": "Caixia Yan, Xiaojun Chang, Minnan Luo, Qinghua Zheng, Xiaoqin Zhang,\n  Zhihui Li and Feiping Nie", "title": "Self-Weighted Robust LDA for Multiclass Classification with Edge Classes", "comments": "17 pages, has been accepted by ACM TIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear discriminant analysis (LDA) is a popular technique to learn the most\ndiscriminative features for multi-class classification. A vast majority of\nexisting LDA algorithms are prone to be dominated by the class with very large\ndeviation from the others, i.e., edge class, which occurs frequently in\nmulti-class classification. First, the existence of edge classes often makes\nthe total mean biased in the calculation of between-class scatter matrix.\nSecond, the exploitation of l2-norm based between-class distance criterion\nmagnifies the extremely large distance corresponding to edge class. In this\nregard, a novel self-weighted robust LDA with l21-norm based pairwise\nbetween-class distance criterion, called SWRLDA, is proposed for multi-class\nclassification especially with edge classes. SWRLDA can automatically avoid the\noptimal mean calculation and simultaneously learn adaptive weights for each\nclass pair without setting any additional parameter. An efficient re-weighted\nalgorithm is exploited to derive the global optimum of the challenging l21-norm\nmaximization problem. The proposed SWRLDA is easy to implement, and converges\nfast in practice. Extensive experiments demonstrate that SWRLDA performs\nfavorably against other compared methods on both synthetic and real-world\ndatasets, while presenting superior computational efficiency in comparison with\nother techniques.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 12:32:55 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Yan", "Caixia", ""], ["Chang", "Xiaojun", ""], ["Luo", "Minnan", ""], ["Zheng", "Qinghua", ""], ["Zhang", "Xiaoqin", ""], ["Li", "Zhihui", ""], ["Nie", "Feiping", ""]]}, {"id": "2009.12406", "submitter": "Utkarsh Sarawgi", "authors": "Utkarsh Sarawgi, Wazeer Zulfikar, Rishab Khincha, Pattie Maes", "title": "Why have a Unified Predictive Uncertainty? Disentangling it using Deep\n  Split Ensembles", "comments": "9 pages including references, + 10 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding and quantifying uncertainty in black box Neural Networks (NNs)\nis critical when deployed in real-world settings such as healthcare. Recent\nworks using Bayesian and non-Bayesian methods have shown how a unified\npredictive uncertainty can be modelled for NNs. Decomposing this uncertainty to\ndisentangle the granular sources of heteroscedasticity in data provides rich\ninformation about its underlying causes. We propose a conceptually simple\nnon-Bayesian approach, deep split ensemble, to disentangle the predictive\nuncertainties using a multivariate Gaussian mixture model. The NNs are trained\nwith clusters of input features, for uncertainty estimates per cluster. We\nevaluate our approach on a series of benchmark regression datasets, while also\ncomparing with unified uncertainty methods. Extensive analyses using dataset\nshits and empirical rule highlight our inherently well-calibrated models. Our\nwork further demonstrates its applicability in a multi-modal setting using a\nbenchmark Alzheimer's dataset and also shows how deep split ensembles can\nhighlight hidden modality-specific biases. The minimal changes required to NNs\nand the training procedure, and the high flexibility to group features into\nclusters makes it readily deployable and useful. The source code is available\nat https://github.com/wazeerzulfikar/deep-split-ensembles\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:15:26 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sarawgi", "Utkarsh", ""], ["Zulfikar", "Wazeer", ""], ["Khincha", "Rishab", ""], ["Maes", "Pattie", ""]]}, {"id": "2009.12443", "submitter": "Fazeleh Hoseini", "authors": "Fazeleh S.Hoseini, Sadegh Rahrovani, Morteza Haghir Chehreghani", "title": "A Generic Framework for Clustering Vehicle Motion Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of autonomous vehicles requires having access to a large\namount of data in the concerning driving scenarios. However, manual annotation\nof such driving scenarios is costly and subject to the errors in the rule-based\ntrajectory labeling systems. To address this issue, we propose an effective\nnon-parametric trajectory clustering framework consisting of five stages: (1)\naligning trajectories and quantifying their pairwise temporal dissimilarities,\n(2) embedding the trajectory-based dissimilarities into a vector space, (3)\nextracting transitive relations, (4) embedding the transitive relations into a\nnew vector space, and (5) clustering the trajectories with an optimal number of\nclusters. We investigate and evaluate the proposed framework on a challenging\nreal-world dataset consisting of annotated trajectories. We observe that the\nproposed framework achieves promising results, despite the complexity caused by\nhaving trajectories of varying length. Furthermore, we extend the framework to\nvalidate the augmentation of the real dataset with synthetic data generated by\na Generative Adversarial Network (GAN) where we examine whether the generated\ntrajectories are consistent with the true underlying clusters.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 21:46:37 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Hoseini", "Fazeleh S.", ""], ["Rahrovani", "Sadegh", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2009.12469", "submitter": "Hoda Eldardiry", "authors": "Hongjie Chen, Ryan A. Rossi, Kanak Mahadik, and Hoda Eldardiry", "title": "A Context Integrated Relational Spatio-Temporal Model for Demand and\n  Supply Forecasting", "comments": "9 pages, 6 figures, submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods for demand forecasting only focus on modeling the\ntemporal dependency. However, forecasting on spatio-temporal data requires\nmodeling of complex nonlinear relational and spatial dependencies. In addition,\ndynamic contextual information can have a significant impact on the demand\nvalues, and therefore needs to be captured. For example, in a bike-sharing\nsystem, bike usage can be impacted by weather. Existing methods assume the\ncontextual impact is fixed. However, we note that the contextual impact evolves\nover time. We propose a novel context integrated relational model, Context\nIntegrated Graph Neural Network (CIGNN), which leverages the temporal,\nrelational, spatial, and dynamic contextual dependencies for multi-step ahead\ndemand forecasting. Our approach considers the demand network over various\ngeographical locations and represents the network as a graph. We define a\ndemand graph, where nodes represent demand time-series, and context graphs (one\nfor each type of context), where nodes represent contextual time-series.\nAssuming that various contexts evolve and have a dynamic impact on the\nfluctuation of demand, our proposed CIGNN model employs a fusion mechanism that\njointly learns from all available types of contextual information. To the best\nof our knowledge, this is the first approach that integrates dynamic contexts\nwith graph neural networks for spatio-temporal demand forecasting, thereby\nincreasing prediction accuracy. We present empirical results on two real-world\ndatasets, demonstrating that CIGNN consistently outperforms state-of-the-art\nbaselines, in both periodic and irregular time-series networks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 22:55:36 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Hongjie", ""], ["Rossi", "Ryan A.", ""], ["Mahadik", "Kanak", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2009.12494", "submitter": "Ziwen Zhuang", "authors": "Jianren Wang, Ziwen Zhuang, Hang Zhao", "title": "SEMI: Self-supervised Exploration via Multisensory Incongruity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Efficient exploration is a long-standing problem in reinforcement learning.\nIn this work, we introduce a self-supervised exploration policy by\nincentivizing the agent to maximize multisensory incongruity, which can be\nmeasured in two aspects: perception incongruity and action incongruity. The\nformer represents the uncertainty in multisensory fusion model, while the\nlatter represents the uncertainty in an agent's policy. Specifically, an\nalignment predictor is trained to detect whether multiple sensory inputs are\naligned, the error of which is used to measure perception incongruity. The\npolicy takes the multisensory observations with sensory-wise dropout as input\nand outputs actions for exploration. The variance of actions is further used to\nmeasure action incongruity. Our formulation allows the agent to learn skills by\nexploring in a self-supervised manner without any external rewards. Besides,\nour method enables the agent to learn a compact multimodal representation from\nhard examples, which further improves the sample efficiency of our policy\nlearning. We demonstrate the efficacy of this formulation across a variety of\nbenchmark environments including object manipulation and audio-visual games.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 01:20:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wang", "Jianren", ""], ["Zhuang", "Ziwen", ""], ["Zhao", "Hang", ""]]}, {"id": "2009.12501", "submitter": "Yassine Yaakoubi", "authors": "Yassine Yaakoubi, Fran\\c{c}ois Soumis, Simon Lacoste-Julien", "title": "Flight-connection Prediction for Airline Crew Scheduling to Construct\n  Initial Clusters for OR Optimizer", "comments": "First publication on the \"Cahiers du GERAD\" series in April 2019", "journal-ref": null, "doi": null, "report-no": "G-2019-26", "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a case study of using machine learning classification algorithms\nto initialize a large-scale commercial solver (GENCOL) based on column\ngeneration in the context of the airline crew pairing problem, where small\nsavings of as little as 1% translate to increasing annual revenue by dozens of\nmillions of dollars in a large airline. Under the imitation learning framework,\nwe focus on the problem of predicting the next connecting flight of a crew,\nframed as a multiclass classification problem trained from historical data, and\ndesign an adapted neural network approach that achieves high accuracy (99.7%\noverall or 82.5% on harder instances). We demonstrate the usefulness of our\napproach by using simple heuristics to combine the flight-connection\npredictions to form initial crew-pairing clusters that can be fed in the GENCOL\nsolver, yielding a 10x speed improvement and up to 0.2% cost saving.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 01:32:07 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 22:30:17 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Yaakoubi", "Yassine", ""], ["Soumis", "Fran\u00e7ois", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2009.12511", "submitter": "Guangyu Xi", "authors": "Guangyu Xi, Chao Tao and Yuan Zhou", "title": "Near-Optimal MNL Bandits Under Risk Criteria", "comments": "AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study MNL bandits, which is a variant of the traditional multi-armed\nbandit problem, under risk criteria. Unlike the ordinary expected revenue, risk\ncriteria are more general goals widely used in industries and bussiness. We\ndesign algorithms for a broad class of risk criteria, including but not limited\nto the well-known conditional value-at-risk, Sharpe ratio and entropy risk, and\nprove that they suffer a near-optimal regret. As a complement, we also conduct\nexperiments with both synthetic and real data to show the empirical performance\nof our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 03:24:40 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 04:24:36 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 02:22:23 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Xi", "Guangyu", ""], ["Tao", "Chao", ""], ["Zhou", "Yuan", ""]]}, {"id": "2009.12518", "submitter": "Serban Stan", "authors": "Serban Stan, Mohammad Rostami", "title": "Unsupervised Model Adaptation for Continual Semantic Segmentation", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm for adapting a semantic segmentation model that is\ntrained using a labeled source domain to generalize well in an unlabeled target\ndomain. A similar problem has been studied extensively in the unsupervised\ndomain adaptation (UDA) literature, but existing UDA algorithms require access\nto both the source domain labeled data and the target domain unlabeled data for\ntraining a domain agnostic semantic segmentation model. Relaxing this\nconstraint enables a user to adapt pretrained models to generalize in a target\ndomain, without requiring access to source data. To this end, we learn a\nprototypical distribution for the source domain in an intermediate embedding\nspace. This distribution encodes the abstract knowledge that is learned from\nthe source domain. We then use this distribution for aligning the target domain\ndistribution with the source domain distribution in the embedding space. We\nprovide theoretical analysis and explain conditions under which our algorithm\nis effective. Experiments on benchmark adaptation task demonstrate our method\nachieves competitive performance even compared with joint UDA approaches.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 04:55:50 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 08:09:52 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Stan", "Serban", ""], ["Rostami", "Mohammad", ""]]}, {"id": "2009.12562", "submitter": "Ferdinando Fioretto", "authors": "Cuong Tran, Ferdinando Fioretto, Pascal Van Hentenryck", "title": "Differentially Private and Fair Deep Learning: A Lagrangian Dual\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical concern in data-driven decision making is to build models whose\noutcomes do not discriminate against some demographic groups, including gender,\nethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of\nthe sensitive attributes is essential, while, in practice, these attributes may\nnot be available due to legal and ethical requirements. To address this\nchallenge, this paper studies a model that protects the privacy of the\nindividuals sensitive information while also allowing it to learn\nnon-discriminatory predictors. The method relies on the notion of differential\nprivacy and the use of Lagrangian duality to design neural networks that can\naccommodate fairness constraints while guaranteeing the privacy of sensitive\nattributes. The paper analyses the tension between accuracy, privacy, and\nfairness and the experimental evaluation illustrates the benefits of the\nproposed model on several prediction tasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 10:50:33 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tran", "Cuong", ""], ["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2009.12576", "submitter": "Minhae Kwon", "authors": "Minhae Kwon, Saurabh Daptardar, Paul Schrater, Xaq Pitkow", "title": "Inverse Rational Control with Partially Observable Continuous Nonlinear\n  Dynamics", "comments": "NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in neuroscience is how the brain creates an internal\nmodel of the world to guide actions using sequences of ambiguous sensory\ninformation. This is naturally formulated as a reinforcement learning problem\nunder partial observations, where an agent must estimate relevant latent\nvariables in the world from its evidence, anticipate possible future states,\nand choose actions that optimize total expected reward. This problem can be\nsolved by control theory, which allows us to find the optimal actions for a\ngiven system dynamics and objective function. However, animals often appear to\nbehave suboptimally. Why? We hypothesize that animals have their own flawed\ninternal model of the world, and choose actions with the highest expected\nsubjective reward according to that flawed model. We describe this behavior as\nrational but not optimal. The problem of Inverse Rational Control (IRC) aims to\nidentify which internal model would best explain an agent's actions. Our\ncontribution here generalizes past work on Inverse Rational Control which\nsolved this problem for discrete control in partially observable Markov\ndecision processes. Here we accommodate continuous nonlinear dynamics and\ncontinuous actions, and impute sensory observations corrupted by unknown noise\nthat is private to the animal. We first build an optimal Bayesian agent that\nlearns an optimal policy generalized over the entire model space of dynamics\nand subjective rewards using deep reinforcement learning. Crucially, this\nallows us to compute a likelihood over models for experimentally observable\naction trajectories acquired from a suboptimal agent. We then find the model\nparameters that maximize the likelihood using gradient ascent.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:47:48 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 07:09:41 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Kwon", "Minhae", ""], ["Daptardar", "Saurabh", ""], ["Schrater", "Paul", ""], ["Pitkow", "Xaq", ""]]}, {"id": "2009.12583", "submitter": "J\\\"org Bornschein", "authors": "Jorg Bornschein, Francesco Visin, Simon Osindero", "title": "Small Data, Big Decisions: Model Selection in the Small-Data Regime", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine (ICML 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly overparametrized neural networks can display curiously strong\ngeneralization performance - a phenomenon that has recently garnered a wealth\nof theoretical and empirical research in order to better understand it. In\ncontrast to most previous work, which typically considers the performance as a\nfunction of the model size, in this paper we empirically study the\ngeneralization performance as the size of the training set varies over multiple\norders of magnitude. These systematic experiments lead to some interesting and\npotentially very useful observations; perhaps most notably that training on\nsmaller subsets of the data can lead to more reliable model selection decisions\nwhilst simultaneously enjoying smaller computational costs. Our experiments\nfurthermore allow us to estimate Minimum Description Lengths for common\ndatasets given modern neural network architectures, thereby paving the way for\nprincipled model selection taking into account Occams-razor.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 12:52:56 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bornschein", "Jorg", ""], ["Visin", "Francesco", ""], ["Osindero", "Simon", ""]]}, {"id": "2009.12585", "submitter": "Francisco Nurudin Alvarez Gonzalez", "authors": "Nurudin Alvarez-Gonzalez, Andreas Kaltenbrunner, Vicen\\c{c} G\\'omez", "title": "Inductive Graph Embeddings through Locality Encodings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning embeddings from large-scale networks is an open challenge. Despite\nthe overwhelming number of existing methods, is is unclear how to exploit\nnetwork structure in a way that generalizes easily to unseen nodes, edges or\ngraphs. In this work, we look at the problem of finding inductive network\nembeddings in large networks without domain-dependent node/edge attributes. We\npropose to use a set of basic predefined local encodings as the basis of a\nlearning algorithm. In particular, we consider the degree frequencies at\ndifferent distances from a node, which can be computed efficiently for\nrelatively short distances and a large number of nodes. Interestingly, the\nresulting embeddings generalize well across unseen or distant regions in the\nnetwork, both in unsupervised settings, when combined with language model\nlearning, as well as in supervised tasks, when used as additional features in a\nneural network. Despite its simplicity, this method achieves state-of-the-art\nperformance in tasks such as role detection, link prediction and node\nclassification, and represents an inductive network embedding method directly\napplicable to large unattributed networks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 13:09:11 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Alvarez-Gonzalez", "Nurudin", ""], ["Kaltenbrunner", "Andreas", ""], ["G\u00f3mez", "Vicen\u00e7", ""]]}, {"id": "2009.12602", "submitter": "David Calhas", "authors": "David Calhas and Rui Henriques", "title": "fMRI Multiple Missing Values Imputation Regularized by a Recurrent\n  Denoiser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Functional Magnetic Resonance Imaging (fMRI) is a neuroimaging technique with\npivotal importance due to its scientific and clinical applications. As with any\nwidely used imaging modality, there is a need to ensure the quality of the\nsame, with missing values being highly frequent due to the presence of\nartifacts or sub-optimal imaging resolutions. Our work focus on missing values\nimputation on multivariate signal data. To do so, a new imputation method is\nproposed consisting on two major steps: spatial-dependent signal imputation and\ntime-dependent regularization of the imputed signal. A novel layer, to be used\nin deep learning architectures, is proposed in this work, bringing back the\nconcept of chained equations for multiple imputation. Finally, a recurrent\nlayer is applied to tune the signal, such that it captures its true patterns.\nBoth operations yield an improved robustness against state-of-the-art\nalternatives.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 13:56:41 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Calhas", "David", ""], ["Henriques", "Rui", ""]]}, {"id": "2009.12604", "submitter": "Andreea-Ioana Deac", "authors": "Andreea Deac, Pierre-Luc Bacon, Jian Tang", "title": "Graph neural induction of value iteration", "comments": "ICML GRL+ 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning tasks can benefit from explicit planning based on\nan internal model of the environment. Previously, such planning components have\nbeen incorporated through a neural network that partially aligns with the\ncomputational graph of value iteration. Such network have so far been focused\non restrictive environments (e.g. grid-worlds), and modelled the planning\nprocedure only indirectly. We relax these constraints, proposing a graph neural\nnetwork (GNN) that executes the value iteration (VI) algorithm, across\narbitrary environment models, with direct supervision on the intermediate steps\nof VI. The results indicate that GNNs are able to model value iteration\naccurately, recovering favourable metrics and policies across a variety of\nout-of-distribution tests. This suggests that GNN executors with strong\nsupervision are a viable component within deep reinforcement learning systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 14:09:16 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Deac", "Andreea", ""], ["Bacon", "Pierre-Luc", ""], ["Tang", "Jian", ""]]}, {"id": "2009.12612", "submitter": "Greg Anderson", "authors": "Greg Anderson, Abhinav Verma, Isil Dillig, Swarat Chaudhuri", "title": "Neurosymbolic Reinforcement Learning with Formally Verified Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Revel, a partially neural reinforcement learning (RL) framework\nfor provably safe exploration in continuous state and action spaces. A key\nchallenge for provably safe deep RL is that repeatedly verifying neural\nnetworks within a learning loop is computationally infeasible. We address this\nchallenge using two policy classes: a general, neurosymbolic class with\napproximate gradients and a more restricted class of symbolic policies that\nallows efficient verification. Our learning algorithm is a mirror descent over\npolicies: in each iteration, it safely lifts a symbolic policy into the\nneurosymbolic space, performs safe gradient updates to the resulting policy,\nand projects the updated policy into the safe symbolic subset, all without\nrequiring explicit verification of neural networks. Our empirical results show\nthat Revel enforces safe exploration in many scenarios in which Constrained\nPolicy Optimization does not, and that it can discover policies that outperform\nthose learned through prior approaches to verified exploration.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 14:51:04 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:02:51 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Anderson", "Greg", ""], ["Verma", "Abhinav", ""], ["Dillig", "Isil", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "2009.12634", "submitter": "Ibrahim Ahmed", "authors": "Ibrahim Ahmed, Marcos Quinones-Grueiro, Gautam Biswas", "title": "Complementary Meta-Reinforcement Learning for Fault-Adaptive Control", "comments": "Accepted to PHM Conference 2020", "journal-ref": "Annual Conference of the PHM Society. Vol. 12. No. 1. 2020", "doi": "10.36001/phmconf.2020.v12i1.1289", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faults are endemic to all systems. Adaptive fault-tolerant control maintains\ndegraded performance when faults occur as opposed to unsafe conditions or\ncatastrophic events. In systems with abrupt faults and strict time constraints,\nit is imperative for control to adapt quickly to system changes to maintain\nsystem operations. We present a meta-reinforcement learning approach that\nquickly adapts its control policy to changing conditions. The approach builds\nupon model-agnostic meta learning (MAML). The controller maintains a complement\nof prior policies learned under system faults. This \"library\" is evaluated on a\nsystem after a new fault to initialize the new policy. This contrasts with\nMAML, where the controller derives intermediate policies anew, sampled from a\ndistribution of similar systems, to initialize a new policy. Our approach\nimproves sample efficiency of the reinforcement learning process. We evaluate\nour approach on an aircraft fuel transfer system under abrupt faults.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 16:30:53 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Ahmed", "Ibrahim", ""], ["Quinones-Grueiro", "Marcos", ""], ["Biswas", "Gautam", ""]]}, {"id": "2009.12658", "submitter": "Hossein Sharifi Noghabi", "authors": "Hossein Sharifi-Noghabi, Hossein Asghari, Nazanin Mehrasa, Martin\n  Ester", "title": "Domain Generalization via Semi-supervised Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of domain generalization is to learn from multiple source domains to\ngeneralize to unseen target domains under distribution discrepancy. Current\nstate-of-the-art methods in this area are fully supervised, but for many\nreal-world problems it is hardly possible to obtain enough labeled samples. In\nthis paper, we propose the first method of domain generalization to leverage\nunlabeled samples, combining of meta learning's episodic training and\nsemi-supervised learning, called DGSML. DGSML employs an entropy-based\npseudo-labeling approach to assign labels to unlabeled samples and then\nutilizes a novel discrepancy loss to ensure that class centroids before and\nafter labeling unlabeled samples are close to each other. To learn a\ndomain-invariant representation, it also utilizes a novel alignment loss to\nensure that the distance between pairs of class centroids, computed after\nadding the unlabeled samples, is preserved across different domains. DGSML is\ntrained by a meta learning approach to mimic the distribution shift between the\ninput source domains and unseen target domains. Experimental results on\nbenchmark datasets indicate that DGSML outperforms state-of-the-art domain\ngeneralization and semi-supervised learning methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 18:05:04 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 07:47:30 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Sharifi-Noghabi", "Hossein", ""], ["Asghari", "Hossein", ""], ["Mehrasa", "Nazanin", ""], ["Ester", "Martin", ""]]}, {"id": "2009.12675", "submitter": "Chen Zhao", "authors": "Chen Zhao, Feng Chen, Zhuoyi Wang, Latifur Khan", "title": "A Primal-Dual Subgradient Approachfor Fair Meta Learning", "comments": "20th IEEE International Conference on Data Mining (ICDM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning to generalize to unseen classes during training,\nknown as few-shot classification, has attracted considerable attention.\nInitialization based methods, such as the gradient-based model agnostic\nmeta-learning (MAML), tackle the few-shot learning problem by \"learning to\nfine-tune\". The goal of these approaches is to learn proper model\ninitialization, so that the classifiers for new classes can be learned from a\nfew labeled examples with a small number of gradient update steps. Few shot\nmeta-learning is well-known with its fast-adapted capability and accuracy\ngeneralization onto unseen tasks. Learning fairly with unbiased outcomes is\nanother significant hallmark of human intelligence, which is rarely touched in\nfew-shot meta-learning. In this work, we propose a Primal-Dual Fair\nMeta-learning framework, namely PDFM, which learns to train fair machine\nlearning models using only a few examples based on data from related tasks. The\nkey idea is to learn a good initialization of a fair model's primal and dual\nparameters so that it can adapt to a new fair learning task via a few gradient\nupdate steps. Instead of manually tuning the dual parameters as hyperparameters\nvia a grid search, PDFM optimizes the initialization of the primal and dual\nparameters jointly for fair meta-learning via a subgradient primal-dual\napproach. We further instantiate examples of bias controlling using mean\ndifference and decision boundary covariance as fairness constraints to each\ntask for supervised regression and classification, respectively. We demonstrate\nthe versatility of our proposed approach by applying our approach to various\nreal-world datasets. Our experiments show substantial improvements over the\nbest prior work for this setting.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 19:47:38 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 18:36:07 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 04:00:20 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Zhao", "Chen", ""], ["Chen", "Feng", ""], ["Wang", "Zhuoyi", ""], ["Khan", "Latifur", ""]]}, {"id": "2009.12681", "submitter": "Hoda Eldardiry", "authors": "Chenhan Yuan, Ryan Rossi, Andrew Katz, and Hoda Eldardiry", "title": "Clustering-based Unsupervised Generative Relation Extraction", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of unsupervised relation extraction.\nExisting probabilistic generative model-based relation extraction methods work\nby extracting sentence features and using these features as inputs to train a\ngenerative model. This model is then used to cluster similar relations.\nHowever, these methods do not consider correlations between sentences with the\nsame entity pair during training, which can negatively impact model\nperformance. To address this issue, we propose a Clustering-based Unsupervised\ngenerative Relation Extraction (CURE) framework that leverages an\n\"Encoder-Decoder\" architecture to perform self-supervised learning so the\nencoder can extract relation information. Given multiple sentences with the\nsame entity pair as inputs, self-supervised learning is deployed by predicting\nthe shortest path between entity pairs on the dependency graph of one of the\nsentences. After that, we extract the relation information using the\nwell-trained encoder. Then, entity pairs that share the same relation are\nclustered based on their corresponding relation information. Each cluster is\nlabeled with a few words based on the words in the shortest paths corresponding\nto the entity pairs in each cluster. These cluster labels also describe the\nmeaning of these relation clusters. We compare the triplets extracted by our\nproposed framework (CURE) and baseline methods with a ground-truth Knowledge\nBase. Experimental results show that our model performs better than\nstate-of-the-art models on both New York Times (NYT) and United Nations\nParallel Corpus (UNPC) standard datasets.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:36:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Yuan", "Chenhan", ""], ["Rossi", "Ryan", ""], ["Katz", "Andrew", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2009.12682", "submitter": "He Sun", "authors": "He Sun, Zhun Deng, Hui Chen, David C. Parkes", "title": "Decision-Aware Conditional GANs for Time Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the decision-aware time-series conditional generative\nadversarial network (DAT-CGAN) as a method for time-series generation. The\nframework adopts a multi-Wasserstein loss on structured decision-related\nquantities, capturing the heterogeneity of decision-related data and providing\nnew effectiveness in supporting the decision processes of end users. We improve\nsample efficiency through an overlapped block-sampling method, and provide a\ntheoretical characterization of the generalization properties of DAT-CGAN. The\nframework is demonstrated on financial time series for a multi-time-step\nportfolio choice problem. We demonstrate better generative quality in regard to\nunderlying data and different decision-related quantities than strong,\nGAN-based baselines.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:37:38 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 00:16:35 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 20:18:47 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Sun", "He", ""], ["Deng", "Zhun", ""], ["Chen", "Hui", ""], ["Parkes", "David C.", ""]]}, {"id": "2009.12683", "submitter": "Hoda Eldardiry", "authors": "Chenhan Yuan, Ryan Rossi, Andrew Katz, and Hoda Eldardiry", "title": "Reinforcement Learning-based N-ary Cross-Sentence Relation Extraction", "comments": "10 pages, 3 figures, submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The models of n-ary cross sentence relation extraction based on distant\nsupervision assume that consecutive sentences mentioning n entities describe\nthe relation of these n entities. However, on one hand, this assumption\nintroduces noisy labeled data and harms the models' performance. On the other\nhand, some non-consecutive sentences also describe one relation and these\nsentences cannot be labeled under this assumption. In this paper, we relax this\nstrong assumption by a weaker distant supervision assumption to address the\nsecond issue and propose a novel sentence distribution estimator model to\naddress the first problem. This estimator selects correctly labeled sentences\nto alleviate the effect of noisy data is a two-level agent reinforcement\nlearning model. In addition, a novel universal relation extractor with a hybrid\napproach of attention mechanism and PCNN is proposed such that it can be\ndeployed in any tasks, including consecutive and nonconsecutive sentences.\nExperiments demonstrate that the proposed model can reduce the impact of noisy\ndata and achieve better performance on general n-ary cross sentence relation\nextraction task compared to baseline models.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:39:55 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Yuan", "Chenhan", ""], ["Rossi", "Ryan", ""], ["Katz", "Andrew", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2009.12690", "submitter": "Vikram Krishnamurthy", "authors": "Vikram Krishnamurthy and George Yin", "title": "Adaptive Non-reversible Stochastic Gradient Langevin Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that adding any skew symmetric matrix to the gradient of\nLangevin dynamics algorithm results in a non-reversible diffusion with improved\nconvergence rate. This paper presents a gradient algorithm to adaptively\noptimize the choice of the skew symmetric matrix. The resulting algorithm\ninvolves a non-reversible diffusion algorithm cross coupled with a stochastic\ngradient algorithm that adapts the skew symmetric matrix. The algorithm uses\nthe same data as the classical Langevin algorithm. A weak convergence proof is\ngiven for the optimality of the choice of the skew symmetric matrix. The\nimproved convergence rate of the algorithm is illustrated numerically in\nBayesian learning and tracking examples.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 21:34:01 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Krishnamurthy", "Vikram", ""], ["Yin", "George", ""]]}, {"id": "2009.12703", "submitter": "Truong Nguyen", "authors": "Truong Nguyen, Guangye Chen, and Luis Chacon", "title": "An Adaptive EM Accelerator for Unsupervised Learning of Gaussian Mixture\n  Models", "comments": "19 pages (single column), 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an Anderson Acceleration (AA) scheme for the adaptive\nExpectation-Maximization (EM) algorithm for unsupervised learning a finite\nmixture model from multivariate data (Figueiredo and Jain 2002). The proposed\nalgorithm is able to determine the optimal number of mixture components\nautonomously, and converges to the optimal solution much faster than its\nnon-accelerated version. The success of the AA-based algorithm stems from\nseveral developments rather than a single breakthrough (and without these, our\ntests demonstrate that AA fails catastrophically). To begin, we ensure the\nmonotonicity of the likelihood function (a the key feature of the standard EM\nalgorithm) with a recently proposed monotonicity-control algorithm (Henderson\nand Varahdan 2019), enhanced by a novel monotonicity test with little overhead.\nWe propose nimble strategies for AA to preserve the positive definiteness of\nthe Gaussian weights and covariance matrices strictly, and to conserve up to\nthe second moments of the observed data set exactly. Finally, we employ a\nK-means clustering algorithm using the gap statistic to avoid excessively\noverestimating the initial number of components, thereby maximizing\nperformance. We demonstrate the accuracy and efficiency of the algorithm with\nseveral synthetic data sets that are mixtures of Gaussians distributions of\nknown number of components, as well as data sets generated from\nparticle-in-cell simulations. Our numerical results demonstrate speed-ups with\nrespect to non-accelerated EM of up to 60X when the exact number of mixture\ncomponents is known, and between a few and more than an order of magnitude with\ncomponent adaptivity.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 22:55:44 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Nguyen", "Truong", ""], ["Chen", "Guangye", ""], ["Chacon", "Luis", ""]]}, {"id": "2009.12710", "submitter": "Zeren Shui", "authors": "Zeren Shui, George Karypis", "title": "Heterogeneous Molecular Graph Neural Networks for Predicting Molecule\n  Properties", "comments": "To appear as a conference paper at ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As they carry great potential for modeling complex interactions, graph neural\nnetwork (GNN)-based methods have been widely used to predict quantum mechanical\nproperties of molecules. Most of the existing methods treat molecules as\nmolecular graphs in which atoms are modeled as nodes. They characterize each\natom's chemical environment by modeling its pairwise interactions with other\natoms in the molecule. Although these methods achieve a great success, limited\namount of works explicitly take many-body interactions, i.e., interactions\nbetween three and more atoms, into consideration. In this paper, we introduce a\nnovel graph representation of molecules, heterogeneous molecular graph (HMG) in\nwhich nodes and edges are of various types, to model many-body interactions.\nHMGs have the potential to carry complex geometric information. To leverage the\nrich information stored in HMGs for chemical prediction problems, we build\nheterogeneous molecular graph neural networks (HMGNN) on the basis of a neural\nmessage passing scheme. HMGNN incorporates global molecule representations and\nan attention mechanism into the prediction process. The predictions of HMGNN\nare invariant to translation and rotation of atom coordinates, and permutation\nof atom indices. Our model achieves state-of-the-art performance in 9 out of 12\ntasks on the QM9 dataset.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 23:29:41 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shui", "Zeren", ""], ["Karypis", "George", ""]]}, {"id": "2009.12718", "submitter": "Abhinav Aggarwal", "authors": "Nan Xu, Oluwaseyi Feyisetan, Abhinav Aggarwal, Zekun Xu, Nathanael\n  Teissier", "title": "Differentially Private Adversarial Robustness Through Randomized\n  Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks, despite their great success in diverse domains, are\nprovably sensitive to small perturbations on correctly classified examples and\nlead to erroneous predictions. Recently, it was proposed that this behavior can\nbe combatted by optimizing the worst case loss function over all possible\nsubstitutions of training examples. However, this can be prone to weighing\nunlikely substitutions higher, limiting the accuracy gain. In this paper, we\nstudy adversarial robustness through randomized perturbations, which has two\nimmediate advantages: (1) by ensuring that substitution likelihood is weighted\nby the proximity to the original word, we circumvent optimizing the worst case\nguarantees and achieve performance gains; and (2) the calibrated randomness\nimparts differentially-private model training, which additionally improves\nrobustness against adversarial attacks on the model outputs. Our approach uses\na novel density-based mechanism based on truncated Gumbel noise, which ensures\ntraining on substitutions of both rare and dense words in the vocabulary while\nmaintaining semantic similarity for model robustness.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 00:58:32 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Xu", "Nan", ""], ["Feyisetan", "Oluwaseyi", ""], ["Aggarwal", "Abhinav", ""], ["Xu", "Zekun", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2009.12724", "submitter": "Shixian Wen", "authors": "Shixian Wen, Amanda Rios, Laurent Itti", "title": "Beneficial Perturbations Network for Defending Adversarial Examples", "comments": "submitted to ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks can be fooled by adversarial attacks: adding carefully\ncomputed small adversarial perturbations to clean inputs can cause\nmisclassification on state-of-the-art machine learning models. The reason is\nthat neural networks fail to accommodate the distribution drift of the input\ndata caused by adversarial perturbations. Here, we present a new solution -\nBeneficial Perturbation Network (BPN) - to defend against adversarial attacks\nby fixing the distribution drift. During training, BPN generates and leverages\nbeneficial perturbations (somewhat opposite to well-known adversarial\nperturbations) by adding new, out-of-network biasing units. Biasing units\ninfluence the parameter space of the network, to preempt and neutralize future\nadversarial perturbations on input data samples. To achieve this, BPN creates\nreverse adversarial attacks during training, with very little cost, by\nrecycling the training gradients already computed. Reverse attacks are captured\nby the biasing units, and the biases can in turn effectively defend against\nfuture adversarial examples. Reverse attacks are a shortcut, i.e., they affect\nthe network's parameters without requiring instantiation of adversarial\nexamples that could assist training. We provide comprehensive empirical\nevidence showing that 1) BPN is robust to adversarial examples and is much more\nrunning memory and computationally efficient compared to classical adversarial\ntraining. 2) BPN can defend against adversarial examples with negligible\nadditional computation and parameter costs compared to training only on clean\nexamples; 3) BPN hurts the accuracy on clean examples much less than classic\nadversarial training; 4) BPN can improve the generalization of the network 5)\nBPN trained only with Fast Gradient Sign Attack can generalize to defend PGD\nattacks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 02:05:26 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 07:25:51 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Wen", "Shixian", ""], ["Rios", "Amanda", ""], ["Itti", "Laurent", ""]]}, {"id": "2009.12755", "submitter": "Yunlong Feng", "authors": "Yunlong Feng and Qiang Wu", "title": "A Statistical Learning Assessment of Huber Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the triumphs and milestones of robust statistics, Huber regression\nplays an important role in robust inference and estimation. It has also been\nfinding a great variety of applications in machine learning. In a parametric\nsetup, it has been extensively studied. However, in the statistical learning\ncontext where a function is typically learned in a nonparametric way, there is\nstill a lack of theoretical understanding of how Huber regression estimators\nlearn the conditional mean function and why it works in the absence of\nlight-tailed noise assumptions. To address these fundamental questions, we\nconduct an assessment of Huber regression from a statistical learning\nviewpoint. First, we show that the usual risk consistency property of Huber\nregression estimators, which is usually pursued in machine learning, cannot\nguarantee their learnability in mean regression. Second, we argue that Huber\nregression should be implemented in an adaptive way to perform mean regression,\nimplying that one needs to tune the scale parameter in accordance with the\nsample size and the moment condition of the noise. Third, with an adaptive\nchoice of the scale parameter, we demonstrate that Huber regression estimators\ncan be asymptotic mean regression calibrated under $(1+\\epsilon)$-moment\nconditions ($\\epsilon>0$). Last but not least, under the same moment\nconditions, we establish almost sure convergence rates for Huber regression\nestimators. Note that the $(1+\\epsilon)$-moment conditions accommodate the\nspecial case where the response variable possesses infinite variance and so the\nestablished convergence rates justify the robustness feature of Huber\nregression estimators. In the above senses, the present study provides a\nsystematic statistical learning assessment of Huber regression estimators and\njustifies their merits in terms of robustness from a theoretical viewpoint.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 06:08:21 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Feng", "Yunlong", ""], ["Wu", "Qiang", ""]]}, {"id": "2009.12780", "submitter": "Anna Jenul", "authors": "Anna Jenul, Stefan Schrunner, Kristian Hovde Liland, Ulf Geir Indahl,\n  Cecilia Marie Futsaether, Oliver Tomic", "title": "RENT -- Repeated Elastic Net Technique for Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an essential step in data science pipelines to reduce\nthe complexity of models trained on large datasets. While a major part of\nfeature selection research focuses on optimizing predictive performance, there\nare only few studies that investigate the integration of feature selection\nstability into the feature selection process. Taking advantage of feature\nselection stability has the potential to enhance interpretability of machine\nlearning models whilst maintaining predictive performance. In this study we\npresent the RENT feature selector for binary classification and regression\nproblems. The proposed methodology is based on an ensemble of elastic net\nregularized models, trained on unique subsets of the dataset. RENT selects\nfeatures based on three criteria evaluating the weight distributions of\nfeatures across all elementary models. Compared to conventional approaches,\nRENT simultaneously performs high-quality feature selection while gathering\nuseful information for model interpretation. In addition, the proposed\nensemble-based selection criteria guarantee robustness of the model by\nselecting features with high stability. In an experimental evaluation, we\ncompare feature selection quality on eight multivariate datasets: six for\nbinary classification and two for regression. We benchmark RENT against six\nestablished feature selectors. In terms of both, number of features selected\nand predictive performance, RENT delivers on-par results with the best\nperforming competitors. The additional information on stability provided by\nRENT can be integrated in an exploratory post-hoc analysis for further insight\nas demonstrated in a use-case from the healthcare domain.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 07:55:52 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 15:55:58 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Jenul", "Anna", ""], ["Schrunner", "Stefan", ""], ["Liland", "Kristian Hovde", ""], ["Indahl", "Ulf Geir", ""], ["Futsaether", "Cecilia Marie", ""], ["Tomic", "Oliver", ""]]}, {"id": "2009.12787", "submitter": "Tomer Sery", "authors": "Tomer Sery, Nir Shlezinger, Kobi Cohen and Yonina C. Eldar", "title": "Over-the-Air Federated Learning from Heterogeneous Data", "comments": "15 pages, 8 figures. Part of the results were accepted to be\n  presented in the 2020 IEEE Global Communications Conference (GLOBECOM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a framework for distributed learning of\ncentralized models. In FL, a set of edge devices train a model using their\nlocal data, while repeatedly exchanging their trained updates with a central\nserver. This procedure allows tuning a centralized model in a distributed\nfashion without having the users share their possibly private data. In this\npaper, we focus on over-the-air (OTA) FL, which has been suggested recently to\nreduce the communication overhead of FL due to the repeated transmissions of\nthe model updates by a large number of users over the wireless channel. In OTA\nFL, all users simultaneously transmit their updates as analog signals over a\nmultiple access channel, and the server receives a superposition of the analog\ntransmitted signals. However, this approach results in the channel noise\ndirectly affecting the optimization procedure, which may degrade the accuracy\nof the trained model. We develop a Convergent OTA FL (COTAF) algorithm which\nenhances the common local stochastic gradient descent (SGD) FL algorithm,\nintroducing precoding at the users and scaling at the server, which gradually\nmitigates the effect of the noise. We analyze the convergence of COTAF to the\nloss minimizing model and quantify the effect of a statistically heterogeneous\nsetup, i.e. when the training data of each user obeys a different distribution.\nOur analysis reveals the ability of COTAF to achieve a convergence rate similar\nto that achievable over error-free channels. Our simulations demonstrate the\nimproved convergence of COTAF over vanilla OTA local SGD for training using\nnon-synthetic datasets. Furthermore, we numerically show that the precoding\ninduced by COTAF notably improves the convergence rate and the accuracy of\nmodels trained via OTA FL.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 08:28:25 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:37:08 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Sery", "Tomer", ""], ["Shlezinger", "Nir", ""], ["Cohen", "Kobi", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2009.12789", "submitter": "Yann Dubois", "authors": "Yann Dubois, Douwe Kiela, David J. Schwab, Ramakrishna Vedantam", "title": "Learning Optimal Representations with the Decodable Information\n  Bottleneck", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of characterizing and finding optimal representations\nfor supervised learning. Traditionally, this question has been tackled using\nthe Information Bottleneck, which compresses the inputs while retaining\ninformation about the targets, in a decoder-agnostic fashion. In machine\nlearning, however, our goal is not compression but rather generalization, which\nis intimately linked to the predictive family or decoder of interest (e.g.\nlinear classifier). We propose the Decodable Information Bottleneck (DIB) that\nconsiders information retention and compression from the perspective of the\ndesired predictive family. As a result, DIB gives rise to representations that\nare optimal in terms of expected test performance and can be estimated with\nguarantees. Empirically, we show that the framework can be used to enforce a\nsmall generalization gap on downstream classifiers and to predict the\ngeneralization ability of neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 08:33:08 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 09:22:20 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Dubois", "Yann", ""], ["Kiela", "Douwe", ""], ["Schwab", "David J.", ""], ["Vedantam", "Ramakrishna", ""]]}, {"id": "2009.12795", "submitter": "Thierry Denoeux", "authors": "Thierry Denoeux", "title": "NN-EVCLUS: Neural Network-based Evidential Clustering", "comments": null, "journal-ref": "Information Sciences, Volume 572, Pages 297-330, 2021", "doi": "10.1016/j.ins.2021.05.011", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidential clustering is an approach to clustering based on the use of\nDempster-Shafer mass functions to represent cluster-membership uncertainty. In\nthis paper, we introduce a neural-network based evidential clustering\nalgorithm, called NN-EVCLUS, which learns a mapping from attribute vectors to\nmass functions, in such a way that more similar inputs are mapped to output\nmass functions with a lower degree of conflict. The neural network can be\npaired with a one-class support vector machine to make it robust to outliers\nand allow for novelty detection. The network is trained to minimize the\ndiscrepancy between dissimilarities and degrees of conflict for all or some\nobject pairs. Additional terms can be added to the loss function to account for\npairwise constraints or labeled data, which can also be used to adapt the\nmetric. Comparative experiments show the superiority of N-EVCLUS over\nstate-of-the-art evidential clustering algorithms for a range of unsupervised\nand constrained clustering tasks involving both attribute and dissimilarity\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 09:05:41 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 01:56:10 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Denoeux", "Thierry", ""]]}, {"id": "2009.12820", "submitter": "Neta Shoham", "authors": "Neta Shoham and Haim Avron", "title": "Experimental Design for Overparameterized Learning with Application to\n  Single Shot Deep Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive performance exhibited by modern machine learning models hinges\non the ability to train such models on a very large amounts of labeled data.\nHowever, since access to large volumes of labeled data is often limited or\nexpensive, it is desirable to alleviate this bottleneck by carefully curating\nthe training set. Optimal experimental design is a well-established paradigm\nfor selecting data point to be labeled so to maximally inform the learning\nprocess. Unfortunately, classical theory on optimal experimental design focuses\non selecting examples in order to learn underparameterized (and thus,\nnon-interpolative) models, while modern machine learning models such as deep\nneural networks are overparameterized, and oftentimes are trained to be\ninterpolative. As such, classical experimental design methods are not\napplicable in many modern learning setups. Indeed, the predictive performance\nof underparameterized models tends to be variance dominated, so classical\nexperimental design focuses on variance reduction, while the predictive\nperformance of overparameterized models can also be, as is shown in this paper,\nbias dominated or of mixed nature. In this paper we propose a design strategy\nthat is well suited for overparameterized regression and interpolation, and we\ndemonstrate the applicability of our method in the context of deep learning by\nproposing a new algorithm for single shot deep active learning.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 11:27:49 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 13:42:14 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 18:46:07 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Shoham", "Neta", ""], ["Avron", "Haim", ""]]}, {"id": "2009.12821", "submitter": "Virginia Aglietti", "authors": "Virginia Aglietti, Theodoros Damoulas, Mauricio \\'Alvarez, Javier\n  Gonz\\'alez", "title": "Multi-task Causal Learning with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of learning the correlation structure of a set\nof intervention functions defined on the directed acyclic graph (DAG) of a\ncausal model. This is useful when we are interested in jointly learning the\ncausal effects of interventions on different subsets of variables in a DAG,\nwhich is common in field such as healthcare or operations research. We propose\nthe first multi-task causal Gaussian process (GP) model, which we call DAG-GP,\nthat allows for information sharing across continuous interventions and across\nexperiments on different variables. DAG-GP accommodates different assumptions\nin terms of data availability and captures the correlation between functions\nlying in input spaces of different dimensionality via a well-defined integral\noperator. We give theoretical results detailing when and how the DAG-GP model\ncan be formulated depending on the DAG. We test both the quality of its\npredictions and its calibrated uncertainties. Compared to single-task models,\nDAG-GP achieves the best fitting performance in a variety of real and synthetic\nsettings. In addition, it helps to select optimal interventions faster than\ncompeting approaches when used within sequential decision making frameworks,\nlike active learning or Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 11:33:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Aglietti", "Virginia", ""], ["Damoulas", "Theodoros", ""], ["\u00c1lvarez", "Mauricio", ""], ["Gonz\u00e1lez", "Javier", ""]]}, {"id": "2009.12836", "submitter": "Lei Huang", "authors": "Lei Huang, Jie Qin, Yi Zhou, Fan Zhu, Li Liu, Ling Shao", "title": "Normalization Techniques in Training DNNs: Methodology, Analysis and\n  Application", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization techniques are essential for accelerating the training and\nimproving the generalization of deep neural networks (DNNs), and have\nsuccessfully been used in various applications. This paper reviews and comments\non the past, present and future of normalization methods in the context of DNN\ntraining. We provide a unified picture of the main motivation behind different\napproaches from the perspective of optimization, and present a taxonomy for\nunderstanding the similarities and differences between them. Specifically, we\ndecompose the pipeline of the most representative normalizing activation\nmethods into three components: the normalization area partitioning,\nnormalization operation and normalization representation recovery. In doing so,\nwe provide insight for designing new normalization technique. Finally, we\ndiscuss the current progress in understanding normalization methods, and\nprovide a comprehensive review of the applications of normalization for\nparticular tasks, in which it can effectively solve the key issues.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 13:06:52 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Huang", "Lei", ""], ["Qin", "Jie", ""], ["Zhou", "Yi", ""], ["Zhu", "Fan", ""], ["Liu", "Li", ""], ["Shao", "Ling", ""]]}, {"id": "2009.12852", "submitter": "Alessandra Cabassi", "authors": "Alessandra Cabassi, Sylvia Richardson, Paul D. W. Kirk", "title": "Kernel learning approaches for summarising and combining posterior\n  similarity matrices", "comments": "Manuscript: 27 pages, 8 figures. Supplement: 62 pages, 68 figures.\n  For associated R code, see https://github.com/acabassi/combine-psms", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When using Markov chain Monte Carlo (MCMC) algorithms to perform inference\nfor Bayesian clustering models, such as mixture models, the output is typically\na sample of clusterings (partitions) drawn from the posterior distribution. In\npractice, a key challenge is how to summarise this output. Here we build upon\nthe notion of the posterior similarity matrix (PSM) in order to suggest new\napproaches for summarising the output of MCMC algorithms for Bayesian\nclustering models. A key contribution of our work is the observation that PSMs\nare positive semi-definite, and hence can be used to define\nprobabilistically-motivated kernel matrices that capture the clustering\nstructure present in the data. This observation enables us to employ a range of\nkernel methods to obtain summary clusterings, and otherwise exploit the\ninformation summarised by PSMs. For example, if we have multiple PSMs, each\ncorresponding to a different dataset on a common set of statistical units, we\nmay use standard methods for combining kernels in order to perform integrative\nclustering. We may moreover embed PSMs within predictive kernel models in order\nto perform outcome-guided data integration. We demonstrate the performances of\nthe proposed methods through a range of simulation studies as well as two real\ndata applications. R code is available at\nhttps://github.com/acabassi/combine-psms.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 14:16:14 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Cabassi", "Alessandra", ""], ["Richardson", "Sylvia", ""], ["Kirk", "Paul D. W.", ""]]}, {"id": "2009.12875", "submitter": "Julian Busch", "authors": "Julian Busch, Evgeniy Faerman, Matthias Schubert and Thomas Seidl", "title": "Learning Self-Expression Metrics for Scalable and Inductive Subspace\n  Clustering", "comments": null, "journal-ref": "NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and\n  Practice", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering has established itself as a state-of-the-art approach to\nclustering high-dimensional data. In particular, methods relying on the\nself-expressiveness property have recently proved especially successful.\nHowever, they suffer from two major shortcomings: First, a quadratic-size\ncoefficient matrix is learned directly, preventing these methods from scaling\nbeyond small datasets. Secondly, the trained models are transductive and thus\ncannot be used to cluster out-of-sample data unseen during training. Instead of\nlearning self-expression coefficients directly, we propose a novel metric\nlearning approach to learn instead a subspace affinity function using a siamese\nneural network architecture. Consequently, our model benefits from a constant\nnumber of parameters and a constant-size memory footprint, allowing it to scale\nto considerably larger datasets. In addition, we can formally show that out\nmodel is still able to exactly recover subspace clusters given an independence\nassumption. The siamese architecture in combination with a novel geometric\nclassifier further makes our model inductive, allowing it to cluster\nout-of-sample data. Additionally, non-linear clusters can be detected by simply\nadding an auto-encoder module to the architecture. The whole model can then be\ntrained end-to-end in a self-supervised manner. This work in progress reports\npromising preliminary results on the MNIST dataset. In the spirit of\nreproducible research, me make all code publicly available. In future work we\nplan to investigate several extensions of our model and to expand experimental\nevaluation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:40:12 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 00:06:37 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Busch", "Julian", ""], ["Faerman", "Evgeniy", ""], ["Schubert", "Matthias", ""], ["Seidl", "Thomas", ""]]}, {"id": "2009.12916", "submitter": "Micol Marchetti-Bowick", "authors": "Sumit Kumar, Yiming Gu, Jerrick Hoang, Galen Clark Haynes, Micol\n  Marchetti-Bowick", "title": "Interaction-Based Trajectory Prediction Over a Hybrid Traffic Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior prediction of traffic actors is an essential component of any\nreal-world self-driving system. Actors' long-term behaviors tend to be governed\nby their interactions with other actors or traffic elements (traffic lights,\nstop signs) in the scene. To capture this highly complex structure of\ninteractions, we propose to use a hybrid graph whose nodes represent both the\ntraffic actors as well as the static and dynamic traffic elements present in\nthe scene. The different modes of temporal interaction (e.g., stopping and\ngoing) among actors and traffic elements are explicitly modeled by graph edges.\nThis explicit reasoning about discrete interaction types not only helps in\npredicting future motion, but also enhances the interpretability of the model,\nwhich is important for safety-critical applications such as autonomous driving.\nWe predict actors' trajectories and interaction types using a graph neural\nnetwork, which is trained in a semi-supervised manner. We show that our\nproposed model, TrafficGraphNet, achieves state-of-the-art trajectory\nprediction accuracy while maintaining a high level of interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:20:03 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kumar", "Sumit", ""], ["Gu", "Yiming", ""], ["Hoang", "Jerrick", ""], ["Haynes", "Galen Clark", ""], ["Marchetti-Bowick", "Micol", ""]]}, {"id": "2009.12919", "submitter": "Simiao Ren", "authors": "Simiao Ren, Willie Padilla, Jordan Malof", "title": "Benchmarking deep inverse models over time, and the neural-adjoint\n  method", "comments": "Preprint. For camera-ready version please visit\n  https://proceedings.neurips.cc//paper_files/paper/2020/hash/007ff380ee5ac49ffc34442f5c2a2b86-Abstract.html", "journal-ref": "NeurIPS proceedings (2020) 33, p38-48", "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of solving generic inverse problems, where one wishes to\ndetermine the hidden parameters of a natural system that will give rise to a\nparticular set of measurements. Recently many new approaches based upon deep\nlearning have arisen generating impressive results. We conceptualize these\nmodels as different schemes for efficiently, but randomly, exploring the space\nof possible inverse solutions. As a result, the accuracy of each approach\nshould be evaluated as a function of time rather than a single estimated\nsolution, as is often done now. Using this metric, we compare several\nstate-of-the-art inverse modeling approaches on four benchmark tasks: two\nexisting tasks, one simple task for visualization and one new task from\nmetamaterial design. Finally, inspired by our conception of the inverse\nproblem, we explore a solution that uses a deep learning model to approximate\nthe forward model, and then uses backpropagation to search for good inverse\nsolutions. This approach, termed the neural-adjoint, achieves the best\nperformance in many scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:32:06 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 19:04:03 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 18:16:06 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ren", "Simiao", ""], ["Padilla", "Willie", ""], ["Malof", "Jordan", ""]]}, {"id": "2009.12920", "submitter": "Yining Wang", "authors": "Xi Chen and David Simchi-Levi and Yining Wang", "title": "Privacy-Preserving Dynamic Personalized Pricing with Demand Learning", "comments": "Final version. Accepted to Management Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of e-commerce has made detailed customers' personal\ninformation readily accessible to retailers, and this information has been\nwidely used in pricing decisions. When involving personalized information, how\nto protect the privacy of such information becomes a critical issue in\npractice. In this paper, we consider a dynamic pricing problem over $T$ time\nperiods with an \\emph{unknown} demand function of posted price and personalized\ninformation. At each time $t$, the retailer observes an arriving customer's\npersonal information and offers a price. The customer then makes the purchase\ndecision, which will be utilized by the retailer to learn the underlying demand\nfunction. There is potentially a serious privacy concern during this process: a\nthird party agent might infer the personalized information and purchase\ndecisions from price changes from the pricing system. Using the fundamental\nframework of differential privacy from computer science, we develop a\nprivacy-preserving dynamic pricing policy, which tries to maximize the retailer\nrevenue while avoiding information leakage of individual customer's information\nand purchasing decisions. To this end, we first introduce a notion of\n\\emph{anticipating} $(\\varepsilon, \\delta)$-differential privacy that is\ntailored to dynamic pricing problem. Our policy achieves both the privacy\nguarantee and the performance guarantee in terms of regret. Roughly speaking,\nfor $d$-dimensional personalized information, our algorithm achieves the\nexpected regret at the order of $\\tilde{O}(\\varepsilon^{-1} \\sqrt{d^3 T})$,\nwhen the customers' information is adversarially chosen. For stochastic\npersonalized information, the regret bound can be further improved to\n$\\tilde{O}(\\sqrt{d^2T} + \\varepsilon^{-2} d^2)$\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:32:34 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 18:53:42 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chen", "Xi", ""], ["Simchi-Levi", "David", ""], ["Wang", "Yining", ""]]}, {"id": "2009.12928", "submitter": "Manohar Kaul", "authors": "Manohar Kaul and Dai Tamaki", "title": "A Weighted Quiver Kernel using Functor Homology", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose a new homological method to study weighted directed\nnetworks. Our model of such networks is a directed graph $Q$ equipped with a\nweight function $w$ on the set $Q_{1}$ of arrows in $Q$. We require that the\nrange $W$ of our weight function is equipped with an addition or a\nmultiplication, i.e., $W$ is a monoid in the mathematical terminology. When $W$\nis equipped with a representation on a vector space $M$, the standard method of\nhomological algebra allows us to define the homology groups $H_{*}(Q,w;M)$. It\nis known that when $Q$ has no oriented cycles, $H_{n}(Q,w;M)=0$ for $n\\ge 2$\nand $H_{1}(Q,w;M)$ can be easily computed. This fact allows us to define a new\ngraph kernel for weighted directed graphs. We made two sample computations with\nreal data and found that our method is practically applicable.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 19:35:28 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kaul", "Manohar", ""], ["Tamaki", "Dai", ""]]}, {"id": "2009.12942", "submitter": "Georgios Takos", "authors": "Georgios Takos", "title": "A Survey on Deep Learning Methods for Semantic Image Segmentation in\n  Real-Time", "comments": "34 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic image segmentation is one of fastest growing areas in computer\nvision with a variety of applications. In many areas, such as robotics and\nautonomous vehicles, semantic image segmentation is crucial, since it provides\nthe necessary context for actions to be taken based on a scene understanding at\nthe pixel level. Moreover, the success of medical diagnosis and treatment\nrelies on the extremely accurate understanding of the data under consideration\nand semantic image segmentation is one of the important tools in many cases.\nRecent developments in deep learning have provided a host of tools to tackle\nthis problem efficiently and with increased accuracy. This work provides a\ncomprehensive analysis of state-of-the-art deep learning architectures in image\nsegmentation and, more importantly, an extensive list of techniques to achieve\nfast inference and computational efficiency. The origins of these techniques as\nwell as their strengths and trade-offs are discussed with an in-depth analysis\nof their impact in the area. The best-performing architectures are summarized\nwith a list of methods used to achieve these state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 20:30:10 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Takos", "Georgios", ""]]}, {"id": "2009.12947", "submitter": "Romain Lopez", "authors": "Romain Lopez and Inderjit S. Dhillon and Michael I. Jordan", "title": "Learning from eXtreme Bandit Feedback", "comments": null, "journal-ref": "AAAI Conference on Artificial Intelligence 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of batch learning from bandit feedback in the setting of\nextremely large action spaces. Learning from extreme bandit feedback is\nubiquitous in recommendation systems, in which billions of decisions are made\nover sets consisting of millions of choices in a single day, yielding massive\nobservational data. In these large-scale real-world applications, supervised\nlearning frameworks such as eXtreme Multi-label Classification (XMC) are widely\nused despite the fact that they incur significant biases due to the mismatch\nbetween bandit feedback and supervised labels. Such biases can be mitigated by\nimportance sampling techniques, but these techniques suffer from impractical\nvariance when dealing with a large number of actions. In this paper, we\nintroduce a selective importance sampling estimator (sIS) that operates in a\nsignificantly more favorable bias-variance regime. The sIS estimator is\nobtained by performing importance sampling on the conditional expectation of\nthe reward with respect to a small subset of actions for each instance (a form\nof Rao-Blackwellization). We employ this estimator in a novel algorithmic\nprocedure -- named Policy Optimization for eXtreme Models (POXM) -- for\nlearning from bandit feedback on XMC tasks. In POXM, the selected actions for\nthe sIS estimator are the top-p actions of the logging policy, where p is\nadjusted from the data and is significantly smaller than the size of the action\nspace. We use a supervised-to-bandit conversion on three XMC datasets to\nbenchmark our POXM method against three competing methods: BanditNet, a\npreviously applied partial matching pruning strategy, and a supervised learning\nbaseline. Whereas BanditNet sometimes improves marginally over the logging\npolicy, our experiments show that POXM systematically and significantly\nimproves over all baselines.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 20:47:25 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 22:58:15 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Lopez", "Romain", ""], ["Dhillon", "Inderjit S.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2009.12966", "submitter": "Bruno Klaus de Aquino Afonso", "authors": "Bruno Klaus de Aquino Afonso, Lilian Berton", "title": "Analysis of label noise in graph-based semi-supervised learning", "comments": null, "journal-ref": null, "doi": "10.1145/3341105.3374013", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, one must acquire labels to help supervise a model that\nwill be able to generalize to unseen data. However, the labeling process can be\ntedious, long, costly, and error-prone. It is often the case that most of our\ndata is unlabeled. Semi-supervised learning (SSL) alleviates that by making\nstrong assumptions about the relation between the labels and the input data\ndistribution. This paradigm has been successful in practice, but most SSL\nalgorithms end up fully trusting the few available labels. In real life, both\nhumans and automated systems are prone to mistakes; it is essential that our\nalgorithms are able to work with labels that are both few and also unreliable.\nOur work aims to perform an extensive empirical evaluation of existing\ngraph-based semi-supervised algorithms, like Gaussian Fields and Harmonic\nFunctions, Local and Global Consistency, Laplacian Eigenmaps, Graph\nTransduction Through Alternating Minimization. To do that, we compare the\naccuracy of classifiers while varying the amount of labeled data and label\nnoise for many different samples. Our results show that, if the dataset is\nconsistent with SSL assumptions, we are able to detect the noisiest instances,\nalthough this gets harder when the number of available labels decreases. Also,\nthe Laplacian Eigenmaps algorithm performed better than label propagation when\nthe data came from high-dimensional clusters.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 22:13:20 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Afonso", "Bruno Klaus de Aquino", ""], ["Berton", "Lilian", ""]]}, {"id": "2009.12976", "submitter": "Ankit Pensia", "authors": "Ankit Pensia, Varun Jog, Po-Ling Loh", "title": "Robust regression with covariate filtering: Heavy tails and adversarial\n  contamination", "comments": "V2: Adds new results for unknown covariance matrix (Theorem 3.13),\n  Gaussian design (Remark 3.12), and Simulations (Section 7)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of linear regression where both covariates and responses\nare potentially (i) heavy-tailed and (ii) adversarially contaminated. Several\ncomputationally efficient estimators have been proposed for the simpler setting\nwhere the covariates are sub-Gaussian and uncontaminated; however, these\nestimators may fail when the covariates are either heavy-tailed or contain\noutliers. In this work, we show how to modify the Huber regression, least\ntrimmed squares, and least absolute deviation estimators to obtain estimators\nwhich are simultaneously computationally and statistically efficient in the\nstronger contamination model. Our approach is quite simple, and consists of\napplying a filtering algorithm to the covariates, and then applying the\nclassical robust regression estimators to the remaining data. We show that the\nHuber regression estimator achieves near-optimal error rates in this setting,\nwhereas the least trimmed squares and least absolute deviation estimators can\nbe made to achieve near-optimal error after applying a postprocessing step.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 22:48:48 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 16:40:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Pensia", "Ankit", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "2009.12981", "submitter": "Tim Sainburg", "authors": "Tim Sainburg, Leland McInnes, Timothy Q Gentner", "title": "Parametric UMAP embeddings for representation and semi-supervised\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UMAP is a non-parametric graph-based dimensionality reduction algorithm using\napplied Riemannian geometry and algebraic topology to find low-dimensional\nembeddings of structured data. The UMAP algorithm consists of two steps: (1)\nCompute a graphical representation of a dataset (fuzzy simplicial complex), and\n(2) Through stochastic gradient descent, optimize a low-dimensional embedding\nof the graph. Here, we extend the second step of UMAP to a parametric\noptimization over neural network weights, learning a parametric relationship\nbetween data and embedding. We first demonstrate that Parametric UMAP performs\ncomparably to its non-parametric counterpart while conferring the benefit of a\nlearned parametric mapping (e.g. fast online embeddings for new data). We then\nexplore UMAP as a regularization, constraining the latent distribution of\nautoencoders, parametrically varying global structure preservation, and\nimproving classifier accuracy for semi-supervised learning by capturing\nstructure in unlabeled data. Google Colab walkthrough:\nhttps://colab.research.google.com/drive/1WkXVZ5pnMrm17m0YgmtoNjM_XHdnE5Vp?usp=sharing\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 23:45:00 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 00:49:12 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 04:46:06 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Sainburg", "Tim", ""], ["McInnes", "Leland", ""], ["Gentner", "Timothy Q", ""]]}, {"id": "2009.12991", "submitter": "Kaihua Tang", "authors": "Kaihua Tang, Jianqiang Huang, Hanwang Zhang", "title": "Long-Tailed Classification by Keeping the Good and Removing the Bad\n  Momentum Causal Effect", "comments": "This paper is accepted by NeurIPS 2020. The code is available on\n  GitHub: https://github.com/KaihuaTang/Long-Tailed-Recognition.pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the class size grows, maintaining a balanced dataset across many classes\nis challenging because the data are long-tailed in nature; it is even\nimpossible when the sample-of-interest co-exists with each other in one\ncollectable unit, e.g., multiple visual instances in one image. Therefore,\nlong-tailed classification is the key to deep learning at scale. However,\nexisting methods are mainly based on re-weighting/re-sampling heuristics that\nlack a fundamental theory. In this paper, we establish a causal inference\nframework, which not only unravels the whys of previous methods, but also\nderives a new principled solution. Specifically, our theory shows that the SGD\nmomentum is essentially a confounder in long-tailed classification. On one\nhand, it has a harmful causal effect that misleads the tail prediction biased\ntowards the head. On the other hand, its induced mediation also benefits the\nrepresentation learning and head prediction. Our framework elegantly\ndisentangles the paradoxical effects of the momentum, by pursuing the direct\ncausal effect caused by an input sample. In particular, we use causal\nintervention in training, and counterfactual reasoning in inference, to remove\nthe \"bad\" while keep the \"good\". We achieve new state-of-the-arts on three\nlong-tailed visual recognition benchmarks: Long-tailed CIFAR-10/-100,\nImageNet-LT for image classification and LVIS for instance segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 00:32:11 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 03:36:22 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 12:02:59 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 04:10:13 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Tang", "Kaihua", ""], ["Huang", "Jianqiang", ""], ["Zhang", "Hanwang", ""]]}, {"id": "2009.12999", "submitter": "Shaoming Song", "authors": "Shaoming Song, Yunfeng Shao, Jian Li", "title": "Loosely Coupled Federated Learning Over Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) was proposed to achieve collaborative machine\nlearning among various clients without uploading private data. However, due to\nmodel aggregation strategies, existing frameworks require strict model\nhomogeneity, limiting the application in more complicated scenarios. Besides,\nthe communication cost of FL's model and gradient transmission is extremely\nhigh. This paper proposes Loosely Coupled Federated Learning (LC-FL), a\nframework using generative models as transmission media to achieve low\ncommunication cost and heterogeneous federated learning. LC-FL can be applied\non scenarios where clients possess different kinds of machine learning models.\nExperiments on real-world datasets covering different multiparty scenarios\ndemonstrate the effectiveness of our proposal.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:09:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Song", "Shaoming", ""], ["Shao", "Yunfeng", ""], ["Li", "Jian", ""]]}, {"id": "2009.13003", "submitter": "Yu Chen", "authors": "Yu Chen, Zhenming Liu, Bin Ren, Xin Jin", "title": "On Efficient Constructions of Checkpoints", "comments": null, "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Efficient construction of checkpoints/snapshots is a critical tool for\ntraining and diagnosing deep learning models. In this paper, we propose a lossy\ncompression scheme for checkpoint constructions (called LC-Checkpoint).\nLC-Checkpoint simultaneously maximizes the compression rate and optimizes the\nrecovery speed, under the assumption that SGD is used to train the model.\nLC-Checkpointuses quantization and priority promotion to store the most crucial\ninformation for SGD to recover, and then uses a Huffman coding to leverage the\nnon-uniform distribution of the gradient scales. Our extensive experiments show\nthat LC-Checkpoint achieves a compression rate up to $28\\times$ and recovery\nspeedup up to $5.77\\times$ over a state-of-the-art algorithm (SCAR).\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:20:15 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Yu", ""], ["Liu", "Zhenming", ""], ["Ren", "Bin", ""], ["Jin", "Xin", ""]]}, {"id": "2009.13008", "submitter": "Anjul Tyagi", "authors": "Anjul Tyagi, Cong Xie, Klaus Mueller", "title": "Visual Steering for One-Shot Deep Neural Network Synthesis", "comments": "9 pages, submitted to IEEE Transactions on Visualization and Computer\n  Graphics, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in the area of deep learning have shown the effectiveness\nof very large neural networks in several applications. However, as these deep\nneural networks continue to grow in size, it becomes more and more difficult to\nconfigure their many parameters to obtain good results. Presently, analysts\nmust experiment with many different configurations and parameter settings,\nwhich is labor-intensive and time-consuming. On the other hand, the capacity of\nfully automated techniques for neural network architecture search is limited\nwithout the domain knowledge of human experts. To deal with the problem, we\nformulate the task of neural network architecture optimization as a graph space\nexploration, based on the one-shot architecture search technique. In this\napproach, a super-graph of all candidate architectures is trained in one-shot\nand the optimal neural network is identified as a sub-graph. In this paper, we\npresent a framework that allows analysts to effectively build the solution\nsub-graph space and guide the network search by injecting their domain\nknowledge. Starting with the network architecture space composed of basic\nneural network components, analysts are empowered to effectively select the\nmost promising components via our one-shot search scheme. Applying this\ntechnique in an iterative manner allows analysts to converge to the best\nperforming neural network architecture for a given application. During the\nexploration, analysts can use their domain knowledge aided by cues provided\nfrom a scatterplot visualization of the search space to edit different\ncomponents and guide the search for faster convergence. We designed our\ninterface in collaboration with several deep learning researchers and its final\neffectiveness is evaluated with a user study and two case studies.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:48:45 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tyagi", "Anjul", ""], ["Xie", "Cong", ""], ["Mueller", "Klaus", ""]]}, {"id": "2009.13011", "submitter": "Dandan Guo", "authors": "Dandan Guo, Bo Chen (Senior Member, IEEE), Wenchao Chen, Chaojie Wang,\n  Hongwei Liu (Member, IEEE), and Mingyuan Zhou", "title": "Variational Temporal Deep Generative Model for Radar HRRP Target\n  Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3027470", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a recurrent gamma belief network (rGBN) for radar automatic target\nrecognition (RATR) based on high-resolution range profile (HRRP), which\ncharacterizes the temporal dependence across the range cells of HRRP. The\nproposed rGBN adopts a hierarchy of gamma distributions to build its temporal\ndeep generative model. For scalable training and fast out-of-sample prediction,\nwe propose the hybrid of a stochastic-gradient Markov chain Monte Carlo (MCMC)\nand a recurrent variational inference model to perform posterior inference. To\nutilize the label information to extract more discriminative latent\nrepresentations, we further propose supervised rGBN to jointly model the HRRP\nsamples and their corresponding labels. Experimental results on synthetic and\nmeasured HRRP data show that the proposed models are efficient in computation,\nhave good classification accuracy and generalization ability, and provide\nhighly interpretable multi-stochastic-layer latent structure.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:03:51 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Guo", "Dandan", "", "Senior Member, IEEE"], ["Chen", "Bo", "", "Senior Member, IEEE"], ["Chen", "Wenchao", "", "Member, IEEE"], ["Wang", "Chaojie", "", "Member, IEEE"], ["Liu", "Hongwei", "", "Member, IEEE"], ["Zhou", "Mingyuan", ""]]}, {"id": "2009.13016", "submitter": "Krishnakumar Balasubramanian", "authors": "Abhishek Roy, Krishnakumar Balasubramanian, Saeed Ghadimi, Prasant\n  Mohapatra", "title": "Escaping Saddle-Points Faster under Interpolation-like Conditions", "comments": "To appear in NeurIPS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that under over-parametrization several standard\nstochastic optimization algorithms escape saddle-points and converge to\nlocal-minimizers much faster. One of the fundamental aspects of\nover-parametrized models is that they are capable of interpolating the training\ndata. We show that, under interpolation-like assumptions satisfied by the\nstochastic gradients in an over-parametrization setting, the first-order oracle\ncomplexity of Perturbed Stochastic Gradient Descent (PSGD) algorithm to reach\nan $\\epsilon$-local-minimizer, matches the corresponding deterministic rate of\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{2})$. We next analyze Stochastic\nCubic-Regularized Newton (SCRN) algorithm under interpolation-like conditions,\nand show that the oracle complexity to reach an $\\epsilon$-local-minimizer\nunder interpolation-like conditions, is\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{2.5})$. While this obtained complexity is\nbetter than the corresponding complexity of either PSGD, or SCRN without\ninterpolation-like assumptions, it does not match the rate of\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{1.5})$ corresponding to deterministic\nCubic-Regularized Newton method. It seems further Hessian-based\ninterpolation-like assumptions are necessary to bridge this gap. We also\ndiscuss the corresponding improved complexities in the zeroth-order settings.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:15:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Roy", "Abhishek", ""], ["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2009.13033", "submitter": "Chang Liao", "authors": "Chang Liao, Yao Cheng, Chengfang Fang, Jie Shi", "title": "Where Does the Robustness Come from? A Study of the Transformation-based\n  Ensemble Defence", "comments": "The 27th ACM Conference on Computer and Communications Security (CCS)\n  Workshop, AISec 2020", "journal-ref": "the 13th ACM Workshop on Artificial Intelligence and Security 2020", "doi": "10.1145/3411508.3421380", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to provide a thorough study on the effectiveness of the\ntransformation-based ensemble defence for image classification and its reasons.\nIt has been empirically shown that they can enhance the robustness against\nevasion attacks, while there is little analysis on the reasons. In particular,\nit is not clear whether the robustness improvement is a result of\ntransformation or ensemble. In this paper, we design two adaptive attacks to\nbetter evaluate the transformation-based ensemble defence. We conduct\nexperiments to show that 1) the transferability of adversarial examples exists\namong the models trained on data records after different reversible\ntransformations; 2) the robustness gained through transformation-based ensemble\nis limited; 3) this limited robustness is mainly from the irreversible\ntransformations rather than the ensemble of a number of models; and 4) blindly\nincreasing the number of sub-models in a transformation-based ensemble does not\nbring extra robustness gain.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:55:56 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 09:16:18 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Liao", "Chang", ""], ["Cheng", "Yao", ""], ["Fang", "Chengfang", ""], ["Shi", "Jie", ""]]}, {"id": "2009.13038", "submitter": "Zhou Xianchen", "authors": "Xianchen Zhou, Yaoyun Zeng, Hongxia Wang", "title": "RoGAT: a robust GNN combined revised GAT with adjusted graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks(GNNs) are useful deep learning models to deal with the\nnon-Euclid data. However, recent works show that GNNs are vulnerable to\nadversarial attacks. Small perturbations can lead to poor performance in many\nGNNs, such as Graph attention networks(GATs). Therefore, enhancing the\nrobustness of GNNs is a critical problem.\n  Robust GAT(RoGAT) is proposed to improve the robustness of GNNs in this\npaper, . Note that the original GAT uses the attention mechanism for different\nedges but is still sensitive to the perturbation, RoGAT adjusts the edges'\nweight to adjust the attention scores progressively. Firstly, RoGAT tunes the\nedges weight based on the assumption that the adjacent nodes should have\nsimilar nodes. Secondly, RoGAT further tunes the features to eliminate\nfeature's noises since even for the clean graph, there exists some unreasonable\ndata. Then, we trained the adjusted GAT model to defense the adversarial\nattacks. Different experiments against targeted and untargeted attacks\ndemonstrate that RoGAT outperforms significantly than most the state-of-the-art\ndefense methods. The implementation of RoGAT based on the DeepRobust repository\nfor adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 03:10:09 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 08:32:45 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Zhou", "Xianchen", ""], ["Zeng", "Yaoyun", ""], ["Wang", "Hongxia", ""]]}, {"id": "2009.13040", "submitter": "Yudong Chen", "authors": "Yudong Chen and Xumei Xi", "title": "Likelihood Landscape and Local Minima Structures of Gaussian Mixture\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the landscape of the population negative\nlog-likelihood function of Gaussian Mixture Models with a general number of\ncomponents. Due to nonconvexity, there exist multiple local minima that are not\nglobally optimal, even when the mixture is well-separated. We show that all\nlocal minima share the same form of structure that partially identifies the\ncomponent centers of the true mixture, in the sense that each local minimum\ninvolves a non-overlapping combination of fitting multiple Gaussians to a\nsingle true component and fitting a single Gaussian to multiple true\ncomponents. Our results apply to the setting where the true mixture components\nsatisfy a certain separation condition, and are valid even when the number of\ncomponents is over-or under-specified. For Gaussian mixtures with three\ncomponents, we obtain sharper results in terms of the scaling with the\nseparation between the components.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 03:23:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Yudong", ""], ["Xi", "Xumei", ""]]}, {"id": "2009.13051", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel, Benjamin Black, Ananth Hari,\n  Caroline Horsch, Luis Santos", "title": "Agent Environment Cycle Games", "comments": "This work of this paper has been merged into the paper \"PettingZoo:\n  Gym for Multi-Agent Reinforcement Learning\" arXiv:2009.14471", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially Observable Stochastic Games (POSGs) are the most general and common\nmodel of games used in Multi-Agent Reinforcement Learning (MARL). We argue that\nthe POSG model is conceptually ill suited to software MARL environments, and\noffer case studies from the literature where this mismatch has led to severely\nunexpected behavior. In response to this, we introduce the Agent Environment\nCycle Games (AEC Games) model, which is more representative of software\nimplementation. We then prove it's as an equivalent model to POSGs. The AEC\ngames model is also uniquely useful in that it can elegantly represent both all\nforms of MARL environments, whereas for example POSGs cannot elegantly\nrepresent strictly turn based games like chess.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:02:08 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 19:06:59 GMT"}, {"version": "v3", "created": "Sat, 1 May 2021 14:24:22 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""], ["Black", "Benjamin", ""], ["Hari", "Ananth", ""], ["Horsch", "Caroline", ""], ["Santos", "Luis", ""]]}, {"id": "2009.13062", "submitter": "Joo Seong Jeong", "authors": "Joo Seong Jeong, Soojeong Kim, Gyeong-In Yu, Yunseong Lee, Byung-Gon\n  Chun", "title": "Accelerating Multi-Model Inference by Merging DNNs of Different Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standardized DNN models that have been proved to perform well on machine\nlearning tasks are widely used and often adopted as-is to solve downstream\ntasks, forming the transfer learning paradigm. However, when serving multiple\ninstances of such DNN models from a cluster of GPU servers, existing techniques\nto improve GPU utilization such as batching are inapplicable because models\noften do not share weights due to fine-tuning. We propose NetFuse, a technique\nof merging multiple DNN models that share the same architecture but have\ndifferent weights and different inputs. NetFuse is made possible by replacing\noperations with more general counterparts that allow a set of weights to be\nassociated with only a certain set of inputs. Experiments on ResNet-50,\nResNeXt-50, BERT, and XLNet show that NetFuse can speed up DNN inference time\nup to 3.6x on a NVIDIA V100 GPU, and up to 3.0x on a TITAN Xp GPU when merging\n32 model instances, while only using up a small additional amount of GPU\nmemory.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:33:09 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Jeong", "Joo Seong", ""], ["Kim", "Soojeong", ""], ["Yu", "Gyeong-In", ""], ["Lee", "Yunseong", ""], ["Chun", "Byung-Gon", ""]]}, {"id": "2009.13092", "submitter": "Masahiro Kato", "authors": "Masahiro Kato and Shota Yasui", "title": "Learning Classifiers under Delayed Feedback with a Time Window\n  Assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider training a binary classifier under delayed feedback (DF\nLearning). In DF Learning, we first receive negative samples; subsequently,\nsome samples turn positive. This problem is conceivable in various real-world\napplications such as online advertisements, where the user action takes place\nlong after the first click. Owing to the delayed feedback, simply separating\nthe positive and negative data causes a sample selection bias. One solution is\nto assume that a long time window after first observing a sample reduces the\nsample selection bias. However, existing studies report that only using a\nportion of all samples based on the time window assumption yields suboptimal\nperformance, and the use of all samples along with the time window assumption\nimproves empirical performance. Extending these existing studies, we propose a\nmethod with an unbiased and convex empirical risk constructed from the whole\nsamples under the time window assumption. We provide experimental results to\ndemonstrate the effectiveness of the proposed method using a real traffic log\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 06:20:24 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kato", "Masahiro", ""], ["Yasui", "Shota", ""]]}, {"id": "2009.13093", "submitter": "Neng Wan", "authors": "Neng Wan, Dapeng Li, and Naira Hovakimyan", "title": "f-Divergence Variational Inference", "comments": "Dapeng Li and Neng Wan contributed equally to this paper.\n  Supplementary material is attached. The links to code are provided in the\n  paper, supplementary material and reference list. To appear in Advances in\n  Neural Information Processing Systems 33 (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the $f$-divergence variational inference ($f$-VI) that\ngeneralizes variational inference to all $f$-divergences. Initiated from\nminimizing a crafty surrogate $f$-divergence that shares the statistical\nconsistency with the $f$-divergence, the $f$-VI framework not only unifies a\nnumber of existing VI methods, e.g. Kullback-Leibler VI, R\\'{e}nyi's\n$\\alpha$-VI, and $\\chi$-VI, but offers a standardized toolkit for VI subject to\narbitrary divergences from $f$-divergence family. A general $f$-variational\nbound is derived and provides a sandwich estimate of marginal likelihood (or\nevidence). The development of the $f$-VI unfolds with a stochastic optimization\nscheme that utilizes the reparameterization trick, importance weighting and\nMonte Carlo approximation; a mean-field approximation scheme that generalizes\nthe well-known coordinate ascent variational inference (CAVI) is also proposed\nfor $f$-VI. Empirical examples, including variational autoencoders and Bayesian\nneural networks, are provided to demonstrate the effectiveness and the wide\napplicability of $f$-VI.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 06:22:05 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 19:53:24 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 04:47:37 GMT"}, {"version": "v4", "created": "Sat, 3 Apr 2021 16:33:25 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wan", "Neng", ""], ["Li", "Dapeng", ""], ["Hovakimyan", "Naira", ""]]}, {"id": "2009.13094", "submitter": "Takashi Mori", "authors": "Takashi Mori, Masahito Ueda", "title": "Improved generalization by noise enhancement", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated that noise in stochastic gradient descent\n(SGD) is closely related to generalization: A larger SGD noise, if not too\nlarge, results in better generalization. Since the covariance of the SGD noise\nis proportional to $\\eta^2/B$, where $\\eta$ is the learning rate and $B$ is the\nminibatch size of SGD, the SGD noise has so far been controlled by changing\n$\\eta$ and/or $B$. However, too large $\\eta$ results in instability in the\ntraining dynamics and a small $B$ prevents scalable parallel computation. It is\nthus desirable to develop a method of controlling the SGD noise without\nchanging $\\eta$ and $B$. In this paper, we propose a method that achieves this\ngoal using ``noise enhancement'', which is easily implemented in practice. We\nexpound the underlying theoretical idea and demonstrate that the noise\nenhancement actually improves generalization for real datasets. It turns out\nthat large-batch training with the noise enhancement even shows better\ngeneralization compared with small-batch training.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 06:29:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mori", "Takashi", ""], ["Ueda", "Masahito", ""]]}, {"id": "2009.13101", "submitter": "R\\'emi Eyraud", "authors": "Remi Eyraud and Stephane Ayache", "title": "Distillation of Weighted Automata from Recurrent Neural Networks using a\n  Spectral Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper is an attempt to bridge the gap between deep learning and\ngrammatical inference. Indeed, it provides an algorithm to extract a\n(stochastic) formal language from any recurrent neural network trained for\nlanguage modelling. In detail, the algorithm uses the already trained network\nas an oracle -- and thus does not require the access to the inner\nrepresentation of the black-box -- and applies a spectral approach to infer a\nweighted automaton.\n  As weighted automata compute linear functions, they are computationally more\nefficient than neural networks and thus the nature of the approach is the one\nof knowledge distillation. We detail experiments on 62 data sets (both\nsynthetic and from real-world applications) that allow an in-depth study of the\nabilities of the proposed algorithm. The results show the WA we extract are\ngood approximations of the RNN, validating the approach. Moreover, we show how\nthe process provides interesting insights toward the behavior of RNN learned on\ndata, enlarging the scope of this work to the one of explainability of deep\nlearning models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 07:04:15 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Eyraud", "Remi", ""], ["Ayache", "Stephane", ""]]}, {"id": "2009.13145", "submitter": "Yifei Huang", "authors": "Yifei Huang, Yaodong Yu, Hongyang Zhang, Yi Ma, Yuan Yao", "title": "Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated\n  Gradients", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a provably stable architecture for Neural Ordinary\nDifferential Equations (ODEs) which achieves non-trivial adversarial robustness\nunder white-box adversarial attacks even when the network is trained naturally.\nFor most existing defense methods withstanding strong white-box attacks, to\nimprove robustness of neural networks, they need to be trained adversarially,\nhence have to strike a trade-off between natural accuracy and adversarial\nrobustness. Inspired by dynamical system theory, we design a stabilized neural\nODE network named SONet whose ODE blocks are skew-symmetric and proved to be\ninput-output stable. With natural training, SONet can achieve comparable\nrobustness with the state-of-the-art adversarial defense methods, without\nsacrificing natural accuracy. Even replacing only the first layer of a ResNet\nby such a ODE block can exhibit further improvement in robustness, e.g., under\nPGD-20 ($\\ell_\\infty=0.031$) attack on CIFAR-10 dataset, it achieves 91.57\\%\nand natural accuracy and 62.35\\% robust accuracy, while a counterpart\narchitecture of ResNet trained with TRADES achieves natural and robust accuracy\n76.29\\% and 45.24\\%, respectively. To understand possible reasons behind this\nsurprisingly good result, we further explore the possible mechanism underlying\nsuch an adversarial robustness. We show that the adaptive stepsize numerical\nODE solver, DOPRI5, has a gradient masking effect that fails the PGD attacks\nwhich are sensitive to gradient information of training loss; on the other\nhand, it cannot fool the CW attack of robust gradients and the SPSA attack that\nis gradient-free. This provides a new explanation that the adversarial\nrobustness of ODE-based networks mainly comes from the obfuscated gradients in\nnumerical ODE solvers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:51:42 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 04:14:08 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Huang", "Yifei", ""], ["Yu", "Yaodong", ""], ["Zhang", "Hongyang", ""], ["Ma", "Yi", ""], ["Yao", "Yuan", ""]]}, {"id": "2009.13154", "submitter": "Matias Quintana", "authors": "Matias Quintana, Stefano Schiavon, Kwok Wai Tham, and Clayton Miller", "title": "Balancing thermal comfort datasets: We GAN, but should we?", "comments": "10 pages, submitted and accepted to BuildSys'20\n  (http://buildsys.acm.org/2020/)", "journal-ref": null, "doi": "10.1145/3408308.3427612", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thermal comfort assessment for the built environment has become more\navailable to analysts and researchers due to the proliferation of sensors and\nsubjective feedback methods. These data can be used for modeling comfort\nbehavior to support design and operations towards energy efficiency and\nwell-being. By nature, occupant subjective feedback is imbalanced as indoor\nconditions are designed for comfort, and responses indicating otherwise are\nless common. This situation creates a scenario for the machine learning\nworkflow where class balancing as a pre-processing step might be valuable for\ndeveloping predictive thermal comfort classification models with\nhigh-performance. This paper investigates the various thermal comfort dataset\nclass balancing techniques from the literature and proposes a modified\nconditional Generative Adversarial Network (GAN), $\\texttt{comfortGAN}$, to\naddress this imbalance scenario. These approaches are applied to three publicly\navailable datasets, ranging from 30 and 67 participants to a global collection\nof thermal comfort datasets, with 1,474; 2,067; and 66,397 data points,\nrespectively. This work finds that a classification model trained on a balanced\ndataset, comprised of real and generated samples from $\\texttt{comfortGAN}$,\nhas higher performance (increase between 4% and 17% in classification accuracy)\nthan other augmentation methods tested. However, when classes representing\ndiscomfort are merged and reduced to three, better imbalanced performance is\nexpected, and the additional increase in performance by $\\texttt{comfortGAN}$\nshrinks to 1-2%. These results illustrate that class balancing for thermal\ncomfort modeling is beneficial using advanced techniques such as GANs, but its\nvalue is diminished in certain scenarios. A discussion is provided to assist\npotential users in determining which scenarios this process is useful and which\nmethod works best.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:09:34 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Quintana", "Matias", ""], ["Schiavon", "Stefano", ""], ["Tham", "Kwok Wai", ""], ["Miller", "Clayton", ""]]}, {"id": "2009.13165", "submitter": "Gardave Bhumbra", "authors": "Gardave S Bhumbra", "title": "Quantal synaptic dilution enhances sparse encoding and dropout\n  regularisation in deep networks", "comments": "23 pages, 8 figures, including Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a technique that silences the activity of units stochastically\nwhile training deep networks to reduce overfitting. Here we introduce Quantal\nSynaptic Dilution (QSD), a biologically plausible model of dropout\nregularisation based on the quantal properties of neuronal synapses, that\nincorporates heterogeneities in response magnitudes and release probabilities\nfor vesicular quanta. QSD outperforms standard dropout in ReLU multilayer\nperceptrons, with enhanced sparse encoding at test time when dropout masks are\nreplaced with identity functions, without shifts in trainable weight or bias\ndistributions. For convolutional networks, the method also improves\ngeneralisation in computer vision tasks with and without inclusion of\nadditional forms of regularisation. QSD also outperforms standard dropout in\nrecurrent networks for language modelling and sentiment analysis. An advantage\nof QSD over many variations of dropout is that it can be implemented generally\nin all conventional deep networks where standard dropout is applicable.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:29:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bhumbra", "Gardave S", ""]]}, {"id": "2009.13180", "submitter": "Trent Kyono", "authors": "Trent Kyono, Yao Zhang, Mihaela van der Schaar", "title": "CASTLE: Regularization via Auxiliary Causal Graph Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization improves generalization of supervised models to out-of-sample\ndata. Prior works have shown that prediction in the causal direction (effect\nfrom cause) results in lower testing error than the anti-causal direction.\nHowever, existing regularization methods are agnostic of causality. We\nintroduce Causal Structure Learning (CASTLE) regularization and propose to\nregularize a neural network by jointly learning the causal relationships\nbetween variables. CASTLE learns the causal directed acyclical graph (DAG) as\nan adjacency matrix embedded in the neural network's input layers, thereby\nfacilitating the discovery of optimal predictors. Furthermore, CASTLE\nefficiently reconstructs only the features in the causal DAG that have a causal\nneighbor, whereas reconstruction-based regularizers suboptimally reconstruct\nall input features. We provide a theoretical generalization bound for our\napproach and conduct experiments on a plethora of synthetic and real publicly\navailable datasets demonstrating that CASTLE consistently leads to better\nout-of-sample predictions as compared to other popular benchmark regularizers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:49:38 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kyono", "Trent", ""], ["Zhang", "Yao", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2009.13181", "submitter": "Camille-Sovanneary Gauthier", "authors": "Camille-Sovanneary Gauthier, Romaric Gaudel and Elisa Fromont", "title": "Position-Based Multiple-Play Bandits with Thompson Sampling", "comments": "Accepted at IDA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-play bandits aim at displaying relevant items at relevant positions\non a web page. We introduce a new bandit-based algorithm, PB-MHB, for online\nrecommender systems which uses the Thompson sampling framework. This algorithm\nhandles a display setting governed by the position-based model. Our sampling\nmethod does not require as input the probability of a user to look at a given\nposition in the web page which is, in practice, very difficult to obtain.\nExperiments on simulated and real datasets show that our method, with fewer\nprior information, deliver better recommendations than state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:50:53 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 10:06:13 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 16:28:21 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Gauthier", "Camille-Sovanneary", ""], ["Gaudel", "Romaric", ""], ["Fromont", "Elisa", ""]]}, {"id": "2009.13211", "submitter": "Eoin Delaney", "authors": "Eoin Delaney, Derek Greene, Mark T. Keane", "title": "Instance-based Counterfactual Explanations for Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a rapidly expanding focus on explaining the\npredictions made by black-box AI systems that handle image and tabular data.\nHowever, considerably less attention has been paid to explaining the\npredictions of opaque AI systems handling time series data. In this paper, we\nadvance a novel model-agnostic, case-based technique -- Native Guide -- that\ngenerates counterfactual explanations for time series classifiers. Given a\nquery time series, $T_{q}$, for which a black-box classification system\npredicts class, $c$, a counterfactual time series explanation shows how $T_{q}$\ncould change, such that the system predicts an alternative class, $c'$. The\nproposed instance-based technique adapts existing counterfactual instances in\nthe case-base by highlighting and modifying discriminative areas of the time\nseries that underlie the classification. Quantitative and qualitative results\nfrom two comparative experiments indicate that Native Guide generates\nplausible, proximal, sparse and diverse explanations that are better than those\nproduced by key benchmark counterfactual methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 10:52:48 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 13:46:51 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Delaney", "Eoin", ""], ["Greene", "Derek", ""], ["Keane", "Mark T.", ""]]}, {"id": "2009.13232", "submitter": "Atandra Burman", "authors": "Atandra Burman, Jitto Titus, David Gbadebo, Melissa Burman", "title": "ECGDetect: Detecting Ischemia via Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronary artery disease(CAD) is the most common type of heart disease and the\nleading cause of death worldwide[1]. A progressive state of this disease marked\nby plaque rupture and clot formation in the coronary arteries, also known as an\nacute coronary syndrome (ACS), is a condition of the heart associated with\nsudden, reduced blood flow caused due to partial or full occlusion of coronary\nvasculature that normally perfuses the myocardium and nerve bundles,\ncompromising the proper functioning of the heart. Often manifesting with pain\nor tightness in the chest as the second most common cause of emergency\ndepartment visits in the United States, it is imperative to detect ACS at the\nearliest. This is particularly relevant to diabetic patients at home, that may\nnot feel classic chest pain symptoms, and are susceptible to silent myocardial\ninjury. In this study, we developed the RCE- ECG-Detect algorithm, a machine\nlearning model to detect the morphological patterns in significant ST change\nassociated with myocardial ischemia. We developed the RCE- ECG-Detect using\ndata from the LTST database which has a sufficiently large sample set to train\na reliable model. We validated the predictive performance of the machine\nlearning model on a holdout test set collected using RCE's ECG wearable. Our\ndeep neural network model, equipped with convolution layers, achieves 90.31%\nROC-AUC, 89.34% sensitivity, 87.81% specificity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 11:57:26 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Burman", "Atandra", ""], ["Titus", "Jitto", ""], ["Gbadebo", "David", ""], ["Burman", "Melissa", ""]]}, {"id": "2009.13233", "submitter": "Aaqib Saeed", "authors": "Aaqib Saeed, Victor Ungureanu, Beat Gfeller", "title": "Sense and Learn: Self-Supervision for Omnipresent Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning general-purpose representations from multisensor data produced by\nthe omnipresent sensing systems (or IoT in general) has numerous applications\nin diverse use areas. Existing purely supervised end-to-end deep learning\ntechniques depend on the availability of a massive amount of well-curated data,\nacquiring which is notoriously difficult but required to achieve a sufficient\nlevel of generalization on a task of interest. In this work, we leverage the\nself-supervised learning paradigm towards realizing the vision of continual\nlearning from unlabeled inputs. We present a generalized framework named Sense\nand Learn for representation or feature learning from raw sensory data. It\nconsists of eight auxiliary tasks that can learn high-level and broadly useful\nfeatures entirely from unannotated data without any human involvement in the\ntedious labeling process. We demonstrate the efficacy of our approach on\nseveral publicly available datasets from different domains and in various\nsettings, including linear separability, semi-supervised or few shot learning,\nand transfer learning. Our methodology achieves results that are competitive\nwith the supervised approaches and close the gap through fine-tuning a network\nwhile learning the downstream tasks in most cases. In particular, we show that\nthe self-supervised network can be utilized as initialization to significantly\nboost the performance in a low-data regime with as few as 5 labeled instances\nper class, which is of high practical importance to real-world problems.\nLikewise, the learned representations with self-supervision are found to be\nhighly transferable between related datasets, even when few labeled instances\nare available from the target domains. The self-learning nature of our\nmethodology opens up exciting possibilities for on-device continual learning.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 11:57:43 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Saeed", "Aaqib", ""], ["Ungureanu", "Victor", ""], ["Gfeller", "Beat", ""]]}, {"id": "2009.13239", "submitter": "Joan Puigcerver", "authors": "Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Cedric Renggli,\n  Andr\\'e Susano Pinto, Sylvain Gelly, Daniel Keysers, Neil Houlsby", "title": "Scalable Transfer Learning with Expert Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer of pre-trained representations can improve sample efficiency and\nreduce computational requirements for new tasks. However, representations used\nfor transfer are usually generic, and are not tailored to a particular\ndistribution of downstream tasks. We explore the use of expert representations\nfor transfer with a simple, yet effective, strategy. We train a diverse set of\nexperts by exploiting existing label structures, and use cheap-to-compute\nperformance proxies to select the relevant expert for each target task. This\nstrategy scales the process of transferring to new tasks, since it does not\nrevisit the pre-training data during transfer. Accordingly, it requires little\nextra compute per target task, and results in a speed-up of 2-3 orders of\nmagnitude compared to competing approaches. Further, we provide an\nadapter-based architecture able to compress many experts into a single model.\nWe evaluate our approach on two different data sources and demonstrate that it\noutperforms baselines on over 20 diverse vision tasks in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:07:10 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Puigcerver", "Joan", ""], ["Riquelme", "Carlos", ""], ["Mustafa", "Basil", ""], ["Renggli", "Cedric", ""], ["Pinto", "Andr\u00e9 Susano", ""], ["Gelly", "Sylvain", ""], ["Keysers", "Daniel", ""], ["Houlsby", "Neil", ""]]}, {"id": "2009.13248", "submitter": "Przemyslaw Biecek", "authors": "Szymon Maksymiuk, Alicja Gosiewska, Przemyslaw Biecek", "title": "Landscape of R packages for eXplainable Artificial Intelligence", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing availability of data and computing power fuels the development of\npredictive models. In order to ensure the safe and effective functioning of\nsuch models, we need methods for exploration, debugging, and validation. New\nmethods and tools for this purpose are being developed within the eXplainable\nArtificial Intelligence (XAI) subdomain of machine learning. In this work (1)\nwe present the taxonomy of methods for model explanations, (2) we identify and\ncompare 27 packages available in R to perform XAI analysis, (3) we present an\nexample of an application of particular packages, (4) we acknowledge recent\ntrends in XAI. The article is primarily devoted to the tools available in R,\nbut since it is easy to integrate the Python code, we will also show examples\nfor the most popular libraries from Python.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:54:57 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 09:28:06 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 20:59:32 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Maksymiuk", "Szymon", ""], ["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2009.13249", "submitter": "Qianliang Wu", "authors": "Qianliang Wu and Tong Zhang and Zhen Cui and Jian Yang", "title": "Interest-Behaviour Multiplicative Network for Resource-limited\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource constraints, e.g. limited product inventory or financial strength,\nmay affect consumers' choices or preferences in some recommendation tasks but\nare usually ignored in previous recommendation methods. In this paper, we aim\nto mine the cue of user preferences in resource-limited recommendation tasks,\nfor which purpose we specifically build a large used car transaction dataset\npossessing resource-limitation characteristics. Accordingly, we propose an\ninterest-behavior multiplicative network to predict the user's future\ninteraction based on dynamic connections between users and items. To describe\nthe user-item connection dynamically, mutually-recursive recurrent neural\nnetworks (MRRNNs) are introduced to capture interactive long-term dependencies,\nand meantime effective representations of users and items are obtained. To\nfurther take the resource limitation into consideration, a resource-limited\nbranch is built to specifically explore the influence of resource variation on\nuser preferences. Finally, mutual information is introduced to measure the\nsimilarity between the user action and fused features to predict future\ninteraction, where the fused features come from both MRRNNs and\nresource-limited branches. We test the performance on the built used car\ntransaction dataset as well as the Tmall dataset, and the experimental results\nverify the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:11:13 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 12:14:35 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 11:59:18 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 03:08:00 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wu", "Qianliang", ""], ["Zhang", "Tong", ""], ["Cui", "Zhen", ""], ["Yang", "Jian", ""]]}, {"id": "2009.13266", "submitter": "Xinyue Zheng", "authors": "Xinyue Zheng, Peng Wang, Qigang Wang, Zhongchao Shi", "title": "Disentangled Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search has shown its great potential in various areas\nrecently. However, existing methods rely heavily on a black-box controller to\nsearch architectures, which suffers from the serious problem of lacking\ninterpretability. In this paper, we propose disentangled neural architecture\nsearch (DNAS) which disentangles the hidden representation of the controller\ninto semantically meaningful concepts, making the neural architecture search\nprocess interpretable. Based on systematical study, we discover the correlation\nbetween network architecture and its performance, and propose a dense-sampling\nstrategy to conduct a targeted search in promising regions that may generate\nwell-performing architectures. We show that: 1) DNAS successfully disentangles\nthe architecture representations, including operation selection, skip\nconnections, and number of layers. 2) Benefiting from interpretability, DNAS\ncan find excellent architectures under different FLOPS restrictions flexibly.\n3) Dense-sampling leads to neural architecture search with higher efficiency\nand better performance. On the NASBench-101 dataset, DNAS achieves\nstate-of-the-art performance of 94.21% using less than 1/13 computational cost\nof baseline methods. On ImageNet dataset, DNAS discovers the competitive\narchitectures that achieves 22.7% test error. our method provides a new\nperspective of understanding neural architecture search.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 03:35:41 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zheng", "Xinyue", ""], ["Wang", "Peng", ""], ["Wang", "Qigang", ""], ["Shi", "Zhongchao", ""]]}, {"id": "2009.13267", "submitter": "Pedram Rooshenas", "authors": "Sumanta Bhattacharyya, Amirmohammad Rooshenas, Subhajit Naskar, Simeng\n  Sun, Mohit Iyyer, Andrew McCallum", "title": "Energy-Based Reranking: Improving Neural Machine Translation Using\n  Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrepancy between maximum likelihood estimation (MLE) and task measures\nsuch as BLEU score has been studied before for autoregressive neural machine\ntranslation (NMT) and resulted in alternative training algorithms (Ranzato et\nal., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However,\nMLE training remains the de facto approach for autoregressive NMT because of\nits computational efficiency and stability. Despite this mismatch between the\ntraining objective and task measure, we notice that the samples drawn from an\nMLE-based trained NMT support the desired distribution -- there are samples\nwith much higher BLEU score comparing to the beam decoding output. To benefit\nfrom this observation, we train an energy-based model to mimic the behavior of\nthe task measure (i.e., the energy-based model assigns lower energy to samples\nwith higher BLEU score), which is resulted in a re-ranking algorithm based on\nthe samples drawn from NMT: energy-based re-ranking (EBR). We use both marginal\nenergy models (over target sentence) and joint energy models (over both source\nand target sentences). Our EBR with the joint energy model consistently\nimproves the performance of the Transformer-based NMT: +4 BLEU points on\nIWSLT'14 German-English, +3.0 BELU points on Sinhala-English, +1.2 BLEU on\nWMT'16 English-German tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 02:50:52 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 04:57:59 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 05:39:16 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bhattacharyya", "Sumanta", ""], ["Rooshenas", "Amirmohammad", ""], ["Naskar", "Subhajit", ""], ["Sun", "Simeng", ""], ["Iyyer", "Mohit", ""], ["McCallum", "Andrew", ""]]}, {"id": "2009.13270", "submitter": "Rajiv Movva", "authors": "Rajiv Movva, Jason Y. Zhao", "title": "Dissecting Lottery Ticket Transformers: Structural and Behavioral Study\n  of Sparse Neural Machine Translation", "comments": "Camera-ready for BlackboxNLP @ EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent work on the lottery ticket hypothesis has produced highly sparse\nTransformers for NMT while maintaining BLEU. However, it is unclear how such\npruning techniques affect a model's learned representations. By probing\nTransformers with more and more low-magnitude weights pruned away, we find that\ncomplex semantic information is first to be degraded. Analysis of internal\nactivations reveals that higher layers diverge most over the course of pruning,\ngradually becoming less complex than their dense counterparts. Meanwhile, early\nlayers of sparse models begin to perform more encoding. Attention mechanisms\nremain remarkably consistent as sparsity increases.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:08:45 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 18:55:22 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Movva", "Rajiv", ""], ["Zhao", "Jason Y.", ""]]}, {"id": "2009.13272", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun, Cicero Nogueira dos Santos, Jason Krone, Bing Xiang", "title": "Augmented Natural Language for Generative Sequence Labeling", "comments": "To appear at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative framework for joint sequence labeling and\nsentence-level classification. Our model performs multiple sequence labeling\ntasks at once using a single, shared natural language output space. Unlike\nprior discriminative methods, our model naturally incorporates label semantics\nand shares knowledge across tasks. Our framework is general purpose, performing\nwell on few-shot, low-resource, and high-resource tasks. We demonstrate these\nadvantages on popular named entity recognition, slot labeling, and intent\nclassification benchmarks. We set a new state-of-the-art for few-shot slot\nlabeling, improving substantially upon the previous 5-shot ($75.0\\% \\rightarrow\n90.9\\%$) and 1-shot ($70.4\\% \\rightarrow 81.0\\%$) state-of-the-art results.\nFurthermore, our model generates large improvements ($46.27\\% \\rightarrow\n63.83\\%$) in low-resource slot labeling over a BERT baseline by incorporating\nlabel semantics. We also maintain competitive results on high-resource tasks,\nperforming within two points of the state-of-the-art on all tasks and setting a\nnew state-of-the-art on the SNIPS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 19:23:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Santos", "Cicero Nogueira dos", ""], ["Krone", "Jason", ""], ["Xiang", "Bing", ""]]}, {"id": "2009.13291", "submitter": "Roberto Molinaro", "authors": "Siddhartha Mishra and Roberto Molinaro", "title": "Physics Informed Neural Networks for Simulating Radiative Transfer", "comments": null, "journal-ref": null, "doi": "10.1016/j.jqsrt.2021.107705", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel machine learning algorithm for simulating radiative\ntransfer. Our algorithm is based on physics informed neural networks (PINNs),\nwhich are trained by minimizing the residual of the underlying radiative\ntranfer equations. We present extensive experiments and theoretical error\nestimates to demonstrate that PINNs provide a very easy to implement, fast,\nrobust and accurate method for simulating radiative transfer. We also present a\nPINN based algorithm for simulating inverse problems for radiative transfer\nefficiently.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:07:02 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 12:42:59 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Mishra", "Siddhartha", ""], ["Molinaro", "Roberto", ""]]}, {"id": "2009.13292", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Oren Barkan, Avi Caciularu, Noam Razin, Ori Katz and\n  Noam Koenigstein", "title": "RecoBERT: A Catalog Language Model for Text-Based Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models that utilize extensive self-supervised pre-training from\nunlabeled text, have recently shown to significantly advance the\nstate-of-the-art performance in a variety of language understanding tasks.\nHowever, it is yet unclear if and how these recent models can be harnessed for\nconducting text-based recommendations. In this work, we introduce RecoBERT, a\nBERT-based approach for learning catalog-specialized language models for\ntext-based item recommendations. We suggest novel training and inference\nprocedures for scoring similarities between pairs of items, that don't require\nitem similarity labels. Both the training and the inference techniques were\ndesigned to utilize the unlabeled structure of textual catalogs, and minimize\nthe discrepancy between them. By incorporating four scores during inference,\nRecoBERT can infer text-based item-to-item similarities more accurately than\nother techniques. In addition, we introduce a new language understanding task\nfor wine recommendations using similarities based on professional wine reviews.\nAs an additional contribution, we publish annotated recommendations dataset\ncrafted by human wine experts. Finally, we evaluate RecoBERT and compare it to\nvarious state-of-the-art NLP models on wine and fashion recommendations tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 14:23:38 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Malkiel", "Itzik", ""], ["Barkan", "Oren", ""], ["Caciularu", "Avi", ""], ["Razin", "Noam", ""], ["Katz", "Ori", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2009.13333", "submitter": "Lei Huang", "authors": "Lei Huang, Yi Zhou, Li Liu, Fan Zhu, Ling Shao", "title": "Group Whitening: Balancing Learning Efficiency and Representational\n  Capacity", "comments": "V4: camera version of CVPR 2021. Code available at:\n  https://github.com/huangleiBuaa/GroupWhitening", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization (BN) is an important technique commonly incorporated into\ndeep learning models to perform standardization within mini-batches. The merits\nof BN in improving a model's learning efficiency can be further amplified by\napplying whitening, while its drawbacks in estimating population statistics for\ninference can be avoided through group normalization (GN). This paper proposes\ngroup whitening (GW), which exploits the advantages of the whitening operation\nand avoids the disadvantages of normalization within mini-batches. In addition,\nwe analyze the constraints imposed on features by normalization, and show how\nthe batch size (group number) affects the performance of batch (group)\nnormalized networks, from the perspective of model's representational capacity.\nThis analysis provides theoretical guidance for applying GW in practice.\nFinally, we apply the proposed GW to ResNet and ResNeXt architectures and\nconduct experiments on the ImageNet and COCO benchmarks. Results show that GW\nconsistently improves the performance of different architectures, with absolute\ngains of $1.02\\%$ $\\sim$ $1.49\\%$ in top-1 accuracy on ImageNet and $1.82\\%$\n$\\sim$ $3.21\\%$ in bounding box AP on COCO.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:00:07 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 12:29:51 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 09:46:16 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 04:17:27 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Huang", "Lei", ""], ["Zhou", "Yi", ""], ["Liu", "Li", ""], ["Zhu", "Fan", ""], ["Shao", "Ling", ""]]}, {"id": "2009.13357", "submitter": "Risheng Liu", "authors": "Yaohua Liu, Risheng Liu", "title": "BOML: A Modularized Bilevel Optimization Library in Python for Meta\n  Learning", "comments": "six pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning (a.k.a. learning to learn) has recently emerged as a promising\nparadigm for a variety of applications. There are now many meta-learning\nmethods, each focusing on different modeling aspects of base and meta learners,\nbut all can be (re)formulated as specific bilevel optimization problems. This\nwork presents BOML, a modularized optimization library that unifies several\nmeta-learning algorithms into a common bilevel optimization framework. It\nprovides a hierarchical optimization pipeline together with a variety of\niteration modules, which can be used to solve the mainstream categories of\nmeta-learning methods, such as meta-feature-based and meta-initialization-based\nformulations. The library is written in Python and is available at\nhttps://github.com/dut-media-lab/BOML.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:21:55 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Yaohua", ""], ["Liu", "Risheng", ""]]}, {"id": "2009.13366", "submitter": "Giorgos Vernikos", "authors": "Giorgos Vernikos, Katerina Margatina, Alexandra Chronopoulou, Ion\n  Androutsopoulos", "title": "Domain Adversarial Fine-Tuning as an Effective Regularizer", "comments": "EMNLP 2020, Findings of EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Processing (NLP), pretrained language models (LMs) that\nare transferred to downstream tasks have been recently shown to achieve\nstate-of-the-art results. However, standard fine-tuning can degrade the\ngeneral-domain representations captured during pretraining. To address this\nissue, we introduce a new regularization technique, AFTER; domain Adversarial\nFine-Tuning as an Effective Regularizer. Specifically, we complement the\ntask-specific loss used during fine-tuning with an adversarial objective. This\nadditional loss term is related to an adversarial classifier, that aims to\ndiscriminate between in-domain and out-of-domain text representations.\nIn-domain refers to the labeled dataset of the task at hand while out-of-domain\nrefers to unlabeled data from a different domain. Intuitively, the adversarial\nclassifier acts as a regularizer which prevents the model from overfitting to\nthe task-specific domain. Empirical results on various natural language\nunderstanding tasks show that AFTER leads to improved performance compared to\nstandard fine-tuning.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:35:06 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 23:56:19 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Vernikos", "Giorgos", ""], ["Margatina", "Katerina", ""], ["Chronopoulou", "Alexandra", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "2009.13370", "submitter": "Lan Truong", "authors": "Lan V. Truong", "title": "Replica Analysis of the Linear Model with Markov or Hidden Markov Signal\n  Priors", "comments": "Add MCMC simulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper estimates free energy, average mutual information, and minimum\nmean square error (MMSE) of a linear model under two assumptions: (1) the\nsource is generated by a Markov chain, (2) the source is generated via a hidden\nMarkov model. Our estimates are based on the replica method in statistical\nphysics. We show that under the posterior mean estimator, the linear model with\nMarkov sources or hidden Markov sources is decoupled into single-input AWGN\nchannels with state information available at both encoder and decoder where the\nstate distribution follows the left Perron-Frobenius eigenvector with unit\nManhattan norm of the stochastic matrix of Markov chains. Numerical results\nshow that the free energies and MSEs obtained via the replica method closely\napproximate to their counterparts achieved by the Metropolis-Hastings algorithm\nor some well-known approximate message passing algorithms in the research\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:38:52 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 15:13:35 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Truong", "Lan V.", ""]]}, {"id": "2009.13384", "submitter": "Michael B\\\"ucker", "authors": "Michael B\\\"ucker and Gero Szepannek and Alicja Gosiewska and\n  Przemyslaw Biecek", "title": "Transparency, Auditability and eXplainability of Machine Learning Models\n  in Credit Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.GN q-fin.EC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major requirement for credit scoring models is to provide a maximally\naccurate risk prediction. Additionally, regulators demand these models to be\ntransparent and auditable. Thus, in credit scoring, very simple predictive\nmodels such as logistic regression or decision trees are still widely used and\nthe superior predictive power of modern machine learning algorithms cannot be\nfully leveraged. Significant potential is therefore missed, leading to higher\nreserves or more credit defaults. This paper works out different dimensions\nthat have to be considered for making credit scoring models understandable and\npresents a framework for making ``black box'' machine learning models\ntransparent, auditable and explainable. Following this framework, we present an\noverview of techniques, demonstrate how they can be applied in credit scoring\nand how results compare to the interpretability of score cards. A real world\ncase study shows that a comparable degree of interpretability can be achieved\nwhile machine learning techniques keep their ability to improve predictive\npower.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:00:13 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["B\u00fccker", "Michael", ""], ["Szepannek", "Gero", ""], ["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2009.13405", "submitter": "Aymen Al Marjani", "authors": "Aymen Al Marjani and Alexandre Proutiere", "title": "Adaptive Sampling for Best Policy Identification in Markov Decision\n  Processes", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of best-policy identification in discounted Markov\nDecision Processes (MDPs) when the learner has access to a generative model.\nThe objective is to devise a learning algorithm returning the best policy as\nearly as possible. We first derive a problem-specific lower bound of the sample\ncomplexity satisfied by any learning algorithm. This lower bound corresponds to\nan optimal sample allocation that solves a non-convex program, and hence, is\nhard to exploit in the design of efficient algorithms. We then provide a simple\nand tight upper bound of the sample complexity lower bound, whose corresponding\nnearly-optimal sample allocation becomes explicit. The upper bound depends on\nspecific functionals of the MDP such as the sub-optimality gaps and the\nvariance of the next-state value function, and thus really captures the\nhardness of the MDP. Finally, we devise KLB-TS (KL Ball Track-and-Stop), an\nalgorithm tracking this nearly-optimal allocation, and provide asymptotic\nguarantees for its sample complexity (both almost surely and in expectation).\nThe advantages of KLB-TS against state-of-the-art algorithms are discussed and\nillustrated numerically.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:22:24 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 17:15:58 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 15:45:40 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 16:40:20 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Marjani", "Aymen Al", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "2009.13423", "submitter": "Marwah Soliman", "authors": "Marwah Soliman, Vyacheslav Lyubchich, Yulia R. Gel", "title": "Ensemble Forecasting of the Zika Space-TimeSpread with Topological Data\n  Analysis", "comments": "29 page, 5 figures", "journal-ref": "Environmetrics, 2020", "doi": null, "report-no": null, "categories": "q-bio.PE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As per the records of theWorld Health Organization, the first formally\nreported incidence of Zika virus occurred in Brazil in May 2015. The disease\nthen rapidly spread to other countries in Americas and East Asia, affecting\nmore than 1,000,000 people. Zika virus is primarily transmitted through bites\nof infected mosquitoes of the species Aedes (Aedes aegypti and Aedes\nalbopictus). The abundance of mosquitoes and, as a result, the prevalence of\nZika virus infections are common in areas which have high precipitation, high\ntemperature, and high population density.Nonlinear spatio-temporal dependency\nof such data and lack of historical public health records make prediction of\nthe virus spread particularly challenging. In this article, we enhance Zika\nforecasting by introducing the concepts of topological data analysis and,\nspecifically, persistent homology of atmospheric variables, into the virus\nspread modeling. The topological summaries allow for capturing higher order\ndependencies among atmospheric variables that otherwise might be unassessable\nvia conventional spatio-temporal modeling approaches based on geographical\nproximity assessed via Euclidean distance. We introduce a new concept of\ncumulative Betti numbers and then integrate the cumulative Betti numbers as\ntopological descriptors into three predictive machine learning models: random\nforest, generalized boosted regression, and deep neural network. Furthermore,\nto better quantify for various sources of uncertainties, we combine the\nresulting individual model forecasts into an ensemble of the Zika spread\npredictions using Bayesian model averaging. The proposed methodology is\nillustrated in application to forecasting of the Zika space-time spread in\nBrazil in the year 2018.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:42:19 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Soliman", "Marwah", ""], ["Lyubchich", "Vyacheslav", ""], ["Gel", "Yulia R.", ""]]}, {"id": "2009.13437", "submitter": "Bernat Coma-Puig", "authors": "Bernat Coma-Puig, Josep Carmona", "title": "An Iterative Approach based on Explainability to Improve the Learning of\n  Fraud Detection Models", "comments": "14 pages, 6 figures. Pre-Print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing predictive models in utility companies to detect Non-Technical\nLosses (i.e. fraud and other meter problems) is challenging: the data available\nis biased, and the algorithms usually used are black-boxes that can not be\neither easily trusted or understood by the stakeholders. In this work, we\nexplain our approach to mitigate these problems in a real supervised system to\ndetect non-technical losses for an international utility company from Spain.\nThis approach exploits human knowledge (e.g. from the data scientists or the\ncompany's stakeholders), and the information provided by explanatory methods to\nimplement smart feature engineering. This simple, efficient method that can be\neasily implemented in other industrial projects is tested in a real dataset and\nthe results evidence that the derived prediction model is better in terms of\naccuracy, interpretability, robustness and flexibility.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:04:07 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Coma-Puig", "Bernat", ""], ["Carmona", "Josep", ""]]}, {"id": "2009.13447", "submitter": "Lexing Ying", "authors": "Jing An, Lexing Ying, Yuhua Zhu", "title": "Why resampling outperforms reweighting for correcting sampling bias with\n  stochastic gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A data set sampled from a certain population is biased if the subgroups of\nthe population are sampled at proportions that are significantly different from\ntheir underlying proportions. Training machine learning models on biased data\nsets requires correction techniques to compensate for the bias. We consider two\ncommonly-used techniques, resampling and reweighting, that rebalance the\nproportions of the subgroups to maintain the desired objective function. Though\nstatistically equivalent, it has been observed that resampling outperforms\nreweighting when combined with stochastic gradient algorithms. By analyzing\nillustrative examples, we explain the reason behind this phenomenon using tools\nfrom dynamical stability and stochastic asymptotics. We also present\nexperiments from regression, classification, and off-policy prediction to\ndemonstrate that this is a general phenomenon. We argue that it is imperative\nto consider the objective function design and the optimization algorithm\ntogether while addressing the sampling bias.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:12:38 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 07:57:53 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["An", "Jing", ""], ["Ying", "Lexing", ""], ["Zhu", "Yuhua", ""]]}, {"id": "2009.13472", "submitter": "Matthew Vowels", "authors": "Matthew James Vowels and Necati Cihan Camgoz and Richard Bowden", "title": "Targeted VAE: Variational and Targeted Learning for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undertaking causal inference with observational data is incredibly useful\nacross a wide range of tasks including the development of medical treatments,\nadvertisements and marketing, and policy making. There are two significant\nchallenges associated with undertaking causal inference using observational\ndata: treatment assignment heterogeneity (i.e., differences between the treated\nand untreated groups), and an absence of counterfactual data (i.e., not knowing\nwhat would have happened if an individual who did get treatment, were instead\nto have not been treated). We address these two challenges by combining\nstructured inference and targeted learning. In terms of structure, we factorize\nthe joint distribution into risk, confounding, instrumental, and miscellaneous\nfactors, and in terms of targeted learning, we apply a regularizer derived from\nthe influence curve in order to reduce residual bias. An ablation study is\nundertaken, and an evaluation on benchmark datasets demonstrates that TVAE has\ncompetitive and state of the art performance across.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:55:24 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 17:35:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Vowels", "Matthew James", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "2009.13484", "submitter": "Marcelo Medeiros", "authors": "Carlos B. Carneiro, I\\'uri H. Ferreira, Marcelo C. Medeiros, Henrique\n  F. Pires and Eduardo Zilberman", "title": "Lockdown effects in US states: an artificial counterfactual approach", "comments": "Updated versions of this paper will be available on\n  http://139.82.34.174/mcm/", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP econ.EM econ.GN q-fin.EC stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adopt an artificial counterfactual approach to assess the impact of\nlockdowns on the short-run evolution of the number of cases and deaths in some\nUS states. To do so, we explore the different timing in which US states adopted\nlockdown policies, and divide them among treated and control groups. For each\ntreated state, we construct an artificial counterfactual. On average, and in\nthe very short-run, the counterfactual accumulated number of cases would be two\ntimes larger if lockdown policies were not implemented.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:21:03 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 18:27:55 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Carneiro", "Carlos B.", ""], ["Ferreira", "I\u00fari H.", ""], ["Medeiros", "Marcelo C.", ""], ["Pires", "Henrique F.", ""], ["Zilberman", "Eduardo", ""]]}, {"id": "2009.13498", "submitter": "Josimar Chire Saire", "authors": "Diana C. Roca Arroyo, Josimar E. Chire Saire", "title": "Parameter Experimental Analysis of the Reservoirs Observers using Echo\n  State Network Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems has a variety of applications for the new information\ngenerated during the time. Many phenomenons like physical, chemical or social\nare not static, then an analysis over the time is necessary. In this work, an\nexperimental analysis of parameters of the model Echo State Network is\nperformed and the influence of the kind of Complex Network is explored to\nunderstand the influence on the performance. The experiments are performed\nusing the Rossler attractor.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:45:52 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Arroyo", "Diana C. Roca", ""], ["Saire", "Josimar E. Chire", ""]]}, {"id": "2009.13500", "submitter": "Stephan Wojtowytsch", "authors": "Weinan E and Stephan Wojtowytsch", "title": "A priori estimates for classification problems using neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider binary and multi-class classification problems using hypothesis\nclasses of neural networks. For a given hypothesis class, we use Rademacher\ncomplexity estimates and direct approximation theorems to obtain a priori error\nestimates for regularized loss functionals.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:47:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["E", "Weinan", ""], ["Wojtowytsch", "Stephan", ""]]}, {"id": "2009.13503", "submitter": "Zihan Zhang", "authors": "Zihan Zhang, Xiangyang Ji, Simon S. Du", "title": "Is Reinforcement Learning More Difficult Than Bandits? A Near-optimal\n  Algorithm Escaping the Curse of Horizon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic reinforcement learning and contextual bandits are two widely studied\nsequential decision-making problems. Episodic reinforcement learning\ngeneralizes contextual bandits and is often perceived to be more difficult due\nto long planning horizon and unknown state-dependent transitions. The current\npaper shows that the long planning horizon and the unknown state-dependent\ntransitions (at most) pose little additional difficulty on sample complexity.\n  We consider the episodic reinforcement learning with $S$ states, $A$ actions,\nplanning horizon $H$, total reward bounded by $1$, and the agent plays for $K$\nepisodes. We propose a new algorithm, \\textbf{M}onotonic \\textbf{V}alue\n\\textbf{P}ropagation (MVP), which relies on a new Bernstein-type bonus.\nCompared to existing bonus constructions, the new bonus is tighter since it is\nbased on a well-designed monotonic value function. In particular, the\n\\emph{constants} in the bonus should be subtly setting to ensure optimism and\nmonotonicity.\n  We show MVP enjoys an $O\\left(\\left(\\sqrt{SAK} + S^2A\\right) \\poly\\log\n\\left(SAHK\\right)\\right)$ regret, approaching the\n$\\Omega\\left(\\sqrt{SAK}\\right)$ lower bound of \\emph{contextual bandits} up to\nlogarithmic terms. Notably, this result 1) \\emph{exponentially} improves the\nstate-of-the-art polynomial-time algorithms by Dann et al. [2019] and Zanette\net al. [2019] in terms of the dependency on $H$, and 2) \\emph{exponentially}\nimproves the running time in [Wang et al. 2020] and significantly improves the\ndependency on $S$, $A$ and $K$ in sample complexity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:52:32 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 07:06:10 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhang", "Zihan", ""], ["Ji", "Xiangyang", ""], ["Du", "Simon S.", ""]]}, {"id": "2009.13504", "submitter": "Peiyuan Liao", "authors": "Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon,\n  Stefanie Jegelka, Ruslan Salakhutdinov", "title": "Information Obfuscation of Graph Neural Networks", "comments": "ICML 2021; Code is available at https://github.com/liaopeiyuan/GAL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the advent of Graph Neural Networks (GNNs) has greatly improved node\nand graph representation learning in many applications, the neighborhood\naggregation scheme exposes additional vulnerabilities to adversaries seeking to\nextract node-level information about sensitive attributes. In this paper, we\nstudy the problem of protecting sensitive attributes by information obfuscation\nwhen learning with graph structured data. We propose a framework to locally\nfilter out pre-determined sensitive attributes via adversarial training with\nthe total variation and the Wasserstein distance. Our method creates a strong\ndefense against inference attacks, while only suffering small loss in task\nperformance. Theoretically, we analyze the effectiveness of our framework\nagainst a worst-case adversary, and characterize an inherent trade-off between\nmaximizing predictive accuracy and minimizing information leakage. Experiments\nacross multiple datasets from recommender systems, knowledge graphs and quantum\nchemistry demonstrate that the proposed approach provides a robust defense\nacross various graph structures and tasks, while producing competitive GNN\nencoders for downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:55:04 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:34:52 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 16:27:46 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 06:25:27 GMT"}, {"version": "v5", "created": "Sun, 13 Jun 2021 05:35:04 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liao", "Peiyuan", ""], ["Zhao", "Han", ""], ["Xu", "Keyulu", ""], ["Jaakkola", "Tommi", ""], ["Gordon", "Geoffrey", ""], ["Jegelka", "Stefanie", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2009.13511", "submitter": "Esteban Vilca", "authors": "Esteban Wilfredo Vilca Zu\\~niga, Liang Zhao", "title": "A new network-base high-level data classification methodology (Quipus)\n  by modeling attribute-attribute interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-level classification algorithms focus on the interactions between\ninstances. These produce a new form to evaluate and classify data. In this\nprocess, the core is a complex network building methodology. The current\nmethodologies use variations of kNN to produce these graphs. However, these\ntechniques ignore some hidden patterns between attributes and require\nnormalization to be accurate. In this paper, we propose a new methodology for\nnetwork building based on attribute-attribute interactions that do not require\nnormalization. The current results show us that this approach improves the\naccuracy of the high-level classification algorithm based on betweenness\ncentrality.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:58:12 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zu\u00f1iga", "Esteban Wilfredo Vilca", ""], ["Zhao", "Liang", ""]]}, {"id": "2009.13512", "submitter": "Sitan Chen", "authors": "Sitan Chen, Adam R. Klivans, Raghu Meka", "title": "Learning Deep ReLU Networks Is Fixed-Parameter Tractable", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning an unknown ReLU network with respect to\nGaussian inputs and obtain the first nontrivial results for networks of depth\nmore than two. We give an algorithm whose running time is a fixed polynomial in\nthe ambient dimension and some (exponentially large) function of only the\nnetwork's parameters.\n  Our bounds depend on the number of hidden units, depth, spectral norm of the\nweight matrices, and Lipschitz constant of the overall network (we show that\nsome dependence on the Lipschitz constant is necessary). We also give a bound\nthat is doubly exponential in the size of the network but is independent of\nspectral norm. These results provably cannot be obtained using gradient-based\nmethods and give the first example of a class of efficiently learnable neural\nnetworks that gradient descent will fail to learn.\n  In contrast, prior work for learning networks of depth three or higher\nrequires exponential time in the ambient dimension, even when the above\nparameters are bounded by a constant. Additionally, all prior work for the\ndepth-two case requires well-conditioned weights and/or positive coefficients\nto obtain efficient run-times. Our algorithm does not require these\nassumptions.\n  Our main technical tool is a type of filtered PCA that can be used to\niteratively recover an approximate basis for the subspace spanned by the hidden\nunits in the first layer. Our analysis leverages new structural results on\nlattice polynomials from tropical geometry.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:58:43 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Sitan", ""], ["Klivans", "Adam R.", ""], ["Meka", "Raghu", ""]]}, {"id": "2009.13562", "submitter": "Jacob Springer", "authors": "Jacob M. Springer, Bryn Marie Reinstadler, Una-May O'Reilly", "title": "STRATA: Building Robustness with a Simple Method for Generating\n  Black-box Adversarial Attacks for Models of Code", "comments": "13 pages, 3 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are imperceptible perturbations in the input to a neural\nmodel that result in misclassification. Generating adversarial examples for\nsource code poses an additional challenge compared to the domains of images and\nnatural language, because source code perturbations must adhere to strict\nsemantic guidelines so the resulting programs retain the functional meaning of\nthe code. We propose a simple and efficient black-box method for generating\nstate-of-the-art adversarial examples on models of code. Our method generates\nuntargeted and targeted attacks, and empirically outperforms competing\ngradient-based methods with less information and less computational effort. We\nalso use adversarial training to construct a model robust to these attacks; our\nattack reduces the F1 score of code2seq by 42%. Adversarial training brings the\nF1 score on adversarial examples up to 99% of baseline.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:21:19 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Springer", "Jacob M.", ""], ["Reinstadler", "Bryn Marie", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2009.13566", "submitter": "Jiong Zhu", "authors": "Jiong Zhu, Ryan A. Rossi, Anup Rao, Tung Mai, Nedim Lipka, Nesreen K.\n  Ahmed, Danai Koutra", "title": "Graph Neural Networks with Heterophily", "comments": "Proceedings version of AAAI 2021 with appendix and additional typo\n  fixes; 12 pages, 4 figures", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence. 35,\n  12 (May 2021), 11168-11176", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have proven to be useful for many different\npractical applications. However, many existing GNN models have implicitly\nassumed homophily among the nodes connected in the graph, and therefore have\nlargely overlooked the important setting of heterophily, where most connected\nnodes are from different classes. In this work, we propose a novel framework\ncalled CPGNN that generalizes GNNs for graphs with either homophily or\nheterophily. The proposed framework incorporates an interpretable compatibility\nmatrix for modeling the heterophily or homophily level in the graph, which can\nbe learned in an end-to-end fashion, enabling it to go beyond the assumption of\nstrong homophily. Theoretically, we show that replacing the compatibility\nmatrix in our framework with the identity (which represents pure homophily)\nreduces to GCN. Our extensive experiments demonstrate the effectiveness of our\napproach in more realistic and challenging experimental settings with\nsignificantly less training data compared to previous works: CPGNN variants\nachieve state-of-the-art results in heterophily settings with or without\ncontextual node features, while maintaining comparable performance in homophily\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:29:36 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 08:19:28 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 19:54:57 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhu", "Jiong", ""], ["Rossi", "Ryan A.", ""], ["Rao", "Anup", ""], ["Mai", "Tung", ""], ["Lipka", "Nedim", ""], ["Ahmed", "Nesreen K.", ""], ["Koutra", "Danai", ""]]}, {"id": "2009.13579", "submitter": "Ruo Yu Tao", "authors": "Ruo Yu Tao, Vincent Fran\\c{c}ois-Lavet, Joelle Pineau", "title": "Novelty Search in Representational Space for Sample Efficient\n  Exploration", "comments": "10 pages + references + appendix. Oral presentation at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for efficient exploration which leverages a\nlow-dimensional encoding of the environment learned with a combination of\nmodel-based and model-free objectives. Our approach uses intrinsic rewards that\nare based on the distance of nearest neighbors in the low dimensional\nrepresentational space to gauge novelty. We then leverage these intrinsic\nrewards for sample-efficient exploration with planning routines in\nrepresentational space for hard exploration tasks with sparse rewards. One key\nelement of our approach is the use of information theoretic principles to shape\nour representations in a way so that our novelty reward goes beyond pixel\nsimilarity. We test our approach on a number of maze tasks, as well as a\ncontrol problem and show that our exploration approach is more sample-efficient\ncompared to strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:51:52 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 19:48:33 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tao", "Ruo Yu", ""], ["Fran\u00e7ois-Lavet", "Vincent", ""], ["Pineau", "Joelle", ""]]}, {"id": "2009.13586", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma", "title": "Apollo: An Adaptive Parameter-wise Diagonal Quasi-Newton Method for\n  Nonconvex Stochastic Optimization", "comments": "Fixed errors in convergence analysis. 29 pages (plus appendix), 6\n  figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Apollo, a quasi-Newton method for nonconvex\nstochastic optimization, which dynamically incorporates the curvature of the\nloss function by approximating the Hessian via a diagonal matrix. Importantly,\nthe update and storage of the diagonal approximation of Hessian is as efficient\nas adaptive first-order optimization methods with linear complexity for both\ntime and memory. To handle nonconvexity, we replace the Hessian with its\nrectified absolute value, which is guaranteed to be positive-definite.\nExperiments on three tasks of vision and language show that Apollo achieves\nsignificant improvements over other stochastic optimization methods, including\nSGD and variants of Adam, in term of both convergence speed and generalization\nperformance. The implementation of the algorithm is available at\nhttps://github.com/XuezheMax/apollo.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 19:07:02 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 07:45:24 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 05:47:47 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 06:57:57 GMT"}, {"version": "v5", "created": "Fri, 2 Apr 2021 05:41:25 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Ma", "Xuezhe", ""]]}, {"id": "2009.13598", "submitter": "Chen Zhong", "authors": "Chen Zhong, M. Cenk Gursoy, and Senem Velipasalar", "title": "Anomaly Detection and Sampling Cost Control via Hierarchical GANs", "comments": "6 pages, 7 figures, has been accepted by Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection incurs certain sampling and sensing costs and therefore it\nis of great importance to strike a balance between the detection accuracy and\nthese costs. In this work, we study anomaly detection by considering the\ndetection of threshold crossings in a stochastic time series without the\nknowledge of its statistics. To reduce the sampling cost in this detection\nprocess, we propose the use of hierarchical generative adversarial networks\n(GANs) to perform nonuniform sampling. In order to improve the detection\naccuracy and reduce the delay in detection, we introduce a buffer zone in the\noperation of the proposed GAN-based detector. In the experiments, we analyze\nthe performance of the proposed hierarchical GAN detector considering the\nmetrics of detection delay, miss rates, average cost of error, and sampling\nratio. We identify the tradeoffs in the performance as the buffer zone sizes\nand the number of GAN levels in the hierarchy vary. We also compare the\nperformance with that of a sampling policy that approximately minimizes the sum\nof average costs of sampling and error given the parameters of the stochastic\nprocess. We demonstrate that the proposed GAN-based detector can have\nsignificant performance improvements in terms of detection delay and average\ncost of error with a larger buffer zone but at the cost of increased sampling\nrates.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 19:39:51 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zhong", "Chen", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "2009.13697", "submitter": "Mengyuan Lee", "authors": "Mengyuan Lee, Seyyedali Hosseinalipour, Christopher G. Brinton,\n  Guanding Yu, and Huaiyu Dai", "title": "A Fast Graph Neural Network-Based Method for Winner Determination in\n  Multi-Unit Combinatorial Auctions", "comments": "Accepted by Transactions on Cloud Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combinatorial auction (CA) is an efficient mechanism for resource\nallocation in different fields, including cloud computing. It can obtain high\neconomic efficiency and user flexibility by allowing bidders to submit bids for\ncombinations of different items instead of only for individual items. However,\nthe problem of allocating items among the bidders to maximize the auctioneers\"\nrevenue, i.e., the winner determination problem (WDP), is NP-complete to solve\nand inapproximable. Existing works for WDPs are generally based on mathematical\noptimization techniques and most of them focus on the single-unit WDP, where\neach item only has one unit. On the contrary, few works consider the multi-unit\nWDP in which each item may have multiple units. Given that the multi-unit WDP\nis more complicated but prevalent in cloud computing, we propose leveraging\nmachine learning (ML) techniques to develop a novel low-complexity algorithm\nfor solving this problem with negligible revenue loss. Specifically, we model\nthe multi-unit WDP as an augmented bipartite bid-item graph and use a graph\nneural network (GNN) with half-convolution operations to learn the probability\nof each bid belonging to the optimal allocation. To improve the sample\ngeneration efficiency and decrease the number of needed labeled instances, we\npropose two different sample generation processes. We also develop two novel\ngraph-based post-processing algorithms to transform the outputs of the GNN into\nfeasible solutions. Through simulations on both synthetic instances and a\nspecific virtual machine (VM) allocation problem in a cloud computing platform,\nwe validate that our proposed method can approach optimal performance with low\ncomplexity and has good generalization ability in terms of problem size and\nuser-type distribution.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 00:22:37 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:31:41 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Lee", "Mengyuan", ""], ["Hosseinalipour", "Seyyedali", ""], ["Brinton", "Christopher G.", ""], ["Yu", "Guanding", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2009.13714", "submitter": "Pu Zhao", "authors": "Pu Zhao, Sijia Liu, Parikshit Ram, Songtao Lu, Yuguang Yao, Djallel\n  Bouneffouf, Xue Lin", "title": "Learned Fine-Tuner for Incongruous Few-Shot Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Model-agnostic meta-learning (MAML) effectively meta-learns an initialization\nof model parameters for few-shot learning where all learning problems share the\nsame format of model parameters -- congruous meta-learning. However, there are\nfew-shot learning scenarios, such as adversarial attack design, where different\nyet related few-shot learning problems may not share any optimizee variables,\nnecessitating incongruous meta-learning. We extend MAML to this setting -- a\nLearned Fine Tuner (LFT) is used to replace hand-designed optimizers (such as\nSGD) for the task-specific fine-tuning. Here, MAML instead meta-learns the\nparameters of this LFT across incongruous tasks leveraging the\nlearning-to-optimize (L2O) framework such that models fine-tuned with LFT (even\nfrom random initializations) adapt quickly to new tasks. As novel\ncontributions, we show that the use of LFT within MAML (i) offers the\ncapability to tackle few-shot learning tasks by meta-learning across\nincongruous yet related problems and (ii) can efficiently work with first-order\nand derivative-free few-shot learning problems. Theoretically, we quantify the\ndifference between LFT (for MAML) and L2O. Empirically, we demonstrate the\neffectiveness of LFT through a novel application of generating universal\nadversarial attacks across different image sources and sizes in the few-shot\nlearning regime.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 01:23:20 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 00:47:28 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 17:42:57 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Ram", "Parikshit", ""], ["Lu", "Songtao", ""], ["Yao", "Yuguang", ""], ["Bouneffouf", "Djallel", ""], ["Lin", "Xue", ""]]}, {"id": "2009.13734", "submitter": "Mohammad Esmaeili", "authors": "Mohammad Esmaeili, and Aria Nosratinia", "title": "Semi-Supervised Node Classification by Graph Convolutional Networks and\n  Extracted Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nodes of a graph existing in a cluster are more likely to connect to each\nother than with other nodes in the graph. Then revealing some information about\nsome nodes, the structure of the graph (graph edges) provides this opportunity\nto know more information about other nodes. From this perspective, this paper\nrevisits the node classification task in a semi-supervised scenario by graph\nconvolutional networks (GCNs). The goal is to benefit from the flow of\ninformation that circulates around the revealed node labels. The contribution\nof this paper is twofold. First, this paper provides a method for extracting\nside information from a graph realization. Then a new GCN architecture is\npresented that combines the output of traditional GCN and the extracted side\ninformation. Another contribution of this paper is relevant to non-graph\nobservations (independent side information) that exists beside a graph\nrealization in many applications. Indeed, the extracted side information can be\nreplaced by a sequence of side information that is independent of the graph\nstructure. For both cases, the experiments on synthetic and real-world datasets\ndemonstrate that the proposed model achieves a higher prediction accuracy in\ncomparison to the existing state-of-the-art methods for the node classification\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 02:38:58 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 19:18:33 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Esmaeili", "Mohammad", ""], ["Nosratinia", "Aria", ""]]}, {"id": "2009.13736", "submitter": "Yunshu Du", "authors": "Yunshu Du, Garrett Warnell, Assefaw Gebremedhin, Peter Stone, Matthew\n  E. Taylor", "title": "Lucid Dreaming for Experience Replay: Refreshing Past States with the\n  Current Policy", "comments": "29 pages (with appendices), 8 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay (ER) improves the data efficiency of off-policy\nreinforcement learning (RL) algorithms by allowing an agent to store and reuse\nits past experiences in a replay buffer. While many techniques have been\nproposed to enhance ER by biasing how experiences are sampled from the buffer,\nthus far they have not considered strategies for refreshing experiences inside\nthe buffer. In this work, we introduce Lucid Dreaming for Experience Replay\n(LiDER), a conceptually new framework that allows replay experiences to be\nrefreshed by leveraging the agent's current policy. LiDER consists of three\nsteps: First, LiDER moves an agent back to a past state. Second, from that\nstate, LiDER then lets the agent execute a sequence of actions by following its\ncurrent policy -- as if the agent were \"dreaming\" about the past and can try\nout different behaviors to encounter new experiences in the dream. Third, LiDER\nstores and reuses the new experience if it turned out better than what the\nagent previously experienced, i.e., to refresh its memories. LiDER is designed\nto be easily incorporated into off-policy, multi-worker RL algorithms that use\nER; we present in this work a case study of applying LiDER to an actor-critic\nbased algorithm. Results show LiDER consistently improves performance over the\nbaseline in six Atari 2600 games. Our open-source implementation of LiDER and\nthe data used to generate all plots in this work are available at\ngithub.com/duyunshu/lucid-dreaming-for-exp-replay.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 02:54:11 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 19:54:39 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 23:43:26 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Du", "Yunshu", ""], ["Warnell", "Garrett", ""], ["Gebremedhin", "Assefaw", ""], ["Stone", "Peter", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "2009.13794", "submitter": "Weiran Yao", "authors": "Weiran Yao, Sean Qian", "title": "From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction\n  Using Social Media Data", "comments": null, "journal-ref": "Transportation research part C: emerging technologies 124 (2021):\n  102938", "doi": "10.1016/j.trc.2020.102938", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of traditional traffic prediction methods is often\nextremely limited when forecasting traffic dynamics in early morning. The\nreason is that traffic can break down drastically during the early morning\ncommute, and the time and duration of this break-down vary substantially from\nday to day. Early morning traffic forecast is crucial to inform morning-commute\ntraffic management, but they are generally challenging to predict in advance,\nparticularly by midnight. In this paper, we propose to mine Twitter messages as\na probing method to understand the impacts of people's work and rest patterns\nin the evening/midnight of the previous day to the next-day morning traffic.\nThe model is tested on freeway networks in Pittsburgh as experiments. The\nresulting relationship is surprisingly simple and powerful. We find that, in\ngeneral, the earlier people rest as indicated from Tweets, the more congested\nroads will be in the next morning. The occurrence of big events in the evening\nbefore, represented by higher or lower tweet sentiment than normal, often\nimplies lower travel demand in the next morning than normal days. Besides,\npeople's tweeting activities in the night before and early morning are\nstatistically associated with congestion in morning peak hours. We make use of\nsuch relationships to build a predictive framework which forecasts morning\ncommute congestion using people's tweeting profiles extracted by 5 am or as\nlate as the midnight prior to the morning. The Pittsburgh study supports that\nour framework can precisely predict morning congestion, particularly for some\nroad segments upstream of roadway bottlenecks with large day-to-day congestion\nvariation. Our approach considerably outperforms those existing methods without\nTwitter message features, and it can learn meaningful representation of demand\nfrom tweeting profiles that offer managerial insights.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:02:33 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 17:56:25 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Yao", "Weiran", ""], ["Qian", "Sean", ""]]}, {"id": "2009.13801", "submitter": "Asif Salim", "authors": "Asif Salim and Sumitra S", "title": "Framework for Designing Filters of Spectral Graph Convolutional Neural\n  Networks in the Context of Regularization Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNNs) have been widely used in graph\nlearning. It has been observed that the smoothness functional on graphs can be\ndefined in terms of the graph Laplacian. This fact points out in the direction\nof using Laplacian in deriving regularization operators on graphs and its\nconsequent use with spectral GCNN filter designs. In this work, we explore the\nregularization properties of graph Laplacian and proposed a generalized\nframework for regularized filter designs in spectral GCNNs. We found that the\nfilters used in many state-of-the-art GCNNs can be derived as a special case of\nthe framework we developed. We designed new filters that are associated with\nwell-defined regularization behavior and tested their performance on\nsemi-supervised node classification tasks. Their performance was found to be\nsuperior to that of the other state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:19:08 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Salim", "Asif", ""], ["S", "Sumitra", ""]]}, {"id": "2009.13807", "submitter": "Renjie Wu", "authors": "Renjie Wu, Eamonn J. Keogh", "title": "Current Time Series Anomaly Detection Benchmarks are Flawed and are\n  Creating the Illusion of Progress", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series anomaly detection has been a perennially important topic in data\nscience, with papers dating back to the 1950s. However, in recent years there\nhas been an explosion of interest in this topic, much of it driven by the\nsuccess of deep learning in other domains and for other time series tasks. Most\nof these papers test on one or more of a handful of popular benchmark datasets,\ncreated by Yahoo, Numenta, NASA, etc. In this work we make a surprising claim.\nThe majority of the individual exemplars in these datasets suffer from one or\nmore of four flaws. Because of these four flaws, we believe that many published\ncomparisons of anomaly detection algorithms may be unreliable, and more\nimportantly, much of the apparent progress in recent years may be illusionary.\nIn addition to demonstrating these claims, with this paper we introduce the UCR\nTime Series Anomaly Datasets. We believe that this resource will perform a\nsimilar role as the UCR Time Series Classification Archive, by providing the\ncommunity with a benchmark that allows meaningful comparisons between\napproaches and a meaningful gauge of overall progress.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:29:04 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 18:49:13 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 20:40:27 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wu", "Renjie", ""], ["Keogh", "Eamonn J.", ""]]}, {"id": "2009.13826", "submitter": "Yanlin Li", "authors": "Yanlin Li, Shi An, Ruisheng Zhang", "title": "EEMC: Embedding Enhanced Multi-tag Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently occurred representation learning make an attractive performance\nin NLP and complex network, it is becoming a fundamental technology in machine\nlearning and data mining. How to use representation learning to improve the\nperformance of classifiers is a very significance research direction. We using\nrepresentation learning technology to map raw data(node of graph) to a\nlow-dimensional feature space. In this space, each raw data obtained a lower\ndimensional vector representation, we do some simple linear operations for\nthose vectors to produce some virtual data, using those vectors and virtual\ndata to training multi-tag classifier. After that we measured the performance\nof classifier by F1 score(Macro% F1 and Micro% F1). Our method make Macro F1\nrise from 28 % - 450% and make average F1 score rise from 12 % - 224%. By\ncontrast, we trained the classifier directly with the lower dimensional vector,\nand measured the performance of classifiers. We validate our algorithm on three\npublic data sets, we found that the virtual data helped the classifier greatly\nimprove the F1 score. Therefore, our algorithm is a effective way to improve\nthe performance of classifier. These result suggest that the virtual data\ngenerated by simple linear operation, in representation space, still retains\nthe information of the raw data. It's also have great significance to the\nlearning of small sample data sets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:29:34 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Li", "Yanlin", ""], ["An", "Shi", ""], ["Zhang", "Ruisheng", ""]]}, {"id": "2009.13831", "submitter": "Milo\\v{s} Simi\\'c", "authors": "Milo\\v{s} Simi\\'c", "title": "Testing for Normality with Neural Networks", "comments": "49 pages, 10 figures; corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we treat the problem of testing for normality as a binary\nclassification problem and construct a feedforward neural network that can\nsuccessfully detect normal distributions by inspecting small samples from them.\nThe numerical experiments conducted on small samples with no more than 100\nelements indicated that the neural network which we trained was more accurate\nand far more powerful than the most frequently used and most powerful standard\ntests of normality: Shapiro-Wilk, Anderson-Darling, Lilliefors and\nJarque-Berra, as well as the kernel tests of goodness-of-fit. The neural\nnetwork had the AUROC score of almost 1, which corresponds to the perfect\nbinary classifier. Additionally, the network's accuracy was higher than 96% on\na set of larger samples with 250-1000 elements. Since the normality of data is\nan assumption of numerous techniques for analysis and inference, the neural\nnetwork constructed in this study has a very high potential for use in everyday\npractice of statistics, data analysis and machine learning in both science and\nindustry.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:35:40 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 07:47:22 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Simi\u0107", "Milo\u0161", ""]]}, {"id": "2009.13853", "submitter": "Adrian Englhardt", "authors": "Adrian Englhardt, Holger Trittenbach, Daniel Kottke, Bernhard Sick,\n  and Klemens B\\\"ohm", "title": "Efficient SVDD Sampling with Approximation Guarantees for the Decision\n  Boundary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Data Description (SVDD) is a popular one-class classifiers for\nanomaly and novelty detection. But despite its effectiveness, SVDD does not\nscale well with data size. To avoid prohibitive training times, sampling\nmethods select small subsets of the training data on which SVDD trains a\ndecision boundary hopefully equivalent to the one obtained on the full data\nset. According to the literature, a good sample should therefore contain\nso-called boundary observations that SVDD would select as support vectors on\nthe full data set. However, non-boundary observations also are essential to not\nfragment contiguous inlier regions and avoid poor classification accuracy.\nOther aspects, such as selecting a sufficiently representative sample, are\nimportant as well. But existing sampling methods largely overlook them,\nresulting in poor classification accuracy. In this article, we study how to\nselect a sample considering these points. Our approach is to frame SVDD\nsampling as an optimization problem, where constraints guarantee that sampling\nindeed approximates the original decision boundary. We then propose RAPID, an\nefficient algorithm to solve this optimization problem. RAPID does not require\nany tuning of parameters, is easy to implement and scales well to large data\nsets. We evaluate our approach on real-world and synthetic data. Our evaluation\nis the most comprehensive one for SVDD sampling so far. Our results show that\nRAPID outperforms its competitors in classification accuracy, in sample size,\nand in runtime.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:28:01 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Englhardt", "Adrian", ""], ["Trittenbach", "Holger", ""], ["Kottke", "Daniel", ""], ["Sick", "Bernhard", ""], ["B\u00f6hm", "Klemens", ""]]}, {"id": "2009.13878", "submitter": "Navid Shervani-Tabar", "authors": "Navid Shervani-Tabar, Nicholas Zabaras", "title": "Physics-Constrained Predictive Molecular Latent Space Discovery with\n  Graph Scattering Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence have propelled the development of\ninnovative computational materials modeling and design techniques. Generative\ndeep learning models have been used for molecular representation, discovery,\nand design. In this work, we assess the predictive capabilities of a molecular\ngenerative model developed based on variational inference and graph theory in\nthe small data regime. Physical constraints that encourage energetically stable\nmolecules are proposed. The encoding network is based on the scattering\ntransform with adaptive spectral filters to allow for better generalization of\nthe model. The decoding network is a one-shot graph generative model that\nconditions atom types on molecular topology. A Bayesian formalism is considered\nto capture uncertainties in the predictive estimates of molecular properties.\nThe model's performance is evaluated by generating molecules with desired\ntarget properties.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:05:27 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 09:18:13 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Shervani-Tabar", "Navid", ""], ["Zabaras", "Nicholas", ""]]}, {"id": "2009.13881", "submitter": "Stephan Eckstein", "authors": "Stephan Eckstein", "title": "Lipschitz neural networks are dense in the set of all Lipschitz\n  functions", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note shows that, for a fixed Lipschitz constant $L > 0$, one layer\nneural networks that are $L$-Lipschitz are dense in the set of all\n$L$-Lipschitz functions with respect to the uniform norm on bounded sets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:15:45 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Eckstein", "Stephan", ""]]}, {"id": "2009.13891", "submitter": "Haotian Fu", "authors": "Haotian Fu, Hongyao Tang, Jianye Hao, Chen Chen, Xidong Feng, Dong Li,\n  Wulong Liu", "title": "Towards Effective Context for Meta-Reinforcement Learning: an Approach\n  based on Contrastive Learning", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context, the embedding of previous collected trajectories, is a powerful\nconstruct for Meta-Reinforcement Learning (Meta-RL) algorithms. By conditioning\non an effective context, Meta-RL policies can easily generalize to new tasks\nwithin a few adaptation steps. We argue that improving the quality of context\ninvolves answering two questions: 1. How to train a compact and sufficient\nencoder that can embed the task-specific information contained in prior\ntrajectories? 2. How to collect informative trajectories of which the\ncorresponding context reflects the specification of tasks? To this end, we\npropose a novel Meta-RL framework called CCM (Contrastive learning augmented\nContext-based Meta-RL). We first focus on the contrastive nature behind\ndifferent tasks and leverage it to train a compact and sufficient context\nencoder. Further, we train a separate exploration policy and theoretically\nderive a new information-gain-based objective which aims to collect informative\ntrajectories in a few steps. Empirically, we evaluate our approaches on common\nbenchmarks as well as several complex sparse-reward environments. The\nexperimental results show that CCM outperforms state-of-the-art algorithms by\naddressing previously mentioned problems respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:29:18 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 12:10:03 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 08:48:23 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fu", "Haotian", ""], ["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Chen", "Chen", ""], ["Feng", "Xidong", ""], ["Li", "Dong", ""], ["Liu", "Wulong", ""]]}, {"id": "2009.13895", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "Ben Day, C\\u{a}t\\u{a}lina Cangea, Arian R. Jamasb, Pietro Li\\`o", "title": "Message Passing Neural Processes", "comments": "18 pages, 6 figures. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Processes (NPs) are powerful and flexible models able to incorporate\nuncertainty when representing stochastic processes, while maintaining a linear\ntime complexity. However, NPs produce a latent description by aggregating\nindependent representations of context points and lack the ability to exploit\nrelational information present in many datasets. This renders NPs ineffective\nin settings where the stochastic process is primarily governed by neighbourhood\nrules, such as cellular automata (CA), and limits performance for any task\nwhere relational information remains unused. We address this shortcoming by\nintroducing Message Passing Neural Processes (MPNPs), the first class of NPs\nthat explicitly makes use of relational structure within the model. Our\nevaluation shows that MPNPs thrive at lower sampling rates, on existing\nbenchmarks and newly-proposed CA and Cora-Branched tasks. We further report\nstrong generalisation over density-based CA rule-sets and significant gains in\nchallenging arbitrary-labelling and few-shot learning setups.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:40:09 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Day", "Ben", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Jamasb", "Arian R.", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2009.13939", "submitter": "Diogo Pernes", "authors": "Diogo Pernes and Jaime S. Cardoso", "title": "Tackling unsupervised multi-source domain adaptation with optimism and\n  consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been known for a while that the problem of multi-source domain\nadaptation can be regarded as a single source domain adaptation task where the\nsource domain corresponds to a mixture of the original source domains.\nNonetheless, how to adjust the mixture distribution weights remains an open\nquestion. Moreover, most existing work on this topic focuses only on minimizing\nthe error on the source domains and achieving domain-invariant representations,\nwhich is insufficient to ensure low error on the target domain. In this work,\nwe present a novel framework that addresses both problems and beats the current\nstate of the art by using a mildly optimistic objective function and\nconsistency regularization on the target samples.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:55:14 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Pernes", "Diogo", ""], ["Cardoso", "Jaime S.", ""]]}, {"id": "2009.13961", "submitter": "Claudio Flores", "authors": "Claudio Cardoso Flores and Marcelo Cunha Medeiros", "title": "Online Action Learning in High Dimensions: A New Exploration Rule for\n  Contextual $\\epsilon_t$-Greedy Heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit problems are pervasive in various fields of research and are also\npresent in several practical applications. Examples, including dynamic pricing\nand assortment and the design of auctions and incentives, permeate a large\nnumber of sequential treatment experiments. Different applications impose\ndistinct levels of restrictions on viable actions. Some favor diversity of\noutcomes, while others require harmful actions to be closely monitored or\nmainly avoided. In this paper, we extend one of the most popular bandit\nsolutions, the original $\\epsilon_t$-greedy heuristics, to high-dimensional\ncontexts. Moreover, we introduce a competing exploration mechanism that counts\nwith searching sets based on order statistics. We view our proposals as\nalternatives for cases where pluralism is valued or, in the opposite direction,\ncases where the end-user should carefully tune the range of exploration of new\nactions. We find reasonable bounds for the cumulative regret of a decaying\n$\\epsilon_t$-greedy heuristic in both cases and we provide an upper bound for\nthe initialization phase that implies the regret bounds when order statistics\nare considered to be at most equal but mostly better than the case when random\nsearching is the sole exploration mechanism. Additionally, we show that\nend-users have sufficient flexibility to avoid harmful actions since any\ncardinality for the higher-order statistics can be used to achieve an stricter\nupper bound. We illustrate the algorithms proposed in this paper both with\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:25:05 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 03:15:00 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Flores", "Claudio Cardoso", ""], ["Medeiros", "Marcelo Cunha", ""]]}, {"id": "2009.13962", "submitter": "Diane Bouchacourt", "authors": "Christina Heinze-Deml and Diane Bouchacourt", "title": "Think before you act: A simple baseline for compositional generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrarily to humans who have the ability to recombine familiar expressions\nto create novel ones, modern neural networks struggle to do so. This has been\nemphasized recently with the introduction of the benchmark dataset \"gSCAN\"\n(Ruis et al. 2020), aiming to evaluate models' performance at compositional\ngeneralization in grounded language understanding. In this work, we challenge\nthe gSCAN benchmark by proposing a simple model that achieves surprisingly good\nperformance on two of the gSCAN test splits. Our model is based on the\nobservation that, to succeed on gSCAN tasks, the agent must (i) identify the\ntarget object (think) before (ii) navigating to it successfully (act).\nConcretely, we propose an attention-inspired modification of the baseline model\nfrom (Ruis et al. 2020), together with an auxiliary loss, that takes into\naccount the sequential nature of steps (i) and (ii). While two compositional\ntasks are trivially solved with our approach, we also find that the other tasks\nremain unsolved, validating the relevance of gSCAN as a benchmark for\nevaluating models' compositional abilities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:27:12 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 07:11:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Heinze-Deml", "Christina", ""], ["Bouchacourt", "Diane", ""]]}, {"id": "2009.13975", "submitter": "Alessandro Brusaferri Eng.", "authors": "Alessandro Brusaferri and Matteo Matteucci and Stefano Spinelli", "title": "Identification of Probability weighted ARX models with arbitrary domains", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hybrid system identification is a key tool to achieve reliable models of\nCyber-Physical Systems from data. PieceWise Affine models guarantees universal\napproximation, local linearity and equivalence to other classes of hybrid\nsystem. Still, PWA identification is a challenging problem, requiring the\nconcurrent solution of regression and classification tasks. In this work, we\nfocus on the identification of PieceWise Auto Regressive with eXogenous input\nmodels with arbitrary regions (NPWARX), thus not restricted to polyhedral\ndomains, and characterized by discontinuous maps. To this end, we propose a\nmethod based on a probabilistic mixture model, where the discrete state is\nrepresented through a multinomial distribution conditioned by the input\nregressors. The architecture is conceived following the Mixture of Expert\nconcept, developed within the machine learning field. To achieve nonlinear\npartitioning, we parametrize the discriminant function using a neural network.\nThen, the parameters of both the ARX submodels and the classifier are\nconcurrently estimated by maximizing the likelihood of the overall model using\nExpectation Maximization. The proposed method is demonstrated on a nonlinear\npiece-wise problem with discontinuous maps.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:50:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Brusaferri", "Alessandro", ""], ["Matteucci", "Matteo", ""], ["Spinelli", "Stefano", ""]]}, {"id": "2009.13977", "submitter": "Alexander Mathiasen Mr", "authors": "Alexander Mathiasen, Frederik Hvilsh{\\o}j, Jakob R{\\o}dsgaard\n  J{\\o}rgensen, Anshul Nasery, Davide Mottin", "title": "What if Neural Networks had SVDs?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various Neural Networks employ time-consuming matrix operations like matrix\ninversion. Many such matrix operations are faster to compute given the Singular\nValue Decomposition (SVD). Previous work allows using the SVD in Neural\nNetworks without computing it. In theory, the techniques can speed up matrix\noperations, however, in practice, they are not fast enough. We present an\nalgorithm that is fast enough to speed up several matrix operations. The\nalgorithm increases the degree of parallelism of an underlying matrix\nmultiplication $H\\cdot X$ where $H$ is an orthogonal matrix represented by a\nproduct of Householder matrices. Code is available at\nwww.github.com/AlexanderMath/fasth .\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:58:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mathiasen", "Alexander", ""], ["Hvilsh\u00f8j", "Frederik", ""], ["J\u00f8rgensen", "Jakob R\u00f8dsgaard", ""], ["Nasery", "Anshul", ""], ["Mottin", "Davide", ""]]}, {"id": "2009.13982", "submitter": "Xinyue Liang", "authors": "Xinyue Liang, Alireza M. Javid, Mikael Skoglund, Saikat Chatterjee", "title": "A Low Complexity Decentralized Neural Net with Centralized Equivalence\n  using Layer-wise Learning", "comments": "Accepted to The International Joint Conference on Neural Networks\n  (IJCNN) 2020, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a low complexity decentralized learning algorithm to train a\nrecently proposed large neural network in distributed processing nodes\n(workers). We assume the communication network between the workers is\nsynchronized and can be modeled as a doubly-stochastic mixing matrix without\nhaving any master node. In our setup, the training data is distributed among\nthe workers but is not shared in the training process due to privacy and\nsecurity concerns. Using alternating-direction-method-of-multipliers (ADMM)\nalong with a layerwise convex optimization approach, we propose a decentralized\nlearning algorithm which enjoys low computational complexity and communication\ncost among the workers. We show that it is possible to achieve equivalent\nlearning performance as if the data is available in a single place. Finally, we\nexperimentally illustrate the time complexity and convergence behavior of the\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:08:12 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Liang", "Xinyue", ""], ["Javid", "Alireza M.", ""], ["Skoglund", "Mikael", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "2009.13987", "submitter": "Lukas Ruff", "authors": "Michael Joswig, Marek Kaluba, Lukas Ruff", "title": "Geometric Disentanglement by Random Convex Polytopes", "comments": "23 pages, preprint; extended experiments and theoretical analysis of\n  RPD in v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.MG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new geometric method for measuring the quality of\nrepresentations obtained from deep learning. Our approach, called Random\nPolytope Descriptor, provides an efficient description of data points based on\nthe construction of random convex polytopes. We demonstrate the use of our\ntechnique by qualitatively comparing the behavior of classic and regularized\nautoencoders. This reveals that applying regularization to autoencoder networks\nmay decrease the out-of-distribution detection performance in latent space.\nWhile our technique is similar in spirit to $k$-means clustering, we achieve\nsignificantly better false positive/negative balance in clustering tasks on\nautoencoded datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:16:26 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 07:39:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Joswig", "Michael", ""], ["Kaluba", "Marek", ""], ["Ruff", "Lukas", ""]]}, {"id": "2009.14024", "submitter": "Pierre-Luc Delisle", "authors": "Pierre-Luc Delisle, Benoit Anctil-Robitaille, Christian Desrosiers and\n  Herve Lombaert", "title": "Realistic Image Normalization for Multi-Domain Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image normalization is a building block in medical image analysis.\nConventional approaches are customarily utilized on a per-dataset basis. This\nstrategy, however, prevents the current normalization algorithms from fully\nexploiting the complex joint information available across multiple datasets.\nConsequently, ignoring such joint information has a direct impact on the\nperformance of segmentation algorithms. This paper proposes to revisit the\nconventional image normalization approach by instead learning a common\nnormalizing function across multiple datasets. Jointly normalizing multiple\ndatasets is shown to yield consistent normalized images as well as an improved\nimage segmentation. To do so, a fully automated adversarial and task-driven\nnormalization approach is employed as it facilitates the training of realistic\nand interpretable images while keeping performance on-par with the\nstate-of-the-art. The adversarial training of our network aims at finding the\noptimal transfer function to improve both the segmentation accuracy and the\ngeneration of realistic images. We evaluated the performance of our normalizer\non both infant and adult brains images from the iSEG, MRBrainS and ABIDE\ndatasets. Results reveal the potential of our normalization approach for\nsegmentation, with Dice improvements of up to 57.5% over our baseline. Our\nmethod can also enhance data availability by increasing the number of samples\navailable when learning from multiple imaging domains.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:57:04 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 14:24:44 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 19:15:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Delisle", "Pierre-Luc", ""], ["Anctil-Robitaille", "Benoit", ""], ["Desrosiers", "Christian", ""], ["Lombaert", "Herve", ""]]}, {"id": "2009.14061", "submitter": "Shonosuke Harada", "authors": "Shonosuke Harada and Hisashi Kashima", "title": "GraphITE: Estimating Individual Effects of Graph-structured Treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outcome estimation of treatments for target individuals is an important\nfoundation for decision making based on causal relations. Most existing outcome\nestimation methods deal with binary or multiple-choice treatments; however, in\nsome applications, the number of treatments can be significantly large, while\nthe treatments themselves have rich information. In this study, we considered\none important instance of such cases: the outcome estimation problem of\ngraph-structured treatments such as drugs. Owing to the large number of\npossible treatments, the counterfactual nature of observational data that\nappears in conventional treatment effect estimation becomes more of a concern\nfor this problem. Our proposed method, GraphITE (pronounced \"graphite\") learns\nthe representations of graph-structured treatments using graph neural networks\nwhile mitigating observation biases using Hilbert-Schmidt Independence\nCriterion regularization, which increases the independence of the\nrepresentations of the targets and treatments. Experiments on two real-world\ndatasets show that GraphITE outperforms baselines, especially in cases with a\nlarge number of treatments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 14:49:30 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 03:28:00 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Harada", "Shonosuke", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2009.14073", "submitter": "Alessandro Brusaferri Eng.", "authors": "Alessandro Brusaferri and Matteo Matteucci and Stefano Spinelli", "title": "Estimation of Switched Markov Polynomial NARX models", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work targets the identification of a class of models for hybrid\ndynamical systems characterized by nonlinear autoregressive exogenous (NARX)\ncomponents, with finite-dimensional polynomial expansions, and by a Markovian\nswitching mechanism. The estimation of the model parameters is performed under\na probabilistic framework via Expectation Maximization, including submodel\ncoefficients, hidden state values and transition probabilities. Discrete mode\nclassification and NARX regression tasks are disentangled within the\niterations. Soft-labels are assigned to latent states on the trajectories by\naveraging over the state posteriors and updated using the parametrization\nobtained from the previous maximization phase. Then, NARXs parameters are\nrepeatedly fitted by solving weighted regression subproblems through a cyclical\ncoordinate descent approach with coordinate-wise minimization. Moreover, we\ninvestigate a two stage selection scheme, based on a l1-norm bridge estimation\nfollowed by hard-thresholding, to achieve parsimonious models through selection\nof the polynomial expansion. The proposed approach is demonstrated on a SMNARX\nproblem composed by three nonlinear sub-models with specific regressors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:00:47 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Brusaferri", "Alessandro", ""], ["Matteucci", "Matteo", ""], ["Spinelli", "Stefano", ""]]}, {"id": "2009.14075", "submitter": "Alexander Mathiasen Mr", "authors": "Alexander Mathiasen, Frederik Hvilsh{\\o}j", "title": "Backpropagating through Fr\\'echet Inception Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fr\\'echet Inception Distance (FID) has been used to evaluate hundreds of\ngenerative models. We introduce FastFID, which can efficiently train generative\nmodels with FID as a loss function. Using FID as an additional loss for\nGenerative Adversarial Networks improves their FID.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:04:40 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 16:01:12 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Mathiasen", "Alexander", ""], ["Hvilsh\u00f8j", "Frederik", ""]]}, {"id": "2009.14096", "submitter": "Min Qian", "authors": "Min Qian and Yan-Fu Li", "title": "Weakly Supervised-Based Oversampling for High Imbalance and High\n  Dimensionality Data Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the abundance of industrial datasets, imbalanced classification has\nbecome a common problem in several application domains. Oversampling is an\neffective method to solve imbalanced classification. One of the main challenges\nof the existing oversampling methods is to accurately label the new synthetic\nsamples. Inaccurate labels of the synthetic samples would distort the\ndistribution of the dataset and possibly worsen the classification performance.\nThis paper introduces the idea of weakly supervised learning to handle the\ninaccurate labeling of synthetic samples caused by traditional oversampling\nmethods. Graph semi-supervised SMOTE is developed to improve the credibility of\nthe synthetic samples' labels. In addition, we propose cost-sensitive\nneighborhood components analysis for high dimensional datasets and bootstrap\nbased ensemble framework for highly imbalanced datasets. The proposed method\nhas achieved good classification performance on 8 synthetic datasets and 3\nreal-world datasets, especially for high imbalance and high dimensionality\nproblems. The average performances and robustness are better than the benchmark\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:26:34 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 11:54:49 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Qian", "Min", ""], ["Li", "Yan-Fu", ""]]}, {"id": "2009.14108", "submitter": "Markus Hofmarcher", "authors": "Vihang P. Patil, Markus Hofmarcher, Marius-Constantin Dinu, Matthias\n  Dorfer, Patrick M. Blies, Johannes Brandstetter, Jose A. Arjona-Medina, Sepp\n  Hochreiter", "title": "Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning algorithms require a large number of samples to solve\ncomplex tasks with sparse and delayed rewards. Complex tasks can often be\nhierarchically decomposed into sub-tasks. A step in the Q-function can be\nassociated with solving a sub-task, where the expectation of the return\nincreases. RUDDER has been introduced to identify these steps and then\nredistribute reward to them, thus immediately giving reward if sub-tasks are\nsolved. Since the problem of delayed rewards is mitigated, learning is\nconsiderably sped up. However, for complex tasks, current exploration\nstrategies as deployed in RUDDER struggle with discovering episodes with high\nrewards. Therefore, we assume that episodes with high rewards are given as\ndemonstrations and do not have to be discovered by exploration. Typically the\nnumber of demonstrations is small and RUDDER's LSTM model as a deep learning\nmethod does not learn well. Hence, we introduce Align-RUDDER, which is RUDDER\nwith two major modifications. First, Align-RUDDER assumes that episodes with\nhigh rewards are given as demonstrations, replacing RUDDER's safe exploration\nand lessons replay buffer. Second, we replace RUDDER's LSTM model by a profile\nmodel that is obtained from multiple sequence alignment of demonstrations.\nProfile models can be constructed from as few as two demonstrations as known\nfrom bioinformatics. Align-RUDDER inherits the concept of reward\nredistribution, which considerably reduces the delay of rewards, thus speeding\nup learning. Align-RUDDER outperforms competitors on complex artificial tasks\nwith delayed reward and few demonstrations. On the MineCraft ObtainDiamond\ntask, Align-RUDDER is able to mine a diamond, though not frequently. Github:\nhttps://github.com/ml-jku/align-rudder, YouTube: https://youtu.be/HO-_8ZUl-UY\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:48:02 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Patil", "Vihang P.", ""], ["Hofmarcher", "Markus", ""], ["Dinu", "Marius-Constantin", ""], ["Dorfer", "Matthias", ""], ["Blies", "Patrick M.", ""], ["Brandstetter", "Johannes", ""], ["Arjona-Medina", "Jose A.", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "2009.14111", "submitter": "Jaehoon Koo", "authors": "Jaehoon Koo, Diego Klabjan, Jean Utke", "title": "Inverse Classification with Limited Budget and Maximum Number of\n  Perturbed Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent machine learning research focuses on developing new classifiers\nfor the sake of improving classification accuracy. With many well-performing\nstate-of-the-art classifiers available, there is a growing need for\nunderstanding interpretability of a classifier necessitated by practical\npurposes such as to find the best diet recommendation for a diabetes patient.\nInverse classification is a post modeling process to find changes in input\nfeatures of samples to alter the initially predicted class. It is useful in\nmany business applications to determine how to adjust a sample input data such\nthat the classifier predicts it to be in a desired class. In real world\napplications, a budget on perturbations of samples corresponding to customers\nor patients is usually considered, and in this setting, the number of\nsuccessfully perturbed samples is key to increase benefits. In this study, we\npropose a new framework to solve inverse classification that maximizes the\nnumber of perturbed samples subject to a per-feature-budget limits and\nfavorable classification classes of the perturbed samples. We design algorithms\nto solve this optimization problem based on gradient methods, stochastic\nprocesses, Lagrangian relaxations, and the Gumbel trick. In experiments, we\nfind that our algorithms based on stochastic processes exhibit an excellent\nperformance in different budget settings and they scale well.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:52:10 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Koo", "Jaehoon", ""], ["Klabjan", "Diego", ""], ["Utke", "Jean", ""]]}, {"id": "2009.14131", "submitter": "Hedibert Lopes", "authors": "Paloma W. Uribe and Hedibert F. Lopes", "title": "Dynamic sparsity on dynamic regression models", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work, we consider variable selection and shrinkage for the\nGaussian dynamic linear regression within a Bayesian framework. In particular,\nwe propose a novel method that allows for time-varying sparsity, based on an\nextension of spike-and-slab priors for dynamic models. This is done by\nassigning appropriate Markov switching priors for the time-varying\ncoefficients' variances, extending the previous work of Ishwaran and Rao\n(2005). Furthermore, we investigate different priors, including the common\nInverted gamma prior for the process variances, and other mixture prior\ndistributions such as Gamma priors for both the spike and the slab, which leads\nto a mixture of Normal-Gammas priors (Griffin ad Brown, 2010) for the\ncoefficients. In this sense, our prior can be view as a dynamic variable\nselection prior which induces either smoothness (through the slab) or shrinkage\ntowards zero (through the spike) at each time point. The MCMC method used for\nposterior computation uses Markov latent variables that can assume binary\nregimes at each time point to generate the coefficients' variances. In that\nway, our model is a dynamic mixture model, thus, we could use the algorithm of\nGerlach et al (2000) to generate the latent processes without conditioning on\nthe states. Finally, our approach is exemplified through simulated examples and\na real data application.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:26:08 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Uribe", "Paloma W.", ""], ["Lopes", "Hedibert F.", ""]]}, {"id": "2009.14133", "submitter": "David Calhas", "authors": "David Calhas, Rui Henriques", "title": "EEG to fMRI Synthesis: Is Deep Learning a candidate?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances on signal, image and video generation underly major breakthroughs on\ngenerative medical imaging tasks, including Brain Image Synthesis. Still, the\nextent to which functional Magnetic Ressonance Imaging (fMRI) can be mapped\nfrom the brain electrophysiology remains largely unexplored. This work provides\nthe first comprehensive view on how to use state-of-the-art principles from\nNeural Processing to synthesize fMRI data from electroencephalographic (EEG)\ndata. Given the distinct spatiotemporal nature of haemodynamic and\nelectrophysiological signals, this problem is formulated as the task of\nlearning a mapping function between multivariate time series with highly\ndissimilar structures. A comparison of state-of-the-art synthesis approaches,\nincluding Autoencoders, Generative Adversarial Networks and Pairwise Learning,\nis undertaken. Results highlight the feasibility of EEG to fMRI brain image\nmappings, pinpointing the role of current advances in Machine Learning and\nshowing the relevance of upcoming contributions to further improve performance.\nEEG to fMRI synthesis offers a way to enhance and augment brain image data, and\nguarantee access to more affordable, portable and long-lasting protocols of\nbrain activity monitoring. The code used in this manuscript is available in\nGithub and the datasets are open source.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:29:20 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Calhas", "David", ""], ["Henriques", "Rui", ""]]}, {"id": "2009.14136", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, David Saltiel, Sandrine Ungari, Abhishek Mukhopadhyay", "title": "Time your hedge with Deep Reinforcement Learning", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can an asset manager plan the optimal timing for her/his hedging strategies\ngiven market conditions? The standard approach based on Markowitz or other more\nor less sophisticated financial rules aims to find the best portfolio\nallocation thanks to forecasted expected returns and risk but fails to fully\nrelate market conditions to hedging strategies decision. In contrast, Deep\nReinforcement Learning (DRL) can tackle this challenge by creating a dynamic\ndependency between market information and hedging strategies allocation\ndecisions. In this paper, we present a realistic and augmented DRL framework\nthat: (i) uses additional contextual information to decide an action, (ii) has\na one period lag between observations and actions to account for one day lag\nturnover of common asset managers to rebalance their hedge, (iii) is fully\ntested in terms of stability and robustness thanks to a repetitive train test\nmethod called anchored walk forward training, similar in spirit to k fold cross\nvalidation for time series and (iv) allows managing leverage of our hedging\nstrategy. Our experiment for an augmented asset manager interested in sizing\nand timing his hedges shows that our approach achieves superior returns and\nlower risk.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:43:41 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:56:27 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ungari", "Sandrine", ""], ["Mukhopadhyay", "Abhishek", ""]]}, {"id": "2009.14138", "submitter": "Qimin Liu", "authors": "Qimin Liu and Fang Liu", "title": "Selective Cascade of Residual ExtraTrees", "comments": "To appear in SN Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel tree-based ensemble method named Selective Cascade of\nResidual ExtraTrees (SCORE). SCORE draws inspiration from representation\nlearning, incorporates regularized regression with variable selection features,\nand utilizes boosting to improve prediction and reduce generalization errors.\nWe also develop a variable importance measure to increase the explainability of\nSCORE. Our computer experiments show that SCORE provides comparable or superior\nperformance in prediction against ExtraTrees, random forest, gradient boosting\nmachine, and neural networks; and the proposed variable importance measure for\nSCORE is comparable to studied benchmark methods. Finally, the predictive\nperformance of SCORE remains stable across hyper-parameter values, suggesting\npotential robustness to hyperparameter specification.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:31:37 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Liu", "Qimin", ""], ["Liu", "Fang", ""]]}, {"id": "2009.14148", "submitter": "Youssef Mroueh", "authors": "Youssef Mroueh, Mattia Rigotti", "title": "Unbalanced Sobolev Descent", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Unbalanced Sobolev Descent (USD), a particle descent algorithm\nfor transporting a high dimensional source distribution to a target\ndistribution that does not necessarily have the same mass. We define the\nSobolev-Fisher discrepancy between distributions and show that it relates to\nadvection-reaction transport equations and the Wasserstein-Fisher-Rao metric\nbetween distributions. USD transports particles along gradient flows of the\nwitness function of the Sobolev-Fisher discrepancy (advection step) and\nreweighs the mass of particles with respect to this witness function (reaction\nstep). The reaction step can be thought of as a birth-death process of the\nparticles with rate of growth proportional to the witness function. When the\nSobolev-Fisher witness function is estimated in a Reproducing Kernel Hilbert\nSpace (RKHS), under mild assumptions we show that USD converges asymptotically\n(in the limit of infinite particles) to the target distribution in the Maximum\nMean Discrepancy (MMD) sense. We then give two methods to estimate the\nSobolev-Fisher witness with neural networks, resulting in two Neural USD\nalgorithms. The first one implements the reaction step with mirror descent on\nthe weights, while the second implements it through a birth-death process of\nparticles. We show on synthetic examples that USD transports distributions with\nor without conservation of mass faster than previous particle descent\nalgorithms, and finally demonstrate its use for molecular biology analyses\nwhere our method is naturally suited to match developmental stages of\npopulations of differentiating cells based on their single-cell RNA sequencing\nprofile. Code is available at https://github.com/ibm/usd .\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:43:38 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mroueh", "Youssef", ""], ["Rigotti", "Mattia", ""]]}, {"id": "2009.14168", "submitter": "Charu Sharma", "authors": "Charu Sharma, Manohar Kaul", "title": "Self-Supervised Few-Shot Learning on Point Clouds", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased availability of massive point clouds coupled with their utility\nin a wide variety of applications such as robotics, shape synthesis, and\nself-driving cars has attracted increased attention from both industry and\nacademia. Recently, deep neural networks operating on labeled point clouds have\nshown promising results on supervised learning tasks like classification and\nsegmentation. However, supervised learning leads to the cumbersome task of\nannotating the point clouds. To combat this problem, we propose two novel\nself-supervised pre-training tasks that encode a hierarchical partitioning of\nthe point clouds using a cover-tree, where point cloud subsets lie within balls\nof varying radii at each level of the cover-tree. Furthermore, our\nself-supervised learning network is restricted to pre-train on the support set\n(comprising of scarce training examples) used to train the downstream network\nin a few-shot learning (FSL) setting. Finally, the fully-trained\nself-supervised network's point embeddings are input to the downstream task's\nnetwork. We present a comprehensive empirical evaluation of our method on both\ndownstream classification and segmentation tasks and show that supervised\nmethods pre-trained with our self-supervised learning method significantly\nimprove the accuracy of state-of-the-art methods. Additionally, our method also\noutperforms previous unsupervised methods in downstream classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:32:44 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sharma", "Charu", ""], ["Kaul", "Manohar", ""]]}, {"id": "2009.14193", "submitter": "Anastasios Angelopoulos", "authors": "Anastasios Angelopoulos, Stephen Bates, Jitendra Malik, Michael I.\n  Jordan", "title": "Uncertainty Sets for Image Classifiers using Conformal Prediction", "comments": "ICLR 2021 Spotlight, https://openreview.net/forum?id=eNdiU_DbM9 .\n  Project website available at\n  https://people.eecs.berkeley.edu/~angelopoulos/blog/posts/conformal-classification/\n  . Codebase available at\n  https://github.com/aangelopoulos/conformal_classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional image classifiers can achieve high predictive accuracy, but\nquantifying their uncertainty remains an unresolved challenge, hindering their\ndeployment in consequential settings. Existing uncertainty quantification\ntechniques, such as Platt scaling, attempt to calibrate the network's\nprobability estimates, but they do not have formal guarantees. We present an\nalgorithm that modifies any classifier to output a predictive set containing\nthe true label with a user-specified probability, such as 90%. The algorithm is\nsimple and fast like Platt scaling, but provides a formal finite-sample\ncoverage guarantee for every model and dataset. Our method modifies an existing\nconformal prediction algorithm to give more stable predictive sets by\nregularizing the small scores of unlikely classes after Platt scaling. In\nexperiments on both Imagenet and Imagenet-V2 with ResNet-152 and other\nclassifiers, our scheme outperforms existing approaches, achieving coverage\nwith sets that are often factors of 5 to 10 smaller than a stand-alone Platt\nscaling baseline.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:58:04 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 18:59:13 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 01:50:26 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Angelopoulos", "Anastasios", ""], ["Bates", "Stephen", ""], ["Malik", "Jitendra", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2009.14229", "submitter": "Amir Shahmoradi", "authors": "Amir Shahmoradi, Fatemeh Bagheri", "title": "ParaMonte: A high-performance serial/parallel Monte Carlo simulation\n  library for C, C++, Fortran", "comments": "submitted to JOSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS astro-ph.IM physics.data-an q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ParaMonte (standing for Parallel Monte Carlo) is a serial and\nMPI/Coarray-parallelized library of Monte Carlo routines for sampling\nmathematical objective functions of arbitrary-dimensions, in particular, the\nposterior distributions of Bayesian models in data science, Machine Learning,\nand scientific inference. The ParaMonte library has been developed with the\ndesign goal of unifying the **automation**, **accessibility**,\n**high-performance**, **scalability**, and **reproducibility** of Monte Carlo\nsimulations. The current implementation of the library includes **ParaDRAM**, a\n**Para**llel **D**elyaed-**R**ejection **A**daptive **M**etropolis Markov Chain\nMonte Carlo sampler, accessible from a wide range of programming languages\nincluding C, C++, Fortran, with a unified Application Programming Interface and\nsimulation environment across all supported programming languages. The\nParaMonte library is MIT-licensed and is permanently located and maintained at\n[https://github.com/cdslaborg/paramonte](https://github.com/cdslaborg/paramonte).\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:04:02 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Shahmoradi", "Amir", ""], ["Bagheri", "Fatemeh", ""]]}, {"id": "2009.14239", "submitter": "Nawaf Bou-Rabee", "authors": "Nawaf Bou-Rabee, Andreas Eberle", "title": "Couplings for Andersen Dynamics", "comments": "36 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR physics.chem-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Andersen dynamics is a standard method for molecular simulations, and a\nprecursor of the Hamiltonian Monte Carlo algorithm used in MCMC inference. The\nstochastic process corresponding to Andersen dynamics is a PDMP (piecewise\ndeterministic Markov process) that iterates between Hamiltonian flows and\nvelocity randomizations of randomly selected particles. Both from the viewpoint\nof molecular dynamics and MCMC inference, a basic question is to understand the\nconvergence to equilibrium of this PDMP particularly in high dimension. Here we\npresent couplings to obtain sharp convergence bounds in the Wasserstein sense\nthat do not require global convexity of the underlying potential energy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:13:17 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Bou-Rabee", "Nawaf", ""], ["Eberle", "Andreas", ""]]}, {"id": "2009.14244", "submitter": "Benyamin Ghojogh", "authors": "Parisa Abdolrahim Poorheravi, Benyamin Ghojogh, Vincent Gaudet, Fakhri\n  Karray, Mark Crowley", "title": "Acceleration of Large Margin Metric Learning for Nearest Neighbor\n  Classification Using Triplet Mining and Stratified Sampling", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning is one of the techniques in manifold learning with the goal\nof finding a projection subspace for increasing and decreasing the inter- and\nintra-class variances, respectively. Some of the metric learning methods are\nbased on triplet learning with anchor-positive-negative triplets. Large margin\nmetric learning for nearest neighbor classification is one of the fundamental\nmethods to do this. Recently, Siamese networks have been introduced with the\ntriplet loss. Many triplet mining methods have been developed for Siamese\nnetworks; however, these techniques have not been applied on the triplets of\nlarge margin metric learning for nearest neighbor classification. In this work,\ninspired by the mining methods for Siamese networks, we propose several triplet\nmining techniques for large margin metric learning. Moreover, a hierarchical\napproach is proposed, for acceleration and scalability of optimization, where\ntriplets are selected by stratified sampling in hierarchical hyper-spheres. We\nanalyze the proposed methods on three publicly available datasets, i.e., Fisher\nIris, ORL faces, and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:24:34 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Poorheravi", "Parisa Abdolrahim", ""], ["Ghojogh", "Benyamin", ""], ["Gaudet", "Vincent", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2009.14248", "submitter": "Seongmin Lee", "authors": "Seongmin Lee, Hyunsik Jeon and U Kang", "title": "Ensemble Multi-Source Domain Adaptation with Pseudolabels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given multiple source datasets with labels, how can we train a target model\nwith no labeled data? Multi-source domain adaptation (MSDA) aims to train a\nmodel using multiple source datasets different from a target dataset in the\nabsence of target data labels. MSDA is a crucial problem applicable to many\npractical cases where labels for the target data are unavailable due to privacy\nissues. Existing MSDA frameworks are limited since they align data without\nconsidering conditional distributions p(x|y) of each domain. They also miss a\nlot of target label information by not considering the target label at all and\nrelying on only one feature extractor. In this paper, we propose Ensemble\nMulti-source Domain Adaptation with Pseudolabels (EnMDAP), a novel method for\nmulti-source domain adaptation. EnMDAP exploits label-wise moment matching to\nalign conditional distributions p(x|y), using pseudolabels for the unavailable\ntarget labels, and introduces ensemble learning theme by using multiple feature\nextractors for accurate domain adaptation. Extensive experiments show that\nEnMDAP provides the state-of-the-art performance for multi-source domain\nadaptation tasks in both of image domains and text domains.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:29:49 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Lee", "Seongmin", ""], ["Jeon", "Hyunsik", ""], ["Kang", "U", ""]]}, {"id": "2009.14250", "submitter": "Yunlong Feng", "authors": "Yunlong Feng and Qiang Wu", "title": "A Framework of Learning Through Empirical Gain Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop in this paper a framework of empirical gain maximization (EGM) to\naddress the robust regression problem where heavy-tailed noise or outliers may\npresent in the response variable. The idea of EGM is to approximate the density\nfunction of the noise distribution instead of approximating the truth function\ndirectly as usual. Unlike the classical maximum likelihood estimation that\nencourages equal importance of all observations and could be problematic in the\npresence of abnormal observations, EGM schemes can be interpreted from a\nminimum distance estimation viewpoint and allow the ignorance of those\nobservations. Furthermore, it is shown that several well-known robust nonconvex\nregression paradigms, such as Tukey regression and truncated least square\nregression, can be reformulated into this new framework. We then develop a\nlearning theory for EGM, by means of which a unified analysis can be conducted\nfor these well-established but not fully-understood regression approaches.\nResulting from the new framework, a novel interpretation of existing bounded\nnonconvex loss functions can be concluded. Within this new framework, the two\nseemingly irrelevant terminologies, the well-known Tukey's biweight loss for\nrobust regression and the triweight kernel for nonparametric smoothing, are\nclosely related. More precisely, it is shown that the Tukey's biweight loss can\nbe derived from the triweight kernel. Similarly, other frequently employed\nbounded nonconvex loss functions in machine learning such as the truncated\nsquare loss, the Geman-McClure loss, and the exponential squared loss can also\nbe reformulated from certain smoothing kernels in statistics. In addition, the\nnew framework enables us to devise new bounded nonconvex loss functions for\nrobust learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:36:26 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 03:07:01 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Feng", "Yunlong", ""], ["Wu", "Qiang", ""]]}, {"id": "2009.14257", "submitter": "Huaqing Xiong", "authors": "Huaqing Xiong, Lin Zhao, Yingbin Liang, Wei Zhang", "title": "Finite-Time Analysis for Double Q-learning", "comments": "Accepted to NeurIPS 2020. The camera-ready version will include\n  additional updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Q-learning is one of the most successful algorithms for finding the\nbest action-value function (and thus the optimal policy) in reinforcement\nlearning, its implementation often suffers from large overestimation of\nQ-function values incurred by random sampling. The double Q-learning algorithm\nproposed in~\\citet{hasselt2010double} overcomes such an overestimation issue by\nrandomly switching the update between two Q-estimators, and has thus gained\nsignificant popularity in practice. However, the theoretical understanding of\ndouble Q-learning is rather limited. So far only the asymptotic convergence has\nbeen established, which does not characterize how fast the algorithm converges.\nIn this paper, we provide the first non-asymptotic (i.e., finite-time) analysis\nfor double Q-learning. We show that both synchronous and asynchronous double\nQ-learning are guaranteed to converge to an $\\epsilon$-accurate neighborhood of\nthe global optimum by taking $\\tilde{\\Omega}\\left(\\left(\n\\frac{1}{(1-\\gamma)^6\\epsilon^2}\\right)^{\\frac{1}{\\omega}}\n+\\left(\\frac{1}{1-\\gamma}\\right)^{\\frac{1}{1-\\omega}}\\right)$ iterations, where\n$\\omega\\in(0,1)$ is the decay parameter of the learning rate, and $\\gamma$ is\nthe discount factor. Our analysis develops novel techniques to derive\nfinite-time bounds on the difference between two inter-connected stochastic\nprocesses, which is new to the literature of stochastic approximation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:48:21 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 14:13:15 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xiong", "Huaqing", ""], ["Zhao", "Lin", ""], ["Liang", "Yingbin", ""], ["Zhang", "Wei", ""]]}, {"id": "2009.14286", "submitter": "Alexander Tsigler", "authors": "A. Tsigler (1) and P. L. Bartlett (1) ((1) UC Berkeley)", "title": "Benign overfitting in ridge regression", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical learning theory suggests that strong regularization is needed to\nlearn a class with large complexity. This intuition is in contrast with the\nmodern practice of machine learning, in particular learning neural networks,\nwhere the number of parameters often exceeds the number of data points. It has\nbeen observed empirically that such overparametrized models can show good\ngeneralization performance even if trained with vanishing or negative\nregularization. The aim of this work is to understand theoretically how this\neffect can occur, by studying the setting of ridge regression. We provide\nnon-asymptotic generalization bounds for overparametrized ridge regression that\ndepend on the arbitrary covariance structure of the data, and show that those\nbounds are tight for a range of regularization parameter values. To our\nknowledge this is the first work that studies overparametrized ridge regression\nin such a general setting. We identify when small or negative regularization is\nsufficient for obtaining small generalization error. On the technical side, our\nbounds only require the data vectors to be i.i.d. sub-gaussian, while most\nprevious work assumes independence of the components of those vectors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 20:00:31 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Tsigler", "A.", "", "UC Berkeley"], ["Bartlett", "P. L.", "", "UC Berkeley"]]}, {"id": "2009.14296", "submitter": "Hedibert Lopes", "authors": "Bruno Fava and Hedibert F. Lopes", "title": "The Illusion of the Illusion of Sparsity: An exercise in prior\n  sensitivity", "comments": "33 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of Big Data raises the question of how to model economic\nrelations when there is a large number of possible explanatory variables. We\nrevisit the issue by comparing the possibility of using dense or sparse models\nin a Bayesian approach, allowing for variable selection and shrinkage. More\nspecifically, we discuss the results reached by Giannone, Lenza, and Primiceri\n(2020) through a \"Spike-and-Slab\" prior, which suggest an \"illusion of\nsparsity\" in economic data, as no clear patterns of sparsity could be detected.\nWe make a further revision of the posterior distributions of the model, and\npropose three experiments to evaluate the robustness of the adopted prior\ndistribution. We find that the pattern of sparsity is sensitive to the prior\ndistribution of the regression coefficients, and present evidence that the\nmodel indirectly induces variable selection and shrinkage, which suggests that\nthe \"illusion of sparsity\" could be, itself, an illusion. Code is available on\ngithub.com/bfava/IllusionOfIllusion.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 20:39:13 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Fava", "Bruno", ""], ["Lopes", "Hedibert F.", ""]]}, {"id": "2009.14308", "submitter": "Nan Ding", "authors": "Nan Ding, Xinjie Fan, Zhenzhong Lan, Dale Schuurmans, Radu Soricut", "title": "Attention that does not Explain Away", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models based on the Transformer architecture have achieved better accuracy\nthan the ones based on competing architectures for a large set of tasks. A\nunique feature of the Transformer is its universal application of a\nself-attention mechanism, which allows for free information flow at arbitrary\ndistances. Following a probabilistic view of the attention via the Gaussian\nmixture model, we find empirical evidence that the Transformer attention tends\nto \"explain away\" certain input neurons. To compensate for this, we propose a\ndoubly-normalized attention scheme that is simple to implement and provides\ntheoretical guarantees for avoiding the \"explaining away\" effect without\nintroducing significant computational or memory cost. Empirically, we show that\nthe new attention schemes result in improved performance on several well-known\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:05:39 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ding", "Nan", ""], ["Fan", "Xinjie", ""], ["Lan", "Zhenzhong", ""], ["Schuurmans", "Dale", ""], ["Soricut", "Radu", ""]]}, {"id": "2009.14310", "submitter": "J\\'er\\^ome-Alexis Chevalier", "authors": "J\\'er\\^ome-Alexis Chevalier, Alexandre Gramfort, Joseph Salmon,\n  Bertrand Thirion", "title": "Statistical control for spatio-temporal MEG/EEG source imaging with\n  desparsified multi-task Lasso", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting where and when brain regions activate in a cognitive task or in a\ngiven clinical condition is the promise of non-invasive techniques like\nmagnetoencephalography (MEG) or electroencephalography (EEG). This problem,\nreferred to as source localization, or source imaging, poses however a\nhigh-dimensional statistical inference challenge. While sparsity promoting\nregularizations have been proposed to address the regression problem, it\nremains unclear how to ensure statistical control of false detections.\nMoreover, M/EEG source imaging requires to work with spatio-temporal data and\nautocorrelated noise. To deal with this, we adapt the desparsified Lasso\nestimator -- an estimator tailored for high dimensional linear model that\nasymptotically follows a Gaussian distribution under sparsity and moderate\nfeature correlation assumptions -- to temporal data corrupted with\nautocorrelated noise. We call it the desparsified multi-task Lasso (d-MTLasso).\nWe combine d-MTLasso with spatially constrained clustering to reduce data\ndimension and with ensembling to mitigate the arbitrary choice of clustering;\nthe resulting estimator is called ensemble of clustered desparsified multi-task\nLasso (ecd-MTLasso). With respect to the current procedures, the two advantages\nof ecd-MTLasso are that i)it offers statistical guarantees and ii)it allows to\ntrade spatial specificity for sensitivity, leading to a powerful adaptive\nmethod. Extensive simulations on realistic head geometries, as well as\nempirical results on various MEG datasets, demonstrate the high recovery\nperformance of ecd-MTLasso and its primary practical benefit: offer a\nstatistically principled way to threshold MEG/EEG source maps.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:17:16 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:49:36 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Chevalier", "J\u00e9r\u00f4me-Alexis", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""], ["Thirion", "Bertrand", ""]]}, {"id": "2009.14311", "submitter": "Dong Quan Nguyen", "authors": "Dong Quan Ngoc Nguyen, Lin Xing, and Lizhen Lin", "title": "Weight Prediction for Variants of Weighted Directed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A weighted directed network (WDN) is a directed graph in which each edge is\nassociated to a unique value called weight. These networks are very suitable\nfor modeling real-world social networks in which there is an assessment of one\nvertex toward other vertices. One of the main problems studied in this paper is\nprediction of edge weights in such networks. We introduce, for the first time,\na metric geometry approach to studying edge weight prediction in WDNs. We\nmodify a usual notion of WDNs, and introduce a new type of WDNs which we coin\nthe term \\textit{almost-weighted directed networks} (AWDNs). AWDNs can capture\nthe weight information of a network from a given training set. We then\nconstruct a class of metrics (or distances) for AWDNs which equips such\nnetworks with a metric space structure. Using the metric geometry structure of\nAWDNs, we propose modified $k$ nearest neighbors (kNN) methods and modified\nsupport-vector machine (SVM) methods which will then be used to predict edge\nweights in AWDNs. In many real-world datasets, in addition to edge weights, one\ncan also associate weights to vertices which capture information of vertices;\nassociation of weights to vertices especially plays an important role in graph\nembedding problems. Adopting a similar approach, we introduce two new types of\ndirected networks in which weights are associated to either a subset of origin\nvertices or a subset of terminal vertices . We, for the first time, construct\nnovel classes of metrics on such networks, and based on these new metrics\npropose modified $k$NN and SVM methods for predicting weights of origins and\nterminals in these networks. We provide experimental results on several\nreal-world datasets, using our geometric methodologies.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:18:24 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Nguyen", "Dong Quan Ngoc", ""], ["Xing", "Lin", ""], ["Lin", "Lizhen", ""]]}, {"id": "2009.14332", "submitter": "Guangtao Wang", "authors": "Guangtao Wang, Rex Ying, Jing Huang, Jure Leskovec", "title": "Multi-hop Attention based Graph Neural Network", "comments": "Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention mechanism in graph neural networks (GNNs) led to\nstate-of-the-art performance on many graph representation learning tasks.\nCurrently, at every layer, attention is computed between connected pairs of\nnodes and depends solely on the representation of the two nodes. However, such\nattention mechanism does not account for nodes that are not directly connected\nbut provide important network context. Here we propose Multi-hop Attention\nGraph Neural Network (MAGNA), a principled way to incorporate multi-hop context\ninformation into every layer of attention computation. MAGNA diffuses the\nattention scores across the network, which increases the receptive field for\nevery layer of the GNN. Unlike previous approaches, MAGNA uses a diffusion\nprior on attention values, to efficiently account for all paths between the\npair of disconnected nodes. We demonstrate in theory and experiments that MAGNA\ncaptures large-scale structural information in every layer, and has a low-pass\neffect that eliminates noisy high-frequency information from graph data.\nExperimental results on node classification as well as the knowledge graph\ncompletion benchmarks show that MAGNA achieves state-of-the-art results: MAGNA\nachieves up to 5.7 percent relative error reduction over the previous\nstate-of-the-art on Cora, Citeseer, and Pubmed. MAGNA also obtains the best\nperformance on a large-scale Open Graph Benchmark dataset. On knowledge graph\ncompletion MAGNA advances state-of-the-art on WN18RR and FB15k-237 across four\ndifferent performance metrics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:41:19 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 00:45:07 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 04:51:02 GMT"}, {"version": "v4", "created": "Sat, 15 May 2021 18:31:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Guangtao", ""], ["Ying", "Rex", ""], ["Huang", "Jing", ""], ["Leskovec", "Jure", ""]]}, {"id": "2009.14337", "submitter": "Guangmo Tong", "authors": "Guangmo Tong", "title": "StratLearner: Learning a Strategy for Misinformation Prevention in\n  Social Networks", "comments": "NeurIPS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a combinatorial optimization problem taking an input, can we learn a\nstrategy to solve it from the examples of input-solution pairs without knowing\nits objective function? In this paper, we consider such a setting and study the\nmisinformation prevention problem. Given the examples of attacker-protector\npairs, our goal is to learn a strategy to compute protectors against future\nattackers, without the need of knowing the underlying diffusion model. To this\nend, we design a structured prediction framework, where the main idea is to\nparameterize the scoring function using random features constructed through\ndistance functions on randomly sampled subgraphs, which leads to a kernelized\nscoring function with weights learnable via the large margin method. Evidenced\nby experiments, our method can produce near-optimal protectors without using\nany information of the diffusion model, and it outperforms other possible\ngraph-based and learning-based methods by an evident margin.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:58:33 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Tong", "Guangmo", ""]]}, {"id": "2009.14343", "submitter": "Abhishek Sharma", "authors": "Abhishek Sharma and Maks Ovsjanikov", "title": "Geometric Matrix Completion: A Functional View", "comments": "Accepted at GRL workshop, ICML'20. Code:\n  \\url{https://github.com/Not-IITian/functional-matrix-completion}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a totally functional view of geometric matrix completion problem.\nDifferently from existing work, we propose a novel regularization inspired from\nthe functional map literature that is more interpretable and theoretically\nsound. On synthetic tasks with strong underlying geometric structure, our\nframework outperforms state of the art by a huge margin (two order of\nmagnitude) demonstrating the potential of our approach. On real datasets, we\nachieve state-of-the-art results at a fraction of the computational effort of\nprevious methods. Our code is publicly available at\nhttps://github.com/Not-IITian/functional-matrix-completion\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 23:23:04 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Sharma", "Abhishek", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "2009.14373", "submitter": "Chien-Hsun Lai", "authors": "Chien-Hsun Lai, Yu-Shuen Wang", "title": "Facilitate the Parametric Dimension Reduction by Gradient Clipping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend a well-known dimension reduction method, t-distributed stochastic\nneighbor embedding (t-SNE), from non-parametric to parametric by training\nneural networks. The main advantage of a parametric technique is the\ngeneralization of handling new data, which is particularly beneficial for\nstreaming data exploration. However, training a neural network to optimize the\nt-SNE objective function frequently fails. Previous methods overcome this\nproblem by pre-training and then fine-tuning the network. We found that the\ntraining failure comes from the gradient exploding problem, which occurs when\ndata points distant in high-dimensional space are projected to nearby embedding\npositions. Accordingly, we applied the gradient clipping method to solve the\nproblem. Since the networks are trained by directly optimizing the t-SNE\nobjective function, our method achieves an embedding quality that is compatible\nwith the non-parametric t-SNE while enjoying the ability of generalization. Due\nto mini-batch network training, our parametric dimension reduction method is\nhighly efficient. We further extended other non-parametric state-of-the-art\napproaches, such as LargeVis and UMAP, to the parametric versions. Experiment\nresults demonstrate the feasibility of our method. Considering its\npracticability, we will soon release the codes for public use.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:21:22 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Lai", "Chien-Hsun", ""], ["Wang", "Yu-Shuen", ""]]}, {"id": "2009.14379", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Atsutoshi Kumagai", "title": "Few-shot Learning for Time-series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series forecasting is important for many applications. Forecasting\nmodels are usually trained using time-series data in a specific target task.\nHowever, sufficient data in the target task might be unavailable, which leads\nto performance degradation. In this paper, we propose a few-shot learning\nmethod that forecasts a future value of a time-series in a target task given a\nfew time-series in the target task. Our model is trained using time-series data\nin multiple training tasks that are different from target tasks. Our model uses\na few time-series to build a forecasting function based on a recurrent neural\nnetwork with an attention mechanism. With the attention mechanism, we can\nretrieve useful patterns in a small number of time-series for the current\nsituation. Our model is trained by minimizing an expected test error of\nforecasting next timestep values. We demonstrate the effectiveness of the\nproposed method using 90 time-series datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:32:22 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Kumagai", "Atsutoshi", ""]]}, {"id": "2009.14389", "submitter": "Liang Du", "authors": "Liang Du, Haiying Zhang, Xin Ren, Xiaolin Lv", "title": "Manifold Adaptive Multiple Kernel K-Means for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple kernel methods based on k-means aims to integrate a group of kernels\nto improve the performance of kernel k-means clustering. However, we observe\nthat most existing multiple kernel k-means methods exploit the nonlinear\nrelationship within kernels, whereas the local manifold structure among\nmultiple kernel space is not sufficiently considered. In this paper, we adopt\nthe manifold adaptive kernel, instead of the original kernel, to integrate the\nlocal manifold structure of kernels. Thus, the induced multiple manifold\nadaptive kernels not only reflect the nonlinear relationship but also the local\nmanifold structure. We then perform multiple kernel clustering within the\nmultiple kernel k-means clustering framework. It has been verified that the\nproposed method outperforms several state-of-the-art baseline methods on a\nvariety of data sets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 02:07:53 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Du", "Liang", ""], ["Zhang", "Haiying", ""], ["Ren", "Xin", ""], ["Lv", "Xiaolin", ""]]}, {"id": "2009.14397", "submitter": "Alberto Bietti", "authors": "Alberto Bietti, Francis Bach", "title": "Deep Equals Shallow for ReLU Networks in Kernel Regimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are often considered to be more expressive than shallow ones in\nterms of approximation. Indeed, certain functions can be approximated by deep\nnetworks provably more efficiently than by shallow ones, however, no tractable\nalgorithms are known for learning such deep models. Separately, a recent line\nof work has shown that deep networks trained with gradient descent may behave\nlike (tractable) kernel methods in a certain over-parameterized regime, where\nthe kernel is determined by the architecture and initialization, and this paper\nfocuses on approximation for such kernels. We show that for ReLU activations,\nthe kernels derived from deep fully-connected networks have essentially the\nsame approximation properties as their shallow two-layer counterpart, namely\nthe same eigenvalue decay for the corresponding integral operator. This\nhighlights the limitations of the kernel framework for understanding the\nbenefits of such deep architectures. Our main theoretical result relies on\ncharacterizing such eigenvalue decays through differentiability properties of\nthe kernel function, which also easily applies to the study of other kernels\ndefined on the sphere.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 02:37:43 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 16:54:31 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 22:25:45 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Bietti", "Alberto", ""], ["Bach", "Francis", ""]]}, {"id": "2009.14416", "submitter": "Qi Qian", "authors": "Qi Qian, Hao Li, Juhua Hu", "title": "Efficient Kernel Transfer in Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is an effective way for model compression in deep\nlearning. Given a large model (i.e., teacher model), it aims to improve the\nperformance of a compact model (i.e., student model) by transferring the\ninformation from the teacher. An essential challenge in knowledge distillation\nis to identify the appropriate information to transfer. In early works, only\nthe final output of the teacher model is used as the soft label to help the\ntraining of student models. Recently, the information from intermediate layers\nis also adopted for better distillation. In this work, we aim to optimize the\nprocess of knowledge distillation from the perspective of kernel matrix. The\noutput of each layer in a neural network can be considered as a new feature\nspace generated by applying a kernel function on original images. Hence, we\npropose to transfer the corresponding kernel matrix (i.e., Gram matrix) from\nteacher models to student models for distillation. However, the size of the\nwhole kernel matrix is quadratic to the number of examples. To improve the\nefficiency, we decompose the original kernel matrix with Nystr{\\\"{o}}m method\nand then transfer the partial matrix obtained with landmark points, whose size\nis linear in the number of examples. More importantly, our theoretical analysis\nshows that the difference between the original kernel matrices of teacher and\nstudent can be well bounded by that of their corresponding partial matrices.\nFinally, a new strategy of generating appropriate landmark points is proposed\nfor better distillation. The empirical study on benchmark data sets\ndemonstrates the effectiveness of the proposed algorithm. Code will be\nreleased.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:03:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Qian", "Qi", ""], ["Li", "Hao", ""], ["Hu", "Juhua", ""]]}, {"id": "2009.14436", "submitter": "Jianjun Yuan", "authors": "Jianjun Yuan", "title": "Online Convex Optimization in Changing Environments and its Application\n  to Resource Allocation", "comments": "phd thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of the big data, we create and collect lots of data from all\ndifferent kinds of sources: the Internet, the sensors, the consumer market, and\nso on. Many of the data are coming sequentially, and would like to be processed\nand understood quickly. One classic way of analyzing data is based on batch\nprocessing, in which the data is stored and analyzed in an offline fashion.\nHowever, when the volume of the data is too large, it is much more difficult\nand time-consuming to do batch processing than sequential processing. What's\nmore, sequential data is usually changing dynamically, and needs to be\nunderstood on-the-fly in order to capture the changes. Online Convex\nOptimization (OCO) is a popular framework that matches the above sequential\ndata processing requirement. Applications using OCO include online routing,\nonline auctions, online classification and regression, as well as online\nresource allocation. Due to the general applicability of OCO to the sequential\ndata and the rigorous theoretical guarantee, it has attracted lots of\nresearchers to develop useful algorithms to fulfill different needs. In this\nthesis, we show our contributions to OCO's development by designing algorithms\nto adapt to changing environments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:53:59 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Yuan", "Jianjun", ""]]}, {"id": "2009.14441", "submitter": "Shay Deutsch Dr.", "authors": "Shay Deutsch, Stefano Soatto", "title": "Spectral Embedding of Graph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an unsupervised graph embedding that trades off local node\nsimilarity and connectivity, and global structure. The embedding is based on a\ngeneralized graph Laplacian, whose eigenvectors compactly capture both network\nstructure and neighborhood proximity in a single representation. The key idea\nis to transform the given graph into one whose weights measure the centrality\nof an edge by the fraction of the number of shortest paths that pass through\nthat edge, and employ its spectral proprieties in the representation. Testing\nthe resulting graph network representation shows significant improvement over\nthe sate of the art in data analysis tasks including social networks and\nmaterial science. We also test our method on node classification from the\nhuman-SARS CoV-2 protein-protein interactome.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:59:10 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Deutsch", "Shay", ""], ["Soatto", "Stefano", ""]]}, {"id": "2009.14444", "submitter": "Sebastien Bubeck", "authors": "S\\'ebastien Bubeck and Yuanzhi Li and Dheeraj Nagaraj", "title": "A law of robustness for two-layers neural networks", "comments": "18 pages, 3 figures. V2: improved Theorem 4 (weaker version of the\n  Conjecture with $n$ replaced by $d$) from ReLU with no bias term in V1, to\n  arbitrary non-linearities (even data-dependent) in V2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of the inherent tradeoffs between the size of a neural\nnetwork and its robustness, as measured by its Lipschitz constant. We make a\nprecise conjecture that, for any Lipschitz activation function and for most\ndatasets, any two-layers neural network with $k$ neurons that perfectly fit the\ndata must have its Lipschitz constant larger (up to a constant) than\n$\\sqrt{n/k}$ where $n$ is the number of datapoints. In particular, this\nconjecture implies that overparametrization is necessary for robustness, since\nit means that one needs roughly one neuron per datapoint to ensure a\n$O(1)$-Lipschitz network, while mere data fitting of $d$-dimensional data\nrequires only one neuron per $d$ datapoints. We prove a weaker version of this\nconjecture when the Lipschitz constant is replaced by an upper bound on it\nbased on the spectral norm of the weight matrix. We also prove the conjecture\nin the high-dimensional regime $n \\approx d$ (which we also refer to as the\nundercomplete case, since only $k \\leq d$ is relevant here). Finally we prove\nthe conjecture for polynomial activation functions of degree $p$ when $n\n\\approx d^p$. We complement these findings with experimental evidence\nsupporting the conjecture.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:13:12 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 23:59:09 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Li", "Yuanzhi", ""], ["Nagaraj", "Dheeraj", ""]]}, {"id": "2009.14448", "submitter": "Jayaraman J. Thiagarajan", "authors": "Bindya Venkatesh and Jayaraman J. Thiagarajan", "title": "Ask-n-Learn: Active Learning via Reliable Gradient Representations for\n  Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep predictive models rely on human supervision in the form of labeled\ntraining data. Obtaining large amounts of annotated training data can be\nexpensive and time consuming, and this becomes a critical bottleneck while\nbuilding such models in practice. In such scenarios, active learning (AL)\nstrategies are used to achieve faster convergence in terms of labeling efforts.\nExisting active learning employ a variety of heuristics based on uncertainty\nand diversity to select query samples. Despite their wide-spread use, in\npractice, their performance is limited by a number of factors including\nnon-calibrated uncertainties, insufficient trade-off between data exploration\nand exploitation, presence of confirmation bias etc. In order to address these\nchallenges, we propose Ask-n-Learn, an active learning approach based on\ngradient embeddings obtained using the pesudo-labels estimated in each\niteration of the algorithm. More importantly, we advocate the use of prediction\ncalibration to obtain reliable gradient embeddings, and propose a data\naugmentation strategy to alleviate the effects of confirmation bias during\npseudo-labeling. Through empirical studies on benchmark image classification\ntasks (CIFAR-10, SVHN, Fashion-MNIST, MNIST), we demonstrate significant\nimprovements over state-of-the-art baselines, including the recently proposed\nBADGE algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:19:56 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Venkatesh", "Bindya", ""], ["Thiagarajan", "Jayaraman J.", ""]]}, {"id": "2009.14454", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Vivek Narayanaswamy, Rushil Anirudh,\n  Peer-Timo Bremer and Andreas Spanias", "title": "Accurate and Robust Feature Importance Estimation under Distribution\n  Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing reliance on the outcomes of black-box models in critical\napplications, post-hoc explainability tools that do not require access to the\nmodel internals are often used to enable humans understand and trust these\nmodels. In particular, we focus on the class of methods that can reveal the\ninfluence of input features on the predicted outputs. Despite their wide-spread\nadoption, existing methods are known to suffer from one or more of the\nfollowing challenges: computational complexities, large uncertainties and most\nimportantly, inability to handle real-world domain shifts. In this paper, we\npropose PRoFILE, a novel feature importance estimation method that addresses\nall these challenges. Through the use of a loss estimator jointly trained with\nthe predictive model and a causal objective, PRoFILE can accurately estimate\nthe feature importance scores even under complex distribution shifts, without\nany additional re-training. To this end, we also develop learning strategies\nfor training the loss estimator, namely contrastive and dropout calibration,\nand find that it can effectively detect distribution shifts. Using empirical\nstudies on several benchmark image and non-image data, we show significant\nimprovements over state-of-the-art approaches, both in terms of fidelity and\nrobustness.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:29:01 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Narayanaswamy", "Vivek", ""], ["Anirudh", "Rushil", ""], ["Bremer", "Peer-Timo", ""], ["Spanias", "Andreas", ""]]}, {"id": "2009.14455", "submitter": "Jayaraman J. Thiagarajan", "authors": "Uday Shankar Shanthamallu, Jayaraman J. Thiagarajan and Andreas\n  Spanias", "title": "Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs), a generalization of neural networks to\ngraph-structured data, are often implemented using message passes between\nentities of a graph. While GNNs are effective for node classification, link\nprediction and graph classification, they are vulnerable to adversarial\nattacks, i.e., a small perturbation to the structure can lead to a non-trivial\nperformance degradation. In this work, we propose Uncertainty Matching GNN\n(UM-GNN), that is aimed at improving the robustness of GNN models, particularly\nagainst poisoning attacks to the graph structure, by leveraging epistemic\nuncertainties from the message passing framework. More specifically, we propose\nto build a surrogate predictor that does not directly access the graph\nstructure, but systematically extracts reliable knowledge from a standard GNN\nthrough a novel uncertainty-matching strategy. Interestingly, this uncoupling\nmakes UM-GNN immune to evasion attacks by design, and achieves significantly\nimproved robustness against poisoning attacks. Using empirical studies with\nstandard benchmarks and a suite of global and target attacks, we demonstrate\nthe effectiveness of UM-GNN, when compared to existing baselines including the\nstate-of-the-art robust GCN.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:29:42 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Shanthamallu", "Uday Shankar", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Spanias", "Andreas", ""]]}, {"id": "2009.14471", "submitter": "Justin Terry", "authors": "J. K. Terry, Benjamin Black, Nathaniel Grammel, Mario Jayakumar,\n  Ananth Hari, Ryan Sullivan, Luis Santos, Rodrigo Perez, Caroline Horsch,\n  Clemens Dieffendahl, Niall L. Williams, Yashas Lokesh, Praveen Ravi", "title": "PettingZoo: Gym for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the PettingZoo library and the accompanying Agent\nEnvironment Cycle (\"AEC\") games model. PettingZoo is a library of diverse sets\nof multi-agent environments with a universal, elegant Python API. PettingZoo\nwas developed with the goal of accelerating research in Multi-Agent\nReinforcement Learning (\"MARL\"), by making work more interchangeable,\naccessible and reproducible akin to what OpenAI's Gym library did for\nsingle-agent reinforcement learning. PettingZoo's API, while inheriting many\nfeatures of Gym, is unique amongst MARL APIs in that it's based around the\nnovel AEC games model. We argue, in part through case studies on major problems\nin popular MARL environments, that the popular game models are poor conceptual\nmodels of the games commonly used with MARL, that they promote severe bugs that\nare hard to detect, and that the AEC games model addresses these problems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 06:42:09 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 20:04:22 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 08:02:06 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 22:34:21 GMT"}, {"version": "v5", "created": "Thu, 25 Feb 2021 22:08:03 GMT"}, {"version": "v6", "created": "Wed, 16 Jun 2021 00:18:34 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Terry", "J. K.", ""], ["Black", "Benjamin", ""], ["Grammel", "Nathaniel", ""], ["Jayakumar", "Mario", ""], ["Hari", "Ananth", ""], ["Sullivan", "Ryan", ""], ["Santos", "Luis", ""], ["Perez", "Rodrigo", ""], ["Horsch", "Caroline", ""], ["Dieffendahl", "Clemens", ""], ["Williams", "Niall L.", ""], ["Lokesh", "Yashas", ""], ["Ravi", "Praveen", ""]]}, {"id": "2009.14499", "submitter": "Ashad Kabir", "authors": "Md Delowar Hossain, Muhammad Ashad Kabir, Adnan Anwar, Md Zahidul\n  Islam", "title": "Detecting Autism Spectrum Disorder using Machine Learning", "comments": null, "journal-ref": "Health information science and systems, 2021", "doi": "10.1007/s13755-021-00145-9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism Spectrum Disorder (ASD), which is a neuro development disorder, is\noften accompanied by sensory issues such an over sensitivity or under\nsensitivity to sounds and smells or touch. Although its main cause is genetics\nin nature, early detection and treatment can help to improve the conditions. In\nrecent years, machine learning based intelligent diagnosis has been evolved to\ncomplement the traditional clinical methods which can be time consuming and\nexpensive. The focus of this paper is to find out the most significant traits\nand automate the diagnosis process using available classification techniques\nfor improved diagnosis purpose. We have analyzed ASD datasets of Toddler,\nChild, Adolescent and Adult. We determine the best performing classifier for\nthese binary datasets using the evaluation metrics recall, precision,\nF-measures and classification errors. Our finding shows that Sequential minimal\noptimization (SMO) based Support Vector Machines (SVM) classifier outperforms\nall other benchmark machine learning algorithms in terms of accuracy during the\ndetection of ASD cases and produces less classification errors compared to\nother algorithms. Also, we find that Relief Attributes algorithm is the best to\nidentify the most significant attributes in ASD datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:33:12 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Hossain", "Md Delowar", ""], ["Kabir", "Muhammad Ashad", ""], ["Anwar", "Adnan", ""], ["Islam", "Md Zahidul", ""]]}, {"id": "2009.14502", "submitter": "Yoonho Boo", "authors": "Yoonho Boo, Sungho Shin, Jungwook Choi, and Wonyong Sung", "title": "Stochastic Precision Ensemble: Self-Knowledge Distillation for Quantized\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantization of deep neural networks (QDNNs) has been actively studied\nfor deployment in edge devices. Recent studies employ the knowledge\ndistillation (KD) method to improve the performance of quantized networks. In\nthis study, we propose stochastic precision ensemble training for QDNNs (SPEQ).\nSPEQ is a knowledge distillation training scheme; however, the teacher is\nformed by sharing the model parameters of the student network. We obtain the\nsoft labels of the teacher by changing the bit precision of the activation\nstochastically at each layer of the forward-pass computation. The student model\nis trained with these soft labels to reduce the activation quantization noise.\nThe cosine similarity loss is employed, instead of the KL-divergence, for KD\ntraining. As the teacher model changes continuously by random bit-precision\nassignment, it exploits the effect of stochastic ensemble KD. SPEQ outperforms\nthe existing quantization training methods in various tasks, such as image\nclassification, question-answering, and transfer learning without the need for\ncumbersome teacher networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:38:37 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Boo", "Yoonho", ""], ["Shin", "Sungho", ""], ["Choi", "Jungwook", ""], ["Sung", "Wonyong", ""]]}, {"id": "2009.14552", "submitter": "Chaosheng Dong", "authors": "Chaosheng Dong, Bo Zeng", "title": "Wasserstein Distributionally Robust Inverse Multiobjective Optimization", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse multiobjective optimization provides a general framework for the\nunsupervised learning task of inferring parameters of a multiobjective decision\nmaking problem (DMP), based on a set of observed decisions from the human\nexpert. However, the performance of this framework relies critically on the\navailability of an accurate DMP, sufficient decisions of high quality, and a\nparameter space that contains enough information about the DMP. To hedge\nagainst the uncertainties in the hypothetical DMP, the data, and the parameter\nspace, we investigate in this paper the distributionally robust approach for\ninverse multiobjective optimization. Specifically, we leverage the Wasserstein\nmetric to construct a ball centered at the empirical distribution of these\ndecisions. We then formulate a Wasserstein distributionally robust inverse\nmultiobjective optimization problem (WRO-IMOP) that minimizes a worst-case\nexpected loss function, where the worst case is taken over all distributions in\nthe Wasserstein ball. We show that the excess risk of the WRO-IMOP estimator\nhas a sub-linear convergence rate. Furthermore, we propose the semi-infinite\nreformulations of the WRO-IMOP and develop a cutting-plane algorithm that\nconverges to an approximate solution in finite iterations. Finally, we\ndemonstrate the effectiveness of our method on both a synthetic multiobjective\nquadratic program and a real world portfolio optimization problem.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 10:44:07 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Dong", "Chaosheng", ""], ["Zeng", "Bo", ""]]}, {"id": "2009.14554", "submitter": "Alexander Mathiasen Mr", "authors": "Alexander Mathiasen and Frederik Hvilsh{\\o}j", "title": "One Reflection Suffice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal weight matrices are used in many areas of deep learning. Much\nprevious work attempt to alleviate the additional computational resources it\nrequires to constrain weight matrices to be orthogonal. One popular approach\nutilizes *many* Householder reflections. The only practical drawback is that\nmany reflections cause low GPU utilization. We mitigate this final drawback by\nproving that *one* reflection is sufficient, if the reflection is computed by\nan auxiliary neural network.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 10:52:27 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Mathiasen", "Alexander", ""], ["Hvilsh\u00f8j", "Frederik", ""]]}, {"id": "2009.14572", "submitter": "Sandro Lera", "authors": "Delilah Donick and Sandro Claudio Lera", "title": "Uncovering Feature Interdependencies in High-Noise Environments with\n  Stepwise Lookahead Decision Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventionally, random forests are built from \"greedy\" decision trees which\neach consider only one split at a time during their construction. The\nsub-optimality of greedy implementation has been well-known, yet mainstream\nadoption of more sophisticated tree building algorithms has been lacking. We\nexamine under what circumstances an implementation of less greedy decision\ntrees actually yields outperformance. To this end, a \"stepwise lookahead\"\nvariation of the random forest algorithm is presented for its ability to better\nuncover binary feature interdependencies. In contrast to the greedy approach,\nthe decision trees included in this random forest algorithm, each\nsimultaneously consider three split nodes in tiers of depth two. It is\ndemonstrated on synthetic data and financial price time series that the\nlookahead version significantly outperforms the greedy one when (a) certain\nnon-linear relationships between feature-pairs are present and (b) if the\nsignal-to-noise ratio is particularly low. A long-short trading strategy for\ncopper futures is then backtested by training both greedy and stepwise\nlookahead random forests to predict the signs of daily price returns. The\nresulting superior performance of the lookahead algorithm is at least partially\nexplained by the presence of \"XOR-like\" relationships between long-term and\nshort-term technical indicators. More generally, across all examined datasets,\nwhen no such relationships between features are present, performance across\nrandom forests is similar. Given its enhanced ability to understand the\nfeature-interdependencies present in complex systems, this lookahead variation\nis a useful extension to the toolkit of data scientists, in particular for\nfinancial machine learning, where conditions (a) and (b) are typically met.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:31:10 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 01:54:54 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 14:11:33 GMT"}, {"version": "v4", "created": "Mon, 1 Feb 2021 04:21:00 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 14:24:26 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Donick", "Delilah", ""], ["Lera", "Sandro Claudio", ""]]}, {"id": "2009.14573", "submitter": "Takato Yasuno", "authors": "Takato Yasuno, Akira Ishii, Masazumi Amakata", "title": "Rain-Code Fusion : Code-to-code ConvLSTM Forecasting Spatiotemporal\n  Precipitation", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, flood damage has become a social problem owing to unexperienced\nweather conditions arising from climate change. An immediate response to heavy\nrain is important for the mitigation of economic losses and also for rapid\nrecovery. Spatiotemporal precipitation forecasts may enhance the accuracy of\ndam inflow prediction, more than 6 hours forward for flood damage mitigation.\nHowever, the ordinary ConvLSTM has the limitation of predictable range more\nthan 3-timesteps in real-world precipitation forecasting owing to the\nirreducible bias between target prediction and ground-truth value. This paper\nproposes a rain-code approach for spatiotemporal precipitation code-to-code\nforecasting. We propose a novel rainy feature that represents a temporal rainy\nprocess using multi-frame fusion for the timestep reduction. We perform\nrain-code studies with various term ranges based on the standard ConvLSTM. We\napplied to a dam region within the Japanese rainy term hourly precipitation\ndata, under 2006 to 2019 approximately 127 thousands hours, every year from May\nto October. We apply the radar analysis hourly data on the central broader\nregion with an area of 136 x 148 km2 . Finally we have provided sensitivity\nstudies between the rain-code size and hourly accuracy within the several\nforecasting range.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:33:45 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 05:51:53 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 04:38:39 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2020 13:13:17 GMT"}, {"version": "v5", "created": "Mon, 23 Nov 2020 12:16:58 GMT"}, {"version": "v6", "created": "Mon, 1 Mar 2021 11:49:45 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Yasuno", "Takato", ""], ["Ishii", "Akira", ""], ["Amakata", "Masazumi", ""]]}, {"id": "2009.14575", "submitter": "Yassine Laguel", "authors": "Yassine Laguel, J\\'er\\^ome Malick and Zaid Harchaoui", "title": "First-order Optimization for Superquantile-based Supervised Learning", "comments": "6 pages, 2 figures, 2 tables, presented at IEEE MLSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical supervised learning via empirical risk (or negative log-likelihood)\nminimization hinges upon the assumption that the testing distribution coincides\nwith the training distribution. This assumption can be challenged in modern\napplications of machine learning in which learning machines may operate at\nprediction time with testing data whose distribution departs from the one of\nthe training data. We revisit the superquantile regression method by proposing\na first-order optimization algorithm to minimize a superquantile-based learning\nobjective. The proposed algorithm is based on smoothing the superquantile\nfunction by infimal convolution. Promising numerical results illustrate the\ninterest of the approach towards safer supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:43:45 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 09:11:20 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Laguel", "Yassine", ""], ["Malick", "J\u00e9r\u00f4me", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2009.14588", "submitter": "Maxim Panov", "authors": "Ivan Sukharev, Valentina Shumovskaia, Kirill Fedyanin, Maxim Panov and\n  Dmitry Berestnev", "title": "EWS-GCN: Edge Weight-Shared Graph Convolutional Network for\n  Transactional Banking Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss how modern deep learning approaches can be applied\nto the credit scoring of bank clients. We show that information about\nconnections between clients based on money transfers between them allows us to\nsignificantly improve the quality of credit scoring compared to the approaches\nusing information about the target client solely. As a final solution, we\ndevelop a new graph neural network model EWS-GCN that combines ideas of graph\nconvolutional and recurrent neural networks via attention mechanism. The\nresulting model allows for robust training and efficient processing of\nlarge-scale data. We also demonstrate that our model outperforms the\nstate-of-the-art graph neural networks achieving excellent results\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:09:28 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Sukharev", "Ivan", ""], ["Shumovskaia", "Valentina", ""], ["Fedyanin", "Kirill", ""], ["Panov", "Maxim", ""], ["Berestnev", "Dmitry", ""]]}, {"id": "2009.14593", "submitter": "Ben Day", "authors": "Vijja Wichitwechkarn, Ben Day, Cristian Bodnar, Matthew Wales, Pietro\n  Li\\`o", "title": "The Role of Isomorphism Classes in Multi-Relational Datasets", "comments": "7 pages main text, 1 page of references and an ethics statement, 3\n  pages of appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-interaction systems abound in nature, from colloidal suspensions to\ngene regulatory circuits. These systems can produce complex dynamics and graph\nneural networks have been proposed as a method to extract underlying\ninteractions and predict how systems will evolve. The current training and\nevaluation procedures for these models through the use of synthetic\nmulti-relational datasets however are agnostic to interaction network\nisomorphism classes, which produce identical dynamics up to initial conditions.\nWe extensively analyse how isomorphism class awareness affects these models,\nfocusing on neural relational inference (NRI) models, which are unique in\nexplicitly inferring interactions to predict dynamics in the unsupervised\nsetting. Specifically, we demonstrate that isomorphism leakage overestimates\nperformance in multi-relational inference and that sampling biases present in\nthe multi-interaction network generation process can impair generalisation. To\nremedy this, we propose isomorphism-aware synthetic benchmarks for model\nevaluation. We use these benchmarks to test generalisation abilities and\ndemonstrate the existence of a threshold sampling frequency of isomorphism\nclasses for successful learning. In addition, we demonstrate that isomorphism\nclasses can be utilised through a simple prioritisation scheme to improve model\nperformance, stability during training and reduce training time.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:15:24 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wichitwechkarn", "Vijja", ""], ["Day", "Ben", ""], ["Bodnar", "Cristian", ""], ["Wales", "Matthew", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2009.14596", "submitter": "Lei Wu", "authors": "Weinan E", "title": "Machine Learning and Computational Mathematics", "comments": null, "journal-ref": null, "doi": "10.4208/cicp.OA-2020-0185", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based machine learning is capable of approximating functions\nin very high dimension with unprecedented efficiency and accuracy. This has\nopened up many exciting new possibilities, not just in traditional areas of\nartificial intelligence, but also in scientific computing and computational\nscience. At the same time, machine learning has also acquired the reputation of\nbeing a set of \"black box\" type of tricks, without fundamental principles. This\nhas been a real obstacle for making further progress in machine learning. In\nthis article, we try to address the following two very important questions: (1)\nHow machine learning has already impacted and will further impact computational\nmathematics, scientific computing and computational science? (2) How\ncomputational mathematics, particularly numerical analysis, {can} impact\nmachine learning? We describe some of the most important progress that has been\nmade on these issues. Our hope is to put things into a perspective that will\nhelp to integrate machine learning with computational mathematics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 23:16:46 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["E", "Weinan", ""]]}, {"id": "2009.14606", "submitter": "Katharina Rombach", "authors": "Katharina Rombach, Gabriel Michau and Olga Fink", "title": "Improving Generalization of Deep Fault Detection Models in the Presence\n  of Mislabeled Data", "comments": "12 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mislabeled samples are ubiquitous in real-world datasets as rule-based or\nexpert labeling is usually based on incorrect assumptions or subject to biased\nopinions. Neural networks can \"memorize\" these mislabeled samples and, as a\nresult, exhibit poor generalization. This poses a critical issue in fault\ndetection applications, where not only the training but also the validation\ndatasets are prone to contain mislabeled samples. In this work, we propose a\nnovel two-step framework for robust training with label noise. In the first\nstep, we identify outliers (including the mislabeled samples) based on the\nupdate in the hypothesis space. In the second step, we propose different\napproaches to modifying the training data based on the identified outliers and\na data augmentation technique. Contrary to previous approaches, we aim at\nfinding a robust solution that is suitable for real-world applications, such as\nfault detection, where no clean, \"noise-free\" validation dataset is available.\nUnder an approximate assumption about the upper limit of the label noise, we\nsignificantly improve the generalization ability of the model trained under\nmassive label noise.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:33:25 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Rombach", "Katharina", ""], ["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "2009.14610", "submitter": "R\\'emy Garnier", "authors": "R\\'emy Garnier", "title": "Concurrent Neural Network : A model of competition between times series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competition between times series often arises in sales prediction, when\nsimilar products are on sale on a marketplace. This article provides a model of\nthe presence of cannibalization between times series. This model creates a\n\"competitiveness\" function that depends on external features such as price and\nmargin. It also provides a theoretical guaranty on the error of the model under\nsome reasonable conditions, and implement this model using a neural network to\ncompute this competitiveness function. This implementation outperforms other\ntraditional time series methods and classical neural networks for market share\nprediction on a real-world data set.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:34:56 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 13:43:00 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Garnier", "R\u00e9my", ""]]}, {"id": "2009.14670", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat and Bogdan Gabrys", "title": "An Online Learning Algorithm for a Neuro-Fuzzy Classifier with\n  Mixed-Attribute Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  General fuzzy min-max neural network (GFMMNN) is one of the efficient\nneuro-fuzzy systems for data classification. However, one of the downsides of\nits original learning algorithms is the inability to handle and learn from the\nmixed-attribute data. While categorical features encoding methods can be used\nwith the GFMMNN learning algorithms, they exhibit a lot of shortcomings. Other\napproaches proposed in the literature are not suitable for on-line learning as\nthey require entire training data available in the learning phase. With the\nrapid change in the volume and velocity of streaming data in many application\nareas, it is increasingly required that the constructed models can learn and\nadapt to the continuous data changes in real-time without the need for their\nfull retraining or access to the historical data. This paper proposes an\nextended online learning algorithm for the GFMMNN. The proposed method can\nhandle the datasets with both continuous and categorical features. The\nextensive experiments confirmed superior and stable classification performance\nof the proposed approach in comparison to other relevant learning algorithms\nfor the GFMM model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:45:36 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2009.14695", "submitter": "Carlos Perales-Gonzalez", "authors": "Carlos Perales-Gonz\\'alez", "title": "Global convergence of Negative Correlation Extreme Learning Machine", "comments": "Jupyter Notebook associated in\n  https://github.com/cperales/pyridge/blob/ncelm/NCELM_convergence.ipynb", "journal-ref": "Neural Process Lett (2021)", "doi": "10.1007/s11063-021-10492-z", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble approaches introduced in the Extreme Learning Machine (ELM)\nliterature mainly come from methods that relies on data sampling procedures,\nunder the assumption that the training data are heterogeneously enough to set\nup diverse base learners. To overcome this assumption, it was proposed an ELM\nensemble method based on the Negative Correlation Learning (NCL) framework,\ncalled Negative Correlation Extreme Learning Machine (NCELM). This model works\nin two stages: i) different ELMs are generated as base learners with random\nweights in the hidden layer, and ii) a NCL penalty term with the information of\nthe ensemble prediction is introduced in each ELM minimization problem,\nupdating the base learners, iii) second step is iterated until the ensemble\nconverges.\n  Although this NCL ensemble method was validated by an experimental study with\nmultiple benchmark datasets, no information was given on the conditions about\nthis convergence. This paper mathematically presents the sufficient conditions\nto guarantee the global convergence of NCELM. The update of the ensemble in\neach iteration is defined as a contraction mapping function, and through Banach\ntheorem, global convergence of the ensemble is proved.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:18:10 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 09:18:57 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Perales-Gonz\u00e1lez", "Carlos", ""]]}, {"id": "2009.14701", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski, Xiao Yu Wang, and Alexander Wong", "title": "Where Does Trust Break Down? A Quantitative Trust Analysis of Deep\n  Neural Networks via Trust Matrix and Conditional Trust Densities", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advances and successes in deep learning in recent years have led to\nconsiderable efforts and investments into its widespread ubiquitous adoption\nfor a wide variety of applications, ranging from personal assistants and\nintelligent navigation to search and product recommendation in e-commerce. With\nthis tremendous rise in deep learning adoption comes questions about the\ntrustworthiness of the deep neural networks that power these applications.\nMotivated to answer such questions, there has been a very recent interest in\ntrust quantification. In this work, we introduce the concept of trust matrix, a\nnovel trust quantification strategy that leverages the recently introduced\nquestion-answer trust metric by Wong et al. to provide deeper, more detailed\ninsights into where trust breaks down for a given deep neural network given a\nset of questions. More specifically, a trust matrix defines the expected\nquestion-answer trust for a given actor-oracle answer scenario, allowing one to\nquickly spot areas of low trust that needs to be addressed to improve the\ntrustworthiness of a deep neural network. The proposed trust matrix is simple\nto calculate, humanly interpretable, and to the best of the authors' knowledge\nis the first to study trust at the actor-oracle answer level. We further extend\nthe concept of trust densities with the notion of conditional trust densities.\nWe experimentally leverage trust matrices to study several well-known deep\nneural network architectures for image recognition, and further study the trust\ndensity and conditional trust densities for an interesting actor-oracle answer\nscenario. The results illustrate that trust matrices, along with conditional\ntrust densities, can be useful tools in addition to the existing suite of trust\nquantification metrics for guiding practitioners and regulators in creating and\ncertifying deep learning solutions for trusted operation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:33:43 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wang", "Xiao Yu", ""], ["Wong", "Alexander", ""]]}, {"id": "2009.14702", "submitter": "Vincent Gripon", "authors": "Vincent Gripon, Matthias L\\\"owe, Franck Vermet", "title": "Some Remarks on Replicated Simulated Annealing", "comments": null, "journal-ref": null, "doi": "10.1007/s10955-021-02727-z", "report-no": null, "categories": "cs.LG cs.NE math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently authors have introduced the idea of training discrete weights neural\nnetworks using a mix between classical simulated annealing and a replica ansatz\nknown from the statistical physics literature. Among other points, they claim\ntheir method is able to find robust configurations. In this paper, we analyze\nthis so-called \"replicated simulated annealing\" algorithm. In particular, we\nexplicit criteria to guarantee its convergence, and study when it successfully\nsamples from configurations. We also perform experiments using synthetic and\nreal data bases.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:33:53 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 18:41:03 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Gripon", "Vincent", ""], ["L\u00f6we", "Matthias", ""], ["Vermet", "Franck", ""]]}, {"id": "2009.14720", "submitter": "Huanrui Yang", "authors": "Huanrui Yang, Jingyang Zhang, Hongliang Dong, Nathan Inkawhich, Andrew\n  Gardner, Andrew Touchet, Wesley Wilkes, Heath Berry, Hai Li", "title": "DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of\n  Ensembles", "comments": "To be appeared in NeurIPS 2020 conference (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research finds CNN models for image classification demonstrate\noverlapped adversarial vulnerabilities: adversarial attacks can mislead CNN\nmodels with small perturbations, which can effectively transfer between\ndifferent models trained on the same dataset. Adversarial training, as a\ngeneral robustness improvement technique, eliminates the vulnerability in a\nsingle model by forcing it to learn robust features. The process is hard, often\nrequires models with large capacity, and suffers from significant loss on clean\ndata accuracy. Alternatively, ensemble methods are proposed to induce\nsub-models with diverse outputs against a transfer adversarial example, making\nthe ensemble robust against transfer attacks even if each sub-model is\nindividually non-robust. Only small clean accuracy drop is observed in the\nprocess. However, previous ensemble training methods are not efficacious in\ninducing such diversity and thus ineffective on reaching robust ensemble. We\npropose DVERGE, which isolates the adversarial vulnerability in each sub-model\nby distilling non-robust features, and diversifies the adversarial\nvulnerability to induce diverse outputs against a transfer attack. The novel\ndiversity metric and training procedure enables DVERGE to achieve higher\nrobustness against transfer attacks comparing to previous ensemble methods, and\nenables the improved robustness when more sub-models are added to the ensemble.\nThe code of this work is available at https://github.com/zjysteven/DVERGE\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:57:35 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 16:35:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yang", "Huanrui", ""], ["Zhang", "Jingyang", ""], ["Dong", "Hongliang", ""], ["Inkawhich", "Nathan", ""], ["Gardner", "Andrew", ""], ["Touchet", "Andrew", ""], ["Wilkes", "Wesley", ""], ["Berry", "Heath", ""], ["Li", "Hai", ""]]}, {"id": "2009.14737", "submitter": "Keyu Tian", "authors": "Keyu Tian, Chen Lin, Ming Sun, Luping Zhou, Junjie Yan, Wanli Ouyang", "title": "Improving Auto-Augment via Augmentation-Wise Weight Sharing", "comments": "Accepted to NeurIPS 2020 (Poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress on automatically searching augmentation policies has\nboosted the performance substantially for various tasks. A key component of\nautomatic augmentation search is the evaluation process for a particular\naugmentation policy, which is utilized to return reward and usually runs\nthousands of times. A plain evaluation process, which includes full model\ntraining and validation, would be time-consuming. To achieve efficiency, many\nchoose to sacrifice evaluation reliability for speed. In this paper, we dive\ninto the dynamics of augmented training of the model. This inspires us to\ndesign a powerful and efficient proxy task based on the Augmentation-Wise\nWeight Sharing (AWS) to form a fast yet accurate evaluation process in an\nelegant way. Comprehensive analysis verifies the superiority of this approach\nin terms of effectiveness and efficiency. The augmentation policies found by\nour method achieve superior accuracies compared with existing auto-augmentation\nsearch methods. On CIFAR-10, we achieve a top-1 error rate of 1.24%, which is\ncurrently the best performing single model without extra training data. On\nImageNet, we get a top-1 error rate of 20.36% for ResNet-50, which leads to\n3.34% absolute error rate reduction over the baseline augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:23:12 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 15:12:47 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tian", "Keyu", ""], ["Lin", "Chen", ""], ["Sun", "Ming", ""], ["Zhou", "Luping", ""], ["Yan", "Junjie", ""], ["Ouyang", "Wanli", ""]]}, {"id": "2009.14738", "submitter": "Yulong Pei", "authors": "Yulong Pei, Tianjin Huang, Werner van Ipenburg, Mykola Pechenizkiy", "title": "ResGCN: Attention-based Deep Residual Modeling for Anomaly Detection on\n  Attributed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively detecting anomalous nodes in attributed networks is crucial for\nthe success of many real-world applications such as fraud and intrusion\ndetection. Existing approaches have difficulties with three major issues:\nsparsity and nonlinearity capturing, residual modeling, and network smoothing.\nWe propose Residual Graph Convolutional Network (ResGCN), an attention-based\ndeep residual modeling approach that can tackle these issues: modeling the\nattributed networks with GCN allows to capture the sparsity and nonlinearity;\nutilizing a deep neural network allows to directly learn residual from the\ninput, and a residual-based attention mechanism reduces the adverse effect from\nanomalous nodes and prevents over-smoothing. Extensive experiments on several\nreal-world attributed networks demonstrate the effectiveness of ResGCN in\ndetecting anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:24:51 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pei", "Yulong", ""], ["Huang", "Tianjin", ""], ["van Ipenburg", "Werner", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2009.14774", "submitter": "Gleb Novikov", "authors": "Tommaso d'Orsi, Gleb Novikov, David Steurer", "title": "Consistent regression when oblivious outliers overwhelm", "comments": "To appear in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a robust linear regression model $y=X\\beta^* + \\eta$, where an\nadversary oblivious to the design $X\\in \\mathbb{R}^{n\\times d}$ may choose\n$\\eta$ to corrupt all but an $\\alpha$ fraction of the observations $y$ in an\narbitrary way. Prior to our work, even for Gaussian $X$, no estimator for\n$\\beta^*$ was known to be consistent in this model except for quadratic sample\nsize $n \\gtrsim (d/\\alpha)^2$ or for logarithmic inlier fraction $\\alpha\\ge\n1/\\log n$. We show that consistent estimation is possible with nearly linear\nsample size and inverse-polynomial inlier fraction. Concretely, we show that\nthe Huber loss estimator is consistent for every sample size $n=\n\\omega(d/\\alpha^2)$ and achieves an error rate of $O(d/\\alpha^2n)^{1/2}$. Both\nbounds are optimal (up to constant factors). Our results extend to designs far\nbeyond the Gaussian case and only require the column span of $X$ to not contain\napproximately sparse vectors). (similar to the kind of assumption commonly made\nabout the kernel space for compressed sensing). We provide two technically\nsimilar proofs. One proof is phrased in terms of strong convexity, extending\nwork of [Tsakonas et al.'14], and particularly short. The other proof\nhighlights a connection between the Huber loss estimator and high-dimensional\nmedian computations. In the special case of Gaussian designs, this connection\nleads us to a strikingly simple algorithm based on computing coordinate-wise\nmedians that achieves optimal guarantees in nearly-linear time, and that can\nexploit sparsity of $\\beta^*$. The model studied here also captures\nheavy-tailed noise distributions that may not even have a first moment.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:21:34 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 17:20:11 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["d'Orsi", "Tommaso", ""], ["Novikov", "Gleb", ""], ["Steurer", "David", ""]]}, {"id": "2009.14786", "submitter": "Nicolas Gontier", "authors": "Nicolas Gontier and Koustuv Sinha and Siva Reddy and Christopher Pal", "title": "Measuring Systematic Generalization in Neural Proof Generation with\n  Transformers", "comments": "NeurIPS 2020; 17 pages; 9 figures; 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in understanding how well Transformer language models\n(TLMs) can perform reasoning tasks when trained on knowledge encoded in the\nform of natural language. We investigate their systematic generalization\nabilities on a logical reasoning task in natural language, which involves\nreasoning over relationships between entities grounded in first-order logical\nproofs. Specifically, we perform soft theorem-proving by leveraging TLMs to\ngenerate natural language proofs. We test the generated proofs for logical\nconsistency, along with the accuracy of the final inference. We observe\nlength-generalization issues when evaluated on longer-than-trained sequences.\nHowever, we observe TLMs improve their generalization performance after being\nexposed to longer, exhaustive proofs. In addition, we discover that TLMs are\nable to generalize better using backward-chaining proofs compared to their\nforward-chaining counterparts, while they find it easier to generate forward\nchaining proofs. We observe that models that are not trained to generate proofs\nare better at generalizing to problems based on longer proofs. This suggests\nthat Transformers have efficient internal reasoning strategies that are harder\nto interpret. These results highlight the systematic generalization behavior of\nTLMs in the context of logical reasoning, and we believe this work motivates\ndeeper inspection of their underlying reasoning strategies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:54:37 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:31:11 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gontier", "Nicolas", ""], ["Sinha", "Koustuv", ""], ["Reddy", "Siva", ""], ["Pal", "Christopher", ""]]}, {"id": "2009.14794", "submitter": "Xingyou Song", "authors": "Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou\n  Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz\n  Mohiuddin, Lukasz Kaiser, David Belanger, Lucy Colwell, Adrian Weller", "title": "Rethinking Attention with Performers", "comments": "Published as a conference paper + oral presentation at ICLR 2021. 38\n  pages. See\n  https://github.com/google-research/google-research/tree/master/protein_lm for\n  protein language model code, and\n  https://github.com/google-research/google-research/tree/master/performer for\n  Performer code. See\n  https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html\n  for Google AI Blog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Performers, Transformer architectures which can estimate regular\n(softmax) full-rank-attention Transformers with provable accuracy, but using\nonly linear (as opposed to quadratic) space and time complexity, without\nrelying on any priors such as sparsity or low-rankness. To approximate softmax\nattention-kernels, Performers use a novel Fast Attention Via positive\nOrthogonal Random features approach (FAVOR+), which may be of independent\ninterest for scalable kernel methods. FAVOR+ can be also used to efficiently\nmodel kernelizable attention mechanisms beyond softmax. This representational\npower is crucial to accurately compare softmax with other kernels for the first\ntime on large-scale tasks, beyond the reach of regular Transformers, and\ninvestigate optimal attention-kernels. Performers are linear architectures\nfully compatible with regular Transformers and with strong theoretical\nguarantees: unbiased or nearly-unbiased estimation of the attention matrix,\nuniform convergence and low estimation variance. We tested Performers on a rich\nset of tasks stretching from pixel-prediction through text models to protein\nsequence modeling. We demonstrate competitive results with other examined\nefficient sparse and dense attention methods, showcasing effectiveness of the\nnovel attention-learning paradigm leveraged by Performers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:09:09 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 21:40:24 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 16:26:47 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Likhosherstov", "Valerii", ""], ["Dohan", "David", ""], ["Song", "Xingyou", ""], ["Gane", "Andreea", ""], ["Sarlos", "Tamas", ""], ["Hawkins", "Peter", ""], ["Davis", "Jared", ""], ["Mohiuddin", "Afroz", ""], ["Kaiser", "Lukasz", ""], ["Belanger", "David", ""], ["Colwell", "Lucy", ""], ["Weller", "Adrian", ""]]}, {"id": "2009.14799", "submitter": "Carson Eisenach", "authors": "Carson Eisenach and Yagna Patel and Dhruv Madeka", "title": "MQTransformer: Multi-Horizon Forecasts with Context Dependent and\n  Feedback-Aware Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural forecasting have produced major improvements in\naccuracy for probabilistic demand prediction. In this work, we propose novel\nimprovements to the current state of the art by incorporating changes inspired\nby recent advances in Transformer architectures for Natural Language\nProcessing. We develop a novel decoder-encoder attention for context-alignment,\nimproving forecasting accuracy by allowing the network to study its own history\nbased on the context for which it is producing a forecast. We also present a\nnovel positional encoding that allows the neural network to learn\ncontext-dependent seasonality functions as well as arbitrary holiday distances.\nFinally we show that the current state of the art MQ-Forecaster (Wen et al.,\n2017) models display excess variability by failing to leverage previous errors\nin the forecast to improve accuracy. We propose a novel decoder-self attention\nscheme for forecasting that produces significant improvements in the excess\nvariation of the forecast.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:12:46 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 23:06:45 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 21:14:11 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Eisenach", "Carson", ""], ["Patel", "Yagna", ""], ["Madeka", "Dhruv", ""]]}, {"id": "2009.14820", "submitter": "Tanner Fiez", "authors": "Tanner Fiez, Lillian Ratliff", "title": "Gradient Descent-Ascent Provably Converges to Strict Local Minmax\n  Equilibria with a Finite Timescale Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role that a finite timescale separation parameter $\\tau$ has on\ngradient descent-ascent in two-player non-convex, non-concave zero-sum games\nwhere the learning rate of player 1 is denoted by $\\gamma_1$ and the learning\nrate of player 2 is defined to be $\\gamma_2=\\tau\\gamma_1$. Existing work\nanalyzing the role of timescale separation in gradient descent-ascent has\nprimarily focused on the edge cases of players sharing a learning rate ($\\tau\n=1$) and the maximizing player approximately converging between each update of\nthe minimizing player ($\\tau \\rightarrow \\infty$). For the parameter choice of\n$\\tau=1$, it is known that the learning dynamics are not guaranteed to converge\nto a game-theoretically meaningful equilibria in general. In contrast, Jin et\nal. (2020) showed that the stable critical points of gradient descent-ascent\ncoincide with the set of strict local minmax equilibria as\n$\\tau\\rightarrow\\infty$. In this work, we bridge the gap between past work by\nshowing there exists a finite timescale separation parameter $\\tau^{\\ast}$ such\nthat $x^{\\ast}$ is a stable critical point of gradient descent-ascent for all\n$\\tau \\in (\\tau^{\\ast}, \\infty)$ if and only if it is a strict local minmax\nequilibrium. Moreover, we provide an explicit construction for computing\n$\\tau^{\\ast}$ along with corresponding convergence rates and results under\ndeterministic and stochastic gradient feedback. The convergence results we\npresent are complemented by a non-convergence result: given a critical point\n$x^{\\ast}$ that is not a strict local minmax equilibrium, then there exists a\nfinite timescale separation $\\tau_0$ such that $x^{\\ast}$ is unstable for all\n$\\tau\\in (\\tau_0, \\infty)$. Finally, we empirically demonstrate on the CIFAR-10\nand CelebA datasets the significant impact timescale separation has on training\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:51:28 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Fiez", "Tanner", ""], ["Ratliff", "Lillian", ""]]}, {"id": "2009.14822", "submitter": "Ikhyun Cho", "authors": "Ikhyun Cho, U Kang", "title": "Pea-KD: Parameter-efficient and Accurate Knowledge Distillation on BERT", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we efficiently compress a model while maintaining its performance?\nKnowledge Distillation (KD) is one of the widely known methods for model\ncompression. In essence, KD trains a smaller student model based on a larger\nteacher model and tries to retain the teacher model's level of performance as\nmuch as possible. However, existing KD methods suffer from the following\nlimitations. First, since the student model is smaller in absolute size, it\ninherently lacks model capacity. Second, the absence of an initial guide for\nthe student model makes it difficult for the student to imitate the teacher\nmodel to its fullest. Conventional KD methods yield low performance due to\nthese limitations. In this paper, we propose Pea-KD (Parameter-efficient and\naccurate Knowledge Distillation), a novel approach to KD. Pea-KD consists of\ntwo main parts: Shuffled Parameter Sharing (SPS) and Pretraining with Teacher's\nPredictions (PTP). Using this combination, we are capable of alleviating the\nKD's limitations. SPS is a new parameter sharing method that increases the\nstudent model capacity. PTP is a KD-specialized initialization method, which\ncan act as a good initial guide for the student. When combined, this method\nyields a significant increase in student model's performance. Experiments\nconducted on BERT with different datasets and tasks show that the proposed\napproach improves the student model's performance by 4.4\\% on average in four\nGLUE tasks, outperforming existing KD baselines by significant margins.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:52:15 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 09:43:34 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Cho", "Ikhyun", ""], ["Kang", "U", ""]]}]