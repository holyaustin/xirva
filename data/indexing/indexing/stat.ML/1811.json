[{"id": "1811.00002", "submitter": "Rafael Valle", "authors": "Ryan Prenger, Rafael Valle, Bryan Catanzaro", "title": "WaveGlow: A Flow-based Generative Network for Speech Synthesis", "comments": "5 pages, 1 figure, 1 table, 13 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose WaveGlow: a flow-based network capable of generating\nhigh quality speech from mel-spectrograms. WaveGlow combines insights from Glow\nand WaveNet in order to provide fast, efficient and high-quality audio\nsynthesis, without the need for auto-regression. WaveGlow is implemented using\nonly a single network, trained using only a single cost function: maximizing\nthe likelihood of the training data, which makes the training procedure simple\nand stable. Our PyTorch implementation produces audio samples at a rate of more\nthan 500 kHz on an NVIDIA V100 GPU. Mean Opinion Scores show that it delivers\naudio quality as good as the best publicly available WaveNet implementation.\nAll code will be made publicly available online.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 03:22:25 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Prenger", "Ryan", ""], ["Valle", "Rafael", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1811.00003", "submitter": "Bhalaji Nagarajan Mr", "authors": "Bhalaji Nagarajan, V Ramana Murthy Oruganti", "title": "Deep Net Features for Complex Emotion Recognition", "comments": "Conflict of interest", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the influence of different acoustic features,\naudio-events based features and automatic speech translation based lexical\nfeatures in complex emotion recognition such as curiosity. Pretrained networks,\nnamely, AudioSet Net, VoxCeleb Net and Deep Speech Net trained extensively for\ndifferent speech based applications are studied for this objective. Information\nfrom deep layers of these networks are considered as descriptors and encoded\ninto feature vectors. Experimental results on the EmoReact dataset consisting\nof 8 complex emotions show the effectiveness, yielding highest F1 score of 0.85\nas against the baseline of 0.69 in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 04:52:18 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 04:46:09 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Nagarajan", "Bhalaji", ""], ["Oruganti", "V Ramana Murthy", ""]]}, {"id": "1811.00006", "submitter": "Kevin Kilgour", "authors": "David B. Ramsay, Kevin Kilgour, Dominik Roblek and Matthew Sharifi", "title": "Low-Dimensional Bottleneck Features for On-Device Continuous Speech\n  Recognition", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low power digital signal processors (DSPs) typically have a very limited\namount of memory in which to cache data. In this paper we develop efficient\nbottleneck feature (BNF) extractors that can be run on a DSP, and retrain a\nbaseline large-vocabulary continuous speech recognition (LVCSR) system to use\nthese BNFs with only a minimal loss of accuracy. The small BNFs allow the DSP\nchip to cache more audio features while the main application processor is\nsuspended, thereby reducing the overall battery usage. Our presented system is\nable to reduce the footprint of standard, fixed point DSP spectral features by\na factor of 10 without any loss in word error rate (WER) and by a factor of 64\nwith only a 5.8% relative increase in WER.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:20:24 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Ramsay", "David B.", ""], ["Kilgour", "Kevin", ""], ["Roblek", "Dominik", ""], ["Sharifi", "Matthew", ""]]}, {"id": "1811.00007", "submitter": "Stefan Bauer", "authors": "Raphael Suter, {\\DJ}or{\\dj}e Miladinovi\\'c, Bernhard Sch\\\"olkopf,\n  Stefan Bauer", "title": "Robustly Disentangled Causal Mechanisms: Validating Deep Representations\n  for Interventional Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn disentangled representations that split underlying\nsources of variation in high dimensional, unstructured data is important for\ndata efficient and robust use of neural networks. While various approaches\naiming towards this goal have been proposed in recent times, a commonly\naccepted definition and validation procedure is missing. We provide a causal\nperspective on representation learning which covers disentanglement and domain\nshift robustness as special cases. Our causal framework allows us to introduce\na new metric for the quantitative evaluation of deep latent variable models. We\nshow how this metric can be estimated from labeled observational data and\nfurther provide an efficient estimation algorithm that scales linearly in the\ndataset size.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:42:01 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 18:29:03 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Suter", "Raphael", ""], ["Miladinovi\u0107", "\u0110or\u0111e", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "1811.00052", "submitter": "Shrey Gadiya", "authors": "Shrey Gadiya, Deepak Anand and Amit Sethi", "title": "Some New Layer Architectures for Graph CNN", "comments": "5 pages, 1 figure, submitted to ICASSP 2019 Special Session on\n  Learning Methods in Complex and Hypercomplex Domains, Brighton, United\n  Kingdom, May 12-17, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While convolutional neural networks (CNNs) have recently made great strides\nin supervised classification of data structured on a grid (e.g. images composed\nof pixel grids), in several interesting datasets, the relations between\nfeatures can be better represented as a general graph instead of a regular\ngrid. Although recent algorithms that adapt CNNs to graphs have shown promising\nresults, they mostly neglect learning explicit operations for edge features\nwhile focusing on vertex features alone. We propose new formulations for\nconvolutional, pooling, and fully connected layers for neural networks that\nmake more comprehensive use of the information available in multi-dimensional\ngraphs. Using these layers led to an improvement in classification accuracy\nover the state-of-the-art methods on benchmark graph datasets.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 18:24:58 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Gadiya", "Shrey", ""], ["Anand", "Deepak", ""], ["Sethi", "Amit", ""]]}, {"id": "1811.00062", "submitter": "Niek Tax", "authors": "Niek Tax, Irene Teinemaa, Sebastiaan J. van Zelst", "title": "An Interdisciplinary Comparison of Sequence Modeling Methods for\n  Next-Element Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data of sequential nature arise in many application domains in forms of, e.g.\ntextual data, DNA sequences, and software execution traces. Different research\ndisciplines have developed methods to learn sequence models from such datasets:\n(i) in the machine learning field methods such as (hidden) Markov models and\nrecurrent neural networks have been developed and successfully applied to a\nwide-range of tasks, (ii) in process mining process discovery techniques aim to\ngenerate human-interpretable descriptive models, and (iii) in the grammar\ninference field the focus is on finding descriptive models in the form of\nformal grammars. Despite their different focuses, these fields share a common\ngoal - learning a model that accurately describes the behavior in the\nunderlying data. Those sequence models are generative, i.e, they can predict\nwhat elements are likely to occur after a given unfinished sequence. So far,\nthese fields have developed mainly in isolation from each other and no\ncomparison exists. This paper presents an interdisciplinary experimental\nevaluation that compares sequence modeling techniques on the task of\nnext-element prediction on four real-life sequence datasets. The results\nindicate that machine learning techniques that generally have no aim at\ninterpretability in terms of accuracy outperform techniques from the process\nmining and grammar inference fields that aim to yield interpretable models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 18:54:27 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Tax", "Niek", ""], ["Teinemaa", "Irene", ""], ["van Zelst", "Sebastiaan J.", ""]]}, {"id": "1811.00073", "submitter": "Prashnna Gyawali", "authors": "Prashnna K Gyawali, Cameron Knight, Sandesh Ghimire, B. Milan Horacek,\n  John L. Sapp and Linwei Wang", "title": "Deep Generative Model with Beta Bernoulli Process for Modeling and\n  Learning Confounding Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While deep representation learning has become increasingly capable of\nseparating task-relevant representations from other confounding factors in the\ndata, two significant challenges remain. First, there is often an unknown and\npotentially infinite number of confounding factors coinciding in the data.\nSecond, not all of these factors are readily observable. In this paper, we\npresent a deep conditional generative model that learns to disentangle a\ntask-relevant representation from an unknown number of confounding factors that\nmay grow infinitely. This is achieved by marrying the representational power of\ndeep generative models with Bayesian non-parametric factor models, where a\nsupervised deterministic encoder learns task-related representation and a\nprobabilistic encoder with an Indian Buffet Process (IBP) learns the unknown\nnumber of unobservable confounding factors. We tested the presented model in\ntwo datasets: a handwritten digit dataset (MNIST) augmented with colored digits\nand a clinical ECG dataset with significant inter-subject variations and\naugmented with signal artifacts. These diverse data sets highlighted the\nability of the presented model to grow with the complexity of the data and\nidentify the absence or presence of unobserved confounding factors.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 19:19:49 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 20:02:28 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 20:36:21 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Gyawali", "Prashnna K", ""], ["Knight", "Cameron", ""], ["Ghimire", "Sandesh", ""], ["Horacek", "B. Milan", ""], ["Sapp", "John L.", ""], ["Wang", "Linwei", ""]]}, {"id": "1811.00075", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall and Hoang Anh Dau and Jason Lines and Michael Flynn\n  and James Large and Aaron Bostrom and Paul Southam and Eamonn Keogh", "title": "The UEA multivariate time series classification archive, 2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2002, the UCR time series classification archive was first released with\nsixteen datasets. It gradually expanded, until 2015 when it increased in size\nfrom 45 datasets to 85 datasets. In October 2018 more datasets were added,\nbringing the total to 128. The new archive contains a wide range of problems,\nincluding variable length series, but it still only contains univariate time\nseries classification problems. One of the motivations for introducing the\narchive was to encourage researchers to perform a more rigorous evaluation of\nnewly proposed time series classification (TSC) algorithms. It has worked: most\nrecent research into TSC uses all 85 datasets to evaluate algorithmic advances.\nResearch into multivariate time series classification, where more than one\nseries are associated with each class label, is in a position where univariate\nTSC research was a decade ago. Algorithms are evaluated using very few datasets\nand claims of improvement are not based on statistical comparisons. We aim to\naddress this problem by forming the first iteration of the MTSC archive, to be\nhosted at the website www.timeseriesclassification.com. Like the univariate\narchive, this formulation was a collaborative effort between researchers at the\nUniversity of East Anglia (UEA) and the University of California, Riverside\n(UCR). The 2018 vintage consists of 30 datasets with a wide range of cases,\ndimensions and series lengths. For this first iteration of the archive we\nformat all data to be of equal length, include no series with missing data and\nprovide train/test splits.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 19:24:20 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Bagnall", "Anthony", ""], ["Dau", "Hoang Anh", ""], ["Lines", "Jason", ""], ["Flynn", "Michael", ""], ["Large", "James", ""], ["Bostrom", "Aaron", ""], ["Southam", "Paul", ""], ["Keogh", "Eamonn", ""]]}, {"id": "1811.00080", "submitter": "Xin Li", "authors": "Xin Li, Ondrej E. Dyck, Mark P. Oxley, Andrew R. Lupini, Leland\n  McInnes, John Healy, Stephen Jesse, Sergei V. Kalinin", "title": "Manifold Learning of Four-dimensional Scanning Transmission Electron\n  Microscopy", "comments": null, "journal-ref": "npj Computational Materials volume 5, Article number: 5 (2019)", "doi": "10.1038/s41524-018-0139-y", "report-no": null, "categories": "eess.IV cond-mat.mtrl-sci physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Four-dimensional scanning transmission electron microscopy (4D-STEM) of local\natomic diffraction patterns is emerging as a powerful technique for probing\nintricate details of atomic structure and atomic electric fields. However,\nefficient processing and interpretation of large volumes of data remain\nchallenging, especially for two-dimensional or light materials because the\ndiffraction signal recorded on the pixelated arrays is weak. Here we employ\ndata-driven manifold leaning approaches for straightforward visualization and\nexploration analysis of the 4D-STEM datasets, distilling real-space neighboring\neffects on atomically resolved deflection patterns from single-layer graphene,\nwith single dopant atoms, as recorded on a pixelated detector. These extracted\npatterns relate to both individual atom sites and sublattice structures,\neffectively discriminating single dopant anomalies via multi-mode views. We\nbelieve manifold learning analysis will accelerate physics discoveries coupled\nbetween data-rich imaging mechanisms and materials such as ferroelectric,\ntopological spin and van der Waals heterostructures.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:55:11 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 17:42:41 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 01:49:29 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Li", "Xin", ""], ["Dyck", "Ondrej E.", ""], ["Oxley", "Mark P.", ""], ["Lupini", "Andrew R.", ""], ["McInnes", "Leland", ""], ["Healy", "John", ""], ["Jesse", "Stephen", ""], ["Kalinin", "Sergei V.", ""]]}, {"id": "1811.00097", "submitter": "Paul McNicholas", "authors": "Sharon M. McNicholas, Paul D. McNicholas and Daniel A. Ashlock", "title": "An Evolutionary Algorithm with Crossover and Mutation for Model-Based\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An evolutionary algorithm (EA) is developed as an alternative to the EM\nalgorithm for parameter estimation in model-based clustering. This EA\nfacilitates a different search of the fitness landscape, i.e., the likelihood\nsurface, utilizing both crossover and mutation. Furthermore, this EA represents\nan efficient approach to \"hard\" model-based clustering and so it can be viewed\nas a sort of generalization of the k-means algorithm, which is itself\nequivalent to a restricted Gaussian mixture model. The EA is illustrated on\nseveral datasets, and its performance is compared to other hard clustering\napproaches and model-based clustering via the EM algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 20:14:10 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:28:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["McNicholas", "Sharon M.", ""], ["McNicholas", "Paul D.", ""], ["Ashlock", "Daniel A.", ""]]}, {"id": "1811.00102", "submitter": "Mayank Baranwal", "authors": "Amber Srivastava, Mayank Baranwal and Srinivasa Salapaka", "title": "On the Persistence of Clustering Solutions and True Number of Clusters\n  in a Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically clustering algorithms provide clustering solutions with\nprespecified number of clusters. The lack of a priori knowledge on the true\nnumber of underlying clusters in the dataset makes it important to have a\nmetric to compare the clustering solutions with different number of clusters.\nThis article quantifies a notion of persistence of clustering solutions that\nenables comparing solutions with different number of clusters. The persistence\nrelates to the range of data-resolution scales over which a clustering solution\npersists; it is quantified in terms of the maximum over two-norms of all the\nassociated cluster-covariance matrices. Thus we associate a persistence value\nfor each element in a set of clustering solutions with different number of\nclusters. We show that the datasets where natural clusters are a priori known,\nthe clustering solutions that identify the natural clusters are most persistent\n- in this way, this notion can be used to identify solutions with true number\nof clusters. Detailed experiments on a variety of standard and synthetic\ndatasets demonstrate that the proposed persistence-based indicator outperforms\nthe existing approaches, such as, gap-statistic method, $X$-means, $G$-means,\n$PG$-means, dip-means algorithms and information-theoretic method, in\naccurately identifying the clustering solutions with true number of clusters.\nInterestingly, our method can be explained in terms of the phase-transition\nphenomenon in the deterministic annealing algorithm, where the number of\ndistinct cluster centers changes (bifurcates) with respect to an annealing\nparameter.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 20:27:16 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 20:45:25 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Srivastava", "Amber", ""], ["Baranwal", "Mayank", ""], ["Salapaka", "Srinivasa", ""]]}, {"id": "1811.00103", "submitter": "Samira Samadi", "authors": "Samira Samadi, Uthaipon Tantipongpipat, Jamie Morgenstern, Mohit\n  Singh, Santosh Vempala", "title": "The Price of Fair PCA: One Extra Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether the standard dimensionality reduction technique of PCA\ninadvertently produces data representations with different fidelity for two\ndifferent populations. We show on several real-world data sets, PCA has higher\nreconstruction error on population A than on B (for example, women versus men\nor lower- versus higher-educated individuals). This can happen even when the\ndata set has a similar number of samples from A and B. This motivates our study\nof dimensionality reduction techniques which maintain similar fidelity for A\nand B. We define the notion of Fair PCA and give a polynomial-time algorithm\nfor finding a low dimensional representation of the data which is\nnearly-optimal with respect to this measure. Finally, we show on real-world\ndata sets that our algorithm can be used to efficiently generate a fair low\ndimensional representation of the data.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 20:32:00 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Samadi", "Samira", ""], ["Tantipongpipat", "Uthaipon", ""], ["Morgenstern", "Jamie", ""], ["Singh", "Mohit", ""], ["Vempala", "Santosh", ""]]}, {"id": "1811.00112", "submitter": "Daniel S\\'aez Trigueros", "authors": "Daniel S\\'aez Trigueros, Li Meng, Margaret Hartnett", "title": "Generating Photo-Realistic Training Data to Improve Face Recognition\n  Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the feasibility of using synthetic data to\naugment face datasets. In particular, we propose a novel generative adversarial\nnetwork (GAN) that can disentangle identity-related attributes from\nnon-identity-related attributes. This is done by training an embedding network\nthat maps discrete identity labels to an identity latent space that follows a\nsimple prior distribution, and training a GAN conditioned on samples from that\ndistribution. Our proposed GAN allows us to augment face datasets by generating\nboth synthetic images of subjects in the training set and synthetic images of\nnew subjects not in the training set. By using recent advances in GAN training,\nwe show that the synthetic images generated by our model are photo-realistic,\nand that training with augmented datasets can indeed increase the accuracy of\nface recognition models as compared with models trained with real images alone.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 20:53:25 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Trigueros", "Daniel S\u00e1ez", ""], ["Meng", "Li", ""], ["Hartnett", "Margaret", ""]]}, {"id": "1811.00115", "submitter": "Yik Chau Lui", "authors": "Kry Yik Chau Lui, Gavin Weiguang Ding, Ruitong Huang, Robert J. McCann", "title": "Dimensionality Reduction has Quantifiable Imperfections: Two Geometric\n  Bounds", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018),\n  Montreal, Canada", "journal-ref": "Neural Information Processing Systems (NIPS 2018)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate Dimensionality reduction (DR) maps in an\ninformation retrieval setting from a quantitative topology point of view. In\nparticular, we show that no DR maps can achieve perfect precision and perfect\nrecall simultaneously. Thus a continuous DR map must have imperfect precision.\nWe further prove an upper bound on the precision of Lipschitz continuous DR\nmaps. While precision is a natural measure in an information retrieval setting,\nit does not measure `how' wrong the retrieved data is. We therefore propose a\nnew measure based on Wasserstein distance that comes with similar theoretical\nguarantee. A key technical step in our proofs is a particular optimization\nproblem of the $L_2$-Wasserstein distance over a constrained set of\ndistributions. We provide a complete solution to this optimization problem,\nwhich can be of independent interest on the technical side.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 20:56:14 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Lui", "Kry Yik Chau", ""], ["Ding", "Gavin Weiguang", ""], ["Huang", "Ruitong", ""], ["McCann", "Robert J.", ""]]}, {"id": "1811.00121", "submitter": "George Kesidis", "authors": "David J. Miller, Xinyi Hu, Zhen Xiang, and George Kesidis", "title": "A Mixture Model Based Defense for Data Poisoning Attacks Against Naive\n  Bayes Spam Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Naive Bayes spam filters are highly susceptible to data poisoning attacks.\nHere, known spam sources/blacklisted IPs exploit the fact that their received\nemails will be treated as (ground truth) labeled spam examples, and used for\nclassifier training (or re-training). The attacking source thus generates\nemails that will skew the spam model, potentially resulting in great\ndegradation in classifier accuracy. Such attacks are successful mainly because\nof the poor representation power of the naive Bayes (NB) model, with only a\nsingle (component) density to represent spam (plus a possible attack). We\npropose a defense based on the use of a mixture of NB models. We demonstrate\nthat the learned mixture almost completely isolates the attack in a second NB\ncomponent, with the original spam component essentially unchanged by the\nattack. Our approach addresses both the scenario where the classifier is being\nre-trained in light of new data and, significantly, the more challenging\nscenario where the attack is embedded in the original spam training set. Even\nfor weak attack strengths, BIC-based model order selection chooses a\ntwo-component solution, which invokes the mixture-based defense. Promising\nresults are presented on the TREC 2005 spam corpus.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 21:04:43 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Miller", "David J.", ""], ["Hu", "Xinyi", ""], ["Xiang", "Zhen", ""], ["Kesidis", "George", ""]]}, {"id": "1811.00123", "submitter": "John Herr", "authors": "John E. Herr, Kevin Koh, Kun Yao, and John Parkhill", "title": "Compressing physical properties of atomic species for improving\n  predictive chemistry", "comments": "6 pages, 5 figures", "journal-ref": "J. Chem. Phys. 151 (2018) 084103", "doi": "10.1063/1.5108803", "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The answers to many unsolved problems lie in the intractable chemical space\nof molecules and materials. Machine learning techniques are rapidly growing in\npopularity as a way to compress and explore chemical space efficiently. One of\nthe most important aspects of machine learning techniques is representation\nthrough the feature vector, which should contain the most important descriptors\nnecessary to make accurate predictions, not least of which is the atomic\nspecies in the molecule or material. In this work we introduce a compressed\nrepresentation of physical properties for atomic species we call the elemental\nmodes. The elemental modes provide an excellent representation by capturing\nmany of the nuances of the periodic table and the similarity of atomic species.\nWe apply the elemental modes to several different tasks for machine learning\nalgorithms and show that they enable us to make improvements to these tasks\neven beyond simply achieving higher accuracy predictions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 21:11:40 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Herr", "John E.", ""], ["Koh", "Kevin", ""], ["Yao", "Kun", ""], ["Parkhill", "John", ""]]}, {"id": "1811.00128", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Evan Cater, Dipendra Misra, Michael L. Littman", "title": "Towards a Simple Approach to Multi-step Model-based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When environmental interaction is expensive, model-based reinforcement\nlearning offers a solution by planning ahead and avoiding costly mistakes.\nModel-based agents typically learn a single-step transition model. In this\npaper, we propose a multi-step model that predicts the outcome of an action\nsequence with variable length. We show that this model is easy to learn, and\nthat the model can make policy-conditional predictions. We report preliminary\nresults that show a clear advantage for the multi-step model compared to its\none-step counterpart.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 21:31:59 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Asadi", "Kavosh", ""], ["Cater", "Evan", ""], ["Misra", "Dipendra", ""], ["Littman", "Michael L.", ""]]}, {"id": "1811.00145", "submitter": "Aman Sinha", "authors": "Matthew O'Kelly, Aman Sinha, Hongseok Namkoong, John Duchi, Russ\n  Tedrake", "title": "Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent developments in autonomous vehicle (AV) technology highlight\nsubstantial progress, we lack tools for rigorous and scalable testing.\nReal-world testing, the $\\textit{de facto}$ evaluation environment, places the\npublic in danger, and, due to the rare nature of accidents, will require\nbillions of miles in order to statistically validate performance claims. We\nimplement a simulation framework that can test an entire modern autonomous\ndriving system, including, in particular, systems that employ deep-learning\nperception and control algorithms. Using adaptive importance-sampling methods\nto accelerate rare-event probability evaluation, we estimate the probability of\nan accident under a base distribution governing standard traffic behavior. We\ndemonstrate our framework on a highway scenario, accelerating system evaluation\nby $2$-$20$ times over naive Monte Carlo sampling methods and $10$-$300\n\\mathsf{P}$ times (where $\\mathsf{P}$ is the number of processors) over\nreal-world testing.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 22:47:22 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 05:32:44 GMT"}, {"version": "v3", "created": "Sat, 12 Jan 2019 19:27:45 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["O'Kelly", "Matthew", ""], ["Sinha", "Aman", ""], ["Namkoong", "Hongseok", ""], ["Duchi", "John", ""], ["Tedrake", "Russ", ""]]}, {"id": "1811.00148", "submitter": "Hongyang Zhang", "authors": "Hongyang Zhang, Vatsal Sharan, Moses Charikar, Yingyu Liang", "title": "Recovery Guarantees for Quadratic Tensors with Limited Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the tensor completion problem of predicting the missing entries\nof a tensor. The commonly used CP model has a triple product form, but an\nalternate family of quadratic models which are the sum of pairwise products\ninstead of a triple product have emerged from applications such as\nrecommendation systems. Non-convex methods are the method of choice for\nlearning quadratic models, and this work examines their sample complexity and\nerror guarantee. Our main result is that with the number of samples being only\nlinear in the dimension, all local minima of the mean squared error objective\nare global minima and recover the original tensor accurately. The techniques\nlead to simple proofs showing that convex relaxation can recover quadratic\ntensors provided with linear number of samples. We substantiate our theoretical\nresults with experiments on synthetic and real-world data, showing that\nquadratic models have better performance than CP models in scenarios where\nthere are limited amount of observations available.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 23:05:22 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Zhang", "Hongyang", ""], ["Sharan", "Vatsal", ""], ["Charikar", "Moses", ""], ["Liang", "Yingyu", ""]]}, {"id": "1811.00152", "submitter": "Hamid Eghbal-zadeh", "authors": "Hamid Eghbal-zadeh, Werner Zellinger, Gerhard Widmer", "title": "Mixture Density Generative Adversarial Networks", "comments": "Accepted at the third workshop on Bayesian Deep Learning (NeurIPS\n  2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks have surprising ability for generating sharp\nand realistic images, though they are known to suffer from the so-called mode\ncollapse problem. In this paper, we propose a new GAN variant called Mixture\nDensity GAN that while being capable of generating high-quality images,\novercomes this problem by encouraging the Discriminator to form clusters in its\nembedding space, which in turn leads the Generator to exploit these and\ndiscover different modes in the data. This is achieved by positioning Gaussian\ndensity functions in the corners of a simplex, using the resulting Gaussian\nmixture as a likelihood function over discriminator embeddings, and formulating\nan objective function for GAN training that is based on these likelihoods. We\ndemonstrate empirically (1) the quality of the generated images in Mixture\nDensity GAN and their strong similarity to real images, as measured by the\nFr\\'echet Inception Distance (FID), which compares very favourably with\nstate-of-the-art methods, and (2) the ability to avoid mode collapse and\ndiscover all data modes.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 23:21:21 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 16:50:02 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Eghbal-zadeh", "Hamid", ""], ["Zellinger", "Werner", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1811.00155", "submitter": "Avner May", "authors": "Jian Zhang, Avner May, Tri Dao, Christopher R\\'e", "title": "Low-Precision Random Fourier Features for Memory-Constrained Kernel\n  Approximation", "comments": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how to train kernel approximation methods that generalize well\nunder a memory budget. Building on recent theoretical work, we define a measure\nof kernel approximation error which we find to be more predictive of the\nempirical generalization performance of kernel approximation methods than\nconventional metrics. An important consequence of this definition is that a\nkernel approximation matrix must be high rank to attain close approximation.\nBecause storing a high-rank approximation is memory intensive, we propose using\na low-precision quantization of random Fourier features (LP-RFFs) to build a\nhigh-rank approximation under a memory budget. Theoretically, we show\nquantization has a negligible effect on generalization performance in important\nsettings. Empirically, we demonstrate across four benchmark datasets that\nLP-RFFs can match the performance of full-precision RFFs and the Nystr\\\"{o}m\nmethod, with 3x-10x and 50x-460x less memory, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 23:24:51 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 05:50:12 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Zhang", "Jian", ""], ["May", "Avner", ""], ["Dao", "Tri", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1811.00159", "submitter": "Gaurush Hiranandani", "authors": "Gaurush Hiranandani, Raghav Somani, Oluwasanmi Koyejo, Sreangsu\n  Acharyya", "title": "Clustered Monotone Transforms for Rating Factorization", "comments": "The first two authors contributed equally to the paper. The paper to\n  appear in WSDM 2019", "journal-ref": null, "doi": "10.1145/3289600.3291005", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting low-rank structure of the user-item rating matrix has been the\ncrux of many recommendation engines. However, existing recommendation engines\nforce raters with heterogeneous behavior profiles to map their intrinsic rating\nscales to a common rating scale (e.g. 1-5). This non-linear transformation of\nthe rating scale shatters the low-rank structure of the rating matrix,\ntherefore resulting in a poor fit and consequentially, poor recommendations. In\nthis paper, we propose Clustered Monotone Transforms for Rating Factorization\n(CMTRF), a novel approach to perform regression up to unknown monotonic\ntransforms over unknown population segments. Essentially, for recommendation\nsystems, the technique searches for monotonic transformations of the rating\nscales resulting in a better fit. This is combined with an underlying matrix\nfactorization regression model that couples the user-wise ratings to exploit\nshared low dimensional structure. The rating scale transformations can be\ngenerated for each user, for a cluster of users, or for all the users at once,\nforming the basis of three simple and efficient algorithms proposed in this\npaper, all of which alternate between transformation of the rating scales and\nmatrix factorization regression. Despite the non-convexity, CMTRF is\ntheoretically shown to recover a unique solution under mild conditions.\nExperimental results on two synthetic and seven real-world datasets show that\nCMTRF outperforms other state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 23:53:24 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Hiranandani", "Gaurush", ""], ["Somani", "Raghav", ""], ["Koyejo", "Oluwasanmi", ""], ["Acharyya", "Sreangsu", ""]]}, {"id": "1811.00170", "submitter": "Charalampos Patrikakis", "authors": "Panagiotis Kasnesis, Charalampos Z. Patrikakis, Iakovos S. Venieris", "title": "PerceptionNet: A Deep Convolutional Neural Network for Late Sensor\n  Fusion", "comments": "This article has been accepted for publication in the proceedings of\n  Intelligent Systems Conference (IntelliSys) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human Activity Recognition (HAR) based on motion sensors has drawn a lot of\nattention over the last few years, since perceiving the human status enables\ncontext-aware applications to adapt their services on users' needs. However,\nmotion sensor fusion and feature extraction have not reached their full\npotentials, remaining still an open issue. In this paper, we introduce\nPerceptionNet, a deep Convolutional Neural Network (CNN) that applies a late 2D\nconvolution to multimodal time-series sensor data, in order to extract\nautomatically efficient features for HAR. We evaluate our approach on two\npublic available HAR datasets to demonstrate that the proposed model fuses\neffectively multimodal sensors and improves the performance of HAR. In\nparticular, PerceptionNet surpasses the performance of state-of-the-art HAR\nmethods based on: (i) features extracted from humans, (ii) deep CNNs exploiting\nearly fusion approaches, and (iii) Long Short-Term Memory (LSTM), by an average\naccuracy of more than 3%.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 00:29:16 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Kasnesis", "Panagiotis", ""], ["Patrikakis", "Charalampos Z.", ""], ["Venieris", "Iakovos S.", ""]]}, {"id": "1811.00178", "submitter": "Anuj Sharma Dr", "authors": "Charanjeet, Anuj Sharma", "title": "Online learning using multiple times weight updating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning makes sequence of decisions with partial data arrival where\nnext movement of data is unknown. In this paper, we have presented a new\ntechnique as multiple times weight updating that update the weight iteratively\nforsame instance. The proposed technique analyzed with popular state-of-art\nalgorithms from literature and experimented using established tool. The results\nindicates that mistake rate reduces to zero or close to zero for various\ndatasets and algorithms. The overhead running cost is not too expensive and\nachieving mistake rate close to zero further strengthen the proposed technique.\nThe present work include bound nature of weight updating for single instance\nand achieve optimal weight value. This proposed work could be extended to big\ndatasets problems to reduce mistake rate in online learning environment. Also,\nthe proposed technique could be helpful to meet real life challenges.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 12:02:46 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 12:49:17 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Charanjeet", "", ""], ["Sharma", "Anuj", ""]]}, {"id": "1811.00181", "submitter": "Jayaraman J. Thiagarajan", "authors": "Uday Shankar Shanthamallu, Jayaraman J. Thiagarajan and Andreas\n  Spanias", "title": "A Regularized Attention Mechanism for Graph Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models that can exploit the inherent structure in data have\ngained prominence. In particular, there is a surge in deep learning solutions\nfor graph-structured data, due to its wide-spread applicability in several\nfields. Graph attention networks (GAT), a recent addition to the broad class of\nfeature learning models in graphs, utilizes the attention mechanism to\nefficiently learn continuous vector representations for semi-supervised\nlearning problems. In this paper, we perform a detailed analysis of GAT models,\nand present interesting insights into their behavior. In particular, we show\nthat the models are vulnerable to heterogeneous rogue nodes and hence propose\nnovel regularization strategies to improve the robustness of GAT models. Using\nbenchmark datasets, we demonstrate performance improvements on semi-supervised\nlearning, using the proposed robust variant of GAT.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 01:45:31 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:57:24 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Shanthamallu", "Uday Shankar", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Spanias", "Andreas", ""]]}, {"id": "1811.00183", "submitter": "Jayaraman J. Thiagarajan", "authors": "Vivek Sivaraman Narayanaswamy, Jayaraman J. Thiagarajan, Huan Song and\n  Andreas Spanias", "title": "Designing an Effective Metric Learning Pipeline for Speaker Diarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art speaker diarization systems utilize knowledge from external\ndata, in the form of a pre-trained distance metric, to effectively determine\nrelative speaker identities to unseen data. However, much of recent focus has\nbeen on choosing the appropriate feature extractor, ranging from pre-trained\n$i-$vectors to representations learned via different sequence modeling\narchitectures (e.g. 1D-CNNs, LSTMs, attention models), while adopting\noff-the-shelf metric learning solutions. In this paper, we argue that,\nregardless of the feature extractor, it is crucial to carefully design a metric\nlearning pipeline, namely the loss function, the sampling strategy and the\ndiscrimnative margin parameter, for building robust diarization systems.\nFurthermore, we propose to adopt a fine-grained validation process to obtain a\ncomprehensive evaluation of the generalization power of metric learning\npipelines. To this end, we measure diarization performance across different\nlanguage speakers, and variations in the number of speakers in a recording.\nUsing empirical studies, we provide interesting insights into the effectiveness\nof different design choices and make recommendations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 01:51:17 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Narayanaswamy", "Vivek Sivaraman", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Song", "Huan", ""], ["Spanias", "Andreas", ""]]}, {"id": "1811.00200", "submitter": "Christopher Mohri", "authors": "Christopher Mohri", "title": "Online Learning Algorithms for Statistical Arbitrage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical arbitrage is a class of financial trading strategies using mean\nreversion models. The corresponding techniques rely on a number of assumptions\nwhich may not hold for general non-stationary stochastic processes. This paper\npresents an alternative technique for statistical arbitrage based on online\nlearning which does not require such assumptions and which benefits from strong\nlearning guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:12:26 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Mohri", "Christopher", ""]]}, {"id": "1811.00208", "submitter": "Xu Chu", "authors": "Xu Chu, Yang Lin, Jingyue Gao, Jiangtao Wang, Yasha Wang, Leye Wang", "title": "Multi-Label Robust Factorization Autoencoder and its Application in\n  Predicting Drug-Drug Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug-drug interactions (DDIs) are a major cause of preventable\nhospitalizations and deaths. Predicting the occurrence of DDIs helps drug\nsafety professionals allocate investigative resources and take appropriate\nregulatory action promptly. Traditional DDI prediction methods predict DDIs\nbased on the similarity between drugs. Recently, researchers revealed that\npredictive performance can be improved by better modeling the interactions\nbetween drug pairs with bilinear forms. However, the shallow models leveraging\nbilinear forms suffer from limitations on capturing complicated nonlinear\ninteractions between drug pairs. To this end, we propose Multi-Label Robust\nFactorization Autoencoder (abbreviated to MuLFA) for DDI prediction, which\nlearns a representation of interactions between drug pairs and has the\ncapability of characterizing complicated nonlinear interactions more precisely.\nMoreover, a novel loss called CuXCov is designed to effectively learn the\nparameters of MuLFA. Furthermore, the decoder is able to generate high-risk\nchemical structures of drug pairs for specific DDIs, assisting pharmacists to\nbetter understand the relationship between drug chemistry and DDI. Experimental\nresults on real-world datasets demonstrate that MuLFA consistently outperforms\nstate-of-the-art methods; particularly, it increases 21:3% predictive\nperformance compared to the best baseline for top 50 frequent DDIs.We also\nillustrate various case studies to demonstrate the efficacy of the chemical\nstructures generated by MuLFA in DDI diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:50:45 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Chu", "Xu", ""], ["Lin", "Yang", ""], ["Gao", "Jingyue", ""], ["Wang", "Jiangtao", ""], ["Wang", "Yasha", ""], ["Wang", "Leye", ""]]}, {"id": "1811.00210", "submitter": "Jie Chen", "authors": "Tengfei Ma, Patrick Ferber, Siyu Huo, Jie Chen, Michael Katz", "title": "Online Planner Selection with Graph Neural Networks and Adaptive\n  Scheduling", "comments": "AAAI 2020. Code is released at\n  https://github.com/matenure/GNN_planner. Data set is released at\n  https://github.com/IBM/IPC-graph-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated planning is one of the foundational areas of AI. Since no single\nplanner can work well for all tasks and domains, portfolio-based techniques\nhave become increasingly popular in recent years. In particular, deep learning\nemerges as a promising methodology for online planner selection. Owing to the\nrecent development of structural graph representations of planning tasks, we\npropose a graph neural network (GNN) approach to selecting candidate planners.\nGNNs are advantageous over a straightforward alternative, the convolutional\nneural networks, in that they are invariant to node permutations and that they\nincorporate node labels for better inference.\n  Additionally, for cost-optimal planning, we propose a two-stage adaptive\nscheduling method to further improve the likelihood that a given task is solved\nin time. The scheduler may switch at halftime to a different planner,\nconditioned on the observed performance of the first one. Experimental results\nvalidate the effectiveness of the proposed method against strong baselines,\nboth deep learning and non-deep learning based.\n  The code is available at \\url{https://github.com/matenure/GNN_planner}.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:51:32 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 02:15:12 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 20:32:03 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 16:16:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ma", "Tengfei", ""], ["Ferber", "Patrick", ""], ["Huo", "Siyu", ""], ["Chen", "Jie", ""], ["Katz", "Michael", ""]]}, {"id": "1811.00217", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O Cruz, Robert Sabourin and George D. C. Cavalcanti", "title": "META-DES.Oracle: Meta-learning and feature selection for ensemble\n  selection", "comments": "Paper published on Information Fusion", "journal-ref": "Volume 38, November 2017, Pages 84-103", "doi": "10.1016/j.inffus.2017.02.010", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key issue in Dynamic Ensemble Selection (DES) is defining a suitable\ncriterion for calculating the classifiers' competence. There are several\ncriteria available to measure the level of competence of base classifiers, such\nas local accuracy estimates and ranking. However, using only one criterion may\nlead to a poor estimation of the classifier's competence. In order to deal with\nthis issue, we have proposed a novel dynamic ensemble selection framework using\nmeta-learning, called META-DES. An important aspect of the META-DES framework\nis that multiple criteria can be embedded in the system encoded as different\nsets of meta-features. However, some DES criteria are not suitable for every\nclassification problem. For instance, local accuracy estimates may produce poor\nresults when there is a high degree of overlap between the classes. Moreover, a\nhigher classification accuracy can be obtained if the performance of the\nmeta-classifier is optimized for the corresponding data. In this paper, we\npropose a novel version of the META-DES framework based on the formal\ndefinition of the Oracle, called META-DES.Oracle. The Oracle is an abstract\nmethod that represents an ideal classifier selection scheme. A meta-feature\nselection scheme using an overfitting cautious Binary Particle Swarm\nOptimization (BPSO) is proposed for improving the performance of the\nmeta-classifier. The difference between the outputs obtained by the\nmeta-classifier and those presented by the Oracle is minimized. Thus, the\nmeta-classifier is expected to obtain results that are similar to the Oracle.\nExperiments carried out using 30 classification problems demonstrate that the\noptimization procedure based on the Oracle definition leads to a significant\nimprovement in classification accuracy when compared to previous versions of\nthe META-DES framework and other state-of-the-art DES techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 04:20:28 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Cruz", "Rafael M. O", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1811.00223", "submitter": "Jong Wook Kim", "authors": "Jong Wook Kim, Rachel Bittner, Aparna Kumar, Juan Pablo Bello", "title": "Neural Music Synthesis for Flexible Timbre Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of raw audio waveform synthesis models like WaveNet\nmotivates a new approach for music synthesis, in which the entire process ---\ncreating audio samples from a score and instrument information --- is modeled\nusing generative neural networks. This paper describes a neural music synthesis\nmodel with flexible timbre controls, which consists of a recurrent neural\nnetwork conditioned on a learned instrument embedding followed by a WaveNet\nvocoder. The learned embedding space successfully captures the diverse\nvariations in timbres within a large dataset and enables timbre control and\nmorphing by interpolating between instruments in the embedding space. The\nsynthesis quality is evaluated both numerically and perceptually, and an\ninteractive web demo is presented.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 04:41:40 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Kim", "Jong Wook", ""], ["Bittner", "Rachel", ""], ["Kumar", "Aparna", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1811.00246", "submitter": "Jinwon An", "authors": "Jinwon An, Sungwon Lyu, Sungzoon Cho", "title": "SARN: Relational Reasoning through Sequential Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an attention module augmented relational network called\nSARN(Sequential Attention Relational Network) that can carry out relational\nreasoning by extracting reference objects and making efficient pairing between\nobjects. SARN greatly reduces the computational and memory requirements of the\nrelational network, which computes all object pairs. It also shows high\naccuracy on the Sort-of-CLEVR dataset compared to other models, especially on\nrelational questions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 05:45:43 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["An", "Jinwon", ""], ["Lyu", "Sungwon", ""], ["Cho", "Sungzoon", ""]]}, {"id": "1811.00247", "submitter": "Padala Manisha Miss", "authors": "Padala Manisha, Sujit Gujar", "title": "FNNC: Achieving Fairness through Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification models fairness can be ensured by solving a constrained\noptimization problem. We focus on fairness constraints like Disparate Impact,\nDemographic Parity, and Equalized Odds, which are non-decomposable and\nnon-convex. Researchers define convex surrogates of the constraints and then\napply convex optimization frameworks to obtain fair classifiers. Surrogates\nserve only as an upper bound to the actual constraints, and convexifying\nfairness constraints might be challenging.\n  We propose a neural network-based framework, \\emph{FNNC}, to achieve fairness\nwhile maintaining high accuracy in classification. The above fairness\nconstraints are included in the loss using Lagrangian multipliers. We prove\nbounds on generalization errors for the constrained losses which asymptotically\ngo to zero. The network is optimized using two-step mini-batch stochastic\ngradient descent. Our experiments show that FNNC performs as good as the state\nof the art, if not better. The experimental evidence supplements our\ntheoretical guarantees. In summary, we have an automated solution to achieve\nfairness in classification, which is easily extendable to many fairness\nconstraints.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 05:49:40 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 11:14:39 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 06:17:20 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Manisha", "Padala", ""], ["Gujar", "Sujit", ""]]}, {"id": "1811.00255", "submitter": "Masaaki Takada Mr.", "authors": "Masaaki Takada, Hironori Fujisawa, Takeichiro Nishikawa", "title": "HMLasso: Lasso with High Missing Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse regression such as the Lasso has achieved great success in handling\nhigh-dimensional data. However, one of the biggest practical problems is that\nhigh-dimensional data often contain large amounts of missing values. Convex\nConditioned Lasso (CoCoLasso) has been proposed for dealing with\nhigh-dimensional data with missing values, but it performs poorly when there\nare many missing values, so that the high missing rate problem has not been\nresolved. In this paper, we propose a novel Lasso-type regression method for\nhigh-dimensional data with high missing rates. We effectively incorporate mean\nimputed covariance, overcoming its inherent estimation bias. The result is an\noptimally weighted modification of CoCoLasso according to missing ratios. We\ntheoretically and experimentally show that our proposed method is highly\neffective even when there are many missing values.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 06:44:53 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2018 04:51:53 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 06:42:00 GMT"}, {"version": "v4", "created": "Wed, 19 Jun 2019 09:05:04 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Takada", "Masaaki", ""], ["Fujisawa", "Hironori", ""], ["Nishikawa", "Takeichiro", ""]]}, {"id": "1811.00260", "submitter": "Edoardo Conti", "authors": "Jason Gauci, Edoardo Conti, Yitao Liang, Kittipat Virochsiri, Yuchen\n  He, Zachary Kaden, Vivek Narayanan, Xiaohui Ye, Zhengxing Chen, Scott\n  Fujimoto", "title": "Horizon: Facebook's Open Source Applied Reinforcement Learning Platform", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present Horizon, Facebook's open source applied\nreinforcement learning (RL) platform. Horizon is an end-to-end platform\ndesigned to solve industry applied RL problems where datasets are large\n(millions to billions of observations), the feedback loop is slow (vs. a\nsimulator), and experiments must be done with care because they don't run in a\nsimulator. Unlike other RL platforms, which are often designed for fast\nprototyping and experimentation, Horizon is designed with production use cases\nas top of mind. The platform contains workflows to train popular deep RL\nalgorithms and includes data preprocessing, feature transformation, distributed\ntraining, counterfactual policy evaluation, optimized serving, and a\nmodel-based data understanding tool. We also showcase and describe real\nexamples where reinforcement learning models trained with Horizon significantly\noutperformed and replaced supervised learning systems at Facebook.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 07:02:45 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 22:49:50 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 05:57:02 GMT"}, {"version": "v4", "created": "Thu, 30 May 2019 20:47:42 GMT"}, {"version": "v5", "created": "Wed, 4 Sep 2019 19:30:00 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Gauci", "Jason", ""], ["Conti", "Edoardo", ""], ["Liang", "Yitao", ""], ["Virochsiri", "Kittipat", ""], ["He", "Yuchen", ""], ["Kaden", "Zachary", ""], ["Narayanan", "Vivek", ""], ["Ye", "Xiaohui", ""], ["Chen", "Zhengxing", ""], ["Fujimoto", "Scott", ""]]}, {"id": "1811.00264", "submitter": "Yaqiang Yao", "authors": "Yaqiang Yao, Huanhuan Chen", "title": "Multiple Kernel $k$-Means Clustering by Selecting Representative Kernels", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cluster data that are not linearly separable in the original feature\nspace, $k$-means clustering was extended to the kernel version. However, the\nperformance of kernel $k$-means clustering largely depends on the choice of\nkernel function. To mitigate this problem, multiple kernel learning has been\nintroduced into the $k$-means clustering to obtain an optimal kernel\ncombination for clustering. Despite the success of multiple kernel $k$-means\nclustering in various scenarios, few of the existing work update the\ncombination coefficients based on the diversity of kernels, which leads to the\nresult that the selected kernels contain high redundancy and would degrade the\nclustering performance and efficiency. In this paper, we propose a simple but\nefficient strategy that selects a diverse subset from the pre-specified kernels\nas the representative kernels, and then incorporate the subset selection\nprocess into the framework of multiple $k$-means clustering. The representative\nkernels can be indicated as the significant combination weights. Due to the\nnon-convexity of the obtained objective function, we develop an alternating\nminimization method to optimize the combination coefficients of the selected\nkernels and the cluster membership alternatively. We evaluate the proposed\napproach on several benchmark and real-world datasets. The experimental results\ndemonstrate the competitiveness of our approach in comparison with the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 07:18:15 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Yao", "Yaqiang", ""], ["Chen", "Huanhuan", ""]]}, {"id": "1811.00293", "submitter": "Arnu Pretorius", "authors": "Arnu Pretorius, Elan Van Biljon, Steve Kroon, Herman Kamper", "title": "Critical initialisation for deep signal propagation in noisy rectifier\n  neural networks", "comments": "20 pages, 11 figures, accepted at the 32nd Conference on Neural\n  Information Processing Systems (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic regularisation is an important weapon in the arsenal of a deep\nlearning practitioner. However, despite recent theoretical advances, our\nunderstanding of how noise influences signal propagation in deep neural\nnetworks remains limited. By extending recent work based on mean field theory,\nwe develop a new framework for signal propagation in stochastic regularised\nneural networks. Our noisy signal propagation theory can incorporate several\ncommon noise distributions, including additive and multiplicative Gaussian\nnoise as well as dropout. We use this framework to investigate initialisation\nstrategies for noisy ReLU networks. We show that no critical initialisation\nstrategy exists using additive noise, with signal propagation exploding\nregardless of the selected noise distribution. For multiplicative noise (e.g.\ndropout), we identify alternative critical initialisation strategies that\ndepend on the second moment of the noise distribution. Simulations and\nexperiments on real-world data confirm that our proposed initialisation is able\nto stably propagate signals in deep networks, while using an initialisation\ndisregarding noise fails to do so. Furthermore, we analyse correlation dynamics\nbetween inputs. Stronger noise regularisation is shown to reduce the depth to\nwhich discriminatory information about the inputs to a noisy ReLU network is\nable to propagate, even when initialised at criticality. We support our\ntheoretical predictions for these trainable depths with simulations, as well as\nwith experiments on MNIST and CIFAR-10\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 09:58:34 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 11:39:03 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Pretorius", "Arnu", ""], ["Van Biljon", "Elan", ""], ["Kroon", "Steve", ""], ["Kamper", "Herman", ""]]}, {"id": "1811.00321", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, Radu\n  Grosu", "title": "Liquid Time-constant Recurrent Neural Networks as Universal\n  Approximators", "comments": "This short report introduces the universal approximation capabilities\n  of liquid time-constant (LTC) recurrent neural networks, and provides\n  theoretical bounds for its dynamics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the notion of liquid time-constant (LTC)\nrecurrent neural networks (RNN)s, a subclass of continuous-time RNNs, with\nvarying neuronal time-constant realized by their nonlinear synaptic\ntransmission model. This feature is inspired by the communication principles in\nthe nervous system of small species. It enables the model to approximate\ncontinuous mapping with a small number of computational units. We show that any\nfinite trajectory of an $n$-dimensional continuous dynamical system can be\napproximated by the internal state of the hidden units and $n$ output units of\nan LTC network. Here, we also theoretically find bounds on their neuronal\nstates and varying time-constant.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 11:36:56 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Lechner", "Mathias", ""], ["Amini", "Alexander", ""], ["Rus", "Daniela", ""], ["Grosu", "Radu", ""]]}, {"id": "1811.00338", "submitter": "Qin Zou", "authors": "Qin Zou, Yanling Wang, Qian Wang, Yi Zhao, Qingquan Li", "title": "Deep Learning-Based Gait Recognition Using Smartphones in the Wild", "comments": "IEEE Transactions on Information Forensics and Security, 15(1), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to other biometrics, gait is difficult to conceal and has the\nadvantage of being unobtrusive. Inertial sensors, such as accelerometers and\ngyroscopes, are often used to capture gait dynamics. These inertial sensors are\ncommonly integrated into smartphones and are widely used by the average person,\nwhich makes gait data convenient and inexpensive to collect. In this paper, we\nstudy gait recognition using smartphones in the wild. In contrast to\ntraditional methods, which often require a person to walk along a specified\nroad and/or at a normal walking speed, the proposed method collects inertial\ngait data under unconstrained conditions without knowing when, where, and how\nthe user walks. To obtain good person identification and authentication\nperformance, deep-learning techniques are presented to learn and model the gait\nbiometrics based on walking data. Specifically, a hybrid deep neural network is\nproposed for robust gait feature representation, where features in the space\nand time domains are successively abstracted by a convolutional neural network\nand a recurrent neural network. In the experiments, two datasets collected by\nsmartphones for a total of 118 subjects are used for evaluations. The\nexperiments show that the proposed method achieves higher than 93.5\\% and\n93.7\\% accuracies in person identification and authentication, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 12:20:37 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 17:48:49 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 15:47:09 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Zou", "Qin", ""], ["Wang", "Yanling", ""], ["Wang", "Qian", ""], ["Zhao", "Yi", ""], ["Li", "Qingquan", ""]]}, {"id": "1811.00401", "submitter": "J\\\"orn-Henrik Jacobsen", "authors": "J\\\"orn-Henrik Jacobsen, Jens Behrmann, Richard Zemel, Matthias Bethge", "title": "Excessive Invariance Causes Adversarial Vulnerability", "comments": null, "journal-ref": "Proceedings of the 7th International Conference on Learning\n  Representations (ICLR), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their impressive performance, deep neural networks exhibit striking\nfailures on out-of-distribution inputs. One core idea of adversarial example\nresearch is to reveal neural network errors under such distribution shifts. We\ndecompose these errors into two complementary sources: sensitivity and\ninvariance. We show deep networks are not only too sensitive to task-irrelevant\nchanges of their input, as is well-known from epsilon-adversarial examples, but\nare also too invariant to a wide range of task-relevant changes, thus making\nvast regions in input space vulnerable to adversarial attacks. We show such\nexcessive invariance occurs across various tasks and architecture types. On\nMNIST and ImageNet one can manipulate the class-specific content of almost any\nimage without changing the hidden activations. We identify an insufficiency of\nthe standard cross-entropy loss as a reason for these failures. Further, we\nextend this objective based on an information-theoretic analysis so it\nencourages the model to consider all task-dependent features in its decision.\nThis provides the first approach tailored explicitly to overcome excessive\ninvariance and resulting vulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 14:14:03 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 03:26:21 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 04:12:20 GMT"}, {"version": "v4", "created": "Sun, 12 Jul 2020 07:26:06 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Jacobsen", "J\u00f6rn-Henrik", ""], ["Behrmann", "Jens", ""], ["Zemel", "Richard", ""], ["Bethge", "Matthias", ""]]}, {"id": "1811.00410", "submitter": "Elliot J. Crowley", "authors": "Antreas Antoniou, Agnieszka S{\\l}owik, Elliot J. Crowley, Amos Storkey", "title": "Dilated DenseNets for Relational Reasoning", "comments": "Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite their impressive performance in many tasks, deep neural networks\noften struggle at relational reasoning. This has recently been remedied with\nthe introduction of a plug-in relational module that considers relations\nbetween pairs of objects. Unfortunately, this is combinatorially expensive. In\nthis extended abstract, we show that a DenseNet incorporating dilated\nconvolutions excels at relational reasoning on the Sort-of-CLEVR dataset,\nallowing us to forgo this relational module and its associated expense.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 14:38:44 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Antoniou", "Antreas", ""], ["S\u0142owik", "Agnieszka", ""], ["Crowley", "Elliot J.", ""], ["Storkey", "Amos", ""]]}, {"id": "1811.00416", "submitter": "Avanti Shrikumar", "authors": "Avanti Shrikumar, Katherine Tian, \\v{Z}iga Avsec, Anna Shcherbina,\n  Abhimanyu Banerjee, Mahfuza Sharmin, Surag Nair, Anshul Kundaje", "title": "Technical Note on Transcription Factor Motif Discovery from Importance\n  Scores (TF-MoDISco) version 0.5.6.5", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TF-MoDISco (Transcription Factor Motif Discovery from Importance Scores) is\nan algorithm for identifying motifs from basepair-level importance scores\ncomputed on genomic sequence data. This technical note focuses on version\nv0.5.6.5. The implementation is available at\nhttps://github.com/kundajelab/tfmodisco/tree/v0.5.6.5\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:22:49 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 03:37:19 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 10:57:12 GMT"}, {"version": "v4", "created": "Fri, 3 Jan 2020 04:08:40 GMT"}, {"version": "v5", "created": "Thu, 30 Apr 2020 11:50:44 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Shrikumar", "Avanti", ""], ["Tian", "Katherine", ""], ["Avsec", "\u017diga", ""], ["Shcherbina", "Anna", ""], ["Banerjee", "Abhimanyu", ""], ["Sharmin", "Mahfuza", ""], ["Nair", "Surag", ""], ["Kundaje", "Anshul", ""]]}, {"id": "1811.00423", "submitter": "Daniel Tait", "authors": "Daniel J. Tait and Bruce J. Worton", "title": "Multiplicative Latent Force Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian modelling of dynamic systems must achieve a compromise between\nproviding a complete mechanistic specification of the process while retaining\nthe flexibility to handle those situations in which data is sparse relative to\nmodel complexity, or a full specification is hard to motivate. Latent force\nmodels achieve this dual aim by specifying a parsimonious linear evolution\nequation which an additive latent Gaussian process (GP) forcing term. In this\nwork we extend the latent force framework to allow for multiplicative\ninteractions between the GP and the latent states leading to more control over\nthe geometry of the trajectories. Unfortunately inference is no longer\nstraightforward and so we introduce an approximation based on the method of\nsuccessive approximations and examine its performance using a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 15:08:46 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Tait", "Daniel J.", ""], ["Worton", "Bruce J.", ""]]}, {"id": "1811.00424", "submitter": "Daniel Rodriguez", "authors": "Raul-Jose Palma-Mendoza, Daniel Rodriguez, Luis de-Marcos", "title": "Distributed ReliefF based Feature Selection in Spark", "comments": null, "journal-ref": null, "doi": "10.1007/s10115-017-1145-y", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection (FS) is a key research area in the machine learning and\ndata mining fields, removing irrelevant and redundant features usually helps to\nreduce the effort required to process a dataset while maintaining or even\nimproving the processing algorithm's accuracy. However, traditional algorithms\ndesigned for executing on a single machine lack scalability to deal with the\nincreasing amount of data that has become available in the current Big Data\nera. ReliefF is one of the most important algorithms successfully implemented\nin many FS applications. In this paper, we present a completely redesigned\ndistributed version of the popular ReliefF algorithm based on the novel Spark\ncluster computing model that we have called DiReliefF. Spark is increasing its\npopularity due to its much faster processing times compared with Hadoop's\nMapReduce model implementation. The effectiveness of our proposal is tested on\nfour publicly available datasets, all of them with a large number of instances\nand two of them with also a large number of features. Subsets of these datasets\nwere also used to compare the results to a non-distributed implementation of\nthe algorithm. The results show that the non-distributed implementation is\nunable to handle such large volumes of data without specialized hardware, while\nour design can process them in a scalable way with much better processing times\nand memory usage.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 15:11:32 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Palma-Mendoza", "Raul-Jose", ""], ["Rodriguez", "Daniel", ""], ["de-Marcos", "Luis", ""]]}, {"id": "1811.00429", "submitter": "Pierre Thodoroff", "authors": "Pierre Thodoroff, Audrey Durand, Joelle Pineau, Doina Precup", "title": "Temporal Regularization in Markov Decision Process", "comments": "Published as a conference paper at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several applications of Reinforcement Learning suffer from instability due to\nhigh variance. This is especially prevalent in high dimensional domains.\nRegularization is a commonly used technique in machine learning to reduce\nvariance, at the cost of introducing some bias. Most existing regularization\ntechniques focus on spatial (perceptual) regularization. Yet in reinforcement\nlearning, due to the nature of the Bellman equation, there is an opportunity to\nalso exploit temporal regularization based on smoothness in value estimates\nover trajectories. This paper explores a class of methods for temporal\nregularization. We formally characterize the bias induced by this technique\nusing Markov chain concepts. We illustrate the various characteristics of\ntemporal regularization via a sequence of simple discrete and continuous MDPs,\nand show that the technique provides improvement even in high-dimensional Atari\ngames.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 15:21:45 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 23:03:53 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Thodoroff", "Pierre", ""], ["Durand", "Audrey", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""]]}, {"id": "1811.00458", "submitter": "Di Chen", "authors": "Di Chen, Carla P. Gomes", "title": "Bias Reduction via End-to-End Shift Learning: Application to Citizen\n  Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citizen science projects are successful at gathering rich datasets for\nvarious applications. However, the data collected by citizen scientists are\noften biased --- in particular, aligned more with the citizens' preferences\nthan with scientific objectives. We propose the Shift Compensation Network\n(SCN), an end-to-end learning scheme which learns the shift from the scientific\nobjectives to the biased data while compensating for the shift by re-weighting\nthe training data. Applied to bird observational data from the citizen science\nproject eBird, we demonstrate how SCN quantifies the data distribution shift\nand outperforms supervised learning models that do not address the data bias.\nCompared with competing models in the context of covariate shift, we further\ndemonstrate the advantage of SCN in both its effectiveness and its capability\nof handling massive high-dimensional data.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 15:54:30 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 21:32:48 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 17:36:08 GMT"}, {"version": "v4", "created": "Wed, 14 Nov 2018 05:35:37 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Chen", "Di", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1811.00464", "submitter": "Yue Li", "authors": "Yue Li, Manolis Kellis", "title": "A latent topic model for mining heterogenous non-randomly missing\n  electronic health records data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHR) are rich heterogeneous collection of patient\nhealth information, whose broad adoption provides great opportunities for\nsystematic health data mining. However, heterogeneous EHR data types and biased\nascertainment impose computational challenges. Here, we present mixEHR, an\nunsupervised generative model integrating collaborative filtering and latent\ntopic models, which jointly models the discrete distributions of data\nobservation bias and actual data using latent disease-topic distributions. We\napply mixEHR on 12.8 million phenotypic observations from the MIMIC dataset,\nand use it to reveal latent disease topics, interpret EHR results, impute\nmissing data, and predict mortality in intensive care units. Using both\nsimulation and real data, we show that mixEHR outperforms previous methods and\nreveals meaningful multi-disease insights.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 16:04:58 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Li", "Yue", ""], ["Kellis", "Manolis", ""]]}, {"id": "1811.00512", "submitter": "Renato Negrinho", "authors": "Renato Negrinho, Matthew R. Gormley, Geoffrey J. Gordon", "title": "Learning Beam Search Policies via Imitation Learning", "comments": "Published in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam search is widely used for approximate decoding in structured prediction\nproblems. Models often use a beam at test time but ignore its existence at\ntrain time, and therefore do not explicitly learn how to use the beam. We\ndevelop an unifying meta-algorithm for learning beam search policies using\nimitation learning. In our setting, the beam is part of the model, and not just\nan artifact of approximate decoding. Our meta-algorithm captures existing\nlearning algorithms and suggests new ones. It also lets us show novel no-regret\nguarantees for learning beam search policies.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:31:10 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 17:15:37 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Negrinho", "Renato", ""], ["Gormley", "Matthew R.", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1811.00513", "submitter": "Congzheng Song", "authors": "Congzheng Song, Vitaly Shmatikov", "title": "Auditing Data Provenance in Text-Generation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To help enforce data-protection regulations such as GDPR and detect\nunauthorized uses of personal data, we develop a new \\emph{model auditing}\ntechnique that helps users check if their data was used to train a machine\nlearning model. We focus on auditing deep-learning models that generate\nnatural-language text, including word prediction and dialog generation. These\nmodels are at the core of popular online services and are often trained on\npersonal data such as users' messages, searches, chats, and comments.\n  We design and evaluate a black-box auditing method that can detect, with very\nfew queries to a model, if a particular user's texts were used to train it\n(among thousands of other users). We empirically show that our method can\nsuccessfully audit well-generalized models that are not overfitted to the\ntraining data. We also analyze how text-generation models memorize word\nsequences and explain why this memorization makes them amenable to auditing.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:32:44 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 18:47:05 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Song", "Congzheng", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1811.00521", "submitter": "Bryan He", "authors": "Bryan He, James Zou", "title": "Minimizing Close-k Aggregate Loss Improves Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification, the de facto method for aggregating individual losses is\nthe average loss. When the actual metric of interest is 0-1 loss, it is common\nto minimize the average surrogate loss for some well-behaved (e.g. convex)\nsurrogate. Recently, several other aggregate losses such as the maximal loss\nand average top-$k$ loss were proposed as alternative objectives to address\nshortcomings of the average loss. However, we identify common classification\nsettings, e.g. the data is imbalanced, has too many easy or ambiguous examples,\netc., when average, maximal and average top-$k$ all suffer from suboptimal\ndecision boundaries, even on an infinitely large training set. To address this\nproblem, we propose a new classification objective called the close-$k$\naggregate loss, where we adaptively minimize the loss for points close to the\ndecision boundary. We provide theoretical guarantees for the 0-1 accuracy when\nwe optimize close-$k$ aggregate loss. We also conduct systematic experiments\nacross the PMLB and OpenML benchmark datasets. Close-$k$ achieves significant\ngains in 0-1 test accuracy, improvements of $\\geq 2$% and $p<0.05$, in over 25%\nof the datasets compared to average, maximal and average top-$k$. In contrast,\nthe previous aggregate losses outperformed close-$k$ in less than 2% of the\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:42:18 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 17:39:14 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["He", "Bryan", ""], ["Zou", "James", ""]]}, {"id": "1811.00525", "submitter": "Marc Khoury", "authors": "Marc Khoury and Dylan Hadfield-Menell", "title": "On the Geometry of Adversarial Examples", "comments": "Improvements to clarity and presentation over initial submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a pervasive phenomenon of machine learning models\nwhere seemingly imperceptible perturbations to the input lead to\nmisclassifications for otherwise statistically accurate models. We propose a\ngeometric framework, drawing on tools from the manifold reconstruction\nliterature, to analyze the high-dimensional geometry of adversarial examples.\nIn particular, we highlight the importance of codimension: for low-dimensional\ndata manifolds embedded in high-dimensional space there are many directions off\nthe manifold in which to construct adversarial examples. Adversarial examples\nare a natural consequence of learning a decision boundary that classifies the\nlow-dimensional data manifold well, but classifies points near the manifold\nincorrectly. Using our geometric framework we prove (1) a tradeoff between\nrobustness under different norms, (2) that adversarial training in balls around\nthe data is sample inefficient, and (3) sufficient sampling conditions under\nwhich nearest neighbor classifiers and ball-based adversarial training are\nrobust.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:47:10 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 21:43:30 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Khoury", "Marc", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "1811.00539", "submitter": "Colin Graber", "authors": "Colin Graber, Ofer Meshi, Alexander Schwing", "title": "Deep Structured Prediction with Nonlinear Output Transformations", "comments": "Appearing in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep structured models are widely used for tasks like semantic segmentation,\nwhere explicit correlations between variables provide important prior\ninformation which generally helps to reduce the data needs of deep nets.\nHowever, current deep structured models are restricted by oftentimes very local\nneighborhood structure, which cannot be increased for computational complexity\nreasons, and by the fact that the output configuration, or a representation\nthereof, cannot be transformed further. Very recent approaches which address\nthose issues include graphical model inference inside deep nets so as to permit\nsubsequent non-linear output space transformations. However, optimization of\nthose formulations is challenging and not well understood. Here, we develop a\nnovel model which generalizes existing approaches, such as structured\nprediction energy networks, and discuss a formulation which maintains\napplicability of existing inference techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:59:58 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Graber", "Colin", ""], ["Meshi", "Ofer", ""], ["Schwing", "Alexander", ""]]}, {"id": "1811.00542", "submitter": "Daniel Emaasit", "authors": "Daniel Emaasit", "title": "Pymc-learn: Practical Probabilistic Machine Learning in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  $\\textit{Pymc-learn}$ is a Python package providing a variety of\nstate-of-the-art probabilistic models for supervised and unsupervised machine\nlearning. It is inspired by $\\textit{scikit-learn}$ and focuses on bringing\nprobabilistic machine learning to non-specialists. It uses a general-purpose\nhigh-level language that mimics $\\textit{scikit-learn}$. Emphasis is put on\nease of use, productivity, flexibility, performance, documentation, and an API\nconsistent with $\\textit{scikit-learn}$. It depends on $\\textit{scikit-learn}$\nand $\\textit{pymc3}$ and is distributed under the new BSD-3 license,\nencouraging its use in both academia and industry. Source code, binaries, and\ndocumentation are available on http://github.com/pymc-learn/pymc-learn.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 22:54:12 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Emaasit", "Daniel", ""]]}, {"id": "1811.00576", "submitter": "Jean Thierry-Mieg", "authors": "Jean Thierry-Mieg", "title": "Connections between physics, mathematics and deep learning", "comments": "Version 1 and 2 title was: How the fundamental concepts of\n  mathematics and physics explain deep learning. Version 3 with the new title\n  is accepted in LHEP. It is enriched by a new chapter on the Bayesian\n  Information criterion seen as an application of renormalisation theory. 19\n  pages, 22 references, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from the Fermat's principle of least action, which governs classical\nand quantum mechanics and from the theory of exterior differential forms, which\ngoverns the geometry of curved manifolds, we show how to derive the equations\ngoverning neural networks in an intrinsic, coordinate invariant way, where the\nloss function plays the role of the Hamiltonian. To be covariant, these\nequations imply a layer metric which is instrumental in pretraining and\nexplains the role of conjugation when using complex numbers. The differential\nformalism also clarifies the relation of the gradient descent optimizer with\nAristotelian and Newtonian mechanics and why large learning steps break the\nlogic of the linearization procedure. We hope that this formal presentation of\nthe differential geometry of neural networks will encourage some physicists to\ndive into deep learning, and reciprocally, that the specialists of deep\nlearning will better appreciate the close interconnection of their subject with\nthe foundations of classical and quantum field theory.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 18:21:42 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 18:14:00 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2019 14:30:52 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Thierry-Mieg", "Jean", ""]]}, {"id": "1811.00577", "submitter": "Luiz F. O. Chamon", "authors": "Luiz F. O. Chamon and Yonina C. Eldar and Alejandro Ribeiro", "title": "Functional Nonlinear Sparse Models", "comments": "Accepted for publication on the IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal processing is rich in inherently continuous and often nonlinear\napplications, such as spectral estimation, optical imaging, and\nsuper-resolution microscopy, in which sparsity plays a key role in obtaining\nstate-of-the-art results. Coping with the infinite dimensionality and\nnon-convexity of these problems typically involves discretization and convex\nrelaxations, e.g., using atomic norms. Nevertheless, grid mismatch and other\ncoherence issues often lead to discretized versions of sparse signals that are\nnot sparse. Even if they are, recovering sparse solutions using convex\nrelaxations requires assumptions that may be hard to meet in practice. What is\nmore, problems involving nonlinear measurements remain non-convex even after\nrelaxing the sparsity objective. We address these issues by directly tackling\nthe continuous, nonlinear problem cast as a sparse functional optimization\nprogram. We prove that when these problems are non-atomic, they have no duality\ngap and can therefore be solved efficiently using duality and~(stochastic)\nconvex optimization methods. We illustrate the wide range of applications of\nthis approach by formulating and solving problems from nonlinear spectral\nestimation and robust classification.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 18:24:25 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 14:08:06 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 23:17:30 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 15:24:04 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Chamon", "Luiz F. O.", ""], ["Eldar", "Yonina C.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1811.00596", "submitter": "Valery Kharitonov", "authors": "Valery Kharitonov, Dmitry Molchanov, Dmitry Vetrov", "title": "Variational Dropout via Empirical Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Automatic Relevance Determination procedure applied to deep\nneural networks. We show that ARD applied to Bayesian DNNs with Gaussian\napproximate posterior distributions leads to a variational bound similar to\nthat of variational dropout, and in the case of a fixed dropout rate,\nobjectives are exactly the same. Experimental results show that the two\napproaches yield comparable results in practice even when the dropout rates are\ntrained. This leads to an alternative Bayesian interpretation of dropout and\nmitigates some of the theoretical issues that arise with the use of improper\npriors in the variational dropout model. Additionally, we explore the use of\nthe hierarchical priors in ARD and show that it helps achieve higher sparsity\nfor the same accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 19:22:39 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 10:56:21 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Kharitonov", "Valery", ""], ["Molchanov", "Dmitry", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1811.00620", "submitter": "Hongyuan Zhan", "authors": "Hongyuan Zhan, Gabriel Gomes, Xiaoye S. Li, Kamesh Madduri, Kesheng Wu", "title": "Efficient Online Hyperparameter Optimization for Kernel Ridge Regression\n  with Applications to Traffic Time Series Prediction", "comments": "An extended version of \"Efficient Online Hyperparameter Learning for\n  Traffic Flow Prediction\" published in The 21st IEEE International Conference\n  on Intelligent Transportation Systems (ITSC 2018)", "journal-ref": "H. Zhan, G. Gomes, X. S. Li, K. Madduri, and K. Wu. Efficient\n  Online Hyperparameter Learning for Traffic Flow Prediction. In 2018 IEEE 21th\n  International Conference on Intelligent Transportation Systems (ITSC), pages\n  1-6. IEEE, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational efficiency is an important consideration for deploying machine\nlearning models for time series prediction in an online setting. Machine\nlearning algorithms adjust model parameters automatically based on the data,\nbut often require users to set additional parameters, known as hyperparameters.\nHyperparameters can significantly impact prediction accuracy. Traffic\nmeasurements, typically collected online by sensors, are serially correlated.\nMoreover, the data distribution may change gradually. A typical adaptation\nstrategy is periodically re-tuning the model hyperparameters, at the cost of\ncomputational burden. In this work, we present an efficient and principled\nonline hyperparameter optimization algorithm for Kernel Ridge regression\napplied to traffic prediction problems. In tests with real traffic measurement\ndata, our approach requires as little as one-seventh of the computation time of\nother tuning methods, while achieving better or similar prediction accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 20:14:49 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Zhan", "Hongyuan", ""], ["Gomes", "Gabriel", ""], ["Li", "Xiaoye S.", ""], ["Madduri", "Kamesh", ""], ["Wu", "Kesheng", ""]]}, {"id": "1811.00628", "submitter": "Zois Boukouvalas", "authors": "Zois Boukouvalas, Daniel C. Elton, Peter W. Chung, Mark D. Fuge", "title": "Independent Vector Analysis for Data Fusion Prior to Molecular Property\n  Prediction with Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its high computational speed and accuracy compared to ab-initio\nquantum chemistry and forcefield modeling, the prediction of molecular\nproperties using machine learning has received great attention in the fields of\nmaterials design and drug discovery. A main ingredient required for machine\nlearning is a training dataset consisting of molecular features\\textemdash for\nexample fingerprint bits, chemical descriptors, etc. that adequately\ncharacterize the corresponding molecules. However, choosing features for any\napplication is highly non-trivial. No \"universal\" method for feature selection\nexists. In this work, we propose a data fusion framework that uses Independent\nVector Analysis to exploit underlying complementary information contained in\ndifferent molecular featurization methods, bringing us a step closer to\nautomated feature generation. Our approach takes an arbitrary number of\nindividual feature vectors and automatically generates a single, compact (low\ndimensional) set of molecular features that can be used to enhance the\nprediction performance of regression models. At the same time our methodology\nretains the possibility of interpreting the generated features to discover\nrelationships between molecular structures and properties. We demonstrate this\non the QM7b dataset for the prediction of several properties such as\natomization energy, polarizability, frontier orbital eigenvalues, ionization\npotential, electron affinity, and excitation energies. In addition, we show how\nour method helps improve the prediction of experimental binding affinities for\na set of human BACE-1 inhibitors. To encourage more widespread use of IVA we\nhave developed the PyIVA Python package, an open source code which is available\nfor download on Github.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 20:34:31 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Boukouvalas", "Zois", ""], ["Elton", "Daniel C.", ""], ["Chung", "Peter W.", ""], ["Fuge", "Mark D.", ""]]}, {"id": "1811.00631", "submitter": "Rados{\\l}aw Piliszek", "authors": "Rados{\\l}aw Piliszek, Krzysztof Mnich, Szymon Migacz, Pawe{\\l}\n  Tabaszewski, Andrzej Su{\\l}ecki, Aneta Polewko-Klim and Witold Rudnicki", "title": "MDFS - MultiDimensional Feature Selection", "comments": "12 pages, 3 figures, 5 tables, license: CC-BY", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identification of informative variables in an information system is often\nperformed using simple one-dimensional filtering procedures that discard\ninformation about interactions between variables. Such approach may result in\nremoving some relevant variables from consideration. Here we present an R\npackage MDFS (MultiDimensional Feature Selection) that performs identification\nof informative variables taking into account synergistic interactions between\nmultiple descriptors and the decision variable. MDFS is an implementation of an\nalgorithm based on information theory. Computational kernel of the package is\nimplemented in C++. A high-performance version implemented in CUDA C is also\navailable. The applications of MDFS are demonstrated using the well-known\nMadelon dataset that has synergistic variables by design. The dataset comes\nfrom the UCI Machine Learning Repository. It is shown that multidimensional\nanalysis is more sensitive than one-dimensional tests and returns more reliable\nrankings of importance.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 12:22:14 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Piliszek", "Rados\u0142aw", ""], ["Mnich", "Krzysztof", ""], ["Migacz", "Szymon", ""], ["Tabaszewski", "Pawe\u0142", ""], ["Su\u0142ecki", "Andrzej", ""], ["Polewko-Klim", "Aneta", ""], ["Rudnicki", "Witold", ""]]}, {"id": "1811.00636", "submitter": "Jerry Li", "authors": "Brandon Tran, Jerry Li, Aleksander Madry", "title": "Spectral Signatures in Backdoor Attacks", "comments": "16 pages, accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work has uncovered a new form of data poisoning: so-called\n\\emph{backdoor} attacks. These attacks are particularly dangerous because they\ndo not affect a network's behavior on typical, benign data. Rather, the network\nonly deviates from its expected output when triggered by a perturbation planted\nby an adversary.\n  In this paper, we identify a new property of all known backdoor attacks,\nwhich we call \\emph{spectral signatures}. This property allows us to utilize\ntools from robust statistics to thwart the attacks. We demonstrate the efficacy\nof these signatures in detecting and removing poisoned examples on real image\nsets and state of the art neural network architectures. We believe that\nunderstanding spectral signatures is a crucial first step towards designing ML\nsystems secure against such backdoor attacks\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 21:12:01 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Tran", "Brandon", ""], ["Li", "Jerry", ""], ["Madry", "Aleksander", ""]]}, {"id": "1811.00639", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov and Boris Flach", "title": "Stochastic Normalizations as Bayesian Learning", "comments": "Accepted to ACCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we investigate the reasons why Batch Normalization (BN) improves\nthe generalization performance of deep networks. We argue that one major\nreason, distinguishing it from data-independent normalization methods, is\nrandomness of batch statistics. This randomness appears in the parameters\nrather than in activations and admits an interpretation as a practical Bayesian\nlearning. We apply this idea to other (deterministic) normalization techniques\nthat are oblivious to the batch size. We show that their generalization\nperformance can be improved significantly by Bayesian learning of the same\nform. We obtain test performance comparable to BN and, at the same time, better\nvalidation losses suitable for subsequent output uncertainty estimation through\napproximate Bayesian posterior.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 21:30:39 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""]]}, {"id": "1811.00641", "submitter": "Anish Acharya", "authors": "Anish Acharya, Rahul Goel, Angeliki Metallinou, Inderjit Dhillon", "title": "Online Embedding Compression for Text Classification using Low Rank\n  Matrix Factorization", "comments": "Accepted in Thirty-Third AAAI Conference on Artificial Intelligence\n  (AAAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have become state of the art for natural language\nprocessing (NLP) tasks, however deploying these models in production system\nposes significant memory constraints. Existing compression methods are either\nlossy or introduce significant latency. We propose a compression method that\nleverages low rank matrix factorization during training,to compress the word\nembedding layer which represents the size bottleneck for most NLP models. Our\nmodels are trained, compressed and then further re-trained on the downstream\ntask to recover accuracy while maintaining the reduced size. Empirically, we\nshow that the proposed method can achieve 90% compression with minimal impact\nin accuracy for sentence classification tasks, and outperforms alternative\nmethods like fixed-point quantization or offline word embedding compression. We\nalso analyze the inference time and storage space for our method through FLOP\ncalculations, showing that we can compress DNN models by a configurable ratio\nand regain accuracy loss without introducing additional latency compared to\nfixed point quantization. Finally, we introduce a novel learning rate schedule,\nthe Cyclically Annealed Learning Rate (CALR), which we empirically demonstrate\nto outperform other popular adaptive learning rate algorithms on a sentence\nclassification benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 21:38:18 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Acharya", "Anish", ""], ["Goel", "Rahul", ""], ["Metallinou", "Angeliki", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "1811.00648", "submitter": "Matthias Rottmann", "authors": "Matthias Rottmann, Pascal Colling, Thomas-Paul Hack, Robin Chan,\n  Fabian H\\\"uger, Peter Schlicht, Hanno Gottschalk", "title": "Prediction Error Meta Classification in Semantic Segmentation: Detection\n  via Aggregated Dispersion Measures of Softmax Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method that \"meta\" classifies whether seg-ments predicted by a\nsemantic segmentation neural networkintersect with the ground truth. For this\npurpose, we employ measures of dispersion for predicted pixel-wise class\nprobability distributions, like classification entropy, that yield heat maps of\nthe input scene's size. We aggregate these dispersion measures segment-wise and\nderive metrics that are well-correlated with the segment-wise IoU of prediction\nand ground truth. This procedure yields an almost plug and play post-processing\ntool to rate the prediction quality of semantic segmentation networks on\nsegment level. This is especially relevant for monitoring neural networks in\nonline applications like automated driving or medical imaging where reliability\nis of utmost importance. In our tests, we use publicly available\nstate-of-the-art networks trained on the Cityscapes dataset and the BraTS2017\ndataset and analyze the predictive power of different metrics as well as\ndifferent sets of metrics. To this end, we compute logistic LASSO regression\nfits for the task of classifying IoU=0 vs. IoU>0 per segment and obtain AUROC\nvalues of up to 91.55%. We complement these tests with linear regression fits\nto predict the segment-wise IoU and obtain prediction standard deviations of\ndown to 0.130 as well as $R^2$ values of up to 84.15%. We show that these\nresults clearly outperform standard approaches.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 22:00:00 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 14:38:24 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Rottmann", "Matthias", ""], ["Colling", "Pascal", ""], ["Hack", "Thomas-Paul", ""], ["Chan", "Robin", ""], ["H\u00fcger", "Fabian", ""], ["Schlicht", "Peter", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1811.00669", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, George D. C. Cavalcanti, Tsang Ing Ren", "title": "A Method For Dynamic Ensemble Selection Based on a Filter and an\n  Adaptive Distance to Improve the Quality of the Regions of Competence", "comments": "Paper published on IJCNN 2011", "journal-ref": null, "doi": "10.1109/IJCNN.2011.6033350", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic classifier selection systems aim to select a group of classifiers\nthat is most adequate for a specific query pattern. This is done by defining a\nregion around the query pattern and analyzing the competence of the classifiers\nin this region. However, the regions are often surrounded by noise which can\ndifficult the classifier selection. This fact makes the performance of most\ndynamic selection systems no better than static selections. In this paper, we\ndemonstrate that the performance dynamic selection systems end up limited by\nthe quality of the regions extracted. Thereafter, we propose a new dynamic\nclassifier selection that improves the regions of competence in order to\nachieve higher recognition rates. obtained from several classification\ndatabases show the proposed method not only increase the recognition\nperformance but also decreases the computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:03:53 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Cavalcanti", "George D. C.", ""], ["Ren", "Tsang Ing", ""]]}, {"id": "1811.00677", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti", "title": "Analyzing different prototype selection techniques for dynamic\n  classifier and ensemble selection", "comments": null, "journal-ref": "Published on the International Joint Conference on Neural\n  Networks, 2017, 3959-3966", "doi": "10.1109/IJCNN.2017.7966355", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dynamic selection (DS) techniques, only the most competent classifiers,\nfor the classification of a specific test sample are selected to predict the\nsample's class labels. The more important step in DES techniques is estimating\nthe competence of the base classifiers for the classification of each specific\ntest sample. The classifiers' competence is usually estimated using the\nneighborhood of the test sample defined on the validation samples, called the\nregion of competence. Thus, the performance of DS techniques is sensitive to\nthe distribution of the validation set. In this paper, we evaluate six\nprototype selection techniques that work by editing the validation data in\norder to remove noise and redundant instances. Experiments conducted using\nseveral state-of-the-art DS techniques over 30 classification problems\ndemonstrate that by using prototype selection techniques we can improve the\nclassification accuracy of DS techniques and also significantly reduce the\ncomputational cost involved.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:34:10 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1811.00683", "submitter": "Marius Hofert", "authors": "Marius Hofert and Avinash Prasad and Mu Zhu", "title": "Quasi-random sampling for multivariate distributions via generative\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative moment matching networks (GMMNs) are introduced for generating\nquasi-random samples from multivariate models with any underlying copula in\norder to compute estimates under variance reduction. So far, quasi-random\nsampling for multivariate distributions required a careful design, exploiting\nspecific properties (such as conditional distributions) of the implied\nparametric copula or the underlying quasi-Monte Carlo (QMC) point set, and was\nonly tractable for a small number of models. Utilizing GMMNs allows one to\nconstruct quasi-random samples for a much larger variety of multivariate\ndistributions without such restrictions, including empirical ones from real\ndata with dependence structures not well captured by parametric copulas. Once\ntrained on pseudo-random samples from a parametric model or on real data, these\nneural networks only require a multivariate standard uniform randomized QMC\npoint set as input and are thus fast in estimating expectations of interest\nunder dependence with variance reduction. Numerical examples are considered to\ndemonstrate the approach, including applications inspired by risk management\npractice. All results are reproducible with the demos GMMN_QMC_paper,\nGMMN_QMC_data and GMMN_QMC_timings as part of the R package gnn.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:59:41 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 16:11:45 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 21:02:04 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Hofert", "Marius", ""], ["Prasad", "Avinash", ""], ["Zhu", "Mu", ""]]}, {"id": "1811.00686", "submitter": "Martin Jankowiak", "authors": "Martin Jankowiak", "title": "Closed Form Variational Objectives For Bayesian Neural Networks with a\n  Single Hidden Layer", "comments": "Bayesian Deep Learning Workshop @ NeurIPS 2018; 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we consider setups in which variational objectives for Bayesian\nneural networks can be computed in closed form. In particular we focus on\nsingle-layer networks in which the activation function is piecewise polynomial\n(e.g. ReLU). In this case we show that for a Normal likelihood and structured\nNormal variational distributions one can compute a variational lower bound in\nclosed form. In addition we compute the predictive mean and variance in closed\nform. Finally, we also show how to compute approximate lower bounds for other\nlikelihoods (e.g. softmax classification). In experiments we show how the\nresulting variational objectives can help improve training and provide fast\ntest time predictions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 00:23:12 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 21:24:56 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Jankowiak", "Martin", ""]]}, {"id": "1811.00688", "submitter": "Ruochen Yang", "authors": "Ruochen Yang, Gaurav Gupta, Paul Bogdan", "title": "Data-driven Perception of Neuron Point Process with Unknown Unknowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of patterns from discrete data time-series for statistical\ninference, threat detection, social opinion dynamics, brain activity prediction\nhas received recent momentum. In addition to the huge data size, the associated\nchallenges are, for example, (i) missing data to construct a closed\ntime-varying complex network, and (ii) contribution of unknown sources which\nare not probed. Towards this end, the current work focuses on statistical\nneuron system model with multi-covariates and unknown inputs. Previous research\nof neuron activity analysis is mainly limited with effects from the spiking\nhistory of target neuron and the interaction with other neurons in the system\nwhile ignoring the influence of unknown stimuli. We propose to use unknown\nunknowns, which describes the effect of unknown stimuli, undetected neuron\nactivities and all other hidden sources of error. The maximum likelihood\nestimation with the fixed-point iteration method is implemented. The\nfixed-point iterations converge fast, and the proposed methods can be\nefficiently parallelized and offer computational advantage especially when the\ninput spiking trains are over long time-horizon. The developed framework\nprovides an intuition into the meaning of having extra degrees-of-freedom in\nthe data to support the need for unknowns. The proposed algorithm is applied to\nsimulated spike trains and on real-world experimental data of mouse\nsomatosensory, mouse retina and cat retina. The model shows a successful\nincreasing of system likelihood with respect to the conditional intensity\nfunction, and it also reveals the convergence with iterations. Results suggest\nthat the neural connection model with unknown unknowns can efficiently estimate\nthe statistical properties of the process by increasing the network likelihood.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 00:42:25 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 06:12:36 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Yang", "Ruochen", ""], ["Gupta", "Gaurav", ""], ["Bogdan", "Paul", ""]]}, {"id": "1811.00703", "submitter": "Gaurav Gupta", "authors": "Gaurav Gupta, Sergio Pequito, Paul Bogdan", "title": "Learning Latent Fractional dynamics with Unknown Unknowns", "comments": "8 pages, 5 figures, American Control Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant effort in understanding complex systems (CS), we lack a\ntheory for modeling, inference, analysis and efficient control of time-varying\ncomplex networks (TVCNs) in uncertain environments. From brain activity\ndynamics to microbiome, and even chromatin interactions within the genome\narchitecture, many such TVCNs exhibits a pronounced spatio-temporal fractality.\nMoreover, for many TVCNs only limited information (e.g., few variables) is\naccessible for modeling, which hampers the capabilities of analytical tools to\nuncover the true degrees of freedom and infer the CS model, the hidden states\nand their parameters. Another fundamental limitation is that of understanding\nand unveiling of unknown drivers of the dynamics that could sporadically excite\nthe network in ways that straightforward modeling does not work due to our\ninability to model non-stationary processes. Towards addressing these\nchallenges, in this paper, we consider the problem of learning the fractional\ndynamical complex networks under unknown unknowns (i.e., hidden drivers) and\npartial observability (i.e., only partial data is available). More precisely,\nwe consider a generalized modeling approach of TVCNs consisting of\ndiscrete-time fractional dynamical equations and propose an iterative framework\nto determine the network parameterization and predict the state of the system.\nWe showcase the performance of the proposed framework in the context of task\nclassification using real electroencephalogram data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 02:01:11 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 20:14:20 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Gupta", "Gaurav", ""], ["Pequito", "Sergio", ""], ["Bogdan", "Paul", ""]]}, {"id": "1811.00706", "submitter": "Luis Borges", "authors": "Lu\\'is Borges, Bruno Martins, P\\'avel Calado", "title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News", "comments": "Accepted for publication in the special issue of the ACM Journal of\n  Data and Information Quality (ACM JDIQ) on Combating Digital Misinformation\n  and Disinformation", "journal-ref": "Journal of Data and Information Quality (JDIQ) 11 (3), 1-26, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 02:13:52 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Borges", "Lu\u00eds", ""], ["Martins", "Bruno", ""], ["Calado", "P\u00e1vel", ""]]}, {"id": "1811.00717", "submitter": "He Zhao", "authors": "He Zhao, Lan Du, Wray Buntine, Mingyuan Zhou", "title": "Dirichlet belief networks for topic structure learning", "comments": "accepted in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, considerable research effort has been devoted to developing deep\narchitectures for topic models to learn topic structures. Although several deep\nmodels have been proposed to learn better topic proportions of documents, how\nto leverage the benefits of deep structures for learning word distributions of\ntopics has not yet been rigorously studied. Here we propose a new multi-layer\ngenerative process on word distributions of topics, where each layer consists\nof a set of topics and each topic is drawn from a mixture of the topics of the\nlayer above. As the topics in all layers can be directly interpreted by words,\nthe proposed model is able to discover interpretable topic hierarchies. As a\nself-contained module, our model can be flexibly adapted to different kinds of\ntopic models to improve their modelling accuracy and interpretability.\nExtensive experiments on text corpora demonstrate the advantages of the\nproposed model.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 02:54:39 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Zhao", "He", ""], ["Du", "Lan", ""], ["Buntine", "Wray", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1811.00741", "submitter": "Pang Wei Koh", "authors": "Pang Wei Koh, Jacob Steinhardt, Percy Liang", "title": "Stronger Data Poisoning Attacks Break Data Sanitization Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models trained on data from the outside world can be\ncorrupted by data poisoning attacks that inject malicious points into the\nmodels' training sets. A common defense against these attacks is data\nsanitization: first filter out anomalous training points before training the\nmodel. Can data poisoning attacks break data sanitization defenses? In this\npaper, we develop three new attacks that can all bypass a broad range of data\nsanitization defenses, including commonly-used anomaly detectors based on\nnearest neighbors, training loss, and singular-value decomposition. For\nexample, our attacks successfully increase the test error on the Enron spam\ndetection dataset from 3% to 24% and on the IMDB sentiment classification\ndataset from 12% to 29% by adding just 3% poisoned data. In contrast, many\nexisting attacks from the literature do not explicitly consider defenses, and\nwe show that those attacks are ineffective in the presence of the defenses we\nconsider. Our attacks are based on two ideas: (i) we coordinate our attacks to\nplace poisoned points near one another, which fools some anomaly detectors, and\n(ii) we formulate each attack as a constrained optimization problem, with\nconstraints designed to ensure that the poisoned points evade detection. While\nthis optimization involves solving an expensive bilevel problem, we explore and\ndevelop three efficient approximations to this problem based on influence\nfunctions; minimax duality; and the Karush-Kuhn-Tucker (KKT) conditions. Our\nresults underscore the urgent need to develop more sophisticated and robust\ndefenses against data poisoning attacks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 05:19:07 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Koh", "Pang Wei", ""], ["Steinhardt", "Jacob", ""], ["Liang", "Percy", ""]]}, {"id": "1811.00749", "submitter": "Shuo Yang", "authors": "Shuo Yang", "title": "Effective Learning of Probabilistic Models for Clinical Predictions from\n  Longitudinal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the expeditious advancement of information technologies, health-related\ndata presented unprecedented potentials for medical and health discoveries but\nat the same time significant challenges for machine learning techniques both in\nterms of size and complexity. Those challenges include: the structured data\nwith various storage formats and value types caused by heterogeneous data\nsources; the uncertainty widely existing in every aspect of medical diagnosis\nand treatments; the high dimensionality of the feature space; the longitudinal\nmedical records data with irregular intervals between adjacent observations;\nthe richness of relations existing among objects with similar genetic factors,\nlocation or socio-demographic background. This thesis aims to develop advanced\nStatistical Relational Learning approaches in order to effectively exploit such\nhealth-related data and facilitate the discoveries in medical research. It\npresents the work on cost-sensitive statistical relational learning for mining\nstructured imbalanced data, the first continuous-time probabilistic logic model\nfor predicting sequential events from longitudinal structured data as well as\nhybrid probabilistic relational models for learning from heterogeneous\nstructured data. It also demonstrates the outstanding performance of these\nproposed models as well as other state of the art machine learning models when\napplied to medical research problems and other real-world large-scale systems,\nreveals the great potential of statistical relational learning for exploring\nthe structured health-related data to facilitate medical research.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 05:59:35 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Yang", "Shuo", ""]]}, {"id": "1811.00753", "submitter": "Kartik Ahuja", "authors": "Kartik Ahuja, Mihaela van der Schaar", "title": "Risk-Stratify: Confident Stratification Of Patients Based On Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A clinician desires to use a risk-stratification method that achieves\nconfident risk-stratification - the risk estimates of the different patients\nreflect the true risks with a high probability. This allows him/her to use\nthese risks to make accurate predictions about prognosis and decisions about\nscreening, treatments for the current patient. We develop Risk-stratify - a two\nphase algorithm that is designed to achieve confident risk-stratification. In\nthe first phase, we grow a tree to partition the covariate space. Each node in\nthe tree is split using statistical tests that determine if the risks of the\nchild nodes are different or not. The choice of the statistical tests depends\non whether the data is censored (Log-rank test) or not (U-test). The set of the\nleaves of the tree form a partition. The risk distribution of patients that\nbelong to a leaf is different from the sibling leaf but not the rest of the\nleaves. Therefore, some of the leaves that have similar underlying risks are\nincorrectly specified to have different risks. In the second phase, we develop\na novel recursive graph decomposition approach to address this problem. We\nmerge the leaves of the tree that have similar risks to form new leaves that\nform the final output. We apply Risk-stratify on a cohort of patients (with no\nhistory of cardiovascular disease) from UK Biobank and assess their risk for\ncardiovascular disease. Risk-stratify significantly improves\nrisk-stratification, i.e., a lower fraction of the groups have over/under\nestimated risks (measured in terms of false discovery rate; 33% reduction) in\ncomparison to state-of-the-art methods for cardiovascular prediction (Random\nforests, Cox model, etc.). We find that the Cox model significantly over\nestimates the risk of 21,621 patients out of 216,211 patients. Risk-stratify\ncan accurately categorize 2,987 of these 21,621 patients as low-risk\nindividuals.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 06:30:52 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Ahuja", "Kartik", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1811.00755", "submitter": "Jialin Song", "authors": "Jialin Song, Yuxin Chen, Yisong Yue", "title": "A General Framework for Multi-fidelity Bayesian Optimization with\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we efficiently gather information to optimize an unknown function,\nwhen presented with multiple, mutually dependent information sources with\ndifferent costs? For example, when optimizing a robotic system, intelligently\ntrading off computer simulations and real robot testings can lead to\nsignificant savings. Existing methods, such as multi-fidelity GP-UCB or Entropy\nSearch-based approaches, either make simplistic assumptions on the interaction\namong different fidelities or use simple heuristics that lack theoretical\nguarantees. In this paper, we study multi-fidelity Bayesian optimization with\ncomplex structural dependencies among multiple outputs, and propose\nMF-MI-Greedy, a principled algorithmic framework for addressing this problem.\nIn particular, we model different fidelities using additive Gaussian processes\nbased on shared latent structures with the target function. Then we use\ncost-sensitive mutual information gain for efficient Bayesian global\noptimization. We propose a simple notion of regret which incorporates the cost\nof different fidelities, and prove that MF-MI-Greedy achieves low regret. We\ndemonstrate the strong empirical performance of our algorithm on both synthetic\nand real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 06:36:13 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Song", "Jialin", ""], ["Chen", "Yuxin", ""], ["Yue", "Yisong", ""]]}, {"id": "1811.00761", "submitter": "Riza Ozcelik", "authors": "R{\\i}za \\\"Oz\\c{c}elik, Hakime \\\"Ozt\\\"urk, Arzucan \\\"Ozg\\\"ur, Elif\n  Ozkirimli", "title": "ChemBoost: A chemical language based approach for protein-ligand binding\n  affinity prediction", "comments": "Molecular Informatics", "journal-ref": null, "doi": "10.1002/minf.202000212", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of high affinity drug-target interactions is a major research\nquestion in drug discovery. Proteins are generally represented by their\nstructures or sequences. However, structures are available only for a small\nsubset of biomolecules and sequence similarity is not always correlated with\nfunctional similarity. We propose ChemBoost, a chemical language based approach\nfor affinity prediction using SMILES syntax. We hypothesize that SMILES is a\ncodified language and ligands are documents composed of chemical words. These\ndocuments can be used to learn chemical word vectors that represent words in\nsimilar contexts with similar vectors. In ChemBoost, the ligands are\nrepresented via chemical word embeddings, while the proteins are represented\nthrough sequence-based features and/or chemical words of their ligands. Our aim\nis to process the patterns in SMILES as a language to predict protein-ligand\naffinity, even when we cannot infer the function from the sequence. We used\neXtreme Gradient Boosting to predict protein-ligand affinities in KIBA and\nBindingDB data sets. ChemBoost was able to predict drug-target binding affinity\nas well as or better than state-of-the-art machine learning systems. When\npowered with ligand-centric representations, ChemBoost was more robust to the\nchanges in protein sequence similarity and successfully captured the\ninteractions between a protein and a ligand, even if the protein has low\nsequence similarity to the known targets of the ligand.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 07:29:56 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 10:28:40 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 21:48:20 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["\u00d6z\u00e7elik", "R\u0131za", ""], ["\u00d6zt\u00fcrk", "Hakime", ""], ["\u00d6zg\u00fcr", "Arzucan", ""], ["Ozkirimli", "Elif", ""]]}, {"id": "1811.00784", "submitter": "Jamie Caldwell", "authors": "J. R. Caldwell, R. A. Watson, C. Thies and J. D. Knowles", "title": "Deep Optimisation: Solving Combinatorial Optimisation Problems using\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Optimisation (DO) combines evolutionary search with Deep Neural Networks\n(DNNs) in a novel way - not for optimising a learning algorithm, but for\nfinding a solution to an optimisation problem. Deep learning has been\nsuccessfully applied to classification, regression, decision and generative\ntasks and in this paper we extend its application to solving optimisation\nproblems. Model Building Optimisation Algorithms (MBOAs), a branch of\nevolutionary algorithms, have been successful in combining machine learning\nmethods and evolutionary search but, until now, they have not utilised DNNs. DO\nis the first algorithm to use a DNN to learn and exploit the problem structure\nto adapt the variation operator (changing the neighbourhood structure of the\nsearch process). We demonstrate the performance of DO using two theoretical\noptimisation problems within the MAXSAT class. The Hierarchical Transformation\nOptimisation Problem (HTOP) has controllable deep structure that provides a\nclear evaluation of how DO works and why using a layerwise technique is\nessential for learning and exploiting problem structure. The Parity Modular\nConstraint Problem (MCparity) is a simplistic example of a problem containing\nhigher-order dependencies (greater than pairwise) which DO can solve and state\nof the art MBOAs cannot. Further, we show that DO can exploit deep structure in\nTSP instances. Together these results show that there exists problems that DO\ncan find and exploit deep problem structure that other algorithms cannot.\nMaking this connection between DNNs and optimisation allows for the utilisation\nof advanced tools applicable to DNNs that current MBOAs are unable to use.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 09:04:29 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Caldwell", "J. R.", ""], ["Watson", "R. A.", ""], ["Thies", "C.", ""], ["Knowles", "J. D.", ""]]}, {"id": "1811.00796", "submitter": "Mitsuru Kusumoto", "authors": "Mitsuru Kusumoto, Keisuke Yahata, Masahiro Sakai", "title": "Automated Theorem Proving in Intuitionistic Propositional Logic by Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem-solving in automated theorem proving (ATP) can be interpreted as\na search problem where the prover constructs a proof tree step by step. In this\npaper, we propose a deep reinforcement learning algorithm for proof search in\nintuitionistic propositional logic. The most significant challenge in the\napplication of deep learning to the ATP is the absence of large, public theorem\ndatabase. We, however, overcame this issue by applying a novel data\naugmentation procedure at each iteration of the reinforcement learning. We also\nimprove the efficiency of the algorithm by representing the syntactic structure\nof formulas by a novel compact graph representation. Using the large volume of\naugmented data, we train highly accurate graph neural networks that approximate\nthe value function for the set of the syntactic structures of formulas. Our\nmethod is also cost-efficient in terms of computational time. We will show that\nour prover outperforms Coq's $\\texttt{tauto}$ tactic, a prover based on\nhuman-engineered heuristics. Within the specified time limit, our prover solved\n84% of the theorems in a benchmark library, while $\\texttt{tauto}$ was able to\nsolve only 52%.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 09:49:18 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Kusumoto", "Mitsuru", ""], ["Yahata", "Keisuke", ""], ["Sakai", "Masahiro", ""]]}, {"id": "1811.00821", "submitter": "Mireille El Gheche", "authors": "Mireille El Gheche and Giovanni Chierchia and Pascal Frossard", "title": "OrthoNet: Multilayer Network Data Clustering", "comments": null, "journal-ref": "IEEE Transactions on Signal and Information Processing over\n  Networks, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network data appears in very diverse applications, like biological, social,\nor sensor networks. Clustering of network nodes into categories or communities\nhas thus become a very common task in machine learning and data mining. Network\ndata comes with some information about the network edges. In some cases, this\nnetwork information can even be given with multiple views or multiple layers,\neach one representing a different type of relationship between the network\nnodes. Increasingly often, network nodes also carry a feature vector. We\npropose in this paper to extend the node clustering problem, that commonly\nconsiders only the network information, to a problem where both the network\ninformation and the node features are considered together for learning a\nclustering-friendly representation of the feature space. Specifically, we\ndesign a generic two-step algorithm for multilayer network data clustering. The\nfirst step aggregates the different layers of network information into a graph\nrepresentation given by the geometric mean of the network Laplacian matrices.\nThe second step uses a neural net to learn a feature embedding that is\nconsistent with the structure given by the network layers. We propose a novel\nalgorithm for efficiently training the neural net via stochastic gradient\ndescent, which encourages the neural net outputs to span the leading\neigenvectors of the aggregated Laplacian matrix, in order to capture the\npairwise interactions on the network, and provide a clustering-friendly\nrepresentation of the feature space. We demonstrate with an extensive set of\nexperiments on synthetic and real datasets that our method leads to a\nsignificant improvement w.r.t. state-of-the-art multilayer graph clustering\nalgorithms, as it judiciously combines nodes features and network information\nin the node embedding algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 11:12:49 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 13:52:55 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 08:25:56 GMT"}, {"version": "v4", "created": "Tue, 2 Jul 2019 12:05:43 GMT"}, {"version": "v5", "created": "Thu, 23 Jan 2020 09:13:20 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Gheche", "Mireille El", ""], ["Chierchia", "Giovanni", ""], ["Frossard", "Pascal", ""]]}, {"id": "1811.00836", "submitter": "Shayan Aziznejad", "authors": "Shayan Aziznejad, Michael Unser", "title": "Multi-Kernel Regression with Sparsity Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a Banach-space formulation of supervised learning\nwith generalized total-variation (gTV) regularization. We identify the class of\nkernel functions that are admissible in this framework. Then, we propose a\nvariation of supervised learning in a continuous-domain hybrid search space\nwith gTV regularization. We show that the solution admits a multi-kernel\nexpansion with adaptive positions. In this representation, the number of active\nkernels is upper-bounded by the number of data points while the gTV\nregularization imposes an $\\ell_1$ penalty on the kernel coefficients. Finally,\nwe illustrate numerically the outcome of our theory.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 12:34:12 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 15:37:03 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 14:34:09 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 10:17:35 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Aziznejad", "Shayan", ""], ["Unser", "Michael", ""]]}, {"id": "1811.00849", "submitter": "Yasha Singh Ms", "authors": "Yasha Singh, Dhruv Srivastava, P.S. Chandranand, Dr. Surinder Singh", "title": "Algorithms for screening of Cervical Cancer: A chronological review", "comments": "This critical review of various machine learning algorithms for\n  Cervical Cancer Screening was completed at National Institute of\n  Biologicals(NIB), India by B.Tech final year Computer Science students at\n  JSSATE, Noida, India under the supervision of Director at NIB Dr. Surinder\n  Singh and Jr. Scientist Sh. P.S. Chandranand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are various algorithms and methodologies used for automated screening\nof cervical cancer by segmenting and classifying cervical cancer cells into\ndifferent categories. This study presents a critical review of different\nresearch papers published that integrated AI methods in screening cervical\ncancer via different approaches analyzed in terms of typical metrics like\ndataset size, drawbacks, accuracy etc. An attempt has been made to furnish the\nreader with an insight of Machine Learning algorithms like SVM (Support Vector\nMachines), GLCM (Gray Level Co-occurrence Matrix), k-NN (k-Nearest Neighbours),\nMARS (Multivariate Adaptive Regression Splines), CNNs (Convolutional Neural\nNetworks), spatial fuzzy clustering algorithms, PNNs (Probabilistic Neural\nNetworks), Genetic Algorithm, RFT (Random Forest Trees), C5.0, CART\n(Classification and Regression Trees) and Hierarchical clustering algorithm for\nfeature extraction, cell segmentation and classification. This paper also\ncovers the publicly available datasets related to cervical cancer. It presents\na holistic review on the computational methods that have evolved over the\nperiod of time, in chronological order in detection of malignant cells.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 13:31:27 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Singh", "Yasha", ""], ["Srivastava", "Dhruv", ""], ["Chandranand", "P. S.", ""], ["Singh", "Dr. Surinder", ""]]}, {"id": "1811.00855", "submitter": "Yanqiao Zhu", "authors": "Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan", "title": "Session-based Recommendation with Graph Neural Networks", "comments": "9 pages, 4 figures, accepted by AAAI Conference on Artificial\n  Intelligence (AAAI-19)", "journal-ref": null, "doi": "10.1609/aaai.v33i01.3301346", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of session-based recommendation aims to predict user actions\nbased on anonymous sessions. Previous methods model a session as a sequence and\nestimate user representations besides item representations to make\nrecommendations. Though achieved promising results, they are insufficient to\nobtain accurate user vectors in sessions and neglect complex transitions of\nitems. To obtain accurate item embedding and take complex transitions of items\ninto account, we propose a novel method, i.e. Session-based Recommendation with\nGraph Neural Networks, SR-GNN for brevity. In the proposed method, session\nsequences are modeled as graph-structured data. Based on the session graph, GNN\ncan capture complex transitions of items, which are difficult to be revealed by\nprevious conventional sequential methods. Each session is then represented as\nthe composition of the global preference and the current interest of that\nsession using an attention network. Extensive experiments conducted on two real\ndatasets show that SR-GNN evidently outperforms the state-of-the-art\nsession-based recommendation methods consistently.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 02:44:16 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 04:47:18 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 04:41:34 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 08:12:19 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Wu", "Shu", ""], ["Tang", "Yuyuan", ""], ["Zhu", "Yanqiao", ""], ["Wang", "Liang", ""], ["Xie", "Xing", ""], ["Tan", "Tieniu", ""]]}, {"id": "1811.00866", "submitter": "Tsui-Wei Weng", "authors": "Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel", "title": "Efficient Neural Network Robustness Certification with General\n  Activation Functions", "comments": "Accepted by NIPS 2018. Huan Zhang and Tsui-Wei Weng contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding minimum distortion of adversarial examples and thus certifying\nrobustness in neural network classifiers for given data points is known to be a\nchallenging problem. Nevertheless, recently it has been shown to be possible to\ngive a non-trivial certified lower bound of minimum adversarial distortion, and\nsome recent progress has been made towards this direction by exploiting the\npiece-wise linear nature of ReLU activations. However, a generic robustness\ncertification for general activation functions still remains largely\nunexplored. To address this issue, in this paper we introduce CROWN, a general\nframework to certify robustness of neural networks with general activation\nfunctions for given input data points. The novelty in our algorithm consists of\nbounding a given activation function with linear and quadratic functions, hence\nallowing it to tackle general activation functions including but not limited to\nfour popular choices: ReLU, tanh, sigmoid and arctan. In addition, we\nfacilitate the search for a tighter certified lower bound by adaptively\nselecting appropriate surrogates for each neuron activation. Experimental\nresults show that CROWN on ReLU networks can notably improve the certified\nlower bounds compared to the current state-of-the-art algorithm Fast-Lin, while\nhaving comparable computational efficiency. Furthermore, CROWN also\ndemonstrates its effectiveness and flexibility on networks with general\nactivation functions, including tanh, sigmoid and arctan.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 14:03:25 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Zhang", "Huan", ""], ["Weng", "Tsui-Wei", ""], ["Chen", "Pin-Yu", ""], ["Hsieh", "Cho-Jui", ""], ["Daniel", "Luca", ""]]}, {"id": "1811.00883", "submitter": "Bin Liu", "authors": "Bin Liu, Shuai Nie, Yaping Zhang, Shan Liang, Wenju Liu", "title": "Deep Segment Attentive Embedding for Duration Robust Speaker\n  Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTM-based speaker verification usually uses a fixed-length local segment\nrandomly truncated from an utterance to learn the utterance-level speaker\nembedding, while using the average embedding of all segments of a test\nutterance to verify the speaker, which results in a critical mismatch between\ntesting and training. This mismatch degrades the performance of speaker\nverification, especially when the durations of training and testing utterances\nare very different. To alleviate this issue, we propose the deep segment\nattentive embedding method to learn the unified speaker embeddings for\nutterances of variable duration. Each utterance is segmented by a sliding\nwindow and LSTM is used to extract the embedding of each segment. Instead of\nonly using one local segment, we use the whole utterance to learn the\nutterance-level embedding by applying an attentive pooling to the embeddings of\nall segments. Moreover, the similarity loss of segment-level embeddings is\nintroduced to guide the segment attention to focus on the segments with more\nspeaker discriminations, and jointly optimized with the similarity loss of\nutterance-level embeddings. Systematic experiments on Tongdun and VoxCeleb show\nthat the proposed method significantly improves robustness of duration variant\nand achieves the relative Equal Error Rate reduction of 50% and 11.54% ,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 01:21:41 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Liu", "Bin", ""], ["Nie", "Shuai", ""], ["Zhang", "Yaping", ""], ["Liang", "Shan", ""], ["Liu", "Wenju", ""]]}, {"id": "1811.00890", "submitter": "Maria I. Gorinova", "authors": "Maria I. Gorinova, Andrew D. Gordon, Charles Sutton", "title": "Probabilistic Programming with Densities in SlicStan: Efficient,\n  Flexible and Deterministic", "comments": null, "journal-ref": "Proc. ACM Program. Lang. 3, POPL, Article 35 (January 2019)", "doi": "10.1145/3290348", "report-no": null, "categories": "cs.PL stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stan is a probabilistic programming language that has been increasingly used\nfor real-world scalable projects. However, to make practical inference\npossible, the language sacrifices some of its usability by adopting a block\nsyntax, which lacks compositionality and flexible user-defined functions.\nMoreover, the semantics of the language has been mainly given in terms of\nintuition about implementation, and has not been formalised.\n  This paper provides a formal treatment of the Stan language, and introduces\nthe probabilistic programming language SlicStan --- a compositional,\nself-optimising version of Stan. Our main contributions are: (1) the\nformalisation of a core subset of Stan through an operational density-based\nsemantics; (2) the design and semantics of the Stan-like language SlicStan,\nwhich facilities better code reuse and abstraction through its compositional\nsyntax, more flexible functions, and information-flow type system; and (3) a\nformal, semantic-preserving procedure for translating SlicStan to Stan.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 14:34:34 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Gorinova", "Maria I.", ""], ["Gordon", "Andrew D.", ""], ["Sutton", "Charles", ""]]}, {"id": "1811.00894", "submitter": "Anthony Bagnall Dr", "authors": "James Large and Paul Southam and Anthony Bagnall", "title": "Can automated smoothing significantly improve benchmark time series\n  classification algorithms?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  tl;dr: no, it cannot, at least not on average on the standard archive\nproblems. We assess whether using six smoothing algorithms (moving average,\nexponential smoothing, Gaussian filter, Savitzky-Golay filter, Fourier\napproximation and a recursive median sieve) could be automatically applied to\ntime series classification problems as a preprocessing step to improve the\nperformance of three benchmark classifiers (1-Nearest Neighbour with Euclidean\nand Dynamic Time Warping distances, and Rotation Forest). We found no\nsignificant improvement over unsmoothed data even when we set the smoothing\nparameter through cross validation. We are not claiming smoothing has no worth.\nIt has an important role in exploratory analysis and helps with specific\nclassification problems where domain knowledge can be exploited. What we\nobserve is that the automatic application does not help and that we cannot\nexplain the improvement of other time series classification algorithms over the\nbaseline classifiers simply as a function of the absence of smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 12:41:24 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Large", "James", ""], ["Southam", "Paul", ""], ["Bagnall", "Anthony", ""]]}, {"id": "1811.00908", "submitter": "Natasa Tagasovska", "authors": "Natasa Tagasovska, David Lopez-Paz", "title": "Single-Model Uncertainties for Deep Learning", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide single-model estimates of aleatoric and epistemic uncertainty for\ndeep neural networks. To estimate aleatoric uncertainty, we propose\nSimultaneous Quantile Regression (SQR), a loss function to learn all the\nconditional quantiles of a given target variable. These quantiles can be used\nto compute well-calibrated prediction intervals. To estimate epistemic\nuncertainty, we propose Orthonormal Certificates (OCs), a collection of diverse\nnon-constant functions that map all training samples to zero. These\ncertificates map out-of-distribution examples to non-zero values, signaling\nepistemic uncertainty. Our uncertainty estimators are computationally\nattractive, as they do not require ensembling or retraining deep models, and\nachieve competitive performance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 14:55:07 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 16:45:59 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 13:38:18 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Tagasovska", "Natasa", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1811.00911", "submitter": "Gaurush Hiranandani", "authors": "Prakhar Gupta, Gaurush Hiranandani, Harvineet Singh, Branislav Kveton,\n  Zheng Wen, Iftikhar Ahamath Burhanuddin", "title": "Online Diverse Learning to Rank from Partial-Click Feedback", "comments": "The first three authors contributed equally to this work. 24 pages, 4\n  figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to rank is an important problem in machine learning and recommender\nsystems. In a recommender system, a user is typically recommended a list of\nitems. Since the user is unlikely to examine the entire recommended list,\npartial feedback arises naturally. At the same time, diverse recommendations\nare important because it is challenging to model all tastes of the user in\npractice. In this paper, we propose the first algorithm for online learning to\nrank diverse items from partial-click feedback. We assume that the user\nexamines the list of recommended items until the user is attracted by an item,\nwhich is clicked, and does not examine the rest of the items. This model of\nuser behavior is known as the cascade model. We propose an online learning\nalgorithm, cascadelsb, for solving our problem. The algorithm actively explores\nthe tastes of the user with the objective of learning to recommend the optimal\ndiverse list. We analyze the algorithm and prove a gap-free upper bound on its\nn-step regret. We evaluate cascadelsb on both synthetic and real-world\ndatasets, compare it to various baselines, and show that it learns even when\nour modeling assumptions do not hold exactly.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:10:00 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 17:36:49 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Gupta", "Prakhar", ""], ["Hiranandani", "Gaurush", ""], ["Singh", "Harvineet", ""], ["Kveton", "Branislav", ""], ["Wen", "Zheng", ""], ["Burhanuddin", "Iftikhar Ahamath", ""]]}, {"id": "1811.00915", "submitter": "Matthias Eberlein", "authors": "Matthias Eberlein, Raphael Hildebrand, Ronald Tetzlaff, Nico Hoffmann,\n  Levin Kuhlmann, Benjamin Brinkmann and Jens M\\\"uller", "title": "Convolutional Neural Networks for Epileptic Seizure Prediction", "comments": "accepted for MLESP 2018", "journal-ref": "2018 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM)", "doi": "10.1109/BIBM.2018.8621225", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is the most common neurological disorder and an accurate forecast of\nseizures would help to overcome the patient's uncertainty and helplessness. In\nthis contribution, we present and discuss a novel methodology for the\nclassification of intracranial electroencephalography (iEEG) for seizure\nprediction. Contrary to previous approaches, we categorically refrain from an\nextraction of hand-crafted features and use a convolutional neural network\n(CNN) topology instead for both the determination of suitable signal\ncharacteristics and the binary classification of preictal and interictal\nsegments. Three different models have been evaluated on public datasets with\nlong-term recordings from four dogs and three patients. Overall, our findings\ndemonstrate the general applicability. In this work we discuss the strengths\nand limitations of our methodology.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:09:18 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 13:58:56 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Eberlein", "Matthias", ""], ["Hildebrand", "Raphael", ""], ["Tetzlaff", "Ronald", ""], ["Hoffmann", "Nico", ""], ["Kuhlmann", "Levin", ""], ["Brinkmann", "Benjamin", ""], ["M\u00fcller", "Jens", ""]]}, {"id": "1811.00928", "submitter": "Micha\\\"el Perrot", "authors": "Debarghya Ghoshdastidar, Micha\\\"el Perrot, Ulrike von Luxburg", "title": "Foundations of Comparison-Based Hierarchical Clustering", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the classical problem of hierarchical clustering, but in a\nframework where one does not have access to a representation of the objects or\ntheir pairwise similarities. Instead, we assume that only a set of comparisons\nbetween objects is available, that is, statements of the form \"objects $i$ and\n$j$ are more similar than objects $k$ and $l$.\" Such a scenario is commonly\nencountered in crowdsourcing applications. The focus of this work is to develop\ncomparison-based hierarchical clustering algorithms that do not rely on the\nprinciples of ordinal embedding. We show that single and complete linkage are\ninherently comparison-based and we develop variants of average linkage. We\nprovide statistical guarantees for the different methods under a planted\nhierarchical partition model. We also empirically demonstrate the performance\nof the proposed approaches on several datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:17:48 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:37:27 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ghoshdastidar", "Debarghya", ""], ["Perrot", "Micha\u00ebl", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1811.00944", "submitter": "Alexander Wein", "authors": "Ankur Moitra and Alexander S. Wein", "title": "Spectral Methods from Tensor Networks", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tensor network is a diagram that specifies a way to \"multiply\" a collection\nof tensors together to produce another tensor (or matrix). Many existing\nalgorithms for tensor problems (such as tensor decomposition and tensor PCA),\nalthough they are not presented this way, can be viewed as spectral methods on\nmatrices built from simple tensor networks. In this work we leverage the full\npower of this abstraction to design new algorithms for certain continuous\ntensor decomposition problems.\n  An important and challenging family of tensor problems comes from orbit\nrecovery, a class of inference problems involving group actions (inspired by\napplications such as cryo-electron microscopy). Orbit recovery problems over\nfinite groups can often be solved via standard tensor methods. However, for\ninfinite groups, no general algorithms are known. We give a new spectral\nalgorithm based on tensor networks for one such problem: continuous\nmulti-reference alignment over the infinite group SO(2). Our algorithm extends\nto the more general heterogeneous case.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:52:35 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Moitra", "Ankur", ""], ["Wein", "Alexander S.", ""]]}, {"id": "1811.00956", "submitter": "Shahina Rahman", "authors": "Shahina Rahman and Valen E. Johnson", "title": "A Fast Algorithm for Clustering High Dimensional Feature Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for clustering high dimensional data. If $P$ features\nfor $N$ objects are represented in an $N\\times P$ matrix ${\\bf X}$, where $N\\ll\nP$, the method is based on exploiting the cluster-dependent structure of the\n$N\\times N$ matrix ${\\bf XX}^T$. Computational burden thus depends primarily on\n$N$, the number of objects to be clustered, rather than $P$, the number of\nfeatures that are measured. This makes the method particularly useful in high\ndimensional settings, where it is substantially faster than a number of other\npopular clustering algorithms. Aside from an upper bound on the number of\npotential clusters, the method is independent of tuning parameters. When\ncompared to $16$ other clustering algorithms on $32$ genomic datasets with gold\nstandards, we show that it provides the most accurate cluster configuration\nmore than twice as often than its closest competitors. We illustrate the method\non data taken from highly cited genomic studies.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:11:31 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Rahman", "Shahina", ""], ["Johnson", "Valen E.", ""]]}, {"id": "1811.00958", "submitter": "Bo Liu", "authors": "Bo Liu and Luwan Zhang and Ji Liu", "title": "Dantzig Selector with an Approximately Optimal Denoising Matrix and its\n  Application to Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dantzig Selector (DS) is widely used in compressed sensing and sparse\nlearning for feature selection and sparse signal recovery. Since the DS\nformulation is essentially a linear programming optimization, many existing\nlinear programming solvers can be simply applied for scaling up. The DS\nformulation can be explained as a basis pursuit denoising problem, wherein the\ndata matrix (or measurement matrix) is employed as the denoising matrix to\neliminate the observation noise. However, we notice that the data matrix may\nnot be the optimal denoising matrix, as shown by a simple counter-example. This\nmotivates us to pursue a better denoising matrix for defining a general DS\nformulation. We first define the optimal denoising matrix through a minimax\noptimization, which turns out to be an NPhard problem. To make the problem\ncomputationally tractable, we propose a novel algorithm, termed as Optimal\nDenoising Dantzig Selector (ODDS), to approximately estimate the optimal\ndenoising matrix. Empirical experiments validate the proposed method. Finally,\na novel sparse reinforcement learning algorithm is formulated by extending the\nproposed ODDS algorithm to temporal difference learning, and empirical\nexperimental results demonstrate to outperform the conventional vanilla DS-TD\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:15:14 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Liu", "Bo", ""], ["Zhang", "Luwan", ""], ["Liu", "Ji", ""]]}, {"id": "1811.00971", "submitter": "Eren Balevi", "authors": "Eren Balevi and Jeffrey G. Andrews", "title": "One-Bit OFDM Receivers via Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops novel deep learning-based architectures and design\nmethodologies for an orthogonal frequency division multiplexing (OFDM) receiver\nunder the constraint of one-bit complex quantization. Single bit quantization\ngreatly reduces complexity and power consumption, but makes accurate channel\nestimation and data detection difficult. This is particularly true for\nmulticarrier waveforms, which have high peak-to-average ratio in the time\ndomain and fragile subcarrier orthogonality in the frequency domain. The severe\ndistortion for one-bit quantization typically results in an error floor even at\nmoderately low signal-to-noise-ratio (SNR) such as 5 dB. For channel estimation\n(using pilots), we design a novel generative supervised deep neural network\n(DNN) that can be trained with a reasonable number of pilots. After channel\nestimation, a neural network-based receiver -- specifically, an autoencoder --\njointly learns a precoder and decoder for data symbol detection. Since\nquantization prevents end-to-end training, we propose a two-step sequential\ntraining policy for this model. With synthetic data, our deep learning-based\nchannel estimation can outperform least squares (LS) channel estimation for\nunquantized (full-resolution) OFDM at average SNRs up to 14 dB. For data\ndetection, our proposed design achieves lower bit error rate (BER) in fading\nthan unquantized OFDM at average SNRs up to 10 dB.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:36:25 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 23:33:46 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Balevi", "Eren", ""], ["Andrews", "Jeffrey G.", ""]]}, {"id": "1811.00972", "submitter": "Naman Deep Singh", "authors": "Naman D. Singh and Abhinav Dhall", "title": "Clustering and Learning from Imbalanced Data", "comments": "9 pages, To Appear at NIPS 2018 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning classifier must outperform a trivial solution, in case of\nimbalanced data, this condition usually does not hold true. To overcome this\nproblem, we propose a novel data level resampling method - Clustering Based\nOversampling for improved learning from class imbalanced datasets. The\nessential idea behind the proposed method is to use the distance between a\nminority class sample and its respective cluster centroid to infer the number\nof new sample points to be generated for that minority class sample. The\nproposed algorithm has very less dependence on the technique used for finding\ncluster centroids and does not effect the majority class learning in any way.\nIt also improves learning from imbalanced data by incorporating the\ndistribution structure of minority class samples in generation of new data\nsamples. The newly generated minority class data is handled in a way as to\nprevent outlier production and overfitting. Implementation analysis on\ndifferent datasets using deep neural networks as the learning classifier shows\nthe effectiveness of this method as compared to other synthetic data resampling\ntechniques across several evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:37:09 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 06:05:58 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Singh", "Naman D.", ""], ["Dhall", "Abhinav", ""]]}, {"id": "1811.00974", "submitter": "Pawel Chilinski", "authors": "Pawel Chilinski and Ricardo Silva", "title": "Neural Likelihoods via Cumulative Distribution Functions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage neural networks as universal approximators of monotonic functions\nto build a parameterization of conditional cumulative distribution functions\n(CDFs). By the application of automatic differentiation with respect to\nresponse variables and then to parameters of this CDF representation, we are\nable to build black box CDF and density estimators. A suite of families is\nintroduced as alternative constructions for the multivariate case. At one\nextreme, the simplest construction is a competitive density estimator against\nstate-of-the-art deep learning methods, although it does not provide an easily\ncomputable representation of multivariate CDFs. At the other extreme, we have a\nflexible construction from which multivariate CDF evaluations and\nmarginalizations can be obtained by a simple forward pass in a deep neural net,\nbut where the computation of the likelihood scales exponentially with\ndimensionality. Alternatives in between the extremes are discussed. We evaluate\nthe different representations empirically on a variety of tasks involving tail\narea probabilities, tail dependence and (partial) density estimation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:40:21 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 12:08:43 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chilinski", "Pawel", ""], ["Silva", "Ricardo", ""]]}, {"id": "1811.00980", "submitter": "Shiqian Ma", "authors": "Shixiang Chen, Shiqian Ma, Anthony Man-Cho So, Tong Zhang", "title": "Proximal Gradient Method for Nonsmooth Optimization over the Stiefel\n  Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimization problems over the Stiefel manifold whose objective\nfunction is the summation of a smooth function and a nonsmooth function.\nExisting methods for solving this kind of problems can be classified into three\nclasses. Algorithms in the first class rely on information of the subgradients\nof the objective function and thus tend to converge slowly in practice.\nAlgorithms in the second class are proximal point algorithms, which involve\nsubproblems that can be as difficult as the original problem. Algorithms in the\nthird class are based on operator-splitting techniques, but they usually lack\nrigorous convergence guarantees. In this paper, we propose a retraction-based\nproximal gradient method for solving this class of problems. We prove that the\nproposed method globally converges to a stationary point. Iteration complexity\nfor obtaining an $\\epsilon$-stationary solution is also analyzed. Numerical\nresults on solving sparse PCA and compressed modes problems are reported to\ndemonstrate the advantages of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:52:39 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 23:08:53 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Chen", "Shixiang", ""], ["Ma", "Shiqian", ""], ["So", "Anthony Man-Cho", ""], ["Zhang", "Tong", ""]]}, {"id": "1811.00986", "submitter": "Loek Tonnaer", "authors": "Nazly Rocio Santos Buitrago (1), Loek Tonnaer (1), Vlado Menkovski\n  (1), Dimitrios Mavroeidis (2) ((1) Eindhoven University of Technology,\n  Eindhoven, The Netherlands, (2) Royal Philips B.V., Eindhoven, The\n  Netherlands)", "title": "Anomaly Detection for imbalanced datasets with Deep Generative Models", "comments": "15 pages, 13 figures, accepted by Benelearn 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important data analysis applications present with severely imbalanced\ndatasets with respect to the target variable. A typical example is medical\nimage analysis, where positive samples are scarce, while performance is\ncommonly estimated against the correct detection of these positive examples. We\napproach this challenge by formulating the problem as anomaly detection with\ngenerative models. We train a generative model without supervision on the\n`negative' (common) datapoints and use this model to estimate the likelihood of\nunseen data. A successful model allows us to detect the `positive' case as low\nlikelihood datapoints.\n  In this position paper, we present the use of state-of-the-art deep\ngenerative models (GAN and VAE) for the estimation of a likelihood of the data.\nOur results show that on the one hand both GANs and VAEs are able to separate\nthe `positive' and `negative' samples in the MNIST case. On the other hand, for\nthe NLST case, neither GANs nor VAEs were able to capture the complexity of the\ndata and discriminate anomalies at the level that this task requires. These\nresults show that even though there are a number of successes presented in the\nliterature for using generative models in similar applications, there remain\nfurther challenges for broad successful implementation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 17:08:31 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Buitrago", "Nazly Rocio Santos", ""], ["Tonnaer", "Loek", ""], ["Menkovski", "Vlado", ""], ["Mavroeidis", "Dimitrios", ""]]}, {"id": "1811.00995", "submitter": "J\\\"orn-Henrik Jacobsen", "authors": "Jens Behrmann, Will Grathwohl, Ricky T. Q. Chen, David Duvenaud,\n  J\\\"orn-Henrik Jacobsen", "title": "Invertible Residual Networks", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning\n  (ICML), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that standard ResNet architectures can be made invertible, allowing\nthe same model to be used for classification, density estimation, and\ngeneration. Typically, enforcing invertibility requires partitioning dimensions\nor restricting network architectures. In contrast, our approach only requires\nadding a simple normalization step during training, already available in\nstandard frameworks. Invertible ResNets define a generative model which can be\ntrained by maximum likelihood on unlabeled data. To compute likelihoods, we\nintroduce a tractable approximation to the Jacobian log-determinant of a\nresidual block. Our empirical evaluation shows that invertible ResNets perform\ncompetitively with both state-of-the-art image classifiers and flow-based\ngenerative models, something that has not been previously achieved with a\nsingle architecture.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 17:17:55 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 17:18:26 GMT"}, {"version": "v3", "created": "Sat, 18 May 2019 18:19:33 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Behrmann", "Jens", ""], ["Grathwohl", "Will", ""], ["Chen", "Ricky T. Q.", ""], ["Duvenaud", "David", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""]]}, {"id": "1811.01017", "submitter": "Emmanouil Theodosis", "authors": "Emmanouil Theodosis and Petros Maragos", "title": "An Adaptive Pruning Algorithm for Spoofing Localisation Based on\n  Tropical Geometry", "comments": "Under review for the International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of spoofing attacks is increasingly relevant as digital systems\nare becoming more ubiquitous. Thus the detection of such attacks and the\nlocalisation of attackers have been objects of recent study. After an attack\nhas been detected, various algorithms have been proposed in order to localise\nthe attacker. In this work we propose a new adaptive pruning algorithm inspired\nby the tropical and geometrical analysis of the traditional Viterbi pruning\nalgorithm to solve the localisation problem. In particular, the proposed\nalgorithm tries to localise the attacker by adapting the leniency parameter\nbased on estimates about the state of the solution space. These estimates stem\nfrom the enclosed volume and the entropy of the solution space, as they were\nintroduced in our previous works.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 18:19:42 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Theodosis", "Emmanouil", ""], ["Maragos", "Petros", ""]]}, {"id": "1811.01031", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, Rehan Ahmed,\n  Muhammad Shafique", "title": "TrISec: Training Data-Unaware Imperceptible Security Attacks on Deep\n  Neural Networks", "comments": null, "journal-ref": "2019 IEEE 25th International Symposium on On-Line Testing and\n  Robust System Design (IOLTS), Rhodes, Greece, 2019, pp. 188-193", "doi": "10.1109/IOLTS.2019.8854425", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the data manipulation attacks on deep neural networks (DNNs) during\nthe training stage introduce a perceptible noise that can be catered by\npreprocessing during inference or can be identified during the validation\nphase. Therefore, data poisoning attacks during inference (e.g., adversarial\nattacks) are becoming more popular. However, many of them do not consider the\nimperceptibility factor in their optimization algorithms, and can be detected\nby correlation and structural similarity analysis, or noticeable (e.g., by\nhumans) in a multi-level security system. Moreover, the majority of the\ninference attack relies on some knowledge about the training dataset. In this\npaper, we propose a novel methodology which automatically generates\nimperceptible attack images by using the back-propagation algorithm on\npre-trained DNNs, without requiring any information about the training dataset\n(i.e., completely training data-unaware). We present a case study on traffic\nsign detection using the VGGNet trained on the German Traffic Sign Recognition\nBenchmarks dataset in an autonomous driving use case. Our results demonstrate\nthat the generated attack images successfully perform misclassification while\nremaining imperceptible in both \"subjective\" and \"objective\" quality tests.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 18:21:17 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 22:51:49 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 10:20:06 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Ahmed", "Rehan", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01054", "submitter": "Kaiyi Ji", "authors": "Kaiyi Ji and Yingbin Liang", "title": "Minimax Estimation of Neural Net Distance", "comments": "To appear in Proc. NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important class of distance metrics proposed for training generative\nadversarial networks (GANs) is the integral probability metric (IPM), in which\nthe neural net distance captures the practical GAN training via two neural\nnetworks. This paper investigates the minimax estimation problem of the neural\nnet distance based on samples drawn from the distributions. We develop the\nfirst known minimax lower bound on the estimation error of the neural net\ndistance, and an upper bound tighter than an existing bound on the estimator\nerror for the empirical neural net distance. Our lower and upper bounds match\nnot only in the order of the sample size but also in terms of the norm of the\nparameter matrices of neural networks, which justifies the empirical neural net\ndistance as a good approximation of the true neural net distance for training\nGANs in practice.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 19:00:27 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Ji", "Kaiyi", ""], ["Liang", "Yingbin", ""]]}, {"id": "1811.01057", "submitter": "Aditi Raghunathan", "authors": "Aditi Raghunathan, Jacob Steinhardt, Percy Liang", "title": "Semidefinite relaxations for certifying robustness to adversarial\n  examples", "comments": "To appear at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their impressive performance on diverse tasks, neural networks fail\ncatastrophically in the presence of adversarial inputs---imperceptibly but\nadversarially perturbed versions of natural inputs. We have witnessed an arms\nrace between defenders who attempt to train robust networks and attackers who\ntry to construct adversarial examples. One promise of ending the arms race is\ndeveloping certified defenses, ones which are provably robust against all\nattackers in some family. These certified defenses are based on convex\nrelaxations which construct an upper bound on the worst case loss over all\nattackers in the family. Previous relaxations are loose on networks that are\nnot trained against the respective relaxation. In this paper, we propose a new\nsemidefinite relaxation for certifying robustness that applies to arbitrary\nReLU networks. We show that our proposed relaxation is tighter than previous\nrelaxations and produces meaningful robustness guarantees on three different\n\"foreign networks\" whose training objectives are agnostic to our proposed\nrelaxation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 19:08:04 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Raghunathan", "Aditi", ""], ["Steinhardt", "Jacob", ""], ["Liang", "Percy", ""]]}, {"id": "1811.01092", "submitter": "Huy Phan", "authors": "Huy Phan, Oliver Y. Ch\\'en, Philipp Koch, Lam Pham, Ian McLoughlin,\n  Alfred Mertins, Maarten De Vos", "title": "Unifying Isolated and Overlapping Audio Event Detection with Multi-Label\n  Multi-Task Convolutional Recurrent Neural Networks", "comments": "Accepted for the 44th International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-label multi-task framework based on a convolutional\nrecurrent neural network to unify detection of isolated and overlapping audio\nevents. The framework leverages the power of convolutional recurrent neural\nnetwork architectures; convolutional layers learn effective features over which\nhigher recurrent layers perform sequential modelling. Furthermore, the output\nlayer is designed to handle arbitrary degrees of event overlap. At each time\nstep in the recurrent output sequence, an output triple is dedicated to each\nevent category of interest to jointly model event occurrence and temporal\nboundaries. That is, the network jointly determines whether an event of this\ncategory occurs, and when it occurs, by estimating onset and offset positions\nat each recurrent time step. We then introduce three sequential losses for\nnetwork training: multi-label classification loss, distance estimation loss,\nand confidence loss. We demonstrate good generalization on two datasets:\nITC-Irst for isolated audio event detection, and TUT-SED-Synthetic-2016 for\noverlapping audio event detection.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 21:16:54 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 21:36:18 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Phan", "Huy", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Koch", "Philipp", ""], ["Pham", "Lam", ""], ["McLoughlin", "Ian", ""], ["Mertins", "Alfred", ""], ["De Vos", "Maarten", ""]]}, {"id": "1811.01118", "submitter": "Priyansh Trivedi", "authors": "Gaurav Maheshwari, Priyansh Trivedi, Denis Lukovnikov, Nilesh\n  Chakraborty, Asja Fischer, Jens Lehmann", "title": "Learning to Rank Query Graphs for Complex Question Answering over\n  Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we conduct an empirical investigation of neural query graph\nranking approaches for the task of complex question answering over knowledge\ngraphs. We experiment with six different ranking models and propose a novel\nself-attention based slot matching model which exploits the inherent structure\nof query graphs, our logical form of choice. Our proposed model generally\noutperforms the other models on two QA datasets over the DBpedia knowledge\ngraph, evaluated in different settings. In addition, we show that transfer\nlearning from the larger of those QA datasets to the smaller dataset yields\nsubstantial improvements, effectively offsetting the general lack of training\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 22:59:31 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Maheshwari", "Gaurav", ""], ["Trivedi", "Priyansh", ""], ["Lukovnikov", "Denis", ""], ["Chakraborty", "Nilesh", ""], ["Fischer", "Asja", ""], ["Lehmann", "Jens", ""]]}, {"id": "1811.01122", "submitter": "Gunnar Carlsson", "authors": "Gunnar Carlsson and Rickard Br\\\"uel Gabrielsson", "title": "Topological Approaches to Deep Learning", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform topological data analysis on the internal states of convolutional\ndeep neural networks to develop an understanding of the computations that they\nperform. We apply this understanding to modify the computations so as to (a)\nspeed up computations and (b) improve generalization from one data set of\ndigits to another. One byproduct of the analysis is the production of a\ngeometry on new sets of features on data sets of images, and use this\nobservation to develop a methodology for constructing analogues of CNN's for\nmany other geometries, including the graph structures constructed by\ntopological data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 23:18:03 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Carlsson", "Gunnar", ""], ["Gabrielsson", "Rickard Br\u00fcel", ""]]}, {"id": "1811.01132", "submitter": "Matthew Fellows", "authors": "Matthew Fellows, Anuj Mahajan, Tim G. J. Rudner and Shimon Whiteson", "title": "VIREL: A Variational Inference Framework for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying probabilistic models to reinforcement learning (RL) enables the\napplication of powerful optimisation tools such as variational inference to RL.\nHowever, existing inference frameworks and their algorithms pose significant\nchallenges for learning optimal policies, e.g., the absence of mode capturing\nbehaviour in pseudo-likelihood methods and difficulties learning deterministic\npolicies in maximum entropy RL based approaches. We propose VIREL, a novel,\ntheoretically grounded probabilistic inference framework for RL that utilises a\nparametrised action-value function to summarise future dynamics of the\nunderlying MDP. This gives VIREL a mode-seeking form of KL divergence, the\nability to learn deterministic optimal polices naturally from inference and the\nability to optimise value functions and policies in separate, iterative steps.\nIn applying variational expectation-maximisation to VIREL we thus show that the\nactor-critic algorithm can be reduced to expectation-maximisation, with policy\nimprovement equivalent to an E-step and policy evaluation to an M-step. We then\nderive a family of actor-critic methods from VIREL, including a scheme for\nadaptive exploration. Finally, we demonstrate that actor-critic algorithms from\nthis family outperform state-of-the-art methods based on soft value functions\nin several domains.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 00:15:48 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 09:57:25 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 12:04:20 GMT"}, {"version": "v4", "created": "Sat, 8 Dec 2018 00:37:04 GMT"}, {"version": "v5", "created": "Tue, 29 Jan 2019 19:21:58 GMT"}, {"version": "v6", "created": "Mon, 9 Sep 2019 15:04:25 GMT"}, {"version": "v7", "created": "Tue, 10 Dec 2019 15:10:16 GMT"}, {"version": "v8", "created": "Mon, 20 Jan 2020 19:00:56 GMT"}, {"version": "v9", "created": "Thu, 16 Jul 2020 14:42:28 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Fellows", "Matthew", ""], ["Mahajan", "Anuj", ""], ["Rudner", "Tim G. J.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1811.01135", "submitter": "Lajanugen Logeswaran", "authors": "Lajanugen Logeswaran, Honglak Lee, Samy Bengio", "title": "Content preserving text generation with attribute controls", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the problem of modifying textual attributes of\nsentences. Given an input sentence and a set of attribute labels, we attempt to\ngenerate sentences that are compatible with the conditioning information. To\nensure that the model generates content compatible sentences, we introduce a\nreconstruction loss which interpolates between auto-encoding and\nback-translation loss components. We propose an adversarial loss to enforce\ngenerated samples to be attribute compatible and realistic. Through\nquantitative, qualitative and human evaluations we demonstrate that our model\nis capable of generating fluent sentences that better reflect the conditioning\ninformation compared to prior methods. We further demonstrate that the model is\ncapable of simultaneously controlling multiple attributes.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 00:29:41 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Logeswaran", "Lajanugen", ""], ["Lee", "Honglak", ""], ["Bengio", "Samy", ""]]}, {"id": "1811.01146", "submitter": "Amanda Sofie Rios", "authors": "Amanda Rios and Laurent Itti", "title": "Closed-Loop Memory GAN for Continual Learning", "comments": "Proceedings of the Twenty-Eighth International Joint Conference on\n  Artificial Intelligence (IJCAI-2019). https://doi.org/10.24963/ijcai.2019/462", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential learning of tasks using gradient descent leads to an unremitting\ndecline in the accuracy of tasks for which training data is no longer\navailable, termed catastrophic forgetting. Generative models have been explored\nas a means to approximate the distribution of old tasks and bypass storage of\nreal data. Here we propose a cumulative closed-loop memory replay GAN (CloGAN)\nprovided with external regularization by a small memory unit selected for\nmaximum sample diversity. We evaluate incremental class learning using a\nnotoriously hard paradigm, single-headed learning, in which each task is a\ndisjoint subset of classes in the overall dataset, and performance is evaluated\non all previous classes. First, we show that when constructing a dynamic memory\nunit to preserve sample heterogeneity, model performance asymptotically\napproaches training on the full dataset. We then show that using a stochastic\ngenerator to continuously output fresh new images during training increases\nperformance significantly further meanwhile generating quality images. We\ncompare our approach to several baselines including fine-tuning by gradient\ndescent (FGD), Elastic Weight Consolidation (EWC), Deep Generative Replay (DGR)\nand Memory Replay GAN (MeRGAN). Our method has very low long-term memory cost,\nthe memory unit, as well as negligible intermediate memory storage.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 02:40:01 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 21:17:48 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 21:44:55 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Rios", "Amanda", ""], ["Itti", "Laurent", ""]]}, {"id": "1811.01158", "submitter": "Lifang He", "authors": "Lifang He, Kun Chen, Wanwan Xu, Jiayu Zhou, Fei Wang", "title": "Boosted Sparse and Low-Rank Tensor Regression", "comments": "10 pages, 5 figures, NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a sparse and low-rank tensor regression model to relate a\nunivariate outcome to a feature tensor, in which each unit-rank tensor from the\nCP decomposition of the coefficient tensor is assumed to be sparse. This\nstructure is both parsimonious and highly interpretable, as it implies that the\noutcome is related to the features through a few distinct pathways, each of\nwhich may only involve subsets of feature dimensions. We take a\ndivide-and-conquer strategy to simplify the task into a set of sparse unit-rank\ntensor regression problems. To make the computation efficient and scalable, for\nthe unit-rank tensor regression, we propose a stagewise estimation procedure to\nefficiently trace out its entire solution path. We show that as the step size\ngoes to zero, the stagewise solution paths converge exactly to those of the\ncorresponding regularized regression. The superior performance of our approach\nis demonstrated on various real-world and synthetic examples.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 04:45:57 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["He", "Lifang", ""], ["Chen", "Kun", ""], ["Xu", "Wanwan", ""], ["Zhou", "Jiayu", ""], ["Wang", "Fei", ""]]}, {"id": "1811.01159", "submitter": "Haitao Liu", "authors": "Haitao Liu, Jianfei Cai, Yew-Soon Ong, Yi Wang", "title": "Understanding and Comparing Scalable Gaussian Process Regression for Big\n  Data", "comments": "25 pages, 15 figures, preprint submitted to KBS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a non-parametric Bayesian model which produces informative predictive\ndistribution, Gaussian process (GP) has been widely used in various fields,\nlike regression, classification and optimization. The cubic complexity of\nstandard GP however leads to poor scalability, which poses challenges in the\nera of big data. Hence, various scalable GPs have been developed in the\nliterature in order to improve the scalability while retaining desirable\nprediction accuracy. This paper devotes to investigating the methodological\ncharacteristics and performance of representative global and local scalable GPs\nincluding sparse approximations and local aggregations from four main\nperspectives: scalability, capability, controllability and robustness. The\nnumerical experiments on two toy examples and five real-world datasets with up\nto 250K points offer the following findings. In terms of scalability, most of\nthe scalable GPs own a time complexity that is linear to the training size. In\nterms of capability, the sparse approximations capture the long-term spatial\ncorrelations, the local aggregations capture the local patterns but suffer from\nover-fitting in some scenarios. In terms of controllability, we could improve\nthe performance of sparse approximations by simply increasing the inducing\nsize. But this is not the case for local aggregations. In terms of robustness,\nlocal aggregations are robust to various initializations of hyperparameters due\nto the local attention mechanism. Finally, we highlight that the proper hybrid\nof global and local scalable GPs may be a promising way to improve both the\nmodel capability and scalability for big data.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 04:46:58 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Liu", "Haitao", ""], ["Cai", "Jianfei", ""], ["Ong", "Yew-Soon", ""], ["Wang", "Yi", ""]]}, {"id": "1811.01171", "submitter": "Mayank Sharma", "authors": "Mayank Sharma, Jayadeva, Sumit Soman", "title": "Radius-margin bounds for deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Explaining the unreasonable effectiveness of deep learning has eluded\nresearchers around the globe. Various authors have described multiple metrics\nto evaluate the capacity of deep architectures. In this paper, we allude to the\nradius margin bounds described for a support vector machine (SVM) with hinge\nloss, apply the same to the deep feed-forward architectures and derive the\nVapnik-Chervonenkis (VC) bounds which are different from the earlier bounds\nproposed in terms of number of weights of the network. In doing so, we also\nrelate the effectiveness of techniques like Dropout and Dropconnect in bringing\ndown the capacity of the network. Finally, we describe the effect of maximizing\nthe input as well as the output margin to achieve an input noise-robust deep\narchitecture.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 07:56:16 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Sharma", "Mayank", ""], ["Jayadeva", "", ""], ["Soman", "Sumit", ""]]}, {"id": "1811.01174", "submitter": "Jian Gao", "authors": "Jian Gao, Deep Chakraborty, Hamidou Tembine, Olaitan Olaleye", "title": "Nonparallel Emotional Speech Conversion", "comments": "Published in INTERSPEECH 2019, 5 pages, 6 figures. Simulation\n  available at http://www.jian-gao.org/emogan", "journal-ref": "https://www.isca-speech.org/archive/Interspeech_2019/abstracts/2878.html", "doi": "10.21437/Interspeech.2019-2878", "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparallel data-driven emotional speech conversion method. It\nenables the transfer of emotion-related characteristics of a speech signal\nwhile preserving the speaker's identity and linguistic content. Most existing\napproaches require parallel data and time alignment, which is not available in\nmost real applications. We achieve nonparallel training based on an\nunsupervised style transfer technique, which learns a translation model between\ntwo distributions instead of a deterministic one-to-one mapping between paired\nexamples. The conversion model consists of an encoder and a decoder for each\nemotion domain. We assume that the speech signal can be decomposed into an\nemotion-invariant content code and an emotion-related style code in latent\nspace. Emotion conversion is performed by extracting and recombining the\ncontent code of the source speech and the style code of the target emotion. We\ntested our method on a nonparallel corpora with four emotions. Both subjective\nand objective evaluations show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 08:28:04 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 17:04:58 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 08:03:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gao", "Jian", ""], ["Chakraborty", "Deep", ""], ["Tembine", "Hamidou", ""], ["Olaleye", "Olaitan", ""]]}, {"id": "1811.01179", "submitter": "Haitao Liu", "authors": "Haitao Liu, Yew-Soon Ong, Jianfei Cai", "title": "Large-scale Heteroscedastic Regression via Gaussian Process", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heteroscedastic regression considering the varying noises among observations\nhas many applications in the fields like machine learning and statistics. Here\nwe focus on the heteroscedastic Gaussian process (HGP) regression which\nintegrates the latent function and the noise function together in a unified\nnon-parametric Bayesian framework. Though showing remarkable performance, HGP\nsuffers from the cubic time complexity, which strictly limits its application\nto big data. To improve the scalability, we first develop a variational sparse\ninference algorithm, named VSHGP, to handle large-scale datasets. Furthermore,\ntwo variants are developed to improve the scalability and capability of VSHGP.\nThe first is stochastic VSHGP (SVSHGP) which derives a factorized evidence\nlower bound, thus enhancing efficient stochastic variational inference. The\nsecond is distributed VSHGP (DVSHGP) which (i) follows the Bayesian committee\nmachine formalism to distribute computations over multiple local VSHGP experts\nwith many inducing points; and (ii) adopts hybrid parameters for experts to\nguard against over-fitting and capture local variety. The superiority of DVSHGP\nand SVSHGP as compared to existing scalable heteroscedastic/homoscedastic GPs\nis then extensively verified on various datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 09:04:35 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 11:45:26 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 08:27:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Liu", "Haitao", ""], ["Ong", "Yew-Soon", ""], ["Cai", "Jianfei", ""]]}, {"id": "1811.01198", "submitter": "En-Liang Hu", "authors": "En-Liang Hu", "title": "Low-Rank Semidefinite Programs via Bilinear Factorization", "comments": "This submission also needs major revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems can be reduced to learning a low-rank positive\nsemidefinite matrix (denoted as $Z$), which encounters semidefinite program\n(SDP). Existing SDP solvers are often expensive for large-scale learning. To\navoid directly solving SDP, some works convert SDP into a nonconvex program by\nfactorizing $Z$ \\textit{quadraticly} as $XX^\\top$. However, this would bring\nhigher-order nonlinearity, resulting in scarcity of structure in subsequent\noptimization. In this paper, we propose a novel surrogate for SDP learning, in\nwhich the structure of subproblem is exploited. More specifically, we surrogate\nunconstrained SDP by a biconvex problem, through factorizing $Z$\n\\textit{bilinearly} as $XY^\\top$ and using a Courant penalty to penalize the\ndifference of $X$ and $Y$, in which the resultant subproblems in terms of $X$\nand $Y$ are convex respectively. Furthermore, we provide a theoretical bound\nfor the associated penalty parameter under the assumption that the subobjective\nfunction of $X$ or $Y$ is $L$-Lipschitz-smooth and $\\sigma$-strongly convex,\nsuch that the proposed surrogate will solve the original SDP when the penalty\nparameter is larger than this bound (that is $\\gamma>\\frac{1}{4}(L-\\sigma)$).\nExperiments on two SDP-related applications demonstrate that the proposed\nalgorithm is as accurate as the state-of-the-art, but is faster on large-scale\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 12:15:42 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 03:32:56 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 03:13:44 GMT"}, {"version": "v4", "created": "Sat, 7 Mar 2020 11:02:05 GMT"}, {"version": "v5", "created": "Wed, 20 Jan 2021 11:19:37 GMT"}, {"version": "v6", "created": "Mon, 1 Feb 2021 06:03:46 GMT"}, {"version": "v7", "created": "Tue, 2 Feb 2021 02:59:16 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hu", "En-Liang", ""]]}, {"id": "1811.01213", "submitter": "Zhehui Chen", "authors": "Haoming Jiang, Zhehui Chen, Yuyang Shi, Bo Dai, and Tuo Zhao", "title": "Learning to Defend by Learning to Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training provides a principled approach for training robust\nneural networks. From an optimization perspective, adversarial training is\nessentially solving a bilevel optimization problem. The leader problem is\ntrying to learn a robust classifier, while the follower problem is trying to\ngenerate adversarial samples. Unfortunately, such a bilevel problem is\ndifficult to solve due to its highly complicated structure. This work proposes\na new adversarial training method based on a generic learning-to-learn (L2L)\nframework. Specifically, instead of applying existing hand-designed algorithms\nfor the inner problem, we learn an optimizer, which is parametrized as a\nconvolutional neural network. At the same time, a robust classifier is learned\nto defense the adversarial attack generated by the learned optimizer.\nExperiments over CIFAR-10 and CIFAR-100 datasets demonstrate that L2L\noutperforms existing adversarial training methods in both classification\naccuracy and computational efficiency. Moreover, our L2L framework can be\nextended to generative adversarial imitation learning and stabilize the\ntraining.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 13:33:23 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 15:13:28 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 23:48:28 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 22:42:13 GMT"}, {"version": "v5", "created": "Sun, 2 May 2021 14:28:02 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Jiang", "Haoming", ""], ["Chen", "Zhehui", ""], ["Shi", "Yuyang", ""], ["Dai", "Bo", ""], ["Zhao", "Tuo", ""]]}, {"id": "1811.01216", "submitter": "Anindya De", "authors": "Anindya De, Ryan O'Donnell and Rocco Servedio", "title": "Learning sparse mixtures of rankings from noisy information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning an unknown mixture of $k$ rankings over $n$\nelements, given access to noisy samples drawn from the unknown mixture. We\nconsider a range of different noise models, including natural variants of the\n\"heat kernel\" noise framework and the Mallows model. For each of these noise\nmodels we give an algorithm which, under mild assumptions, learns the unknown\nmixture to high accuracy and runs in $n^{O(\\log k)}$ time. The best previous\nalgorithms for closely related problems have running times which are\nexponential in $k$.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 13:36:12 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["De", "Anindya", ""], ["O'Donnell", "Ryan", ""], ["Servedio", "Rocco", ""]]}, {"id": "1811.01225", "submitter": "Xiaoyi Dong", "authors": "Xiaoyi Dong, Weiming Zhang, Nenghai Yu", "title": "CAAD 2018: Powerful None-Access Black-Box Attack Based on Adversarial\n  Transformation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an improvement of Adversarial Transformation\nNetworks(ATN) to generate adversarial examples, which can fool white-box models\nand black-box models with a state of the art performance and won the 2rd place\nin the non-target task in CAAD 2018.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 14:18:40 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Dong", "Xiaoyi", ""], ["Zhang", "Weiming", ""], ["Yu", "Nenghai", ""]]}, {"id": "1811.01247", "submitter": "Jiwoong Im", "authors": "Daniel Jiwoong Im, Nakul Verma, Kristin Branson", "title": "Stochastic Neighbor Embedding under f-divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The t-distributed Stochastic Neighbor Embedding (t-SNE) is a powerful and\npopular method for visualizing high-dimensional data. It minimizes the\nKullback-Leibler (KL) divergence between the original and embedded data\ndistributions. In this work, we propose extending this method to other\nf-divergences. We analytically and empirically evaluate the types of latent\nstructure-manifold, cluster, and hierarchical-that are well-captured using both\nthe original KL-divergence as well as the proposed f-divergence generalization,\nand find that different divergences perform better for different types of\nstructure.\n  A common concern with $t$-SNE criterion is that it is optimized using\ngradient descent, and can become stuck in poor local minima. We propose\noptimizing the f-divergence based loss criteria by minimizing a variational\nbound. This typically performs better than optimizing the primal form, and our\nexperiments show that it can improve upon the embedding results obtained from\nthe original $t$-SNE criterion as well.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 16:56:15 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Im", "Daniel Jiwoong", ""], ["Verma", "Nakul", ""], ["Branson", "Kristin", ""]]}, {"id": "1811.01249", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Sajad Darabi, Babak Moatamed, Majid Sarrafzadeh", "title": "Dynamic Feature Acquisition Using Denoising Autoencoders", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2018", "doi": "10.1109/TNNLS.2018.2880403", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world scenarios, different features have different acquisition costs\nat test-time which necessitates cost-aware methods to optimize the cost and\nperformance trade-off. This paper introduces a novel and scalable approach for\ncost-aware feature acquisition at test-time. The method incrementally asks for\nfeatures based on the available context that are known feature values. The\nproposed method is based on sensitivity analysis in neural networks and density\nestimation using denoising autoencoders with binary representation layers. In\nthe proposed architecture, a denoising autoencoder is used to handle unknown\nfeatures (i.e., features that are yet to be acquired), and the sensitivity of\npredictions with respect to each unknown feature is used as a context-dependent\nmeasure of informativeness. We evaluated the proposed method on eight different\nreal-world datasets as well as one synthesized dataset and compared its\nperformance with several other approaches in the literature. According to the\nresults, the suggested method is capable of efficiently acquiring features at\ntest-time in a cost- and context-aware fashion.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 17:14:28 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Darabi", "Sajad", ""], ["Moatamed", "Babak", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1811.01287", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "C\\u{a}t\\u{a}lina Cangea, Petar Veli\\v{c}kovi\\'c, Nikola Jovanovi\\'c,\n  Thomas Kipf, Pietro Li\\`o", "title": "Towards Sparse Hierarchical Graph Classifiers", "comments": "To appear in the Workshop on Relational Representation Learning (R2L)\n  at NIPS 2018. 6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in representation learning on graphs, mainly leveraging graph\nconvolutional networks, have brought a substantial improvement on many\ngraph-based benchmark tasks. While novel approaches to learning node embeddings\nare highly suitable for node classification and link prediction, their\napplication to graph classification (predicting a single label for the entire\ngraph) remains mostly rudimentary, typically using a single global pooling step\nto aggregate node features or a hand-designed, fixed heuristic for hierarchical\ncoarsening of the graph structure. An important step towards ameliorating this\nis differentiable graph coarsening---the ability to reduce the size of the\ngraph in an adaptive, data-dependent manner within a graph neural network\npipeline, analogous to image downsampling within CNNs. However, the previous\nprominent approach to pooling has quadratic memory requirements during training\nand is therefore not scalable to large graphs. Here we combine several recent\nadvances in graph neural network design to demonstrate that competitive\nhierarchical graph classification results are possible without sacrificing\nsparsity. Our results are verified on several established graph classification\nbenchmarks, and highlight an important direction for future research in\ngraph-based neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 21:39:43 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Jovanovi\u0107", "Nikola", ""], ["Kipf", "Thomas", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1811.01302", "submitter": "Peter Henderson", "authors": "Peter Henderson, Koustuv Sinha, Rosemary Nan Ke, Joelle Pineau", "title": "Adversarial Gain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples can be defined as inputs to a model which induce a\nmistake - where the model output is different than that of an oracle, perhaps\nin surprising or malicious ways. Original models of adversarial attacks are\nprimarily studied in the context of classification and computer vision tasks.\nWhile several attacks have been proposed in natural language processing (NLP)\nsettings, they often vary in defining the parameters of an attack and what a\nsuccessful attack would look like. The goal of this work is to propose a\nunifying model of adversarial examples suitable for NLP tasks in both\ngenerative and classification settings. We define the notion of adversarial\ngain: based in control theory, it is a measure of the change in the output of a\nsystem relative to the perturbation of the input (caused by the so-called\nadversary) presented to the learner. This definition, as we show, can be used\nunder different feature spaces and distance conditions to determine attack or\ndefense effectiveness across different intuitive manifolds. This notion of\nadversarial gain not only provides a useful way for evaluating adversaries and\ndefenses, but can act as a building block for future work in robustness under\nadversaries due to its rooted nature in stability and manifold theory.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 00:02:42 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Henderson", "Peter", ""], ["Sinha", "Koustuv", ""], ["Ke", "Rosemary Nan", ""], ["Pineau", "Joelle", ""]]}, {"id": "1811.01305", "submitter": "Yuefeng Liang", "authors": "Yuefeng Liang, Cho-Jui Hsieh, Thomas C.M. Lee", "title": "Block-wise Partitioning for Extreme Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification aims to learn a classifier that annotates\nan instance with a relevant subset of labels from an extremely large label set.\nMany existing solutions embed the label matrix to a low-dimensional linear\nsubspace, or examine the relevance of a test instance to every label via a\nlinear scan. In practice, however, those approaches can be computationally\nexorbitant. To alleviate this drawback, we propose a Block-wise Partitioning\n(BP) pretreatment that divides all instances into disjoint clusters, to each of\nwhich the most frequently tagged label subset is attached. One multi-label\nclassifier is trained on one pair of instance and label clusters, and the label\nset of a test instance is predicted by first delivering it to the most\nappropriate instance cluster. Experiments on benchmark multi-label data sets\nreveal that BP pretreatment significantly reduces prediction time, and retains\nalmost the same level of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 00:54:11 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Liang", "Yuefeng", ""], ["Hsieh", "Cho-Jui", ""], ["Lee", "Thomas C. M.", ""]]}, {"id": "1811.01315", "submitter": "Xilei Zhao", "authors": "Xilei Zhao, Xiang Yan, Alan Yu, Pascal Van Hentenryck", "title": "Modeling Stated Preference for Mobility-on-Demand Transit: A Comparison\n  of Machine Learning and Logit Models", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logit models are usually applied when studying individual travel behavior,\ni.e., to predict travel mode choice and to gain behavioral insights on traveler\npreferences. Recently, some studies have applied machine learning to model\ntravel mode choice and reported higher out-of-sample predictive accuracy than\ntraditional logit models (e.g., multinomial logit). However, little research\nfocuses on comparing the interpretability of machine learning with logit\nmodels. In other words, how to draw behavioral insights from the\nhigh-performance \"black-box\" machine-learning models remains largely unsolved\nin the field of travel behavior modeling.\n  This paper aims at providing a comprehensive comparison between the two\napproaches by examining the key similarities and differences in model\ndevelopment, evaluation, and behavioral interpretation between logit and\nmachine-learning models for travel mode choice modeling. To complement the\ntheoretical discussions, the paper also empirically evaluates the two\napproaches on the stated-preference survey data for a new type of transit\nsystem integrating high-frequency fixed-route services and ridesourcing. The\nresults show that machine learning can produce significantly higher predictive\naccuracy than logit models. Moreover, machine learning and logit models largely\nagree on many aspects of behavioral interpretations. In addition, machine\nlearning can automatically capture the nonlinear relationship between the input\nfeatures and choice outcomes. The paper concludes that there is great potential\nin merging ideas from machine learning and conventional statistical methods to\ndevelop refined models for travel behavior research and suggests some new\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 02:55:49 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 19:40:52 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhao", "Xilei", ""], ["Yan", "Xiang", ""], ["Yu", "Alan", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1811.01316", "submitter": "Huiling Zhen", "authors": "Hui-Ling Zhen, Xi Lin, Alan Z. Tang, Zhenhua Li, Qingfu Zhang and Sam\n  Kwong", "title": "Nonlinear Collaborative Scheme for Deep Neural Networks", "comments": "11 pages, 3 figures (20 subfigures), prepared to submit to IEEE\n  Trans. on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional research attributes the improvements of generalization ability\nof deep neural networks either to powerful optimizers or the new network\ndesign. Different from them, in this paper, we aim to link the generalization\nability of a deep network to optimizing a new objective function. To this end,\nwe propose a \\textit{nonlinear collaborative scheme} for deep network training,\nwith the key technique as combining different loss functions in a nonlinear\nmanner. We find that after adaptively tuning the weights of different loss\nfunctions, the proposed objective function can efficiently guide the\noptimization process. What is more, we demonstrate that, from the mathematical\nperspective, the nonlinear collaborative scheme can lead to (i) smaller KL\ndivergence with respect to optimal solutions; (ii) data-driven stochastic\ngradient descent; (iii) tighter PAC-Bayes bound. We also prove that its\nadvantage can be strengthened by nonlinearity increasing. To some extent, we\nbridge the gap between learning (i.e., minimizing the new objective function)\nand generalization (i.e., minimizing a PAC-Bayes bound) in the new scheme. We\nalso interpret our findings through the experiments on Residual Networks and\nDenseNet, showing that our new scheme performs superior to single-loss and\nmulti-loss schemes no matter with randomization or not.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 03:24:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Zhen", "Hui-Ling", ""], ["Lin", "Xi", ""], ["Tang", "Alan Z.", ""], ["Li", "Zhenhua", ""], ["Zhang", "Qingfu", ""], ["Kwong", "Sam", ""]]}, {"id": "1811.01338", "submitter": "Ashish Ranjan", "authors": "Ashish Ranjan, Md Shah Fahad, David Fernandez-Baca, Akshay Deepak and\n  Sudhakar Tripathi", "title": "Deep Robust Framework for Protein Function Prediction using\n  Variable-Length Protein Sequences", "comments": null, "journal-ref": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,\n  2019", "doi": "10.1109/TCBB.2019.2911609", "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amino acid sequence portrays most intrinsic form of a protein and expresses\nprimary structure of protein. The order of amino acids in a sequence enables a\nprotein to acquire a particular stable conformation that is responsible for the\nfunctions of the protein. This relationship between a sequence and its function\nmotivates the need to analyse the sequences for predicting protein functions.\nEarly generation computational methods using BLAST, FASTA, etc. perform\nfunction transfer based on sequence similarity with existing databases and are\ncomputationally slow. Although machine learning based approaches are fast, they\nfail to perform well for long protein sequences (i.e., protein sequences with\nmore than 300 amino acid residues). In this paper, we introduce a novel method\nfor construction of two separate feature sets for protein sequences based on\nanalysis of 1) single fixed-sized segments and 2) multi-sized segments, using\nbi-directional long short-term memory network. Further, model based on proposed\nfeature set is combined with the state of the art Multi-lable Linear\nDiscriminant Analysis (MLDA) features based model to improve the accuracy.\nExtensive evaluations using separate datasets for biological processes and\nmolecular functions demonstrate promising results for both single-sized and\nmulti-sized segments based feature sets. While former showed an improvement of\n+3.37% and +5.48%, the latter produces an improvement of +5.38% and +8.00%\nrespectively for two datasets over the state of the art MLDA based classifier.\nAfter combining two models, there is a significant improvement of +7.41% and\n+9.21% respectively for two datasets compared to MLDA based classifier.\nSpecifically, the proposed approach performed well for the long protein\nsequences and superior overall performance.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 08:49:38 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 08:37:28 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Ranjan", "Ashish", ""], ["Fahad", "Md Shah", ""], ["Fernandez-Baca", "David", ""], ["Deepak", "Akshay", ""], ["Tripathi", "Sudhakar", ""]]}, {"id": "1811.01339", "submitter": "Ahmadreza Ahmadi", "authors": "Ahmadreza Ahmadi and Jun Tani", "title": "A Novel Predictive-Coding-Inspired Variational RNN Model for Online\n  Prediction and Recognition", "comments": "The paper is accepted in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study introduces PV-RNN, a novel variational RNN inspired by the\npredictive-coding ideas. The model learns to extract the probabilistic\nstructures hidden in fluctuating temporal patterns by dynamically changing the\nstochasticity of its latent states. Its architecture attempts to address two\nmajor concerns of variational Bayes RNNs: how can latent variables learn\nmeaningful representations and how can the inference model transfer future\nobservations to the latent variables. PV-RNN does both by introducing adaptive\nvectors mirroring the training data, whose values can then be adapted\ndifferently during evaluation. Moreover, prediction errors during\nbackpropagation, rather than external inputs during the forward computation,\nare used to convey information to the network about the external data. For\ntesting, we introduce error regression for predicting unseen sequences as\ninspired by predictive coding that leverages those mechanisms. The model\nintroduces a weighting parameter, the meta-prior, to balance the optimization\npressure placed on two terms of a lower bound on the marginal likelihood of the\nsequential data. We test the model on two datasets with probabilistic\nstructures and show that with high values of the meta-prior the network\ndevelops deterministic chaos through which the data's randomness is imitated.\nFor low values, the model behaves as a random process. The network performs\nbest on intermediate values, and is able to capture the latent probabilistic\nstructure with good generalization. Analyzing the meta-prior's impact on the\nnetwork allows to precisely study the theoretical value and practical benefits\nof incorporating stochastic dynamics in our model. We demonstrate better\nprediction performance on a robot imitation task with our model using error\nregression compared to a standard variational Bayes model lacking such a\nprocedure.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 08:56:50 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 14:59:40 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 02:08:58 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Ahmadi", "Ahmadreza", ""], ["Tani", "Jun", ""]]}, {"id": "1811.01376", "submitter": "Kohki Mametani", "authors": "Kohki Mametani, Tsuneo Kato, Seiichi Yamamoto", "title": "Investigating context features hidden in End-to-End TTS", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have introduced end-to-end TTS, which integrates the\nproduction of context and acoustic features in statistical parametric speech\nsynthesis. As a result, a single neural network replaced laborious feature\nengineering with automated feature learning. However, little is known about\nwhat types of context information end-to-end TTS extracts from text input\nbefore synthesizing speech, and the previous knowledge about context features\nis barely utilized. In this work, we first point out the model similarity\nbetween end-to-end TTS and parametric TTS. Based on the similarity, we evaluate\nthe quality of encoder outputs from an end-to-end TTS system against eight\ncriteria that are derived from a standard set of context information used in\nparametric TTS. We conduct experiments using an evaluation procedure that has\nbeen newly developed in the machine learning literature for quantitative\nanalysis of neural representations, while adapting it to the TTS domain.\nExperimental results show that the encoder outputs reflect both linguistic and\nphonetic contexts, such as vowel reduction at phoneme level, lexical stress at\nsyllable level, and part-of-speech at word level, possibly due to the joint\noptimization of context and acoustic features.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 14:22:37 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 14:55:07 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mametani", "Kohki", ""], ["Kato", "Tsuneo", ""], ["Yamamoto", "Seiichi", ""]]}, {"id": "1811.01382", "submitter": "Kai Hu", "authors": "Kai Hu, Zhijian Ou, Min Hu, Junlan Feng", "title": "Neural CRF transducers for sequence labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional random fields (CRFs) have been shown to be one of the most\nsuccessful approaches to sequence labeling. Various linear-chain neural CRFs\n(NCRFs) are developed to implement the non-linear node potentials in CRFs, but\nstill keeping the linear-chain hidden structure. In this paper, we propose NCRF\ntransducers, which consists of two RNNs, one extracting features from\nobservations and the other capturing (theoretically infinite) long-range\ndependencies between labels. Different sequence labeling methods are evaluated\nover POS tagging, chunking and NER (English, Dutch). Experiment results show\nthat NCRF transducers achieve consistent improvements over linear-chain NCRFs\nand RNN transducers across all the four tasks, and can improve state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 14:45:50 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Hu", "Kai", ""], ["Ou", "Zhijian", ""], ["Hu", "Min", ""], ["Feng", "Junlan", ""]]}, {"id": "1811.01437", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Hassan Ali, Hammad Tariq, Muhammad Abdullah Hanif, Semeen\n  Rehman, Rehan Ahmed and Muhammad Shafique", "title": "QuSecNets: Quantization-based Defense Mechanism for Securing Deep Neural\n  Network against Adversarial Attacks", "comments": null, "journal-ref": "2019 IEEE 25th International Symposium on On-Line Testing and\n  Robust System Design (IOLTS), Rhodes, Greece, 2019, pp. 182-187", "doi": "10.1109/IOLTS.2019.8854377", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have emerged as a significant threat to machine learning\nalgorithms, especially to the convolutional neural networks (CNNs). In this\npaper, we propose two quantization-based defense mechanisms, Constant\nQuantization (CQ) and Trainable Quantization (TQ), to increase the robustness\nof CNNs against adversarial examples. CQ quantizes input pixel intensities\nbased on a \"fixed\" number of quantization levels, while in TQ, the quantization\nlevels are \"iteratively learned during the training phase\", thereby providing a\nstronger defense mechanism. We apply the proposed techniques on undefended CNNs\nagainst different state-of-the-art adversarial attacks from the open-source\n\\textit{Cleverhans} library. The experimental results demonstrate 50%-96% and\n10%-50% increase in the classification accuracy of the perturbed images\ngenerated from the MNIST and the CIFAR-10 datasets, respectively, on commonly\nused CNN (Conv2D(64, 8x8) - Conv2D(128, 6x6) - Conv2D(128, 5x5) - Dense(10) -\nSoftmax()) available in \\textit{Cleverhans} library.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 21:25:38 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 09:30:01 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Khalid", "Faiq", ""], ["Ali", "Hassan", ""], ["Tariq", "Hammad", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Ahmed", "Rehan", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01443", "submitter": "Faiq Khalid", "authors": "Hassan Ali, Faiq Khalid, Hammad Tariq, Muhammad Abdullah Hanif, Semeen\n  Rehman, Rehan Ahmed and Muhammad Shafique", "title": "SSCNets: Robustifying DNNs using Secure Selective Convolutional Filters", "comments": null, "journal-ref": "IEEE Design & Test, vol. 37, no. 2, pp. 58-65, April 2020", "doi": "10.1109/MDAT.2019.2961325", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel technique based on the Secure Selective\nConvolutional (SSC) techniques in the training loop that increases the\nrobustness of a given DNN by allowing it to learn the data distribution based\non the important edges in the input image. We validate our technique on\nConvolutional DNNs against the state-of-the-art attacks from the open-source\nCleverhans library using the MNIST, the CIFAR-10, and the CIFAR-100 datasets.\nOur experimental results show that the attack success rate, as well as the\nimperceptibility of the adversarial images, can be significantly reduced by\nadding effective pre-processing functions, i.e., Sobel filtering.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 21:54:11 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 03:44:31 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Ali", "Hassan", ""], ["Khalid", "Faiq", ""], ["Tariq", "Hammad", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Ahmed", "Rehan", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01444", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Muhammmad Abdullah Hanif, Semeen Rehman, Junaid Qadir,\n  Muhammad Shafique", "title": "FAdeML: Understanding the Impact of Pre-Processing Noise Filtering on\n  Adversarial Machine Learning", "comments": "Accepted in Design, Automation and Test in Europe 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN)-based machine learning (ML) algorithms have\nrecently emerged as the leading ML paradigm particularly for the task of\nclassification due to their superior capability of learning efficiently from\nlarge datasets. The discovery of a number of well-known attacks such as dataset\npoisoning, adversarial examples, and network manipulation (through the addition\nof malicious nodes) has, however, put the spotlight squarely on the lack of\nsecurity in DNN-based ML systems. In particular, malicious actors can use these\nwell-known attacks to cause random/targeted misclassification, or cause a\nchange in the prediction confidence, by only slightly but systematically\nmanipulating the environmental parameters, inference data, or the data\nacquisition block. Most of the prior adversarial attacks have, however, not\naccounted for the pre-processing noise filters commonly integrated with the\nML-inference module. Our contribution in this work is to show that this is a\nmajor omission since these noise filters can render ineffective the majority of\nthe existing attacks, which rely essentially on introducing adversarial noise.\nApart from this, we also extend the state of the art by proposing a novel\npre-processing noise Filter-aware Adversarial ML attack called FAdeML. To\ndemonstrate the effectiveness of the proposed methodology, we generate an\nadversarial attack image by exploiting the \"VGGNet\" DNN trained for the \"German\nTraffic Sign Recognition Benchmarks (GTSRB\" dataset, which despite having no\nvisual noise, can cause a classifier to misclassify even in the presence of\npre-processing noise filters.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 21:56:33 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Khalid", "Faiq", ""], ["Hanif", "Muhammmad Abdullah", ""], ["Rehman", "Semeen", ""], ["Qadir", "Junaid", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01459", "submitter": "Xinshao Wang Mr", "authors": "Xinshao Wang, Yang Hua, Elyor Kodirov, Guosheng Hu, Neil M. Robertson", "title": "Deep Metric Learning by Online Soft Mining and Class-Aware Attention", "comments": "Learning Robust Representations, Deep Metric Learning, Person\n  Re-identification (AAAI 2019 Oral) Code:\n  https://github.com/XinshaoAmosWang/OSM_CAA_WeightedContrastiveLoss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning aims to learn a deep embedding that can capture the\nsemantic similarity of data points. Given the availability of massive training\nsamples, deep metric learning is known to suffer from slow convergence due to a\nlarge fraction of trivial samples. Therefore, most existing methods generally\nresort to sample mining strategies for selecting nontrivial samples to\naccelerate convergence and improve performance. In this work, we identify two\ncritical limitations of the sample mining methods, and provide solutions for\nboth of them. First, previous mining methods assign one binary score to each\nsample, i.e., dropping or keeping it, so they only selects a subset of relevant\nsamples in a mini-batch. Therefore, we propose a novel sample mining method,\ncalled Online Soft Mining (OSM), which assigns one continuous score to each\nsample to make use of all samples in the mini-batch. OSM learns extended\nmanifolds that preserve useful intraclass variances by focusing on more similar\npositives. Second, the existing methods are easily influenced by outliers as\nthey are generally included in the mined subset. To address this, we introduce\nClass-Aware Attention (CAA) that assigns little attention to abnormal data\nsamples. Furthermore, by combining OSM and CAA, we propose a novel weighted\ncontrastive loss to learn discriminative embeddings. Extensive experiments on\ntwo fine-grained visual categorisation datasets and two video-based person\nre-identification benchmarks show that our method significantly outperforms the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 23:47:18 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 20:40:29 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 22:36:39 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Wang", "Xinshao", ""], ["Hua", "Yang", ""], ["Kodirov", "Elyor", ""], ["Hu", "Guosheng", ""], ["Robertson", "Neil M.", ""]]}, {"id": "1811.01463", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, Muhammad Shafique", "title": "Security for Machine Learning-based Systems: Attacks and Challenges\n  during Training and Inference", "comments": null, "journal-ref": "International Conference on Frontiers of Information Technology\n  (FIT) 2018", "doi": "10.1109/FIT.2018.00064", "report-no": "INSPEC Accession Number: 18398499", "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential increase in dependencies between the cyber and physical world\nleads to an enormous amount of data which must be efficiently processed and\nstored. Therefore, computing paradigms are evolving towards machine learning\n(ML)-based systems because of their ability to efficiently and accurately\nprocess the enormous amount of data. Although ML-based solutions address the\nefficient computing requirements of big data, they introduce (new) security\nvulnerabilities into the systems, which cannot be addressed by traditional\nmonitoring-based security measures. Therefore, this paper first presents a\nbrief overview of various security threats in machine learning, their\nrespective threat models and associated research challenges to develop robust\nsecurity measures. To illustrate the security vulnerabilities of ML during\ntraining, inferencing and hardware implementation, we demonstrate some key\nsecurity threats on ML using LeNet and VGGNet for MNIST and German Traffic Sign\nRecognition Benchmarks (GTSRB), respectively. Moreover, based on the security\nanalysis of ML-training, we also propose an attack that has a very less impact\non the inference accuracy. Towards the end, we highlight the associated\nresearch challenges in developing security measures and provide a brief\noverview of the techniques used to mitigate such security threats.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 00:30:21 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01464", "submitter": "Ke Sun", "authors": "Ke Sun", "title": "Intrinsic Universal Measurements of Non-linear Embeddings", "comments": "work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic problem in machine learning is to find a mapping $f$ from a low\ndimensional latent space to a high dimensional observation space. Equipped with\nthe representation power of non-linearity, a learner can easily find a mapping\nwhich perfectly fits all the observations. However such a mapping is often not\nconsidered as good as it is not simple enough and over-fits. How to define\nsimplicity? This paper tries to make such a formal definition of the amount of\ninformation imposed by a non-linear mapping. This definition is based on\ninformation geometry and is independent of observations, nor specific\nparametrizations. We prove these basic properties and discuss relationships\nwith parametric and non-parametric embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 00:32:28 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Sun", "Ke", ""]]}, {"id": "1811.01466", "submitter": "Vu Nguyen", "authors": "Vu Nguyen, Sunil Gupta, Santu Rana, Cheng Li, Svetha Venkatesh", "title": "Practical Batch Bayesian Optimization for Less Expensive Functions", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) and its batch extensions are successful for\noptimizing expensive black-box functions. However, these traditional BO\napproaches are not yet ideal for optimizing less expensive functions when the\ncomputational cost of BO can dominate the cost of evaluating the blackbox\nfunction. Examples of these less expensive functions are cheap machine learning\nmodels, inexpensive physical experiment through simulators, and acquisition\nfunction optimization in Bayesian optimization. In this paper, we consider a\nbatch BO setting for situations where function evaluations are less expensive.\nOur model is based on a new exploration strategy using geometric distance that\nprovides an alternative way for exploration, selecting a point far from the\nobserved locations. Using that intuition, we propose to use Sobol sequence to\nguide exploration that will get rid of running multiple global optimization\nsteps as used in previous works. Based on the proposed distance exploration, we\npresent an efficient batch BO approach. We demonstrate that our approach\noutperforms other baselines and global optimization methods when the function\nevaluations are less expensive.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 00:49:31 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Nguyen", "Vu", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Li", "Cheng", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1811.01483", "submitter": "Jongwook Choi", "authors": "Jongwook Choi, Yijie Guo, Marcin Moczulski, Junhyuk Oh, Neal Wu,\n  Mohammad Norouzi, Honglak Lee", "title": "Contingency-Aware Exploration in Reinforcement Learning", "comments": "In ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates whether learning contingency-awareness and\ncontrollable aspects of an environment can lead to better exploration in\nreinforcement learning. To investigate this question, we consider an\ninstantiation of this hypothesis evaluated on the Arcade Learning Element\n(ALE). In this study, we develop an attentive dynamics model (ADM) that\ndiscovers controllable elements of the observations, which are often associated\nwith the location of the character in Atari games. The ADM is trained in a\nself-supervised fashion to predict the actions taken by the agent. The learned\ncontingency information is used as a part of the state representation for\nexploration purposes. We demonstrate that combining actor-critic algorithm with\ncount-based exploration using our representation achieves impressive results on\na set of notoriously challenging Atari games due to sparse rewards. For\nexample, we report a state-of-the-art score of >11,000 points on Montezuma's\nRevenge without using expert demonstrations, explicit high-level information\n(e.g., RAM states), or supervisory data. Our experiments confirm that\ncontingency-awareness is indeed an extremely powerful concept for tackling\nexploration problems in reinforcement learning and opens up interesting\nresearch questions for further investigations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 02:12:11 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 05:12:36 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 18:55:24 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Choi", "Jongwook", ""], ["Guo", "Yijie", ""], ["Moczulski", "Marcin", ""], ["Oh", "Junhyuk", ""], ["Wu", "Neal", ""], ["Norouzi", "Mohammad", ""], ["Lee", "Honglak", ""]]}, {"id": "1811.01501", "submitter": "Zhouchen Lin", "authors": "Jia Li, Cong Fang, Zhouchen Lin", "title": "Lifted Proximal Operator Machines", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new optimization method for training feed-forward neural\nnetworks. By rewriting the activation function as an equivalent proximal\noperator, we approximate a feed-forward neural network by adding the proximal\noperators to the objective function as penalties, hence we call the lifted\nproximal operator machine (LPOM). LPOM is block multi-convex in all layer-wise\nweights and activations. This allows us to use block coordinate descent to\nupdate the layer-wise weights and activations in parallel. Most notably, we\nonly use the mapping of the activation function itself, rather than its\nderivatives, thus avoiding the gradient vanishing or blow-up issues in gradient\nbased training methods. So our method is applicable to various non-decreasing\nLipschitz continuous activation functions, which can be saturating and\nnon-differentiable. LPOM does not require more auxiliary variables than the\nlayer-wise activations, thus using roughly the same amount of memory as\nstochastic gradient descent (SGD) does. We further prove the convergence of\nupdating the layer-wise weights and activations. Experiments on MNIST and\nCIFAR-10 datasets testify to the advantages of LPOM.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 03:33:24 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Li", "Jia", ""], ["Fang", "Cong", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1811.01506", "submitter": "Connie Kou", "authors": "Connie Kou, Hwee Kuan Lee, Jorge Sanz, Teck Khim Ng", "title": "Theoretical and Experimental Analysis on the Generalizability of\n  Distribution Regression Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is emerging interest in performing regression between distributions. In\ncontrast to prediction on single instances, these machine learning methods can\nbe useful for population-based studies or on problems that are inherently\nstatistical in nature. The recently proposed distribution regression network\n(DRN) has shown superior performance for the distribution-to-distribution\nregression task compared to conventional neural networks. However, in Kou et\nal. (2018) and some other works on distribution regression, there is a lack of\ncomprehensive comparative study on both theoretical basis and generalization\nabilities of the methods. We derive some mathematical properties of DRN and\nqualitatively compare it to conventional neural networks. We also perform\ncomprehensive experiments to study the generalizability of distribution\nregression models, by studying their robustness to limited training data, data\nsampling noise and task difficulty. DRN consistently outperforms conventional\nneural networks, requiring fewer training data and maintaining robust\nperformance with noise. Furthermore, the theoretical properties of DRN can be\nused to provide some explanation on the ability of DRN to achieve better\ngeneralization performance than conventional neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 04:09:49 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 06:56:39 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 07:23:21 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Kou", "Connie", ""], ["Lee", "Hwee Kuan", ""], ["Sanz", "Jorge", ""], ["Ng", "Teck Khim", ""]]}, {"id": "1811.01531", "submitter": "Efthymios Tzinis", "authors": "Efthymios Tzinis, Shrikant Venkataramani and Paris Smaragdis", "title": "Unsupervised Deep Clustering for Source Separation: Direct Learning from\n  Mixtures using Spatial Information", "comments": "Submitted to ICASSP 2019 (v1: November 5th 2018)", "journal-ref": "ICASSP 2019 - 2019 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP.2019.8683201", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a monophonic source separation system that is trained by only\nobserving mixtures with no ground truth separation information. We use a deep\nclustering approach which trains on multi-channel mixtures and learns to\nproject spectrogram bins to source clusters that correlate with various spatial\nfeatures. We show that using such a training process we can obtain separation\nperformance that is as good as making use of ground truth separation\ninformation. Once trained, this system is capable of performing sound\nseparation on monophonic inputs, despite having learned how to do so using\nmulti-channel recordings.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 07:00:12 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 07:39:34 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Tzinis", "Efthymios", ""], ["Venkataramani", "Shrikant", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1811.01533", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Transfer learning for time series classification", "comments": "Accepted at IEEE International Conference on Big Data 2018", "journal-ref": null, "doi": "10.1109/BigData.2018.8621990", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning for deep neural networks is the process of first training a\nbase network on a source dataset, and then transferring the learned features\n(the network's weights) to a second network to be trained on a target dataset.\nThis idea has been shown to improve deep neural network's generalization\ncapabilities in many computer vision tasks such as image recognition and object\nlocalization. Apart from these applications, deep Convolutional Neural Networks\n(CNNs) have also recently gained popularity in the Time Series Classification\n(TSC) community. However, unlike for image recognition problems, transfer\nlearning techniques have not yet been investigated thoroughly for the TSC task.\nThis is surprising as the accuracy of deep learning models for TSC could\npotentially be improved if the model is fine-tuned from a pre-trained neural\nnetwork instead of training it from scratch. In this paper, we fill this gap by\ninvestigating how to transfer deep CNNs for the TSC task. To evaluate the\npotential of transfer learning, we performed extensive experiments using the\nUCR archive which is the largest publicly available TSC benchmark containing 85\ndatasets. For each dataset in the archive, we pre-trained a model and then\nfine-tuned it on the other datasets resulting in 7140 different deep neural\nnetworks. These experiments revealed that transfer learning can improve or\ndegrade the model's predictions depending on the dataset used for transfer.\nTherefore, in an effort to predict the best source dataset for a given target\ndataset, we propose a new method relying on Dynamic Time Warping to measure\ninter-datasets similarities. We describe how our method can guide the transfer\nto choose the best source dataset leading to an improvement in accuracy on 71\nout of 85 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 07:06:32 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1811.01545", "submitter": "Ping Guo", "authors": "P. Guo, K. Wang, and X. L. Zhou", "title": "PILAE: A Non-gradient Descent Learning Scheme for Deep Feedforward\n  Neural Networks", "comments": "This work is our effort toward to realize AutoML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a non-gradient descent learning scheme is proposed for deep\nfeedforward neural networks (DNN). As we known, autoencoder can be used as the\nbuilding blocks of the multi-layer perceptron (MLP) deep neural network. So,\nthe MLP will be taken as an example to illustrate the proposed scheme of\npseudoinverse learning algorithm for autoencoder (PILAE) training. The PILAE\nwith low rank approximation is a non-gradient based learning algorithm, and the\nencoder weight matrix is set to be the low rank approximation of the\npseudoinverse of the input matrix, while the decoder weight matrix is\ncalculated by the pseudoinverse learning algorithm. It is worth to note that\nonly few network structure hyperparameters need to be tuned. Hence, the\nproposed algorithm can be regarded as a quasi-automated training algorithm\nwhich can be utilized in autonomous machine learning research field. The\nexperimental results show that the proposed learning scheme for DNN can achieve\nbetter performance on considering the tradeoff between training efficiency and\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 08:14:11 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 01:30:10 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Guo", "P.", ""], ["Wang", "K.", ""], ["Zhou", "X. L.", ""]]}, {"id": "1811.01557", "submitter": "Chin-Chia Michael Yeh", "authors": "Chin-Chia Michael Yeh, Yan Zhu, Evangelos E. Papalexakis, Abdullah\n  Mueen, Eamonn Keogh", "title": "Representation Learning by Reconstructing Neighborhoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its introduction, unsupervised representation learning has attracted a\nlot of attention from the research community, as it is demonstrated to be\nhighly effective and easy-to-apply in tasks such as dimension reduction,\nclustering, visualization, information retrieval, and semi-supervised learning.\nIn this work, we propose a novel unsupervised representation learning framework\ncalled neighbor-encoder, in which domain knowledge can be easily incorporated\ninto the learning process without modifying the general encoder-decoder\narchitecture of the classic autoencoder.In contrast to autoencoder, which\nreconstructs the input data itself, neighbor-encoder reconstructs the input\ndata's neighbors. As the proposed representation learning problem is\nessentially a neighbor reconstruction problem, domain knowledge can be easily\nincorporated in the form of an appropriate definition of similarity between\nobjects. Based on that observation, our framework can leverage any\noff-the-shelf similarity search algorithms or side information to find the\nneighbor of an input object. Applications of other algorithms (e.g.,\nassociation rule mining) in our framework are also possible, given that the\nappropriate definition of neighbor can vary in different contexts. We have\ndemonstrated the effectiveness of our framework in many diverse domains,\nincluding images, text, and time series, and for various data mining tasks\nincluding classification, clustering, and visualization. Experimental results\nshow that neighbor-encoder not only outperforms autoencoder in most of the\nscenarios we consider, but also achieves the state-of-the-art performance on\ntext document clustering.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 08:56:21 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 06:31:16 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Yeh", "Chin-Chia Michael", ""], ["Zhu", "Yan", ""], ["Papalexakis", "Evangelos E.", ""], ["Mueen", "Abdullah", ""], ["Keogh", "Eamonn", ""]]}, {"id": "1811.01558", "submitter": "Qianxiao Li", "authors": "Qianxiao Li, Cheng Tai, Weinan E", "title": "Stochastic Modified Equations and Dynamics of Stochastic Gradient\n  Algorithms I: Mathematical Foundations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the mathematical foundations of the stochastic modified equations\n(SME) framework for analyzing the dynamics of stochastic gradient algorithms,\nwhere the latter is approximated by a class of stochastic differential\nequations with small noise parameters. We prove that this approximation can be\nunderstood mathematically as an weak approximation, which leads to a number of\nprecise and useful results on the approximations of stochastic gradient descent\n(SGD), momentum SGD and stochastic Nesterov's accelerated gradient method in\nthe general setting of stochastic objectives. We also demonstrate through\nexplicit calculations that this continuous-time approach can uncover important\nanalytical insights into the stochastic gradient algorithms under consideration\nthat may not be easy to obtain in a purely discrete-time setting.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 09:00:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Li", "Qianxiao", ""], ["Tai", "Cheng", ""], ["E", "Weinan", ""]]}, {"id": "1811.01564", "submitter": "Nikolas Ioannou", "authors": "Nikolas Ioannou, Celestine D\\\"unner, Kornilios Kourtis, and Thomas\n  Parnell", "title": "Parallel training of linear models without compromising convergence", "comments": "Presented at the Workshop on Systems for ML and Open Source Software\n  at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze, evaluate, and improve the performance of training\ngeneralized linear models on modern CPUs. We start with a state-of-the-art\nasynchronous parallel training algorithm, identify system-level performance\nbottlenecks, and apply optimizations that improve data parallelism, cache line\nlocality, and cache line prefetching of the algorithm. These modifications\nreduce the per-epoch run-time significantly, but take a toll on algorithm\nconvergence in terms of the required number of epochs. To alleviate these\nshortcomings of our systems-optimized version, we propose a novel, dynamic data\npartitioning scheme across threads which allows us to approach the convergence\nof the sequential version. The combined set of optimizations result in a\nconsistent bottom line speedup in convergence of up to 12x compared to the\ninitial asynchronous parallel training algorithm and up to 42x, compared to\nstate of the art implementations (scikit-learn and h2o) on a range of\nmulti-core CPU architectures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 09:23:41 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 16:12:12 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Ioannou", "Nikolas", ""], ["D\u00fcnner", "Celestine", ""], ["Kourtis", "Kornilios", ""], ["Parnell", "Thomas", ""]]}, {"id": "1811.01574", "submitter": "Kaihui Liu", "authors": "Kaihui Liu, Jiayi Wang, Zhengli Xing, Linxiao Yang, and Jun Fang", "title": "Low-Rank Phase Retrieval via Variational Bayesian Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of low-rank phase retrieval whose\nobjective is to estimate a complex low-rank matrix from magnitude-only\nmeasurements. We propose a hierarchical prior model for low-rank phase\nretrieval, in which a Gaussian-Wishart hierarchical prior is placed on the\nunderlying low-rank matrix to promote the low-rankness of the matrix. Based on\nthe proposed hierarchical model, a variational expectation-maximization (EM)\nalgorithm is developed. The proposed method is less sensitive to the choice of\nthe initialization point and works well with random initialization. Simulation\nresults are provided to illustrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 09:47:31 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Liu", "Kaihui", ""], ["Wang", "Jiayi", ""], ["Xing", "Zhengli", ""], ["Yang", "Linxiao", ""], ["Fang", "Jun", ""]]}, {"id": "1811.01587", "submitter": "Xiaoliang Song", "authors": "Yiyang Wang, Risheng Liu, Long Ma and Xiaoliang Song", "title": "Task Embedded Coordinate Update: A Realizable Framework for Multivariate\n  Non-convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We in this paper propose a realizable framework TECU, which embeds\ntask-specific strategies into update schemes of coordinate descent, for\noptimizing multivariate non-convex problems with coupled objective functions.\nOn one hand, TECU is capable of improving algorithm efficiencies through\nembedding productive numerical algorithms, for optimizing univariate\nsub-problems with nice properties. From the other side, it also augments\nprobabilities to receive desired results, by embedding advanced techniques in\noptimizations of realistic tasks. Integrating both numerical algorithms and\nadvanced techniques together, TECU is proposed in a unified framework for\nsolving a class of non-convex problems. Although the task embedded strategies\nbring inaccuracies in sub-problem optimizations, we provide a realizable\ncriterion to control the errors, meanwhile, to ensure robust performances with\nrigid theoretical analyses. By respectively embedding ADMM and a residual-type\nCNN in our algorithm framework, the experimental results verify both efficiency\nand effectiveness of embedding task-oriented strategies in coordinate descent\nfor solving practical problems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 10:15:43 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 06:01:18 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Wang", "Yiyang", ""], ["Liu", "Risheng", ""], ["Ma", "Long", ""], ["Song", "Xiaoliang", ""]]}, {"id": "1811.01609", "submitter": "Hirokazu Kameoka", "authors": "Hirokazu Kameoka, Kou Tanaka, Damian Kwasny, Takuhiro Kaneko,\n  Nobukatsu Hojo", "title": "ConvS2S-VC: Fully convolutional sequence-to-sequence voice conversion", "comments": "Published in IEEE/ACM Trans. ASLP\n  https://ieeexplore.ieee.org/document/9113442", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a voice conversion (VC) method using sequence-to-sequence\n(seq2seq or S2S) learning, which flexibly converts not only the voice\ncharacteristics but also the pitch contour and duration of input speech. The\nproposed method, called ConvS2S-VC, has three key features. First, it uses a\nmodel with a fully convolutional architecture. This is particularly\nadvantageous in that it is suitable for parallel computations using GPUs. It is\nalso beneficial since it enables effective normalization techniques such as\nbatch normalization to be used for all the hidden layers in the networks.\nSecond, it achieves many-to-many conversion by simultaneously learning mappings\namong multiple speakers using only a single model instead of separately\nlearning mappings between each speaker pair using a different model. This\nenables the model to fully utilize available training data collected from\nmultiple speakers by capturing common latent features that can be shared across\ndifferent speakers. Owing to this structure, our model works reasonably well\neven without source speaker information, thus making it able to handle\nany-to-many conversion tasks. Third, we introduce a mechanism, called the\nconditional batch normalization that switches batch normalization layers in\naccordance with the target speaker. This particular mechanism has been found to\nbe extremely effective for our many-to-many conversion model. We conducted\nspeaker identity conversion experiments and found that ConvS2S-VC obtained\nhigher sound quality and speaker similarity than baseline methods. We also\nfound from audio examples that it could perform well in various tasks including\nemotional expression conversion, electrolaryngeal speech enhancement, and\nEnglish accent conversion.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 11:02:29 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 09:28:54 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 19:14:50 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Kameoka", "Hirokazu", ""], ["Tanaka", "Kou", ""], ["Kwasny", "Damian", ""], ["Kaneko", "Takuhiro", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "1811.01640", "submitter": "Michele Alberti", "authors": "Vinaychandran Pondenkandath, Michele Alberti, Sammer Puran, Rolf\n  Ingold, Marcus Liwicki", "title": "Leveraging Random Label Memorization for Unsupervised Pre-Training", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to leverage large unlabeled datasets by\npre-training state-of-the-art deep neural networks on randomly-labeled\ndatasets. Specifically, we train the neural networks to memorize arbitrary\nlabels for all the samples in a dataset and use these pre-trained networks as a\nstarting point for regular supervised learning. Our assumption is that the\n\"memorization infrastructure\" learned by the network during the random-label\ntraining proves to be beneficial for the conventional supervised learning as\nwell. We test the effectiveness of our pre-training on several video action\nrecognition datasets (HMDB51, UCF101, Kinetics) by comparing the results of the\nsame network with and without the random label pre-training. Our approach\nyields an improvement - ranging from 1.5% on UCF-101 to 5% on Kinetics - in\nclassification accuracy, which calls for further research in this direction.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 12:27:14 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Pondenkandath", "Vinaychandran", ""], ["Alberti", "Michele", ""], ["Puran", "Sammer", ""], ["Ingold", "Rolf", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1811.01661", "submitter": "Stanislaw Gorlow", "authors": "Pedro J. Villasana T. and Stanislaw Gorlow", "title": "Exact multiplicative updates for convolutional $\\beta$-NMF in 2D", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend the $\\beta$-CNMF to two dimensions and derive exact\nmultiplicative updates for its factors. The new updates generalize and correct\nthe nonnegative matrix factor deconvolution previously proposed by Schmidt and\nM{\\o}rup. We show by simulation that the updates lead to a monotonically\ndecreasing $\\beta$-divergence in terms of the mean and the standard deviation\nand that the corresponding convergence curves are consistent across the most\ncommon values for $\\beta$.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 13:17:55 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["T.", "Pedro J. Villasana", ""], ["Gorlow", "Stanislaw", ""]]}, {"id": "1811.01662", "submitter": "Tien Huu Do", "authors": "Tien Huu Do, Duc Minh Nguyen, Evaggelia Tsiligianni, Angel Lopez\n  Aguirre, Valerio Panzica La Manna, Frank Pasveer, Wilfried Philips, Nikos\n  Deligiannis", "title": "Matrix Completion With Variational Graph Autoencoders: Application in\n  Hyperlocal Air Quality Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring air quality from a limited number of observations is an essential\ntask for monitoring and controlling air pollution. Existing inference methods\ntypically use low spatial resolution data collected by fixed monitoring\nstations and infer the concentration of air pollutants using additional types\nof data, e.g., meteorological and traffic information. In this work, we focus\non street-level air quality inference by utilizing data collected by mobile\nstations. We formulate air quality inference in this setting as a graph-based\nmatrix completion problem and propose a novel variational model based on graph\nconvolutional autoencoders. Our model captures effectively the spatio-temporal\ncorrelation of the measurements and does not depend on the availability of\nadditional information apart from the street-network topology. Experiments on a\nreal air quality dataset, collected with mobile stations, shows that the\nproposed model outperforms state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 13:18:32 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Do", "Tien Huu", ""], ["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Aguirre", "Angel Lopez", ""], ["La Manna", "Valerio Panzica", ""], ["Pasveer", "Frank", ""], ["Philips", "Wilfried", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1811.01686", "submitter": "Arash Khoeini", "authors": "Arash Khoeini, Bita Shams, Saman Haratizadeh", "title": "GEMRank: Global Entity Embedding For Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, word embedding algorithms have been applied to map the entities of\nrecommender systems, such as users and items, to new feature spaces using\ntextual element-context relations among them. Unlike many other domains, this\napproach has not achieved a desired performance in collaborative filtering\nproblems, probably due to unavailability of appropriate textual data. In this\npaper we propose a new recommendation framework, called GEMRank that can be\napplied when the user-item matrix is the sole available souce of information.\nIt uses the concept of profile co-occurrence for defining relations among\nentities and applies a factorization method for embedding the users and items.\nGEMRank then feeds the extracted representations to a neural network model to\npredict user-item like/dislike relations which the final recommendations are\nmade based on. We evaluated GEMRank in an extensive set of experiments against\nstate of the art recommendation methods. The results show that GEMRank\nsignificantly outperforms the baseline algorithms in a variety of data sets\nwith different degrees of density.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 13:54:20 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Khoeini", "Arash", ""], ["Shams", "Bita", ""], ["Haratizadeh", "Saman", ""]]}, {"id": "1811.01704", "submitter": "Ahmed Taha Elthakeb", "authors": "Ahmed T. Elthakeb, Prannoy Pilligundla, FatemehSadat Mireshghallah,\n  Amir Yazdanbakhsh, Hadi Esmaeilzadeh", "title": "ReLeQ: A Reinforcement Learning Approach for Deep Quantization of Neural\n  Networks", "comments": "Presented as a spotlight paper at NeurIPS Workshop on ML for Systems\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) typically require massive amount of computation\nresource in inference tasks for computer vision applications. Quantization can\nsignificantly reduce DNN computation and storage by decreasing the bitwidth of\nnetwork encodings. Recent research affirms that carefully selecting the\nquantization levels for each layer can preserve the accuracy while pushing the\nbitwidth below eight bits. However, without arduous manual effort, this deep\nquantization can lead to significant accuracy loss, leaving it in a position of\nquestionable utility. As such, deep quantization opens a large hyper-parameter\nspace (bitwidth of the layers), the exploration of which is a major challenge.\nWe propose a systematic approach to tackle this problem, by automating the\nprocess of discovering the quantization levels through an end-to-end deep\nreinforcement learning framework (ReLeQ). We adapt policy optimization methods\nto the problem of quantization, and focus on finding the best design decisions\nin choosing the state and action spaces, network architecture and training\nframework, as well as the tuning of various hyperparamters. We show how ReLeQ\ncan balance speed and quality, and provide an asymmetric general solution for\nquantization of a large variety of deep networks (AlexNet, CIFAR-10, LeNet,\nMobileNet-V1, ResNet-20, SVHN, and VGG-11) that virtually preserves the\naccuracy (=< 0.3% loss) while minimizing the computation and storage cost. With\nthese DNNs, ReLeQ enables conventional hardware to achieve 2.2x speedup over\n8-bit execution. Similarly, a custom DNN accelerator achieves 2.0x speedup and\nenergy reduction compared to 8-bit runs. These encouraging results mark ReLeQ\nas the initial step towards automating the deep quantization of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:18:06 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 23:49:36 GMT"}, {"version": "v3", "created": "Fri, 17 May 2019 02:02:27 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2020 17:17:43 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Elthakeb", "Ahmed T.", ""], ["Pilligundla", "Prannoy", ""], ["Mireshghallah", "FatemehSadat", ""], ["Yazdanbakhsh", "Amir", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1811.01710", "submitter": "Shankar Kumar", "authors": "Jared Lichtarge, Christopher Alberti, Shankar Kumar, Noam Shazeer,\n  Niki Parmar", "title": "Weakly Supervised Grammatical Error Correction using Iterative Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach to Grammatical Error Correction (GEC) that is\neffective at making use of models trained on large amounts of weakly supervised\nbitext. We train the Transformer sequence-to-sequence model on 4B tokens of\nWikipedia revisions and employ an iterative decoding strategy that is tailored\nto the loosely-supervised nature of the Wikipedia training corpus. Finetuning\non the Lang-8 corpus and ensembling yields an F0.5 of 58.3 on the CoNLL'14\nbenchmark and a GLEU of 62.4 on JFLEG. The combination of weakly supervised\ntraining and iterative decoding obtains an F0.5 of 48.2 on CoNLL'14 even\nwithout using any labeled GEC data.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 01:31:10 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Lichtarge", "Jared", ""], ["Alberti", "Christopher", ""], ["Kumar", "Shankar", ""], ["Shazeer", "Noam", ""], ["Parmar", "Niki", ""]]}, {"id": "1811.01713", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian E.H. Yen, Kun Xu, Fangli Xu, Avinash Balakrishnan,\n  Pin-Yu Chen, Pradeep Ravikumar, Michael J. Witbrock", "title": "Word Mover's Embedding: From Word2Vec to Document Embedding", "comments": "EMNLP'18 Camera-Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the celebrated Word2Vec technique yields semantically rich\nrepresentations for individual words, there has been relatively less success in\nextending to generate unsupervised sentences or documents embeddings. Recent\nwork has demonstrated that a distance measure between documents called\n\\emph{Word Mover's Distance} (WMD) that aligns semantically similar words,\nyields unprecedented KNN classification accuracy. However, WMD is expensive to\ncompute, and it is hard to extend its use beyond a KNN classifier. In this\npaper, we propose the \\emph{Word Mover's Embedding } (WME), a novel approach to\nbuilding an unsupervised document (sentence) embedding from pre-trained word\nembeddings. In our experiments on 9 benchmark text classification datasets and\n22 textual similarity tasks, the proposed technique consistently matches or\noutperforms state-of-the-art techniques, with significantly higher accuracy on\nproblems of short length.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 19:43:17 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian E. H.", ""], ["Xu", "Kun", ""], ["Xu", "Fangli", ""], ["Balakrishnan", "Avinash", ""], ["Chen", "Pin-Yu", ""], ["Ravikumar", "Pradeep", ""], ["Witbrock", "Michael J.", ""]]}, {"id": "1811.01715", "submitter": "Siwei Wang", "authors": "Siwei Wang, Longbo Huang", "title": "Multi-armed Bandits with Compensation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study the known-compensation multi-arm bandit (KCMAB) problem,\nwhere a system controller offers a set of arms to many short-term players for\n$T$ steps. In each step, one short-term player arrives to the system. Upon\narrival, the player aims to select an arm with the current best average reward\nand receives a stochastic reward associated with the arm. In order to\nincentivize players to explore other arms, the controller provides a proper\npayment compensation to players. The objective of the controller is to maximize\nthe total reward collected by players while minimizing the compensation. We\nfirst provide a compensation lower bound $\\Theta(\\sum_i {\\Delta_i\\log T\\over\nKL_i})$, where $\\Delta_i$ and $KL_i$ are the expected reward gap and\nKullback-Leibler (KL) divergence between distributions of arm $i$ and the best\narm, respectively. We then analyze three algorithms to solve the KCMAB problem,\nand obtain their regrets and compensations. We show that the algorithms all\nachieve $O(\\log T)$ regret and $O(\\log T)$ compensation that match the\ntheoretical lower bound. Finally, we present experimental results to\ndemonstrate the performance of the algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:24:46 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Wang", "Siwei", ""], ["Huang", "Longbo", ""]]}, {"id": "1811.01742", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Robert Sabourin and George D. C. Cavalcanti", "title": "META-DES.H: a dynamic ensemble selection technique using meta-learning\n  and a dynamic weighting approach", "comments": "arXiv admin note: substantial text overlap with arXiv:1509.00825,\n  arXiv:1810.01270, arXiv:1811.00217", "journal-ref": "Published on the International Joint Conference on Neural Networks\n  (IJCNN), 2015, pp. 1-8", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Dynamic Ensemble Selection (DES) techniques, only the most competent\nclassifiers are selected to classify a given query sample. Hence, the key issue\nin DES is how to estimate the competence of each classifier in a pool to select\nthe most competent ones. In order to deal with this issue, we proposed a novel\ndynamic ensemble selection framework using meta-learning, called META-DES. The\nframework is divided into three steps. In the first step, the pool of\nclassifiers is generated from the training data. In the second phase the\nmeta-features are computed using the training data and used to train a\nmeta-classifier that is able to predict whether or not a base classifier from\nthe pool is competent enough to classify an input instance. In this paper, we\npropose improvements to the training and generalization phase of the META-DES\nframework. In the training phase, we evaluate four different algorithms for the\ntraining of the meta-classifier. For the generalization phase, three\ncombination approaches are evaluated: Dynamic selection, where only the\nclassifiers that attain a certain competence level are selected; Dynamic\nweighting, where the meta-classifier estimates the competence of each\nclassifier in the pool, and the outputs of all classifiers in the pool are\nweighted based on their level of competence; and a hybrid approach, in which\nfirst an ensemble with the most competent classifiers is selected, after which\nthe weights of the selected classifiers are estimated in order to be used in a\nweighted majority voting scheme. Experiments are carried out on 30\nclassification datasets. Experimental results demonstrate that the changes\nproposed in this paper significantly improve the recognition accuracy of the\nsystem in several datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:28:01 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1811.01743", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti", "title": "On Meta-Learning for Dynamic Ensemble Selection", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.01270;\n  text overlap with arXiv:1509.00825", "journal-ref": "Published on the International Conference on Pattern Recognition\n  (ICPR), 2014, pp. 1230-1235", "doi": "10.1109/ICPR.2014.221", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel dynamic ensemble selection framework using\nmeta-learning. The framework is divided into three steps. In the first step,\nthe pool of classifiers is generated from the training data. The second phase\nis responsible to extract the meta-features and train the meta-classifier. Five\ndistinct sets of meta-features are proposed, each one corresponding to a\ndifferent criterion to measure the level of competence of a classifier for the\nclassification of a given query sample. The meta-features are computed using\nthe training data and used to train a meta-classifier that is able to predict\nwhether or not a base classifier from the pool is competent enough to classify\nan input instance. Three different training scenarios for the training of the\nmeta-classifier are considered: problem-dependent, problem-independent and\nhybrid. Experimental results show that the problem-dependent scenario provides\nthe best result. In addition, the performance of the problem-dependent scenario\nis strongly correlated with the recognition rate of the system. A comparison\nwith state-of-the-art techniques shows that the proposed-dependent approach\noutperforms current dynamic ensemble selection techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:13:38 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1811.01747", "submitter": "Ali Emami Mr.", "authors": "Ali Emami, Paul Trichelair, Adam Trischler, Kaheer Suleman, Hannes\n  Schulz and Jackie Chi Kit Cheung", "title": "The Knowref Coreference Corpus: Removing Gender and Number Cues for\n  Difficult Pronominal Anaphora Resolution", "comments": "9 pages (excluding references), accepted for ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new benchmark for coreference resolution and NLI, Knowref,\nthat targets common-sense understanding and world knowledge. Previous\ncoreference resolution tasks can largely be solved by exploiting the number and\ngender of the antecedents, or have been handcrafted and do not reflect the\ndiversity of naturally occurring text. We present a corpus of over 8,000\nannotated text passages with ambiguous pronominal anaphora. These instances are\nboth challenging and realistic. We show that various coreference systems,\nwhether rule-based, feature-rich, or neural, perform significantly worse on the\ntask than humans, who display high inter-annotator agreement. To explain this\nperformance gap, we show empirically that state-of-the art models often fail to\ncapture context, instead relying on the gender or number of candidate\nantecedents to make a decision. We then use problem-specific insights to\npropose a data-augmentation trick called antecedent switching to alleviate this\ntendency in models. Finally, we show that antecedent switching yields promising\nresults on other tasks as well: we use it to achieve state-of-the-art results\non the GAP coreference task.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:41:26 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 22:16:35 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 20:06:32 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Emami", "Ali", ""], ["Trichelair", "Paul", ""], ["Trischler", "Adam", ""], ["Suleman", "Kaheer", ""], ["Schulz", "Hannes", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1811.01753", "submitter": "Patrick Krauss", "authors": "Achim Schilling, Claus Metzner, Jonas Rietsch, Richard Gerum, Holger\n  Schulze, Patrick Krauss", "title": "How deep is deep enough? -- Quantifying class separability in the hidden\n  layers of deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks typically outperform more traditional machine learning\nmodels in their ability to classify complex data, and yet is not clear how the\nindividual hidden layers of a deep network contribute to the overall\nclassification performance. We thus introduce a Generalized Discrimination\nValue (GDV) that measures, in a non-invasive manner, how well different data\nclasses separate in each given network layer. The GDV can be used for the\nautomatic tuning of hyper-parameters, such as the width profile and the total\ndepth of a network. Moreover, the layer-dependent GDV(L) provides new insights\ninto the data transformations that self-organize during training: In the case\nof multi-layer perceptrons trained with error backpropagation, we find that\nclassification of highly complex data sets requires a temporal {\\em reduction}\nof class separability, marked by a characteristic 'energy barrier' in the\ninitial part of the GDV(L) curve. Even more surprisingly, for a given data set,\nthe GDV(L) is running through a fixed 'master curve', independently from the\ntotal number of network layers. Furthermore, applying the GDV to Deep Belief\nNetworks reveals that also unsupervised training with the Contrastive\nDivergence method can systematically increase class separability over tens of\nlayers, even though the system does not 'know' the desired class labels. These\nresults indicate that the GDV may become a useful tool to open the black box of\ndeep learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:46:12 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 13:09:32 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Schilling", "Achim", ""], ["Metzner", "Claus", ""], ["Rietsch", "Jonas", ""], ["Gerum", "Richard", ""], ["Schulze", "Holger", ""], ["Krauss", "Patrick", ""]]}, {"id": "1811.01760", "submitter": "Junhong Lin", "authors": "Junhong Lin and Volkan Cevher", "title": "Kernel Conjugate Gradient Methods with Random Projections", "comments": "43 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study kernel conjugate gradient methods (KCGM) with random\nprojections for least-squares regression over a separable Hilbert space.\nConsidering two types of random projections generated by randomized sketches\nand Nystr\\\"{o}m subsampling, we prove optimal statistical results with respect\nto variants of norms for the algorithms under a suitable stopping rule.\nParticularly, our results show that if the projection dimension is proportional\nto the effective dimension of the problem, KCGM with randomized sketches can\ngeneralize optimally, while achieving a computational advantage. As a\ncorollary, we derive optimal rates for classic KCGM in the case that the target\nfunction may not be in the hypothesis space, filling a theoretical gap.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:50:58 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Lin", "Junhong", ""], ["Cevher", "Volkan", ""]]}, {"id": "1811.01777", "submitter": "Tao Sun", "authors": "Tao Sun, Penghang Yin, Dongsheng Li, Chun Huang, Lei Guan, Hao Jiang", "title": "Non-ergodic Convergence Analysis of Heavy-Ball Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the convergence of the Heavy-ball method, and\npresent improved convergence complexity results in the convex setting. We\nprovide the first non-ergodic O(1/k) rate result of the Heavy-ball algorithm\nwith constant step size for coercive objective functions. For objective\nfunctions satisfying a relaxed strongly convex condition, the linear\nconvergence is established under weaker assumptions on the step size and\ninertial parameter than made in the existing literature. We extend our results\nto multi-block version of the algorithm with both the cyclic and stochastic\nupdate rules. In addition, our results can also be extended to decentralized\noptimization, where the ergodic analysis is not applicable.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 15:10:39 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 12:14:17 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Sun", "Tao", ""], ["Yin", "Penghang", ""], ["Li", "Dongsheng", ""], ["Huang", "Chun", ""], ["Guan", "Lei", ""], ["Jiang", "Hao", ""]]}, {"id": "1811.01778", "submitter": "Paul Trichelair", "authors": "Paul Trichelair and Ali Emami and Adam Trischler and Kaheer Suleman\n  and Jackie Chi Kit Cheung", "title": "How Reasonable are Common-Sense Reasoning Tasks: A Case-Study on the\n  Winograd Schema Challenge and SWAG", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have significantly improved the state-of-the-art on\ncommon-sense reasoning (CSR) benchmarks like the Winograd Schema Challenge\n(WSC) and SWAG. The question we ask in this paper is whether improved\nperformance on these benchmarks represents genuine progress towards\ncommon-sense-enabled systems. We make case studies of both benchmarks and\ndesign protocols that clarify and qualify the results of previous work by\nanalyzing threats to the validity of previous experimental designs. Our\nprotocols account for several properties prevalent in common-sense benchmarks\nincluding size limitations, structural regularities, and variable instance\ndifficulty.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 15:11:24 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:28:44 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Trichelair", "Paul", ""], ["Emami", "Ali", ""], ["Trischler", "Adam", ""], ["Suleman", "Kaheer", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1811.01811", "submitter": "Kemal Davaslioglu", "authors": "Yi Shi, Yalin E. Sagduyu, Kemal Davaslioglu, and Jason H. Li", "title": "Active Deep Learning Attacks under Strict Rate Limitations for Online\n  API Calls", "comments": "Presented at 2018 IEEE International Symposium on Technologies for\n  Homeland Security (HST) on October 23 2018. Received the Best Paper Award in\n  Cyber Security Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been applied to a broad range of applications and some\nof them are available online as application programming interfaces (APIs) with\neither free (trial) or paid subscriptions. In this paper, we study adversarial\nmachine learning in the form of back-box attacks on online classifier APIs. We\nstart with a deep learning based exploratory (inference) attack, which aims to\nbuild a classifier that can provide similar classification results (labels) as\nthe target classifier. To minimize the difference between the labels returned\nby the inferred classifier and the target classifier, we show that the deep\nlearning based exploratory attack requires a large number of labeled training\ndata samples. These labels can be collected by calling the online API, but\nusually there is some strict rate limitation on the number of allowed API\ncalls. To mitigate the impact of limited training data, we develop an active\nlearning approach that first builds a classifier based on a small number of API\ncalls and uses this classifier to select samples to further collect their\nlabels. Then, a new classifier is built using more training data samples. This\nupdating process can be repeated multiple times. We show that this active\nlearning approach can build an adversarial classifier with a small statistical\ndifference from the target classifier using only a limited number of training\ndata samples. We further consider evasion and causative (poisoning) attacks\nbased on the inferred classifier that is built by the exploratory attack.\nEvasion attack determines samples that the target classifier is likely to\nmisclassify, whereas causative attack provides erroneous training data samples\nto reduce the reliability of the re-trained classifier. The success of these\nattacks show that adversarial machine learning emerges as a feasible threat in\nthe realistic case with limited training data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 15:50:30 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Shi", "Yi", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Li", "Jason H.", ""]]}, {"id": "1811.01824", "submitter": "Patrick Fernandes", "authors": "Patrick Fernandes, Miltiadis Allamanis, Marc Brockschmidt", "title": "Structured Neural Summarization", "comments": "Published in ICLR 2019 https://openreview.net/forum?id=H1ersoRqtm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarization of long sequences into a concise statement is a core problem in\nnatural language processing, requiring non-trivial understanding of the input.\nBased on the promising results of graph neural networks on highly structured\ndata, we develop a framework to extend existing sequence encoders with a graph\ncomponent that can reason about long-distance relationships in weakly\nstructured data such as text. In an extensive evaluation, we show that the\nresulting hybrid sequence-graph models outperform both pure sequence models as\nwell as pure graph models on a range of summarization tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 16:12:04 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 13:22:59 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 11:47:10 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 12:43:02 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Fernandes", "Patrick", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""]]}, {"id": "1811.01837", "submitter": "Micha Livne", "authors": "Micha Livne, David J. Fleet", "title": "TzK Flow - Conditional Generative Model", "comments": "5 pages, 4 figures, Accepted to Bayesian Deep Learning Workshop NIPS\n  2018, camera ready NOTE: This workshop paper has been replaced. Please refer\n  to the following work: arXiv:1902.01893", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce TzK (pronounced \"task\"), a conditional probability flow-based\nmodel that exploits attributes (e.g., style, class membership, or other side\ninformation) in order to learn tight conditional prior around manifolds of the\ntarget observations. The model is trained via approximated ML, and offers\nefficient approximation of arbitrary data sample distributions (similar to GAN\nand flow-based ML), and stable training (similar to VAE and ML), while avoiding\nvariational approximations. TzK exploits meta-data to facilitate a bottleneck,\nsimilar to autoencoders, thereby producing a low-dimensional representation.\nUnlike autoencoders, the bottleneck does not limit model expressiveness,\nsimilar to flow-based ML. Supervised, unsupervised, and semi-supervised\nlearning are supported by replacing missing observations with samples from\nlearned priors. We demonstrate TzK by training jointly on MNIST and Omniglot\ndatasets with minimal preprocessing, and weak supervision, with results\ncomparable to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 16:44:37 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 21:03:44 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 22:34:26 GMT"}, {"version": "v4", "created": "Tue, 19 Feb 2019 22:57:39 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Livne", "Micha", ""], ["Fleet", "David J.", ""]]}, {"id": "1811.01838", "submitter": "Marius Jahrens", "authors": "Marius Jahrens, Thomas Martinetz", "title": "Multi-layer Relation Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational Networks (RN) as introduced by Santoro et al. (2017) have\ndemonstrated strong relational reasoning capabilities with a rather shallow\narchitecture. Its single-layer design, however, only considers pairs of\ninformation objects, making it unsuitable for problems requiring reasoning\nacross a higher number of facts. To overcome this limitation, we propose a\nmulti-layer relation network architecture which enables successive refinements\nof relational information through multiple layers. We show that the increased\ndepth allows for more complex relational reasoning by applying it to the bAbI\n20 QA dataset, solving all 20 tasks with joint training and surpassing the\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 16:44:54 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Jahrens", "Marius", ""], ["Martinetz", "Thomas", ""]]}, {"id": "1811.01845", "submitter": "Siddhartha Dhar Choudhury", "authors": "Siddhartha Dhar Choudhury, Shashank Pandey, Kunal Mehrotra", "title": "Deep Genetic Network", "comments": "The paper has some major flaws and needs to be re written, it will\n  take time so cannot be replaced soon enough", "journal-ref": null, "doi": "10.35940/ijeat.A1128.109119", "report-no": "A1128109119", "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimizing a neural network's performance is a tedious and time taking\nprocess, this iterative process does not have any defined solution which can\nwork for all the problems. Optimization can be roughly categorized into -\nArchitecture and Hyperparameter optimization. Many algorithms have been devised\nto address this problem. In this paper we introduce a neural network\narchitecture (Deep Genetic Network) which will optimize its parameters during\ntraining based on its fitness. Deep Genetic Net uses genetic algorithms along\nwith deep neural networks to address the hyperparameter optimization problem,\nthis approach uses ideas like mating and mutation which are key to genetic\nalgorithms which help the neural net architecture to learn to optimize its\nhyperparameters by itself rather than depending on a person to explicitly set\nthe values. Using genetic algorithms for this problem proved to work\nexceptionally well when given enough time to train the network. The proposed\narchitecture is found to work well in optimizing hyperparameters in affine,\nconvolutional and recurrent layers proving to be a good choice for conventional\nsupervised learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 17:04:02 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 17:02:45 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Choudhury", "Siddhartha Dhar", ""], ["Pandey", "Shashank", ""], ["Mehrotra", "Kunal", ""]]}, {"id": "1811.01846", "submitter": "Cong Feng", "authors": "Cong Feng and Jie Zhang", "title": "Reinforcement Learning based Dynamic Model Selection for Short-Term Load\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing prevalence of smart grid technology, short-term load\nforecasting (STLF) becomes particularly important in power system operations.\nThere is a large collection of methods developed for STLF, but selecting a\nsuitable method under varying conditions is still challenging. This paper\ndevelops a novel reinforcement learning based dynamic model selection (DMS)\nmethod for STLF. A forecasting model pool is first built, including ten\nstate-of-the-art machine learning based forecasting models. Then a Q-learning\nagent learns the optimal policy of selecting the best forecasting model for the\nnext time step, based on the model performance. The optimal DMS policy is\napplied to select the best model at each time step with a moving window.\nNumerical simulations on two-year load and weather data show that the\nQ-learning algorithm converges fast, resulting in effective and efficient DMS.\nThe developed STLF model with Q-learning based DMS improves the forecasting\naccuracy by approximately 50%, compared to the state-of-the-art machine\nlearning based STLF models.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 17:04:35 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Feng", "Cong", ""], ["Zhang", "Jie", ""]]}, {"id": "1811.01848", "submitter": "Aravind Rajeswaran", "authors": "Kendall Lowrey, Aravind Rajeswaran, Sham Kakade, Emanuel Todorov, Igor\n  Mordatch", "title": "Plan Online, Learn Offline: Efficient Learning and Exploration via\n  Model-Based Control", "comments": "The first two authors contributed equally. Accepted at ICLR 2019.\n  Supplementary videos available at: https://sites.google.com/view/polo-mpc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a plan online and learn offline (POLO) framework for the setting\nwhere an agent, with an internal model, needs to continually act and learn in\nthe world. Our work builds on the synergistic relationship between local\nmodel-based control, global value function learning, and exploration. We study\nhow local trajectory optimization can cope with approximation errors in the\nvalue function, and can stabilize and accelerate value function learning.\nConversely, we also study how approximate value functions can help reduce the\nplanning horizon and allow for better policies beyond local solutions. Finally,\nwe also demonstrate how trajectory optimization can be used to perform\ntemporally coordinated exploration in conjunction with estimating uncertainty\nin value function approximation. This exploration is critical for fast and\nstable learning of the value function. Combining these components enable\nsolutions to complex simulated control tasks, like humanoid locomotion and\ndexterous in-hand manipulation, in the equivalent of a few minutes of\nexperience in the real world.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 17:09:18 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 20:54:47 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 16:39:23 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Lowrey", "Kendall", ""], ["Rajeswaran", "Aravind", ""], ["Kakade", "Sham", ""], ["Todorov", "Emanuel", ""], ["Mordatch", "Igor", ""]]}, {"id": "1811.01900", "submitter": "Ryan Murphy", "authors": "Ryan L. Murphy, Balasubramaniam Srinivasan, Vinayak Rao, Bruno Ribeiro", "title": "Janossy Pooling: Learning Deep Permutation-Invariant Functions for\n  Variable-Size Inputs", "comments": "This version clarifies and adds detail to some of the arguments", "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a simple and overarching representation for permutation-invariant\nfunctions of sequences (or multiset functions). Our approach, which we call\nJanossy pooling, expresses a permutation-invariant function as the average of a\npermutation-sensitive function applied to all reorderings of the input\nsequence. This allows us to leverage the rich and mature literature on\npermutation-sensitive functions to construct novel and flexible\npermutation-invariant functions. If carried out naively, Janossy pooling can be\ncomputationally prohibitive. To allow computational tractability, we consider\nthree kinds of approximations: canonical orderings of sequences, functions with\n$k$-order interactions, and stochastic optimization algorithms with random\npermutations. Our framework unifies a variety of existing work in the\nliterature, and suggests possible modeling and algorithmic extensions. We\nexplore a few in our experiments, which demonstrate improved performance over\ncurrent state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:26:41 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 14:35:49 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 21:13:26 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Murphy", "Ryan L.", ""], ["Srinivasan", "Balasubramaniam", ""], ["Rao", "Vinayak", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "1811.01903", "submitter": "Jelena Diakonikolas", "authors": "Jelena Diakonikolas and Crist\\'obal Guzm\\'an", "title": "Lower Bounds for Parallel and Randomized Convex Optimization", "comments": "In Proc. COLT'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of whether parallelization in the exploration of the\nfeasible set can be used to speed up convex optimization, in the local oracle\nmodel of computation. We show that the answer is negative for both\ndeterministic and randomized algorithms applied to essentially any of the\ninteresting geometries and nonsmooth, weakly-smooth, or smooth objective\nfunctions. In particular, we show that it is not possible to obtain a\npolylogarithmic (in the sequential complexity of the problem) number of\nparallel rounds with a polynomial (in the dimension) number of queries per\nround. In the majority of these settings and when the dimension of the space is\npolynomial in the inverse target accuracy, our lower bounds match the oracle\ncomplexity of sequential convex optimization, up to at most a logarithmic\nfactor in the dimension, which makes them (nearly) tight. Prior to our work,\nlower bounds for parallel convex optimization algorithms were only known in a\nsmall fraction of the settings considered in this paper, mainly applying to\nEuclidean ($\\ell_2$) and $\\ell_\\infty$ spaces. Our work provides a more general\napproach for proving lower bounds in the setting of parallel convex\noptimization.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:32:06 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 14:29:38 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 21:41:52 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Diakonikolas", "Jelena", ""], ["Guzm\u00e1n", "Crist\u00f3bal", ""]]}, {"id": "1811.01908", "submitter": "David Cortes", "authors": "David Cortes", "title": "Fast Non-Bayesian Poisson Factorization for Implicit-Feedback\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores non-negative matrix factorization based on regularized\nPoisson models for recommender systems with implicit-feedback data. The\nproperties of Poisson likelihood allow a shortcut for very fast computation and\noptimization over elements with zero-value when the latent-factor matrices are\nnon-negative, making it a more suitable approach than squared loss for very\nsparse inputs such as implicit-feedback data. A simple and embarrassingly\nparallel optimization approach based on proximal gradients is presented, which\nin large datasets converges 2-3 orders of magnitude faster than its Bayesian\ncounterpart (Hierarchical Poisson Factorization) fit through variational\ninference techniques, and 1 order of magnitude faster than implicit-ALS fit\nwith the Conjugate Gradient method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:35:22 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 17:30:10 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 13:13:36 GMT"}, {"version": "v4", "created": "Sat, 23 May 2020 09:21:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cortes", "David", ""]]}, {"id": "1811.01926", "submitter": "Robin van Emden", "authors": "Robin van Emden, Maurits Kaptein", "title": "contextual: Evaluating Contextual Multi-Armed Bandit Problems in R", "comments": "55 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, contextual bandit algorithms have been gaining in\npopularity due to their effectiveness and flexibility in solving sequential\ndecision problems---from online advertising and finance to clinical trial\ndesign and personalized medicine. At the same time, there are, as of yet,\nsurprisingly few options that enable researchers and practitioners to simulate\nand compare the wealth of new and existing bandit algorithms in a standardized\nway. To help close this gap between analytical research and empirical\nevaluation the current paper introduces the object-oriented R package\n\"contextual\": a user-friendly and, through its object-oriented structure,\neasily extensible framework that facilitates parallelized comparison of\ncontextual and context-free bandit policies through both simulation and offline\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 08:37:03 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 16:55:30 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 13:33:36 GMT"}, {"version": "v4", "created": "Wed, 1 Jan 2020 14:31:34 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["van Emden", "Robin", ""], ["Kaptein", "Maurits", ""]]}, {"id": "1811.01931", "submitter": "Robert Giaquinto", "authors": "Robert Giaquinto and Arindam Banerjee", "title": "DAPPER: Scaling Dynamic Author Persona Topic Model to Billion Word\n  Corpora", "comments": "Published in IEEE International Conference on Data Mining, November\n  2018, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting common narratives from multi-author dynamic text corpora requires\ncomplex models, such as the Dynamic Author Persona (DAP) topic model. However,\nsuch models are complex and can struggle to scale to large corpora, often\nbecause of challenging non-conjugate terms. To overcome such challenges, in\nthis paper we adapt new ideas in approximate inference to the DAP model,\nresulting in the DAP Performed Exceedingly Rapidly (DAPPER) topic model.\nSpecifically, we develop Conjugate-Computation Variational Inference (CVI)\nbased variational Expectation-Maximization (EM) for learning the model,\nyielding fast, closed form updates for each document, replacing iterative\noptimization in earlier work. Our results show significant improvements in\nmodel fit and training time without needing to compromise the model's temporal\nstructure or the application of Regularized Variation Inference (RVI). We\ndemonstrate the scalability and effectiveness of the DAPPER model by extracting\nhealth journeys from the CaringBridge corpus --- a collection of 9 million\njournals written by 200,000 authors during health crises.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 21:27:56 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Giaquinto", "Robert", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1811.02002", "submitter": "Ya-Ping Hsieh", "authors": "Ya-Ping Hsieh, Chen Liu, Volkan Cevher", "title": "Finding Mixed Nash Equilibria of Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reconsider the training objective of Generative Adversarial Networks\n(GANs) from the mixed Nash Equilibria (NE) perspective. Inspired by the\nclassical prox methods, we develop a novel algorithmic framework for GANs via\nan infinite-dimensional two-player game and prove rigorous convergence rates to\nthe mixed NE, resolving the longstanding problem that no provably convergent\nalgorithm exists for general GANs. We then propose a principled procedure to\nreduce our novel prox methods to simple sampling routines, leading to\npractically efficient algorithms. Finally, we provide experimental evidence\nthat our approach outperforms methods that seek pure strategy equilibria, such\nas SGD, Adam, and RMSProp, both in speed and quality.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 13:07:18 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Hsieh", "Ya-Ping", ""], ["Liu", "Chen", ""], ["Cevher", "Volkan", ""]]}, {"id": "1811.02017", "submitter": "Taco Cohen", "authors": "Taco Cohen, Mario Geiger, Maurice Weiler", "title": "A General Theory of Equivariant CNNs on Homogeneous Spaces", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32 (NeurIPS\n  2019) 9142-9153", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general theory of Group equivariant Convolutional Neural\nNetworks (G-CNNs) on homogeneous spaces such as Euclidean space and the sphere.\nFeature maps in these networks represent fields on a homogeneous base space,\nand layers are equivariant maps between spaces of fields. The theory enables a\nsystematic classification of all existing G-CNNs in terms of their symmetry\ngroup, base space, and field type. We also consider a fundamental question:\nwhat is the most general kind of equivariant linear map between feature spaces\n(fields) of given types? Following Mackey, we show that such maps correspond\none-to-one with convolutions using equivariant kernels, and characterize the\nspace of such kernels.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 20:22:10 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 14:59:52 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Cohen", "Taco", ""], ["Geiger", "Mario", ""], ["Weiler", "Maurice", ""]]}, {"id": "1811.02033", "submitter": "Liu Yang", "authors": "Liu Yang, Dongkun Zhang, George Em Karniadakis", "title": "Physics-Informed Generative Adversarial Networks for Stochastic\n  Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a new class of physics-informed generative adversarial networks\n(PI-GANs) to solve in a unified manner forward, inverse and mixed stochastic\nproblems based on a limited number of scattered measurements. Unlike standard\nGANs relying only on data for training, here we encoded into the architecture\nof GANs the governing physical laws in the form of stochastic differential\nequations (SDEs) using automatic differentiation. In particular, we applied\nWasserstein GANs with gradient penalty (WGAN-GP) for its enhanced stability\ncompared to vanilla GANs. We first tested WGAN-GP in approximating Gaussian\nprocesses of different correlation lengths based on data realizations collected\nfrom simultaneous reads at sparsely placed sensors. We obtained good\napproximation of the generated stochastic processes to the target ones even for\na mismatch between the input noise dimensionality and the effective\ndimensionality of the target stochastic processes. We also studied the\noverfitting issue for both the discriminator and generator, and we found that\noverfitting occurs also in the generator in addition to the discriminator as\npreviously reported. Subsequently, we considered the solution of elliptic SDEs\nrequiring approximations of three stochastic processes, namely the solution,\nthe forcing, and the diffusion coefficient. We used three generators for the\nPI-GANs, two of them were feed forward deep neural networks (DNNs) while the\nother one was the neural network induced by the SDE. Depending on the data, we\nemployed one or multiple feed forward DNNs as the discriminators in PI-GANs.\nHere, we have demonstrated the accuracy and effectiveness of PI-GANs in solving\nSDEs for up to 30 dimensions, but in principle, PI-GANs could tackle very high\ndimensional problems given more sensor data with low-polynomial growth in\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 21:01:29 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Yang", "Liu", ""], ["Zhang", "Dongkun", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1811.02054", "submitter": "Varun Chandrasekaran", "authors": "Varun Chandrasekaran, Kamalika Chaudhuri, Irene Giacomelli, Somesh Jha\n  and Songbai Yan", "title": "Exploring Connections Between Active Learning and Model Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is being increasingly used by individuals, research\ninstitutions, and corporations. This has resulted in the surge of Machine\nLearning-as-a-Service (MLaaS) - cloud services that provide (a) tools and\nresources to learn the model, and (b) a user-friendly query interface to access\nthe model. However, such MLaaS systems raise privacy concerns such as model\nextraction. In model extraction attacks, adversaries maliciously exploit the\nquery interface to steal the model. More precisely, in a model extraction\nattack, a good approximation of a sensitive or proprietary model held by the\nserver is extracted (i.e. learned) by a dishonest user who interacts with the\nserver only via the query interface. This attack was introduced by Tramer et\nal. at the 2016 USENIX Security Symposium, where practical attacks for various\nmodels were shown. We believe that better understanding the efficacy of model\nextraction attacks is paramount to designing secure MLaaS systems. To that end,\nwe take the first step by (a) formalizing model extraction and discussing\npossible defense strategies, and (b) drawing parallels between model extraction\nand established area of active learning. In particular, we show that recent\nadvancements in the active learning domain can be used to implement powerful\nmodel extraction attacks, and investigate possible defense strategies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 22:06:12 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 16:25:32 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 09:32:36 GMT"}, {"version": "v4", "created": "Sat, 2 Mar 2019 06:30:45 GMT"}, {"version": "v5", "created": "Tue, 5 Mar 2019 14:58:47 GMT"}, {"version": "v6", "created": "Wed, 20 Nov 2019 04:20:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chandrasekaran", "Varun", ""], ["Chaudhuri", "Kamalika", ""], ["Giacomelli", "Irene", ""], ["Jha", "Somesh", ""], ["Yan", "Songbai", ""]]}, {"id": "1811.02061", "submitter": "Vassilis N. Ioannidis", "authors": "Vassilis N. Ioannidis, Antonio G. Marques, and Georgios B. Giannakis", "title": "A Recurrent Graph Neural Network for Multi-Relational Data", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The era of data deluge has sparked the interest in graph-based learning\nmethods in a number of disciplines such as sociology, biology, neuroscience, or\nengineering. In this paper, we introduce a graph recurrent neural network\n(GRNN) for scalable semi-supervised learning from multi-relational data. Key\naspects of the novel GRNN architecture are the use of multi-relational graphs,\nthe dynamic adaptation to the different relations via learnable weights, and\nthe consideration of graph-based regularizers to promote smoothness and\nalleviate over-parametrization. Our ultimate goal is to design a powerful\nlearning architecture able to: discover complex and highly non-linear data\nassociations, combine (and select) multiple types of relations, and scale\ngracefully with respect to the size of the graph. Numerical tests with real\ndata sets corroborate the design goals and illustrate the performance gains\nrelative to competing alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 22:21:43 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 17:30:03 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 01:26:51 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Marques", "Antonio G.", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1811.02067", "submitter": "Christopher Snyder", "authors": "Christopher Snyder and Sriram Vishwanath", "title": "Sample Compression, Support Vectors, and Generalization in Deep Learning", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though Deep Neural Networks (DNNs) are widely celebrated for their\npractical performance, they possess many intriguing properties related to depth\nthat are difficult to explain both theoretically and intuitively. Understanding\nhow weights in deep networks coordinate together across layers to form useful\nlearners has proven challenging, in part because the repeated composition of\nnonlinearities has proved intractable. This paper presents a reparameterization\nof DNNs as a linear function of a feature map that is locally independent of\nthe weights. This feature map transforms depth-dependencies into simple tensor\nproducts and maps each input to a discrete subset of the feature space. Then,\nusing a max-margin assumption, the paper develops a sample compression\nrepresentation of the neural network in terms of the discrete activation state\nof neurons induced by s ``support vectors\". The paper shows that the number of\nsupport vectors s relates with learning guarantees for neural networks through\nsample compression bounds, yielding a sample complexity of O(ns/epsilon) for\nnetworks with n neurons. Finally, the number of support vectors s is found to\nmonotonically increase with width and label noise but decrease with depth.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 22:32:15 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 20:43:01 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 19:37:01 GMT"}, {"version": "v4", "created": "Tue, 17 Mar 2020 16:54:10 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Snyder", "Christopher", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1811.02084", "submitter": "Noam Shazeer", "authors": "Noam Shazeer, Youlong Cheng, Niki Parmar, Dustin Tran, Ashish Vaswani,\n  Penporn Koanantakool, Peter Hawkins, HyoukJoong Lee, Mingsheng Hong, Cliff\n  Young, Ryan Sepassi, Blake Hechtman", "title": "Mesh-TensorFlow: Deep Learning for Supercomputers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch-splitting (data-parallelism) is the dominant distributed Deep Neural\nNetwork (DNN) training strategy, due to its universal applicability and its\namenability to Single-Program-Multiple-Data (SPMD) programming. However,\nbatch-splitting suffers from problems including the inability to train very\nlarge models (due to memory constraints), high latency, and inefficiency at\nsmall batch sizes. All of these can be solved by more general distribution\nstrategies (model-parallelism). Unfortunately, efficient model-parallel\nalgorithms tend to be complicated to discover, describe, and to implement,\nparticularly on large clusters. We introduce Mesh-TensorFlow, a language for\nspecifying a general class of distributed tensor computations. Where\ndata-parallelism can be viewed as splitting tensors and operations along the\n\"batch\" dimension, in Mesh-TensorFlow, the user can specify any\ntensor-dimensions to be split across any dimensions of a multi-dimensional mesh\nof processors. A Mesh-TensorFlow graph compiles into a SPMD program consisting\nof parallel operations coupled with collective communication primitives such as\nAllreduce. We use Mesh-TensorFlow to implement an efficient data-parallel,\nmodel-parallel version of the Transformer sequence-to-sequence model. Using TPU\nmeshes of up to 512 cores, we train Transformer models with up to 5 billion\nparameters, surpassing state of the art results on WMT'14 English-to-French\ntranslation task and the one-billion-word language modeling benchmark.\nMesh-Tensorflow is available at https://github.com/tensorflow/mesh .\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 23:25:02 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Shazeer", "Noam", ""], ["Cheng", "Youlong", ""], ["Parmar", "Niki", ""], ["Tran", "Dustin", ""], ["Vaswani", "Ashish", ""], ["Koanantakool", "Penporn", ""], ["Hawkins", "Peter", ""], ["Lee", "HyoukJoong", ""], ["Hong", "Mingsheng", ""], ["Young", "Cliff", ""], ["Sepassi", "Ryan", ""], ["Hechtman", "Blake", ""]]}, {"id": "1811.02091", "submitter": "Dustin Tran", "authors": "Dustin Tran, Matthew Hoffman, Dave Moore, Christopher Suter, Srinivas\n  Vasudevan, Alexey Radul, Matthew Johnson, Rif A. Saurous", "title": "Simple, Distributed, and Accelerated Probabilistic Programming", "comments": "Appears in Neural Information Processing Systems, 2018. Code\n  available at http://bit.ly/2JpFipt", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a simple, low-level approach for embedding probabilistic\nprogramming in a deep learning ecosystem. In particular, we distill\nprobabilistic programming down to a single abstraction---the random variable.\nOur lightweight implementation in TensorFlow enables numerous applications: a\nmodel-parallel variational auto-encoder (VAE) with 2nd-generation tensor\nprocessing units (TPUv2s); a data-parallel autoregressive model (Image\nTransformer) with TPUv2s; and multi-GPU No-U-Turn Sampler (NUTS). For both a\nstate-of-the-art VAE on 64x64 ImageNet and Image Transformer on 256x256\nCelebA-HQ, our approach achieves an optimal linear speedup from 1 to 256 TPUv2\nchips. With NUTS, we see a 100x speedup on GPUs over Stan and 37x over PyMC3.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 23:53:59 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 02:56:29 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Tran", "Dustin", ""], ["Hoffman", "Matthew", ""], ["Moore", "Dave", ""], ["Suter", "Christopher", ""], ["Vasudevan", "Srinivas", ""], ["Radul", "Alexey", ""], ["Johnson", "Matthew", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1811.02095", "submitter": "Like Hui", "authors": "Like Hui, Siyuan Ma, Mikhail Belkin", "title": "Kernel Machines Beat Deep Neural Networks on Mask-based Single-channel\n  Speech Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a fast kernel method for mask-based single-channel speech\nenhancement. Specifically, our method solves a kernel regression problem\nassociated to a non-smooth kernel function (exponential power kernel) with a\nhighly efficient iterative method (EigenPro). Due to the simplicity of this\nmethod, its hyper-parameters such as kernel bandwidth can be automatically and\nefficiently selected using line search with subsamples of training data. We\nobserve an empirical correlation between the regression loss (mean square\nerror) and regular metrics for speech enhancement. This observation justifies\nour training target and motivates us to achieve lower regression loss by\ntraining separate kernel model per frequency subband. We compare our method\nwith the state-of-the-art deep neural networks on mask-based HINT and TIMIT.\nExperimental results show that our kernel method consistently outperforms deep\nneural networks while requiring less training time.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 00:04:55 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Hui", "Like", ""], ["Ma", "Siyuan", ""], ["Belkin", "Mikhail", ""]]}, {"id": "1811.02096", "submitter": "Po-Ling Loh", "authors": "Po-Ling Loh", "title": "Scale calibration for high-dimensional robust regression", "comments": "43 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for high-dimensional linear regression when a scale\nparameter of the additive errors is unknown. The proposed estimator is based on\na penalized Huber $M$-estimator, for which theoretical results on estimation\nerror have recently been proposed in high-dimensional statistics literature.\nHowever, the variance of the error term in the linear model is intricately\nconnected to the optimal parameter used to define the shape of the Huber loss.\nOur main idea is to use an adaptive technique, based on Lepski's method, to\novercome the difficulties in solving a joint nonconvex optimization problem\nwith respect to the location and scale parameters.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 00:07:17 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Loh", "Po-Ling", ""]]}, {"id": "1811.02130", "submitter": "Prem Seetharaman", "authors": "Prem Seetharaman, Gordon Wichern, Jonathan Le Roux, Bryan Pardo", "title": "Bootstrapping single-channel source separation via unsupervised spatial\n  clustering on stereo mixtures", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating an audio scene into isolated sources is a fundamental problem in\ncomputer audition, analogous to image segmentation in visual scene analysis.\nSource separation systems based on deep learning are currently the most\nsuccessful approaches for solving the underdetermined separation problem, where\nthere are more sources than channels. Traditionally, such systems are trained\non sound mixtures where the ground truth decomposition is already known. Since\nmost real-world recordings do not have such a decomposition available, this\nlimits the range of mixtures one can train on, and the range of mixtures the\nlearned models may successfully separate. In this work, we use a simple blind\nspatial source separation algorithm to generate estimated decompositions of\nstereo mixtures. These estimates, together with a weighting scheme in the\ntime-frequency domain, based on confidence in the separation quality, are used\nto train a deep learning model that can be used for single-channel separation,\nwhere no source direction information is available. This demonstrates how a\nsimple cue such as the direction of origin of source can be used to bootstrap a\nmodel for source separation that can be used in situations where that cue is\nnot available.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 02:20:40 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Seetharaman", "Prem", ""], ["Wichern", "Gordon", ""], ["Roux", "Jonathan Le", ""], ["Pardo", "Bryan", ""]]}, {"id": "1811.02132", "submitter": "Guoqiang Zhong", "authors": "Jinxuan Sun, Guoqiang Zhong, Yang Chen, Yongbin Liu, Tao Li, Zhongwen\n  Guo", "title": "Student's t-Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have a great performance in image\ngeneration, but they need a large scale of data to train the entire framework,\nand often result in nonsensical results. We propose a new method referring to\nconditional GAN, which equipments the latent noise with mixture of Student's\nt-distribution with attention mechanism in addition to class information.\nStudent's t-distribution has long tails that can provide more diversity to the\nlatent noise. Meanwhile, the discriminator in our model implements two tasks\nsimultaneously, judging whether the images come from the true data\ndistribution, and identifying the class of each generated images. The\nparameters of the mixture model can be learned along with those of GANs.\nMoreover, we mathematically prove that any multivariate Student's\nt-distribution can be obtained by a linear transformation of a normal\nmultivariate Student's t-distribution. Experiments comparing the proposed\nmethod with typical GAN, DeliGAN and DCGAN indicate that, our method has a\ngreat performance on generating diverse and legible objects with limited data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 02:31:28 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Sun", "Jinxuan", ""], ["Zhong", "Guoqiang", ""], ["Chen", "Yang", ""], ["Liu", "Yongbin", ""], ["Li", "Tao", ""], ["Guo", "Zhongwen", ""]]}, {"id": "1811.02141", "submitter": "Matias Carrasco Kind", "authors": "Sahand Hariri, Matias Carrasco Kind, Robert J. Brunner", "title": "Extended Isolation Forest", "comments": "12 pages; 21 figures, Published. Open source code in\n  https://github.com/sahandha/eif", "journal-ref": null, "doi": "10.1109/TKDE.2019.2947676", "report-no": null, "categories": "cs.LG astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension to the model-free anomaly detection algorithm,\nIsolation Forest. This extension, named Extended Isolation Forest (EIF),\nresolves issues with assignment of anomaly score to given data points. We\nmotivate the problem using heat maps for anomaly scores. These maps suffer from\nartifacts generated by the criteria for branching operation of the binary tree.\nWe explain this problem in detail and demonstrate the mechanism by which it\noccurs visually. We then propose two different approaches for improving the\nsituation. First we propose transforming the data randomly before creation of\neach tree, which results in averaging out the bias. Second, which is the\npreferred way, is to allow the slicing of the data to use hyperplanes with\nrandom slopes. This approach results in remedying the artifact seen in the\nanomaly score heat maps. We show that the robustness of the algorithm is much\nimproved using this method by looking at the variance of scores of data points\ndistributed along constant level sets. We report AUROC and AUPRC for our\nsynthetic datasets, along with real-world benchmark datasets. We find no\nappreciable difference in the rate of convergence nor in computation time\nbetween the standard Isolation Forest and EIF.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 03:02:13 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 23:20:56 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 05:38:57 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Hariri", "Sahand", ""], ["Kind", "Matias Carrasco", ""], ["Brunner", "Robert J.", ""]]}, {"id": "1811.02161", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha, Rakesh Shivanna, Chiranjib Bhattacharyya", "title": "How Many Pairwise Preferences Do We Need to Rank A Graph Consistently?", "comments": "In Thirty-Third AAAI Conference on Artificial Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimal recovery of true ranking of $n$ items from\na randomly chosen subset of their pairwise preferences. It is well known that\nwithout any further assumption, one requires a sample size of $\\Omega(n^2)$ for\nthe purpose. We analyze the problem with an additional structure of relational\ngraph $G([n],E)$ over the $n$ items added with an assumption of\n\\emph{locality}: Neighboring items are similar in their rankings. Noting the\npreferential nature of the data, we choose to embed not the graph, but, its\n\\emph{strong product} to capture the pairwise node relationships. Furthermore,\nunlike existing literature that uses Laplacian embedding for graph based\nlearning problems, we use a richer class of graph\nembeddings---\\emph{orthonormal representations}---that includes (normalized)\nLaplacian as its special case. Our proposed algorithm, {\\it Pref-Rank},\npredicts the underlying ranking using an SVM based approach over the chosen\nembedding of the product graph, and is the first to provide \\emph{statistical\nconsistency} on two ranking losses: \\emph{Kendall's tau} and \\emph{Spearman's\nfootrule}, with a required sample complexity of $O(n^2\n\\chi(\\bar{G}))^{\\frac{2}{3}}$ pairs, $\\chi(\\bar{G})$ being the \\emph{chromatic\nnumber} of the complement graph $\\bar{G}$. Clearly, our sample complexity is\nsmaller for dense graphs, with $\\chi(\\bar G)$ characterizing the degree of node\nconnectivity, which is also intuitive due to the locality assumption e.g.\n$O(n^\\frac{4}{3})$ for union of $k$-cliques, or $O(n^\\frac{5}{3})$ for random\nand power law graphs etc.---a quantity much smaller than the fundamental limit\nof $\\Omega(n^2)$ for large $n$. This, for the first time, relates ranking\ncomplexity to structural properties of the graph. We also report experimental\nevaluations on different synthetic and real datasets, where our algorithm is\nshown to outperform the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 04:54:18 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 20:26:20 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Saha", "Aadirupa", ""], ["Shivanna", "Rakesh", ""], ["Bhattacharyya", "Chiranjib", ""]]}, {"id": "1811.02172", "submitter": "Chong Wang", "authors": "Jiangtao Feng, Lingpeng Kong, Po-Sen Huang, Chong Wang, Da Huang,\n  Jiayuan Mao, Kan Qiao, Dengyong Zhou", "title": "Neural Phrase-to-Phrase Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Neural Phrase-to-Phrase Machine Translation\n(NP$^2$MT). Our model uses a phrase attention mechanism to discover relevant\ninput (source) segments that are used by a decoder to generate output (target)\nphrases. We also design an efficient dynamic programming algorithm to decode\nsegments that allows the model to be trained faster than the existing neural\nphrase-based machine translation method by Huang et al. (2018). Furthermore,\nour method can naturally integrate with external phrase dictionaries during\ndecoding. Empirical experiments show that our method achieves comparable\nperformance with the state-of-the art methods on benchmark datasets. However,\nwhen the training and testing data are from different distributions or domains,\nour method performs better.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 05:47:52 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Feng", "Jiangtao", ""], ["Kong", "Lingpeng", ""], ["Huang", "Po-Sen", ""], ["Wang", "Chong", ""], ["Huang", "Da", ""], ["Mao", "Jiayuan", ""], ["Qiao", "Kan", ""], ["Zhou", "Dengyong", ""]]}, {"id": "1811.02196", "submitter": "Utkarsh Porwal", "authors": "Utkarsh Porwal and Smruthi Mukund", "title": "Credit Card Fraud Detection in e-Commerce: An Outlier Detection Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often the challenge associated with tasks like fraud and spam detection is\nthe lack of all likely patterns needed to train suitable supervised learning\nmodels. This problem accentuates when the fraudulent patterns are not only\nscarce, they also change over time. Change in fraudulent pattern is because\nfraudsters continue to innovate novel ways to circumvent measures put in place\nto prevent fraud. Limited data and continuously changing patterns makes\nlearning significantly difficult. We hypothesize that good behavior does not\nchange with time and data points representing good behavior have consistent\nspatial signature under different groupings. Based on this hypothesis we are\nproposing an approach that detects outliers in large data sets by assigning a\nconsistency score to each data point using an ensemble of clustering methods.\nOur main contribution is proposing a novel method that can detect outliers in\nlarge datasets and is robust to changing patterns. We also argue that area\nunder the ROC curve, although a commonly used metric to evaluate outlier\ndetection methods is not the right metric. Since outlier detection problems\nhave a skewed distribution of classes, precision-recall curves are better\nsuited because precision compares false positives to true positives (outliers)\nrather than true negatives (inliers) and therefore is not affected by the\nproblem of class imbalance. We show empirically that area under the\nprecision-recall curve is a better than ROC as an evaluation metric. The\nproposed approach is tested on the modified version of the Landsat satellite\ndataset, the modified version of the ann-thyroid dataset and a large real world\ncredit card fraud detection dataset available through Kaggle where we show\nsignificant improvement over the baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 07:06:38 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 00:00:30 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Porwal", "Utkarsh", ""], ["Mukund", "Smruthi", ""]]}, {"id": "1811.02198", "submitter": "Dongsheng Li", "authors": "Dongsheng Li and Chao Chen and Qin Lv and Junchi Yan and Li Shang and\n  Stephen M. Chu", "title": "Collaborative Filtering with Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) is a popular technique in today's recommender\nsystems, and matrix approximation-based CF methods have achieved great success\nin both rating prediction and top-N recommendation tasks. However, real-world\nuser-item rating matrices are typically sparse, incomplete and noisy, which\nintroduce challenges to the algorithm stability of matrix approximation, i.e.,\nsmall changes in the training data may significantly change the models. As a\nresult, existing matrix approximation solutions yield low generalization\nperformance, exhibiting high error variance on the training data, and\nminimizing the training error may not guarantee error reduction on the test\ndata. This paper investigates the algorithm stability problem of matrix\napproximation methods and how to achieve stable collaborative filtering via\nstable matrix approximation. We present a new algorithm design framework, which\n(1) introduces new optimization objectives to guide stable matrix approximation\nalgorithm design, and (2) solves the optimization problem to obtain stable\napproximation solutions with good generalization performance. Experimental\nresults on real-world datasets demonstrate that the proposed method can achieve\nbetter accuracy compared with state-of-the-art matrix approximation methods and\nensemble methods in both rating prediction and top-N recommendation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 07:13:23 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Li", "Dongsheng", ""], ["Chen", "Chao", ""], ["Lv", "Qin", ""], ["Yan", "Junchi", ""], ["Shang", "Li", ""], ["Chu", "Stephen M.", ""]]}, {"id": "1811.02225", "submitter": "Pierre Ablin", "authors": "Pierre Ablin (PARIETAL), Dylan Fagot (IRIT), Herwig Wendt (IRIT),\n  Alexandre Gramfort (PARIETAL), C\\'edric F\\'evotte (IRIT)", "title": "A Quasi-Newton algorithm on the orthogonal manifold for NMF with\n  transform learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is a popular method for audio spectral\nunmixing. While NMF is traditionally applied to off-the-shelf time-frequency\nrepresentations based on the short-time Fourier or Cosine transforms, the\nability to learn transforms from raw data attracts increasing attention.\nHowever, this adds an important computational overhead. When assumed orthogonal\n(like the Fourier or Cosine transforms), learning the transform yields a\nnon-convex optimization problem on the orthogonal matrix manifold. In this\npaper, we derive a quasi-Newton method on the manifold using sparse\napproximations of the Hessian. Experiments on synthetic and real audio data\nshow that the proposed algorithm out-performs state-of-the-art first-order and\ncoordinate-descent methods by orders of magnitude. A Python package for fast\nTL-NMF is released online at https://github.com/pierreablin/tlnmf.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 08:49:40 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ablin", "Pierre", "", "PARIETAL"], ["Fagot", "Dylan", "", "IRIT"], ["Wendt", "Herwig", "", "IRIT"], ["Gramfort", "Alexandre", "", "PARIETAL"], ["F\u00e9votte", "C\u00e9dric", "", "IRIT"]]}, {"id": "1811.02228", "submitter": "Bo Dai", "authors": "Bo Dai, Hanjun Dai, Arthur Gretton, Le Song, Dale Schuurmans, Niao He", "title": "Kernel Exponential Family Estimation via Doubly Dual Embedding", "comments": "22 pages, 20 figures; AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate penalized maximum log-likelihood estimation for exponential\nfamily distributions whose natural parameter resides in a reproducing kernel\nHilbert space. Key to our approach is a novel technique, doubly dual embedding,\nthat avoids computation of the partition function. This technique also allows\nthe development of a flexible sampling strategy that amortizes the cost of\nMonte-Carlo sampling in the inference stage. The resulting estimator can be\neasily generalized to kernel conditional exponential families. We establish a\nconnection between kernel exponential family estimation and MMD-GANs, revealing\na new perspective for understanding GANs. Compared to the score matching based\nestimators, the proposed method improves both memory and time efficiency while\nenjoying stronger statistical properties, such as fully capturing smoothness in\nits statistical convergence rate while the score matching estimator appears to\nsaturate. Finally, we show that the proposed estimator empirically outperforms\nstate-of-the-art\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 08:51:51 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 23:21:40 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2019 06:26:10 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Dai", "Bo", ""], ["Dai", "Hanjun", ""], ["Gretton", "Arthur", ""], ["Song", "Le", ""], ["Schuurmans", "Dale", ""], ["He", "Niao", ""]]}, {"id": "1811.02284", "submitter": "Johan Barthelemy", "authors": "Johan Barth\\'elemy and Morgane Dumont and Timoteo Carletti", "title": "Comparison of Discrete Choice Models and Artificial Neural Networks in\n  Presence of Missing Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification, the process of assigning a label (or class) to an observation\ngiven its features, is a common task in many applications. Nonetheless in most\nreal-life applications, the labels can not be fully explained by the observed\nfeatures. Indeed there can be many factors hidden to the modellers. The\nunexplained variation is then treated as some random noise which is handled\ndifferently depending on the method retained by the practitioner. This work\nfocuses on two simple and widely used supervised classification algorithms:\ndiscrete choice models and artificial neural networks in the context of binary\nclassification.\n  Through various numerical experiments involving continuous or discrete\nexplanatory features, we present a comparison of the retained methods'\nperformance in presence of missing variables. The impact of the distribution of\nthe two classes in the training data is also investigated. The outcomes of\nthose experiments highlight the fact that artificial neural networks\noutperforms the discrete choice models, except when the distribution of the\nclasses in the training data is highly unbalanced.\n  Finally, this work provides some guidelines for choosing the right classifier\nwith respect to the training data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 11:03:04 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Barth\u00e9lemy", "Johan", ""], ["Dumont", "Morgane", ""], ["Carletti", "Timoteo", ""]]}, {"id": "1811.02314", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Pascal Frossard, and Saikat Chatterjee", "title": "Kernel Regression for Graph Signal Prediction in Presence of Sparse\n  Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In presence of sparse noise we propose kernel regression for predicting\noutput vectors which are smooth over a given graph. Sparse noise models the\ntraining outputs being corrupted either with missing samples or large\nperturbations. The presence of sparse noise is handled using appropriate use of\n$\\ell_1$-norm along-with use of $\\ell_2$-norm in a convex cost function. For\noptimization of the cost function, we propose an iteratively reweighted\nleast-squares (IRLS) approach that is suitable for kernel substitution or\nkernel trick due to availability of a closed form solution. Simulations using\nreal-world temperature data show efficacy of our proposed method, mainly for\nlimited-size training datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 12:19:58 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Frossard", "Pascal", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1811.02316", "submitter": "Wouter van Loon", "authors": "Wouter van Loon, Marjolein Fokkema, Botond Szabo, Mark de Rooij", "title": "Stacked Penalized Logistic Regression for Selecting Views in Multi-View\n  Learning", "comments": "26 pages, 9 figures. Accepted manuscript", "journal-ref": "Information Fusion 61 (2020) 113-123", "doi": "10.1016/j.inffus.2020.03.007", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biomedical research, many different types of patient data can be\ncollected, such as various types of omics data and medical imaging modalities.\nApplying multi-view learning to these different sources of information can\nincrease the accuracy of medical classification models compared with\nsingle-view procedures. However, collecting biomedical data can be expensive\nand/or burdening for patients, so that it is important to reduce the amount of\nrequired data collection. It is therefore necessary to develop multi-view\nlearning methods which can accurately identify those views that are most\nimportant for prediction. In recent years, several biomedical studies have used\nan approach known as multi-view stacking (MVS), where a model is trained on\neach view separately and the resulting predictions are combined through\nstacking. In these studies, MVS has been shown to increase classification\naccuracy. However, the MVS framework can also be used for selecting a subset of\nimportant views. To study the view selection potential of MVS, we develop a\nspecial case called stacked penalized logistic regression (StaPLR). Compared\nwith existing view-selection methods, StaPLR can make use of faster\noptimization algorithms and is easily parallelized. We show that nonnegativity\nconstraints on the parameters of the function which combines the views play an\nimportant role in preventing unimportant views from entering the model. We\ninvestigate the performance of StaPLR through simulations, and consider two\nreal data examples. We compare the performance of StaPLR with an existing view\nselection method called the group lasso and observe that, in terms of view\nselection, StaPLR is often more conservative and has a consistently lower false\npositive rate.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 12:23:52 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 13:18:44 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 14:26:11 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["van Loon", "Wouter", ""], ["Fokkema", "Marjolein", ""], ["Szabo", "Botond", ""], ["de Rooij", "Mark", ""]]}, {"id": "1811.02319", "submitter": "Yang Li", "authors": "Yang Li, Jiawei Jiang, Yingxia Shao and Bin Cui", "title": "Fast Hyperparameter Optimization of Deep Neural Networks via Ensembling\n  Multiple Surrogates", "comments": "More mature method is developed in the paper - MFES-HB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep neural networks crucially depends on good\nhyperparameter configurations. Bayesian optimization is a powerful framework\nfor optimizing the hyperparameters of DNNs. These methods need sufficient\nevaluation data to approximate and minimize the validation error function of\nhyperparameters. However, the expensive evaluation cost of DNNs leads to very\nfew evaluation data within a limited time, which greatly reduces the efficiency\nof Bayesian optimization. Besides, the previous researches focus on using the\ncomplete evaluation data to conduct Bayesian optimization, and ignore the\nintermediate evaluation data generated by early stopping methods. To alleviate\nthe insufficient evaluation data problem, we propose a fast hyperparameter\noptimization method, HOIST, that utilizes both the complete and intermediate\nevaluation data to accelerate the hyperparameter optimization of DNNs.\nSpecifically, we train multiple basic surrogates to gather information from the\nmixed evaluation data, and then combine all basic surrogates using weighted\nbagging to provide an accurate ensemble surrogate. Our empirical studies show\nthat HOIST outperforms the state-of-the-art approaches on a wide range of DNNs,\nincluding feed forward neural networks, convolutional neural networks,\nrecurrent neural networks, and variational autoencoder.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 12:29:02 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 07:56:01 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 09:04:03 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Li", "Yang", ""], ["Jiang", "Jiawei", ""], ["Shao", "Yingxia", ""], ["Cui", "Bin", ""]]}, {"id": "1811.02322", "submitter": "Michael Kaufmann", "authors": "Michael Kaufmann, Thomas Parnell, Kornilios Kourtis", "title": "Elastic CoCoA: Scaling In to Improve Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we experimentally analyze the convergence behavior of CoCoA and\nshow, that the number of workers required to achieve the highest convergence\nrate at any point in time, changes over the course of the training. Based on\nthis observation, we build Chicle, an elastic framework that dynamically\nadjusts the number of workers based on feedback from the training algorithm, in\norder to select the number of workers that results in the highest convergence\nrate. In our evaluation of 6 datasets, we show that Chicle is able to\naccelerate the time-to-accuracy by a factor of up to 5.96x compared to the best\nstatic setting, while being robust enough to find an optimal or near-optimal\nsetting automatically in most cases.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 12:35:28 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Kaufmann", "Michael", ""], ["Parnell", "Thomas", ""], ["Kourtis", "Kornilios", ""]]}, {"id": "1811.02361", "submitter": "Honglin Li", "authors": "Honglin Li, Frieder Ganz, Shirin Enshaeifar, Payam Barnaghi", "title": "Kalman Filter Modifier for Neural Networks in Non-stationary\n  Environments", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in a non-stationary environment is an inevitable problem when\napplying machine learning algorithm to real world environment. Learning new\ntasks without forgetting the previous knowledge is a challenge issue in machine\nlearning. We propose a Kalman Filter based modifier to maintain the performance\nof Neural Network models under non-stationary environments. The result shows\nthat our proposed model can preserve the key information and adapts better to\nthe changes. The accuracy of proposed model decreases by 0.4% in our\nexperiments, while the accuracy of conventional model decreases by 90% in the\ndrifts environment.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 14:16:29 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Li", "Honglin", ""], ["Ganz", "Frieder", ""], ["Enshaeifar", "Shirin", ""], ["Barnaghi", "Payam", ""]]}, {"id": "1811.02384", "submitter": "Chunna Li", "authors": "Chun-Na Li, Yuan-Hai Shao, Zhen Wang, Nai-Yang Deng", "title": "Robust Bhattacharyya bound linear discriminant analysis through adaptive\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel linear discriminant analysis criterion via\nthe Bhattacharyya error bound estimation based on a novel L1-norm (L1BLDA) and\nL2-norm (L2BLDA). Both L1BLDA and L2BLDA maximize the between-class scatters\nwhich are measured by the weighted pairwise distances of class means and\nmeanwhile minimize the within-class scatters under the L1-norm and L2-norm,\nrespectively. The proposed models can avoid the small sample size (SSS) problem\nand have no rank limit that may encounter in LDA. It is worth mentioning that,\nthe employment of L1-norm gives a robust performance of L1BLDA, and L1BLDA is\nsolved through an effective non-greedy alternating direction method of\nmultipliers (ADMM), where all the projection vectors can be obtained once for\nall. In addition, the weighting constants of L1BLDA and L2BLDA between the\nbetween-class and within-class terms are determined by the involved data set,\nwhich makes our L1BLDA and L2BLDA adaptive. The experimental results on both\nbenchmark data sets as well as the handwritten digit databases demonstrate the\neffectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 14:55:14 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Li", "Chun-Na", ""], ["Shao", "Yuan-Hai", ""], ["Wang", "Zhen", ""], ["Deng", "Nai-Yang", ""]]}, {"id": "1811.02438", "submitter": "Yuma Koizumi", "authors": "Yuma Koizumi, Noboru Harada, Yoichi Haneda", "title": "Trainable Adaptive Window Switching for Speech Enhancement", "comments": "accepted to the 44th International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a trainable adaptive window switching (AWS) method and\napply it to a deep-neural-network (DNN) for speech enhancement in the modified\ndiscrete cosine transform domain. Time-frequency (T-F) mask processing in the\nshort-time Fourier transform (STFT)-domain is a typical speech enhancement\nmethod. To recover the target signal precisely, DNN-based short-time frequency\ntransforms have recently been investigated and used instead of the STFT.\nHowever, since such a fixed-resolution short-time frequency transform method\nhas a T-F resolution problem based on the uncertainty principle, not only the\nshort-time frequency transform but also the length of the windowing function\nshould be optimized. To overcome this problem, we incorporate AWS into the\nspeech enhancement procedure, and the windowing function of each time-frame is\nmanipulated using a DNN depending on the input signal. We confirmed that the\nproposed method achieved a higher signal-to-distortion ratio than conventional\nspeech enhancement methods in fixed-resolution frequency domains.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 12:25:42 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 09:14:01 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 05:45:31 GMT"}, {"version": "v4", "created": "Tue, 19 Feb 2019 23:56:50 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Koizumi", "Yuma", ""], ["Harada", "Noboru", ""], ["Haneda", "Yoichi", ""]]}, {"id": "1811.02454", "submitter": "Zhao Zhong", "authors": "Chen Lin, Zhao Zhong, Wei Wu, Junjie Yan", "title": "Synaptic Strength For Convolutional Neural Network", "comments": "Accepted by NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks(CNNs) are both computation and memory intensive\nwhich hindered their deployment in mobile devices. Inspired by the relevant\nconcept in neural science literature, we propose Synaptic Pruning: a\ndata-driven method to prune connections between input and output feature maps\nwith a newly proposed class of parameters called Synaptic Strength. Synaptic\nStrength is designed to capture the importance of a connection based on the\namount of information it transports. Experiment results show the effectiveness\nof our approach. On CIFAR-10, we prune connections for various CNN models with\nup to 96% , which results in significant size reduction and computation saving.\nFurther evaluation on ImageNet demonstrates that synaptic pruning is able to\ndiscover efficient models which is competitive to state-of-the-art compact CNNs\nsuch as MobileNet-V2 and NasNet-Mobile. Our contribution is summarized as\nfollowing: (1) We introduce Synaptic Strength, a new class of parameters for\nCNNs to indicate the importance of each connections. (2) Our approach can prune\nvarious CNNs with high compression without compromising accuracy. (3) Further\ninvestigation shows, the proposed Synaptic Strength is a better indicator for\nkernel pruning compared with the previous approach in both empirical result and\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 16:06:49 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Lin", "Chen", ""], ["Zhong", "Zhao", ""], ["Wu", "Wei", ""], ["Yan", "Junjie", ""]]}, {"id": "1811.02459", "submitter": "Daniel Hernandez Diaz", "authors": "Daniel Hernandez, Antonio Khalil Moretti, Ziqiang Wei, Shreya Saxena,\n  John Cunningham and Liam Paninski", "title": "Nonlinear Evolution via Spatially-Dependent Linear Dynamics for\n  Electrophysiology and Calcium Data", "comments": "8 figs, Accepted at NBDT", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models have been widely applied for the analysis of time\nseries resulting from experimental neuroscience techniques. In these datasets,\nobservations are relatively smooth and possibly nonlinear. We present\nVariational Inference for Nonlinear Dynamics (VIND), a variational inference\nframework that is able to uncover nonlinear, smooth latent dynamics from\nsequential data. The framework is a direct extension of PfLDS; including a\nstructured approximate posterior describing spatially-dependent linear\ndynamics, as well as an algorithm that relies on the fixed-point iteration\nmethod to achieve convergence. We apply VIND to electrophysiology, single-cell\nvoltage and widefield imaging datasets with state-of-the-art results in\nreconstruction error. In single-cell voltage data, VIND finds a 5D latent\nspace, with variables akin to those of Hodgkin-Huxley-like models. VIND's\nlearned dynamics are further quantified by predicting future neural activity.\nVIND excels in this task, in some cases substantially outperforming current\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 16:10:56 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 16:18:42 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 18:00:58 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Hernandez", "Daniel", ""], ["Moretti", "Antonio Khalil", ""], ["Wei", "Ziqiang", ""], ["Saxena", "Shreya", ""], ["Cunningham", "John", ""], ["Paninski", "Liam", ""]]}, {"id": "1811.02471", "submitter": "Marc Ru{\\ss}wurm", "authors": "Marc Ru{\\ss}wurm and Marco K\\\"orner", "title": "Convolutional LSTMs for Cloud-Robust Segmentation of Remote Sensing\n  Imagery", "comments": "Cameraready version to NeurIPS 2018 Spatiotemporal Workshop.\n  Openreview: https://openreview.net/forum?id=Sye7df9CK7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clouds frequently cover the Earth's surface and pose an omnipresent challenge\nto optical Earth observation methods. The vast majority of remote sensing\napproaches either selectively choose single cloud-free observations or employ a\npre-classification strategy to identify and mask cloudy pixels. We follow a\ndifferent strategy and treat cloud coverage as noise that is inherent to the\nobserved satellite data. In prior work, we directly employed a straightforward\n\\emph{convolutional long short-term memory} network for vegetation\nclassification without explicit cloud filtering and achieved state-of-the-art\nclassification accuracies. In this work, we investigate this cloud-robustness\nfurther by visualizing internal cell activations and performing an ablation\nexperiment on datasets of different cloud coverage. In the visualizations of\nnetwork states, we identified some cells in which modulation and input gates\nclosed on cloudy pixels. This indicates that the network has internalized a\ncloud-filtering mechanism without being specifically trained on cloud labels.\nOverall, our results question the necessity of sophisticated pre-processing\npipelines for multi-temporal deep learning approaches.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 17:58:22 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 11:30:38 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Ru\u00dfwurm", "Marc", ""], ["K\u00f6rner", "Marco", ""]]}, {"id": "1811.02489", "submitter": "William Wilkinson", "authors": "William J. Wilkinson, Michael Riis Andersen, Joshua D. Reiss, Dan\n  Stowell, and Arno Solin", "title": "Unifying Probabilistic Models for Time-Frequency Analysis", "comments": "Accepted to International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In audio signal processing, probabilistic time-frequency models have many\nbenefits over their non-probabilistic counterparts. They adapt to the incoming\nsignal, quantify uncertainty, and measure correlation between the signal's\namplitude and phase information, making time domain resynthesis\nstraightforward. However, these models are still not widely used since they\ncome at a high computational cost, and because they are formulated in such a\nway that it can be difficult to interpret all the modelling assumptions. By\nshowing their equivalence to Spectral Mixture Gaussian processes, we illuminate\nthe underlying model assumptions and provide a general framework for\nconstructing more complex models that better approximate real-world signals.\nOur interpretation makes it intuitive to inspect, compare, and alter the models\nsince all prior knowledge is encoded in the Gaussian process kernel functions.\nWe utilise a state space representation to perform efficient inference via\nKalman smoothing, and we demonstrate how our interpretation allows for\nefficient parameter learning in the frequency domain.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 17:00:19 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 09:13:19 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 08:15:06 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2018 13:36:07 GMT"}, {"version": "v5", "created": "Mon, 12 Nov 2018 15:34:51 GMT"}, {"version": "v6", "created": "Tue, 12 Feb 2019 11:08:21 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Wilkinson", "William J.", ""], ["Andersen", "Michael Riis", ""], ["Reiss", "Joshua D.", ""], ["Stowell", "Dan", ""], ["Solin", "Arno", ""]]}, {"id": "1811.02506", "submitter": "Viet Hung Tran", "authors": "Viet Hung Tran", "title": "Variational Bayes Inference in Digital Receivers", "comments": "PhD thesis, Trinity College Dublin, Ireland (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digital telecommunications receiver is an important context for inference\nmethodology, the key objective being to minimize the expected loss function in\nrecovering the transmitted information. For that criterion, the optimal\ndecision is the Bayesian minimum-risk estimator. However, the computational\nload of the Bayesian estimator is often prohibitive and, hence, efficient\ncomputational schemes are required. The design of novel schemes, striking new\nbalances between accuracy and computational load, is the primary concern of\nthis thesis. Two popular techniques, one exact and one approximate, will be\nstudied.\n  The exact scheme is a recursive one, namely the generalized distributive law\n(GDL), whose purpose is to distribute all operators across the conditionally\nindependent (CI) factors of the joint model, so as to reduce the total number\nof operators required. In a novel theorem derived in this thesis, GDL, if\napplicable, will be shown to guarantee such a reduction in all cases. An\nassociated lemma also quantifies this reduction. For practical use, two novel\nalgorithms, namely the no-longer-needed (NLN) algorithm and the generalized\nform of the Markovian Forward-Backward (FB) algorithm, recursively factorizes\nand computes the CI factors of an arbitrary model, respectively.\n  The approximate scheme is an iterative one, namely the Variational Bayes (VB)\napproximation, whose purpose is to find the independent (i.e. zero-order\nMarkov) model closest to the true joint model in the minimum Kullback-Leibler\ndivergence (KLD) sense. Despite being computationally efficient, this naive\nmean field approximation confers only modest performance for highly correlated\nmodels. A novel approximation, namely Transformed Variational Bayes (TVB), will\nbe designed in the thesis in order to relax the zero-order constraint in the VB\napproximation, further reducing the KLD of the optimal approximation.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 12:42:15 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Tran", "Viet Hung", ""]]}, {"id": "1811.02525", "submitter": "Kin Gutierrez", "authors": "Kin Gutierrez, Jin Li, Cristian Challu, Artur Dubrawski", "title": "Double Adaptive Stochastic Gradient Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive moment methods have been remarkably successful in deep learning\noptimization, particularly in the presence of noisy and/or sparse gradients. We\nfurther the advantages of adaptive moment techniques by proposing a family of\ndouble adaptive stochastic gradient methods~\\textsc{DASGrad}. They leverage the\ncomplementary ideas of the adaptive moment algorithms widely used by deep\nlearning community, and recent advances in adaptive probabilistic algorithms.We\nanalyze the theoretical convergence improvements of our approach in a\nstochastic convex optimization setting, and provide empirical validation of our\nfindings with convex and non convex objectives. We observe that the benefits\nof~\\textsc{DASGrad} increase with the model complexity and variability of the\ngradients, and we explore the resulting utility in extensions of\ndistribution-matching multitask learning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 17:47:34 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Gutierrez", "Kin", ""], ["Li", "Jin", ""], ["Challu", "Cristian", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1811.02540", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, Tuomas Sandholm", "title": "Regret Circuits: Composability of Regret Minimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret minimization is a powerful tool for solving large-scale problems; it\nwas recently used in breakthrough results for large-scale extensive-form game\nsolving. This was achieved by composing simplex regret minimizers into an\noverall regret-minimization framework for extensive-form game strategy spaces.\nIn this paper we study the general composability of regret minimizers. We\nderive a calculus for constructing regret minimizers for composite convex sets\nthat are obtained from convexity-preserving operations on simpler convex sets.\nWe show that local regret minimizers for the simpler sets can be combined with\nadditional regret minimizers into an aggregate regret minimizer for the\ncomposite set. As one application, we show that the CFR framework can be\nconstructed easily from our framework. We also show ways to include curtailing\n(constraining) operations into our framework. For one, they enables the\nconstruction of CFR generalization for extensive-form games with general convex\nstrategy constraints that can cut across decision points.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:30:27 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 20:30:43 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1811.02553", "submitter": "Andrew Ilyas", "authors": "Andrew Ilyas, Logan Engstrom, Shibani Santurkar, Dimitris Tsipras,\n  Firdaus Janoos, Larry Rudolph, Aleksander Madry", "title": "A Closer Look at Deep Policy Gradients", "comments": "ICLR 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how the behavior of deep policy gradient algorithms reflects the\nconceptual framework motivating their development. To this end, we propose a\nfine-grained analysis of state-of-the-art methods based on key elements of this\nframework: gradient estimation, value prediction, and optimization landscapes.\nOur results show that the behavior of deep policy gradient algorithms often\ndeviates from what their motivating framework would predict: the surrogate\nobjective does not match the true reward landscape, learned value estimators\nfail to fit the true value function, and gradient estimates poorly correlate\nwith the \"true\" gradient. The mismatch between predicted and empirical behavior\nwe uncover highlights our poor understanding of current methods, and indicates\nthe need to move beyond current benchmark-centric evaluation methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:54:21 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 18:54:30 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2018 02:45:35 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 16:24:26 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ilyas", "Andrew", ""], ["Engstrom", "Logan", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Janoos", "Firdaus", ""], ["Rudolph", "Larry", ""], ["Madry", "Aleksander", ""]]}, {"id": "1811.02564", "submitter": "Siyuan Ma", "authors": "Raef Bassily, Mikhail Belkin, Siyuan Ma", "title": "On exponential convergence of SGD in non-convex over-parametrized\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large over-parametrized models learned via stochastic gradient descent (SGD)\nmethods have become a key element in modern machine learning. Although SGD\nmethods are very effective in practice, most theoretical analyses of SGD\nsuggest slower convergence than what is empirically observed. In our recent\nwork [8] we analyzed how interpolation, common in modern over-parametrized\nlearning, results in exponential convergence of SGD with constant step size for\nconvex loss functions. In this note, we extend those results to a much broader\nnon-convex function class satisfying the Polyak-Lojasiewicz (PL) condition. A\nnumber of important non-convex problems in machine learning, including some\nclasses of neural networks, have been recently shown to satisfy the PL\ncondition. We argue that the PL condition provides a relevant and attractive\nsetting for many machine learning problems, particularly in the\nover-parametrized regime.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 00:05:00 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Bassily", "Raef", ""], ["Belkin", "Mikhail", ""], ["Ma", "Siyuan", ""]]}, {"id": "1811.02566", "submitter": "Titouan Parcollet", "authors": "Titouan Parcollet, Mohamed Morchid, Georges Linar\\`es, Renato De Mori", "title": "Bidirectional Quaternion Long-Short Term Memory Recurrent Neural\n  Networks for Speech Recognition", "comments": "Submitted at ICASSP 2019. arXiv admin note: text overlap with\n  arXiv:1806.04418", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNN) are at the core of modern automatic speech\nrecognition (ASR) systems. In particular, long-short term memory (LSTM)\nrecurrent neural networks have achieved state-of-the-art results in many speech\nrecognition tasks, due to their efficient representation of long and short term\ndependencies in sequences of inter-dependent features. Nonetheless, internal\ndependencies within the element composing multidimensional features are weakly\nconsidered by traditional real-valued representations. We propose a novel\nquaternion long-short term memory (QLSTM) recurrent neural network that takes\ninto account both the external relations between the features composing a\nsequence, and these internal latent structural dependencies with the quaternion\nalgebra. QLSTMs are compared to LSTMs during a memory copy-task and a realistic\napplication of speech recognition on the Wall Street Journal (WSJ) dataset.\nQLSTM reaches better performances during the two experiments with up to $2.8$\ntimes less learning parameters, leading to a more expressive representation of\nthe information.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 21:17:34 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Parcollet", "Titouan", ""], ["Morchid", "Mohamed", ""], ["Linar\u00e8s", "Georges", ""], ["De Mori", "Renato", ""]]}, {"id": "1811.02579", "submitter": "Dallas Card", "authors": "Dallas Card and Michael Zhang and Noah A. Smith", "title": "Deep Weighted Averaging Classifiers", "comments": "13 pages, 8 figures, 5 tables, added DOI and updated to meet ACM\n  formatting requirements, In Proceedings of FAT* (2019)", "journal-ref": null, "doi": "10.1145/3287560.3287595", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have achieved impressive gains in\nclassification accuracy on a variety of types of data, including images and\ntext. Despite these gains, however, concerns have been raised about the\ncalibration, robustness, and interpretability of these models. In this paper we\npropose a simple way to modify any conventional deep architecture to\nautomatically provide more transparent explanations for classification\ndecisions, as well as an intuitive notion of the credibility of each\nprediction. Specifically, we draw on ideas from nonparametric kernel\nregression, and propose to predict labels based on a weighted sum of training\ninstances, where the weights are determined by distance in a learned\ninstance-embedding space. Working within the framework of conformal methods, we\npropose a new measure of nonconformity suggested by our model, and\nexperimentally validate the accompanying theoretical expectations,\ndemonstrating improved transparency, controlled error rates, and robustness to\nout-of-domain data, without compromising on accuracy or calibration.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 19:00:06 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 20:00:55 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Card", "Dallas", ""], ["Zhang", "Michael", ""], ["Smith", "Noah A.", ""]]}, {"id": "1811.02597", "submitter": "Sina Ghiassian", "authors": "Sina Ghiassian, Andrew Patterson, Martha White, Richard S. Sutton,\n  Adam White", "title": "Online Off-policy Prediction", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of online prediction learning, where\nlearning proceeds continuously as the agent interacts with an environment. The\npredictions made by the agent are contingent on a particular way of behaving,\nrepresented as a value function. However, the behavior used to select actions\nand generate the behavior data might be different from the one used to define\nthe predictions, and thus the samples are generated off-policy. The ability to\nlearn behavior-contingent predictions online and off-policy has long been\nadvocated as a key capability of predictive-knowledge learning systems but\nremained an open algorithmic challenge for decades. The issue lies with the\ntemporal difference (TD) learning update at the heart of most prediction\nalgorithms: combining bootstrapping, off-policy sampling and function\napproximation may cause the value estimate to diverge. A breakthrough came with\nthe development of a new objective function that admitted stochastic gradient\ndescent variants of TD. Since then, many sound online off-policy prediction\nalgorithms have been developed, but there has been limited empirical work\ninvestigating the relative merits of all the variants. This paper aims to fill\nthese empirical gaps and provide clarity on the key ideas behind each method.\nWe summarize the large body of literature on off-policy learning, focusing on\n1- methods that use computation linear in the number of features and are\nconvergent under off-policy sampling, and 2- other methods which have proven\nuseful with non-fixed, nonlinear function approximation. We provide an\nempirical study of off-policy prediction methods in two challenging\nmicroworlds. We report each method's parameter sensitivity, empirical\nconvergence rate, and final performance, providing new insights that should\nenable practitioners to successfully extend these new methods to large-scale\napplications.[Abridged abstract]\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 19:09:04 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Ghiassian", "Sina", ""], ["Patterson", "Andrew", ""], ["White", "Martha", ""], ["Sutton", "Richard S.", ""], ["White", "Adam", ""]]}, {"id": "1811.02598", "submitter": "Yannis Pantazis", "authors": "Yannis Pantazis, Dipjyoti Paul, Michail Fasoulakis, Yannis Stylianou", "title": "Training Generative Adversarial Networks with Weights", "comments": "6 pages, 3 figures, submitted to Icassp2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive success of Generative Adversarial Networks (GANs) is often\novershadowed by the difficulties in their training. Despite the continuous\nefforts and improvements, there are still open issues regarding their\nconvergence properties. In this paper, we propose a simple training variation\nwhere suitable weights are defined and assist the training of the Generator. We\nprovide theoretical arguments why the proposed algorithm is better than the\nbaseline training in the sense of speeding up the training process and of\ncreating a stronger Generator. Performance results showed that the new\nalgorithm is more accurate in both synthetic and image datasets resulting in\nimprovements ranging between 5% and 50%.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 19:10:33 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Pantazis", "Yannis", ""], ["Paul", "Dipjyoti", ""], ["Fasoulakis", "Michail", ""], ["Stylianou", "Yannis", ""]]}, {"id": "1811.02619", "submitter": "Yaqi Duan", "authors": "Yaqi Duan, Zheng Tracy Ke, Mengdi Wang", "title": "State Aggregation Learning from Markov Transition Data", "comments": "Accepted to NeurIPS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State aggregation is a popular model reduction method rooted in optimal\ncontrol. It reduces the complexity of engineering systems by mapping the\nsystem's states into a small number of meta-states. The choice of aggregation\nmap often depends on the data analysts' knowledge and is largely ad hoc. In\nthis paper, we propose a tractable algorithm that estimates the probabilistic\naggregation map from the system's trajectory. We adopt a soft-aggregation\nmodel, where each meta-state has a signature raw state, called an anchor state.\nThis model includes several common state aggregation models as special cases.\nOur proposed method is a simple two-step algorithm: The first step is spectral\ndecomposition of empirical transition matrix, and the second step conducts a\nlinear transformation of singular vectors to find their approximate convex\nhull. It outputs the aggregation distributions and disaggregation distributions\nfor each meta-state in explicit forms, which are not obtainable by classical\nspectral methods. On the theoretical side, we prove sharp error bounds for\nestimating the aggregation and disaggregation distributions and for identifying\nanchor states. The analysis relies on a new entry-wise deviation bound for\nsingular vectors of the empirical transition matrix of a Markov process, which\nis of independent interest and cannot be deduced from existing literature. The\napplication of our method to Manhattan traffic data successfully generates a\ndata-driven state aggregation map with nice interpretations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 20:31:37 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 00:17:54 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 01:29:52 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Duan", "Yaqi", ""], ["Ke", "Zheng Tracy", ""], ["Wang", "Mengdi", ""]]}, {"id": "1811.02625", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Yizheng Chen, Ahmed Abdou, Suman Jana", "title": "MixTrain: Scalable Training of Verifiably Robust Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making neural networks robust against adversarial inputs has resulted in an\narms race between new defenses and attacks. The most promising defenses,\nadversarially robust training and verifiably robust training, have limitations\nthat restrict their practical applications. The adversarially robust training\nonly makes the networks robust against a subclass of attackers and we reveal\nsuch weaknesses by developing a new attack based on interval gradients. By\ncontrast, verifiably robust training provides protection against any L-p\nnorm-bounded attacker but incurs orders of magnitude more computational and\nmemory overhead than adversarially robust training.\n  We propose two novel techniques, stochastic robust approximation and dynamic\nmixed training, to drastically improve the efficiency of verifiably robust\ntraining without sacrificing verified robustness. We leverage two critical\ninsights: (1) instead of over the entire training set, sound\nover-approximations over randomly subsampled training data points are\nsufficient for efficiently guiding the robust training process; and (2) We\nobserve that the test accuracy and verifiable robustness often conflict after\ncertain training epochs. Therefore, we use a dynamic loss function to\nadaptively balance them for each epoch.\n  We designed and implemented our techniques as part of MixTrain and evaluated\nit on six networks trained on three popular datasets including MNIST, CIFAR,\nand ImageNet-200. Our evaluations show that MixTrain can achieve up to $95.2\\%$\nverified robust accuracy against $L_\\infty$ norm-bounded attackers while taking\n$15$ and $3$ times less training time than state-of-the-art verifiably robust\ntraining and adversarially robust training schemes, respectively. Furthermore,\nMixTrain easily scales to larger networks like the one trained on ImageNet-200,\nsignificantly outperforming the existing verifiably robust training methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 20:47:28 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 23:52:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Wang", "Shiqi", ""], ["Chen", "Yizheng", ""], ["Abdou", "Ahmed", ""], ["Jana", "Suman", ""]]}, {"id": "1811.02628", "submitter": "Dong Yul Oh", "authors": "Dong Yul Oh and Il Dong Yun", "title": "Learning Bone Suppression from Dual Energy Chest X-rays using\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Suppressing bones on chest X-rays such as ribs and clavicle is often expected\nto improve pathologies classification. These bones can interfere with a broad\nrange of diagnostic tasks on pulmonary disease except for musculoskeletal\nsystem. Current conventional method for acquisition of bone suppressed X-rays\nis dual energy imaging, which captures two radiographs at a very short interval\nwith different energy levels; however, the patient is exposed to radiation\ntwice and the artifacts arise due to heartbeats between two shots. In this\npaper, we introduce a deep generative model trained to predict bone suppressed\nimages on single energy chest X-rays, analyzing a finite set of previously\nacquired dual energy chest X-rays. Since the relatively small amount of data is\navailable, such approach relies on the methodology maximizing the data\nutilization. Here we integrate the following two approaches. First, we use a\nconditional generative adversarial network that complements the traditional\nregression method minimizing the pairwise image difference. Second, we use Haar\n2D wavelet decomposition to offer a perceptual guideline in frequency details\nto allow the model to converge quickly and efficiently. As a result, we achieve\nstate-of-the-art performance on bone suppression as compared to the existing\napproaches with dual energy chest X-rays.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 01:01:31 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Oh", "Dong Yul", ""], ["Yun", "Il Dong", ""]]}, {"id": "1811.02629", "submitter": "Spyridon Bakas", "authors": "Spyridon Bakas, Mauricio Reyes, Andras Jakab, Stefan Bauer, Markus\n  Rempfler, Alessandro Crimi, Russell Takeshi Shinohara, Christoph Berger, Sung\n  Min Ha, Martin Rozycki, Marcel Prastawa, Esther Alberts, Jana Lipkova, John\n  Freymann, Justin Kirby, Michel Bilello, Hassan Fathallah-Shaykh, Roland\n  Wiest, Jan Kirschke, Benedikt Wiestler, Rivka Colen, Aikaterini Kotrotsou,\n  Pamela Lamontagne, Daniel Marcus, Mikhail Milchenko, Arash Nazeri, Marc-Andre\n  Weber, Abhishek Mahajan, Ujjwal Baid, Elizabeth Gerstner, Dongjin Kwon, Gagan\n  Acharya, Manu Agarwal, Mahbubul Alam, Alberto Albiol, Antonio Albiol,\n  Francisco J. Albiol, Varghese Alex, Nigel Allinson, Pedro H. A. Amorim,\n  Abhijit Amrutkar, Ganesh Anand, Simon Andermatt, Tal Arbel, Pablo Arbelaez,\n  Aaron Avery, Muneeza Azmat, Pranjal B., W Bai, Subhashis Banerjee, Bill\n  Barth, Thomas Batchelder, Kayhan Batmanghelich, Enzo Battistella, Andrew\n  Beers, Mikhail Belyaev, Martin Bendszus, Eze Benson, Jose Bernal, Halandur\n  Nagaraja Bharath, George Biros, Sotirios Bisdas, James Brown, Mariano\n  Cabezas, Shilei Cao, Jorge M. Cardoso, Eric N Carver, Adri\\`a Casamitjana,\n  Laura Silvana Castillo, Marcel Cat\\`a, Philippe Cattin, Albert Cerigues,\n  Vinicius S. Chagas, Siddhartha Chandra, Yi-Ju Chang, Shiyu Chang, Ken Chang,\n  Joseph Chazalon, Shengcong Chen, Wei Chen, Jefferson W Chen, Zhaolin Chen,\n  Kun Cheng, Ahana Roy Choudhury, Roger Chylla, Albert Cl\\'erigues, Steven\n  Colleman, Ramiro German Rodriguez Colmeiro, Marc Combalia, Anthony Costa,\n  Xiaomeng Cui, Zhenzhen Dai, Lutao Dai, Laura Alexandra Daza, Eric Deutsch,\n  Changxing Ding, Chao Dong, Shidu Dong, Wojciech Dudzik, Zach Eaton-Rosen,\n  Gary Egan, Guilherme Escudero, Th\\'eo Estienne, Richard Everson, Jonathan\n  Fabrizio, Yong Fan, Longwei Fang, Xue Feng, Enzo Ferrante, Lucas Fidon,\n  Martin Fischer, Andrew P. French, Naomi Fridman, Huan Fu, David Fuentes,\n  Yaozong Gao, Evan Gates, David Gering, Amir Gholami, Willi Gierke, Ben\n  Glocker, Mingming Gong, Sandra Gonz\\'alez-Vill\\'a, T. Grosges, Yuanfang Guan,\n  Sheng Guo, Sudeep Gupta, Woo-Sup Han, Il Song Han, Konstantin Harmuth,\n  Huiguang He, Aura Hern\\'andez-Sabat\\'e, Evelyn Herrmann, Naveen Himthani,\n  Winston Hsu, Cheyu Hsu, Xiaojun Hu, Xiaobin Hu, Yan Hu, Yifan Hu, Rui Hua,\n  Teng-Yi Huang, Weilin Huang, Sabine Van Huffel, Quan Huo, Vivek HV, Khan M.\n  Iftekharuddin, Fabian Isensee, Mobarakol Islam, Aaron S. Jackson, Sachin R.\n  Jambawalikar, Andrew Jesson, Weijian Jian, Peter Jin, V Jeya Maria Jose,\n  Alain Jungo, B Kainz, Konstantinos Kamnitsas, Po-Yu Kao, Ayush Karnawat,\n  Thomas Kellermeier, Adel Kermi, Kurt Keutzer, Mohamed Tarek Khadir, Mahendra\n  Khened, Philipp Kickingereder, Geena Kim, Nik King, Haley Knapp, Urspeter\n  Knecht, Lisa Kohli, Deren Kong, Xiangmao Kong, Simon Koppers, Avinash Kori,\n  Ganapathy Krishnamurthi, Egor Krivov, Piyush Kumar, Kaisar Kushibar, Dmitrii\n  Lachinov, Tryphon Lambrou, Joon Lee, Chengen Lee, Yuehchou Lee, M Lee,\n  Szidonia Lefkovits, Laszlo Lefkovits, James Levitt, Tengfei Li, Hongwei Li,\n  Wenqi Li, Hongyang Li, Xiaochuan Li, Yuexiang Li, Heng Li, Zhenye Li, Xiaoyu\n  Li, Zeju Li, XiaoGang Li, Wenqi Li, Zheng-Shen Lin, Fengming Lin, Pietro Lio,\n  Chang Liu, Boqiang Liu, Xiang Liu, Mingyuan Liu, Ju Liu, Luyan Liu, Xavier\n  Llado, Marc Moreno Lopez, Pablo Ribalta Lorenzo, Zhentai Lu, Lin Luo, Zhigang\n  Luo, Jun Ma, Kai Ma, Thomas Mackie, Anant Madabushi, Issam Mahmoudi, Klaus H.\n  Maier-Hein, Pradipta Maji, CP Mammen, Andreas Mang, B. S. Manjunath, Michal\n  Marcinkiewicz, S McDonagh, Stephen McKenna, Richard McKinley, Miriam Mehl,\n  Sachin Mehta, Raghav Mehta, Raphael Meier, Christoph Meinel, Dorit Merhof,\n  Craig Meyer, Robert Miller, Sushmita Mitra, Aliasgar Moiyadi, David\n  Molina-Garcia, Miguel A.B. Monteiro, Grzegorz Mrukwa, Andriy Myronenko, Jakub\n  Nalepa, Thuyen Ngo, Dong Nie, Holly Ning, Chen Niu, Nicholas K Nuechterlein,\n  Eric Oermann, Arlindo Oliveira, Diego D. C. Oliveira, Arnau Oliver, Alexander\n  F. I. Osman, Yu-Nian Ou, Sebastien Ourselin, Nikos Paragios, Moo Sung Park,\n  Brad Paschke, J. Gregory Pauloski, Kamlesh Pawar, Nick Pawlowski, Linmin Pei,\n  Suting Peng, Silvio M. Pereira, Julian Perez-Beteta, Victor M. Perez-Garcia,\n  Simon Pezold, Bao Pham, Ashish Phophalia, Gemma Piella, G.N. Pillai, Marie\n  Piraud, Maxim Pisov, Anmol Popli, Michael P. Pound, Reza Pourreza, Prateek\n  Prasanna, Vesna Prkovska, Tony P. Pridmore, Santi Puch, \\'Elodie Puybareau,\n  Buyue Qian, Xu Qiao, Martin Rajchl, Swapnil Rane, Michael Rebsamen, Hongliang\n  Ren, Xuhua Ren, Karthik Revanuru, Mina Rezaei, Oliver Rippel, Luis Carlos\n  Rivera, Charlotte Robert, Bruce Rosen, Daniel Rueckert, Mohammed Safwan,\n  Mostafa Salem, Joaquim Salvi, Irina Sanchez, Irina S\\'anchez, Heitor M.\n  Santos, Emmett Sartor, Dawid Schellingerhout, Klaudius Scheufele, Matthew R.\n  Scott, Artur A. Scussel, Sara Sedlar, Juan Pablo Serrano-Rubio, N. Jon Shah,\n  Nameetha Shah, Mazhar Shaikh, B. Uma Shankar, Zeina Shboul, Haipeng Shen,\n  Dinggang Shen, Linlin Shen, Haocheng Shen, Varun Shenoy, Feng Shi, Hyung Eun\n  Shin, Hai Shu, Diana Sima, M Sinclair, Orjan Smedby, James M. Snyder,\n  Mohammadreza Soltaninejad, Guidong Song, Mehul Soni, Jean Stawiaski, Shashank\n  Subramanian, Li Sun, Roger Sun, Jiawei Sun, Kay Sun, Yu Sun, Guoxia Sun,\n  Shuang Sun, Yannick R Suter, Laszlo Szilagyi, Sanjay Talbar, Dacheng Tao,\n  Dacheng Tao, Zhongzhao Teng, Siddhesh Thakur, Meenakshi H Thakur, Sameer\n  Tharakan, Pallavi Tiwari, Guillaume Tochon, Tuan Tran, Yuhsiang M. Tsai,\n  Kuan-Lun Tseng, Tran Anh Tuan, Vadim Turlapov, Nicholas Tustison, Maria\n  Vakalopoulou, Sergi Valverde, Rami Vanguri, Evgeny Vasiliev, Jonathan\n  Ventura, Luis Vera, Tom Vercauteren, C. A. Verrastro, Lasitha Vidyaratne,\n  Veronica Vilaplana, Ajeet Vivekanandan, Guotai Wang, Qian Wang, Chiatse J.\n  Wang, Weichung Wang, Duo Wang, Ruixuan Wang, Yuanyuan Wang, Chunliang Wang,\n  Guotai Wang, Ning Wen, Xin Wen, Leon Weninger, Wolfgang Wick, Shaocheng Wu,\n  Qiang Wu, Yihong Wu, Yong Xia, Yanwu Xu, Xiaowen Xu, Peiyuan Xu, Tsai-Ling\n  Yang, Xiaoping Yang, Hao-Yu Yang, Junlin Yang, Haojin Yang, Guang Yang,\n  Hongdou Yao, Xujiong Ye, Changchang Yin, Brett Young-Moxon, Jinhua Yu,\n  Xiangyu Yue, Songtao Zhang, Angela Zhang, Kun Zhang, Xuejie Zhang, Lichi\n  Zhang, Xiaoyue Zhang, Yazhuo Zhang, Lei Zhang, Jianguo Zhang, Xiang Zhang,\n  Tianhao Zhang, Sicheng Zhao, Yu Zhao, Xiaomei Zhao, Liang Zhao, Yefeng Zheng,\n  Liming Zhong, Chenhong Zhou, Xiaobing Zhou, Fan Zhou, Hongtu Zhu, Jin Zhu,\n  Ying Zhuge, Weiwei Zong, Jayashree Kalpathy-Cramer, Keyvan Farahani, Christos\n  Davatzikos, Koen van Leemput, Bjoern Menze", "title": "Identifying the Best Machine Learning Algorithms for Brain Tumor\n  Segmentation, Progression Assessment, and Overall Survival Prediction in the\n  BRATS Challenge", "comments": "The International Multimodal Brain Tumor Segmentation (BraTS)\n  Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gliomas are the most common primary brain malignancies, with different\ndegrees of aggressiveness, variable prognosis and various heterogeneous\nhistologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic\ncore, active and non-enhancing core. This intrinsic heterogeneity is also\nportrayed in their radio-phenotype, as their sub-regions are depicted by\nvarying intensity profiles disseminated across multi-parametric magnetic\nresonance imaging (mpMRI) scans, reflecting varying biological properties.\nTheir heterogeneous shape, extent, and location are some of the factors that\nmake these tumors difficult to resect, and in some cases inoperable. The amount\nof resected tumor is a factor also considered in longitudinal scans, when\nevaluating the apparent tumor for potential diagnosis of progression.\nFurthermore, there is mounting evidence that accurate segmentation of the\nvarious tumor sub-regions can offer the basis for quantitative image analysis\ntowards prediction of patient overall survival. This study assesses the\nstate-of-the-art machine learning (ML) methods used for brain tumor image\nanalysis in mpMRI scans, during the last seven instances of the International\nBrain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we\nfocus on i) evaluating segmentations of the various glioma sub-regions in\npre-operative mpMRI scans, ii) assessing potential tumor progression by virtue\nof longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO\ncriteria, and iii) predicting the overall survival from pre-operative mpMRI\nscans of patients that underwent gross total resection. Finally, we investigate\nthe challenge of identifying the best ML algorithms for each of these tasks,\nconsidering that apart from being diverse on each instance of the challenge,\nthe multi-institutional mpMRI BraTS dataset has also been a continuously\nevolving/growing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 05:10:18 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 23:18:19 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 13:35:04 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Bakas", "Spyridon", ""], ["Reyes", "Mauricio", ""], ["Jakab", "Andras", ""], ["Bauer", "Stefan", ""], ["Rempfler", "Markus", ""], ["Crimi", "Alessandro", ""], ["Shinohara", "Russell Takeshi", ""], ["Berger", "Christoph", ""], ["Ha", "Sung Min", ""], ["Rozycki", "Martin", ""], ["Prastawa", "Marcel", ""], ["Alberts", "Esther", ""], ["Lipkova", "Jana", ""], ["Freymann", "John", ""], ["Kirby", "Justin", ""], ["Bilello", "Michel", ""], ["Fathallah-Shaykh", "Hassan", ""], ["Wiest", "Roland", ""], ["Kirschke", "Jan", ""], ["Wiestler", "Benedikt", ""], ["Colen", "Rivka", ""], ["Kotrotsou", "Aikaterini", ""], ["Lamontagne", "Pamela", ""], ["Marcus", "Daniel", ""], ["Milchenko", "Mikhail", ""], ["Nazeri", "Arash", ""], ["Weber", "Marc-Andre", ""], ["Mahajan", "Abhishek", ""], ["Baid", "Ujjwal", ""], ["Gerstner", "Elizabeth", ""], ["Kwon", "Dongjin", ""], ["Acharya", "Gagan", ""], ["Agarwal", "Manu", ""], ["Alam", "Mahbubul", ""], ["Albiol", "Alberto", ""], ["Albiol", "Antonio", ""], ["Albiol", "Francisco J.", ""], ["Alex", "Varghese", ""], ["Allinson", "Nigel", ""], ["Amorim", "Pedro H. A.", ""], ["Amrutkar", "Abhijit", ""], ["Anand", "Ganesh", ""], ["Andermatt", "Simon", ""], ["Arbel", "Tal", ""], ["Arbelaez", "Pablo", ""], ["Avery", "Aaron", ""], ["Azmat", "Muneeza", ""], ["B.", "Pranjal", ""], ["Bai", "W", ""], ["Banerjee", "Subhashis", ""], ["Barth", "Bill", ""], ["Batchelder", "Thomas", ""], ["Batmanghelich", "Kayhan", ""], ["Battistella", "Enzo", ""], ["Beers", "Andrew", ""], ["Belyaev", "Mikhail", ""], ["Bendszus", "Martin", ""], ["Benson", "Eze", ""], ["Bernal", "Jose", ""], ["Bharath", "Halandur Nagaraja", ""], ["Biros", "George", ""], ["Bisdas", "Sotirios", ""], ["Brown", "James", ""], ["Cabezas", "Mariano", ""], ["Cao", "Shilei", ""], ["Cardoso", "Jorge M.", ""], ["Carver", "Eric N", ""], ["Casamitjana", "Adri\u00e0", ""], ["Castillo", "Laura Silvana", ""], ["Cat\u00e0", "Marcel", ""], ["Cattin", "Philippe", ""], ["Cerigues", "Albert", ""], ["Chagas", "Vinicius S.", ""], ["Chandra", "Siddhartha", ""], ["Chang", "Yi-Ju", ""], ["Chang", "Shiyu", ""], ["Chang", "Ken", ""], ["Chazalon", "Joseph", ""], ["Chen", "Shengcong", ""], ["Chen", "Wei", ""], ["Chen", "Jefferson W", ""], ["Chen", "Zhaolin", ""], ["Cheng", "Kun", ""], ["Choudhury", "Ahana Roy", ""], ["Chylla", "Roger", ""], ["Cl\u00e9rigues", "Albert", ""], ["Colleman", "Steven", ""], ["Colmeiro", "Ramiro German Rodriguez", ""], ["Combalia", "Marc", ""], ["Costa", "Anthony", ""], ["Cui", "Xiaomeng", ""], ["Dai", "Zhenzhen", ""], ["Dai", "Lutao", ""], ["Daza", "Laura Alexandra", ""], ["Deutsch", "Eric", ""], ["Ding", "Changxing", ""], ["Dong", "Chao", ""], ["Dong", "Shidu", ""], ["Dudzik", "Wojciech", ""], ["Eaton-Rosen", "Zach", ""], ["Egan", "Gary", ""], ["Escudero", "Guilherme", ""], ["Estienne", "Th\u00e9o", ""], ["Everson", "Richard", ""], ["Fabrizio", "Jonathan", ""], ["Fan", "Yong", ""], ["Fang", "Longwei", ""], ["Feng", "Xue", ""], ["Ferrante", "Enzo", ""], ["Fidon", "Lucas", ""], ["Fischer", "Martin", ""], ["French", "Andrew P.", ""], ["Fridman", "Naomi", ""], ["Fu", "Huan", ""], ["Fuentes", "David", ""], ["Gao", "Yaozong", ""], ["Gates", "Evan", ""], ["Gering", "David", ""], ["Gholami", "Amir", ""], ["Gierke", "Willi", ""], ["Glocker", "Ben", ""], ["Gong", "Mingming", ""], ["Gonz\u00e1lez-Vill\u00e1", "Sandra", ""], ["Grosges", "T.", ""], ["Guan", "Yuanfang", ""], ["Guo", "Sheng", ""], ["Gupta", "Sudeep", ""], ["Han", "Woo-Sup", ""], ["Han", "Il Song", ""], ["Harmuth", "Konstantin", ""], ["He", "Huiguang", ""], ["Hern\u00e1ndez-Sabat\u00e9", "Aura", ""], ["Herrmann", "Evelyn", ""], ["Himthani", "Naveen", ""], ["Hsu", "Winston", ""], ["Hsu", "Cheyu", ""], ["Hu", "Xiaojun", ""], ["Hu", "Xiaobin", ""], ["Hu", "Yan", ""], ["Hu", "Yifan", ""], ["Hua", "Rui", ""], ["Huang", "Teng-Yi", ""], ["Huang", "Weilin", ""], ["Van Huffel", "Sabine", ""], ["Huo", "Quan", ""], ["HV", "Vivek", ""], ["Iftekharuddin", "Khan M.", ""], ["Isensee", "Fabian", ""], ["Islam", "Mobarakol", ""], ["Jackson", "Aaron S.", ""], ["Jambawalikar", "Sachin R.", ""], ["Jesson", "Andrew", ""], ["Jian", "Weijian", ""], ["Jin", "Peter", ""], ["Jose", "V Jeya Maria", ""], ["Jungo", "Alain", ""], ["Kainz", "B", ""], ["Kamnitsas", "Konstantinos", ""], ["Kao", "Po-Yu", ""], ["Karnawat", "Ayush", ""], ["Kellermeier", "Thomas", ""], ["Kermi", "Adel", ""], ["Keutzer", "Kurt", ""], ["Khadir", "Mohamed Tarek", ""], ["Khened", "Mahendra", ""], ["Kickingereder", "Philipp", ""], ["Kim", "Geena", ""], ["King", "Nik", ""], ["Knapp", "Haley", ""], ["Knecht", "Urspeter", ""], ["Kohli", "Lisa", ""], ["Kong", "Deren", ""], ["Kong", "Xiangmao", ""], ["Koppers", "Simon", ""], ["Kori", "Avinash", ""], ["Krishnamurthi", "Ganapathy", ""], ["Krivov", "Egor", ""], ["Kumar", "Piyush", ""], ["Kushibar", "Kaisar", ""], ["Lachinov", "Dmitrii", ""], ["Lambrou", "Tryphon", ""], ["Lee", "Joon", ""], ["Lee", "Chengen", ""], ["Lee", "Yuehchou", ""], ["Lee", "M", ""], ["Lefkovits", "Szidonia", ""], ["Lefkovits", "Laszlo", ""], ["Levitt", "James", ""], ["Li", "Tengfei", ""], ["Li", "Hongwei", ""], ["Li", "Wenqi", ""], ["Li", "Hongyang", ""], ["Li", "Xiaochuan", ""], ["Li", "Yuexiang", ""], ["Li", "Heng", ""], ["Li", "Zhenye", ""], ["Li", "Xiaoyu", ""], ["Li", "Zeju", ""], ["Li", "XiaoGang", ""], ["Li", "Wenqi", ""], ["Lin", "Zheng-Shen", ""], ["Lin", "Fengming", ""], ["Lio", "Pietro", ""], ["Liu", "Chang", ""], ["Liu", "Boqiang", ""], ["Liu", "Xiang", ""], ["Liu", "Mingyuan", ""], ["Liu", "Ju", ""], ["Liu", "Luyan", ""], ["Llado", "Xavier", ""], ["Lopez", "Marc Moreno", ""], ["Lorenzo", "Pablo Ribalta", ""], ["Lu", "Zhentai", ""], ["Luo", "Lin", ""], ["Luo", "Zhigang", ""], ["Ma", "Jun", ""], ["Ma", "Kai", ""], ["Mackie", "Thomas", ""], ["Madabushi", "Anant", ""], ["Mahmoudi", "Issam", ""], ["Maier-Hein", "Klaus H.", ""], ["Maji", "Pradipta", ""], ["Mammen", "CP", ""], ["Mang", "Andreas", ""], ["Manjunath", "B. S.", ""], ["Marcinkiewicz", "Michal", ""], ["McDonagh", "S", ""], ["McKenna", "Stephen", ""], ["McKinley", "Richard", ""], ["Mehl", "Miriam", ""], ["Mehta", "Sachin", ""], ["Mehta", "Raghav", ""], ["Meier", "Raphael", ""], ["Meinel", "Christoph", ""], ["Merhof", "Dorit", ""], ["Meyer", "Craig", ""], ["Miller", "Robert", ""], ["Mitra", "Sushmita", ""], ["Moiyadi", "Aliasgar", ""], ["Molina-Garcia", "David", ""], ["Monteiro", "Miguel A. B.", ""], ["Mrukwa", "Grzegorz", ""], ["Myronenko", "Andriy", ""], ["Nalepa", "Jakub", ""], ["Ngo", "Thuyen", ""], ["Nie", "Dong", ""], ["Ning", "Holly", ""], ["Niu", "Chen", ""], ["Nuechterlein", "Nicholas K", ""], ["Oermann", "Eric", ""], ["Oliveira", "Arlindo", ""], ["Oliveira", "Diego D. C.", ""], ["Oliver", "Arnau", ""], ["Osman", "Alexander F. I.", ""], ["Ou", "Yu-Nian", ""], ["Ourselin", "Sebastien", ""], ["Paragios", "Nikos", ""], ["Park", "Moo Sung", ""], ["Paschke", "Brad", ""], ["Pauloski", "J. Gregory", ""], ["Pawar", "Kamlesh", ""], ["Pawlowski", "Nick", ""], ["Pei", "Linmin", ""], ["Peng", "Suting", ""], ["Pereira", "Silvio M.", ""], ["Perez-Beteta", "Julian", ""], ["Perez-Garcia", "Victor M.", ""], ["Pezold", "Simon", ""], ["Pham", "Bao", ""], ["Phophalia", "Ashish", ""], ["Piella", "Gemma", ""], ["Pillai", "G. N.", ""], ["Piraud", "Marie", ""], ["Pisov", "Maxim", ""], ["Popli", "Anmol", ""], ["Pound", "Michael P.", ""], ["Pourreza", "Reza", ""], ["Prasanna", "Prateek", ""], ["Prkovska", "Vesna", ""], ["Pridmore", "Tony P.", ""], ["Puch", "Santi", ""], ["Puybareau", "\u00c9lodie", ""], ["Qian", "Buyue", ""], ["Qiao", "Xu", ""], ["Rajchl", "Martin", ""], ["Rane", "Swapnil", ""], ["Rebsamen", "Michael", ""], ["Ren", "Hongliang", ""], ["Ren", "Xuhua", ""], ["Revanuru", "Karthik", ""], ["Rezaei", "Mina", ""], ["Rippel", "Oliver", ""], ["Rivera", "Luis Carlos", ""], ["Robert", "Charlotte", ""], ["Rosen", "Bruce", ""], ["Rueckert", "Daniel", ""], ["Safwan", "Mohammed", ""], ["Salem", "Mostafa", ""], ["Salvi", "Joaquim", ""], ["Sanchez", "Irina", ""], ["S\u00e1nchez", "Irina", ""], ["Santos", "Heitor M.", ""], ["Sartor", "Emmett", ""], ["Schellingerhout", "Dawid", ""], ["Scheufele", "Klaudius", ""], ["Scott", "Matthew R.", ""], ["Scussel", "Artur A.", ""], ["Sedlar", "Sara", ""], ["Serrano-Rubio", "Juan Pablo", ""], ["Shah", "N. Jon", ""], ["Shah", "Nameetha", ""], ["Shaikh", "Mazhar", ""], ["Shankar", "B. Uma", ""], ["Shboul", "Zeina", ""], ["Shen", "Haipeng", ""], ["Shen", "Dinggang", ""], ["Shen", "Linlin", ""], ["Shen", "Haocheng", ""], ["Shenoy", "Varun", ""], ["Shi", "Feng", ""], ["Shin", "Hyung Eun", ""], ["Shu", "Hai", ""], ["Sima", "Diana", ""], ["Sinclair", "M", ""], ["Smedby", "Orjan", ""], ["Snyder", "James M.", ""], ["Soltaninejad", "Mohammadreza", ""], ["Song", "Guidong", ""], ["Soni", "Mehul", ""], ["Stawiaski", "Jean", ""], ["Subramanian", "Shashank", ""], ["Sun", "Li", ""], ["Sun", "Roger", ""], ["Sun", "Jiawei", ""], ["Sun", "Kay", ""], ["Sun", "Yu", ""], ["Sun", "Guoxia", ""], ["Sun", "Shuang", ""], ["Suter", "Yannick R", ""], ["Szilagyi", "Laszlo", ""], ["Talbar", "Sanjay", ""], ["Tao", "Dacheng", ""], ["Tao", "Dacheng", ""], ["Teng", "Zhongzhao", ""], ["Thakur", "Siddhesh", ""], ["Thakur", "Meenakshi H", ""], ["Tharakan", "Sameer", ""], ["Tiwari", "Pallavi", ""], ["Tochon", "Guillaume", ""], ["Tran", "Tuan", ""], ["Tsai", "Yuhsiang M.", ""], ["Tseng", "Kuan-Lun", ""], ["Tuan", "Tran Anh", ""], ["Turlapov", "Vadim", ""], ["Tustison", "Nicholas", ""], ["Vakalopoulou", "Maria", ""], ["Valverde", "Sergi", ""], ["Vanguri", "Rami", ""], ["Vasiliev", "Evgeny", ""], ["Ventura", "Jonathan", ""], ["Vera", "Luis", ""], ["Vercauteren", "Tom", ""], ["Verrastro", "C. A.", ""], ["Vidyaratne", "Lasitha", ""], ["Vilaplana", "Veronica", ""], ["Vivekanandan", "Ajeet", ""], ["Wang", "Guotai", ""], ["Wang", "Qian", ""], ["Wang", "Chiatse J.", ""], ["Wang", "Weichung", ""], ["Wang", "Duo", ""], ["Wang", "Ruixuan", ""], ["Wang", "Yuanyuan", ""], ["Wang", "Chunliang", ""], ["Wang", "Guotai", ""], ["Wen", "Ning", ""], ["Wen", "Xin", ""], ["Weninger", "Leon", ""], ["Wick", "Wolfgang", ""], ["Wu", "Shaocheng", ""], ["Wu", "Qiang", ""], ["Wu", "Yihong", ""], ["Xia", "Yong", ""], ["Xu", "Yanwu", ""], ["Xu", "Xiaowen", ""], ["Xu", "Peiyuan", ""], ["Yang", "Tsai-Ling", ""], ["Yang", "Xiaoping", ""], ["Yang", "Hao-Yu", ""], ["Yang", "Junlin", ""], ["Yang", "Haojin", ""], ["Yang", "Guang", ""], ["Yao", "Hongdou", ""], ["Ye", "Xujiong", ""], ["Yin", "Changchang", ""], ["Young-Moxon", "Brett", ""], ["Yu", "Jinhua", ""], ["Yue", "Xiangyu", ""], ["Zhang", "Songtao", ""], ["Zhang", "Angela", ""], ["Zhang", "Kun", ""], ["Zhang", "Xuejie", ""], ["Zhang", "Lichi", ""], ["Zhang", "Xiaoyue", ""], ["Zhang", "Yazhuo", ""], ["Zhang", "Lei", ""], ["Zhang", "Jianguo", ""], ["Zhang", "Xiang", ""], ["Zhang", "Tianhao", ""], ["Zhao", "Sicheng", ""], ["Zhao", "Yu", ""], ["Zhao", "Xiaomei", ""], ["Zhao", "Liang", ""], ["Zheng", "Yefeng", ""], ["Zhong", "Liming", ""], ["Zhou", "Chenhong", ""], ["Zhou", "Xiaobing", ""], ["Zhou", "Fan", ""], ["Zhu", "Hongtu", ""], ["Zhu", "Jin", ""], ["Zhuge", "Ying", ""], ["Zong", "Weiwei", ""], ["Kalpathy-Cramer", "Jayashree", ""], ["Farahani", "Keyvan", ""], ["Davatzikos", "Christos", ""], ["van Leemput", "Koen", ""], ["Menze", "Bjoern", ""]]}, {"id": "1811.02640", "submitter": "Kashyap Chitta", "authors": "Kashyap Chitta, Jose M. Alvarez, Adam Lesnikowski", "title": "Deep Probabilistic Ensembles: Approximate Variational Inference through\n  KL Regularization", "comments": "Workshop on Bayesian Deep Learning (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Deep Probabilistic Ensembles (DPEs), a scalable\ntechnique that uses a regularized ensemble to approximate a deep Bayesian\nNeural Network (BNN). We do so by incorporating a KL divergence penalty term\ninto the training objective of an ensemble, derived from the evidence lower\nbound used in variational inference. We evaluate the uncertainty estimates\nobtained from our models for active learning on visual classification. Our\napproach steadily improves upon active learning baselines as the annotation\nbudget is increased.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 20:59:51 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 21:12:55 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Chitta", "Kashyap", ""], ["Alvarez", "Jose M.", ""], ["Lesnikowski", "Adam", ""]]}, {"id": "1811.02642", "submitter": "Aman Rana", "authors": "Aman Rana, Gregory Yauney, Alarice Lowe, Pratik Shah", "title": "Computational Histological Staining and Destaining of Prostate Core\n  Biopsy RGB Images with Generative Adversarial Neural Networks", "comments": "Accepted for publication at 2018 IEEE International Conference on\n  Machine Learning and Applications (ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00133", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Histopathology tissue samples are widely available in two states:\nparaffin-embedded unstained and non-paraffin-embedded stained whole slide RGB\nimages (WSRI). Hematoxylin and eosin stain (H&E) is one of the principal stains\nin histology but suffers from several shortcomings related to tissue\npreparation, staining protocols, slowness and human error. We report two novel\napproaches for training machine learning models for the computational H&E\nstaining and destaining of prostate core biopsy RGB images. The staining model\nuses a conditional generative adversarial network that learns hierarchical\nnon-linear mappings between whole slide RGB image (WSRI) pairs of prostate core\nbiopsy before and after H&E staining. The trained staining model can then\ngenerate computationally H&E-stained prostate core WSRIs using previously\nunseen non-stained biopsy images as input. The destaining model, by learning\nmappings between an H&E stained WSRI and a non-stained WSRI of the same biopsy,\ncan computationally destain previously unseen H&E-stained images. Structural\nand anatomical details of prostate tissue and colors, shapes, geometries,\nlocations of nuclei, stroma, vessels, glands and other cellular components were\ngenerated by both models with structural similarity indices of 0.68 (staining)\nand 0.84 (destaining). The proposed staining and destaining models can engender\ncomputational H&E staining and destaining of WSRI biopsies without additional\nequipment and devices.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 17:36:00 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 16:37:49 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Rana", "Aman", ""], ["Yauney", "Gregory", ""], ["Lowe", "Alarice", ""], ["Shah", "Pratik", ""]]}, {"id": "1811.02651", "submitter": "Emre E\\u{g}riboz", "authors": "Emre E\\u{g}riboz, Furkan Kaynar, Song\\\"ul Varl{\\i} Albayrak, Benan\n  M\\\"usellim, Tuba Sel\\c{c}uk", "title": "Finding and Following of Honeycombing Regions in Computed Tomography\n  Lung Images by Deep Learning", "comments": "4 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, besides the medical treatment methods in medical field,\nComputer Aided Diagnosis (CAD) systems which can facilitate the decision making\nphase of the physician and can detect the disease at an early stage have\nstarted to be used frequently. The diagnosis of Idiopathic Pulmonary Fibrosis\n(IPF) disease by using CAD systems is very important in that it can be followed\nby doctors and radiologists. It has become possible to diagnose and follow up\nthe disease with the help of CAD systems by the development of high resolution\ncomputed imaging scanners and increasing size of computation power. The purpose\nof this project is to design a tool that will help specialists diagnose and\nfollow up the IPF disease by identifying areas of honeycombing and ground glass\npatterns in High Resolution Computed Tomography (HRCT) lung images. Creating a\nprogram module that segments the lung pair and creating a self-learner deep\nlearning model from given Computed Tomography (CT) images for the specific\ndiseased regions thanks to doctors are the main purposes of this work. Through\nthe created model, program module will be able to find special regions in given\nnew CT images. In this study, the performance of lung segmentation was tested\nby the S{\\o}rensen-Dice coefficient method and the mean performance was\nmeasured as 90.7%, testing of the created model was performed with data not\nused in the training stage of the CNN network, and the average performance was\nmeasured as 87.8% for healthy regions, 73.3% for ground-glass areas and 69.1%\nfor honeycombing zones.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 18:29:45 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 21:25:09 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 10:24:10 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["E\u011friboz", "Emre", ""], ["Kaynar", "Furkan", ""], ["Albayrak", "Song\u00fcl Varl\u0131", ""], ["M\u00fcsellim", "Benan", ""], ["Sel\u00e7uk", "Tuba", ""]]}, {"id": "1811.02654", "submitter": "Ryan Sherman", "authors": "Ryan Sherman", "title": "A Volumetric Convolutional Neural Network for Brain Tumor Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain cancer can be very fatal, but chances of survival increase through\nearly detection and treatment. Doctors use Magnetic Resonance Imaging (MRI) to\ndetect and locate tumors in the brain, and very carefully analyze scans to\nsegment brain tumors. Manual segmentation is time consuming and tiring for\ndoctors, and it can be difficult for them to notice extremely small\nabnormalities. Automated segmentations performed by computers offer quicker\ndiagnoses, the ability to notice small details, and more accurate\nsegmentations. Advances in deep learning and computer hardware have allowed for\nhigh-performing automated segmentation approaches. However, several problems\npersist in practice: increased training time, class imbalance, and low\nperformance. In this paper, I propose applying V-Net, a volumetric, fully\nconvolutional neural network, to segment brain tumors in MRI scans from the\nBraTS Challenges. With this approach, I achieve a whole tumor dice score of\n0.89 and train the network in a short time while addressing class imbalance\nwith the use of a dice loss layer. Then, I propose applying an existing\ntechnique to improve automated segmentation performance in practice.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:28:54 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Sherman", "Ryan", ""]]}, {"id": "1811.02655", "submitter": "Alper Atamturk", "authors": "Alper Atamturk, Andres Gomez, Shaoning Han", "title": "Sparse and Smooth Signal Estimation: Convexification of L0 Formulations", "comments": "BCOL Research Report 18.05, IEOR, UC Berkeley", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal estimation problems with smoothness and sparsity priors can be\nnaturally modeled as quadratic optimization with $\\ell_0$-\"norm\" constraints.\nSince such problems are non-convex and hard-to-solve, the standard approach is,\ninstead, to tackle their convex surrogates based on $\\ell_1$-norm relaxations.\nIn this paper, we propose a new iterative (convex) conic quadratic relaxations\nthat exploit not only the $\\ell_0$-\"norm\" terms, but also the fitness and\nsmoothness functions. The iterative convexification approach substantially\ncloses the gap between the $\\ell_0$-\"norm\" and its $\\ell_1$ surrogate. These\nstronger relaxations lead to significantly better estimators than $\\ell_1$-norm\napproaches and also allow one to utilize affine sparsity priors. In addition,\nthe parameters of the model and the resulting estimators are easily\ninterpretable. Experiments with a tailored Lagrangian decomposition method\nindicate that the proposed iterative convex relaxations \\rev{yield solutions\nwithin 1\\% of the exact $\\ell_0$ approach, and can tackle instances with up to\n100,000 variables under one minute.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 21:10:20 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 22:39:48 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 19:03:59 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Atamturk", "Alper", ""], ["Gomez", "Andres", ""], ["Han", "Shaoning", ""]]}, {"id": "1811.02656", "submitter": "Titouan Parcollet", "authors": "Titouan Parcollet, Mohamed Morchid, Georges Linar\\`es", "title": "Quaternion Convolutional Neural Networks for Heterogeneous Image\n  Processing", "comments": "Submitted at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) have recently achieved state-of-the-art\nresults in various applications. In the case of image recognition, an ideal\nmodel has to learn independently of the training data, both local dependencies\nbetween the three components (R,G,B) of a pixel, and the global relations\ndescribing edges or shapes, making it efficient with small or heterogeneous\ndatasets. Quaternion-valued convolutional neural networks (QCNN) solved this\nproblematic by introducing multidimensional algebra to CNN. This paper proposes\nto explore the fundamental reason of the success of QCNN over CNN, by\ninvestigating the impact of the Hamilton product on a color image\nreconstruction task performed from a gray-scale only training. By learning\nindependently both internal and external relations and with less parameters\nthan real valued convolutional encoder-decoder (CAE), quaternion convolutional\nencoder-decoders (QCAE) perfectly reconstructed unseen color images while CAE\nproduced worst and gray-scale versions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 11:22:54 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Parcollet", "Titouan", ""], ["Morchid", "Mohamed", ""], ["Linar\u00e8s", "Georges", ""]]}, {"id": "1811.02657", "submitter": "Tan Nguyen", "authors": "Tan Nguyen, Nhat Ho, Ankit Patel, Anima Anandkumar, Michael I. Jordan,\n  Richard G. Baraniuk", "title": "A Bayesian Perspective of Convolutional Neural Networks through a\n  Deconvolutional Generative Model", "comments": "Keywords: neural nets, generative models, semi-supervised learning,\n  cross-entropy, statistical guarantees 80 pages, 7 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of Convolutional Neural Networks (CNNs) for\nsupervised prediction in images, we design the Deconvolutional Generative Model\n(DGM), a new probabilistic generative model whose inference calculations\ncorrespond to those in a given CNN architecture. The DGM uses a CNN to design\nthe prior distribution in the probabilistic model. Furthermore, the DGM\ngenerates images from coarse to finer scales. It introduces a small set of\nlatent variables at each scale, and enforces dependencies among all the latent\nvariables via a conjugate prior distribution. This conjugate prior yields a new\nregularizer based on paths rendered in the generative model for training\nCNNs-the Rendering Path Normalization (RPN). We demonstrate that this\nregularizer improves generalization, both in theory and in practice. In\naddition, likelihood estimation in the DGM yields training losses for CNNs, and\ninspired by this, we design a new loss termed as the Max-Min cross entropy\nwhich outperforms the traditional cross-entropy loss for object classification.\nThe Max-Min cross entropy suggests a new deep network architecture, namely the\nMax-Min network, which can learn from less labeled data while maintaining good\nprediction performance. Our experiments demonstrate that the DGM with the RPN\nand the Max-Min architecture exceeds or matches the-state-of-art on benchmarks\nincluding SVHN, CIFAR10, and CIFAR100 for semi-supervised and supervised\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 01:27:37 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 10:21:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Nguyen", "Tan", ""], ["Ho", "Nhat", ""], ["Patel", "Ankit", ""], ["Anandkumar", "Anima", ""], ["Jordan", "Michael I.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1811.02658", "submitter": "George Kesidis", "authors": "Yujia Wang, David J. Miller, George Kesidis", "title": "When Not to Classify: Detection of Reverse Engineering Attacks on DNN\n  Image Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses detection of a reverse engineering (RE) attack targeting\na deep neural network (DNN) image classifier; by querying, RE's aim is to\ndiscover the classifier's decision rule. RE can enable test-time evasion\nattacks, which require knowledge of the classifier. Recently, we proposed a\nquite effective approach (ADA) to detect test-time evasion attacks. In this\npaper, we extend ADA to detect RE attacks (ADA-RE). We demonstrate our method\nis successful in detecting \"stealthy\" RE attacks before they learn enough to\nlaunch effective test-time evasion attacks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 20:59:49 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Wang", "Yujia", ""], ["Miller", "David J.", ""], ["Kesidis", "George", ""]]}, {"id": "1811.02659", "submitter": "Aman Rana", "authors": "Perikumar Javia, Aman Rana, Nathan Shapiro, Pratik Shah", "title": "Machine Learning Algorithms for Classification of Microcirculation\n  Images from Septic and Non-Septic Patients", "comments": "Accepted for publication at 2018 IEEE International Conference on\n  Machine Learning and Applications (IEEE ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00097", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Sepsis is a life-threatening disease and one of the major causes of death in\nhospitals. Imaging of microcirculatory dysfunction is a promising approach for\nautomated diagnosis of sepsis. We report a machine learning classifier capable\nof distinguishing non-septic and septic images from dark field microcirculation\nvideos of patients. The classifier achieves an accuracy of 89.45%. The area\nunder the receiver operating characteristics of the classifier was 0.92, the\nprecision was 0.92 and the recall was 0.84. Codes representing the learned\nfeature space of trained classifier were visualized using t-SNE embedding and\nwere separable and distinguished between images from critically ill and\nnon-septic patients. Using an unsupervised convolutional autoencoder,\nindependent of the clinical diagnosis, we also report clustering of learned\nfeatures from a compressed representation associated with healthy images and\nthose with microcirculatory dysfunction. The feature space used by our trained\nclassifier to distinguish between images from septic and non-septic patients\nhas potential diagnostic application.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 15:34:18 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 16:50:47 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Javia", "Perikumar", ""], ["Rana", "Aman", ""], ["Shapiro", "Nathan", ""], ["Shah", "Pratik", ""]]}, {"id": "1811.02661", "submitter": "Trent Kyono", "authors": "Trent Kyono, Fiona J. Gilbert, Mihaela van der Schaar", "title": "MAMMO: A Deep Learning Solution for Facilitating Radiologist-Machine\n  Collaboration in Breast Cancer Diagnosis", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an aging and growing population, the number of women requiring either\nscreening or symptomatic mammograms is increasing. To reduce the number of\nmammograms that need to be read by a radiologist while keeping the diagnostic\naccuracy the same or better than current clinical practice, we develop Man and\nMachine Mammography Oracle (MAMMO) - a clinical decision support system capable\nof triaging mammograms into those that can be confidently classified by a\nmachine and those that cannot be, thus requiring the reading of a radiologist.\nThe first component of MAMMO is a novel multi-view convolutional neural network\n(CNN) with multi-task learning (MTL). MTL enables the CNN to learn the\nradiological assessments known to be associated with cancer, such as breast\ndensity, conspicuity, suspicion, etc., in addition to learning the primary task\nof cancer diagnosis. We show that MTL has two advantages: 1) learning refined\nfeature representations associated with cancer improves the classification\nperformance of the diagnosis task and 2) issuing radiological assessments\nprovides an additional layer of model interpretability that a radiologist can\nuse to debug and scrutinize the diagnoses provided by the CNN. The second\ncomponent of MAMMO is a triage network, which takes as input the radiological\nassessment and diagnostic predictions of the first network's MTL outputs and\ndetermines which mammograms can be correctly and confidently diagnosed by the\nCNN and which mammograms cannot, thus needing to be read by a radiologist.\nResults obtained on a private dataset of 8,162 patients show that MAMMO reduced\nthe number of radiologist readings by 42.8% while improving the overall\ndiagnostic accuracy in comparison to readings done by radiologists alone. We\nanalyze the triage of patients decided by MAMMO to gain a better understanding\nof what unique mammogram characteristics require radiologists' expertise.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 10:45:53 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Kyono", "Trent", ""], ["Gilbert", "Fiona J.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1811.02662", "submitter": "Guixiang Ma", "authors": "Guixiang Ma, Nesreen K. Ahmed, Ted Willke, Dipanjan Sengupta, Michael\n  W. Cole, Nicholas B. Turk-Browne, Philip S. Yu", "title": "Similarity Learning with Higher-Order Graph Convolutions for Brain\n  Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a similarity metric has gained much attention recently, where the\ngoal is to learn a function that maps input patterns to a target space while\npreserving the semantic distance in the input space. While most related work\nfocused on images, we focus instead on learning a similarity metric for\nneuroimages, such as fMRI and DTI images. We propose an end-to-end similarity\nlearning framework called Higher-order Siamese GCN for multi-subject fMRI data\nanalysis. The proposed framework learns the brain network representations via a\nsupervised metric-based approach with siamese neural networks using two graph\nconvolutional networks as the twin networks. Our proposed framework performs\nhigher-order convolutions by incorporating higher-order proximity in graph\nconvolutional networks to characterize and learn the community structure in\nbrain connectivity networks. To the best of our knowledge, this is the first\ncommunity-preserving similarity learning framework for multi-subject brain\nnetwork analysis. Experimental results on four real fMRI datasets demonstrate\nthe potential use cases of the proposed framework for multi-subject brain\nanalysis in health and neuropsychiatric disorders. Our proposed approach\nachieves an average AUC gain of 75% compared to PCA, an average AUC gain of\n65.5% compared to Spectral Embedding, and an average AUC gain of 24.3% compared\nto S-GCN across the four datasets, indicating promising application in clinical\ninvestigation and brain disease diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 03:51:45 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 03:49:36 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 16:01:11 GMT"}, {"version": "v4", "created": "Tue, 16 Apr 2019 06:16:46 GMT"}, {"version": "v5", "created": "Wed, 1 May 2019 21:10:27 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Ma", "Guixiang", ""], ["Ahmed", "Nesreen K.", ""], ["Willke", "Ted", ""], ["Sengupta", "Dipanjan", ""], ["Cole", "Michael W.", ""], ["Turk-Browne", "Nicholas B.", ""], ["Yu", "Philip S.", ""]]}, {"id": "1811.02667", "submitter": "Jakub Nalepa", "authors": "Pablo Ribalta Lorenzo, Lukasz Tulczyjew, Michal Marcinkiewicz, Jakub\n  Nalepa", "title": "Band Selection from Hyperspectral Images Using Attention-based\n  Convolutional Neural Networks", "comments": "This is an initial draft of the paper submitted to IEEE ACCESS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces new attention-based convolutional neural networks for\nselecting bands from hyperspectral images. The proposed approach re-uses\nconvolutional activations at different depths, identifying the most informative\nregions of the spectrum with the help of gating mechanisms. Our attention\ntechniques are modular and easy to implement, and they can be seamlessly\ntrained end-to-end using gradient descent. Our rigorous experiments showed that\ndeep models equipped with the attention mechanism deliver high-quality\nclassification, and repeatedly identify significant bands in the training data,\npermitting the creation of refined and extremely compact sets that retain the\nmost meaningful features.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 19:32:48 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 18:11:11 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 08:50:48 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Lorenzo", "Pablo Ribalta", ""], ["Tulczyjew", "Lukasz", ""], ["Marcinkiewicz", "Michal", ""], ["Nalepa", "Jakub", ""]]}, {"id": "1811.02668", "submitter": "Nghia (Andy) Nguyen", "authors": "Hanadi El Achi, Tatiana Belousova, Lei Chen, Amer Wahed, Iris Wang,\n  Zhihong Hu, Zeyad Kanaan, Adan Rios, Andy N.D. Nguyen", "title": "Automated Diagnosis of Lymphoma with Digital Pathology Images Using Deep\n  Learning", "comments": "13 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown promising results in using Deep Learning to detect\nmalignancy in whole slide imaging. However, they were limited to just\npredicting positive or negative finding for a specific neoplasm. We attempted\nto use Deep Learning with a convolutional neural network algorithm to build a\nlymphoma diagnostic model for four diagnostic categories: benign lymph node,\ndiffuse large B cell lymphoma, Burkitt lymphoma, and small lymphocytic\nlymphoma. Our software was written in Python language. We obtained digital\nwhole slide images of Hematoxylin and Eosin stained slides of 128 cases\nincluding 32 cases for each diagnostic category. Four sets of 5 representative\nimages, 40x40 pixels in dimension, were taken for each case. A total of 2,560\nimages were obtained from which 1,856 were used for training, 464 for\nvalidation and 240 for testing. For each test set of 5 images, the predicted\ndiagnosis was combined from prediction of 5 images. The test results showed\nexcellent diagnostic accuracy at 95% for image-by-image prediction and at 10%\nfor set-by-set prediction. This preliminary study provided a proof of concept\nfor incorporating automated lymphoma diagnostic screen into future pathology\nworkflow to augment the pathologists' productivity.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 19:40:50 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Achi", "Hanadi El", ""], ["Belousova", "Tatiana", ""], ["Chen", "Lei", ""], ["Wahed", "Amer", ""], ["Wang", "Iris", ""], ["Hu", "Zhihong", ""], ["Kanaan", "Zeyad", ""], ["Rios", "Adan", ""], ["Nguyen", "Andy N. D.", ""]]}, {"id": "1811.02672", "submitter": "Michele Santacatterina", "authors": "Yi Su and Lequn Wang and Michele Santacatterina and Thorsten Joachims", "title": "CAB: Continuous Adaptive Blending Estimator for Policy Evaluation and\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to perform offline A/B-testing and off-policy learning using\nlogged contextual bandit feedback is highly desirable in a broad range of\napplications, including recommender systems, search engines, ad placement, and\npersonalized health care. Both offline A/B-testing and off-policy learning\nrequire a counterfactual estimator that evaluates how some new policy would\nhave performed, if it had been used instead of the logging policy. In this\npaper, we identify a family of counterfactual estimators which subsumes most\nsuch estimators proposed to date. Our analysis of this family identifies a new\nestimator - called Continuous Adaptive Blending (CAB) - which enjoys many\nadvantageous theoretical and practical properties. In particular, it can be\nsubstantially less biased than clipped Inverse Propensity Score (IPS) weighting\nand the Direct Method, and it can have less variance than Doubly Robust and IPS\nestimators. In addition, it is sub-differentiable such that it can be used for\nlearning, unlike the SWITCH estimator. Experimental results show that CAB\nprovides excellent evaluation accuracy and outperforms other counterfactual\nestimators in terms of learning performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 21:47:00 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 22:29:01 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 01:17:17 GMT"}, {"version": "v4", "created": "Wed, 28 Aug 2019 19:01:31 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Su", "Yi", ""], ["Wang", "Lequn", ""], ["Santacatterina", "Michele", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1811.02693", "submitter": "Jacob Rafati", "authors": "Jacob Rafati and Roummel F. Marcia", "title": "Deep Reinforcement Learning via L-BFGS Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms allow artificial agents to improve\ntheir action selections so as to increase rewarding experiences in their\nenvironments. Deep Reinforcement Learning algorithms require solving a\nnonconvex and nonlinear unconstrained optimization problem. Methods for solving\nthe optimization problems in deep RL are restricted to the class of first-order\nalgorithms, such as stochastic gradient descent (SGD). The major drawback of\nthe SGD methods is that they have the undesirable effect of not escaping saddle\npoints and their performance can be seriously obstructed by ill-conditioning.\nFurthermore, SGD methods require exhaustive trial and error to fine-tune many\nlearning parameters. Using second derivative information can result in improved\nconvergence properties, but computing the Hessian matrix for large-scale\nproblems is not practical. Quasi-Newton methods require only first-order\ngradient information, like SGD, but they can construct a low rank approximation\nof the Hessian matrix and result in superlinear convergence. The limited-memory\nBroyden-Fletcher-Goldfarb-Shanno (L-BFGS) approach is one of the most popular\nquasi-Newton methods that construct positive definite Hessian approximations.\nIn this paper, we introduce an efficient optimization method, based on the\nlimited memory BFGS quasi-Newton method using line search strategy -- as an\nalternative to SGD methods. Our method bridges the disparity between first\norder methods and second order methods by continuing to use gradient\ninformation to calculate a low-rank Hessian approximations. We provide formal\nconvergence analysis as well as empirical results on a subset of the classic\nATARI 2600 games. Our results show a robust convergence with preferred\ngeneralization characteristics, as well as fast training time and no need for\nthe experience replaying mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 22:18:21 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 20:52:38 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Rafati", "Jacob", ""], ["Marcia", "Roummel F.", ""]]}, {"id": "1811.02694", "submitter": "Ran Wang", "authors": "Ran Wang, Yao Wang, Adeen Flinker", "title": "Reconstructing Speech Stimuli From Human Auditory Cortex Activity Using\n  a WaveNet Approach", "comments": "6 pages, 3 figures. Conference of 2018 IEEE Signal Processing in\n  Medicine and Biology Symposium (SPMB 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The superior temporal gyrus (STG) region of cortex critically contributes to\nspeech recognition. In this work, we show that a proposed WaveNet, with limited\navailable data, is able to reconstruct speech stimuli from STG intracranial\nrecordings. We further investigate the impulse response of the fitted model for\neach recording electrode and observe phoneme level temporospectral tuning\nproperties for the recorded area of cortex. This discovery is consistent with\nprevious studies implicating the posterior STG (pSTG) in a phonetic\nrepresentation of speech and provides detailed acoustic features that certain\nelectrode sites possibly extract during speech recognition.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 22:19:28 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 02:17:16 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Wang", "Ran", ""], ["Wang", "Yao", ""], ["Flinker", "Adeen", ""]]}, {"id": "1811.02702", "submitter": "Gary Cheng", "authors": "Gary Cheng and Armin Askari and Kannan Ramchandran and Laurent El\n  Ghaoui", "title": "Greedy Frank-Wolfe Algorithm for Exemplar Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of selecting representatives from a\ndata set for arbitrary supervised/unsupervised learning tasks. We identify a\nsubset $S$ of a data set $A$ such that 1) the size of $S$ is much smaller than\n$A$ and 2) $S$ efficiently describes the entire data set, in a way formalized\nvia convex optimization. In order to generate $|S| = k$ exemplars, our\nkernelizable algorithm, Frank-Wolfe Sparse Representation (FWSR), only needs to\nexecute $\\approx k$ iterations with a per-iteration cost that is quadratic in\nthe size of $A$. This is in contrast to other state of the art methods which\nneed to execute until convergence with each iteration costing an extra factor\nof $d$ (dimension of the data). Moreover, we also provide a proof of linear\nconvergence for our method. We support our results with empirical experiments;\nwe test our algorithm against current methods in three different experimental\nsetups on four different data sets. FWSR outperforms other exemplar finding\nmethods both in speed and accuracy in almost all scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 23:32:45 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 21:55:12 GMT"}, {"version": "v3", "created": "Sun, 23 Feb 2020 02:19:14 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cheng", "Gary", ""], ["Askari", "Armin", ""], ["Ramchandran", "Kannan", ""], ["Ghaoui", "Laurent El", ""]]}, {"id": "1811.02722", "submitter": "Danny Doan", "authors": "Minh Tuan Doan, Jianzhong Qi, Sutharshan Rajasegarar, Christopher\n  Leckie", "title": "Scalable Bottom-up Subspace Clustering using FP-Trees for High\n  Dimensional Data", "comments": "Accepted to IEEE International Conference on Big Data 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering aims to find groups of similar objects (clusters) that\nexist in lower dimensional subspaces from a high dimensional dataset. It has a\nwide range of applications, such as analysing high dimensional sensor data or\nDNA sequences. However, existing algorithms have limitations in finding\nclusters in non-disjoint subspaces and scaling to large data, which impinge\ntheir applicability in areas such as bioinformatics and the Internet of Things.\nWe aim to address such limitations by proposing a subspace clustering algorithm\nusing a bottom-up strategy. Our algorithm first searches for base clusters in\nlow dimensional subspaces. It then forms clusters in higher-dimensional\nsubspaces using these base clusters, which we formulate as a frequent pattern\nmining problem. This formulation enables efficient search for clusters in\nhigher-dimensional subspaces, which is done using FP-trees. The proposed\nalgorithm is evaluated against traditional bottom-up clustering algorithms and\nstate-of-the-art subspace clustering algorithms. The experimental results show\nthat the proposed algorithm produces clusters with high accuracy, and scales\nwell to large volumes of data. We also demonstrate the algorithm's performance\nusing real-life data, including ten genomic datasets and a car parking\noccupancy dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 01:54:39 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Doan", "Minh Tuan", ""], ["Qi", "Jianzhong", ""], ["Rajasegarar", "Sutharshan", ""], ["Leckie", "Christopher", ""]]}, {"id": "1811.02728", "submitter": "Rizal Fathony", "authors": "Rizal Fathony, Ashkan Rezaei, Mohammad Ali Bashiri, Xinhua Zhang,\n  Brian D. Ziebart", "title": "Distributionally Robust Graphical Models", "comments": "Appears in Neural Information Processing Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many structured prediction problems, complex relationships between\nvariables are compactly defined using graphical structures. The most prevalent\ngraphical prediction methods---probabilistic graphical models and large margin\nmethods---have their own distinct strengths but also possess significant\ndrawbacks. Conditional random fields (CRFs) are Fisher consistent, but they do\nnot permit integration of customized loss metrics into their learning process.\nLarge-margin models, such as structured support vector machines (SSVMs), have\nthe flexibility to incorporate customized loss metrics, but lack Fisher\nconsistency guarantees. We present adversarial graphical models (AGM), a\ndistributionally robust approach for constructing a predictor that performs\nrobustly for a class of data distributions defined using a graphical structure.\nOur approach enjoys both the flexibility of incorporating customized loss\nmetrics into its design as well as the statistical guarantee of Fisher\nconsistency. We present exact learning and prediction algorithms for AGM with\ntime complexity similar to existing graphical models and show the practical\nbenefits of our approach with experiments.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 02:18:32 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Fathony", "Rizal", ""], ["Rezaei", "Ashkan", ""], ["Bashiri", "Mohammad Ali", ""], ["Zhang", "Xinhua", ""], ["Ziebart", "Brian D.", ""]]}, {"id": "1811.02756", "submitter": "Kursat Rasim Mestav", "authors": "Kursat Rasim Mestav, Jaime Luengo-Rozas and Lang Tong", "title": "Bayesian State Estimation for Unobservable Distribution Systems via Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of state estimation for unobservable distribution systems is\nconsidered. A deep learning approach to Bayesian state estimation is proposed\nfor real-time applications. The proposed technique consists of distribution\nlearning of stochastic power injection, a Monte Carlo technique for the\ntraining of a deep neural network for state estimation, and a Bayesian bad-data\ndetection and filtering algorithm. Structural characteristics of the deep\nneural networks are investigated. Simulations illustrate the accuracy of\nBayesian state estimation for unobservable systems and demonstrate the benefit\nof employing a deep neural network. Numerical results show the robustness of\nBayesian state estimation against modeling and estimation errors and the\npresence of bad and missing data. Comparing with pseudo-measurement techniques,\ndirect Bayesian state estimation via deep learning neural network outperforms\nexisting benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 04:37:33 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 05:11:27 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 20:04:58 GMT"}, {"version": "v4", "created": "Mon, 25 Feb 2019 00:37:22 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mestav", "Kursat Rasim", ""], ["Luengo-Rozas", "Jaime", ""], ["Tong", "Lang", ""]]}, {"id": "1811.02757", "submitter": "Yikuan Li", "authors": "Yikuan Li, Liang Yao, Chengsheng Mao, Anand Srivastava, Xiaoqian Jiang\n  and Yuan Luo", "title": "Early Prediction of Acute Kidney Injury in Critical Care Setting Using\n  Clinical Notes", "comments": "4 pages, 3 figures, accepted by BIBM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Acute kidney injury (AKI) in critically ill patients is associated with\nsignificant morbidity and mortality. Development of novel methods to identify\npatients with AKI earlier will allow for testing of novel strategies to prevent\nor reduce the complications of AKI. We developed data-driven prediction models\nto estimate the risk of new AKI onset. We generated models from clinical notes\nwithin the first 24 hours following intensive care unit (ICU) admission\nextracted from Medical Information Mart for Intensive Care III (MIMIC-III).\nFrom the clinical notes, we generated clinically meaningful word and concept\nrepresentations and embeddings, respectively. Five supervised learning\nclassifiers and knowledge-guided deep learning architecture were used to\nconstruct prediction models. The best configuration yielded a competitive AUC\nof 0.779. Our work suggests that natural language processing of clinical notes\ncan be applied to assist clinicians in identifying the risk of incident AKI\nonset in critically ill patients upon admission to the ICU.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 04:45:55 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 18:34:48 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Li", "Yikuan", ""], ["Yao", "Liang", ""], ["Mao", "Chengsheng", ""], ["Srivastava", "Anand", ""], ["Jiang", "Xiaoqian", ""], ["Luo", "Yuan", ""]]}, {"id": "1811.02783", "submitter": "Yaroslav Zharov", "authors": "Yaroslav Zharov, Denis Korzhenkov, Pavel Shvechikov, Alexander\n  Tuzhilin", "title": "YASENN: Explaining Neural Networks via Partitioning Activation Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to feed-forward neural network interpretation\nbased on partitioning the space of sequences of neuron activations. In line\nwith this approach, we propose a model-specific interpretation method, called\nYASENN. Our method inherits many advantages of model-agnostic distillation,\nsuch as an ability to focus on the particular input region and to express an\nexplanation in terms of features different from those observed by a neural\nnetwork. Moreover, examination of distillation error makes the method\napplicable to the problems with low tolerance to interpretation mistakes.\nTechnically, YASENN distills the network with an ensemble of layer-wise\ngradient boosting decision trees and encodes the sequences of neuron\nactivations with leaf indices. The finite number of unique codes induces a\npartitioning of the input space. Each partition may be described in a variety\nof ways, including examination of an interpretable model (e.g. a logistic\nregression or a decision tree) trained to discriminate between objects of those\npartitions. Our experiments provide an intuition behind the method and\ndemonstrate revealed artifacts in neural network decision making.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 07:35:45 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Zharov", "Yaroslav", ""], ["Korzhenkov", "Denis", ""], ["Shvechikov", "Pavel", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "1811.02798", "submitter": "Phi Vu Tran", "authors": "Phi Vu Tran", "title": "Multi-Task Graph Autoencoders", "comments": "NIPS 2018 Workshop on Relational Representation Learning. Short\n  version of arXiv:1802.08352", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We examine two fundamental tasks associated with graph representation\nlearning: link prediction and node classification. We present a new autoencoder\narchitecture capable of learning a joint representation of local graph\nstructure and available node features for the simultaneous multi-task learning\nof unsupervised link prediction and semi-supervised node classification. Our\nsimple, yet effective and versatile model is efficiently trained end-to-end in\na single stage, whereas previous related deep graph embedding methods require\nmultiple training steps that are difficult to optimize. We provide an empirical\nevaluation of our model on five benchmark relational, graph-structured datasets\nand demonstrate significant improvement over three strong baselines for graph\nrepresentation learning. Reference code and data are available at\nhttps://github.com/vuptran/graph-representation-learning\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 08:27:52 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Tran", "Phi Vu", ""]]}, {"id": "1811.02814", "submitter": "Weiping Zhang", "authors": "Ye Tian, Weiping Zhang", "title": "THORS: An Efficient Approach for Making Classifiers Cost-sensitive", "comments": "26 pages, 6 figures", "journal-ref": "IEEE ACCESS 7(1):97704-97718 2019", "doi": "10.1109/ACCESS.2019.2929078", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an effective THresholding method based on ORder\nStatistic, called THORS, to convert an arbitrary scoring-type classifier, which\ncan induce a continuous cumulative distribution function of the score, into a\ncost-sensitive one. The procedure, uses order statistic to find an optimal\nthreshold for classification, requiring almost no knowledge of classifiers\nitself. Unlike common data-driven methods, we analytically show that THORS has\ntheoretical guaranteed performance, theoretical bounds for the costs and lower\ntime complexity. Coupled with empirical results on several real-world data\nsets, we argue that THORS is the preferred cost-sensitive technique.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 10:06:00 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Tian", "Ye", ""], ["Zhang", "Weiping", ""]]}, {"id": "1811.02820", "submitter": "Anton Belyy", "authors": "Anton Belyy", "title": "Construction and Quality Evaluation of Heterogeneous Hierarchical Topic\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In our work, we propose to represent HTM as a set of flat models, or layers,\nand a set of topical hierarchies, or edges. We suggest several quality measures\nfor edges of hierarchical models, resembling those proposed for flat models. We\nconduct an assessment experimentation and show strong correlation between the\nproposed measures and human judgement on topical edge quality. We also\nintroduce heterogeneous algorithm to build hierarchical topic models for\nheterogeneous data sources. We show how making certain adjustments to learning\nprocess helps to retain original structure of customized models while allowing\nfor slight coherent modifications for new documents. We evaluate this approach\nusing the proposed measures and show that the proposed heterogeneous algorithm\nsignificantly outperforms the baseline concat approach. Finally, we implement\nour own ESE called Rysearch, which demonstrates the potential of ARTM approach\nfor visualizing large heterogeneous document collections.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 10:32:50 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Belyy", "Anton", ""]]}, {"id": "1811.02827", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Umut Guclu and Marcel van Gerven", "title": "Wasserstein variational gradient descent: From semi-discrete optimal\n  transport to ensemble variational inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle-based variational inference offers a flexible way of approximating\ncomplex posterior distributions with a set of particles. In this paper we\nintroduce a new particle-based variational inference method based on the theory\nof semi-discrete optimal transport. Instead of minimizing the KL divergence\nbetween the posterior and the variational approximation, we minimize a\nsemi-discrete optimal transport divergence. The solution of the resulting\noptimal transport problem provides both a particle approximation and a set of\noptimal transportation densities that map each particle to a segment of the\nposterior distribution. We approximate these transportation densities by\nminimizing the KL divergence between a truncated distribution and the optimal\ntransport solution. The resulting algorithm can be interpreted as a form of\nensemble variational inference where each particle is associated with a local\nvariational approximation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 10:50:40 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 15:21:50 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Ambrogioni", "Luca", ""], ["Guclu", "Umut", ""], ["van Gerven", "Marcel", ""]]}, {"id": "1811.02834", "submitter": "Vayer Titouan", "authors": "Titouan Vayer, Laetita Chapel, R\\'emi Flamary, Romain Tavenard,\n  Nicolas Courty", "title": "Fused Gromov-Wasserstein distance for structured objects: theoretical\n  foundations and mathematical properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport theory has recently found many applications in machine\nlearning thanks to its capacity for comparing various machine learning objects\nconsidered as distributions. The Kantorovitch formulation, leading to the\nWasserstein distance, focuses on the features of the elements of the objects\nbut treat them independently, whereas the Gromov-Wasserstein distance focuses\nonly on the relations between the elements, depicting the structure of the\nobject, yet discarding its features.\n  In this paper we propose to extend these distances in order to encode\nsimultaneously both the feature and structure informations, resulting in the\nFused Gromov-Wasserstein distance. We develop the mathematical framework for\nthis novel distance, prove its metric and interpolation properties and provide\na concentration result for the convergence of finite samples. We also\nillustrate and interpret its use in various contexts where structured objects\nare involved.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 11:06:43 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Vayer", "Titouan", ""], ["Chapel", "Laetita", ""], ["Flamary", "R\u00e9mi", ""], ["Tavenard", "Romain", ""], ["Courty", "Nicolas", ""]]}, {"id": "1811.02850", "submitter": "Ilya Kamenshchikov", "authors": "Ilya Kamenshchikov, Matthias Krauledat", "title": "Effects of Dataset properties on the training of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks are a new family of generative models,\nfrequently used for generating photorealistic images. The theory promises for\nthe GAN to eventually reach an equilibrium where generator produces pictures\nindistinguishable for the training set. In practice, however, a range of\nproblems frequently prevents the system from reaching this equilibrium, with\ntraining not progressing ahead due to instabilities or mode collapse. This\npaper describes a series of experiments trying to identify patterns in regard\nto the effect of the training set on the dynamics and eventual outcome of the\ntraining.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 11:49:51 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 09:48:12 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 08:29:37 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Kamenshchikov", "Ilya", ""], ["Krauledat", "Matthias", ""]]}, {"id": "1811.02934", "submitter": "Deyu Meng", "authors": "Hongwei Yong, Deyu Meng, Jinxing Li, Wangmeng Zuo, Lei Zhang", "title": "Model Inconsistent but Correlated Noise: Multi-view Subspace Learning\n  with Regularized Mixture of Gaussians", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view subspace learning (MSL) aims to find a low-dimensional subspace of\nthe data obtained from multiple views. Different from single view case, MSL\nshould take both common and specific knowledge among different views into\nconsideration. To enhance the robustness of model, the complexity,\nnon-consistency and similarity of noise in multi-view data should be fully\ntaken into consideration. Most current MSL methods only assume a simple\nGaussian or Laplacian distribution for the noise while neglect the complex\nnoise configurations in each view and noise correlations among different views\nof practical data. To this issue, this work initiates a MSL method by encoding\nthe multi-view-shared and single-view-specific noise knowledge in data.\nSpecifically, we model data noise in each view as a separated Mixture of\nGaussians (MoG), which can fit a wider range of complex noise types than\nconventional Gaussian/Laplacian. Furthermore, we link all single-view-noise as\na whole by regularizing them by a common MoG component, encoding the shared\nnoise knowledge among them. Such regularization component can be formulated as\na concise KL-divergence regularization term under a MAP framework, leading to\ngood interpretation of our model and simple EM-based solving strategy to the\nproblem. Experimental results substantiate the superiority of our method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 15:30:39 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Yong", "Hongwei", ""], ["Meng", "Deyu", ""], ["Li", "Jinxing", ""], ["Zuo", "Wangmeng", ""], ["Zhang", "Lei", ""]]}, {"id": "1811.02945", "submitter": "Marija Jegorova", "authors": "Marija Jegorova, St\\'ephane Doncieux, Timothy Hospedales", "title": "Behavioural Repertoire via Generative Adversarial Policy Networks", "comments": "In Proceedings of 2019 Joint IEEE 9th International Conference on\n  Development and Learning and Epigenetic Robotics (ICDL-EpiRob), pages 320 -\n  326", "journal-ref": "2019 Joint IEEE 9th International Conference on Development and\n  Learning and Epigenetic Robotics (ICDL-EpiRob)", "doi": "10.1109/ICDL-EpiRob44920.2019", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms are enabling robots to solve increasingly challenging\nreal-world tasks. These approaches often rely on demonstrations and reproduce\nthe behavior shown. Unexpected changes in the environment may require using\ndifferent behaviors to achieve the same effect, for instance to reach and grasp\nan object in changing clutter. An emerging paradigm addressing this robustness\nissue is to learn a diverse set of successful behaviors for a given task, from\nwhich a robot can select the most suitable policy when faced with a new\nenvironment. In this paper, we explore a novel realization of this vision by\nlearning a generative model over policies. Rather than learning a single\npolicy, or a small fixed repertoire, our generative model for policies\ncompactly encodes an unbounded number of policies and allows novel controller\nvariants to be sampled. Leveraging our generative policy network, a robot can\nsample novel behaviors until it finds one that works for a new environment. We\ndemonstrate this idea with an application of robust ball-throwing in the\npresence of obstacles. We show that this approach achieves a greater diversity\nof behaviors than an existing evolutionary approach, while maintaining good\nefficacy of sampled behaviors, allowing a Baxter robot to hit targets more\noften when ball throwing in the presence of obstacles.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 15:47:48 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 17:11:05 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 17:37:28 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jegorova", "Marija", ""], ["Doncieux", "St\u00e9phane", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1811.02979", "submitter": "Benjamin Mark", "authors": "Benjamin Mark, Garvesh Raskutti, Rebecca Willett", "title": "Estimating Network Structure from Incomplete Event Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate Bernoulli autoregressive (BAR) processes model time series of\nevents in which the likelihood of current events is determined by the times and\nlocations of past events. These processes can be used to model nonlinear\ndynamical systems corresponding to criminal activity, responses of patients to\ndifferent medical treatment plans, opinion dynamics across social networks,\nepidemic spread, and more. Past work examines this problem under the assumption\nthat the event data is complete, but in many cases only a fraction of events\nare observed. Incomplete observations pose a significant challenge in this\nsetting because the unobserved events still govern the underlying dynamical\nsystem. In this work, we develop a novel approach to estimating the parameters\nof a BAR process in the presence of unobserved events via an unbiased estimator\nof the complete data log-likelihood function. We propose a computationally\nefficient estimation algorithm which approximates this estimator via Taylor\nseries truncation and establish theoretical results for both the statistical\nerror and optimization error of our algorithm. We further justify our approach\nby testing our method on both simulated data and a real data set consisting of\ncrimes recorded by the city of Chicago.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 16:44:48 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Mark", "Benjamin", ""], ["Raskutti", "Garvesh", ""], ["Willett", "Rebecca", ""]]}, {"id": "1811.02986", "submitter": "Loc Tran H", "authors": "Loc Hoang Tran, Linh Hoang Tran", "title": "Un-normalized hypergraph p-Laplacian based semi-supervised learning\n  methods", "comments": "13 pages, 3 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:1810.12743, arXiv:1212.0388", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most network-based machine learning methods assume that the labels of two\nadjacent samples in the network are likely to be the same. However, assuming\nthe pairwise relationship between samples is not complete. The information a\ngroup of samples that shows very similar pattern and tends to have similar\nlabels is missed. The natural way overcoming the information loss of the above\nassumption is to represent the feature dataset of samples as the hypergraph.\nThus, in this paper, we will present the un-normalized hypergraph p-Laplacian\nsemi-supervised learning methods. These methods will be applied to the zoo\ndataset and the tiny version of 20 newsgroups dataset. Experiment results show\nthat the accuracy performance measures of these un-normalized hypergraph\np-Laplacian based semi-supervised learning methods are significantly greater\nthan the accuracy performance measure of the un-normalized hypergraph Laplacian\nbased semi-supervised learning method (the current state of the art method\nhypergraph Laplacian based semi-supervised learning method for classification\nproblem with p=2).\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 03:46:32 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 13:21:46 GMT"}, {"version": "v3", "created": "Sun, 28 Apr 2019 10:51:40 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Tran", "Loc Hoang", ""], ["Tran", "Linh Hoang", ""]]}, {"id": "1811.03016", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Weidong Shi", "title": "Toward Efficient Breast Cancer Diagnosis and Survival Prediction Using\n  L-Perceptron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is the most frequently reported cancer type among the women\naround the globe and beyond that it has the second highest female fatality rate\namong all cancer types. Despite all the progresses made in prevention and early\nintervention, early prognosis and survival prediction rates are still\nunsatisfactory. In this paper, we propose a novel type of perceptron called\nL-Perceptron which outperforms all the previous supervised learning methods by\nreaching 97.42 \\% and 98.73 \\% in terms of accuracy and sensitivity,\nrespectively in Wisconsin Breast Cancer dataset. Experimental results on\nHaberman's Breast Cancer Survival dataset, show the superiority of proposed\nmethod by reaching 75.18 \\% and 83.86 \\% in terms of accuracy and F1 score,\nrespectively. The results are the best reported ones obtained in 10-fold cross\nvalidation in absence of any preprocessing or feature selection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 05:17:08 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Shi", "Weidong", ""]]}, {"id": "1811.03056", "submitter": "Christoph Dann", "authors": "Christoph Dann, Lihong Li, Wei Wei, Emma Brunskill", "title": "Policy Certificates: Towards Accountable Reinforcement Learning", "comments": "article appearing at ICML 2019; full version including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a reinforcement learning algorithm can vary drastically\nduring learning because of exploration. Existing algorithms provide little\ninformation about the quality of their current policy before executing it, and\nthus have limited use in high-stakes applications like healthcare. We address\nthis lack of accountability by proposing that algorithms output policy\ncertificates. These certificates bound the sub-optimality and return of the\npolicy in the next episode, allowing humans to intervene when the certified\nquality is not satisfactory. We further introduce two new algorithms with\ncertificates and present a new framework for theoretical analysis that\nguarantees the quality of their policies and certificates. For tabular MDPs, we\nshow that computing certificates can even improve the sample-efficiency of\noptimism-based exploration. As a result, one of our algorithms is the first to\nachieve minimax-optimal PAC bounds up to lower-order terms, and this algorithm\nalso matches (and in some settings slightly improves upon) existing minimax\nregret bounds.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 18:16:28 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 15:32:43 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 20:50:36 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Dann", "Christoph", ""], ["Li", "Lihong", ""], ["Wei", "Wei", ""], ["Brunskill", "Emma", ""]]}, {"id": "1811.03060", "submitter": "Raphael Tang", "authors": "Raphael Tang, Ashutosh Adhikari, Jimmy Lin", "title": "FLOPs as a Direct Optimization Objective for Learning Sparse Neural\n  Networks", "comments": "4 pages, accepted to the NIPS 2018 Workshop on Compact Deep Neural\n  Networks with Industrial Applications (CDNNRIA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a plethora of techniques for inducing structured sparsity in\nparametric models during the optimization process, with the final goal of\nresource-efficient inference. However, few methods target a specific number of\nfloating-point operations (FLOPs) as part of the optimization objective,\ndespite many reporting FLOPs as part of the results. Furthermore, a\none-size-fits-all approach ignores realistic system constraints, which differ\nsignificantly between, say, a GPU and a mobile phone -- FLOPs on the former\nincur less latency than on the latter; thus, it is important for practitioners\nto be able to specify a target number of FLOPs during model compression. In\nthis work, we extend a state-of-the-art technique to directly incorporate FLOPs\nas part of the optimization objective and show that, given a desired FLOPs\nrequirement, different neural networks can be successfully trained for image\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 18:21:25 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 18:20:10 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Tang", "Raphael", ""], ["Adhikari", "Ashutosh", ""], ["Lin", "Jimmy", ""]]}, {"id": "1811.03064", "submitter": "Chin-Chia Michael Yeh", "authors": "Chin-Chia Michael Yeh", "title": "Towards a Near Universal Time Series Data Mining Tool: Introducing the\n  Matrix Profile", "comments": "PhD dissertation (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has seen a flurry of research on all-pairs-similarity-search\n(or, self-join) for text, DNA, and a handful of other datatypes, and these\nsystems have been applied to many diverse data mining problems. Surprisingly,\nhowever, little progress has been made on addressing this problem for time\nseries subsequences. In this thesis, we have introduced a near universal time\nseries data mining tool called matrix profile which solves the\nall-pairs-similarity-search problem and caches the output in an easy-to-access\nfashion. The proposed algorithm is not only parameter-free, exact and scalable,\nbut also applicable for both single and multidimensional time series. By\nbuilding time series data mining methods on top of matrix profile, many time\nseries data mining tasks (e.g., motif discovery, discord discovery, shapelet\ndiscovery, semantic segmentation, and clustering) can be efficiently solved.\nBecause the same matrix profile can be shared by a diverse set of time series\ndata mining methods, matrix profile is versatile and\ncomputed-once-use-many-times data structure. We demonstrate the utility of\nmatrix profile for many time series data mining problems, including motif\ndiscovery, discord discovery, weakly labeled time series classification, and\nrepresentation learning on domains as diverse as seismology, entomology, music\nprocessing, bioinformatics, human activity monitoring, electrical power-demand\nmonitoring, and medicine. We hope the matrix profile is not the end but the\nbeginning of many more time series data mining projects.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 09:21:33 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 04:40:46 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Yeh", "Chin-Chia Michael", ""]]}, {"id": "1811.03076", "submitter": "Prem Seetharaman", "authors": "Prem Seetharaman, Gordon Wichern, Shrikant Venkataramani, Jonathan Le\n  Roux", "title": "Class-conditional embeddings for music source separation", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isolating individual instruments in a musical mixture has a myriad of\npotential applications, and seems imminently achievable given the levels of\nperformance reached by recent deep learning methods. While most musical source\nseparation techniques learn an independent model for each instrument, we\npropose using a common embedding space for the time-frequency bins of all\ninstruments in a mixture inspired by deep clustering and deep attractor\nnetworks. Additionally, an auxiliary network is used to generate parameters of\na Gaussian mixture model (GMM) where the posterior distribution over GMM\ncomponents in the embedding space can be used to create a mask that separates\nindividual sources from a mixture. In addition to outperforming a\nmask-inference baseline on the MUSDB-18 dataset, our embedding space is easily\ninterpretable and can be used for query-based separation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 18:49:34 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Seetharaman", "Prem", ""], ["Wichern", "Gordon", ""], ["Venkataramani", "Shrikant", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "1811.03081", "submitter": "Ben Moews", "authors": "Levi Fussell and Ben Moews", "title": "Forging new worlds: high-resolution synthetic galaxies with chained\n  generative adversarial networks", "comments": "13 pages, 9 figures", "journal-ref": "Mon. Notices Royal Astron. Soc. 485(3) (2019) 3203-3214", "doi": "10.1093/mnras/stz602", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astronomy of the 21st century increasingly finds itself with extreme\nquantities of data. This growth in data is ripe for modern technologies such as\ndeep image processing, which has the potential to allow astronomers to\nautomatically identify, classify, segment and deblend various astronomical\nobjects. In this paper, we explore the use of chained generative adversarial\nnetworks (GANs), a class of generative models that learn mappings from latent\nspaces to data distributions by modelling the joint distribution of the data,\nto produce physically realistic galaxy images as one use case of such models.\nIn cosmology, such datasets can aid in the calibration of shape measurements\nfor weak lensing by augmenting data with synthetic images. By measuring the\ndistributions of multiple physical properties, we show that images generated\nwith our approach closely follow the distributions of real galaxies, further\nestablishing state-of-the-art GAN architectures as a valuable tool for\nmodern-day astronomy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 18:56:55 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 18:48:30 GMT"}, {"version": "v3", "created": "Sat, 16 Mar 2019 15:28:08 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Fussell", "Levi", ""], ["Moews", "Ben", ""]]}, {"id": "1811.03087", "submitter": "Antoine Labatie", "authors": "Antoine Labatie", "title": "Characterizing Well-Behaved vs. Pathological Deep Neural Networks", "comments": "Proceedings of ICML 2019 (with contact info updated and formatting\n  issues fixed). Code available at https://github.com/alabatie/moments-dnns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach, requiring only mild assumptions, for the\ncharacterization of deep neural networks at initialization. Our approach\napplies both to fully-connected and convolutional networks and easily\nincorporates batch normalization and skip-connections. Our key insight is to\nconsider the evolution with depth of statistical moments of signal and noise,\nthereby characterizing the presence or absence of pathologies in the hypothesis\nspace encoded by the choice of hyperparameters. We establish: (i) for\nfeedforward networks, with and without batch normalization, the\nmultiplicativity of layer composition inevitably leads to ill-behaved moments\nand pathologies; (ii) for residual networks with batch normalization, on the\nother hand, skip-connections induce power-law rather than exponential\nbehaviour, leading to well-behaved moments and no pathology.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 18:59:37 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 17:27:38 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 11:10:24 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 17:49:07 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2019 12:43:23 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Labatie", "Antoine", ""]]}, {"id": "1811.03115", "submitter": "Mitchell Stern", "authors": "Mitchell Stern, Noam Shazeer, Jakob Uszkoreit", "title": "Blockwise Parallel Decoding for Deep Autoregressive Models", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep autoregressive sequence-to-sequence models have demonstrated impressive\nperformance across a wide variety of tasks in recent years. While common\narchitecture classes such as recurrent, convolutional, and self-attention\nnetworks make different trade-offs between the amount of computation needed per\nlayer and the length of the critical path at training time, generation still\nremains an inherently sequential process. To overcome this limitation, we\npropose a novel blockwise parallel decoding scheme in which we make predictions\nfor multiple time steps in parallel then back off to the longest prefix\nvalidated by a scoring model. This allows for substantial theoretical\nimprovements in generation speed when applied to architectures that can process\noutput sequences in parallel. We verify our approach empirically through a\nseries of experiments using state-of-the-art self-attention models for machine\ntranslation and image super-resolution, achieving iteration reductions of up to\n2x over a baseline greedy decoder with no loss in quality, or up to 7x in\nexchange for a slight decrease in performance. In terms of wall-clock time, our\nfastest models exhibit real-time speedups of up to 4x over standard greedy\ndecoding.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 19:09:40 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Stern", "Mitchell", ""], ["Shazeer", "Noam", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1811.03129", "submitter": "Michael Wakin", "authors": "Zhihui Zhu, Qiuwei Li, Xinshuo Yang, Gongguo Tang, and Michael B.\n  Wakin", "title": "Global Optimality in Distributed Low-rank Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of a variant of distributed gradient descent (DGD)\non a distributed low-rank matrix approximation problem wherein some\noptimization variables are used for consensus (as in classical DGD) and some\noptimization variables appear only locally at a single node in the network. We\nterm the resulting algorithm DGD+LOCAL. Using algorithmic connections to\ngradient descent and geometric connections to the well-behaved landscape of the\ncentralized low-rank matrix approximation problem, we identify sufficient\nconditions where DGD+LOCAL is guaranteed to converge with exact consensus to a\nglobal minimizer of the original centralized problem. For the distributed\nlow-rank matrix approximation problem, these guarantees are stronger---in terms\nof consensus and optimality---than what appear in the literature for classical\nDGD and more general problems.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 19:48:20 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 20:03:10 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zhu", "Zhihui", ""], ["Li", "Qiuwei", ""], ["Yang", "Xinshuo", ""], ["Tang", "Gongguo", ""], ["Wakin", "Michael B.", ""]]}, {"id": "1811.03146", "submitter": "Marvin Kennis", "authors": "Marvin Aron Kennis", "title": "Multi-channel discourse as an indicator for Bitcoin price and volume\n  movements", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research aims to identify how Bitcoin-related news publications and\nonline discourse are expressed in Bitcoin exchange movements of price and\nvolume. Being inherently digital, all Bitcoin-related fundamental data (from\nexchanges, as well as transactional data directly from the blockchain) is\navailable online, something that is not true for traditional businesses or\ncurrencies traded on exchanges. This makes Bitcoin an interesting subject for\nsuch research, as it enables the mapping of sentiment to fundamental events\nthat might otherwise be inaccessible. Furthermore, Bitcoin discussion largely\ntakes place on online forums and chat channels. In stock trading, the value of\nsentiment data in trading decisions has been demonstrated numerous times [1]\n[2] [3], and this research aims to determine whether there is value in such\ndata for Bitcoin trading models. To achieve this, data over the year 2015 has\nbeen collected from Bitcointalk.org, (the biggest Bitcoin forum in post\nvolume), established news sources such as Bloomberg and the Wall Street\nJournal, the complete /r/btc and /r/Bitcoin subreddits, and the bitcoin-otc and\nbitcoin-dev IRC channels. By analyzing this data on sentiment and volume, we\nfind weak to moderate correlations between forum, news, and Reddit sentiment\nand movements in price and volume from 1 to 5 days after the sentiment was\nexpressed. A Granger causality test confirms the predictive causality of the\nsentiment on the daily percentage price and volume movements, and at the same\ntime underscores the predictive causality of market movements on sentiment\nexpressions in online communities\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:39:00 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Kennis", "Marvin Aron", ""]]}, {"id": "1811.03149", "submitter": "Alireza Abdoli", "authors": "Alireza Abdoli, Amy C. Murillo, Chin-Chia M. Yeh, Alec C. Gerry,\n  Eamonn J. Keogh", "title": "Time Series Classification to Improve Poultry Welfare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poultry farms are an important contributor to the human food chain.\nWorldwide, humankind keeps an enormous number of domesticated birds (e.g.\nchickens) for their eggs and their meat, providing rich sources of low-fat\nprotein. However, around the world, there have been growing concerns about the\nquality of life for the livestock in poultry farms; and increasingly vocal\ndemands for improved standards of animal welfare. Recent advances in sensing\ntechnologies and machine learning allow the possibility of automatically\nassessing the health of some individual birds, and employing the lessons\nlearned to improve the welfare for all birds. This task superficially appears\nto be easy, given the dramatic progress in recent years in classifying human\nbehaviors, and given that human behaviors are presumably more complex. However,\nas we shall demonstrate, classifying chicken behaviors poses several unique\nchallenges, chief among which is creating a generalizable dictionary of\nbehaviors from sparse and noisy data. In this work we introduce a novel time\nseries dictionary learning algorithm that can robustly learn from weakly\nlabeled data sources.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 21:18:40 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Abdoli", "Alireza", ""], ["Murillo", "Amy C.", ""], ["Yeh", "Chin-Chia M.", ""], ["Gerry", "Alec C.", ""], ["Keogh", "Eamonn J.", ""]]}, {"id": "1811.03151", "submitter": "Kathleen Greene", "authors": "K. Gretchen Greene", "title": "DragonPaint: Rule based bootstrapping for small data with an application\n  to cartoon coloring", "comments": null, "journal-ref": "In Proceedings of the Fourth International Conference on\n  Predictive Applications and APIs, 82, 1-9, Boston, MA, USA, 2018. PMLR", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we confront the problem of deep learning's big labeled data\nrequirements, offer a rule based strategy for extreme augmentation of small\ndata sets and apply that strategy with the image to image translation model by\nIsola et al. (2016) to automate cel style cartoon coloring with very limited\ntraining data. While our experimental results using geometric rules and\ntransformations demonstrate the performance of our methods on an image\ntranslation task with industry applications in art, design and animation, we\nalso propose the use of rules on partial data sets as a generalizable small\ndata strategy, potentially applicable across data types and domains.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 21:23:31 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Greene", "K. Gretchen", ""]]}, {"id": "1811.03154", "submitter": "Francisco Ruiz", "authors": "Maryam Fatemi, Karl Granstr\\\"om, Lennart Svensson, Francisco J. R.\n  Ruiz, Lars Hammarstrand", "title": "Poisson Multi-Bernoulli Mapping Using Gibbs Sampling", "comments": "14 pages, 6 figures", "journal-ref": "IEEE Transactions on Signal Processing, Vol. 65, Issue 11, June\n  2017", "doi": "10.1109/TSP.2017.2675866", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the mapping problem. Using a conjugate prior form, we\nderive the exact theoretical batch multi-object posterior density of the map\ngiven a set of measurements. The landmarks in the map are modeled as extended\nobjects, and the measurements are described as a Poisson process, conditioned\non the map. We use a Poisson process prior on the map and prove that the\nposterior distribution is a hybrid Poisson, multi-Bernoulli mixture\ndistribution. We devise a Gibbs sampling algorithm to sample from the batch\nmulti-object posterior. The proposed method can handle uncertainties in the\ndata associations and the cardinality of the set of landmarks, and is\nparallelizable, making it suitable for large-scale problems. The performance of\nthe proposed method is evaluated on synthetic data and is shown to outperform a\nstate-of-the-art method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 21:30:55 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Fatemi", "Maryam", ""], ["Granstr\u00f6m", "Karl", ""], ["Svensson", "Lennart", ""], ["Ruiz", "Francisco J. R.", ""], ["Hammarstrand", "Lars", ""]]}, {"id": "1811.03166", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Alexander Wong, Ali Ghodsi", "title": "SRP: Efficient class-aware embedding learning for large-scale data via\n  supervised random projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised dimensionality reduction strategies have been of great interest.\nHowever, current supervised dimensionality reduction approaches are difficult\nto scale for situations characterized by large datasets given the high\ncomputational complexities associated with such methods. While stochastic\napproximation strategies have been explored for unsupervised dimensionality\nreduction to tackle this challenge, such approaches are not well-suited for\naccelerating computational speed for supervised dimensionality reduction.\nMotivated to tackle this challenge, in this study we explore a novel direction\nof directly learning optimal class-aware embeddings in a supervised manner via\nthe notion of supervised random projections (SRP). The key idea behind SRP is\nthat, rather than performing spectral decomposition (or approximations thereof)\nwhich are computationally prohibitive for large-scale data, we instead perform\na direct decomposition by leveraging kernel approximation theory and the\nsymmetry of the Hilbert-Schmidt Independence Criterion (HSIC) measure of\ndependence between the embedded data and the labels. Experimental results on\nfive different synthetic and real-world datasets demonstrate that the proposed\nSRP strategy for class-aware embedding learning can be very promising in\nproducing embeddings that are highly competitive with existing supervised\ndimensionality reduction methods (e.g., SPCA and KSPCA) while achieving 1-2\norders of magnitude better computational performance. As such, such an\nefficient approach to learning embeddings for dimensionality reduction can be a\npowerful tool for large-scale data analysis and visualization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 22:09:23 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Wong", "Alexander", ""], ["Ghodsi", "Ali", ""]]}, {"id": "1811.03179", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang", "title": "How Well Generative Adversarial Networks Learn Distributions", "comments": "36 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the rates of convergence for learning distributions\nimplicitly with the adversarial framework and Generative Adversarial Networks\n(GAN), which subsume Wasserstein, Sobolev, MMD GAN, and Generalized/Simulated\nMethod of Moments (GMM/SMM) as special cases. We study a wide range of\nparametric and nonparametric target distributions, under a host of objective\nevaluation metrics. We investigate how to obtain a good statistical guarantee\nfor GANs through the lens of regularization. On the nonparametric end, we\nderive the optimal minimax rates for distribution estimation under the\nadversarial framework. On the parametric end, we establish a theory for general\nneural network classes (including deep leaky ReLU networks), that characterizes\nthe interplay on the choice of generator and discriminator pair. We discover\nand isolate a new notion of regularization, called the\ngenerator-discriminator-pair regularization, that sheds light on the advantage\nof GANs compared to classical parametric and nonparametric approaches for\nexplicit distribution estimation. We develop novel oracle inequalities as the\nmain technical tools for analyzing GANs, which is of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 23:14:45 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 15:08:06 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 14:57:20 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liang", "Tengyuan", ""]]}, {"id": "1811.03194", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er, Pascal Dupr\\'e, Gili Rusak, Giancarlo Pellegrino,\n  Dan Boneh", "title": "AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning", "comments": "17 pages, 14 figures", "journal-ref": "In 2019 ACM SIGSAC Conference on Computer and Communications\n  Security (CCS '19)", "doi": "10.1145/3319535.3354222", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptual ad-blocking is a novel approach that detects online advertisements\nbased on their visual content. Compared to traditional filter lists, the use of\nperceptual signals is believed to be less prone to an arms race with web\npublishers and ad networks. We demonstrate that this may not be the case. We\ndescribe attacks on multiple perceptual ad-blocking techniques, and unveil a\nnew arms race that likely disfavors ad-blockers. Unexpectedly, perceptual\nad-blocking can also introduce new vulnerabilities that let an attacker bypass\nweb security boundaries and mount DDoS attacks.\n  We first analyze the design space of perceptual ad-blockers and present a\nunified architecture that incorporates prior academic and commercial work. We\nthen explore a variety of attacks on the ad-blocker's detection pipeline, that\nenable publishers or ad networks to evade or detect ad-blocking, and at times\neven abuse its high privilege level to bypass web security boundaries.\n  On one hand, we show that perceptual ad-blocking must visually classify\nrendered web content to escape an arms race centered on obfuscation of page\nmarkup. On the other, we present a concrete set of attacks on visual\nad-blockers by constructing adversarial examples in a real web page context.\nFor seven ad-detectors, we create perturbed ads, ad-disclosure logos, and\nnative web content that misleads perceptual ad-blocking with 100% success\nrates. In one of our attacks, we demonstrate how a malicious user can upload\nadversarial content, such as a perturbed image in a Facebook post, that fools\nthe ad-blocker into removing another users' non-ad content.\n  Moving beyond the Web and visual domain, we also build adversarial examples\nfor AdblockRadio, an open source radio client that uses machine learning to\ndetects ads in raw audio streams.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 00:20:12 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:02:47 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 10:27:39 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Dupr\u00e9", "Pascal", ""], ["Rusak", "Gili", ""], ["Pellegrino", "Giancarlo", ""], ["Boneh", "Dan", ""]]}, {"id": "1811.03205", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Ashish Khetan, Zinan Lin, Sewoong Oh", "title": "Robustness of Conditional GANs to Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning conditional generators from noisy labeled\nsamples, where the labels are corrupted by random noise. A standard training of\nconditional GANs will not only produce samples with wrong labels, but also\ngenerate poor quality samples. We consider two scenarios, depending on whether\nthe noise model is known or not. When the distribution of the noise is known,\nwe introduce a novel architecture which we call Robust Conditional GAN (RCGAN).\nThe main idea is to corrupt the label of the generated sample before feeding to\nthe adversarial discriminator, forcing the generator to produce samples with\nclean labels. This approach of passing through a matching noisy channel is\njustified by corresponding multiplicative approximation bounds between the loss\nof the RCGAN and the distance between the clean real distribution and the\ngenerator distribution. This shows that the proposed approach is robust, when\nused with a carefully chosen discriminator architecture, known as projection\ndiscriminator. When the distribution of the noise is not known, we provide an\nextension of our architecture, which we call RCGAN-U, that learns the noise\nmodel simultaneously while training the generator. We show experimentally on\nMNIST and CIFAR-10 datasets that both the approaches consistently improve upon\nbaseline approaches, and RCGAN-U closely matches the performance of RCGAN.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 01:07:17 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Khetan", "Ashish", ""], ["Lin", "Zinan", ""], ["Oh", "Sewoong", ""]]}, {"id": "1811.03233", "submitter": "Byeongho Heo", "authors": "Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi", "title": "Knowledge Transfer via Distillation of Activation Boundaries Formed by\n  Hidden Neurons", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An activation boundary for a neuron refers to a separating hyperplane that\ndetermines whether the neuron is activated or deactivated. It has been long\nconsidered in neural networks that the activations of neurons, rather than\ntheir exact output values, play the most important role in forming\nclassification friendly partitions of the hidden feature space. However, as far\nas we know, this aspect of neural networks has not been considered in the\nliterature of knowledge transfer. In this paper, we propose a knowledge\ntransfer method via distillation of activation boundaries formed by hidden\nneurons. For the distillation, we propose an activation transfer loss that has\nthe minimum value when the boundaries generated by the student coincide with\nthose by the teacher. Since the activation transfer loss is not differentiable,\nwe design a piecewise differentiable loss approximating the activation transfer\nloss. By the proposed method, the student learns a separating boundary between\nactivation region and deactivation region formed by each neuron in the teacher.\nThrough the experiments in various aspects of knowledge transfer, it is\nverified that the proposed method outperforms the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 02:47:56 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 15:29:53 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Heo", "Byeongho", ""], ["Lee", "Minsik", ""], ["Yun", "Sangdoo", ""], ["Choi", "Jin Young", ""]]}, {"id": "1811.03250", "submitter": "Chi Wang", "authors": "Silu Huang, Chi Wang, Bolin Ding, Surajit Chaudhuri", "title": "ABC: Efficient Selection of Machine Learning Configuration on Large\n  Dataset", "comments": "Full version of an AAAI 2019 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning configuration refers to a combination of preprocessor,\nlearner, and hyperparameters. Given a set of configurations and a large dataset\nrandomly split into training and testing set, we study how to efficiently\nselect the best configuration with approximately the highest testing accuracy\nwhen trained from the training set. To guarantee small accuracy loss, we\ndevelop a solution using confidence interval (CI)-based progressive sampling\nand pruning strategy. Compared to using full data to find the exact best\nconfiguration, our solution achieves more than two orders of magnitude speedup,\nwhile the returned top configuration has identical or close test accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 03:44:11 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 08:11:52 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Huang", "Silu", ""], ["Wang", "Chi", ""], ["Ding", "Bolin", ""], ["Chaudhuri", "Surajit", ""]]}, {"id": "1811.03259", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao and Hongyu Ren and Arianna Yuan and Jiaming Song and\n  Noah Goodman and Stefano Ermon", "title": "Bias and Generalization in Deep Generative Models: An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensional settings, density estimation algorithms rely crucially on\ntheir inductive bias. Despite recent empirical success, the inductive bias of\ndeep generative models is not well understood. In this paper we propose a\nframework to systematically investigate bias and generalization in deep\ngenerative models of images. Inspired by experimental methods from cognitive\npsychology, we probe each learning algorithm with carefully designed training\ndatasets to characterize when and how existing models generate novel attributes\nand their combinations. We identify similarities to human psychology and verify\nthat these patterns are consistent across commonly used models and\narchitectures.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 04:15:28 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Zhao", "Shengjia", ""], ["Ren", "Hongyu", ""], ["Yuan", "Arianna", ""], ["Song", "Jiaming", ""], ["Goodman", "Noah", ""], ["Ermon", "Stefano", ""]]}, {"id": "1811.03270", "submitter": "Dacheng Tao", "authors": "Jingwei Zhang, Tongliang Liu, Dacheng Tao", "title": "An Optimal Transport View on Generalization", "comments": "27 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We derive upper bounds on the generalization error of learning algorithms\nbased on their \\emph{algorithmic transport cost}: the expected Wasserstein\ndistance between the output hypothesis and the output hypothesis conditioned on\nan input example. The bounds provide a novel approach to study the\ngeneralization of learning algorithms from an optimal transport view and impose\nless constraints on the loss function, such as sub-gaussian or bounded. We\nfurther provide several upper bounds on the algorithmic transport cost in terms\nof total variation distance, relative entropy (or KL-divergence), and VC\ndimension, thus further bridging optimal transport theory and information\ntheory with statistical learning theory. Moreover, we also study different\nconditions for loss functions under which the generalization error of a\nlearning algorithm can be upper bounded by different probability metrics\nbetween distributions relating to the output hypothesis and/or the input data.\nFinally, under our established framework, we analyze the generalization in deep\nlearning and conclude that the generalization error in deep neural networks\n(DNNs) decreases exponentially to zero as the number of layers increases. Our\nanalyses of generalization error in deep learning mainly exploit the\nhierarchical structure in DNNs and the contraction property of $f$-divergence,\nwhich may be of independent interest in analyzing other learning models with\nhierarchical structure.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 05:02:11 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Zhang", "Jingwei", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1811.03305", "submitter": "Mahesh Subedar", "authors": "Ranganath Krishnan, Mahesh Subedar, Omesh Tickoo", "title": "BAR: Bayesian Activity Recognition using variational inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation in deep neural networks is essential for designing\nreliable and robust AI systems. Applications such as video surveillance for\nidentifying suspicious activities are designed with deep neural networks\n(DNNs), but DNNs do not provide uncertainty estimates. Capturing reliable\nuncertainty estimates in safety and security critical applications will help to\nestablish trust in the AI system. Our contribution is to apply Bayesian deep\nlearning framework to visual activity recognition application and quantify\nmodel uncertainty along with principled confidence. We utilize the stochastic\nvariational inference technique while training the Bayesian DNNs to infer the\napproximate posterior distribution around model parameters and perform Monte\nCarlo sampling on the posterior of model parameters to obtain the predictive\ndistribution. We show that the Bayesian inference applied to DNNs provide\nreliable confidence measures for visual activity recognition task as compared\nto conventional DNNs. We also show that our method improves the visual activity\nrecognition precision-recall AUC by 6.2% compared to non-Bayesian baseline. We\nevaluate our models on Moments-In-Time (MiT) activity recognition dataset by\nselecting a subset of in- and out-of-distribution video samples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 08:04:09 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 08:08:34 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Krishnan", "Ranganath", ""], ["Subedar", "Mahesh", ""], ["Tickoo", "Omesh", ""]]}, {"id": "1811.03322", "submitter": "Daning Cheng", "authors": "Cheng Daning, Zhang Hanping, Xia Fen, Li Shigang, Zhang Yunquan", "title": "Using Known Information to Accelerate HyperParameters Optimization Based\n  on SMBO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automl is the key technology for machine learning problem. Current state of\nart hyperparameter optimization methods are based on traditional black-box\noptimization methods like SMBO (SMAC, TPE). The objective function of black-box\noptimization is non-smooth, or time-consuming to evaluate, or in some way\nnoisy. Recent years, many researchers offered the work about the properties of\nhyperparameters. However, traditional hyperparameter optimization methods do\nnot take those information into consideration. In this paper, we use gradient\ninformation and machine learning model analysis information to accelerate\ntraditional hyperparameter optimization methods SMBO. In our L2 norm\nexperiments, our method yielded state-of-the-art performance, and in many cases\noutperformed the previous best configuration approach.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 09:04:09 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 06:58:56 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Daning", "Cheng", ""], ["Hanping", "Zhang", ""], ["Fen", "Xia", ""], ["Shigang", "Li", ""], ["Yunquan", "Zhang", ""]]}, {"id": "1811.03356", "submitter": "Antonio Carta", "authors": "Davide Bacciu, Antonio Carta, Alessandro Sperduti", "title": "Linear Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks can learn complex transduction problems that\nrequire maintaining and actively exploiting a memory of their inputs. Such\nmodels traditionally consider memory and input-output functionalities\nindissolubly entangled. We introduce a novel recurrent architecture based on\nthe conceptual separation between the functional input-output transformation\nand the memory mechanism, showing how they can be implemented through different\nneural components. By building on such conceptualization, we introduce the\nLinear Memory Network, a recurrent model comprising a feedforward neural\nnetwork, realizing the non-linear functional transformation, and a linear\nautoencoder for sequences, implementing the memory component. The resulting\narchitecture can be efficiently trained by building on closed-form solutions to\nlinear optimization problems. Further, by exploiting equivalence results\nbetween feedforward and recurrent neural networks we devise a pretraining\nschema for the proposed architecture. Experiments on polyphonic music datasets\nshow competitive results against gated recurrent networks and other state of\nthe art models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 11:08:04 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Bacciu", "Davide", ""], ["Carta", "Antonio", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "1811.03377", "submitter": "Pablo G. Camara", "authors": "Kiya W. Govek, Venkata S. Yamajala, Pablo G. Camara", "title": "Spectral Simplicial Theory for Feature Selection and Applications to\n  Genomics", "comments": "22 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale and complexity of modern data sets and the limitations associated\nwith testing large numbers of hypotheses underline the need for feature\nselection methods. Spectral techniques rank features according to their degree\nof consistency with an underlying metric structure, but their current\ngraph-based formulation restricts their applicability to point features. We\nextend spectral methods for feature selection to abstract simplicial complexes\nand present a general framework which can be applied to 2-point and\nhigher-order features. Combinatorial Laplacian scores take into account the\ntopology spanned by the data and reduce to the ordinary Laplacian score in the\ncase of point features. We demonstrate the utility of spectral simplicial\nmethods for feature selection with several examples of application to the\nanalysis of gene expression and multi-modal genomic data. Our results provide a\nunifying perspective on topological data analysis and manifold learning\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 12:27:49 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Govek", "Kiya W.", ""], ["Yamajala", "Venkata S.", ""], ["Camara", "Pablo G.", ""]]}, {"id": "1811.03388", "submitter": "Jill-J\\^enn Vie", "authors": "Jill-J\\^enn Vie and Hisashi Kashima", "title": "Knowledge Tracing Machines: Factorization Machines for Knowledge Tracing", "comments": "8 pages, 3 figures, 7 tables, to appear at the 33th AAAI Conference\n  on Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge tracing is a sequence prediction problem where the goal is to\npredict the outcomes of students over questions as they are interacting with a\nlearning platform. By tracking the evolution of the knowledge of some student,\none can optimize instruction. Existing methods are either based on temporal\nlatent variable models, or factor analysis with temporal features. We here show\nthat factorization machines (FMs), a model for regression or classification,\nencompasses several existing models in the educational literature as special\ncases, notably additive factor model, performance factor model, and\nmultidimensional item response theory. We show, using several real datasets of\ntens of thousands of users and items, that FMs can estimate student knowledge\naccurately and fast even when student data is sparsely observed, and handle\nside information such as multiple knowledge components and number of attempts\nat item or skill level. Our approach allows to fit student models of higher\ndimension than existing models, and provides a testbed to try new combinations\nof features in order to improve existing models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 13:02:09 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 05:41:18 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Vie", "Jill-J\u00eann", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1811.03392", "submitter": "Ivan Olier", "authors": "Ivan Olier and Oghenejokpeme I. Orhobor and Joaquin Vanschoren and\n  Ross D. King", "title": "Transformative Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key to success in machine learning (ML) is the use of effective data\nrepresentations. Traditionally, data representations were hand-crafted.\nRecently it has been demonstrated that, given sufficient data, deep neural\nnetworks can learn effective implicit representations from simple input\nrepresentations. However, for most scientific problems, the use of deep\nlearning is not appropriate as the amount of available data is limited, and/or\nthe output models must be explainable. Nevertheless, many scientific problems\ndo have significant amounts of data available on related tasks, which makes\nthem amenable to multi-task learning, i.e. learning many related problems\nsimultaneously. Here we propose a novel and general representation learning\napproach for multi-task learning that works successfully with small amounts of\ndata. The fundamental new idea is to transform an input intrinsic data\nrepresentation (i.e., handcrafted features), to an extrinsic representation\nbased on what a pre-trained set of models predict about the examples. This\ntransformation has the dual advantages of producing significantly more accurate\npredictions, and providing explainable models. To demonstrate the utility of\nthis transformative learning approach, we have applied it to three real-world\nscientific problems: drug-design (quantitative structure activity relationship\nlearning), predicting human gene expression (across different tissue types and\ndrug treatments), and meta-learning for machine learning (predicting which\nmachine learning methods work best for a given problem). In all three problems,\ntransformative machine learning significantly outperforms the best intrinsic\nrepresentation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 13:09:05 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Olier", "Ivan", ""], ["Orhobor", "Oghenejokpeme I.", ""], ["Vanschoren", "Joaquin", ""], ["King", "Ross D.", ""]]}, {"id": "1811.03402", "submitter": "Steven Whang", "authors": "Yuji Roh, Geon Heo, Steven Euijong Whang", "title": "A Survey on Data Collection for Machine Learning: a Big Data -- AI\n  Integration Perspective", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection is a major bottleneck in machine learning and an active\nresearch topic in multiple communities. There are largely two reasons data\ncollection has recently become a critical issue. First, as machine learning is\nbecoming more widely-used, we are seeing new applications that do not\nnecessarily have enough labeled data. Second, unlike traditional machine\nlearning, deep learning techniques automatically generate features, which saves\nfeature engineering costs, but in return may require larger amounts of labeled\ndata. Interestingly, recent research in data collection comes not only from the\nmachine learning, natural language, and computer vision communities, but also\nfrom the data management community due to the importance of handling large\namounts of data. In this survey, we perform a comprehensive study of data\ncollection from a data management point of view. Data collection largely\nconsists of data acquisition, data labeling, and improvement of existing data\nor models. We provide a research landscape of these operations, provide\nguidelines on which technique to use when, and identify interesting research\nchallenges. The integration of machine learning and data management for data\ncollection is part of a larger trend of Big data and Artificial Intelligence\n(AI) integration and opens many opportunities for new research.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 13:37:46 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 13:48:36 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Roh", "Yuji", ""], ["Heo", "Geon", ""], ["Whang", "Steven Euijong", ""]]}, {"id": "1811.03403", "submitter": "Jarryd Son", "authors": "Jarryd Son, Amit Mishra", "title": "ExGate: Externally Controlled Gating for Feature-based Attention in\n  Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptual capabilities of artificial systems have come a long way since the\nadvent of deep learning. These methods have proven to be effective, however\nthey are not as efficient as their biological counterparts. Visual attention is\na set of mechanisms that are employed in biological visual systems to ease\ncomputational load by only processing pertinent parts of the stimuli. This\npaper addresses the implementation of top-down, feature-based attention in an\nartificial neural network by use of externally controlled neuron gating. Our\nresults showed a 5% increase in classification accuracy on the CIFAR-10 dataset\nversus a non-gated version, while adding very few parameters. Our gated model\nalso produces more reasonable errors in predictions by drastically reducing\nprediction of classes that belong to a different category to the true class.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 13:39:49 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Son", "Jarryd", ""], ["Mishra", "Amit", ""]]}, {"id": "1811.03407", "submitter": "Marco Cox", "authors": "Marco Cox, Thijs van de Laar, Bert de Vries", "title": "A Factor Graph Approach to Automated Design of Bayesian Signal\n  Processing Algorithms", "comments": "Accepted for publication in the International Journal of Approximate\n  Reasoning", "journal-ref": null, "doi": "10.1016/j.ijar.2018.11.002", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The benefits of automating design cycles for Bayesian inference-based\nalgorithms are becoming increasingly recognized by the machine learning\ncommunity. As a result, interest in probabilistic programming frameworks has\nmuch increased over the past few years. This paper explores a specific\nprobabilistic programming paradigm, namely message passing in Forney-style\nfactor graphs (FFGs), in the context of automated design of efficient Bayesian\nsignal processing algorithms. To this end, we developed \"ForneyLab\"\n(https://github.com/biaslab/ForneyLab.jl) as a Julia toolbox for message\npassing-based inference in FFGs. We show by example how ForneyLab enables\nautomatic derivation of Bayesian signal processing algorithms, including\nalgorithms for parameter estimation and model comparison. Crucially, due to the\nmodular makeup of the FFG framework, both the model specification and inference\nmethods are readily extensible in ForneyLab. In order to test this framework,\nwe compared variational message passing as implemented by ForneyLab with\nautomatic differentiation variational inference (ADVI) and Monte Carlo methods\nas implemented by state-of-the-art tools \"Edward\" and \"Stan\". In terms of\nperformance, extensibility and stability issues, ForneyLab appears to enjoy an\nedge relative to its competitors for automated inference in state-space models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 13:53:46 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Cox", "Marco", ""], ["van de Laar", "Thijs", ""], ["de Vries", "Bert", ""]]}, {"id": "1811.03422", "submitter": "Wenbo Guo", "authors": "Wenbo Guo and Sui Huang and Yunzhe Tao and Xinyu Xing and Lin Lin", "title": "Explaining Deep Learning Models - A Bayesian Non-parametric Approach", "comments": "In Proceedings of the 32nd Conference on Neural Information\n  Processing Systems. arXiv admin note: text overlap with arXiv:1705.08564", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and interpreting how machine learning (ML) models make\ndecisions have been a big challenge. While recent research has proposed various\ntechnical approaches to provide some clues as to how an ML model makes\nindividual predictions, they cannot provide users with an ability to inspect a\nmodel as a complete entity. In this work, we propose a novel technical approach\nthat augments a Bayesian non-parametric regression mixture model with multiple\nelastic nets. Using the enhanced mixture model, we can extract generalizable\ninsights for a target model through a global approximation. To demonstrate the\nutility of our approach, we evaluate it on different ML models in the context\nof image recognition. The empirical results indicate that our proposed approach\nnot only outperforms the state-of-the-art techniques in explaining individual\ndecisions but also provides users with an ability to discover the\nvulnerabilities of the target ML models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 16:26:32 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Guo", "Wenbo", ""], ["Huang", "Sui", ""], ["Tao", "Yunzhe", ""], ["Xing", "Xinyu", ""], ["Lin", "Lin", ""]]}, {"id": "1811.03431", "submitter": "I\\~nigo Urteaga", "authors": "I\\~nigo Urteaga, Mollie McKillop, Sharon Lipsky-Gorman and No\\'emie\n  Elhadad", "title": "Phenotyping Endometriosis through Mixed Membership Models of\n  Self-Tracking Data", "comments": "As presented in Machine Learning for Healthcare 2018,\n  https://www.mlforhc.org/2018-conference/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of self-tracking data and unsupervised\nmixed-membership models to phenotype endometriosis. Endometriosis is a\nsystemic, chronic condition of women in reproductive age and, at the same time,\na highly enigmatic condition with no known biomarkers to monitor its\nprogression and no established staging. We leverage data collected through a\nself-tracking app in an observational research study of over 2,800 women with\nendometriosis tracking their condition over a year and a half (456,900\nobservations overall). We extend a classical mixed-membership model to\naccommodate the idiosyncrasies of the data at hand (i.e., the multimodality of\nthe tracked variables). Our experiments show that our approach identifies\npotential subtypes that are robust in terms of biases of self-tracked data\n(e.g., wide variations in tracking frequency amongst participants), as well as\nto variations in hyperparameters of the model. Jointly modeling a wide range of\nobservations about participants (symptoms, quality of life, treatments) yields\nclinically meaningful subtypes that both validate what is already known about\nendometriosis and suggest new findings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 17:54:18 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Urteaga", "I\u00f1igo", ""], ["McKillop", "Mollie", ""], ["Lipsky-Gorman", "Sharon", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "1811.03433", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Nicholas Ayache", "title": "Explainable cardiac pathology classification on cine MRI with motion\n  characterization by semi-supervised learning of apparent flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to classify cardiac pathology based on a novel approach\nto extract image derived features to characterize the shape and motion of the\nheart. An original semi-supervised learning procedure, which makes efficient\nuse of a large amount of non-segmented images and a small amount of images\nsegmented manually by experts, is developed to generate pixel-wise apparent\nflow between two time points of a 2D+t cine MRI image sequence. Combining the\napparent flow maps and cardiac segmentation masks, we obtain a local apparent\nflow corresponding to the 2D motion of myocardium and ventricular cavities.\nThis leads to the generation of time series of the radius and thickness of\nmyocardial segments to represent cardiac motion. These time series of motion\nfeatures are reliable and explainable characteristics of pathological cardiac\nmotion. Furthermore, they are combined with shape-related features to classify\ncardiac pathologies. Using only nine feature values as input, we propose an\nexplainable, simple and flexible model for pathology classification. On ACDC\ntraining set and testing set, the model achieves 95% and 94% respectively as\nclassification accuracy. Its performance is hence comparable to that of the\nstate-of-the-art. Comparison with various other models is performed to outline\nsome advantages of our model.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 14:22:05 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 20:52:47 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1811.03436", "submitter": "Heeyoul Choi", "authors": "Hayoung Eom, Heeyoul Choi", "title": "Alpha-Integration Pooling for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have achieved remarkable performance in\nmany applications, especially in image recognition tasks. As a crucial\ncomponent of CNNs, sub-sampling plays an important role for efficient training\nor invariance property, and max-pooling and arithmetic average-pooling are\ncommonly used sub-sampling methods. In addition to the two pooling methods,\nhowever, there could be many other pooling types, such as geometric average,\nharmonic average, and so on. Since it is not easy for algorithms to find the\nbest pooling method, usually the pooling types are assumed a priority, which\nmight not be optimal for different tasks. In line with the deep learning\nphilosophy, the type of pooling can be driven by data for a given task. In this\npaper, we propose {\\it $\\alpha$-integration pooling} ($\\alpha$I-pooling), which\nhas a trainable parameter $\\alpha$ to find the type of pooling.\n$\\alpha$I-pooling is a general pooling method including max-pooling and\narithmetic average-pooling as a special case, depending on the parameter\n$\\alpha$. Experiments show that $\\alpha$I-pooling outperforms other pooling\nmethods including max-pooling, in image recognition tasks. Also, it turns out\nthat each layer has different optimal pooling type.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 14:25:08 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 04:08:27 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 06:20:00 GMT"}, {"version": "v4", "created": "Sat, 14 Mar 2020 12:33:21 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Eom", "Hayoung", ""], ["Choi", "Heeyoul", ""]]}, {"id": "1811.03437", "submitter": "Mustafa Hajij", "authors": "Omar Elbagalati, Mustafa Hajij", "title": "Integrating Project Spatial Coordinates into Pavement Management\n  Prioritization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, pavement management software products and studies on optimizing the\nprioritization of pavement maintenance and rehabilitation (M&R) have been\nmainly focused on three parameters; the pre-treatment pavement condition, the\nrehabilitation cost, and the available budget. Yet, the role of the candidate\nprojects' spatial characteristics in the decision-making process has not been\ndeeply considered. Such a limitation, predominately, allows the recommended M&R\nprojects' schedule to involve simultaneously running but spatially scattered\nconstruction sites, which are very challenging to monitor and manage. This\nstudy introduces a novel approach to integrate pavement segments' spatial\ncoordinates into the M&R prioritization analysis. The introduced approach aims\nat combining the pavement segments with converged spatial coordinates to be\nrepaired in the same timeframe without compromising the allocated budget levels\nor the overall target Pavement Condition Index (PCI). Such a combination would\nresult in minimizing the routing of crews, materials and other equipment among\nthe construction sites and would provide better collaborations and\ncommunications between the pavement maintenance teams. Proposed herein is a\nnovel spatial clustering algorithm that automatically finds the projects within\na certain budget and spatial constrains. The developed algorithm was\nsuccessfully validated using 1,800 pavement maintenance projects from two\nreal-life examples of the City of Milton, GA and the City of Tyler, TX.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:38:28 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Elbagalati", "Omar", ""], ["Hajij", "Mustafa", ""]]}, {"id": "1811.03444", "submitter": "Heeyoul Choi", "authors": "Sangchul Hahn, Heeyoul Choi", "title": "Disentangling Latent Factors of Variational Auto-Encoder with Whitening", "comments": "ICANN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After deep generative models were successfully applied to image generation\ntasks, learning disentangled latent variables of data has become a crucial part\nof deep generative model research. Many models have been proposed to learn an\ninterpretable and factorized representation of latent variable by modifying\ntheir objective function or model architecture. To disentangle the latent\nvariable, some models show lower quality of reconstructed images and others\nincrease the model complexity which is hard to train. In this paper, we propose\na simple disentangling method based on a traditional whitening process. The\nproposed method is applied to the latent variables of variational auto-encoder\n(VAE), although it can be applied to any generative models with latent\nvariables. In experiment, we apply the proposed method to simple VAE models and\nexperiment results confirm that our method finds more interpretable factors\nfrom the latent space while keeping the reconstruction error the same as the\nconventional VAE's error.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 14:33:16 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 03:30:39 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hahn", "Sangchul", ""], ["Choi", "Heeyoul", ""]]}, {"id": "1811.03450", "submitter": "Vincent Cheutet", "authors": "L. Chang, Yacine Ouzrout (DISP), Antoine Nongaillard (DISP), Abdelaziz\n  Bouras (DISP)", "title": "Optimized Hidden Markov Model based on Constrained Particle Swarm\n  Optimization", "comments": null, "journal-ref": "IEEE International Conference on Software, Knowledge Information,\n  Industrial Management and Applications SKIMA'12 International Conference, Sep\n  2012, Chengdu, China. 6 p", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of Bayesian analysis tools, Hidden Markov Model (HMM) has been used to\nin extensive applications. Most HMMs are solved by Baum-Welch algorithm (BWHMM)\nto predict the model parameters, which is difficult to find global optimal\nsolutions. This paper proposes an optimized Hidden Markov Model with Particle\nSwarm Optimization (PSO) algorithm and so is called PSOHMM. In order to\novercome the statistical constraints in HMM, the paper develops\nre-normalization and re-mapping mechanisms to ensure the constraints in HMM.\nThe experiments have shown that PSOHMM can search better solution than BWHMM,\nand has faster convergence speed.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 09:53:16 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Chang", "L.", "", "DISP"], ["Ouzrout", "Yacine", "", "DISP"], ["Nongaillard", "Antoine", "", "DISP"], ["Bouras", "Abdelaziz", "", "DISP"]]}, {"id": "1811.03491", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane", "title": "Degree-$d$ Chow Parameters Robustly Determine Degree-$d$ PTFs (and\n  Algorithmic Applications)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The degree-$d$ Chow parameters of a Boolean function $f: \\{-1,1\\}^n \\to\n\\mathbb{R}$ are its degree at most $d$ Fourier coefficients. It is well-known\nthat degree-$d$ Chow parameters uniquely characterize degree-$d$ polynomial\nthreshold functions (PTFs) within the space of all bounded functions. In this\npaper, we prove a robust version of this theorem: For $f$ any Boolean\ndegree-$d$ PTF and $g$ any bounded function, if the degree-$d$ Chow parameters\nof $f$ are close to the degree-$d$ Chow parameters of $g$ in $\\ell_2$-norm,\nthen $f$ is close to $g$ in $\\ell_1$-distance. Notably, our bound relating the\ntwo distances is completely independent of the dimension $n$. That is, we show\nthat Boolean degree-$d$ PTFs are {\\em robustly identifiable} from their\ndegree-$d$ Chow parameters. Results of this form had been shown for the $d=1$\ncase~\\cite{OS11:chow, DeDFS14}, but no non-trivial bound was previously known\nfor $d >1$.\n  Our robust identifiability result gives the following algorithmic\napplications: First, we show that Boolean degree-$d$ PTFs can be efficiently\napproximately reconstructed from approximations to their degree-$d$ Chow\nparameters. This immediately implies that degree-$d$ PTFs are efficiently\nlearnable in the uniform distribution $d$-RFA\nmodel~\\cite{BenDavidDichterman:98}. As a byproduct of our approach, we also\nobtain the first low integer-weight approximations of degree-$d$ PTFs, for\n$d>1$. As our second application, our robust identifiability result gives the\nfirst efficient algorithm, with dimension-independent error guarantees, for\nmalicious learning of Boolean degree-$d$ PTFs under the uniform distribution.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 17:59:16 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""]]}, {"id": "1811.03508", "submitter": "Chen Cai", "authors": "Chen Cai, Yusu Wang", "title": "A simple yet effective baseline for non-attributed graph classification", "comments": "13 pages. Shorter version appears at 2019 ICLR Workshop:\n  Representation Learning on Graphs and Manifolds. arXiv admin note: text\n  overlap with arXiv:1810.00826 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graphs are complex objects that do not lend themselves easily to typical\nlearning tasks. Recently, a range of approaches based on graph kernels or graph\nneural networks have been developed for graph classification and for\nrepresentation learning on graphs in general. As the developed methodologies\nbecome more sophisticated, it is important to understand which components of\nthe increasingly complex methods are necessary or most effective.\n  As a first step, we develop a simple yet meaningful graph representation, and\nexplore its effectiveness in graph classification. We test our baseline\nrepresentation for the graph classification task on a range of graph datasets.\nInterestingly, this simple representation achieves similar performance as the\nstate-of-the-art graph kernels and graph neural networks for non-attributed\ngraph classification. Its performance on classifying attributed graphs is\nslightly weaker as it does not incorporate attributes. However, given its\nsimplicity and efficiency, we believe that it still serves as an effective\nbaseline for attributed graph classification. Our graph representation is\nefficient (linear-time) to compute. We also provide a simple connection with\nthe graph neural networks.\n  Note that these observations are only for the task of graph classification\nwhile existing methods are often designed for a broader scope including node\nembedding and link prediction. The results are also likely biased due to the\nlimited amount of benchmark datasets available. Nevertheless, the good\nperformance of our simple baseline calls for the development of new, more\ncomprehensive benchmark datasets so as to better evaluate and analyze different\ngraph learning methods. Furthermore, given the computational efficiency of our\ngraph summary, we believe that it is a good candidate as a baseline method for\nfuture graph classification (or even other graph learning) studies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 15:53:37 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 19:15:19 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Cai", "Chen", ""], ["Wang", "Yusu", ""]]}, {"id": "1811.03516", "submitter": "Feryal Behbahani", "authors": "Feryal Behbahani, Kyriacos Shiarlis, Xi Chen, Vitaly Kurin, Sudhanshu\n  Kasewa, Ciprian Stirbu, Jo\\~ao Gomes, Supratik Paul, Frans A. Oliehoek,\n  Jo\\~ao Messias, Shimon Whiteson", "title": "Learning from Demonstration in the Wild", "comments": "Accepted to the IEEE International Conference on Robotics and\n  Automation (ICRA) 2019; extended version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration (LfD) is useful in settings where hand-coding\nbehaviour or a reward function is impractical. It has succeeded in a wide range\nof problems but typically relies on manually generated demonstrations or\nspecially deployed sensors and has not generally been able to leverage the\ncopious demonstrations available in the wild: those that capture behaviours\nthat were occurring anyway using sensors that were already deployed for another\npurpose, e.g., traffic camera footage capturing demonstrations of natural\nbehaviour of vehicles, cyclists, and pedestrians. We propose Video to Behaviour\n(ViBe), a new approach to learn models of behaviour from unlabelled raw video\ndata of a traffic scene collected from a single, monocular, initially\nuncalibrated camera with ordinary resolution. Our approach calibrates the\ncamera, detects relevant objects, tracks them through time, and uses the\nresulting trajectories to perform LfD, yielding models of naturalistic\nbehaviour. We apply ViBe to raw videos of a traffic intersection and show that\nit can learn purely from videos, without additional expert knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:03:23 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 00:11:48 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Behbahani", "Feryal", ""], ["Shiarlis", "Kyriacos", ""], ["Chen", "Xi", ""], ["Kurin", "Vitaly", ""], ["Kasewa", "Sudhanshu", ""], ["Stirbu", "Ciprian", ""], ["Gomes", "Jo\u00e3o", ""], ["Paul", "Supratik", ""], ["Oliehoek", "Frans A.", ""], ["Messias", "Jo\u00e3o", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1811.03531", "submitter": "Zachary Charles", "authors": "Zachary Charles, Harrison Rosenberg, Dimitris Papailiopoulos", "title": "A Geometric Perspective on the Transferability of Adversarial Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art machine learning models frequently misclassify inputs that\nhave been perturbed in an adversarial manner. Adversarial perturbations\ngenerated for a given input and a specific classifier often seem to be\neffective on other inputs and even different classifiers. In other words,\nadversarial perturbations seem to transfer between different inputs, models,\nand even different neural network architectures. In this work, we show that in\nthe context of linear classifiers and two-layer ReLU networks, there provably\nexist directions that give rise to adversarial perturbations for many\nclassifiers and data points simultaneously. We show that these \"transferable\nadversarial directions\" are guaranteed to exist for linear separators of a\ngiven set, and will exist with high probability for linear classifiers trained\non independent sets drawn from the same distribution. We extend our results to\nlarge classes of two-layer ReLU networks. We further show that adversarial\ndirections for ReLU networks transfer to linear classifiers while the reverse\nneed not hold, suggesting that adversarial perturbations for more complex\nmodels are more likely to transfer to other classifiers. We validate our\nfindings empirically, even for deeper ReLU networks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:23:50 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Charles", "Zachary", ""], ["Rosenberg", "Harrison", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1811.03537", "submitter": "Adish Singla", "authors": "Teresa Yeo, Parameswaran Kamalaruban, Adish Singla, Arpit Merchant,\n  Thibault Asselborn, Louis Faucon, Pierre Dillenbourg, Volkan Cevher", "title": "Iterative Classroom Teaching", "comments": "AAAI'19 (extended version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the machine teaching problem in a classroom-like setting wherein\nthe teacher has to deliver the same examples to a diverse group of students.\nTheir diversity stems from differences in their initial internal states as well\nas their learning rates. We prove that a teacher with full knowledge about the\nlearning dynamics of the students can teach a target concept to the entire\nclassroom using O(min{d,N} log(1/eps)) examples, where d is the ambient\ndimension of the problem, N is the number of learners, and eps is the accuracy\nparameter. We show the robustness of our teaching strategy when the teacher has\nlimited knowledge of the learners' internal dynamics as provided by a noisy\noracle. Further, we study the trade-off between the learners' workload and the\nteacher's cost in teaching the target concept. Our experiments validate our\ntheoretical results and suggest that appropriately partitioning the classroom\ninto homogenous groups provides a balance between these two objectives.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:34:14 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 16:16:23 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Yeo", "Teresa", ""], ["Kamalaruban", "Parameswaran", ""], ["Singla", "Adish", ""], ["Merchant", "Arpit", ""], ["Asselborn", "Thibault", ""], ["Faucon", "Louis", ""], ["Dillenbourg", "Pierre", ""], ["Cevher", "Volkan", ""]]}, {"id": "1811.03539", "submitter": "Marcos Oliveira", "authors": "Marcos Oliveira, Diego Pinheiro, Mariana Macedo, Carmelo Bastos-Filho,\n  Ronaldo Menezes", "title": "Uncovering the Social Interaction in Swarm Intelligence with Network\n  Science", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.MA cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm intelligence is the collective behavior emerging in systems with\nlocally interacting components. Because of their self-organization\ncapabilities, swarm-based systems show essential properties for handling\nreal-world problems such as robustness, scalability, and flexibility. Yet, we\ndo not know why swarm-based algorithms work well and neither we can compare the\ndifferent approaches in the literature. The lack of a common framework capable\nof characterizing these several swarm-based algorithms, transcending their\nparticularities, has led to a stream of publications inspired by different\naspects of nature without a systematic comparison over existing approaches.\nHere, we address this gap by introducing a network-based framework---the\ninteraction network---to examine computational swarm-based systems via the\noptics of the social dynamics of such interaction network; a clear example of\nnetwork science being applied to bring further clarity to a complicated field\nwithin artificial intelligence. We discuss the social interactions of four\nwell-known swarm-based algorithms and provide an in-depth case study of the\nParticle Swarm Optimization. The interaction network enables researchers to\nstudy swarm algorithms as systems, removing the algorithm particularities from\nthe analyses while focusing on the structure of the social interactions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:36:11 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 10:27:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Oliveira", "Marcos", ""], ["Pinheiro", "Diego", ""], ["Macedo", "Mariana", ""], ["Bastos-Filho", "Carmelo", ""], ["Menezes", "Ronaldo", ""]]}, {"id": "1811.03562", "submitter": "Mizanur Rahman", "authors": "Mizanur Rahman, Mashrur Chowdhury and Jerome McClendon", "title": "Real time Traffic Flow Parameters Prediction with Basic Safety Messages\n  at Low Penetration of Connected Vehicles", "comments": "16 pages, 15 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expected low market penetration of connected vehicles (CVs) in the near\nfuture could be a constraint in estimating traffic flow parameters, such as\naverage travel speed of a roadway segment and average space headway between\nvehicles from the CV broadcasted data. This estimated traffic flow parameters\nfrom low penetration of connected vehicles become noisy compared to 100 percent\npenetration of CVs, and such noise reduces the real time prediction accuracy of\na machine learning model, such as the accuracy of long short term memory (LSTM)\nmodel in terms of predicting traffic flow parameters. The accurate prediction\nof the parameters is important for future traffic condition assessment. To\nimprove the prediction accuracy using noisy traffic flow parameters, which is\nconstrained by limited CV market penetration and limited CV data, we developed\na real time traffic data prediction model that combines LSTM with Kalman filter\nbased Rauch Tung Striebel (RTS) noise reduction model. We conducted a case\nstudy using the Enhanced Next Generation Simulation (NGSIM) dataset, which\ncontains vehicle trajectory data for every one tenth of a second, to evaluate\nthe performance of this prediction model. Compared to a baseline LSTM model\nperformance, for only 5 percent penetration of CVs, the analyses revealed that\ncombined LSTM and RTS model reduced the mean absolute percentage error (MAPE)\nfrom 19 percent to 5 percent for speed prediction and from 27 percent to 9\npercent for space-headway prediction. The statistical significance test with a\n95 percent confidence interval confirmed no significant difference in predicted\naverage speed and average space headway using this LSTM and RTS combination\nwith only 5 percent CV penetration rate.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:34:14 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 15:25:34 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Rahman", "Mizanur", ""], ["Chowdhury", "Mashrur", ""], ["McClendon", "Jerome", ""]]}, {"id": "1811.03567", "submitter": "Honglin Chen", "authors": "Will Xiao, Honglin Chen, Qianli Liao and Tomaso Poggio", "title": "Biologically-plausible learning algorithms can scale to large datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation (BP) algorithm is often thought to be biologically\nimplausible in the brain. One of the main reasons is that BP requires symmetric\nweight matrices in the feedforward and feedback pathways. To address this\n\"weight transport problem\" (Grossberg, 1987), two more biologically plausible\nalgorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax\nBP's weight symmetry requirements and demonstrate comparable learning\ncapabilities to that of BP on small datasets. However, a recent study by\nBartunov et al. (2018) evaluate variants of target-propagation (TP) and\nfeedback alignment (FA) on MINIST, CIFAR, and ImageNet datasets, and find that\nalthough many of the proposed algorithms perform well on MNIST and CIFAR, they\nperform significantly worse than BP on ImageNet. Here, we additionally evaluate\nthe sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and\nFA in that the feedback and feedforward weights share signs but not magnitudes.\nWe examine the performance of sign-symmetry and feedback alignment on ImageNet\nand MS COCO datasets using different network architectures (ResNet-18 and\nAlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained\nwith sign-symmetry can attain classification performance approaching that of\nBP-trained networks. These results complement the study by Bartunov et al.\n(2018), and establish a new benchmark for future biologically plausible\nlearning algorithms on more difficult datasets and more complex architectures.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:43:59 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 21:23:57 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 02:03:52 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Xiao", "Will", ""], ["Chen", "Honglin", ""], ["Liao", "Qianli", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1811.03568", "submitter": "Zhenyu Liao", "authors": "Yacine Chitour, Zhenyu Liao, Romain Couillet", "title": "A Geometric Approach of Gradient Descent Algorithms in Neural Networks", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an original geometric framework to analyze the\nconvergence properties of gradient descent trajectories in the context of\nlinear neural networks. Built upon a key invariance property induced by the\nnetwork structure, we propose a conjecture called \\emph{overfitting conjecture}\nstating that, for almost every training data, the corresponding gradient\ndescent trajectory converges to a global minimum, for almost every initial\ncondition. This would imply that, for linear neural networks of an arbitrary\nnumber of hidden layers, the solution achieved by simple gradient descent\nalgorithm is equivalent to that of least square estimation. Our first result\nconsists in establishing, in the case of linear networks of arbitrary depth,\nconvergence of gradient descent trajectories to critical points of the loss\nfunction. Our second result is the proof of the \\emph{overfitting conjecture}\nin the case of single-hidden-layer linear networks with an argument based on\nthe notion of normal hyperbolicity and under a generic property on the training\ndata (i.e., holding for almost every training data).\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:45:19 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 17:05:02 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Chitour", "Yacine", ""], ["Liao", "Zhenyu", ""], ["Couillet", "Romain", ""]]}, {"id": "1811.03571", "submitter": "Luca Bortolussi", "authors": "Luca Bortolussi and Guido Sanguinetti", "title": "Intrinsic Geometric Vulnerability of High-Dimensional Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of modern Artificial Intelligence (AI) technologies depends\ncritically on the ability to learn non-linear functional dependencies from\nlarge, high dimensional data sets. Despite recent high-profile successes,\nempirical evidence indicates that the high predictive performance is often\npaired with low robustness, making AI systems potentially vulnerable to\nadversarial attacks. In this report, we provide a simple intuitive argument\nsuggesting that high performance and vulnerability are intrinsically coupled,\nand largely dependent on the geometry of typical, high-dimensional data sets.\nOur work highlights a major potential pitfall of modern AI systems, and\nsuggests practical research directions to ameliorate the problem.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:51:27 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 14:13:58 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Bortolussi", "Luca", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "1811.03575", "submitter": "Kashyap Chitta", "authors": "Kashyap Chitta, Jose M. Alvarez, Adam Lesnikowski", "title": "Large-Scale Visual Active Learning with Deep Probabilistic Ensembles", "comments": "arXiv admin note: text overlap with arXiv:1811.02640", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating the right data for training deep neural networks is an important\nchallenge. Active learning using uncertainty estimates from Bayesian Neural\nNetworks (BNNs) could provide an effective solution to this. Despite being\ntheoretically principled, BNNs require approximations to be applied to\nlarge-scale problems, where both performance and uncertainty estimation are\ncrucial. In this paper, we introduce Deep Probabilistic Ensembles (DPEs), a\nscalable technique that uses a regularized ensemble to approximate a deep BNN.\nWe conduct a series of large-scale visual active learning experiments to\nevaluate DPEs on classification with the CIFAR-10, CIFAR-100 and ImageNet\ndatasets, and semantic segmentation with the BDD100k dataset. Our models\nrequire significantly less training data to achieve competitive performances,\nand steadily improve upon strong active learning baselines as the annotation\nbudget is increased.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:56:43 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 21:45:26 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 02:02:13 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Chitta", "Kashyap", ""], ["Alvarez", "Jose M.", ""], ["Lesnikowski", "Adam", ""]]}, {"id": "1811.03600", "submitter": "Christopher Shallue", "authors": "Christopher J. Shallue and Jaehoon Lee and Joseph Antognini and Jascha\n  Sohl-Dickstein and Roy Frostig and George E. Dahl", "title": "Measuring the Effects of Data Parallelism on Neural Network Training", "comments": null, "journal-ref": "Journal of Machine Learning Research 20 (2019) 1-49", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent hardware developments have dramatically increased the scale of data\nparallelism available for neural network training. Among the simplest ways to\nharness next-generation hardware is to increase the batch size in standard\nmini-batch neural network training algorithms. In this work, we aim to\nexperimentally characterize the effects of increasing the batch size on\ntraining time, as measured by the number of steps necessary to reach a goal\nout-of-sample error. We study how this relationship varies with the training\nalgorithm, model, and data set, and find extremely large variation between\nworkloads. Along the way, we show that disagreements in the literature on how\nbatch size affects model quality can largely be explained by differences in\nmetaparameter tuning and compute budgets at different batch sizes. We find no\nevidence that larger batch sizes degrade out-of-sample performance. Finally, we\ndiscuss the implications of our results on efforts to train neural networks\nmuch faster in the future. Our experimental data is publicly available as a\ndatabase of 71,638,836 loss measurements taken over the course of training for\n168,160 individual models across 35 workloads.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 18:33:41 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 00:16:26 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 00:47:44 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Shallue", "Christopher J.", ""], ["Lee", "Jaehoon", ""], ["Antognini", "Joseph", ""], ["Sohl-Dickstein", "Jascha", ""], ["Frostig", "Roy", ""], ["Dahl", "George E.", ""]]}, {"id": "1811.03601", "submitter": "Jack Langerman", "authors": "Ziming Qiu, Jack Langerman, Nitin Nair, Orlando Aristizabal, Jonathan\n  Mamou, Daniel H. Turnbull, Jeffrey Ketterling, Yao Wang", "title": "Deep BV: A Fully Automated System for Brain Ventricle Localization and\n  Segmentation in 3D Ultrasound Images of Embryonic Mice", "comments": "IEEE Signal Processing in Medicine and Biology Symposium - 2018, 6\n  pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volumetric analysis of brain ventricle (BV) structure is a key tool in the\nstudy of central nervous system development in embryonic mice. High-frequency\nultrasound (HFU) is the only non-invasive, real-time modality available for\nrapid volumetric imaging of embryos in utero. However, manual segmentation of\nthe BV from HFU volumes is tedious, time-consuming, and requires specialized\nexpertise. In this paper, we propose a novel deep learning based BV\nsegmentation system for whole-body HFU images of mouse embryos. Our fully\nautomated system consists of two modules: localization and segmentation. It\nfirst applies a volumetric convolutional neural network on a 3D sliding window\nover the entire volume to identify a 3D bounding box containing the entire BV.\nIt then employs a fully convolutional network to segment the detected bounding\nbox into BV and background. The system achieves a Dice Similarity Coefficient\n(DSC) of 0.8956 for BV segmentation on an unseen 111 HFU volume test set\nsurpassing the previous state-of-the-art method (DSC of 0.7119) by a margin of\n25%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 20:07:53 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Qiu", "Ziming", ""], ["Langerman", "Jack", ""], ["Nair", "Nitin", ""], ["Aristizabal", "Orlando", ""], ["Mamou", "Jonathan", ""], ["Turnbull", "Daniel H.", ""], ["Ketterling", "Jeffrey", ""], ["Wang", "Yao", ""]]}, {"id": "1811.03617", "submitter": "Youjie Li", "authors": "Mingchao Yu, Zhifeng Lin, Krishna Narra, Songze Li, Youjie Li, Nam\n  Sung Kim, Alexander Schwing, Murali Annavaram, Salman Avestimehr", "title": "GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient\n  Aggregation in Distributed CNN Training", "comments": "Accepted at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallelism can boost the training speed of convolutional neural\nnetworks (CNN), but could suffer from significant communication costs caused by\ngradient aggregation. To alleviate this problem, several scalar quantization\ntechniques have been developed to compress the gradients. But these techniques\ncould perform poorly when used together with decentralized aggregation\nprotocols like ring all-reduce (RAR), mainly due to their inability to directly\naggregate compressed gradients. In this paper, we empirically demonstrate the\nstrong linear correlations between CNN gradients, and propose a gradient vector\nquantization technique, named GradiVeQ, to exploit these correlations through\nprincipal component analysis (PCA) for substantial gradient dimension\nreduction. GradiVeQ enables direct aggregation of compressed gradients, hence\nallows us to build a distributed learning system that parallelizes GradiVeQ\ngradient compression and RAR communications. Extensive experiments on popular\nCNNs demonstrate that applying GradiVeQ slashes the wall-clock gradient\naggregation time of the original RAR by more than 5X without noticeable\naccuracy loss, and reduces the end-to-end training time by almost 50%. The\nresults also show that GradiVeQ is compatible with scalar quantization\ntechniques such as QSGD (Quantized SGD), and achieves a much higher speed-up\ngain under the same compression ratio.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 18:59:50 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 06:01:28 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Yu", "Mingchao", ""], ["Lin", "Zhifeng", ""], ["Narra", "Krishna", ""], ["Li", "Songze", ""], ["Li", "Youjie", ""], ["Kim", "Nam Sung", ""], ["Schwing", "Alexander", ""], ["Annavaram", "Murali", ""], ["Avestimehr", "Salman", ""]]}, {"id": "1811.03619", "submitter": "Youjie Li", "authors": "Youjie Li, Mingchao Yu, Songze Li, Salman Avestimehr, Nam Sung Kim,\n  Alexander Schwing", "title": "Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep\n  Net Training", "comments": "Accepted at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training of deep nets is an important technique to address some\nof the present day computing challenges like memory consumption and\ncomputational demands. Classical distributed approaches, synchronous or\nasynchronous, are based on the parameter server architecture, i.e., worker\nnodes compute gradients which are communicated to the parameter server while\nupdated parameters are returned. Recently, distributed training with AllReduce\noperations gained popularity as well. While many of those operations seem\nappealing, little is reported about wall-clock training time improvements. In\nthis paper, we carefully analyze the AllReduce based setup, propose timing\nmodels which include network latency, bandwidth, cluster size and compute time,\nand demonstrate that a pipelined training with a width of two combines the best\nof both synchronous and asynchronous training. Specifically, for a setup\nconsisting of a four-node GPU cluster we show wall-clock time training\nimprovements of up to 5.4x compared to conventional approaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 18:59:55 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 04:54:32 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2019 08:38:49 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Li", "Youjie", ""], ["Yu", "Mingchao", ""], ["Li", "Songze", ""], ["Avestimehr", "Salman", ""], ["Kim", "Nam Sung", ""], ["Schwing", "Alexander", ""]]}, {"id": "1811.03621", "submitter": "Hang Qiu", "authors": "Hang Qiu, Krishna Chintalapudi, Ramesh Govindan", "title": "Satyam: Democratizing Groundtruth for Machine Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The democratization of machine learning (ML) has led to ML-based machine\nvision systems for autonomous driving, traffic monitoring, and video\nsurveillance. However, true democratization cannot be achieved without greatly\nsimplifying the process of collecting groundtruth for training and testing\nthese systems. This groundtruth collection is necessary to ensure good\nperformance under varying conditions. In this paper, we present the design and\nevaluation of Satyam, a first-of-its-kind system that enables a layperson to\nlaunch groundtruth collection tasks for machine vision with minimal effort.\nSatyam leverages a crowdtasking platform, Amazon Mechanical Turk, and automates\nseveral challenging aspects of groundtruth collection: creating and launching\nof custom web-UI tasks for obtaining the desired groundtruth, controlling\nresult quality in the face of spammers and untrained workers, adapting prices\nto match task complexity, filtering spammers and workers with poor performance,\nand processing worker payments. We validate Satyam using several popular\nbenchmark vision datasets, and demonstrate that groundtruth obtained by Satyam\nis comparable to that obtained from trained experts and provides matching ML\nperformance when used for training.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 01:35:47 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Qiu", "Hang", ""], ["Chintalapudi", "Krishna", ""], ["Govindan", "Ramesh", ""]]}, {"id": "1811.03666", "submitter": "Daeyoung Choi", "authors": "Daeyoung Choi, Kyungeun Lee, Duhun Hwang, Wonjong Rhee", "title": "Statistical Characteristics of Deep Representations: An Empirical\n  Investigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, the effects of eight representation regularization methods are\ninvestigated, including two newly developed rank regularizers (RR). The\ninvestigation shows that the statistical characteristics of representations\nsuch as correlation, sparsity, and rank can be manipulated as intended, during\ntraining. Furthermore, it is possible to improve the baseline performance\nsimply by trying all the representation regularizers and fine-tuning the\nstrength of their effects. In contrast to performance improvement, no\nconsistent relationship between performance and statistical characteristics was\nobservable. The results indicate that manipulation of statistical\ncharacteristics can be helpful for improving performance, but only indirectly\nthrough its influence on learning dynamics or its tuning effects.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 20:17:50 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 11:39:32 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Choi", "Daeyoung", ""], ["Lee", "Kyungeun", ""], ["Hwang", "Duhun", ""], ["Rhee", "Wonjong", ""]]}, {"id": "1811.03679", "submitter": "Samuel Kessler", "authors": "Samuel Kessler, Arnold Salas, Vincent W. C. Tan, Stefan Zohren,\n  Stephen Roberts", "title": "Practical Bayesian Learning of Neural Networks via Adaptive Optimisation\n  Methods", "comments": "Presented at the ICML 2020 Workshop on Uncertainty and Robustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework for the estimation of the posterior\ndistribution over the weights of a neural network, based on a new probabilistic\ninterpretation of adaptive optimisation algorithms such as AdaGrad and Adam. We\ndemonstrate the effectiveness of our Bayesian Adam method, Badam, by\nexperimentally showing that the learnt uncertainties correctly relate to the\nweights' predictive capabilities by weight pruning. We also demonstrate the\nquality of the derived uncertainty measures by comparing the performance of\nBadam to standard methods in a Thompson sampling setting for multi-armed\nbandits, where good uncertainty measures are required for an agent to balance\nexploration and exploitation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 21:04:00 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 13:05:01 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 16:47:37 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Kessler", "Samuel", ""], ["Salas", "Arnold", ""], ["Tan", "Vincent W. C.", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "1811.03700", "submitter": "Chao Weng", "authors": "Chao Weng, Dong Yu", "title": "A Comparison of Lattice-free Discriminative Training Criteria for Purely\n  Sequence-Trained Neural Network Acoustic Models", "comments": "under review ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, three lattice-free (LF) discriminative training criteria for\npurely sequence-trained neural network acoustic models are compared on LVCSR\ntasks, namely maximum mutual information (MMI), boosted maximum mutual\ninformation (bMMI) and state-level minimum Bayes risk (sMBR). We demonstrate\nthat, analogous to LF-MMI, a neural network acoustic model can also be trained\nfrom scratch using LF-bMMI or LF-sMBR criteria respectively without the need of\ncross-entropy pre-training. Furthermore, experimental results on\nSwitchboard-300hrs and Switchboard+Fisher-2100hrs datasets show that models\ntrained with LF-bMMI consistently outperform those trained with plain LF-MMI\nand achieve a relative word error rate (WER) reduction of 5% over competitive\ntemporal convolution projected LSTM (TDNN-LSTMP) LF-MMI baselines.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 22:37:55 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 10:55:10 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Weng", "Chao", ""], ["Yu", "Dong", ""]]}, {"id": "1811.03711", "submitter": "Yuanyuan Liu", "authors": "Qiang Zhang, Rui Luo, Yaodong Yang, Yuanyuan Liu", "title": "Benchmarking Deep Sequential Models on Volatility Predictions for\n  Financial Time Series", "comments": "NIPS 2018, Workshop on Challenges and Opportunities for AI in\n  Financial Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volatility is a quantity of measurement for the price movements of stocks or\noptions which indicates the uncertainty within financial markets. As an\nindicator of the level of risk or the degree of variation, volatility is\nimportant to analyse the financial market, and it is taken into consideration\nin various decision-making processes in financial activities. On the other\nhand, recent advancement in deep learning techniques has shown strong\ncapabilities in modelling sequential data, such as speech and natural language.\nIn this paper, we empirically study the applicability of the latest deep\nstructures with respect to the volatility modelling problem, through which we\naim to provide an empirical guidance for the theoretical analysis of the\nmarriage between deep learning techniques and financial applications in the\nfuture. We examine both the traditional approaches and the deep sequential\nmodels on the task of volatility prediction, including the most recent variants\nof convolutional and recurrent networks, such as the dilated architecture.\nAccordingly, experiments with real-world stock price datasets are performed on\na set of 1314 daily stock series for 2018 days of transaction. The evaluation\nand comparison are based on the negative log likelihood (NLL) of real-world\nstock price time series. The result shows that the dilated neural models,\nincluding dilated CNN and Dilated RNN, produce most accurate estimation and\nprediction, outperforming various widely-used deterministic models in the GARCH\nfamily and several recently proposed stochastic models. In addition, the high\nflexibility and rich expressive power are validated in this study.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 23:11:38 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Zhang", "Qiang", ""], ["Luo", "Rui", ""], ["Yang", "Yaodong", ""], ["Liu", "Yuanyuan", ""]]}, {"id": "1811.03717", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski", "title": "Fast determinantal point processes via distortion-free intermediate\n  sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a fixed $n\\times d$ matrix $\\mathbf{X}$, where $n\\gg d$, we study the\ncomplexity of sampling from a distribution over all subsets of rows where the\nprobability of a subset is proportional to the squared volume of the\nparallelepiped spanned by the rows (a.k.a. a determinantal point process). In\nthis task, it is important to minimize the preprocessing cost of the procedure\n(performed once) as well as the sampling cost (performed repeatedly). To that\nend, we propose a new determinantal point process algorithm which has the\nfollowing two properties, both of which are novel: (1) a preprocessing step\nwhich runs in time $O(\\text{number-of-non-zeros}(\\mathbf{X})\\cdot\\log\nn)+\\text{poly}(d)$, and (2) a sampling step which runs in $\\text{poly}(d)$\ntime, independent of the number of rows $n$. We achieve this by introducing a\nnew regularized determinantal point process (R-DPP), which serves as an\nintermediate distribution in the sampling procedure by reducing the number of\nrows from $n$ to $\\text{poly}(d)$. Crucially, this intermediate distribution\ndoes not distort the probabilities of the target sample. Our key novelty in\ndefining the R-DPP is the use of a Poisson random variable for controlling the\nprobabilities of different subset sizes, leading to new determinantal formulas\nsuch as the normalization constant for this distribution. Our algorithm has\napplications in many diverse areas where determinantal point processes have\nbeen used, such as machine learning, stochastic optimization, data\nsummarization and low-rank matrix reconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 23:35:29 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 20:59:29 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""]]}, {"id": "1811.03728", "submitter": "Bryant Chen", "authors": "Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig,\n  Benjamin Edwards, Taesung Lee, Ian Molloy, and Biplav Srivastava", "title": "Detecting Backdoor Attacks on Deep Neural Networks by Activation\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning (ML) models are being increasingly trusted to make\ndecisions in different and varying areas, the safety of systems using such\nmodels has become an increasing concern. In particular, ML models are often\ntrained on data from potentially untrustworthy sources, providing adversaries\nwith the opportunity to manipulate them by inserting carefully crafted samples\ninto the training set. Recent work has shown that this type of attack, called a\npoisoning attack, allows adversaries to insert backdoors or trojans into the\nmodel, enabling malicious behavior with simple external backdoor triggers at\ninference time and only a blackbox perspective of the model itself. Detecting\nthis type of attack is challenging because the unexpected behavior occurs only\nwhen a backdoor trigger, which is known only to the adversary, is present.\nModel users, either direct users of training data or users of pre-trained model\nfrom a catalog, may not guarantee the safe operation of their ML-based system.\nIn this paper, we propose a novel approach to backdoor detection and removal\nfor neural networks. Through extensive experimental results, we demonstrate its\neffectiveness for neural networks classifying text and images. To the best of\nour knowledge, this is the first methodology capable of detecting poisonous\ndata crafted to insert backdoors and repairing the model that does not require\na verified and trusted dataset.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 01:08:00 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Chen", "Bryant", ""], ["Carvalho", "Wilka", ""], ["Baracaldo", "Nathalie", ""], ["Ludwig", "Heiko", ""], ["Edwards", "Benjamin", ""], ["Lee", "Taesung", ""], ["Molloy", "Ian", ""], ["Srivastava", "Biplav", ""]]}, {"id": "1811.03733", "submitter": "Bhavya Kailkhura", "authors": "Thomas A. Hogan and Bhavya Kailkhura", "title": "Universal Decision-Based Black-Box Perturbations: Breaking\n  Security-Through-Obscurity Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding a universal (image-agnostic) perturbation to\nfool machine learning (ML) classifiers (e.g., neural nets, decision tress) in\nthe hard-label black-box setting. Recent work in adversarial ML in the\nwhite-box setting (model parameters are known) has shown that many\nstate-of-the-art image classifiers are vulnerable to universal adversarial\nperturbations: a fixed human-imperceptible perturbation that, when added to any\nimage, causes it to be misclassified with high probability Kurakin et al.\n[2016], Szegedy et al. [2013], Chen et al. [2017a], Carlini and Wagner [2017].\nThis paper considers a more practical and challenging problem of finding such\nuniversal perturbations in an obscure (or black-box) setting. More\nspecifically, we use zeroth order optimization algorithms to find such a\nuniversal adversarial perturbation when no model information is revealed-except\nthat the attacker can make queries to probe the classifier. We further relax\nthe assumption that the output of a query is continuous valued confidence\nscores for all the classes and consider the case where the output is a\nhard-label decision. Surprisingly, we found that even in these extremely\nobscure regimes, state-of-the-art ML classifiers can be fooled with a very high\nprobability just by adding a single human-imperceptible image perturbation to\nany natural image. The surprising existence of universal perturbations in a\nhard-label black-box setting raises serious security concerns with the\nexistence of a universal noise vector that adversaries can possibly exploit to\nbreak a classifier on most natural images.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 01:43:22 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:56:52 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hogan", "Thomas A.", ""], ["Kailkhura", "Bhavya", ""]]}, {"id": "1811.03739", "submitter": "Sihong Xie", "authors": "Shuaijun Ge and Guixiang Ma and Sihong Xie and Philip S. Yu", "title": "Securing Behavior-based Opinion Spam Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reviews spams are prevalent in e-commerce to manipulate product ranking and\ncustomers decisions maliciously. While spams generated based on simple spamming\nstrategy can be detected effectively, hardened spammers can evade regular\ndetectors via more advanced spamming strategies. Previous work gave more\nattention to evasion against text and graph-based detectors, but evasions\nagainst behavior-based detectors are largely ignored, leading to\nvulnerabilities in spam detection systems. Since real evasion data are scarce,\nwe first propose EMERAL (Evasion via Maximum Entropy and Rating sAmpLing) to\ngenerate evasive spams to certain existing detectors. EMERAL can simulate\nspammers with different goals and levels of knowledge about the detectors,\ntargeting at different stages of the life cycle of target products. We show\nthat in the evasion-defense dynamic, only a few evasion types are meaningful to\nthe spammers, and any spammer will not be able to evade too many detection\nsignals at the same time. We reveal that some evasions are quite insidious and\ncan fail all detection signals. We then propose DETER (Defense via Evasion\ngeneraTion using EmeRal), based on model re-training on diverse evasive samples\ngenerated by EMERAL. Experiments confirm that DETER is more accurate in\ndetecting both suspicious time window and individual spamming reviews. In terms\nof security, DETER is versatile enough to be vaccinated against diverse and\nunexpected evasions, is agnostic about evasion strategy and can be released\nwithout privacy concern.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 02:09:31 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Ge", "Shuaijun", ""], ["Ma", "Guixiang", ""], ["Xie", "Sihong", ""], ["Yu", "Philip S.", ""]]}, {"id": "1811.03744", "submitter": "Anindya De", "authors": "Anindya De, Philip M. Long and Rocco A. Servedio", "title": "Density estimation for shift-invariant multidimensional distributions", "comments": "Appears in the Proceedings of ITCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study density estimation for classes of shift-invariant distributions over\n$\\mathbb{R}^d$. A multidimensional distribution is \"shift-invariant\" if,\nroughly speaking, it is close in total variation distance to a small shift of\nit in any direction. Shift-invariance relaxes smoothness assumptions commonly\nused in non-parametric density estimation to allow jump discontinuities. The\ndifferent classes of distributions that we consider correspond to different\nrates of tail decay.\n  For each such class we give an efficient algorithm that learns any\ndistribution in the class from independent samples with respect to total\nvariation distance. As a special case of our general result, we show that\n$d$-dimensional shift-invariant distributions which satisfy an exponential tail\nbound can be learned to total variation distance error $\\epsilon$ using\n$\\tilde{O}_d(1/ \\epsilon^{d+2})$ examples and $\\tilde{O}_d(1/ \\epsilon^{2d+2})$\ntime. This implies that, for constant $d$, multivariate log-concave\ndistributions can be learned in $\\tilde{O}_d(1/\\epsilon^{2d+2})$ time using\n$\\tilde{O}_d(1/\\epsilon^{d+2})$ samples, answering a question of [Diakonikolas,\nKane and Stewart, 2016] All of our results extend to a model of noise-tolerant\ndensity estimation using Huber's contamination model, in which the target\ndistribution to be learned is a $(1-\\epsilon,\\epsilon)$ mixture of some unknown\ndistribution in the class with some other arbitrary and unknown distribution,\nand the learning algorithm must output a hypothesis distribution with total\nvariation distance error $O(\\epsilon)$ from the target distribution. We show\nthat our general results are close to best possible by proving a simple\n$\\Omega\\left(1/\\epsilon^d\\right)$ information-theoretic lower bound on sample\ncomplexity even for learning bounded distributions that are shift-invariant.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 02:29:43 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["De", "Anindya", ""], ["Long", "Philip M.", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1811.03751", "submitter": "Sailik Sengupta", "authors": "Niharika Jain, Lydia Manikonda, Alberto Olmo Hernandez, Sailik\n  Sengupta and Subbarao Kambhampati", "title": "Imagining an Engineer: On GAN-Based Data Augmentation Perpetuating\n  Biases", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of synthetic data generated by Generative Adversarial Networks (GANs)\nhas become quite a popular method to do data augmentation for many\napplications. While practitioners celebrate this as an economical way to get\nmore synthetic data that can be used to train downstream classifiers, it is not\nclear that they recognize the inherent pitfalls of this technique. In this\npaper, we aim to exhort practitioners against deriving any false sense of\nsecurity against data biases based on data augmentation. To drive this point\nhome, we show that starting with a dataset consisting of head-shots of\nengineering researchers, GAN-based augmentation \"imagines\" synthetic engineers,\nmost of whom have masculine features and white skin color (inferred from a\nhuman subject study conducted on Amazon Mechanical Turk). This demonstrates how\nbiases inherent in the training data are reinforced, and sometimes even\namplified, by GAN-based data augmentation; it should serve as a cautionary tale\nfor the lay practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 03:02:35 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Jain", "Niharika", ""], ["Manikonda", "Lydia", ""], ["Hernandez", "Alberto Olmo", ""], ["Sengupta", "Sailik", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1811.03760", "submitter": "Youru Li", "authors": "Youru Li, Zhenfeng Zhu, Deqiang Kong, Hua Han, Yao Zhao", "title": "EA-LSTM: Evolutionary Attention-based LSTM for Time Series Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series prediction with deep learning methods, especially long short-term\nmemory neural networks (LSTMs), have scored significant achievements in recent\nyears. Despite the fact that the LSTMs can help to capture long-term\ndependencies, its ability to pay different degree of attention on sub-window\nfeature within multiple time-steps is insufficient. To address this issue, an\nevolutionary attention-based LSTM training with competitive random search is\nproposed for multivariate time series prediction. By transferring shared\nparameters, an evolutionary attention learning approach is introduced to the\nLSTMs model. Thus, like that for biological evolution, the pattern for\nimportance-based attention sampling can be confirmed during temporal\nrelationship mining. To refrain from being trapped into partial optimization\nlike traditional gradient-based methods, an evolutionary computation inspired\ncompetitive random search method is proposed, which can well configure the\nparameters in the attention layer. Experimental results have illustrated that\nthe proposed model can achieve competetive prediction performance compared with\nother baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 03:42:36 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Li", "Youru", ""], ["Zhu", "Zhenfeng", ""], ["Kong", "Deqiang", ""], ["Han", "Hua", ""], ["Zhao", "Yao", ""]]}, {"id": "1811.03790", "submitter": "Tomi Kinnunen", "authors": "Tomi Kinnunen and Rosa Gonz\\'alez Hautam\\\"aki and Ville Vestman and Md\n  Sahidullah", "title": "Can We Use Speaker Recognition Technology to Attack Itself? Enhancing\n  Mimicry Attacks Using Automatic Target Speaker Selection", "comments": "(A slightly shorter version) has been submitted to IEEE ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider technology-assisted mimicry attacks in the context of automatic\nspeaker verification (ASV). We use ASV itself to select targeted speakers to be\nattacked by human-based mimicry. We recorded 6 naive mimics for whom we select\ntarget celebrities from VoxCeleb1 and VoxCeleb2 corpora (7,365 potential\ntargets) using an i-vector system. The attacker attempts to mimic the selected\ntarget, with the utterances subjected to ASV tests using an independently\ndeveloped x-vector system. Our main finding is negative: even if some of the\nattacker scores against the target speakers were slightly increased, our mimics\ndid not succeed in spoofing the x-vector system. Interestingly, however, the\nrelative ordering of the selected targets (closest, furthest, median) are\nconsistent between the systems, which suggests some level of transferability\nbetween the systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 06:15:08 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Kinnunen", "Tomi", ""], ["Hautam\u00e4ki", "Rosa Gonz\u00e1lez", ""], ["Vestman", "Ville", ""], ["Sahidullah", "Md", ""]]}, {"id": "1811.03804", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Haochuan Li, Liwei Wang, Xiyu Zhai", "title": "Gradient Descent Finds Global Minima of Deep Neural Networks", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent finds a global minimum in training deep neural networks\ndespite the objective function being non-convex. The current paper proves\ngradient descent achieves zero training loss in polynomial time for a deep\nover-parameterized neural network with residual connections (ResNet). Our\nanalysis relies on the particular structure of the Gram matrix induced by the\nneural network architecture. This structure allows us to show the Gram matrix\nis stable throughout the training process and this stability implies the global\noptimality of the gradient descent algorithm. We further extend our analysis to\ndeep residual convolutional neural networks and obtain a similar convergence\nresult.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 07:39:59 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 05:31:53 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 03:35:26 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 19:01:22 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Li", "Haochuan", ""], ["Wang", "Liwei", ""], ["Zhai", "Xiyu", ""]]}, {"id": "1811.03821", "submitter": "Mingxiao An", "authors": "Mingxiao An, Yongzhou Chen, Qi Liu, Chuanren Liu, Guangyi Lv, Fangzhao\n  Wu, Jianhui Ma", "title": "Skeptical Deep Learning with Distribution Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep neural networks have been successfully used for various\nclassification tasks, especially for problems with massive perfectly labeled\ntraining data. However, it is often costly to have large-scale credible labels\nin real-world applications. One solution is to make supervised learning robust\nwith imperfectly labeled input. In this paper, we develop a distribution\ncorrection approach that allows deep neural networks to avoid overfitting\nimperfect training data. Specifically, we treat the noisy input as samples from\nan incorrect distribution, which will be automatically corrected during our\ntraining process. We test our approach on several classification datasets with\nelaborately generated noisy labels. The results show significantly higher\nprediction and recovery accuracy with our approach compared to alternative\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 09:07:06 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 08:25:23 GMT"}, {"version": "v3", "created": "Sun, 13 Jan 2019 06:08:55 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["An", "Mingxiao", ""], ["Chen", "Yongzhou", ""], ["Liu", "Qi", ""], ["Liu", "Chuanren", ""], ["Lv", "Guangyi", ""], ["Wu", "Fangzhao", ""], ["Ma", "Jianhui", ""]]}, {"id": "1811.03850", "submitter": "Erwan Le Merrer", "authors": "Corentin Hardy, Erwan Le Merrer, Bruno Sericola", "title": "MD-GAN: Multi-Discriminator Generative Adversarial Networks for\n  Distributed Datasets", "comments": "To be published in IPDPS 2019: the 33rd IEEE International Parallel &\n  Distributed Processing Symposium", "journal-ref": "IEEE International Parallel and Distributed Processing Symposium\n  (IPDPS) 2019", "doi": "10.1109/IPDPS.2019.00095", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent technical breakthrough in the domain of machine learning is the\ndiscovery and the multiple applications of Generative Adversarial Networks\n(GANs). Those generative models are computationally demanding, as a GAN is\ncomposed of two deep neural networks, and because it trains on large datasets.\nA GAN is generally trained on a single server.\n  In this paper, we address the problem of distributing GANs so that they are\nable to train over datasets that are spread on multiple workers. MD-GAN is\nexposed as the first solution for this problem: we propose a novel learning\nprocedure for GANs so that they fit this distributed setup. We then compare the\nperformance of MD-GAN to an adapted version of Federated Learning to GANs,\nusing the MNIST and CIFAR10 datasets. MD-GAN exhibits a reduction by a factor\nof two of the learning complexity on each worker node, while providing better\nperformances than federated learning on both datasets. We finally discuss the\npractical implications of distributing GANs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 10:24:35 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 15:41:49 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hardy", "Corentin", ""], ["Merrer", "Erwan Le", ""], ["Sericola", "Bruno", ""]]}, {"id": "1811.03862", "submitter": "David Gaudrie", "authors": "David Gaudrie, Rodolphe Le Riche, Victor Picheny, Benoit Enaux,\n  Vincent Herbert", "title": "Targeting Solutions in Bayesian Multi-Objective Optimization: Sequential\n  and Batch Versions", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence volume 88, pages\n  187-212(2020)", "doi": "10.1007/s10472-019-09644-8", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective optimization aims at finding trade-off solutions to\nconflicting objectives. These constitute the Pareto optimal set. In the context\nof expensive-to-evaluate functions, it is impossible and often non-informative\nto look for the entire set. As an end-user would typically prefer a certain\npart of the objective space, we modify the Bayesian multi-objective\noptimization algorithm which uses Gaussian Processes to maximize the Expected\nHypervolume Improvement, to focus the search in the preferred region. The\ncumulated effects of the Gaussian Processes and the targeting strategy lead to\na particularly efficient convergence to the desired part of the Pareto set. To\ntake advantage of parallel computing, a multi-point extension of the targeting\ncriterion is proposed and analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 11:03:54 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 09:00:00 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 14:14:34 GMT"}, {"version": "v4", "created": "Thu, 29 Aug 2019 14:04:02 GMT"}, {"version": "v5", "created": "Wed, 19 Feb 2020 08:02:44 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Gaudrie", "David", ""], ["Riche", "Rodolphe Le", ""], ["Picheny", "Victor", ""], ["Enaux", "Benoit", ""], ["Herbert", "Vincent", ""]]}, {"id": "1811.03883", "submitter": "Duo Zhang", "authors": "Duo Zhang, Geir Lindholm, Nicolas Martinez, Harsha Ratnaweera", "title": "Exploiting Capacity of Sewer System Using Unsupervised Learning\n  Algorithms Combined with Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting capacity of sewer system using decentralized control is a cost\neffective mean of minimizing the overflow. Given the size of the real sewer\nsystem, exploiting all the installed control structures in the sewer pipes can\nbe challenging. This paper presents a divide and conquer solution to implement\ndecentralized control measures based on unsupervised learning algorithms. A\nsewer system is first divided into a number of subcatchments. A series of\nnatural and built factors that have the impact on sewer system performance is\nthen collected. Clustering algorithms are then applied to grouping\nsubcatchments with similar hydraulic hydrologic characteristics. Following\nwhich, principal component analysis is performed to interpret the main features\nof sub-catchment groups and identify priority control locations. Overflows\nunder different control scenarios are compared based on the hydraulic model.\nSimulation results indicate that priority control applied to the most suitable\ncluster could bring the most profitable result.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 12:39:53 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Zhang", "Duo", ""], ["Lindholm", "Geir", ""], ["Martinez", "Nicolas", ""], ["Ratnaweera", "Harsha", ""]]}, {"id": "1811.03895", "submitter": "Sultan Javed Majeed", "authors": "Sultan Javed Majeed and Marcus Hutter", "title": "Performance Guarantees for Homomorphisms Beyond Markov Decision\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world problems have huge state and/or action spaces. Therefore, a\nnaive application of existing tabular solution methods is not tractable on such\nproblems. Nonetheless, these solution methods are quite useful if an agent has\naccess to a relatively small state-action space homomorphism of the true\nenvironment and near-optimal performance is guaranteed by the map. A plethora\nof research is focused on the case when the homomorphism is a Markovian\nrepresentation of the underlying process. However, we show that near-optimal\nperformance is sometimes guaranteed even if the homomorphism is non-Markovian.\nMoreover, we can aggregate significantly more states by lifting the Markovian\nrequirement without compromising on performance. In this work, we expand\nExtreme State Aggregation (ESA) framework to joint state-action aggregations.\nWe also lift the policy uniformity condition for aggregation in ESA that allows\neven coarser modeling of the true environment.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 13:39:16 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Majeed", "Sultan Javed", ""], ["Hutter", "Marcus", ""]]}, {"id": "1811.03897", "submitter": "Patric Fulop", "authors": "Remus Pop, Patric Fulop", "title": "Deep Ensemble Bayesian Active Learning : Addressing the Mode Collapse\n  issue in Monte Carlo dropout via Ensembles", "comments": "ICLR under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image classification tasks, the ability of deep CNNs to deal with complex\nimage data has proven to be unrivalled. However, they require large amounts of\nlabeled training data to reach their full potential. In specialised domains\nsuch as healthcare, labeled data can be difficult and expensive to obtain.\nActive Learning aims to alleviate this problem, by reducing the amount of\nlabelled data needed for a specific task while delivering satisfactory\nperformance. We propose DEBAL, a new active learning strategy designed for deep\nneural networks. This method improves upon the current state-of-the-art deep\nBayesian active learning method, which suffers from the mode collapse problem.\nWe correct for this deficiency by making use of the expressive power and\nstatistical properties of model ensembles. Our proposed method manages to\ncapture superior data uncertainty, which translates into improved\nclassification performance. We demonstrate empirically that our ensemble method\nyields faster convergence of CNNs trained on the MNIST and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 13:44:12 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Pop", "Remus", ""], ["Fulop", "Patric", ""]]}, {"id": "1811.03909", "submitter": "Athanasios Davvetas", "authors": "Athanasios Davvetas, Iraklis A. Klampanos and Vangelis Karkaletsis", "title": "Evidence Transfer for Improving Clustering Tasks Using External\n  Categorical Evidence", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852384", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce evidence transfer for clustering, a deep learning\nmethod that can incrementally manipulate the latent representations of an\nautoencoder, according to external categorical evidence, in order to improve a\nclustering outcome. By evidence transfer we define the process by which the\ncategorical outcome of an external, auxiliary task is exploited to improve a\nprimary task, in this case representation learning for clustering. Our proposed\nmethod makes no assumptions regarding the categorical evidence presented, nor\nthe structure of the latent space. We compare our method, against the baseline\nsolution by performing k-means clustering before and after its deployment.\nExperiments with three different kinds of evidence show that our method\neffectively manipulates the latent representations when introduced with real\ncorresponding evidence, while remaining robust when presented with low quality\nevidence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 14:10:18 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 19:39:04 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""], ["Karkaletsis", "Vangelis", ""]]}, {"id": "1811.03962", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song", "title": "A Convergence Theory for Deep Learning via Over-Parameterization", "comments": "V2 adds citation and V3/V4/V5 polish writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated dominating performance in many\nfields; since AlexNet, networks used in practice are going wider and deeper. On\nthe theoretical side, a long line of works has been focusing on training neural\nnetworks with one hidden layer. The theory of multi-layer networks remains\nlargely unsettled.\n  In this work, we prove why stochastic gradient descent (SGD) can find\n$\\textit{global minima}$ on the training objective of DNNs in\n$\\textit{polynomial time}$. We only make two assumptions: the inputs are\nnon-degenerate and the network is over-parameterized. The latter means the\nnetwork width is sufficiently large: $\\textit{polynomial}$ in $L$, the number\nof layers and in $n$, the number of samples.\n  Our key technique is to derive that, in a sufficiently large neighborhood of\nthe random initialization, the optimization landscape is almost-convex and\nsemi-smooth even with ReLU activations. This implies an equivalence between\nover-parameterized neural networks and neural tangent kernel (NTK) in the\nfinite (and polynomial) width setting.\n  As concrete examples, starting from randomly initialized weights, we prove\nthat SGD can attain 100% training accuracy in classification tasks, or minimize\nregression loss in linear convergence speed, with running time polynomial in\n$n,L$. Our theory applies to the widely-used but non-smooth ReLU activation,\nand to any smooth and possibly non-convex loss functions. In terms of network\narchitectures, our theory at least applies to fully-connected neural networks,\nconvolutional neural networks (CNN), and residual neural networks (ResNet).\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 15:16:13 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 18:54:20 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 11:44:07 GMT"}, {"version": "v4", "created": "Mon, 4 Feb 2019 03:57:59 GMT"}, {"version": "v5", "created": "Mon, 17 Jun 2019 06:39:04 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""], ["Song", "Zhao", ""]]}, {"id": "1811.03963", "submitter": "Cong Chen", "authors": "Ching-Yun Ko, Cong Chen, Yuke Zhang, Kim Batselier, Ngai Wong", "title": "Deep Compression of Sum-Product Networks on Tensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sum-product networks (SPNs) represent an emerging class of neural networks\nwith clear probabilistic semantics and superior inference speed over graphical\nmodels. This work reveals a strikingly intimate connection between SPNs and\ntensor networks, thus leading to a highly efficient representation that we call\ntensor SPNs (tSPNs). For the first time, through mapping an SPN onto a tSPN and\nemploying novel optimization techniques, we demonstrate remarkable parameter\ncompression with negligible loss in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 15:16:55 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Ko", "Ching-Yun", ""], ["Chen", "Cong", ""], ["Zhang", "Yuke", ""], ["Batselier", "Kim", ""], ["Wong", "Ngai", ""]]}, {"id": "1811.03970", "submitter": "Iftitahu Ni'mah", "authors": "Wenting Xiong, Iftitahu Ni'mah, Juan M. G. Huesca, Werner van\n  Ipenburg, Jan Veldsink, and Mykola Pechenizkiy", "title": "Looking Deeper into Deep Learning Model: Attribution-based Explanations\n  of TextCNN", "comments": "NIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services: the Impact of Fairness, Explainability, Accuracy, and\n  Privacy, Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer-wise Relevance Propagation (LRP) and saliency maps have been recently\nused to explain the predictions of Deep Learning models, specifically in the\ndomain of text classification. Given different attribution-based explanations\nto highlight relevant words for a predicted class label, experiments based on\nword deleting perturbation is a common evaluation method. This word removal\napproach, however, disregards any linguistic dependencies that may exist\nbetween words or phrases in a sentence, which could semantically guide a\nclassifier to a particular prediction. In this paper, we present a\nfeature-based evaluation framework for comparing the two attribution methods on\ncustomer reviews (public data sets) and Customer Due Diligence (CDD) extracted\nreports (corporate data set). Instead of removing words based on the relevance\nscore, we investigate perturbations based on embedded features removal from\nintermediate layers of Convolutional Neural Networks. Our experimental study is\ncarried out on embedded-word, embedded-document, and embedded-ngrams\nexplanations. Using the proposed framework, we provide a visualization tool to\nassist analysts in reasoning toward the model's final prediction.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 18:23:48 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 23:18:23 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xiong", "Wenting", ""], ["Ni'mah", "Iftitahu", ""], ["Huesca", "Juan M. G.", ""], ["van Ipenburg", "Werner", ""], ["Veldsink", "Jan", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1811.03980", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio, Muhammad Abdullah Hanif, Semeen Rehman, Maurizio\n  Martina, and Muhammad Shafique", "title": "A Methodology for Automatic Selection of Activation Functions to Design\n  Hybrid Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions influence behavior and performance of DNNs. Nonlinear\nactivation functions, like Rectified Linear Units (ReLU), Exponential Linear\nUnits (ELU) and Scaled Exponential Linear Units (SELU), outperform the linear\ncounterparts. However, selecting an appropriate activation function is a\nchallenging problem, as it affects the accuracy and the complexity of the given\nDNN. In this paper, we propose a novel methodology to automatically select the\nbest-possible activation function for each layer of a given DNN, such that the\noverall DNN accuracy, compared to considering only one type of activation\nfunction for the whole DNN, is improved. However, an associated scientific\nchallenge in exploring all the different configurations of activation functions\nwould be time and resource-consuming. Towards this, our methodology identifies\nthe Evaluation Points during learning to evaluate the accuracy in an\nintermediate step of training and to perform early termination by checking the\naccuracy gradient of the learning curve. This helps in significantly reducing\nthe exploration time during training. Moreover, our methodology selects, for\neach layer, the dropout rate that optimizes the accuracy. Experiments show that\nwe are able to achieve on average 7% to 15% Relative Error Reduction on MNIST,\nCIFAR-10 and CIFAR-100 benchmarks, with limited performance and power penalty\non GPUs.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 14:30:58 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Marchisio", "Alberto", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.04006", "submitter": "Stanislav Fedorov", "authors": "Stanislav Fedorov, Antonio Candelieri", "title": "Reachability-based safe learning for optimal control problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we seek for an approach to integrate safety in the learning\nprocess that relies on a partly known state-space model of the system and\nregards the unknown dynamics as an additive bounded disturbance. We introduce a\nframework for safely learning a control strategy for a given system with an\nadditive disturbance. On the basis of the known part of the model, a safe set\nin which the system can learn safely, the algorithm can choose optimal actions\nfor pursuing the target set as long as the safety-preserving condition is\nsatisfied. After some learning episodes, the disturbance can be updated based\non real-world data. To this end, Gaussian Process regression is conducted on\nthe collected disturbance samples. Since the unstable nature of the law of the\nreal world, for example, change of friction or conductivity with the\ntemperature, we expect to have the more robust solution of optimal control\nproblem.\n  For evaluation of approach described above we choose an inverted pendulum as\na benchmark model. The proposed algorithm manages to learn a policy that does\nnot violate the pre-specified safety constraints. Observed performance is\nimproved when it was incorporated exploration set up to make sure that an\noptimal policy is learned everywhere in the safe set. Finally, we outline some\npromising directions for future research beyond the scope of this paper.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 16:37:59 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Fedorov", "Stanislav", ""], ["Candelieri", "Antonio", ""]]}, {"id": "1811.04017", "submitter": "Th\\'eo Ryffel", "authors": "Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso,\n  Daniel Rueckert and Jonathan Passerat-Palmbach", "title": "A generic framework for privacy preserving deep learning", "comments": "PPML 2018, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We detail a new framework for privacy preserving deep learning and discuss\nits assets. The framework puts a premium on ownership and secure processing of\ndata and introduces a valuable representation based on chains of commands and\ntensors. This abstraction allows one to implement complex privacy preserving\nconstructs such as Federated Learning, Secure Multiparty Computation, and\nDifferential Privacy while still exposing a familiar deep learning API to the\nend-user. We report early results on the Boston Housing and Pima Indian\nDiabetes datasets. While the privacy features apart from Differential Privacy\ndo not impact the prediction accuracy, the current implementation of the\nframework introduces a significant overhead in performance, which will be\naddressed at a later stage of the development. We believe this work is an\nimportant milestone introducing the first reliable, general framework for\nprivacy preserving deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 17:10:47 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 18:11:15 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Ryffel", "Theo", ""], ["Trask", "Andrew", ""], ["Dahl", "Morten", ""], ["Wagner", "Bobby", ""], ["Mancuso", "Jason", ""], ["Rueckert", "Daniel", ""], ["Passerat-Palmbach", "Jonathan", ""]]}, {"id": "1811.04022", "submitter": "Yiran Wang", "authors": "Gunther Uhlmann and Yiran Wang", "title": "Convolutional neural networks in phase space and inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study inverse problems consisting on determining medium properties using\nthe responses to probing waves from the machine learning point of view. Based\non the understanding of propagation of waves and their nonlinear interactions,\nwe construct a deep convolutional neural network in which the parameters are\nused to classify and reconstruct the coefficients of nonlinear wave equations\nthat model the medium properties. Furthermore, for given approximation\naccuracy, we obtain the depth and number of units of the network and their\nquantitative dependence on the complexity of the medium.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 17:17:07 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Uhlmann", "Gunther", ""], ["Wang", "Yiran", ""]]}, {"id": "1811.04026", "submitter": "Yibo Yang", "authors": "Yibo Yang, Paris Perdikaris", "title": "Adversarial Uncertainty Quantification in Physics-Informed Neural\n  Networks", "comments": "This paper has been submitted to Journal of Computational Physics. 33\n  pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2019.05.027", "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning framework for quantifying and propagating\nuncertainty in systems governed by non-linear differential equations using\nphysics-informed neural networks. Specifically, we employ latent variable\nmodels to construct probabilistic representations for the system states, and\nput forth an adversarial inference procedure for training them on data, while\nconstraining their predictions to satisfy given physical laws expressed by\npartial differential equations. Such physics-informed constraints provide a\nregularization mechanism for effectively training deep generative models as\nsurrogates of physical systems in which the cost of data acquisition is high,\nand training data-sets are typically small. This provides a flexible framework\nfor characterizing uncertainty in the outputs of physical systems due to\nrandomness in their inputs or noise in their observations that entirely\nbypasses the need for repeatedly sampling expensive experiments or numerical\nsimulators. We demonstrate the effectiveness of our approach through a series\nof examples involving uncertainty propagation in non-linear conservation laws,\nand the discovery of constitutive laws for flow through porous media directly\nfrom noisy data.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 17:20:31 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Yang", "Yibo", ""], ["Perdikaris", "Paris", ""]]}, {"id": "1811.04060", "submitter": "Marcel Wever", "authors": "Marcel Wever and Felix Mohr and Eyke H\\\"ullermeier", "title": "Automated Multi-Label Classification based on ML-Plan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning (AutoML) has received increasing attention in the\nrecent past. While the main tools for AutoML, such as Auto-WEKA, TPOT, and\nauto-sklearn, mainly deal with single-label classification and regression,\nthere is very little work on other types of machine learning tasks. In\nparticular, there is almost no work on automating the engineering of machine\nlearning applications for multi-label classification. This paper makes two\ncontributions. First, it discusses the usefulness and feasibility of an AutoML\napproach for multi-label classification. Second, we show how the scope of\nML-Plan, an AutoML-tool for multi-class classification, can be extended towards\nmulti-label classification using MEKA, which is a multi-label extension of the\nwell-known Java library WEKA. The resulting approach recursively refines MEKA's\nmulti-label classifiers, which sometimes nest another multi-label classifier,\nup to the selection of a single-label base learner provided by WEKA. In our\nevaluation, we find that the proposed approach yields superb results and\nperforms significantly better than a set of baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 18:40:35 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Wever", "Marcel", ""], ["Mohr", "Felix", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1811.04064", "submitter": "You Lu", "authors": "You Lu, Zhiyuan Liu, Bert Huang", "title": "Block Belief Propagation for Parameter Learning in Markov Random Fields", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional learning methods for training Markov random fields require doing\ninference over all variables to compute the likelihood gradient. The iteration\ncomplexity for those methods therefore scales with the size of the graphical\nmodels. In this paper, we propose \\emph{block belief propagation learning}\n(BBPL), which uses block-coordinate updates of approximate marginals to compute\napproximate gradients, removing the need to compute inference on the entire\ngraphical model. Thus, the iteration complexity of BBPL does not scale with the\nsize of the graphs. We prove that the method converges to the same solution as\nthat obtained by using full inference per iteration, despite these\napproximations, and we empirically demonstrate its scalability improvements\nover standard training methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 18:50:52 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Lu", "You", ""], ["Liu", "Zhiyuan", ""], ["Huang", "Bert", ""]]}, {"id": "1811.04076", "submitter": "Kou Tanaka", "authors": "Kou Tanaka, Hirokazu Kameoka, Takuhiro Kaneko, Nobukatsu Hojo", "title": "AttS2S-VC: Sequence-to-Sequence Voice Conversion with Attention and\n  Context Preservation Mechanisms", "comments": "Submitted to ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method based on a sequence-to-sequence learning\n(Seq2Seq) with attention and context preservation mechanism for voice\nconversion (VC) tasks. Seq2Seq has been outstanding at numerous tasks involving\nsequence modeling such as speech synthesis and recognition, machine\ntranslation, and image captioning. In contrast to current VC techniques, our\nmethod 1) stabilizes and accelerates the training procedure by considering\nguided attention and proposed context preservation losses, 2) allows not only\nspectral envelopes but also fundamental frequency contours and durations of\nspeech to be converted, 3) requires no context information such as phoneme\nlabels, and 4) requires no time-aligned source and target speech data in\nadvance. In our experiment, the proposed VC framework can be trained in only\none day, using only one GPU of an NVIDIA Tesla K80, while the quality of the\nsynthesized speech is higher than that of speech converted by Gaussian mixture\nmodel-based VC and is comparable to that of speech generated by recurrent\nneural network-based text-to-speech synthesis, which can be regarded as an\nupper limit on VC performance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 05:19:43 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Tanaka", "Kou", ""], ["Kameoka", "Hirokazu", ""], ["Kaneko", "Takuhiro", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "1811.04127", "submitter": "Teodor Vanislavov Marinov", "authors": "Raman Arora, Michael Dinitz, Teodor V. Marinov, Mehryar Mohri", "title": "Policy Regret in Repeated Games", "comments": "Camera ready from NeurIPS 2018; 25 pages; Slightly updated results\n  and proofs for Section 3 and Section 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of \\emph{policy regret} in online learning is a well defined?\nperformance measure for the common scenario of adaptive adversaries, which more\ntraditional quantities such as external regret do not take into account. We\nrevisit the notion of policy regret and first show that there are online\nlearning settings in which policy regret and external regret are incompatible:\nany sequence of play that achieves a favorable regret with respect to one\ndefinition must do poorly with respect to the other. We then focus on the\ngame-theoretic setting where the adversary is a self-interested agent. In that\nsetting, we show that external regret and policy regret are not in conflict\nand, in fact, that a wide class of algorithms can ensure a favorable regret\nwith respect to both definitions, so long as the adversary is also using such\nan algorithm. We also show that the sequence of play of no-policy regret\nalgorithms converges to a \\emph{policy equilibrium}, a new notion of\nequilibrium that we introduce. Relating this back to external regret, we show\nthat coarse correlated equilibria, which no-external regret players converge\nto, are a strict subset of policy equilibria. Thus, in game-theoretic settings,\nevery sequence of play with no external regret also admits no policy regret,\nbut the converse does not hold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 20:30:09 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 18:30:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Arora", "Raman", ""], ["Dinitz", "Michael", ""], ["Marinov", "Teodor V.", ""], ["Mohri", "Mehryar", ""]]}, {"id": "1811.04132", "submitter": "Monireh Ebrahimi", "authors": "Monireh Ebrahimi, Md Kamruzzaman Sarker, Federico Bianchi, Ning Xie,\n  Derek Doran, Pascal Hitzler", "title": "Reasoning over RDF Knowledge Bases using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic Web knowledge representation standards, and in particular RDF and\nOWL, often come endowed with a formal semantics which is considered to be of\nfundamental importance for the field. Reasoning, i.e., the drawing of logical\ninferences from knowledge expressed in such standards, is traditionally based\non logical deductive methods and algorithms which can be proven to be sound and\ncomplete and terminating, i.e. correct in a very strong sense. For various\nreasons, though, in particular, the scalability issues arising from the\never-increasing amounts of Semantic Web data available and the inability of\ndeductive algorithms to deal with noise in the data, it has been argued that\nalternative means of reasoning should be investigated which bear high promise\nfor high scalability and better robustness. From this perspective, deductive\nalgorithms can be considered the gold standard regarding correctness against\nwhich alternative methods need to be tested. In this paper, we show that it is\npossible to train a Deep Learning system on RDF knowledge graphs, such that it\nis able to perform reasoning over new RDF knowledge graphs, with high precision\nand recall compared to the deductive gold standard.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 21:00:46 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Ebrahimi", "Monireh", ""], ["Sarker", "Md Kamruzzaman", ""], ["Bianchi", "Federico", ""], ["Xie", "Ning", ""], ["Doran", "Derek", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1811.04133", "submitter": "Efthymios Tzinis", "authors": "Efthymios Tzinis, Georgios Paraskevopoulos, Christos Baziotis and\n  Alexandros Potamianos", "title": "Integrating Recurrence Dynamics for Speech Emotion Recognition", "comments": null, "journal-ref": "Proc. Interspeech 2018, pp. 927-931", "doi": "10.21437/Interspeech.2018-1377", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of features that can capture nonlinear\nrecurrence dynamics embedded in the speech signal for the task of Speech\nEmotion Recognition (SER). Reconstruction of the phase space of each speech\nframe and the computation of its respective Recurrence Plot (RP) reveals\ncomplex structures which can be measured by performing Recurrence\nQuantification Analysis (RQA). These measures are aggregated by using\nstatistical functionals over segment and utterance periods. We report SER\nresults for the proposed feature set on three databases using different\nclassification methods. When fusing the proposed features with traditional\nfeature sets, we show an improvement in unweighted accuracy of up to 5.7% and\n10.7% on Speaker-Dependent (SD) and Speaker-Independent (SI) SER tasks,\nrespectively, over the baseline. Following a segment-based approach we\ndemonstrate state-of-the-art performance on IEMOCAP using a Bidirectional\nRecurrent Neural Network.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 21:02:52 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Tzinis", "Efthymios", ""], ["Paraskevopoulos", "Georgios", ""], ["Baziotis", "Christos", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1811.04136", "submitter": "Wai Ming Tai", "authors": "Jeff M. Phillips, Wai Ming Tai", "title": "The GaussianSketch for Almost Relative Error Kernel Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two versions of a new sketch for approximately embedding the\nGaussian kernel into Euclidean inner product space. These work by truncating\ninfinite expansions of the Gaussian kernel, and carefully invoking the\nRecursiveTensorSketch [Ahle et al. SODA 2020]. After providing concentration\nand approximation properties of these sketches, we use them to approximate the\nkernel distance between points sets. These sketches yield almost\n$(1+\\varepsilon)$-relative error, but with a small additive $\\alpha$ term. In\nthe first variants the dependence on $1/\\alpha$ is poly-logarithmic, but has\nhigher degree of polynomial dependence on the original dimension $d$. In the\nsecond variant, the dependence on $1/\\alpha$ is still poly-logarithmic, but the\ndependence on $d$ is linear.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 21:12:32 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 09:26:19 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 06:43:27 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Phillips", "Jeff M.", ""], ["Tai", "Wai Ming", ""]]}, {"id": "1811.04142", "submitter": "Kehelwala Dewage Gayan Maduranga", "authors": "Kehelwala D. G. Maduranga, Kyle E. Helfrich, and Qiang Ye", "title": "Complex Unitary Recurrent Neural Networks using Scaled Cayley Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been successfully used on a wide range\nof sequential data problems. A well known difficulty in using RNNs is the\n\\textit{vanishing or exploding gradient} problem. Recently, there have been\nseveral different RNN architectures that try to mitigate this issue by\nmaintaining an orthogonal or unitary recurrent weight matrix. One such\narchitecture is the scaled Cayley orthogonal recurrent neural network (scoRNN)\nwhich parameterizes the orthogonal recurrent weight matrix through a scaled\nCayley transform. This parametrization contains a diagonal scaling matrix\nconsisting of positive or negative one entries that can not be optimized by\ngradient descent. Thus the scaling matrix is fixed before training and a\nhyperparameter is introduced to tune the matrix for each particular task. In\nthis paper, we develop a unitary RNN architecture based on a complex scaled\nCayley transform. Unlike the real orthogonal case, the transformation uses a\ndiagonal scaling matrix consisting of entries on the complex unit circle which\ncan be optimized using gradient descent and no longer requires the tuning of a\nhyperparameter. We also provide an analysis of a potential issue of the modReLU\nactiviation function which is used in our work and several other unitary RNNs.\nIn the experiments conducted, the scaled Cayley unitary recurrent neural\nnetwork (scuRNN) achieves comparable or better results than scoRNN and other\nunitary RNNs without fixing the scaling matrix.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 21:37:36 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:06:38 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Maduranga", "Kehelwala D. G.", ""], ["Helfrich", "Kyle E.", ""], ["Ye", "Qiang", ""]]}, {"id": "1811.04151", "submitter": "Wei Zeng", "authors": "Wei Zeng, Azadeh Davoodi, Yu Hen Hu", "title": "Design Rule Violation Hotspot Prediction Based on Neural Network\n  Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design rule check is a critical step in the physical design of integrated\ncircuits to ensure manufacturability. However, it can be done only after a\ntime-consuming detailed routing procedure, which adds drastically to the time\nof design iterations. With advanced technology nodes, the outcomes of global\nrouting and detailed routing become less correlated, which adds to the\ndifficulty of predicting design rule violations from earlier stages. In this\npaper, a framework based on neural network ensembles is proposed to predict\ndesign rule violation hotspots using information from placement and global\nrouting. A soft voting structure and a PCA-based subset selection scheme are\ndeveloped on top of a baseline neural network from a recent work. Experimental\nresults show that the proposed architecture achieves significant improvement in\nmodel performance compared to the baseline case. For half of test cases, the\nperformance is even better than random forest, a commonly-used ensemble\nlearning model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 22:18:26 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Zeng", "Wei", ""], ["Davoodi", "Azadeh", ""], ["Hu", "Yu Hen", ""]]}, {"id": "1811.04234", "submitter": "Felix Petersen", "authors": "Felix Petersen, Moritz Schubotz, Bela Gipp", "title": "Towards Formula Translation using Recursive Neural Networks", "comments": "11 pages, Work-in-Progress paper in CICM-WS 2018 Workshop Papers at\n  11th Conference on Intelligent Computer Mathematics CICM 2018", "journal-ref": "Conference on Intelligent Computer Mathematics (CICM) 2018,\n  CEUR-WS Vol-2307, WiP3", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it has become common to perform automated translations on natural\nlanguage, performing translations between different representations of\nmathematical formulae has thus far not been possible. We implemented the first\ntranslator for mathematical formulae based on recursive neural networks. We\nchose recursive neural networks because mathematical formulae inherently\ninclude a structural encoding. In our implementation, we developed new\ntechniques and topologies for recursive tree-to-tree neural networks based on\nmulti-variate multi-valued Long Short-Term Memory cells. We propose a novel\napproach for mini-batch training that utilizes clustering and tree traversal.\nWe evaluate our translator and analyze the behavior of our proposed topologies\nand techniques based on a translation from generic LaTeX to the semantic LaTeX\nnotation. We use the semantic LaTeX notation from the Digital Library for\nMathematical Formulae and the Digital Repository for Mathematical Formulae at\nthe National Institute for Standards and Technology. We find that a simple\nheuristics-based clustering algorithm outperforms the conventional clustering\nalgorithms on the task of clustering binary trees of mathematical formulae with\nrespect to their topology. Furthermore, we find a mask for the loss function,\nwhich can prevent the neural network from finding a local minimum of the loss\nfunction. Given our preliminary results, a complete translation from formula to\nformula is not yet possible. However, we achieved a prediction accuracy of\n47.05% for predicting symbols at the correct position and an accuracy of 92.3%\nwhen ignoring the predicted position. Concluding, our work advances the field\nof recursive neural networks by improving the training speed and quality of\ntraining. In the future, we will work towards a complete translation allowing a\nmachine-interpretation of LaTeX formulae.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 11:20:18 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Petersen", "Felix", ""], ["Schubotz", "Moritz", ""], ["Gipp", "Bela", ""]]}, {"id": "1811.04251", "submitter": "David  McAllester", "authors": "David McAllester and Karl Stratos", "title": "Formal Limitations on the Measurement of Mutual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring mutual information from finite data is difficult. Recent work has\nconsidered variational methods maximizing a lower bound. In this paper, we\nprove that serious statistical limitations are inherent to any method of\nmeasuring mutual information. More specifically, we show that any\ndistribution-free high-confidence lower bound on mutual information estimated\nfrom N samples cannot be larger than O(ln N ).\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 13:12:27 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 13:07:27 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 13:39:36 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 12:03:39 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["McAllester", "David", ""], ["Stratos", "Karl", ""]]}, {"id": "1811.04277", "submitter": "Haitao Liu", "authors": "Haitao Liu, Randy C. Paffenroth, Jian Zou, Chong Zhou", "title": "Anomaly Detection via Graphical Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomalies and outliers are common in real-world data, and they can arise from\nmany sources, such as sensor faults. Accordingly, anomaly detection is\nimportant both for analyzing the anomalies themselves and for cleaning the data\nfor further analysis of its ambient structure. Nonetheless, a precise\ndefinition of anomalies is important for automated detection and herein we\napproach such problems from the perspective of detecting sparse latent effects\nembedded in large collections of noisy data. Standard Graphical Lasso-based\ntechniques can identify the conditional dependency structure of a collection of\nrandom variables based on their sample covariance matrix. However, classic\nGraphical Lasso is sensitive to outliers in the sample covariance matrix. In\nparticular, several outliers in a sample covariance matrix can destroy the\nsparsity of its inverse. Accordingly, we propose a novel optimization problem\nthat is similar in spirit to Robust Principal Component Analysis (RPCA) and\nsplits the sample covariance matrix $M$ into two parts, $M=F+S$, where $F$ is\nthe cleaned sample covariance whose inverse is sparse and computable by\nGraphical Lasso, and $S$ contains the outliers in $M$. We accomplish this\ndecomposition by adding an additional $ \\ell_1$ penalty to classic Graphical\nLasso, and name it \"Robust Graphical Lasso (Rglasso)\". Moreover, we propose an\nAlternating Direction Method of Multipliers (ADMM) solution to the optimization\nproblem which scales to large numbers of unknowns. We evaluate our algorithm on\nboth real and synthetic datasets, obtaining interpretable results and\noutperforming the standard robust Minimum Covariance Determinant (MCD) method\nand Robust Principal Component Analysis (RPCA) regarding both accuracy and\nspeed.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 16:15:04 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Liu", "Haitao", ""], ["Paffenroth", "Randy C.", ""], ["Zou", "Jian", ""], ["Zhou", "Chong", ""]]}, {"id": "1811.04319", "submitter": "Ronen Tamari", "authors": "Ronen Tamari, Hiroyuki Shindo, Dafna Shahaf, Yuji Matsumoto", "title": "Playing by the Book: An Interactive Game Approach for Action Graph\n  Extraction from Text", "comments": "Accepted to NAACL 2019 ESSP workshop\n  (https://scientific-knowledge.github.io/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding procedural text requires tracking entities, actions and effects\nas the narrative unfolds. We focus on the challenging real-world problem of\naction-graph extraction from material science papers, where language is highly\nspecialized and data annotation is expensive and scarce. We propose a novel\napproach, Text2Quest, where procedural text is interpreted as instructions for\nan interactive game. A learning agent completes the game by executing the\nprocedure correctly in a text-based simulated lab environment. The framework\ncan complement existing approaches and enables richer forms of learning\ncompared to static texts. We discuss potential limitations and advantages of\nthe approach, and release a prototype proof-of-concept, hoping to encourage\nresearch in this direction.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 21:45:07 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 16:59:00 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 19:19:05 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Tamari", "Ronen", ""], ["Shindo", "Hiroyuki", ""], ["Shahaf", "Dafna", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1811.04324", "submitter": "Yuhang Song", "authors": "Yuhang Song, Jianyi Wang, Thomas Lukasiewicz, Zhenghua Xu, Mai Xu", "title": "Diversity-Driven Extensible Hierarchical Reinforcement Learning", "comments": "8 pages, 8 figures, In Proceedings of the 33rd National Conference on\n  Artificial Intelligence, AAAI 2019, Honolulu, Hawaii, USA, January 27, 2019.\n  Jianyi Wang is the co-first author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning (HRL) has recently shown promising\nadvances on speeding up learning, improving the exploration, and discovering\nintertask transferable skills. Most recent works focus on HRL with two levels,\ni.e., a master policy manipulates subpolicies, which in turn manipulate\nprimitive actions. However, HRL with multiple levels is usually needed in many\nreal-world scenarios, whose ultimate goals are highly abstract, while their\nactions are very primitive. Therefore, in this paper, we propose a\ndiversity-driven extensible HRL (DEHRL), where an extensible and scalable\nframework is built and learned levelwise to realize HRL with multiple levels.\nDEHRL follows a popular assumption: diverse subpolicies are useful, i.e.,\nsubpolicies are believed to be more useful if they are more diverse. However,\nexisting implementations of this diversity assumption usually have their own\ndrawbacks, which makes them inapplicable to HRL with multiple levels.\nConsequently, we further propose a novel diversity-driven solution to achieve\nthis assumption in DEHRL. Experimental studies evaluate DEHRL with five\nbaselines from four perspectives in two domains; the results show that DEHRL\noutperforms the state-of-the-art baselines in all four aspects.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 23:35:34 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 10:26:58 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Song", "Yuhang", ""], ["Wang", "Jianyi", ""], ["Lukasiewicz", "Thomas", ""], ["Xu", "Zhenghua", ""], ["Xu", "Mai", ""]]}, {"id": "1811.04343", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Konark Jain, Ratneel V. Deo, Sally Cripps", "title": "Langevin-gradient parallel tempering for Bayesian neural learning", "comments": "In review. Software:\n  https://github.com/sydney-machine-learning/parallel-tempering-neural-net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian neural learning feature a rigorous approach to estimation and\nuncertainty quantification via the posterior distribution of weights that\nrepresent knowledge of the neural network. This not only provides point\nestimates of optimal set of weights but also the ability to quantify\nuncertainty in decision making using the posterior distribution. Markov chain\nMonte Carlo (MCMC) techniques are typically used to obtain sample-based\nestimates of the posterior distribution. However, these techniques face\nchallenges in convergence and scalability, particularly in settings with large\ndatasets and network architectures. This paper address these challenges in two\nways. First, parallel tempering is used used to explore multiple modes of the\nposterior distribution and implemented in multi-core computing architecture.\nSecond, we make within-chain sampling schemes more efficient by using Langevin\ngradient information in forming Metropolis-Hastings proposal distributions. We\ndemonstrate the techniques using time series prediction and pattern\nclassification applications. The results show that the method not only improves\nthe computational time, but provides better prediction or decision making\ncapabilities when compared to related methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 03:53:54 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Chandra", "Rohitash", ""], ["Jain", "Konark", ""], ["Deo", "Ratneel V.", ""], ["Cripps", "Sally", ""]]}, {"id": "1811.04344", "submitter": "Abigail Jacobs", "authors": "Jen J. Gong, Abigail Z. Jacobs, Toby E. Stuart, Mathijs de Vaan", "title": "Discovering heterogeneous subpopulations for fine-grained analysis of\n  opioid use and opioid use disorders", "comments": "Withdrawn pending data use agreement clarification", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The opioid epidemic in the United States claims over 40,000 lives per year,\nand it is estimated that well over two million Americans have an opioid use\ndisorder. Over-prescription and misuse of prescription opioids play an\nimportant role in the epidemic. Individuals who are prescribed opioids, and who\nare diagnosed with opioid use disorder, have diverse underlying health states.\nPolicy interventions targeting prescription opioid use, opioid use disorder,\nand overdose often fail to account for this variation. To identify latent\nhealth states, or phenotypes, pertinent to opioid use and opioid use disorders,\nwe use probabilistic topic modeling with medical diagnosis histories from a\nstatewide population of individuals who were prescribed opioids. We demonstrate\nthat our learned phenotypes are predictive of future opioid use-related\noutcomes. In addition, we show how the learned phenotypes can provide important\ncontext for variability in opioid prescriptions. Understanding the\nheterogeneity in individual health states and in prescription opioid use can\nhelp identify policy interventions to address this public health crisis.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 04:00:32 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 04:52:42 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 23:25:41 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Gong", "Jen J.", ""], ["Jacobs", "Abigail Z.", ""], ["Stuart", "Toby E.", ""], ["de Vaan", "Mathijs", ""]]}, {"id": "1811.04345", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Zhiwei Qin, Xuewen Chen, Matthew Nokleby and Jieping Ye", "title": "Optimizing Taxi Carpool Policies via Reinforcement Learning and\n  Spatio-Temporal Mining", "comments": "Accepted at IEEE International Conference on Big Data 2018. arXiv\n  admin note: text overlap with arXiv:1710.04350", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a reinforcement learning (RL) based system to learn\nan effective policy for carpooling that maximizes transportation efficiency so\nthat fewer cars are required to fulfill the given amount of trip demand. For\nthis purpose, first, we develop a deep neural network model, called ST-NN\n(Spatio-Temporal Neural Network), to predict taxi trip time from the raw GPS\ntrip data. Secondly, we develop a carpooling simulation environment for RL\ntraining, with the output of ST-NN and using the NYC taxi trip dataset. In\norder to maximize transportation efficiency and minimize traffic congestion, we\nchoose the effective distance covered by the driver on a carpool trip as the\nreward. Therefore, the more effective distance a driver achieves over a trip\n(i.e. to satisfy more trip demand) the higher the efficiency and the less will\nbe the traffic congestion. We compared the performance of RL learned policy to\na fixed policy (which always accepts carpool) as a baseline and obtained\npromising results that are interpretable and demonstrate the advantage of our\nRL approach. We also compare the performance of ST-NN to that of\nstate-of-the-art travel time estimation methods and observe that ST-NN\nsignificantly improves the prediction performance and is more robust to\noutliers.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 04:13:31 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Jindal", "Ishan", ""], ["Qin", "Zhiwei", ""], ["Chen", "Xuewen", ""], ["Nokleby", "Matthew", ""], ["Ye", "Jieping", ""]]}, {"id": "1811.04350", "submitter": "John Yang", "authors": "John Yang, Gyujeong Lee, Minsung Hyun, Simyung Chang, Nojun Kwak", "title": "Towards Governing Agent's Efficacy: Action-Conditional $\\beta$-VAE for\n  Deep Transparent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the blackbox issue of deep neural networks in the settings of\nreinforcement learning (RL) where neural agents learn towards maximizing reward\ngains in an uncontrollable way. Such learning approach is risky when the\ninteracting environment includes an expanse of state space because it is then\nalmost impossible to foresee all unwanted outcomes and penalize them with\nnegative rewards beforehand. Unlike reverse analysis of learned neural features\nfrom previous works, our proposed method \\nj{tackles the blackbox issue by\nencouraging} an RL policy network to learn interpretable latent features\nthrough an implementation of a disentangled representation learning method.\nToward this end, our method allows an RL agent to understand self-efficacy by\ndistinguishing its influences from uncontrollable environmental factors, which\nclosely resembles the way humans understand their scenes. Our experimental\nresults show that the learned latent factors not only are interpretable, but\nalso enable modeling the distribution of entire visited state space with a\nspecific action condition. We have experimented that this characteristic of the\nproposed structure can lead to ex post facto governance for desired behaviors\nof RL agents.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 04:48:15 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Yang", "John", ""], ["Lee", "Gyujeong", ""], ["Hyun", "Minsung", ""], ["Chang", "Simyung", ""], ["Kwak", "Nojun", ""]]}, {"id": "1811.04351", "submitter": "Min-Hsiu Hsieh", "authors": "Chao Zhang and Min-Hsiu Hsieh and Dacheng Tao", "title": "Generalization Bounds for Vicinal Risk Minimization Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vicinal risk minimization (VRM) principle, first proposed by\n\\citet{vapnik1999nature}, is an empirical risk minimization (ERM) variant that\nreplaces Dirac masses with vicinal functions. Although there is strong\nnumerical evidence showing that VRM outperforms ERM if appropriate vicinal\nfunctions are chosen, a comprehensive theoretical understanding of VRM is still\nlacking. In this paper, we study the generalization bounds for VRM. Our results\nsupport Vapnik's original arguments and additionally provide deeper insights\ninto VRM. First, we prove that the complexity of function classes convolving\nwith vicinal functions can be controlled by that of the original function\nclasses under the assumption that the function class is composed of\nLipschitz-continuous functions. Then, the resulting generalization bounds for\nVRM suggest that the generalization performance of VRM is also effected by the\nchoice of vicinity function and the quality of function classes. These findings\ncan be used to examine whether the choice of vicinal function is appropriate\nfor the VRM-based learning setting. Finally, we provide a theoretical\nexplanation for existing VRM models, e.g., uniform distribution-based models,\nGaussian distribution-based models, and mixup models.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 05:06:02 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Zhang", "Chao", ""], ["Hsieh", "Min-Hsiu", ""], ["Tao", "Dacheng", ""]]}, {"id": "1811.04364", "submitter": "Shehroz Khan", "authors": "Amir Ahmad, Shehroz S. Khan", "title": "Survey of state-of-the-art mixed data clustering algorithms", "comments": "20 Pages, 2 columns, 6 Tables, 209 References", "journal-ref": "IEEE Access, 2019", "doi": "10.1109/ACCESS.2019.2903568", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed data comprises both numeric and categorical features, and mixed\ndatasets occur frequently in many domains, such as health, finance, and\nmarketing. Clustering is often applied to mixed datasets to find structures and\nto group similar objects for further analysis. However, clustering mixed data\nis challenging because it is difficult to directly apply mathematical\noperations, such as summation or averaging, to the feature values of these\ndatasets. In this paper, we present a taxonomy for the study of mixed data\nclustering algorithms by identifying five major research themes. We then\npresent a state-of-the-art review of the research works within each research\ntheme. We analyze the strengths and weaknesses of these methods with pointers\nfor future research directions. Lastly, we present an in-depth analysis of the\noverall challenges in this field, highlight open research questions and discuss\nguidelines to make progress in the field.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 07:27:51 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 23:11:42 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 22:30:04 GMT"}, {"version": "v4", "created": "Tue, 29 Jan 2019 05:54:20 GMT"}, {"version": "v5", "created": "Sat, 9 Mar 2019 21:25:46 GMT"}, {"version": "v6", "created": "Mon, 18 Mar 2019 18:30:33 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ahmad", "Amir", ""], ["Khan", "Shehroz S.", ""]]}, {"id": "1811.04376", "submitter": "Tanmayee Narendra Ms", "authors": "Tanmayee Narendra, Anush Sankaran, Deepak Vijaykeerthy and Senthil\n  Mani", "title": "Explaining Deep Learning Models using Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning models have been successfully applied to a variety of\ntasks, due to the millions of parameters, they are becoming increasingly opaque\nand complex. In order to establish trust for their widespread commercial use,\nit is important to formalize a principled framework to reason over these\nmodels. In this work, we use ideas from causal inference to describe a general\nframework to reason over CNN models. Specifically, we build a Structural Causal\nModel (SCM) as an abstraction over a specific aspect of the CNN. We also\nformulate a method to quantitatively rank the filters of a convolution layer\naccording to their counterfactual importance. We illustrate our approach with\npopular CNN architectures such as LeNet5, VGG19, and ResNet32.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 09:26:55 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Narendra", "Tanmayee", ""], ["Sankaran", "Anush", ""], ["Vijaykeerthy", "Deepak", ""], ["Mani", "Senthil", ""]]}, {"id": "1811.04380", "submitter": "Iurii Kemaev", "authors": "Iurii Kemaev, Daniil Polykovskiy, Dmitry Vetrov", "title": "ReSet: Learning Recurrent Dynamic Routing in ResNet-like Neural Networks", "comments": "Published in Proceedings of The 10th Asian Conference on Machine\n  Learning, http://proceedings.mlr.press/v95/kemaev18a.html", "journal-ref": "Proceedings of The 10th Asian Conference on Machine Learning, PMLR\n  95:422-437, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Network is a powerful Machine Learning tool that shows outstanding\nperformance in Computer Vision, Natural Language Processing, and Artificial\nIntelligence. In particular, recently proposed ResNet architecture and its\nmodifications produce state-of-the-art results in image classification\nproblems. ResNet and most of the previously proposed architectures have a fixed\nstructure and apply the same transformation to all input images. In this work,\nwe develop a ResNet-based model that dynamically selects Computational Units\n(CU) for each input object from a learned set of transformations. Dynamic\nselection allows the network to learn a sequence of useful transformations and\napply only required units to predict the image label. We compare our model to\nResNet-38 architecture and achieve better results than the original ResNet on\nCIFAR-10.1 test set. While examining the produced paths, we discovered that the\nnetwork learned different routes for images from different classes and similar\nroutes for similar images.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 09:45:41 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Kemaev", "Iurii", ""], ["Polykovskiy", "Daniil", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1811.04383", "submitter": "David Cortes", "authors": "David Cortes", "title": "Adapting multi-armed bandits policies to contextual bandits scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores adaptations of successful multi-armed bandits policies to\nthe online contextual bandits scenario with binary rewards using binary\nclassification algorithms such as logistic regression as black-box oracles.\nSome of these adaptations are achieved through bootstrapping or approximate\nbootstrapping, while others rely on other forms of randomness, resulting in\nmore scalable approaches than previous works, and the ability to work with any\ntype of classification algorithm. In particular, the Adaptive-Greedy algorithm\nshows a lot of promise, in many cases achieving better performance than upper\nconfidence bound and Thompson sampling strategies, at the expense of more\nhyperparameters to tune.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 09:56:11 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 07:40:14 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Cortes", "David", ""]]}, {"id": "1811.04393", "submitter": "Jiatao Jiang", "authors": "Jiatao Jiang, Zhen Cui, Chunyan Xu, Jian Yang", "title": "Gaussian-Induced Convolution for Graphs", "comments": "8 pages, 9 figures, AAAI-19 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representation on graph plays a crucial role in numerous tasks of\npattern recognition. Different from grid-shaped images/videos, on which local\nconvolution kernels can be lattices, however, graphs are fully coordinate-free\non vertices and edges. In this work, we propose a Gaussian-induced convolution\n(GIC) framework to conduct local convolution filtering on irregular graphs.\nSpecifically, an edge-induced Gaussian mixture model is designed to encode\nvariations of subgraph region by integrating edge information into weighted\nGaussian models, each of which implicitly characterizes one component of\nsubgraph variations. In order to coarsen a graph, we derive a vertex-induced\nGaussian mixture model to cluster vertices dynamically according to the\nconnection of edges, which is approximately equivalent to the weighted graph\ncut. We conduct our multi-layer graph convolution network on several public\ndatasets of graph classification. The extensive experiments demonstrate that\nour GIC is effective and can achieve the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 11:21:18 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Jiang", "Jiatao", ""], ["Cui", "Zhen", ""], ["Xu", "Chunyan", ""], ["Yang", "Jian", ""]]}, {"id": "1811.04407", "submitter": "Liu Yuezhang", "authors": "Liu Yuezhang, Ruohan Zhang, Dana H. Ballard", "title": "An initial attempt of combining visual selective attention with deep\n  reinforcement learning", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual attention serves as a means of feature selection mechanism in the\nperceptual system. Motivated by Broadbent's leaky filter model of selective\nattention, we evaluate how such mechanism could be implemented and affect the\nlearning process of deep reinforcement learning. We visualize and analyze the\nfeature maps of DQN on a toy problem Catch, and propose an approach to combine\nvisual selective attention with deep reinforcement learning. We experiment with\noptical flow-based attention and A2C on Atari games. Experiment results show\nthat visual selective attention could lead to improvements in terms of sample\nefficiency on tested games. An intriguing relation between attention and batch\nnormalization is also discovered.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 12:22:44 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 07:14:00 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 17:48:44 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Yuezhang", "Liu", ""], ["Zhang", "Ruohan", ""], ["Ballard", "Dana H.", ""]]}, {"id": "1811.04411", "submitter": "Xiaoyu Du", "authors": "Xiangnan He, Jinhui Tang, Xiaoyu Du, Richang Hong, Tongwei Ren and\n  Tat-Seng Chua", "title": "Fast Matrix Factorization with Non-Uniform Weights on Missing Data", "comments": "IEEE Transactions on Neural Networks and Learning Systems (TNNLS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Matrix factorization (MF) has been widely used to discover the low-rank\nstructure and to predict the missing entries of data matrix. In many real-world\nlearning systems, the data matrix can be very high-dimensional but sparse. This\nposes an imbalanced learning problem, since the scale of missing entries is\nusually much larger than that of observed entries, but they cannot be ignored\ndue to the valuable negative signal. For efficiency concern, existing work\ntypically applies a uniform weight on missing entries to allow a fast learning\nalgorithm. However, this simplification will decrease modeling fidelity,\nresulting in suboptimal performance for downstream applications.\n  In this work, we weight the missing data non-uniformly, and more generically,\nwe allow any weighting strategy on the missing data. To address the efficiency\nchallenge, we propose a fast learning method, for which the time complexity is\ndetermined by the number of observed entries in the data matrix, rather than\nthe matrix size. The key idea is two-fold: 1) we apply truncated SVD on the\nweight matrix to get a more compact representation of the weights, and 2) we\nlearn MF parameters with element-wise alternating least squares (eALS) and\nmemorize the key intermediate variables to avoid repeating computations that\nare unnecessary. We conduct extensive experiments on two recommendation\nbenchmarks, demonstrating the correctness, efficiency, and effectiveness of our\nfast eALS method.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 13:17:42 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 07:07:27 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["He", "Xiangnan", ""], ["Tang", "Jinhui", ""], ["Du", "Xiaoyu", ""], ["Hong", "Richang", ""], ["Ren", "Tongwei", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1811.04422", "submitter": "Xiaojin Zhu", "authors": "Xiaojin Zhu", "title": "An Optimal Control View of Adversarial Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe an optimal control view of adversarial machine learning, where the\ndynamical system is the machine learner, the input are adversarial actions, and\nthe control costs are defined by the adversary's goals to do harm and be hard\nto detect. This view encompasses many types of adversarial machine learning,\nincluding test-item attacks, training-data poisoning, and adversarial reward\nshaping. The view encourages adversarial machine learning researcher to utilize\nadvances in control theory and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 14:28:34 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Zhu", "Xiaojin", ""]]}, {"id": "1811.04451", "submitter": "Richard Kurle", "authors": "Richard Kurle and Stephan G\\\"unnemann and Patrick van der Smagt", "title": "Multi-Source Neural Variational Inference", "comments": "AAAI 2019, Association for the Advancement of Artificial Intelligence\n  (AAAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from multiple sources of information is an important problem in\nmachine-learning research. The key challenges are learning representations and\nformulating inference methods that take into account the complementarity and\nredundancy of various information sources. In this paper we formulate a\nvariational autoencoder based multi-source learning framework in which each\nencoder is conditioned on a different information source. This allows us to\nrelate the sources via the shared latent variables by computing divergence\nmeasures between individual source's posterior approximations. We explore a\nvariety of options to learn these encoders and to integrate the beliefs they\ncompute into a consistent posterior approximation. We visualise learned beliefs\non a toy dataset and evaluate our methods for learning shared representations\nand structured output prediction, showing trade-offs of learning separate\nencoders for each information source. Furthermore, we demonstrate how conflict\ndetection and redundancy can increase robustness of inference in a multi-source\nsetting.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 18:59:21 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 13:46:04 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Kurle", "Richard", ""], ["G\u00fcnnemann", "Stephan", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1811.04455", "submitter": "Anthony Nouy", "authors": "Erwan Grelier and Anthony Nouy and Mathilde Chevreuil", "title": "Learning with tree-based tensor formats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the approximation of high-dimensional functions\nin a statistical learning setting, by empirical risk minimization over model\nclasses of functions in tree-based tensor format. These are particular classes\nof rank-structured functions that can be seen as deep neural networks with a\nsparse architecture related to the tree and multilinear activation functions.\nFor learning in a given model class, we exploit the fact that tree-based tensor\nformats are multilinear models and recast the problem of risk minimization over\na nonlinear set into a succession of learning problems with linear models.\nSuitable changes of representation yield numerically stable learning problems\nand allow to exploit sparsity. For high-dimensional problems or when only a\nsmall data set is available, the selection of a good model class is a critical\nissue. For a given tree, the selection of the tuple of tree-based ranks that\nminimize the risk is a combinatorial problem. Here, we propose a rank\nadaptation strategy which provides in practice a good convergence of the risk\nas a function of the model class complexity. Finding a good tree is also a\ncombinatorial problem, which can be related to the choice of a particular\nsparse architecture for deep neural networks. Here, we propose a stochastic\nalgorithm for minimizing the complexity of the representation of a given\nfunction over a class of trees with a given arity, allowing changes in the\ntopology of the tree. This tree optimization algorithm is then included in a\nlearning scheme that successively adapts the tree and the corresponding\ntree-based ranks. Contrary to classical learning algorithms for nonlinear model\nclasses, the proposed algorithms are numerically stable, reliable, and require\nonly a low level expertise of the user.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 19:03:31 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 12:33:34 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Grelier", "Erwan", ""], ["Nouy", "Anthony", ""], ["Chevreuil", "Mathilde", ""]]}, {"id": "1811.04463", "submitter": "Fayyaz Minhas", "authors": "Kanza Hamid, Amina Asif, Wajid Abbasi, Durre Sabih and Fayyaz Minhas", "title": "Machine Learning with Abstention for Automated Liver Disease Diagnosis", "comments": "Preprint version before submission for publication. complete version\n  published in proc. 15th International Conference on Frontiers of Information\n  Technology (FIT 2017), December 18-20, 2017, Islamabad, Pakistan.\n  http://ieeexplore.ieee.org/document/8261064/", "journal-ref": "15th IEEE International Conference on Frontiers of Information\n  Technology (FIT 2017), December 18-20, 2017, Islamabad, Pakistan", "doi": "10.1109/FIT.2017.00070", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for detection of liver abnormalities in\nan automated manner using ultrasound images. For this purpose, we have\nimplemented a machine learning model that can not only generate labels (normal\nand abnormal) for a given ultrasound image but it can also detect when its\nprediction is likely to be incorrect. The proposed model abstains from\ngenerating the label of a test example if it is not confident about its\nprediction. Such behavior is commonly practiced by medical doctors who, when\ngiven insufficient information or a difficult case, can chose to carry out\nfurther clinical or diagnostic tests before generating a diagnosis. However,\nexisting machine learning models are designed in a way to always generate a\nlabel for a given example even when the confidence of their prediction is low.\nWe have proposed a novel stochastic gradient based solver for the learning with\nabstention paradigm and use it to make a practical, state of the art method for\nliver disease classification. The proposed method has been benchmarked on a\ndata set of approximately 100 patients from MINAR, Multan, Pakistan and our\nresults show that the proposed scheme offers state of the art classification\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 19:37:40 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Hamid", "Kanza", ""], ["Asif", "Amina", ""], ["Abbasi", "Wajid", ""], ["Sabih", "Durre", ""], ["Minhas", "Fayyaz", ""]]}, {"id": "1811.04471", "submitter": "Zhen Li", "authors": "Zhen Li, Nicholas J. Meyer, Eric B. Laber, Robert Brigantic", "title": "Thompson Sampling for Pursuit-Evasion Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pursuit-evasion is a multi-agent sequential decision problem wherein a group\nof agents known as pursuers coordinate their traversal of a spatial domain to\nlocate an agent trying to evade them. Pursuit evasion problems arise in a\nnumber of import application domains including defense and route planning.\nLearning to optimally coordinate pursuer behaviors so as to minimize time to\ncapture of the evader is challenging because of a large action space and sparse\nnoisy state information; consequently, previous approaches have relied\nprimarily on heuristics. We propose a variant of Thompson Sampling for\npursuit-evasion that allows for the application of existing model-based\nplanning algorithms. This approach is general in that it allows for an\narbitrary number of pursuers, a general spatial domain, and the integration of\nauxiliary information provided by informants. In a suite of simulation\nexperiments, Thompson Sampling for pursuit evasion significantly reduces\ntime-to-capture relative to competing algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 20:17:01 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Li", "Zhen", ""], ["Meyer", "Nicholas J.", ""], ["Laber", "Eric B.", ""], ["Brigantic", "Robert", ""]]}, {"id": "1811.04475", "submitter": "Shaunak Mishra", "authors": "Anit Kumar Sahu, Shaunak Mishra, Narayan Bhamidipati", "title": "Managing App Install Ad Campaigns in RTB: A Q-Learning Approach", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real time bidding (RTB) enables demand side platforms (bidders) to scale ad\ncampaigns across multiple publishers affiliated to an RTB ad exchange. While\ndriving multiple campaigns for mobile app install ads via RTB, the bidder\ntypically has to: (i) maintain each campaign's efficiency (i.e., meet\nadvertiser's target cost-per-install), (ii) be sensitive to advertiser's\nbudget, and (iii) make profit after payouts to the ad exchange. In this\nprocess, there is a sense of delayed rewards for the bidder's actions; the\nexchange charges the bidder right after the ad is shown, but the bidder gets to\nknow about resultant installs after considerable delay. This makes it\nchallenging for the bidder to decide beforehand the bid (and corresponding cost\ncharged to advertiser) for each ad display opportunity. To jointly handle the\nobjectives mentioned above, we propose a state space based policy which decides\nthe exchange bid and advertiser cost for each opportunity. The state space\ncaptures the current efficiency, budget utilization and profit. The policy\nbased on this state space is trained on past decisions and outcomes via a novel\nQ-learning algorithm which accounts for the delay in install notifications. In\nour experiments based on data from app install campaigns managed by Yahoo's\nGemini advertising platform, the Q-learning based policy led to a significant\nincrease in the profit and number of efficient campaigns.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 20:42:09 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Sahu", "Anit Kumar", ""], ["Mishra", "Shaunak", ""], ["Bhamidipati", "Narayan", ""]]}, {"id": "1811.04477", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Unifying Gaussian LWF and AMP Chain Graphs to Model Interference", "comments": "v2: Section 6 has been added. v3: Sections 7 and 8 have been added.\n  v4: Major reorganization. v5: Major reorganization. v6-v7: Minor changes. v8:\n  Addition of Appendix B. v9: Section 7 has been rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intervention may have an effect on units other than those to which it was\nadministered. This phenomenon is called interference and it usually goes\nunmodeled. In this paper, we propose to combine Lauritzen-Wermuth-Frydenberg\nand Andersson-Madigan-Perlman chain graphs to create a new class of causal\nmodels that can represent both interference and non-interference relationships\nfor Gaussian distributions. Specifically, we define the new class of models,\nintroduce global and local and pairwise Markov properties for them, and prove\ntheir equivalence. We also propose an algorithm for maximum likelihood\nparameter estimation for the new models, and report experimental results.\nFinally, we show how to compute the effects of interventions in the new models.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 20:43:19 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 15:07:45 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2019 22:12:47 GMT"}, {"version": "v4", "created": "Mon, 1 Apr 2019 20:43:27 GMT"}, {"version": "v5", "created": "Mon, 29 Apr 2019 09:57:12 GMT"}, {"version": "v6", "created": "Tue, 30 Apr 2019 14:19:18 GMT"}, {"version": "v7", "created": "Tue, 4 Jun 2019 11:52:31 GMT"}, {"version": "v8", "created": "Sun, 16 Jun 2019 19:34:21 GMT"}, {"version": "v9", "created": "Fri, 5 Jul 2019 10:17:54 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1811.04480", "submitter": "Vahid Noroozi", "authors": "Vahid Noroozi, Sara Bahaadini, Lei Zheng, Sihong Xie, Weixiang Shao,\n  Philip S. Yu", "title": "Semi-supervised Deep Representation Learning for Multi-View Problems", "comments": "Accepted to IEEE Big Data 2018. 9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks for learning representation of multi-view data have\nbeen previously proposed as one of the state-of-the-art multi-view dimension\nreduction techniques, how to make the representation discriminative with only a\nsmall amount of labeled data is not well-studied. We introduce a\nsemi-supervised neural network model, named Multi-view Discriminative Neural\nNetwork (MDNN), for multi-view problems. MDNN finds nonlinear view-specific\nmappings by projecting samples to a common feature space using multiple coupled\ndeep networks. It is capable of leveraging both labeled and unlabeled data to\nproject multi-view data so that samples from different classes are separated\nand those from the same class are clustered together. It also uses the\ninter-view correlation between views to exploit the available information in\nboth the labeled and unlabeled data. Extensive experiments conducted on four\ndatasets demonstrate the effectiveness of the proposed algorithm for multi-view\nsemi-supervised learning.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 20:53:50 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Noroozi", "Vahid", ""], ["Bahaadini", "Sara", ""], ["Zheng", "Lei", ""], ["Xie", "Sihong", ""], ["Shao", "Weixiang", ""], ["Yu", "Philip S.", ""]]}, {"id": "1811.04504", "submitter": "Aaron Mishkin", "authors": "Aaron Mishkin, Frederik Kunstner, Didrik Nielsen, Mark Schmidt and\n  Mohammad Emtiyaz Khan", "title": "SLANG: Fast Structured Covariance Approximations for Bayesian Deep\n  Learning with Natural Gradient", "comments": "NeurIPS 2018 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation in large deep-learning models is a computationally\nchallenging task, where it is difficult to form even a Gaussian approximation\nto the posterior distribution. In such situations, existing methods usually\nresort to a diagonal approximation of the covariance matrix despite, the fact\nthat these matrices are known to result in poor uncertainty estimates. To\naddress this issue, we propose a new stochastic, low-rank, approximate\nnatural-gradient (SLANG) method for variational inference in large, deep\nmodels. Our method estimates a \"diagonal plus low-rank\" structure based solely\non back-propagated gradients of the network log-likelihood. This requires\nstrictly less gradient computations than methods that compute the gradient of\nthe whole variational objective. Empirical evaluations on standard benchmarks\nconfirm that SLANG enables faster and more accurate estimation of uncertainty\nthan mean-field methods, and performs comparably to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 23:18:27 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 01:01:06 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Mishkin", "Aaron", ""], ["Kunstner", "Frederik", ""], ["Nielsen", "Didrik", ""], ["Schmidt", "Mark", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "1811.04539", "submitter": "Apoorva Nandini Saridena", "authors": "Naman Patel, Apoorva Nandini Saridena, Anna Choromanska, Prashanth\n  Krishnamurthy, Farshad Khorrami", "title": "Adversarial Learning-Based On-Line Anomaly Monitoring for Assured\n  Autonomy", "comments": "Proceedings of the 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes an on-line monitoring framework for continuous real-time\nsafety/security in learning-based control systems (specifically application to\na unmanned ground vehicle). We monitor validity of mappings from sensor inputs\nto actuator commands, controller-focused anomaly detection (CFAM), and from\nactuator commands to sensor inputs, system-focused anomaly detection (SFAM).\nCFAM is an image conditioned energy based generative adversarial network\n(EBGAN) in which the energy based discriminator distinguishes between proper\nand anomalous actuator commands. SFAM is based on an action condition video\nprediction framework to detect anomalies between predicted and observed\ntemporal evolution of sensor data. We demonstrate the effectiveness of the\napproach on our autonomous ground vehicle for indoor environments and on\nUdacity dataset for outdoor environments.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 03:33:45 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Patel", "Naman", ""], ["Saridena", "Apoorva Nandini", ""], ["Choromanska", "Anna", ""], ["Krishnamurthy", "Prashanth", ""], ["Khorrami", "Farshad", ""]]}, {"id": "1811.04548", "submitter": "Liu Jiang", "authors": "Liu Jiang, Shixia Liu, Changjian Chen", "title": "Recent Research Advances on Interactive Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Machine Learning (IML) is an iterative learning process that\ntightly couples a human with a machine learner, which is widely used by\nresearchers and practitioners to effectively solve a wide variety of real-world\napplication problems. Although recent years have witnessed the proliferation of\nIML in the field of visual analytics, most recent surveys either focus on a\nspecific area of IML or aim to summarize a visualization field that is too\ngeneric for IML. In this paper, we systematically review the recent literature\non IML and classify them into a task-oriented taxonomy built by us. We conclude\nthe survey with a discussion of open challenges and research opportunities that\nwe believe are inspiring for future work in IML.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 04:07:46 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Jiang", "Liu", ""], ["Liu", "Shixia", ""], ["Chen", "Changjian", ""]]}, {"id": "1811.04551", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David\n  Ha, Honglak Lee, James Davidson", "title": "Learning Latent Dynamics for Planning from Pixels", "comments": "20 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning has been very successful for control tasks with known environment\ndynamics. To leverage planning in unknown environments, the agent needs to\nlearn the dynamics from interactions with the world. However, learning dynamics\nmodels that are accurate enough for planning has been a long-standing\nchallenge, especially in image-based domains. We propose the Deep Planning\nNetwork (PlaNet), a purely model-based agent that learns the environment\ndynamics from images and chooses actions through fast online planning in latent\nspace. To achieve high performance, the dynamics model must accurately predict\nthe rewards ahead for multiple time steps. We approach this using a latent\ndynamics model with both deterministic and stochastic transition components.\nMoreover, we propose a multi-step variational inference objective that we name\nlatent overshooting. Using only pixel observations, our agent solves continuous\ncontrol tasks with contact dynamics, partial observability, and sparse rewards,\nwhich exceed the difficulty of tasks that were previously solved by planning\nwith learned models. PlaNet uses substantially fewer episodes and reaches final\nperformance close to and sometimes higher than strong model-free algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 04:30:10 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 22:21:00 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 19:12:41 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 18:28:53 GMT"}, {"version": "v5", "created": "Tue, 4 Jun 2019 18:13:09 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hafner", "Danijar", ""], ["Lillicrap", "Timothy", ""], ["Fischer", "Ian", ""], ["Villegas", "Ruben", ""], ["Ha", "David", ""], ["Lee", "Honglak", ""], ["Davidson", "James", ""]]}, {"id": "1811.04568", "submitter": "Hiroshi Seki", "authors": "Hiroshi Seki, Takaaki Hori, Shinji Watanabe", "title": "Vectorization of hypotheses and speech for faster beam search in encoder\n  decoder-based speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based encoder decoder network uses a left-to-right beam search\nalgorithm in the inference step. The current beam search expands hypotheses and\ntraverses the expanded hypotheses at the next time step. This traversal is\nimplemented using a for-loop program in general, and it leads to speed down of\nthe recognition process. In this paper, we propose a parallelism technique for\nbeam search, which accelerates the search process by vectorizing multiple\nhypotheses to eliminate the for-loop program. We also propose a technique to\nbatch multiple speech utterances for off-line recognition use, which reduces\nthe for-loop program with regard to the traverse of multiple utterances. This\nextension is not trivial during beam search unlike during training due to\nseveral pruning and thresholding techniques for efficient decoding. In\naddition, our method can combine scores of external modules, RNNLM and CTC, in\na batch as shallow fusion. We achieved 3.7 x speedup compared with the original\nbeam search algorithm by vectoring hypotheses, and achieved 10.5 x speedup by\nfurther changing processing unit to GPU.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 06:02:19 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Seki", "Hiroshi", ""], ["Hori", "Takaaki", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1811.04576", "submitter": "Yasuhiro Ikeda", "authors": "Yasuhiro Ikeda, Kengo Tajiri, Yuusuke Nakano, Keishiro Watanabe,\n  Keisuke Ishibashi", "title": "Estimation of Dimensions Contributing to Detected Anomalies with\n  Variational Autoencoders", "comments": null, "journal-ref": "AAAI-19 Workshop on Network Interpretability for Deep Learning,\n  2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection using dimensionality reduction has been an essential\ntechnique for monitoring multidimensional data. Although deep learning-based\nmethods have been well studied for their remarkable detection performance,\ntheir interpretability is still a problem. In this paper, we propose a novel\nalgorithm for estimating the dimensions contributing to the detected anomalies\nby using variational autoencoders (VAEs). Our algorithm is based on an\napproximative probabilistic model that considers the existence of anomalies in\nthe data, and by maximizing the log-likelihood, we estimate which dimensions\ncontribute to determining data as an anomaly. The experiments results with\nbenchmark datasets show that our algorithm extracts the contributing dimensions\nmore accurately than baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 06:36:52 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 02:32:05 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Ikeda", "Yasuhiro", ""], ["Tajiri", "Kengo", ""], ["Nakano", "Yuusuke", ""], ["Watanabe", "Keishiro", ""], ["Ishibashi", "Keisuke", ""]]}, {"id": "1811.04624", "submitter": "V\\'ictor Campos", "authors": "V\\'ictor Campos, Xavier Giro-i-Nieto, Jordi Torres", "title": "Importance Weighted Evolution Strategies", "comments": "NIPS Deep Reinforcement Learning Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution Strategies (ES) emerged as a scalable alternative to popular\nReinforcement Learning (RL) techniques, providing an almost perfect speedup\nwhen distributed across hundreds of CPU cores thanks to a reduced communication\noverhead. Despite providing large improvements in wall-clock time, ES is data\ninefficient when compared to competing RL methods. One of the main causes of\nsuch inefficiency is the collection of large batches of experience, which are\ndiscarded after each policy update. In this work, we study how to perform more\nthan one update per batch of experience by means of Importance Sampling while\npreserving the scalability of the original method. The proposed method,\nImportance Weighted Evolution Strategies (IW-ES), shows promising results and\nis a first step towards designing efficient ES algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 09:44:50 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Campos", "V\u00edctor", ""], ["Giro-i-Nieto", "Xavier", ""], ["Torres", "Jordi", ""]]}, {"id": "1811.04634", "submitter": "Firat Ozdemir", "authors": "Firat Ozdemir, Orcun Goksel", "title": "Extending Pretrained Segmentation Networks with Additional Anatomical\n  Structures", "comments": "Published in IJCARS. 8 pages, 4 figures, contains supplementary\n  material", "journal-ref": "International Journal of Computer Assisted Radiology and Surgery,\n  2 May 2019, issn 1861-6429", "doi": "10.1007/s11548-019-01984-4", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensive surgical planning require complex patient-specific anatomical\nmodels. For instance, functional muskuloskeletal simulations necessitate all\nrelevant structures to be segmented, which could be performed in real-time\nusing deep neural networks given sufficient annotated samples. Such large\ndatasets of multiple structure annotations are costly to procure and are often\nunavailable in practice. Nevertheless, annotations from different studies and\ncenters can be readily available, or become available in the future in an\nincremental fashion. We propose a class-incremental segmentation framework for\nextending a deep network trained for some anatomical structure to yet another\nstructure using a small incremental annotation set. Through distilling\nknowledge from the current state of the framework, we bypass the need for a\nfull retraining. This is a meta-method to extend any choice of desired deep\nsegmentation network with only a minor addition per structure, which makes it\nsuitable for lifelong class-incremental learning and applicable also for future\ndeep neural network architectures. We evaluated our methods on a public knee\ndataset of 100 MR volumes. Through varying amount of incremental annotation\nratios, we show how our proposed method can retain the previous anatomical\nstructure segmentation performance superior to the conventional finetuning\napproach. In addition, our framework inherently exploits transferable knowledge\nfrom previously trained structures to incremental tasks, demonstrated by\nsuperior results compared to non-incremental training. With the presented\nmethod, new anatomical structures can be learned without catastrophic\nforgetting of older structures and without extensive increase of memory and\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 09:58:07 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 12:31:38 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Ozdemir", "Firat", ""], ["Goksel", "Orcun", ""]]}, {"id": "1811.04644", "submitter": "Jialin Dong", "authors": "Jialin Dong, Yuanming Shi, Zhi Ding", "title": "Blind Over-the-Air Computation and Data Fusion via Provable Wirtinger\n  Flow", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-the-air computation (AirComp) shows great promise to support fast data\nfusion in Internet-of-Things (IoT) networks. AirComp typically computes desired\nfunctions of distributed sensing data by exploiting superposed data\ntransmission in multiple access channels. To overcome its reliance on channel\nstation information (CSI), this work proposes a novel blind over-the-air\ncomputation (BlairComp) without requiring CSI access, particularly for low\ncomplexity and low latency IoT networks. To solve the resulting non-convex\noptimization problem without the initialization dependency exhibited by the\nsolutions of a number of recently proposed efficient algorithms, we develop a\nWirtinger flow solution to the BlairComp problem based on random\ninitialization. To analyze the resulting efficiency, we prove its statistical\noptimality and global convergence guarantee. Specifically, in the first stage\nof the algorithm, the iteration of randomly initialized Wirtinger flow given\nsufficient data samples can enter a local region that enjoys strong convexity\nand strong smoothness within a few iterations. We also prove the estimation\nerror of BlairComp in the local region to be sufficiently small. We show that,\nat the second stage of the algorithm, its estimation error decays exponentially\nat a linear convergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 10:38:07 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Dong", "Jialin", ""], ["Shi", "Yuanming", ""], ["Ding", "Zhi", ""]]}, {"id": "1811.04646", "submitter": "Adrien Spagnol", "authors": "Adrien Spagnol, Rodolphe Le Riche and Sebastien Da Veiga", "title": "Global sensitivity analysis for optimization with variable selection", "comments": null, "journal-ref": "SIAM/ASA Journal on Uncertainty Quantification, ASA, American\n  Statistical Association, 2019", "doi": "10.1137/18M1167978", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimization of high dimensional functions is a key issue in engineering\nproblems but it frequently comes at a cost that is not acceptable since it\nusually involves a complex and expensive computer code. Engineers often\novercome this limitation by first identifying which parameters drive the most\nthe function variations: non-influential variables are set to a fixed value and\nthe optimization procedure is carried out with the remaining influential\nvariables. Such variable selection is performed through influence measures that\nare meaningful for regression problems. However it does not account for the\nspecific structure of optimization problems where we would like to identify\nwhich variables most lead to constraints satisfaction and low values of the\nobjective function. In this paper, we propose a new sensitivity analysis that\naccounts for the specific aspects of optimization problems. In particular, we\nintroduce an influence measure based on the Hilbert-Schmidt Independence\nCriterion to characterize whether a design variable matters to reach low values\nof the objective function and to satisfy the constraints. This sensitivity\nmeasure makes it possible to sort the inputs and reduce the problem dimension.\nWe compare a random and a greedy strategies to set the values of the\nnon-influential variables before conducting a local optimization. Applications\nto several test-cases show that this variable selection and the greedy strategy\nsignificantly reduce the number of function evaluations at a limited cost in\nterms of solution performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 10:41:20 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Spagnol", "Adrien", ""], ["Riche", "Rodolphe Le", ""], ["Da Veiga", "Sebastien", ""]]}, {"id": "1811.04662", "submitter": "Navin Cooray", "authors": "Navin Cooray (1), Fernando Andreotti (1), Christine Lo (2), Mkael\n  Symmonds (3), Michele T.M. Hu (2) and Maarten De Vos (1) ((1) University of\n  Oxford, Institute of Biomedical Engineering, Dept. Engineering Sciences,\n  Oxford, UK, (2) Nuffield Department of Clinical Neurosciences, Oxford\n  Parkinson's Disease Centre (OPDC), University of Oxford, UK, (3) Department\n  of Clinical Neurophysiology, Oxford University Hospitals, John Radcliffe\n  Hospital, University of Oxford, UK)", "title": "Detection of REM Sleep Behaviour Disorder by Automated Polysomnography\n  Analysis", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evidence suggests Rapid-Eye-Movement (REM) Sleep Behaviour Disorder (RBD) is\nan early predictor of Parkinson's disease. This study proposes a\nfully-automated framework for RBD detection consisting of automated sleep\nstaging followed by RBD identification. Analysis was assessed using a limited\npolysomnography montage from 53 participants with RBD and 53 age-matched\nhealthy controls. Sleep stage classification was achieved using a Random Forest\n(RF) classifier and 156 features extracted from electroencephalogram (EEG),\nelectrooculogram (EOG) and electromyogram (EMG) channels. For RBD detection, a\nRF classifier was trained combining established techniques to quantify muscle\natonia with additional features that incorporate sleep architecture and the EMG\nfractal exponent. Automated multi-state sleep staging achieved a 0.62 Cohen's\nKappa score. RBD detection accuracy improved by 10% to 96% (compared to\nindividual established metrics) when using manually annotated sleep staging.\nAccuracy remained high (92%) when using automated sleep staging. This study\noutperforms established metrics and demonstrates that incorporating sleep\narchitecture and sleep stage transitions can benefit RBD detection. This study\nalso achieved automated sleep staging with a level of accuracy comparable to\nmanual annotation. This study validates a tractable, fully-automated, and\nsensitive pipeline for RBD identification that could be translated to wearable\ntake-home technology.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 11:13:51 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Cooray", "Navin", ""], ["Andreotti", "Fernando", ""], ["Lo", "Christine", ""], ["Symmonds", "Mkael", ""], ["Hu", "Michele T. M.", ""], ["De Vos", "Maarten", ""]]}, {"id": "1811.04689", "submitter": "Che-Ping Tsai", "authors": "Che-Ping Tsai, Hung-Yi Lee", "title": "Adversarial Learning of Label Dependency: A Novel Framework for\n  Multi-class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that exploiting relations between labels improves the\nperformance of multi-label classification. We propose a novel framework based\non generative adversarial networks (GANs) to model label dependency. The\ndiscriminator learns to model label dependency by discriminating real and\ngenerated label sets. To fool the discriminator, the classifier, or generator,\nlearns to generate label sets with dependencies close to real data. Extensive\nexperiments and comparisons on two large-scale image classification benchmark\ndatasets (MS-COCO and NUS-WIDE) show that the discriminator improves\ngeneralization ability for different kinds of models\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 12:29:17 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Tsai", "Che-Ping", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1811.04713", "submitter": "Michael Chertkov", "authors": "Michael Chertkov, Vladimir Chernyak and Yury Maximov", "title": "Gauges, Loops, and Polynomials for Partition Functions of Graphical\n  Models", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-18-30593", "categories": "cs.LG math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models represent multivariate and generally not normalized\nprobability distributions. Computing the normalization factor, called the\npartition function, is the main inference challenge relevant to multiple\nstatistical and optimization applications. The problem is of an exponential\ncomplexity with respect to the number of variables. In this manuscript, aimed\nat approximating the PF, we consider Multi-Graph Models where binary variables\nand multivariable factors are associated with edges and nodes, respectively, of\nan undirected multi-graph. We suggest a new methodology for analysis and\ncomputations that combines the Gauge Function technique with the technique from\nthe field of real stable polynomials. We show that the Gauge Function has a\nnatural polynomial representation in terms of gauges/variables associated with\nedges of the multi-graph. Moreover, it can be used to recover the Partition\nFunction through a sequence of transformations allowing appealing algebraic and\ngraphical interpretations. Algebraically, one step in the sequence consists in\napplication of a differential operator over gauges associated with an edge.\nGraphically, the sequence is interpreted as a repetitive elimination of edges\nresulting in a sequence of models on decreasing in size graphs with the same\nPartition Function. Even though complexity of computing factors in the sequence\nmodels grow exponentially with the number of eliminated edges, polynomials\nassociated with the new factors remain bi-stable if the original factors have\nthis property. Moreover, we show that Belief Propagation estimations in the\nsequence do not decrease, each low-bounding the Partition Function.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 13:27:42 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 18:07:08 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 13:15:04 GMT"}, {"version": "v4", "created": "Sun, 6 Jan 2019 06:41:58 GMT"}, {"version": "v5", "created": "Mon, 1 Apr 2019 02:24:32 GMT"}, {"version": "v6", "created": "Fri, 28 Aug 2020 20:52:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chertkov", "Michael", ""], ["Chernyak", "Vladimir", ""], ["Maximov", "Yury", ""]]}, {"id": "1811.04727", "submitter": "Robert Walecki Mr", "authors": "Robert Walecki, Albert Buchard, Kostis Gourgoulias, Chris Hart, Maria\n  Lomeli, A. K. W. Navarro, Max Zwiessele, Yura Perov, Saurabh Johri", "title": "Universal Marginalizer for Amortised Inference and Embedding of\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models are powerful tools which allow us to formalise\nour knowledge about the world and reason about its inherent uncertainty. There\nexist a considerable number of methods for performing inference in\nprobabilistic graphical models; however, they can be computationally costly due\nto significant time burden and/or storage requirements; or they lack\ntheoretical guarantees of convergence and accuracy when applied to large scale\ngraphical models. To this end, we propose the Universal Marginaliser Importance\nSampler (UM-IS) -- a hybrid inference scheme that combines the flexibility of a\ndeep neural network trained on samples from the model and inherits the\nasymptotic guarantees of importance sampling. We show how combining samples\ndrawn from the graphical model with an appropriate masking function allows us\nto train a single neural network to approximate any of the corresponding\nconditional marginal distributions, and thus amortise the cost of inference. We\nalso show that the graph embeddings can be applied for tasks such as:\nclustering, classification and interpretation of relationships between the\nnodes. Finally, we benchmark the method on a large graph (>1000 nodes), showing\nthat UM-IS outperforms sampling-based methods by a large margin while being\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 13:55:15 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Walecki", "Robert", ""], ["Buchard", "Albert", ""], ["Gourgoulias", "Kostis", ""], ["Hart", "Chris", ""], ["Lomeli", "Maria", ""], ["Navarro", "A. K. W.", ""], ["Zwiessele", "Max", ""], ["Perov", "Yura", ""], ["Johri", "Saurabh", ""]]}, {"id": "1811.04745", "submitter": "Xiaolei Ma", "authors": "Xiaolei Ma, Yi Li, Zhiyong Cui, Yinhai Wang", "title": "Forecasting Transportation Network Speed Using Deep Capsule Networks\n  with Nested LSTM Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and reliable traffic forecasting for complicated transportation\nnetworks is of vital importance to modern transportation management. The\ncomplicated spatial dependencies of roadway links and the dynamic temporal\npatterns of traffic states make it particularly challenging. To address these\nchallenges, we propose a new capsule network (CapsNet) to extract the spatial\nfeatures of traffic networks and utilize a nested LSTM (NLSTM) structure to\ncapture the hierarchical temporal dependencies in traffic sequence data. A\nframework for network-level traffic forecasting is also proposed by\nsequentially connecting CapsNet and NLSTM. On the basis of literature review,\nour study is the first to adopt CapsNet and NLSTM in the field of traffic\nforecasting. An experiment on a Beijing transportation network with 278 links\nshows that the proposed framework with the capability of capturing complicated\nspatiotemporal traffic patterns outperforms multiple state-of-the-art traffic\nforecasting baseline models. The superiority and feasibility of CapsNet and\nNLSTM are also demonstrated, respectively, by visualizing and quantitatively\nevaluating the experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 01:13:32 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Ma", "Xiaolei", ""], ["Li", "Yi", ""], ["Cui", "Zhiyong", ""], ["Wang", "Yinhai", ""]]}, {"id": "1811.04751", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Gaussian AutoEncoder", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative AutoEncoders require a chosen probability distribution in latent\nspace, usually multivariate Gaussian. The original Variational AutoEncoder\n(VAE) uses randomness in encoder - causing problematic distortion, and overlaps\nin latent space for distinct inputs. It turned out unnecessary: we can instead\nuse deterministic encoder with additional regularizer to ensure that sample\ndistribution in latent space is close to the required. The original approach\n(WAE) uses Wasserstein metric, what required comparing with random sample and\nusing an arbitrarily chosen kernel. Later CWAE finally derived a non-random\nanalytic formula by averaging $L_2$ distance of Gaussian-smoothened sample over\nall 1D projections. However, these arbitrarily chosen regularizers do not lead\nto Gaussian distribution.\n  This article proposes approach for regularizers directly optimizing agreement\nbetween empirical distribution function and its desired CDF for chosen\nproperties, for example radii and distances for Gaussian distribution, or\ncoordinate-wise, to directly attract this distribution in latent space of\nAutoEncoder. We can also attract different distributions with this general\napproach, for example latent space uniform distribution on $[0,1]^D$ hypercube\nor torus would allow for data compression without entropy coding, increased\ndensity near codewords would optimize for the required quantization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 14:49:19 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 16:25:12 GMT"}, {"version": "v3", "created": "Wed, 26 Dec 2018 14:39:33 GMT"}, {"version": "v4", "created": "Mon, 14 Jan 2019 13:14:21 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1811.04752", "submitter": "Brandon Malone", "authors": "Brandon Malone, Alberto Garcia-Duran, and Mathias Niepert", "title": "Learning Representations of Missing Data for Predicting Patient Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting actionable insight from Electronic Health Records (EHRs) poses\nseveral challenges for traditional machine learning approaches. Patients are\noften missing data relative to each other; the data comes in a variety of\nmodalities, such as multivariate time series, free text, and categorical\ndemographic information; important relationships among patients can be\ndifficult to detect; and many others. In this work, we propose a novel approach\nto address these first three challenges using a representation learning scheme\nbased on message passing. We show that our proposed approach is competitive\nwith or outperforms the state of the art for predicting in-hospital mortality\n(binary classification), the length of hospital visits (regression) and the\ndischarge destination (multiclass classification).\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 14:51:41 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Malone", "Brandon", ""], ["Garcia-Duran", "Alberto", ""], ["Niepert", "Mathias", ""]]}, {"id": "1811.04759", "submitter": "Gherardo Varando", "authors": "Gherardo Varando and Concha Bielza and Pedro Larra\\~naga and Eva\n  Riccomagno", "title": "Markov Property in Generative Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that, for generative classifiers, conditional independence\ncorresponds to linear constraints for the induced discrimination functions.\nDiscrimination functions of undirected Markov network classifiers can thus be\ncharacterized by sets of linear constraints. These constraints are represented\nby a second order finite difference operator over functions of categorical\nvariables. As an application we study the expressive power of generative\nclassifiers under the undirected Markov property and we present a general\nmethod to combine discriminative and generative classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 15:02:49 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Varando", "Gherardo", ""], ["Bielza", "Concha", ""], ["Larra\u00f1aga", "Pedro", ""], ["Riccomagno", "Eva", ""]]}, {"id": "1811.04770", "submitter": "Bradley McDanel", "authors": "H. T. Kung and Bradley McDanel and Sai Qian Zhang", "title": "Packing Sparse Convolutional Neural Networks for Efficient Systolic\n  Array Implementations: Column Combining Under Joint Optimization", "comments": "To appear in ASPLOS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel approach of packing sparse convolutional neural\nnetworks for their efficient systolic array implementations. By combining\nsubsets of columns in the original filter matrix associated with a\nconvolutional layer, we increase the utilization efficiency of the systolic\narray substantially (e.g., ~4x) due to the increased density of nonzeros in the\nresulting packed filter matrix. In combining columns, for each row, all filter\nweights but one with the largest magnitude are pruned. We retrain the remaining\nweights to preserve high accuracy. We demonstrate that in mitigating data\nprivacy concerns the retraining can be accomplished with only fractions of the\noriginal dataset (e.g., 10\\% for CIFAR-10). We study the effectiveness of this\njoint optimization for both high utilization and classification accuracy with\nASIC and FPGA designs based on efficient bit-serial implementations of\nmultiplier-accumulators. We present analysis and empirical evidence on the\nsuperior performance of our column combining approach against prior arts under\nmetrics such as energy efficiency (3x) and inference latency (12x).\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 23:09:31 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Kung", "H. T.", ""], ["McDanel", "Bradley", ""], ["Zhang", "Sai Qian", ""]]}, {"id": "1811.04784", "submitter": "Tim Verbelen", "authors": "Xander Steenbrugge, Sam Leroux, Tim Verbelen, Bart Dhoedt", "title": "Improving Generalization for Abstract Reasoning Tasks Using Disentangled\n  Feature Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the generalization characteristics of unsupervised\nrepresentation learning by leveraging disentangled VAE's to learn a useful\nlatent space on a set of relational reasoning problems derived from Raven\nProgressive Matrices. We show that the latent representations, learned by\nunsupervised training using the right objective function, significantly\noutperform the same architectures trained with purely supervised learning,\nespecially when it comes to generalization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 15:23:26 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Steenbrugge", "Xander", ""], ["Leroux", "Sam", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1811.04788", "submitter": "Sourish Das", "authors": "Rajiv Sambasivan and Sourish Das and Sujit K Sahu", "title": "A Bayesian Perspective of Statistical Machine Learning for Big Data", "comments": "26 pages, 3 figures, Review paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical Machine Learning (SML) refers to a body of algorithms and methods\nby which computers are allowed to discover important features of input data\nsets which are often very large in size. The very task of feature discovery\nfrom data is essentially the meaning of the keyword `learning' in SML.\nTheoretical justifications for the effectiveness of the SML algorithms are\nunderpinned by sound principles from different disciplines, such as Computer\nScience and Statistics. The theoretical underpinnings particularly justified by\nstatistical inference methods are together termed as statistical learning\ntheory.\n  This paper provides a review of SML from a Bayesian decision theoretic point\nof view -- where we argue that many SML techniques are closely connected to\nmaking inference by using the so called Bayesian paradigm. We discuss many\nimportant SML techniques such as supervised and unsupervised learning, deep\nlearning, online learning and Gaussian processes especially in the context of\nvery large data sets where these are often employed. We present a dictionary\nwhich maps the key concepts of SML from Computer Science and Statistics. We\nillustrate the SML techniques with three moderately large data sets where we\nalso discuss many practical implementation issues. Thus the review is\nespecially targeted at statisticians and computer scientists who are aspiring\nto understand and apply SML for moderately large to big data sets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 14:26:55 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 01:43:53 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Sambasivan", "Rajiv", ""], ["Das", "Sourish", ""], ["Sahu", "Sujit K", ""]]}, {"id": "1811.04803", "submitter": "Mark Chilenski", "authors": "Mark Chilenski, George Cybenko, Isaac Dekine, Piyush Kumar, Gil Raz", "title": "Observability Properties of Colored Graphs", "comments": "13 pages, 17 figures", "journal-ref": null, "doi": "10.1109/TNSE.2019.2948474", "report-no": null, "categories": "cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A colored graph is a directed graph in which nodes or edges have been\nassigned colors that are not necessarily unique. Observability problems in such\ngraphs consider whether an agent observing the colors of edges or nodes\ntraversed on a path in the graph can determine which node they are at currently\nor which nodes were visited earlier in the traversal. Previous research efforts\nhave identified several different notions of observability as well as the\nassociated properties of graphs for which those observability properties hold.\nThis paper unifies the prior work into a common framework with several new\nresults about relationships between those notions and associated graph\nproperties. The new framework provides an intuitive way to reason about the\nattainable accuracy as a function of lag and time spent observing, and\nidentifies simple modifications to improve the observability of a given graph.\nWe show that one form of the graph modification problem is in NP-Complete. The\nintuition of the new framework is borne out with numerical experiments. This\nwork has implications for problems that can be described in terms of an agent\ntraversing a colored graph, including the reconstruction of hidden states in a\nhidden Markov model (HMM).\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 15:12:24 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 21:31:06 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Chilenski", "Mark", ""], ["Cybenko", "George", ""], ["Dekine", "Isaac", ""], ["Kumar", "Piyush", ""], ["Raz", "Gil", ""]]}, {"id": "1811.04820", "submitter": "Jessa Bekker", "authors": "Jessa Bekker and Jesse Davis", "title": "Learning from positive and unlabeled data: a survey", "comments": "There was a typo in section 2.4. The fraction of labeled examples in\n  the single-training-set scenario should be \\alpha c, and not \\alpha e(x) as\n  was written in the previous version", "journal-ref": "Machine Learning (2020) 1-42", "doi": "10.1007/s10994-020-05877-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from positive and unlabeled data or PU learning is the setting where\na learner only has access to positive examples and unlabeled data. The\nassumption is that the unlabeled data can contain both positive and negative\nexamples. This setting has attracted increasing interest within the machine\nlearning literature as this type of data naturally arises in applications such\nas medical diagnosis and knowledge base completion. This article provides a\nsurvey of the current state of the art in PU learning. It proposes seven key\nresearch questions that commonly arise in this field and provides a broad\noverview of how the field has tried to address them.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 16:00:36 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 11:31:44 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 10:33:23 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Bekker", "Jessa", ""], ["Davis", "Jesse", ""]]}, {"id": "1811.04890", "submitter": "Zhao Wang", "authors": "Zhao Wang and Aron Culotta", "title": "When do Words Matter? Understanding the Impact of Lexical Choice on\n  Audience Perception using Individual Treatment Effect Estimation", "comments": "AAAI_2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies across many disciplines have shown that lexical choice can affect\naudience perception. For example, how users describe themselves in a social\nmedia profile can affect their perceived socio-economic status. However, we\nlack general methods for estimating the causal effect of lexical choice on the\nperception of a specific sentence. While randomized controlled trials may\nprovide good estimates, they do not scale to the potentially millions of\ncomparisons necessary to consider all lexical choices. Instead, in this paper,\nwe first offer two classes of methods to estimate the effect on perception of\nchanging one word to another in a given sentence. The first class of algorithms\nbuilds upon quasi-experimental designs to estimate individual treatment effects\nfrom observational data. The second class treats treatment effect estimation as\na classification problem. We conduct experiments with three data sources (Yelp,\nTwitter, and Airbnb), finding that the algorithmic estimates align well with\nthose produced by randomized-control trials. Additionally, we find that it is\npossible to transfer treatment effect classifiers across domains and still\nmaintain high accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 18:13:40 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 02:53:17 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 01:25:30 GMT"}, {"version": "v4", "created": "Thu, 15 Nov 2018 03:49:36 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wang", "Zhao", ""], ["Culotta", "Aron", ""]]}, {"id": "1811.04911", "submitter": "Chang Liu", "authors": "Sophia Collet, Robert Dadashi, Zahi N. Karam, Chang Liu, Parinaz\n  Sobhani, Yevgeniy Vahlis, Ji Chao Zhang", "title": "Boosting Model Performance through Differentially Private Model\n  Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key factor in developing high performing machine learning models is the\navailability of sufficiently large datasets. This work is motivated by\napplications arising in Software as a Service (SaaS) companies where there\nexist numerous similar yet disjoint datasets from multiple client companies. To\novercome the challenges of insufficient data without explicitly aggregating the\nclients' datasets due to privacy concerns, one solution is to collect more data\nfor each individual client, another is to privately aggregate information from\nmodels trained on each client's data. In this work, two approaches for private\nmodel aggregation are proposed that enable the transfer of knowledge from\nexisting models trained on other companies' datasets to a new company with\nlimited labeled data while protecting each client company's underlying\nindividual sensitive information. The two proposed approaches are based on\nstate-of-the-art private learning algorithms: Differentially Private\nPermutation-based Stochastic Gradient Descent and Approximate Minima\nPerturbation. We empirically show that by leveraging differentially private\ntechniques, we can enable private model aggregation and augment data utility\nwhile providing provable mathematical guarantees on privacy. The proposed\nmethods thus provide significant business value for SaaS companies and their\nclients, specifically as a solution for the cold-start problem.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 18:50:17 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 17:48:03 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Collet", "Sophia", ""], ["Dadashi", "Robert", ""], ["Karam", "Zahi N.", ""], ["Liu", "Chang", ""], ["Sobhani", "Parinaz", ""], ["Vahlis", "Yevgeniy", ""], ["Zhang", "Ji Chao", ""]]}, {"id": "1811.04918", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li and Yingyu Liang", "title": "Learning and Generalization in Overparameterized Neural Networks, Going\n  Beyond Two Layers", "comments": "V1/V2/V3/V4 polish writing, V5 adds experiments, V6 reflects our\n  camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental learning theory behind neural networks remains largely open.\nWhat classes of functions can neural networks actually learn? Why doesn't the\ntrained network overfit when it is overparameterized?\n  In this work, we prove that overparameterized neural networks can learn some\nnotable concept classes, including two and three-layer networks with fewer\nparameters and smooth activations. Moreover, the learning can be simply done by\nSGD (stochastic gradient descent) or its variants in polynomial time using\npolynomially many samples. The sample complexity can also be almost independent\nof the number of parameters in the network.\n  On the technique side, our analysis goes beyond the so-called NTK (neural\ntangent kernel) linearization of neural networks in prior works. We establish a\nnew notion of quadratic approximation of the neural network (that can be viewed\nas a second-order variant of NTK), and connect it to the SGD theory of escaping\nsaddle points.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 18:57:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 15:56:01 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 04:10:51 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 17:09:46 GMT"}, {"version": "v5", "created": "Tue, 28 May 2019 10:25:09 GMT"}, {"version": "v6", "created": "Mon, 1 Jun 2020 17:11:51 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""], ["Liang", "Yingyu", ""]]}, {"id": "1811.04973", "submitter": "Ehsan Kazemi", "authors": "Soheil Ghili and Ehsan Kazemi and Amin Karbasi", "title": "Eliminating Latent Discrimination: Train Then Mask", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we control for latent discrimination in predictive models? How can we\nprovably remove it? Such questions are at the heart of algorithmic fairness and\nits impacts on society. In this paper, we define a new operational fairness\ncriteria, inspired by the well-understood notion of omitted variable-bias in\nstatistics and econometrics. Our notion of fairness effectively controls for\nsensitive features and provides diagnostics for deviations from fair decision\nmaking. We then establish analytical and algorithmic results about the\nexistence of a fair classifier in the context of supervised learning. Our\nresults readily imply a simple, but rather counter-intuitive, strategy for\neliminating latent discrimination. In order to prevent other features proxying\nfor sensitive features, we need to include sensitive features in the training\nphase, but exclude them in the test/evaluation phase while controlling for\ntheir effects. We evaluate the performance of our algorithm on several\nreal-world datasets and show how fairness for these datasets can be improved\nwith a very small loss in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 19:25:05 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 22:25:55 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Ghili", "Soheil", ""], ["Kazemi", "Ehsan", ""], ["Karbasi", "Amin", ""]]}, {"id": "1811.04985", "submitter": "Aswin Raghavan", "authors": "Samyak Parajuli, Aswin Raghavan, Sek Chai", "title": "Generalized Ternary Connect: End-to-End Learning and Compression of\n  Multiplication-Free Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep neural networks in edge computing devices hinges on the\nbalance between accuracy and complexity of computations. Ternary Connect (TC)\n\\cite{lin2015neural} addresses this issue by restricting the parameters to\nthree levels $-1, 0$, and $+1$, thus eliminating multiplications in the forward\npass of the network during prediction. We propose Generalized Ternary Connect\n(GTC), which allows an arbitrary number of levels while at the same time\neliminating multiplications by restricting the parameters to integer powers of\ntwo. The primary contribution is that GTC learns the number of levels and their\nvalues for each layer, jointly with the weights of the network in an end-to-end\nfashion. Experiments on MNIST and CIFAR-10 show that GTC naturally converges to\nan `almost binary' network for deep classification networks (e.g. VGG-16) and\ndeep variational auto-encoders, with negligible loss of classification accuracy\nand comparable visual quality of generated samples respectively. We demonstrate\nsuperior compression and similar accuracy of GTC in comparison to several\nstate-of-the-art methods for neural network compression. We conclude with\nsimulations showing the potential benefits of GTC in hardware.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 20:08:00 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Parajuli", "Samyak", ""], ["Raghavan", "Aswin", ""], ["Chai", "Sek", ""]]}, {"id": "1811.05010", "submitter": "Long Nguyen Msc", "authors": "Long Nguyen, Zhou Yang, Jiazhen Zhu, Jia Li, Fang Jin", "title": "Coordinating Disaster Emergency Response with Heuristic Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial and time-sensitive task when any disaster occurs is to rescue\nvictims and distribute resources to the right groups and locations. This task\nis challenging in populated urban areas, due to the huge burst of help requests\ngenerated in a very short period. To improve the efficiency of the emergency\nresponse in the immediate aftermath of a disaster, we propose a heuristic\nmulti-agent reinforcement learning scheduling algorithm, named as ResQ, which\ncan effectively schedule the rapid deployment of volunteers to rescue victims\nin dynamic settings. The core concept is to quickly identify victims and\nvolunteers from social network data and then schedule rescue parties with an\nadaptive learning algorithm. This framework performs two key functions: 1)\nidentify trapped victims and rescue volunteers, and 2) optimize the volunteers'\nrescue strategy in a complex time-sensitive environment. The proposed ResQ\nalgorithm can speed up the training processes through a heuristic function\nwhich reduces the state-action space by identifying the set of particular\nactions over others. Experimental results showed that the proposed heuristic\nmulti-agent reinforcement learning based scheduling outperforms several\nstate-of-art methods, in terms of both reward rate and response times.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 21:39:07 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Nguyen", "Long", ""], ["Yang", "Zhou", ""], ["Zhu", "Jiazhen", ""], ["Li", "Jia", ""], ["Jin", "Fang", ""]]}, {"id": "1811.05016", "submitter": "Shuang Li", "authors": "Shuang Li, Shuai Xiao, Shixiang Zhu, Nan Du, Yao Xie, Le Song", "title": "Learning Temporal Point Processes via Reinforcement Learning", "comments": "Add code link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social goods, such as healthcare, smart city, and information networks, often\nproduce ordered event data in continuous time. The generative processes of\nthese event data can be very complex, requiring flexible models to capture\ntheir dynamics. Temporal point processes offer an elegant framework for\nmodeling event data without discretizing the time. However, the existing\nmaximum-likelihood-estimation (MLE) learning paradigm requires hand-crafting\nthe intensity function beforehand and cannot directly monitor the\ngoodness-of-fit of the estimated model in the process of training. To alleviate\nthe risk of model-misspecification in MLE, we propose to generate samples from\nthe generative model and monitor the quality of the samples in the process of\ntraining until the samples and the real data are indistinguishable. We take\ninspiration from reinforcement learning (RL) and treat the generation of each\nevent as the action taken by a stochastic policy. We parameterize the policy as\na flexible recurrent neural network and gradually improve the policy to mimic\nthe observed event distribution. Since the reward function is unknown in this\nsetting, we uncover an analytic and nonparametric form of the reward function\nusing an inverse reinforcement learning formulation. This new RL framework\nallows us to derive an efficient policy gradient algorithm for learning\nflexible point process models, and we show that it performs well in both\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 21:56:27 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 21:53:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Li", "Shuang", ""], ["Xiao", "Shuai", ""], ["Zhu", "Shixiang", ""], ["Du", "Nan", ""], ["Xie", "Yao", ""], ["Song", "Le", ""]]}, {"id": "1811.05039", "submitter": "Zhenyu A. Liao", "authors": "Zhenyu A. Liao, Charupriya Sharma, James Cussens and Peter van Beek", "title": "Finding All Bayesian Network Structures within a Factor of Optimal", "comments": "11 pages with supplemental material, to appear at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian network is a widely used probabilistic graphical model with\napplications in knowledge discovery and prediction. Learning a Bayesian network\n(BN) from data can be cast as an optimization problem using the well-known\nscore-and-search approach. However, selecting a single model (i.e., the best\nscoring BN) can be misleading or may not achieve the best possible accuracy. An\nalternative to committing to a single model is to perform some form of Bayesian\nor frequentist model averaging, where the space of possible BNs is sampled or\nenumerated in some fashion. Unfortunately, existing approaches for model\naveraging either severely restrict the structure of the Bayesian network or\nhave only been shown to scale to networks with fewer than 30 random variables.\nIn this paper, we propose a novel approach to model averaging inspired by\nperformance guarantees in approximation algorithms. Our approach has two\nprimary advantages. First, our approach only considers credible models in that\nthey are optimal or near-optimal in score. Second, our approach is more\nefficient and scales to significantly larger Bayesian networks than existing\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 23:19:51 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Liao", "Zhenyu A.", ""], ["Sharma", "Charupriya", ""], ["Cussens", "James", ""], ["van Beek", "Peter", ""]]}, {"id": "1811.05042", "submitter": "Jun Wen", "authors": "Jun Wen, Risheng Liu, Nenggan Zheng, Qian Zheng, Zhefeng Gong, Junsong\n  Yuan", "title": "Exploiting Local Feature Patterns for Unsupervised Domain Adaptation", "comments": "AAAI-2019 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation methods aim to alleviate performance\ndegradation caused by domain-shift by learning domain-invariant\nrepresentations. Existing deep domain adaptation methods focus on holistic\nfeature alignment by matching source and target holistic feature distributions,\nwithout considering local features and their multi-mode statistics. We show\nthat the learned local feature patterns are more generic and transferable and a\nfurther local feature distribution matching enables fine-grained feature\nalignment. In this paper, we present a method for learning domain-invariant\nlocal feature patterns and jointly aligning holistic and local feature\nstatistics. Comparisons to the state-of-the-art unsupervised domain adaptation\nmethods on two popular benchmark datasets demonstrate the superiority of our\napproach and its effectiveness on alleviating negative transfer.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 23:23:23 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 20:27:16 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Wen", "Jun", ""], ["Liu", "Risheng", ""], ["Zheng", "Nenggan", ""], ["Zheng", "Qian", ""], ["Gong", "Zhefeng", ""], ["Yuan", "Junsong", ""]]}, {"id": "1811.05062", "submitter": "Chandrasekaran Anirudh Bhardwaj", "authors": "Chandrasekaran Anirudh Bhardwaj, Megha Mishra, Kalyani Desikan", "title": "Dynamic Feature Scaling for K-Nearest Neighbor Algorithm", "comments": "Presented in International Conference on Mathematical Computer\n  Engineering 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nearest Neighbors Algorithm is a Lazy Learning Algorithm, in which the\nalgorithm tries to approximate the predictions with the help of similar\nexisting vectors in the training dataset. The predictions made by the K-Nearest\nNeighbors algorithm is based on averaging the target values of the spatial\nneighbors. The selection process for neighbors in the Hermitian space is done\nwith the help of distance metrics such as Euclidean distance, Minkowski\ndistance, Mahalanobis distance etc. A majority of the metrics such as Euclidean\ndistance are scale variant, meaning that the results could vary for different\nrange of values used for the features. Standard techniques used for the\nnormalization of scaling factors are feature scaling method such as Z-score\nnormalization technique, Min-Max scaling etc. Scaling methods uniformly assign\nequal weights to all the features, which might result in a non-ideal situation.\nThis paper proposes a novel method to assign weights to individual feature with\nthe help of out of bag errors obtained from constructing multiple decision tree\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 01:44:55 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Bhardwaj", "Chandrasekaran Anirudh", ""], ["Mishra", "Megha", ""], ["Desikan", "Kalyani", ""]]}, {"id": "1811.05072", "submitter": "Ji Wang", "authors": "Ji Wang and Weidong Bao and Lichao Sun and Xiaomin Zhu and Bokai Cao\n  and Philip S. Yu", "title": "Private Model Compression via Knowledge Distillation", "comments": "Conference version accepted by AAAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The soaring demand for intelligent mobile applications calls for deploying\npowerful deep neural networks (DNNs) on mobile devices. However, the\noutstanding performance of DNNs notoriously relies on increasingly complex\nmodels, which in turn is associated with an increase in computational expense\nfar surpassing mobile devices' capacity. What is worse, app service providers\nneed to collect and utilize a large volume of users' data, which contain\nsensitive information, to build the sophisticated DNN models. Directly\ndeploying these models on public mobile devices presents prohibitive privacy\nrisk. To benefit from the on-device deep learning without the capacity and\nprivacy concerns, we design a private model compression framework RONA.\nFollowing the knowledge distillation paradigm, we jointly use hint learning,\ndistillation learning, and self learning to train a compact and fast neural\nnetwork. The knowledge distilled from the cumbersome model is adaptively\nbounded and carefully perturbed to enforce differential privacy. We further\npropose an elegant query sample selection method to reduce the number of\nqueries and control the privacy loss. A series of empirical evaluations as well\nas the implementation on an Android mobile device show that RONA can not only\ncompress cumbersome models efficiently but also provide a strong privacy\nguarantee. For example, on SVHN, when a meaningful\n$(9.83,10^{-6})$-differential privacy is guaranteed, the compact model trained\nby RONA can obtain 20$\\times$ compression ratio and 19$\\times$ speed-up with\nmerely 0.97% accuracy loss.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 02:21:57 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Wang", "Ji", ""], ["Bao", "Weidong", ""], ["Sun", "Lichao", ""], ["Zhu", "Xiaomin", ""], ["Cao", "Bokai", ""], ["Yu", "Philip S.", ""]]}, {"id": "1811.05076", "submitter": "Miaoyan Wang", "authors": "Miaoyan Wang and Lexin Li", "title": "Learning from Binary Multiway Data: Probabilistic Tensor Decomposition\n  and its Statistical Optimality", "comments": "35 pages, 7 figures, 4 tables", "journal-ref": "Journal of Machine Learning Research, 21(154): 1-38, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of decomposing a higher-order tensor with binary\nentries. Such data problems arise frequently in applications such as\nneuroimaging, recommendation system, topic modeling, and sensor network\nlocalization. We propose a multilinear Bernoulli model, develop a\nrank-constrained likelihood-based estimation method, and obtain the theoretical\naccuracy guarantees. In contrast to continuous-valued problems, the binary\ntensor problem exhibits an interesting phase transition phenomenon according to\nthe signal-to-noise ratio. The error bound for the parameter tensor estimation\nis established, and we show that the obtained rate is minimax optimal under the\nconsidered model. Furthermore, we develop an alternating optimization algorithm\nwith convergence guarantees. The efficacy of our approach is demonstrated\nthrough both simulations and analyses of multiple data sets on the tasks of\ntensor completion and clustering.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 02:49:17 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 04:48:47 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 04:05:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Miaoyan", ""], ["Li", "Lexin", ""]]}, {"id": "1811.05090", "submitter": "Joseph Marino", "authors": "Joseph Marino, Milan Cvitkovic, Yisong Yue", "title": "A General Method for Amortizing Variational Filtering", "comments": "Advances in Neural Information Processing Systems (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the variational filtering EM algorithm, a simple,\ngeneral-purpose method for performing variational inference in dynamical latent\nvariable models using information from only past and present variables, i.e.\nfiltering. The algorithm is derived from the variational objective in the\nfiltering setting and consists of an optimization procedure at each time step.\nBy performing each inference optimization procedure with an iterative amortized\ninference model, we obtain a computationally efficient implementation of the\nalgorithm, which we call amortized variational filtering. We present\nexperiments demonstrating that this general-purpose method improves performance\nacross several deep dynamical latent variable models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 03:39:27 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Marino", "Joseph", ""], ["Cvitkovic", "Milan", ""], ["Yue", "Yisong", ""]]}, {"id": "1811.05095", "submitter": "Sergul Aydore", "authors": "Sergul Aydore, Lee Dicker, Dean Foster", "title": "A Local Regret in Nonconvex Online Learning", "comments": "Continual Workshop at NIPS 2018, 2 figures, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online learning process to forecast a sequence of outcomes for\nnonconvex models. A typical measure to evaluate online learning algorithms is\nregret but such standard definition of regret is intractable for nonconvex\nmodels even in offline settings. Hence, gradient based definition of regrets\nare common for both offline and online nonconvex problems. Recently, a notion\nof local gradient based regret was introduced. Inspired by the concept of\ncalibration and a local gradient based regret, we introduce another definition\nof regret and we discuss why our definition is more interpretable for\nforecasting problems. We also provide bound analysis for our regret under\ncertain assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 04:19:19 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 22:14:41 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Aydore", "Sergul", ""], ["Dicker", "Lee", ""], ["Foster", "Dean", ""]]}, {"id": "1811.05105", "submitter": "Arjun Punjabi", "authors": "Arjun Punjabi, Adam Martersteck, Yanran Wang, Todd B. Parrish, Aggelos\n  K. Katsaggelos, and the Alzheimer's Disease Neuroimaging Initiative", "title": "Neuroimaging Modality Fusion in Alzheimer's Classification Using\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0225759", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated methods for Alzheimer's disease (AD) classification have the\npotential for great clinical benefits and may provide insight for combating the\ndisease. Machine learning, and more specifically deep neural networks, have\nbeen shown to have great efficacy in this domain. These algorithms often use\nneurological imaging data such as MRI and PET, but a comprehensive and balanced\ncomparison of these modalities has not been performed. In order to accurately\ndetermine the relative strength of each imaging variant, this work performs a\ncomparison study in the context of Alzheimer's dementia classification using\nthe Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Furthermore,\nthis work analyzes the benefits of using both modalities in a fusion setting\nand discusses how these data types may be leveraged in future AD studies using\ndeep learning.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 04:53:54 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Punjabi", "Arjun", ""], ["Martersteck", "Adam", ""], ["Wang", "Yanran", ""], ["Parrish", "Todd B.", ""], ["Katsaggelos", "Aggelos K.", ""], ["Initiative", "the Alzheimer's Disease Neuroimaging", ""]]}, {"id": "1811.05134", "submitter": "Xiaowei Chen", "authors": "Xiaowei Chen, Weiran Huang, Wei Chen, John C.S. Lui", "title": "Community Exploration: From Offline Optimization to Online Learning", "comments": "full version of the nips'18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the community exploration problem that has many real-world\napplications such as online advertising. In the problem, an explorer allocates\nlimited budget to explore communities so as to maximize the number of members\nhe could meet. We provide a systematic study of the community exploration\nproblem, from offline optimization to online learning. For the offline setting\nwhere the sizes of communities are known, we prove that the greedy methods for\nboth of non-adaptive exploration and adaptive exploration are optimal. For the\nonline setting where the sizes of communities are not known and need to be\nlearned from the multi-round explorations, we propose an `upper confidence'\nlike algorithm that achieves the logarithmic regret bounds. By combining the\nfeedback from different rounds, we can achieve a constant regret bound.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 07:18:38 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 07:01:47 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Chen", "Xiaowei", ""], ["Huang", "Weiran", ""], ["Chen", "Wei", ""], ["Lui", "John C. S.", ""]]}, {"id": "1811.05141", "submitter": "Zhuoyi Wang", "authors": "Zhuoyi Wang, Zelun Kong, Hemeng Tao, Swarup Chandra, Latifur Khan", "title": "Co-Representation Learning For Classification and Novel Class Detection\n  via Deep Networks", "comments": "The paper absence of relative theoretical prove, some supplement\n  experiment should also be add", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges of performing label prediction over a data stream\nconcerns with the emergence of instances belonging to unobserved class labels\nover time. Previously, this problem has been addressed by detecting such\ninstances and using them for appropriate classifier adaptation. The fundamental\naspect of a novel-class detection strategy relies on the ability of comparison\namong observed instances to discriminate them into known and unknown classes.\nTherefore, studies in the past have proposed various metrics suitable for\ncomparison over the observed feature space. Unfortunately, these similarity\nmeasures fail to reliably identify distinct regions in observed feature spaces\nuseful for class discrimination and novel-class detection, especially in\nstreams containing high-dimensional data instances such as images and texts. In\nthis paper, we address this key challenge by proposing a semi-supervised\nmulti-task learning framework called \\sysname{} which aims to intrinsically\nsearch for a latent space suitable for detecting labels of instances from both\nknown and unknown classes. We empirically measure the performance of \\sysname{}\nover multiple real-world image and text datasets and demonstrate its\nsuperiority by comparing its performance with existing semi-supervised methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 07:39:37 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 03:11:33 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wang", "Zhuoyi", ""], ["Kong", "Zelun", ""], ["Tao", "Hemeng", ""], ["Chandra", "Swarup", ""], ["Khan", "Latifur", ""]]}, {"id": "1811.05154", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Csaba Szepesvari, Sharan Vaswani, Zheng Wen,\n  Mohammad Ghavamzadeh, and Tor Lattimore", "title": "Garbage In, Reward Out: Bootstrapping Exploration in Multi-Armed Bandits", "comments": "Proceedings of the 36th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a bandit algorithm that explores by randomizing its history of\nrewards. Specifically, it pulls the arm with the highest mean reward in a\nnon-parametric bootstrap sample of its history with pseudo rewards. We design\nthe pseudo rewards such that the bootstrap mean is optimistic with a\nsufficiently high probability. We call our algorithm Giro, which stands for\ngarbage in, reward out. We analyze Giro in a Bernoulli bandit and derive a $O(K\n\\Delta^{-1} \\log n)$ bound on its $n$-round regret, where $\\Delta$ is the\ndifference in the expected rewards of the optimal and the best suboptimal arms,\nand $K$ is the number of arms. The main advantage of our exploration design is\nthat it easily generalizes to structured problems. To show this, we propose\ncontextual Giro with an arbitrary reward generalization model. We evaluate Giro\nand its contextual variant on multiple synthetic and real-world problems, and\nobserve that it performs well.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 08:15:39 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 04:53:11 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 03:53:30 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Kveton", "Branislav", ""], ["Szepesvari", "Csaba", ""], ["Vaswani", "Sharan", ""], ["Wen", "Zheng", ""], ["Ghavamzadeh", "Mohammad", ""], ["Lattimore", "Tor", ""]]}, {"id": "1811.05157", "submitter": "Bin Yang", "authors": "Jilin Hu, Chenjuan Guo, Bin Yang, Christian S. Jensen, Lu Chen", "title": "Recurrent Multi-Graph Neural Networks for Travel Cost Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Origin-destination (OD) matrices are often used in urban planning, where a\ncity is partitioned into regions and an element (i, j) in an OD matrix records\nthe cost (e.g., travel time, fuel consumption, or travel speed) from region i\nto region j. In this paper, we partition a day into multiple intervals, e.g.,\n96 15-min intervals and each interval is associated with an OD matrix which\nrepresents the costs in the interval; and we consider sparse and stochastic OD\nmatrices, where the elements represent stochastic but not deterministic costs\nand some elements are missing due to lack of data between two regions. We solve\nthe sparse, stochastic OD matrix forecasting problem. Given a sequence of\nhistorical OD matrices that are sparse, we aim at predicting future OD matrices\nwith no empty elements. We propose a generic learning framework to solve the\nproblem by dealing with sparse matrices via matrix factorization and two graph\nconvolutional neural networks and capturing temporal dynamics via recurrent\nneural network. Empirical studies using two taxi datasets from different\ncountries verify the effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 08:19:41 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hu", "Jilin", ""], ["Guo", "Chenjuan", ""], ["Yang", "Bin", ""], ["Jensen", "Christian S.", ""], ["Chen", "Lu", ""]]}, {"id": "1811.05232", "submitter": "Zhuozhuo Tu", "authors": "Zhuozhuo Tu, Jingwei Zhang, Dacheng Tao", "title": "Theoretical Analysis of Adversarial Learning: A Minimax Approach", "comments": "27 pages, add some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Here we propose a general theoretical method for analyzing the risk bound in\nthe presence of adversaries. Specifically, we try to fit the adversarial\nlearning problem into the minimax framework. We first show that the original\nadversarial learning problem can be reduced to a minimax statistical learning\nproblem by introducing a transport map between distributions. Then, we prove a\nnew risk bound for this minimax problem in terms of covering numbers under a\nweak version of Lipschitz condition. Our method can be applied to multi-class\nclassification problems and commonly used loss functions such as the hinge and\nramp losses. As some illustrative examples, we derive the adversarial risk\nbounds for SVMs, deep neural networks, and PCA, and our bounds have two\ndata-dependent terms, which can be optimized for achieving adversarial\nrobustness.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 11:48:43 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 00:24:09 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Tu", "Zhuozhuo", ""], ["Zhang", "Jingwei", ""], ["Tao", "Dacheng", ""]]}, {"id": "1811.05249", "submitter": "Louis Kirsch", "authors": "Louis Kirsch, Julius Kunze, David Barber", "title": "Modular Networks: Learning to Decompose Neural Computation", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling model capacity has been vital in the success of deep learning. For a\ntypical network, necessary compute resources and training time grow\ndramatically with model size. Conditional computation is a promising way to\nincrease the number of parameters with a relatively small increase in\nresources. We propose a training algorithm that flexibly chooses neural modules\nbased on the data to be processed. Both the decomposition and modules are\nlearned end-to-end. In contrast to existing approaches, training does not rely\non regularization to enforce diversity in module use. We apply modular networks\nboth to image recognition and language modeling tasks, where we achieve\nsuperior performance compared to several baselines. Introspection reveals that\nmodules specialize in interpretable contexts.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 12:24:23 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Kirsch", "Louis", ""], ["Kunze", "Julius", ""], ["Barber", "David", ""]]}, {"id": "1811.05259", "submitter": "Manaar Alam", "authors": "Manaar Alam and Debdeep Mukhopadhyay", "title": "How Secure are Deep Learning Algorithms from Side-Channel based Reverse\n  Engineering?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning algorithms have recently become the de-facto paradigm for\nvarious prediction problems, which include many privacy-preserving applications\nlike online medical image analysis. Presumably, the privacy of data in a deep\nlearning system is a serious concern. There have been several efforts to\nanalyze and exploit the information leakages from deep learning architectures\nto compromise data privacy. In this paper, however, we attempt to provide an\nevaluation strategy for such information leakages through deep neural network\narchitectures by considering a case study on Convolutional Neural Network (CNN)\nbased image classifier. The approach takes the aid of low-level hardware\ninformation, provided by Hardware Performance Counters (HPCs), during the\nexecution of a CNN classifier and a simple hypothesis testing in order to\nproduce an alarm if there exists any information leakage on the actual input.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 12:42:24 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Alam", "Manaar", ""], ["Mukhopadhyay", "Debdeep", ""]]}, {"id": "1811.05266", "submitter": "Jean-Marc Andreoli", "authors": "Jean-Marc Andreoli", "title": "A conjugate prior for the Dirichlet distribution", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note investigates a conjugate class for the Dirichlet distribution class\nin the exponential family.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 13:02:55 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Andreoli", "Jean-Marc", ""]]}, {"id": "1811.05320", "submitter": "Haifeng Li", "authors": "Ling Zhao, Yujiao Song, Chao Zhang, Yu Liu, Pu Wang, Tao Lin, Min Deng\n  and Haifeng Li", "title": "T-GCN: A Temporal Graph ConvolutionalNetwork for Traffic Prediction", "comments": "10 pages, 14 figures", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems-2019", "doi": "10.1109/TITS.2019.2935152", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and real-time traffic forecasting plays an important role in the\nIntelligent Traffic System and is of great significance for urban traffic\nplanning, traffic management, and traffic control. However, traffic forecasting\nhas always been considered an open scientific issue, owing to the constraints\nof urban road network topological structure and the law of dynamic change with\ntime, namely, spatial dependence and temporal dependence. To capture the\nspatial and temporal dependence simultaneously, we propose a novel neural\nnetwork-based traffic forecasting method, the temporal graph convolutional\nnetwork (T-GCN) model, which is in combination with the graph convolutional\nnetwork (GCN) and gated recurrent unit (GRU). Specifically, the GCN is used to\nlearn complex topological structures to capture spatial dependence and the\ngated recurrent unit is used to learn dynamic changes of traffic data to\ncapture temporal dependence. Then, the T-GCN model is employed to traffic\nforecasting based on the urban road network. Experiments demonstrate that our\nT-GCN model can obtain the spatio-temporal correlation from traffic data and\nthe predictions outperform state-of-art baselines on real-world traffic\ndatasets. Our tensorflow implementation of the T-GCN is available at\nhttps://github.com/lehaifeng/T-GCN.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 03:30:03 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 15:40:57 GMT"}, {"version": "v3", "created": "Mon, 31 Dec 2018 05:32:23 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zhao", "Ling", ""], ["Song", "Yujiao", ""], ["Zhang", "Chao", ""], ["Liu", "Yu", ""], ["Wang", "Pu", ""], ["Lin", "Tao", ""], ["Deng", "Min", ""], ["Li", "Haifeng", ""]]}, {"id": "1811.05321", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, A. Golubkov, B. Grechuk, E.M. Mirkes, I.Y. Tyukin", "title": "Correction of AI systems by linear discriminants: Probabilistic\n  foundations", "comments": "arXiv admin note: text overlap with arXiv:1809.07656 and\n  arXiv:1802.02172", "journal-ref": "Information Sciences 466 (2018), 303-322", "doi": "10.1016/j.ins.2018.07.040", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) systems sometimes make errors and will make\nerrors in the future, from time to time. These errors are usually unexpected,\nand can lead to dramatic consequences. Intensive development of AI and its\npractical applications makes the problem of errors more important. Total\nre-engineering of the systems can create new errors and is not always possible\ndue to the resources involved. The important challenge is to develop fast\nmethods to correct errors without damaging existing skills. We formulated the\ntechnical requirements to the 'ideal' correctors. Such correctors include\nbinary classifiers, which separate the situations with high risk of errors from\nthe situations where the AI systems work properly. Surprisingly, for\nessentially high-dimensional data such methods are possible: simple linear\nFisher discriminant can separate the situations with errors from correctly\nsolved tasks even for exponentially large samples. The paper presents the\nprobabilistic basis for fast non-destructive correction of AI systems. A series\nof new stochastic separation theorems is proven. These theorems provide new\ninstruments for fast non-iterative correction of errors of legacy AI systems.\nThe new approaches become efficient in high-dimensions, for correction of\nhigh-dimensional systems in high-dimensional world (i.e. for processing of\nessentially high-dimensional data by large systems).\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 13:11:13 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Gorban", "A. N.", ""], ["Golubkov", "A.", ""], ["Grechuk", "B.", ""], ["Mirkes", "E. M.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1811.05336", "submitter": "Xingwei Hu Dr", "authors": "Xingwei Hu", "title": "On Asymptotic Covariances of A Few Unrotated Factor Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide explicit formulas, in terms of the covariances of\nsample covariances or sample correlations, for the asymptotic covariances of\nunrotated factor loading estimates and unique variance estimates. These\nestimates are extracted from least square, principal, iterative principal\ncomponent, alpha or image factor analysis. If the sample is taken from a\nmultivariate normal population, these formulas, together with the delta\nmethods, will produce the standard errors for the rotated loading estimates. A\nsimulation study shows that the formulas provide reasonable results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 05:10:11 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hu", "Xingwei", ""]]}, {"id": "1811.05355", "submitter": "Fabien Cardinaux", "authors": "Fabien Cardinaux and Stefan Uhlich and Kazuki Yoshiyama and Javier\n  Alonso Garc\\'ia and Stephen Tiedemann and Thomas Kemp and Akira Nakamura", "title": "Iteratively Training Look-Up Tables for Network Quantization", "comments": "NIPS 2018 workshop on Compact Deep Neural Networks with industrial\n  applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating deep neural networks on devices with limited resources requires the\nreduction of their memory footprints and computational requirements. In this\npaper we introduce a training method, called look-up table quantization, LUT-Q,\nwhich learns a dictionary and assigns each weight to one of the dictionary's\nvalues. We show that this method is very flexible and that many other\ntechniques can be seen as special cases of LUT-Q. For example, we can constrain\nthe dictionary trained with LUT-Q to generate networks with pruned weight\nmatrices or restrict the dictionary to powers-of-two to avoid the need for\nmultiplications. In order to obtain fully multiplier-less networks, we also\nintroduce a multiplier-less version of batch normalization. Extensive\nexperiments on image recognition and object detection tasks show that LUT-Q\nconsistently achieves better performance than other methods with the same\nquantization bitwidth.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 15:03:49 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Cardinaux", "Fabien", ""], ["Uhlich", "Stefan", ""], ["Yoshiyama", "Kazuki", ""], ["Garc\u00eda", "Javier Alonso", ""], ["Tiedemann", "Stephen", ""], ["Kemp", "Thomas", ""], ["Nakamura", "Akira", ""]]}, {"id": "1811.05370", "submitter": "Aditya Siddhant", "authors": "Aditya Siddhant, Anuj Goyal, Angeliki Metallinou", "title": "Unsupervised Transfer Learning for Spoken Language Understanding in\n  Intelligent Agents", "comments": "To appear at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User interaction with voice-powered agents generates large amounts of\nunlabeled utterances. In this paper, we explore techniques to efficiently\ntransfer the knowledge from these unlabeled utterances to improve model\nperformance on Spoken Language Understanding (SLU) tasks. We use Embeddings\nfrom Language Model (ELMo) to take advantage of unlabeled data by learning\ncontextualized word representations. Additionally, we propose ELMo-Light\n(ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our\nfindings suggest unsupervised pre-training on a large corpora of unlabeled\nutterances leads to significantly better SLU performance compared to training\nfrom scratch and it can even outperform conventional supervised transfer.\nAdditionally, we show that the gains from unsupervised transfer techniques can\nbe further improved by supervised transfer. The improvements are more\npronounced in low resource settings and when using only 1000 labeled in-domain\nsamples, our techniques match the performance of training from scratch on\n10-15x more labeled in-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 15:44:31 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Siddhant", "Aditya", ""], ["Goyal", "Anuj", ""], ["Metallinou", "Angeliki", ""]]}, {"id": "1811.05372", "submitter": "Abhishek Divekar", "authors": "Abhishek Divekar (1 and 5), Meet Parekh (2 and 5), Vaibhav Savla (3\n  and 5), Rudra Mishra (4 and 5), Mahesh Shirole (5) ((1) Amazon, (2) New York\n  University, (3) Infosys, (4) Samsung, (5) Veermata Jijabai Technological\n  Institute)", "title": "Benchmarking datasets for Anomaly-based Network Intrusion Detection: KDD\n  CUP 99 alternatives", "comments": "Paper accepted into Proceedings of IEEE International Conference on\n  Computing, Communication and Security 2018 (ICCCS-2018) Statistics: 8 pages,\n  7 tables, 3 figures, 34 references", "journal-ref": "2018 3rd IEEE International Conference on Computing, Communication\n  and Security (ICCCS)", "doi": "10.1109/CCCS.2018.8586840", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has been steadily gaining traction for its use in\nAnomaly-based Network Intrusion Detection Systems (A-NIDS). Research into this\ndomain is frequently performed using the KDD~CUP~99 dataset as a benchmark.\nSeveral studies question its usability while constructing a contemporary NIDS,\ndue to the skewed response distribution, non-stationarity, and failure to\nincorporate modern attacks. In this paper, we compare the performance for\nKDD-99 alternatives when trained using classification models commonly found in\nliterature: Neural Network, Support Vector Machine, Decision Tree, Random\nForest, Naive Bayes and K-Means. Applying the SMOTE oversampling technique and\nrandom undersampling, we create a balanced version of NSL-KDD and prove that\nskewed target classes in KDD-99 and NSL-KDD hamper the efficacy of classifiers\non minority classes (U2R and R2L), leading to possible security risks. We\nexplore UNSW-NB15, a modern substitute to KDD-99 with greater uniformity of\npattern distribution. We benchmark this dataset before and after SMOTE\noversampling to observe the effect on minority performance. Our results\nindicate that classifiers trained on UNSW-NB15 match or better the Weighted\nF1-Score of those trained on NSL-KDD and KDD-99 in the binary case, thus\nadvocating UNSW-NB15 as a modern substitute to these datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 15:49:54 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Divekar", "Abhishek", "", "1 and 5"], ["Parekh", "Meet", "", "2 and 5"], ["Savla", "Vaibhav", "", "3\n  and 5"], ["Mishra", "Rudra", "", "4 and 5"], ["Shirole", "Mahesh", ""]]}, {"id": "1811.05375", "submitter": "Carlos Sarraute", "authors": "Martin Fixman, Martin Minnoni, Carlos Sarraute", "title": "Comparison of Feature Extraction Methods and Predictors for Income\n  Inference", "comments": "Argentine Symposium on Big Data (AGRANDA), September 5, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Patterns of mobile phone communications, coupled with the information of the\nsocial network graph and financial behavior, allow us to make inferences of\nusers' socio-economic attributes such as their income level. We present here\nseveral methods to extract features from mobile phone usage (calls and\nmessages), and compare different combinations of supervised machine learning\ntechniques and sets of features used as input for the inference of users'\nincome. Our experimental results show that the Bayesian method based on the\ncommunication graph outperforms standard machine learning algorithms using\nnode-based features.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 15:53:22 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fixman", "Martin", ""], ["Minnoni", "Martin", ""], ["Sarraute", "Carlos", ""]]}, {"id": "1811.05381", "submitter": "James Lucas", "authors": "Cem Anil, James Lucas, Roger Grosse", "title": "Sorting out Lipschitz function approximation", "comments": "8 main pages, 21 pages total, 17 figures. Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks under a strict Lipschitz constraint is useful for\nprovable adversarial robustness, generalization bounds, interpretable\ngradients, and Wasserstein distance estimation. By the composition property of\nLipschitz functions, it suffices to ensure that each individual affine\ntransformation or nonlinear activation is 1-Lipschitz. The challenge is to do\nthis while maintaining the expressive power. We identify a necessary property\nfor such an architecture: each of the layers must preserve the gradient norm\nduring backpropagation. Based on this, we propose to combine a gradient norm\npreserving activation function, GroupSort, with norm-constrained weight\nmatrices. We show that norm-constrained GroupSort architectures are universal\nLipschitz function approximators. Empirically, we show that norm-constrained\nGroupSort networks achieve tighter estimates of Wasserstein distance than their\nReLU counterparts and can achieve provable adversarial robustness guarantees\nwith little cost to accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 16:15:22 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 14:34:43 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Anil", "Cem", ""], ["Lucas", "James", ""], ["Grosse", "Roger", ""]]}, {"id": "1811.05443", "submitter": "Prasanna Sattigeri", "authors": "Abhishek Kumar and Prasanna Sattigeri and Kahini Wadhawan and Leonid\n  Karlinsky and Rogerio Feris and William T. Freeman and Gregory Wornell", "title": "Co-regularized Alignment for Unsupervised Domain Adaptation", "comments": "NIPS 2018 accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, trained with large amount of labeled data, can fail to\ngeneralize well when tested with examples from a \\emph{target domain} whose\ndistribution differs from the training data distribution, referred as the\n\\emph{source domain}. It can be expensive or even infeasible to obtain required\namount of labeled data in all possible domains. Unsupervised domain adaptation\nsets out to address this problem, aiming to learn a good predictive model for\nthe target domain using labeled examples from the source domain but only\nunlabeled examples from the target domain. Domain alignment approaches this\nproblem by matching the source and target feature distributions, and has been\nused as a key component in many state-of-the-art domain adaptation methods.\nHowever, matching the marginal feature distributions does not guarantee that\nthe corresponding class conditional distributions will be aligned across the\ntwo domains. We propose co-regularized domain alignment for unsupervised domain\nadaptation, which constructs multiple diverse feature spaces and aligns source\nand target distributions in each of them individually, while encouraging that\nalignments agree with each other with regard to the class predictions on the\nunlabeled target examples. The proposed method is generic and can be used to\nimprove any domain adaptation method which uses domain alignment. We\ninstantiate it in the context of a recent state-of-the-art method and observe\nthat it provides significant performance improvements on several domain\nadaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 18:22:15 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Kumar", "Abhishek", ""], ["Sattigeri", "Prasanna", ""], ["Wadhawan", "Kahini", ""], ["Karlinsky", "Leonid", ""], ["Feris", "Rogerio", ""], ["Freeman", "William T.", ""], ["Wornell", "Gregory", ""]]}, {"id": "1811.05467", "submitter": "Laura Martinus", "authors": "Jade Z. Abbott and Laura Martinus", "title": "Towards Neural Machine Translation for African Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given that South African education is in crisis, strategies for improvement\nand sustainability of high-quality, up-to-date education must be explored. In\nthe migration of education online, inclusion of machine translation for\nlow-resourced local languages becomes necessary. This paper aims to spur the\nuse of current neural machine translation (NMT) techniques for low-resourced\nlocal languages. The paper demonstrates state-of-the-art performance on\nEnglish-to-Setswana translation using the Autshumato dataset. The use of the\nTransformer architecture beat previous techniques by 5.33 BLEU points. This\ndemonstrates the promise of using current NMT techniques for African languages.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 06:49:08 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Abbott", "Jade Z.", ""], ["Martinus", "Laura", ""]]}, {"id": "1811.05468", "submitter": "Maximilian Hofer", "authors": "Maximilian Hofer, Andrey Kormilitzin, Paul Goldberg, Alejo\n  Nevado-Holgado", "title": "Few-shot Learning for Named Entity Recognition in Medical Text", "comments": "10 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models have recently achieved state-of-the-art\nperformance gains in a variety of natural language processing (NLP) tasks\n(Young, Hazarika, Poria, & Cambria, 2017). However, these gains rely on the\navailability of large amounts of annotated examples, without which\nstate-of-the-art performance is rarely achievable. This is especially\ninconvenient for the many NLP fields where annotated examples are scarce, such\nas medical text. To improve NLP models in this situation, we evaluate five\nimprovements on named entity recognition (NER) tasks when only ten annotated\nexamples are available: (1) layer-wise initialization with pre-trained weights,\n(2) hyperparameter tuning, (3) combining pre-training data, (4) custom word\nembeddings, and (5) optimizing out-of-vocabulary (OOV) words. Experimental\nresults show that the F1 score of 69.3% achievable by state-of-the-art models\ncan be improved to 78.87%.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 13:12:02 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Hofer", "Maximilian", ""], ["Kormilitzin", "Andrey", ""], ["Goldberg", "Paul", ""], ["Nevado-Holgado", "Alejo", ""]]}, {"id": "1811.05475", "submitter": "Jingcheng Du", "authors": "Jingcheng Du, Qingyu Chen, Yifan Peng, Yang Xiang, Cui Tao, Zhiyong Lu", "title": "ML-Net: multi-label classification of biomedical texts with deep neural\n  networks", "comments": null, "journal-ref": null, "doi": "10.1093/jamia/ocz085", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-label text classification, each textual document can be assigned\nwith one or more labels. Due to this nature, the multi-label text\nclassification task is often considered to be more challenging compared to the\nbinary or multi-class text classification problems. As an important task with\nbroad applications in biomedicine such as assigning diagnosis codes, a number\nof different computational methods (e.g. training and combining binary\nclassifiers for each label) have been proposed in recent years. However, many\nsuffered from modest accuracy and efficiency, with only limited success in\npractical use. We propose ML-Net, a novel deep learning framework, for\nmulti-label classification of biomedical texts. As an end-to-end system, ML-Net\ncombines a label prediction network with an automated label count prediction\nmechanism to output an optimal set of labels by leveraging both predicted\nconfidence score of each label and the contextual information in the target\ndocument. We evaluate ML-Net on three independent, publicly-available corpora\nin two kinds of text genres: biomedical literature and clinical notes. For\nevaluation, example-based measures such as precision, recall and f-measure are\nused. ML-Net is compared with several competitive machine learning baseline\nmodels. Our benchmarking results show that ML-Net compares favorably to the\nstate-of-the-art methods in multi-label classification of biomedical texts.\nML-NET is also shown to be robust when evaluated on different text genres in\nbiomedicine. Unlike traditional machine learning methods, ML-Net does not\nrequire human efforts in feature engineering and is highly efficient and\nscalable approach to tasks with a large set of labels (no need to build\nindividual classifiers for each separate label). Finally, ML-NET is able to\ndynamically estimate the label count based on the document context in a more\nsystematic and accurate manner.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 17:31:49 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 16:02:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Du", "Jingcheng", ""], ["Chen", "Qingyu", ""], ["Peng", "Yifan", ""], ["Xiang", "Yang", ""], ["Tao", "Cui", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1811.05491", "submitter": "Alvin Chua", "authors": "Alvin J. K. Chua, Chad R. Galley, Michele Vallisneri", "title": "Reduced-order modeling with artificial neurons for gravitational-wave\n  inference", "comments": "Published version", "journal-ref": "Phys. Rev. Lett. 122, 211101 (2019)", "doi": "10.1103/PhysRevLett.122.211101", "report-no": null, "categories": "astro-ph.IM gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gravitational-wave data analysis is rapidly absorbing techniques from deep\nlearning, with a focus on convolutional networks and related methods that treat\nnoisy time series as images. We pursue an alternative approach, in which\nwaveforms are first represented as weighted sums over reduced bases\n(reduced-order modeling); we then train artificial neural networks to map\ngravitational-wave source parameters into basis coefficients. Statistical\ninference proceeds directly in coefficient space, where it is theoretically\nstraightforward and computationally efficient. The neural networks also provide\nanalytic waveform derivatives, which are useful for gradient-based sampling\nschemes. We demonstrate fast and accurate coefficient interpolation for the\ncase of a four-dimensional binary-inspiral waveform family, and discuss\npromising applications of our framework in parameter estimation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 19:00:23 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 09:48:43 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Chua", "Alvin J. K.", ""], ["Galley", "Chad R.", ""], ["Vallisneri", "Michele", ""]]}, {"id": "1811.05512", "submitter": "Paulina Grnarova", "authors": "Paulina Grnarova, Kfir Y Levy, Aurelien Lucchi, Nathanael Perraudin,\n  Ian Goodfellow, Thomas Hofmann and Andreas Krause", "title": "A domain agnostic measure for monitoring and evaluating GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown remarkable results in\nmodeling complex distributions, but their evaluation remains an unsettled\nissue. Evaluations are essential for: (i) relative assessment of different\nmodels and (ii) monitoring the progress of a single model throughout training.\nThe latter cannot be determined by simply inspecting the generator and\ndiscriminator loss curves as they behave non-intuitively. We leverage the\nnotion of duality gap from game theory to propose a measure that addresses both\n(i) and (ii) at a low computational cost. Extensive experiments show the\neffectiveness of this measure to rank different GAN models and capture the\ntypical GAN failure scenarios, including mode collapse and non-convergent\nbehaviours. This evaluation metric also provides meaningful monitoring on the\nprogression of the loss during training. It highly correlates with FID on\nnatural image datasets, and with domain specific scores for text, sound and\ncosmology data where FID is not directly suitable. In particular, our proposed\nmetric requires no labels or a pretrained classifier, making it domain\nagnostic.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 19:49:57 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 09:44:56 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Grnarova", "Paulina", ""], ["Levy", "Kfir Y", ""], ["Lucchi", "Aurelien", ""], ["Perraudin", "Nathanael", ""], ["Goodfellow", "Ian", ""], ["Hofmann", "Thomas", ""], ["Krause", "Andreas", ""]]}, {"id": "1811.05521", "submitter": "Mandar Kulkarni Mr.", "authors": "Mandar Kulkarni", "title": "Deep Q learning for fooling neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to external attacks. In this paper, we\npropose a Reinforcement Learning (RL) based approach to generate adversarial\nexamples for the pre-trained (target) models. We assume a semi black-box\nsetting where the only access an adversary has to the target model is the class\nprobabilities obtained for the input queries. We train a Deep Q Network (DQN)\nagent which, with experience, learns to attack only a small portion of image\npixels to generate non-targeted adversarial images. Initially, an agent\nexplores an environment by sequentially modifying random sets of image pixels\nand observes its effect on the class probabilities. At the end of an episode,\nit receives a positive (negative) reward if it succeeds (fails) to alter the\nlabel of the image. Experimental results with MNIST, CIFAR-10 and Imagenet\ndatasets demonstrate that our RL framework is able to learn an effective attack\npolicy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 20:23:37 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Kulkarni", "Mandar", ""]]}, {"id": "1811.05527", "submitter": "Gabriel Peyr\\'e", "authors": "Marco Cuturi and Gabriel Peyr\\'e", "title": "Semi-dual Regularized Optimal Transport", "comments": null, "journal-ref": "SIAM Review, 60(4), 941-965, 2018", "doi": "10.1137/18M1208654", "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational problems that involve Wasserstein distances and more generally\noptimal transport (OT) theory are playing an increasingly important role in\ndata sciences. Such problems can be used to form an examplar measure out of\nvarious probability measures, as in the Wasserstein barycenter problem, or to\ncarry out parametric inference and density fitting, where the loss is measured\nin terms of an optimal transport cost to the measure of observations. Despite\nbeing conceptually simple, such problems are computationally challenging\nbecause they involve minimizing over quantities (Wasserstein distances) that\nare themselves hard to compute. Entropic regularization has recently emerged as\nan efficient tool to approximate the solution of such variational Wasserstein\nproblems. In this paper, we give a thorough duality tour of these\nregularization techniques. In particular, we show how important concepts from\nclassical OT such as c-transforms and semi-discrete approaches translate into\nsimilar ideas in a regularized setting. These dual formulations lead to smooth\nvariational problems, which can be solved using smooth, differentiable and\nconvex optimization problems that are simpler to implement and numerically more\nstable that their un-regularized counterparts. We illustrate the versatility of\nthis approach by applying it to the computation of Wasserstein barycenters and\ngradient flows of spatial regularization functionals.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 20:56:14 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Cuturi", "Marco", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1811.05537", "submitter": "Tong Qin", "authors": "Tong Qin, Kailiang Wu, Dongbin Xiu", "title": "Data Driven Governing Equations Approximation Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.06.042", "report-no": null, "categories": "math.NA cs.LG cs.NE math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a numerical framework for approximating unknown governing\nequations using observation data and deep neural networks (DNN). In particular,\nwe propose to use residual network (ResNet) as the basic building block for\nequation approximation. We demonstrate that the ResNet block can be considered\nas a one-step method that is exact in temporal integration. We then present two\nmulti-step methods, recurrent ResNet (RT-ResNet) method and recursive ReNet\n(RS-ResNet) method. The RT-ResNet is a multi-step method on uniform time steps,\nwhereas the RS-ResNet is an adaptive multi-step method using variable time\nsteps. All three methods presented here are based on integral form of the\nunderlying dynamical system. As a result, they do not require time derivative\ndata for equation recovery and can cope with relatively coarsely distributed\ntrajectory data. Several numerical examples are presented to demonstrate the\nperformance of the methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 21:47:27 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Qin", "Tong", ""], ["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1811.05540", "submitter": "Ahmed Nazim Uddin", "authors": "Ahmed Nazim Uddin, Md Ashequr Rahman, Md. Rafidul Islam, Mohammad\n  Ariful Haque", "title": "Native Language Identification using i-vector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of determining a speaker's native language based only on his\nspeeches in a second language is known as Native Language Identification or\nNLI. Due to its increasing applications in various domains of speech signal\nprocessing, this has emerged as an important research area in recent times. In\nthis paper we have proposed an i-vector based approach to develop an automatic\nNLI system using MFCC and GFCC features. For evaluation of our approach, we\nhave tested our framework on the 2016 ComParE Native language sub-challenge\ndataset which has English language speakers from 11 different native language\nbackgrounds. Our proposed method outperforms the baseline system with an\nimprovement in accuracy by 21.95% for the MFCC feature based i-vector framework\nand 22.81% for the GFCC feature based i-vector framework.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 17:12:47 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Uddin", "Ahmed Nazim", ""], ["Rahman", "Md Ashequr", ""], ["Islam", "Md. Rafidul", ""], ["Haque", "Mohammad Ariful", ""]]}, {"id": "1811.05542", "submitter": "Aran Komatsuzaki", "authors": "Aran Komatsuzaki", "title": "Extractive Summary as Discrete Latent Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare various methods to compress a text using a neural\nmodel. We find that extracting tokens as latent variables significantly\noutperforms the state-of-the-art discrete latent variable models such as\nVQ-VAE. Furthermore, we compare various extractive compression schemes. There\nare two best-performing methods that perform equally. One method is to simply\nchoose the tokens with the highest tf-idf scores. Another is to train a\nbidirectional language model similar to ELMo and choose the tokens with the\nhighest loss. If we consider any subsequence of a text to be a text in a\nbroader sense, we conclude that language is a strong compression code of\nitself. Our finding justifies the high quality of generation achieved with\nhierarchical method, as their latent variables are nothing but natural language\nsummary. We also conclude that there is a hierarchy in language such that an\nentire text can be predicted much more easily based on a sequence of a small\nnumber of keywords, which can be easily found by classical methods as tf-idf.\nWe speculate that this extraction process may be useful for unsupervised\nhierarchical text generation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 02:02:18 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 22:56:42 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Komatsuzaki", "Aran", ""]]}, {"id": "1811.05544", "submitter": "Dichao Hu", "authors": "Dichao Hu", "title": "An Introductory Survey on Attention Mechanisms in NLP Problems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First derived from human intuition, later adapted to machine translation for\nautomatic token alignment, attention mechanism, a simple method that can be\nused for encoding sequence data based on the importance score each element is\nassigned, has been widely applied to and attained significant improvement in\nvarious tasks in natural language processing, including sentiment\nclassification, text summarization, question answering, dependency parsing,\netc. In this paper, we survey through recent works and conduct an introductory\nsummary of the attention mechanism in different NLP problems, aiming to provide\nour readers with basic knowledge on this widely used method, discuss its\ndifferent variants for different tasks, explore its association with other\ntechniques in machine learning, and examine methods for evaluating its\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 16:19:22 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Hu", "Dichao", ""]]}, {"id": "1811.05561", "submitter": "Deovrat Kakde", "authors": "Deovrat Kakde, Arin Chaudhuri and Diana Shaw", "title": "A New SVDD-Based Multivariate Non-parametric Process Capability Index", "comments": null, "journal-ref": null, "doi": "10.1109/ICPHM.2018.8448517", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process capability index (PCI) is a commonly used statistic to measure\nability of a process to operate within the given specifications or to produce\nproducts which meet the required quality specifications. PCI can be univariate\nor multivariate depending upon the number of process specifications or quality\ncharacteristics of interest. Most PCIs make distributional assumptions which\nare often unrealistic in practice.\n  This paper proposes a new multivariate non-parametric process capability\nindex. This index can be used when distribution of the process or quality\nparameters is either unknown or does not follow commonly used distributions\nsuch as multivariate normal.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 23:05:38 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Kakde", "Deovrat", ""], ["Chaudhuri", "Arin", ""], ["Shaw", "Diana", ""]]}, {"id": "1811.05590", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan, Roman V. Yampolskiy and Arslan Munir", "title": "Emergence of Addictive Behaviors in Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to the technical analysis of wireheading\nin intelligent agents. Inspired by the natural analogues of wireheading and\ntheir prevalent manifestations, we propose the modeling of such phenomenon in\nReinforcement Learning (RL) agents as psychological disorders. In a preliminary\nstep towards evaluating this proposal, we study the feasibility and dynamics of\nemergent addictive policies in Q-learning agents in the tractable environment\nof the game of Snake. We consider a slightly modified settings for this game,\nin which the environment provides a \"drug\" seed alongside the original\n\"healthy\" seed for the consumption of the snake. We adopt and extend an\nRL-based model of natural addiction to Q-learning agents in this settings, and\nderive sufficient parametric conditions for the emergence of addictive\nbehaviors in such agents. Furthermore, we evaluate our theoretical analysis\nwith three sets of simulation-based experiments. The results demonstrate the\nfeasibility of addictive wireheading in RL agents, and provide promising venues\nof further research on the psychopathological modeling of complex AI safety\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 01:30:00 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Behzadan", "Vahid", ""], ["Yampolskiy", "Roman V.", ""], ["Munir", "Arslan", ""]]}, {"id": "1811.05614", "submitter": "Ziyao Li", "authors": "Ziyao Li and Liang Zhang and Guojie Song", "title": "SepNE: Bringing Separability to Network Embedding", "comments": "8 pages, 4 figures, accepted in the Proceedings of the 33rd AAAI's\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many successful methods have been proposed for learning low dimensional\nrepresentations on large-scale networks, while almost all existing methods are\ndesigned in inseparable processes, learning embeddings for entire networks even\nwhen only a small proportion of nodes are of interest. This leads to great\ninconvenience, especially on super-large or dynamic networks, where these\nmethods become almost impossible to implement. In this paper, we formalize the\nproblem of separated matrix factorization, based on which we elaborate a novel\nobjective function that preserves both local and global information. We further\npropose SepNE, a simple and flexible network embedding algorithm which\nindependently learns representations for different subsets of nodes in\nseparated processes. By implementing separability, our algorithm reduces the\nredundant efforts to embed irrelevant nodes, yielding scalability to\nsuper-large networks, automatic implementation in distributed learning and\nfurther adaptations. We demonstrate the effectiveness of this approach on\nseveral real-world networks with different scales and subjects. With comparable\naccuracy, our approach significantly outperforms state-of-the-art baselines in\nrunning times on large networks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 02:47:28 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:53:03 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Li", "Ziyao", ""], ["Zhang", "Liang", ""], ["Song", "Guojie", ""]]}, {"id": "1811.05642", "submitter": "Xiao Li", "authors": "Zhihui Zhu, Xiao Li, Kai Liu, and Qiuwei Li", "title": "Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization", "comments": "Accepted in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetric nonnegative matrix factorization (NMF), a special but important\nclass of the general NMF, is demonstrated to be useful for data analysis and in\nparticular for various clustering tasks. Unfortunately, designing fast\nalgorithms for Symmetric NMF is not as easy as for the nonsymmetric\ncounterpart, the latter admitting the splitting property that allows efficient\nalternating-type algorithms. To overcome this issue, we transfer the symmetric\nNMF to a nonsymmetric one, then we can adopt the idea from the state-of-the-art\nalgorithms for nonsymmetric NMF to design fast algorithms solving symmetric\nNMF. We rigorously establish that solving nonsymmetric reformulation returns a\nsolution for symmetric NMF and then apply fast alternating based algorithms for\nthe corresponding reformulated problem. Furthermore, we show these fast\nalgorithms admit strong convergence guarantee in the sense that the generated\nsequence is convergent at least at a sublinear rate and it converges globally\nto a critical point of the symmetric NMF. We conduct experiments on both\nsynthetic data and image clustering to support our result.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 05:09:33 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Zhu", "Zhihui", ""], ["Li", "Xiao", ""], ["Liu", "Kai", ""], ["Li", "Qiuwei", ""]]}, {"id": "1811.05646", "submitter": "Yizheng Liao", "authors": "Yizheng Liao, Yang Weng, Chin-Woo Tan, Ram Rajagopal", "title": "Fast Distribution Grid Line Outage Identification with $\\mu$PMU", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing integration of distributed energy resources (DERs) in urban\ndistribution grids raises various reliability issues due to DER's uncertain and\ncomplex behaviors. With a large-scale DER penetration, traditional outage\ndetection methods, which rely on customers making phone calls and smart meters'\n\"last gasp\" signals, will have limited performance, because the renewable\ngenerators can supply powers after line outages and many urban grids are mesh\nso line outages do not affect power supply. To address these drawbacks, we\npropose a data-driven outage monitoring approach based on the stochastic time\nseries analysis from micro phasor measurement unit ($\\mu$PMU). Specifically, we\nprove via power flow analysis that the dependency of time-series voltage\nmeasurements exhibits significant statistical changes after line outages. This\nmakes the theory on optimal change-point detection suitable to identify line\noutages via $\\mu$PMUs with fast and accurate sampling. However, existing change\npoint detection methods require post-outage voltage distribution unknown in\ndistribution systems. Therefore, we design a maximum likelihood-based method to\ndirectly learn the distribution parameters from $\\mu$PMU data. We prove that\nthe estimated parameters-based detection still achieves the optimal\nperformance, making it extremely useful for distribution grid outage\nidentifications. Simulation results show highly accurate outage identification\nin eight distribution grids with 14 configurations with and without DERs using\n$\\mu$PMU data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 05:19:31 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Liao", "Yizheng", ""], ["Weng", "Yang", ""], ["Tan", "Chin-Woo", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1811.05654", "submitter": "Sandeep Juneja", "authors": "Sandeep Juneja and Subhashini Krishnasamy", "title": "Sample complexity of partition identification using multi-armed bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a vector of probability distributions, or arms, each of which can be\nsampled independently, we consider the problem of identifying the partition to\nwhich this vector belongs from a finitely partitioned universe of such vector\nof distributions. We study this as a pure exploration problem in multi armed\nbandit settings and develop sample complexity bounds on the total mean number\nof samples required for identifying the correct partition with high\nprobability. This framework subsumes well studied problems such as finding the\nbest arm or the best few arms. We consider distributions belonging to the\nsingle parameter exponential family and primarily consider partitions where the\nvector of means of arms lie either in a given set or its complement. The sets\nconsidered correspond to distributions where there exists a mean above a\nspecified threshold, where the set is a half space and where either the set or\nits complement is a polytope, or more generally, a convex set. In these\nsettings, we characterize the lower bounds on mean number of samples for each\narm highlighting their dependence on the problem geometry. Further, inspired by\nthe lower bounds, we propose algorithms that can match these bounds\nasymptotically with decreasing probability of error. Applications of this\nframework may be diverse. We briefly discuss one associated with finance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 05:41:08 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 12:09:25 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Juneja", "Sandeep", ""], ["Krishnasamy", "Subhashini", ""]]}, {"id": "1811.05660", "submitter": "Soumya Sanyal", "authors": "Soumya Sanyal, Janakiraman Balachandran, Naganand Yadati, Abhishek\n  Kumar, Padmini Rajagopalan, Suchismita Sanyal, Partha Talukdar", "title": "MT-CGCNN: Integrating Crystal Graph Convolutional Neural Network with\n  Multitask Learning for Material Property Prediction", "comments": "NIPS Workshop on Machine Learning for Molecules and Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing accurate, transferable and computationally inexpensive machine\nlearning models can rapidly accelerate the discovery and development of new\nmaterials. Some of the major challenges involved in developing such models are,\n(i) limited availability of materials data as compared to other fields, (ii)\nlack of universal descriptor of materials to predict its various properties.\nThe limited availability of materials data can be addressed through transfer\nlearning, while the generic representation was recently addressed by Xie and\nGrossman [1], where they developed a crystal graph convolutional neural network\n(CGCNN) that provides a unified representation of crystals. In this work, we\ndevelop a new model (MT-CGCNN) by integrating CGCNN with transfer learning\nbased on multi-task (MT) learning. We demonstrate the effectiveness of MT-CGCNN\nby simultaneous prediction of various material properties such as Formation\nEnergy, Band Gap and Fermi Energy for a wide range of inorganic crystals (46774\nmaterials). MT-CGCNN is able to reduce the test error when employed on\ncorrelated properties by upto 8%. The model prediction has lower test error\ncompared to CGCNN, even when the training data is reduced by 10%. We also\ndemonstrate our model's better performance through prediction of end user\nscenario related to metal/non-metal classification. These results encourage\nfurther development of machine learning approaches which leverage multi-task\nlearning to address the aforementioned challenges in the discovery of new\nmaterials. We make MT-CGCNN's source code available to encourage reproducible\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 06:13:29 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Sanyal", "Soumya", ""], ["Balachandran", "Janakiraman", ""], ["Yadati", "Naganand", ""], ["Kumar", "Abhishek", ""], ["Rajagopalan", "Padmini", ""], ["Sanyal", "Suchismita", ""], ["Talukdar", "Partha", ""]]}, {"id": "1811.05688", "submitter": "Yixing Guan", "authors": "Yixing Guan, Jinyu Zhao, Yiqin Qiu, Zheng Zhang, Gus Xia", "title": "Melodic Phrase Segmentation By Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated melodic phrase detection and segmentation is a classical task in\ncontent-based music information retrieval and also the key towards automated\nmusic structure analysis. However, traditional methods still cannot satisfy\npractical requirements. In this paper, we explore and adapt various neural\nnetwork architectures to see if they can be generalized to work with the\nsymbolic representation of music and produce satisfactory melodic phrase\nsegmentation. The main issue of applying deep-learning methods to phrase\ndetection is the sparse labeling problem of training sets. We proposed two\ntailored label engineering with corresponding training techniques for different\nneural networks in order to make decisions at a sequential level. Experiment\nresults show that the CNN-CRF architecture performs the best, being able to\noffer finer segmentation and faster to train, while CNN, Bi-LSTM-CNN and\nBi-LSTM-CRF are acceptable alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 08:42:06 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Guan", "Yixing", ""], ["Zhao", "Jinyu", ""], ["Qiu", "Yiqin", ""], ["Zhang", "Zheng", ""], ["Xia", "Gus", ""]]}, {"id": "1811.05695", "submitter": "Xiao He", "authors": "Xiao He, Francesco Alesiani and Ammar Shaker", "title": "Efficient and Scalable Multi-task Regression on Massive Number of Tasks", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world large-scale regression problems can be formulated as\nMulti-task Learning (MTL) problems with a massive number of tasks, as in retail\nand transportation domains. However, existing MTL methods still fail to offer\nboth the generalization performance and the scalability for such problems.\nScaling up MTL methods to problems with a tremendous number of tasks is a big\nchallenge. Here, we propose a novel algorithm, named Convex Clustering\nMulti-Task regression Learning (CCMTL), which integrates with convex clustering\non the k-nearest neighbor graph of the prediction models. Further, CCMTL\nefficiently solves the underlying convex problem with a newly proposed\noptimization method. CCMTL is accurate, efficient to train, and empirically\nscales linearly in the number of tasks. On both synthetic and real-world\ndatasets, the proposed CCMTL outperforms seven state-of-the-art (SoA)\nmulti-task learning methods in terms of prediction accuracy as well as\ncomputational efficiency. On a real-world retail dataset with 23,812 tasks,\nCCMTL requires only around 30 seconds to train on a single thread, while the\nSoA methods need up to hours or even days.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 09:19:39 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["He", "Xiao", ""], ["Alesiani", "Francesco", ""], ["Shaker", "Ammar", ""]]}, {"id": "1811.05844", "submitter": "Gautier Izacard", "authors": "Gautier Izacard, Brett Bernstein and Carlos Fernandez-Granda", "title": "A Learning-Based Framework for Line-Spectra Super-resolution", "comments": "Accepted at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning-based approach for estimating the spectrum of a\nmultisinusoidal signal from a finite number of samples. A neural-network is\ntrained to approximate the spectra of such signals on simulated data. The\nproposed methodology is very flexible: adapting to different signal and noise\nmodels only requires modifying the training data accordingly. Numerical\nexperiments show that the approach performs competitively with classical\nmethods designed for additive Gaussian noise at a range of noise levels, and is\nalso effective in the presence of impulsive noise.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:20:29 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 20:33:33 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Izacard", "Gautier", ""], ["Bernstein", "Brett", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "1811.05850", "submitter": "Senwei Liang", "authors": "Senwei Liang, Yuehaw Khoo, Haizhao Yang", "title": "Drop-Activation: Implicit Parameter Reduction and Harmonic\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting frequently occurs in deep learning. In this paper, we propose a\nnovel regularization method called Drop-Activation to reduce overfitting and\nimprove generalization. The key idea is to drop nonlinear activation functions\nby setting them to be identity functions randomly during training time. During\ntesting, we use a deterministic network with a new activation function to\nencode the average effect of dropping activations randomly. Our theoretical\nanalyses support the regularization effect of Drop-Activation as implicit\nparameter reduction and verify its capability to be used together with Batch\nNormalization (Ioffe and Szegedy 2015). The experimental results on CIFAR-10,\nCIFAR-100, SVHN, EMNIST, and ImageNet show that Drop-Activation generally\nimproves the performance of popular neural network architectures for the image\nclassification task. Furthermore, as a regularizer Drop-Activation can be used\nin harmony with standard training and regularization techniques such as Batch\nNormalization and Auto Augment (Cubuk et al. 2019). The code is available at\n\\url{https://github.com/LeungSamWai/Drop-Activation}.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:27:56 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 04:00:30 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 01:10:35 GMT"}, {"version": "v4", "created": "Mon, 3 Jun 2019 11:05:48 GMT"}, {"version": "v5", "created": "Sat, 28 Mar 2020 19:08:30 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Liang", "Senwei", ""], ["Khoo", "Yuehaw", ""], ["Yang", "Haizhao", ""]]}, {"id": "1811.05852", "submitter": "Kelli Humbird", "authors": "K. D. Humbird, J. L. Peterson, R. G. McClarren", "title": "Predicting the time-evolution of multi-physics systems with\n  sequence-to-sequence models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, sequence-to-sequence (seq2seq) models, originally developed for\nlanguage translation, are used to predict the temporal evolution of complex,\nmulti-physics computer simulations. The predictive performance of seq2seq\nmodels is compared to state transition models for datasets generated with\nmulti-physics codes with varying levels of complexity - from simple 1D\ndiffusion calculations to simulations of inertial confinement fusion\nimplosions. Seq2seq models demonstrate the ability to accurately emulate\ncomplex systems, enabling the rapid estimation of the evolution of quantities\nof interest in computationally expensive simulations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:36:46 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Humbird", "K. D.", ""], ["Peterson", "J. L.", ""], ["McClarren", "R. G.", ""]]}, {"id": "1811.05868", "submitter": "Oleksandr Shchur", "authors": "Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, Stephan\n  G\\\"unnemann", "title": "Pitfalls of Graph Neural Network Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised node classification in graphs is a fundamental problem in\ngraph mining, and the recently proposed graph neural networks (GNNs) have\nachieved unparalleled results on this task. Due to their massive success, GNNs\nhave attracted a lot of attention, and many novel architectures have been put\nforward. In this paper we show that existing evaluation strategies for GNN\nmodels have serious shortcomings. We show that using the same\ntrain/validation/test splits of the same datasets, as well as making\nsignificant changes to the training procedure (e.g. early stopping criteria)\nprecludes a fair comparison of different architectures. We perform a thorough\nempirical evaluation of four prominent GNN models and show that considering\ndifferent splits of the data leads to dramatically different rankings of\nmodels. Even more importantly, our findings suggest that simpler GNN\narchitectures are able to outperform the more sophisticated ones if the\nhyperparameters and the training procedure are tuned fairly for all models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:53:19 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 13:15:39 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Shchur", "Oleksandr", ""], ["Mumme", "Maximilian", ""], ["Bojchevski", "Aleksandar", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1811.05869", "submitter": "Haokun Chen", "authors": "Haokun Chen, Xinyi Dai, Han Cai, Weinan Zhang, Xuejian Wang, Ruiming\n  Tang, Yuzhou Zhang, Yong Yu", "title": "Large-scale Interactive Recommendation with Tree-structured Policy\n  Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has recently been introduced to interactive\nrecommender systems (IRS) because of its nature of learning from dynamic\ninteractions and planning for long-run performance. As IRS is always with\nthousands of items to recommend (i.e., thousands of actions), most existing\nRL-based methods, however, fail to handle such a large discrete action space\nproblem and thus become inefficient. The existing work that tries to deal with\nthe large discrete action space problem by utilizing the deep deterministic\npolicy gradient framework suffers from the inconsistency between the continuous\naction representation (the output of the actor network) and the real discrete\naction. To avoid such inconsistency and achieve high efficiency and\nrecommendation effectiveness, in this paper, we propose a Tree-structured\nPolicy Gradient Recommendation (TPGR) framework, where a balanced hierarchical\nclustering tree is built over the items and picking an item is formulated as\nseeking a path from the root to a certain leaf of the tree. Extensive\nexperiments on carefully-designed environments based on two real-world datasets\ndemonstrate that our model provides superior recommendation performance and\nsignificant efficiency improvement over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:53:25 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Chen", "Haokun", ""], ["Dai", "Xinyi", ""], ["Cai", "Han", ""], ["Zhang", "Weinan", ""], ["Wang", "Xuejian", ""], ["Tang", "Ruiming", ""], ["Zhang", "Yuzhou", ""], ["Yu", "Yong", ""]]}, {"id": "1811.05910", "submitter": "Jonas Adler", "authors": "Jonas Adler, Ozan \\\"Oktem", "title": "Deep Bayesian Inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing statistical properties of solutions of inverse problems is\nessential for decision making. Bayesian inversion offers a tractable framework\nfor this purpose, but current approaches are computationally unfeasible for\nmost realistic imaging applications in the clinic. We introduce two novel deep\nlearning based methods for solving large-scale inverse problems using Bayesian\ninversion: a sampling based method using a WGAN with a novel mini-discriminator\nand a direct approach that trains a neural network using a novel loss function.\nThe performance of both methods is demonstrated on image reconstruction in\nultra low dose 3D helical CT. We compute the posterior mean and standard\ndeviation of the 3D images followed by a hypothesis test to assess whether a\n\"dark spot\" in the liver of a cancer stricken patient is present. Both methods\nare computationally efficient and our evaluation shows very promising\nperformance that clearly supports the claim that Bayesian inversion is usable\nfor 3D imaging in time critical applications.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 17:06:56 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Adler", "Jonas", ""], ["\u00d6ktem", "Ozan", ""]]}, {"id": "1811.05922", "submitter": "Assaf Eisenman", "authors": "Assaf Eisenman, Maxim Naumov, Darryl Gardner, Misha Smelyanskiy,\n  Sergey Pupyrev, Kim Hazelwood, Asaf Cidon, Sachin Katti", "title": "Bandana: Using Non-volatile Memory for Storing Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical large-scale recommender systems use deep learning models that are\nstored on a large amount of DRAM. These models often rely on embeddings, which\nconsume most of the required memory. We present Bandana, a storage system that\nreduces the DRAM footprint of embeddings, by using Non-volatile Memory (NVM) as\nthe primary storage medium, with a small amount of DRAM as cache. The main\nchallenge in storing embeddings on NVM is its limited read bandwidth compared\nto DRAM. Bandana uses two primary techniques to address this limitation: first,\nit stores embedding vectors that are likely to be read together in the same\nphysical location, using hypergraph partitioning, and second, it decides the\nnumber of embedding vectors to cache in DRAM by simulating dozens of small\ncaches. These techniques allow Bandana to increase the effective read bandwidth\nof NVM by 2-3x and thereby significantly reduce the total cost of ownership.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 17:47:33 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 01:48:26 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Eisenman", "Assaf", ""], ["Naumov", "Maxim", ""], ["Gardner", "Darryl", ""], ["Smelyanskiy", "Misha", ""], ["Pupyrev", "Sergey", ""], ["Hazelwood", "Kim", ""], ["Cidon", "Asaf", ""], ["Katti", "Sachin", ""]]}, {"id": "1811.05927", "submitter": "Zheng Tracy Ke", "authors": "Jiashun Jin, Zheng Tracy Ke, Shengming Luo", "title": "SCORE+ for Network Community Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SCORE is a recent approach to network community detection proposed by Jin\n(2015). In this note, we propose a simple improvement of SCORE, called SCORE+,\nand compare its performance with several other methods, using 10 different\nnetwork data sets. For 7 of these data sets, the performances of SCORE and\nSCORE+ are similar, but for the other 3 data sets (Polbooks, Simmons, Caltech),\nSCORE+ provides a significant improvement.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 17:53:33 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Jin", "Jiashun", ""], ["Ke", "Zheng Tracy", ""], ["Luo", "Shengming", ""]]}, {"id": "1811.05932", "submitter": "Xi Liu", "authors": "Xi Liu, Ping-Chun Hsieh, Nick Duffield, Rui Chen, Muhe Xie, Xidao Wen", "title": "Streaming Network Embedding through Local Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, considerable research attention has been paid to network embedding,\na popular approach to construct feature vectors of vertices. Due to the curse\nof dimensionality and sparsity in graphical datasets, this approach has become\nindispensable for machine learning tasks over large networks. The majority of\nexisting literature has considered this technique under the assumption that the\nnetwork is static. However, networks in many applications, nodes and edges\naccrue to a growing network as a streaming. A small number of very recent\nresults have addressed the problem of embedding for dynamic networks. However,\nthey either rely on knowledge of vertex attributes, suffer high-time complexity\nor need to be re-trained without closed-form expression. Thus the approach of\nadapting the existing methods to the streaming environment faces non-trivial\ntechnical challenges.\n  These challenges motivate developing new approaches to the problems of\nstreaming network embedding. In this paper, We propose a new framework that is\nable to generate latent features for new vertices with high efficiency and low\ncomplexity under specified iteration rounds. We formulate a constrained\noptimization problem for the modification of the representation resulting from\na stream arrival. We show this problem has no closed-form solution and instead\ndevelop an online approximation solution. Our solution follows three steps: (1)\nidentify vertices affected by new vertices, (2) generate latent features for\nnew vertices, and (3) update the latent features of the most affected vertices.\nThe generated representations are provably feasible and not far from the\noptimal ones in terms of expectation. Multi-class classification and clustering\non five real-world networks demonstrate that our model can efficiently update\nvertex representations and simultaneously achieve comparable or even better\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 18:02:29 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Liu", "Xi", ""], ["Hsieh", "Ping-Chun", ""], ["Duffield", "Nick", ""], ["Chen", "Rui", ""], ["Xie", "Muhe", ""], ["Wen", "Xidao", ""]]}, {"id": "1811.05933", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou, Bernhard Sch\\\"olkopf", "title": "Deep Nonlinear Non-Gaussian Filtering for Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filtering is a general name for inferring the states of a dynamical system\ngiven observations. The most common filtering approach is Gaussian Filtering\n(GF) where the distribution of the inferred states is a Gaussian whose mean is\nan affine function of the observations. There are two restrictions in this\nmodel: Gaussianity and Affinity. We propose a model to relax both these\nassumptions based on recent advances in implicit generative models. Empirical\nresults show that the proposed method gives a significant advantage over GF and\nnonlinear methods based on fixed nonlinear kernels.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 18:02:58 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Mehrjou", "Arash", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1811.05965", "submitter": "Eli Sennesh", "authors": "Eli Sennesh, Adam \\'Scibior, Hao Wu, Jan-Willem van de Meent", "title": "Composing Modeling and Inference Operations with Probabilistic Program\n  Combinators", "comments": "Published at the NeurIPS workshop \"All of Bayesian Nonparametrics\n  (Especially the Useful Bits)\" 2018\n  (https://sites.google.com/view/nipsbnp2018/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programs with dynamic computation graphs can define measures\nover sample spaces with unbounded dimensionality, which constitute programmatic\nanalogues to Bayesian nonparametrics. Owing to the generality of this model\nclass, inference relies on `black-box' Monte Carlo methods that are often not\nable to take advantage of conditional independence and exchangeability, which\nhave historically been the cornerstones of efficient inference. We here seek to\ndevelop a `middle ground' between probabilistic models with fully dynamic and\nfully static computation graphs. To this end, we introduce a combinator library\nfor the Probabilistic Torch framework. Combinators are functions that accept\nmodels and return transformed models. We assume that models are dynamic, but\nthat model composition is static, in the sense that combinator application\ntakes place prior to evaluating the model on data. Combinators provide\nprimitives for both model and inference composition. Model combinators take the\nform of classic functional programming constructs such as map and reduce. These\nconstructs define a computation graph at a coarsened level of representation,\nin which nodes correspond to models, rather than individual variables.\nInference combinators implement operations such as importance resampling and\napplication of a transition kernel, which alter the evaluation strategy for a\nmodel whilst preserving proper weighting. Owing to this property, models\ndefined using combinators can be trained using stochastic methods that optimize\neither variational or wake-sleep style objectives. As a validation of this\nprinciple, we use combinators to implement black box inference for hidden\nMarkov models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 18:53:28 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 14:16:04 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 01:05:58 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Sennesh", "Eli", ""], ["\u015acibior", "Adam", ""], ["Wu", "Hao", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1811.05975", "submitter": "Fredrik D. Johansson", "authors": "Fredrik D. Johansson", "title": "Machine Learning Analysis of Heterogeneity in the Effect of Student\n  Mindset Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study heterogeneity in the effect of a mindset intervention on\nstudent-level performance through an observational dataset from the National\nStudy of Learning Mindsets (NSLM). Our analysis uses machine learning (ML) to\naddress the following associated problems: assessing treatment group overlap\nand covariate balance, imputing conditional average treatment effects, and\ninterpreting imputed effects. By comparing several different model families we\nillustrate the flexibility of both off-the-shelf and purpose-built estimators.\nWe find that the mindset intervention has a positive average effect of 0.26,\n95%-CI [0.22, 0.30], and that heterogeneity in the range of [0.1, 0.4] is\nmoderated by school-level achievement level, poverty concentration, urbanicity,\nand student prior expectations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 13:43:39 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Johansson", "Fredrik D.", ""]]}, {"id": "1811.06002", "submitter": "Gennady Ososkov Alexeevich", "authors": "Dmitriy Baranov, Gennady Ososkov, Pavel Goncharov, Andrei Tsytrinov", "title": "Catch and Prolong: recurrent neural network for seeking track-candidates", "comments": "5 pages, 1 figure, XXII International Scientific Conference of Young\n  Scientists and Specialists (AYSS-2018), April 23-27, 2018,\n  http://ayss-2018.jinr.ru", "journal-ref": null, "doi": "10.1051/epjconf/201920105001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most important problems of data processing in high energy and\nnuclear physics is the event reconstruction. Its main part is the track\nreconstruction procedure which consists in looking for all tracks that\nelementary particles leave when they pass through a detector among a huge\nnumber of points, so-called hits, produced when flying particles fire detector\ncoordinate planes. Unfortunately, the tracking is seriously impeded by the\nfamous shortcoming of multiwired, strip and GEM detectors due to appearance in\nthem a lot of fake hits caused by extra spurious crossings of fired strips.\nSince the number of those fakes is several orders of magnitude greater than for\ntrue hits, one faces with the quite serious difficulty to unravel possible\ntrack-candidates via true hits ignoring fakes. We introduce a renewed method\nthat is a significant improvement of our previous two-stage approach based on\nhit preprocessing using directed K-d tree search followed a deep neural\nclassifier. We combine these two stages in one by applying recurrent neural\nnetwork that simultaneously determines whether a set of points belongs to a\ntrue track or not and predicts where to look for the next point of track on the\nnext coordinate plane of the detector. We show that proposed deep network is\nmore accurate, faster and does not require any special preprocessing stage.\nPreliminary results of our approach for simulated events of the BM@N GEM\ndetector are presented.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 19:03:26 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Baranov", "Dmitriy", ""], ["Ososkov", "Gennady", ""], ["Goncharov", "Pavel", ""], ["Tsytrinov", "Andrei", ""]]}, {"id": "1811.06017", "submitter": "Cunxi Yu", "authors": "Cunxi Yu and Wang Zhou", "title": "Performance Estimation of Synthesis Flows cross Technologies using LSTMs\n  and Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing complexity of Integrated Circuits (ICs) and\nSystem-on-Chip (SoC), developing high-quality synthesis flows within a short\nmarket time becomes more challenging. We propose a general approach that\nprecisely estimates the Quality-of-Result (QoR), such as delay and area, of\nunseen synthesis flows for specific designs. The main idea is training a\nRecurrent Neural Network (RNN) regressor, where the flows are inputs and QoRs\nare ground truth. The RNN regressor is constructed with Long Short-Term Memory\n(LSTM) and fully-connected layers. This approach is demonstrated with 1.2\nmillion data points collected using 14nm, 7nm regular-voltage (RVT), and 7nm\nlow-voltage (LVT) FinFET technologies with twelve IC designs. The accuracy of\npredicting the QoRs (delay and area) within one technology is\n$\\boldsymbol{\\geq}$\\textbf{98.0}\\% over $\\sim$240,000 test points. To enable\naccurate predictions cross different technologies and different IC designs, we\npropose a transfer-learning approach that utilizes the model pre-trained with\n14nm datasets. Our transfer learning approach obtains estimation accuracy\n$\\geq$96.3\\% over $\\sim$960,000 test points, using only 100 data points for\ntraining.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 19:17:14 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Yu", "Cunxi", ""], ["Zhou", "Wang", ""]]}, {"id": "1811.06029", "submitter": "Qinglong Wang", "authors": "Qinglong Wang, Kaixuan Zhang, Xue Liu, C. Lee Giles", "title": "Verification of Recurrent Neural Networks Through Rule Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification problem for neural networks is verifying whether a neural\nnetwork will suffer from adversarial samples, or approximating the maximal\nallowed scale of adversarial perturbation that can be endured. While most prior\nwork contributes to verifying feed-forward networks, little has been explored\nfor verifying recurrent networks. This is due to the existence of a more\nrigorous constraint on the perturbation space for sequential data, and the lack\nof a proper metric for measuring the perturbation. In this work, we address\nthese challenges by proposing a metric which measures the distance between\nstrings, and use deterministic finite automata (DFA) to represent a rigorous\noracle which examines if the generated adversarial samples violate certain\nconstraints on a perturbation. More specifically, we empirically show that\ncertain recurrent networks allow relatively stable DFA extraction. As such,\nDFAs extracted from these recurrent networks can serve as a surrogate oracle\nfor when the ground truth DFA is unknown. We apply our verification mechanism\nto several widely used recurrent networks on a set of the Tomita grammars. The\nresults demonstrate that only a few models remain robust against adversarial\nsamples. In addition, we show that for grammars with different levels of\ncomplexity, there is also a difference in the difficulty of robust learning of\nthese grammars.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 19:40:30 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wang", "Qinglong", ""], ["Zhang", "Kaixuan", ""], ["Liu", "Xue", ""], ["Giles", "C. Lee", ""]]}, {"id": "1811.06032", "submitter": "Amy Zhang", "authors": "Amy Zhang, Yuxin Wu, Joelle Pineau", "title": "Natural Environment Benchmarks for Reinforcement Learning", "comments": "12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While current benchmark reinforcement learning (RL) tasks have been useful to\ndrive progress in the field, they are in many ways poor substitutes for\nlearning with real-world data. By testing increasingly complex RL algorithms on\nlow-complexity simulation environments, we often end up with brittle RL\npolicies that generalize poorly beyond the very specific domain. To combat\nthis, we propose three new families of benchmark RL domains that contain some\nof the complexity of the natural world, while still supporting fast and\nextensive data acquisition. The proposed domains also permit a characterization\nof generalization through fair train/test separation, and easy comparison and\nreplication of results. Through this work, we challenge the RL research\ncommunity to develop more robust algorithms that meet high standards of\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 19:50:54 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Zhang", "Amy", ""], ["Wu", "Yuxin", ""], ["Pineau", "Joelle", ""]]}, {"id": "1811.06055", "submitter": "Chao Gao", "authors": "Chao Gao and Zongming Ma", "title": "Minimax Rates in Network Analysis: Graphon Estimation, Community\n  Detection and Hypothesis Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys some recent developments in fundamental limits and optimal\nalgorithms for network analysis. We focus on minimax optimal rates in three\nfundamental problems of network analysis: graphon estimation, community\ndetection, and hypothesis testing. For each problem, we review state-of-the-art\nresults in the literature followed by general principles behind the optimal\nprocedures that lead to minimax estimation and testing. This allows us to\nconnect problems in network analysis to other statistical inference problems\nfrom a general perspective.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 20:49:47 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 05:34:34 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Gao", "Chao", ""], ["Ma", "Zongming", ""]]}, {"id": "1811.06060", "submitter": "Truyen Tran", "authors": "Phuoc Nguyen, Truyen Tran, Sunil Gupta, Santu Rana and Svetha\n  Venkatesh", "title": "Hybrid Generative-Discriminative Models for Inverse Materials Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering new physical products and processes often demands enormous\nexperimentation and expensive simulation. To design a new product with certain\ntarget characteristics, an extensive search is performed in the design space by\ntrying out a large number of design combinations before reaching to the target\ncharacteristics. However, forward searching for the target design becomes\nprohibitive when the target is itself moving or only partially understood. To\naddress this bottleneck, we propose to use backward prediction by leveraging\nthe rich data generated during earlier exploration and construct a machine\nlearning framework to predict the design parameters for any target in a single\nstep. This poses two technical challenges: the first caused due to one-to-many\nmapping when learning the inverse problem and the second caused due to an user\nspecifying the target specifications only partially. To overcome the\nchallenges, we formulate this problem as conditional density estimation under\nhigh-dimensional setting with incomplete input and multimodal output. We solve\nthe problem through a deep hybrid generative-discriminative model, which is\ntrained end-to-end to predict the optimum design.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 03:04:41 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Nguyen", "Phuoc", ""], ["Tran", "Truyen", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1811.06067", "submitter": "Sambuddha Ghosal", "authors": "Balaji Sesha Sarath Pokuri, Sambuddha Ghosal, Apurva Kokate, Baskar\n  Ganapathysubramanian and Soumik Sarkar", "title": "Interpretable deep learning for guided structure-property explorations\n  in photovoltaics", "comments": "Workshop on Machine Learning for Molecules and Materials (MLMM),\n  Neural Information Processing Systems (NeurIPS) 2018, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of an organic photovoltaic device is intricately connected to\nits active layer morphology. This connection between the active layer and\ndevice performance is very expensive to evaluate, either experimentally or\ncomputationally. Hence, designing morphologies to achieve higher performances\nis non-trivial and often intractable. To solve this, we first introduce a deep\nconvolutional neural network (CNN) architecture that can serve as a fast and\nrobust surrogate for the complex structure-property map. Several tests were\nperformed to gain trust in this trained model. Then, we utilize this fast\nframework to perform robust microstructural design to enhance device\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 21:08:08 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 19:59:56 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2018 02:14:14 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Pokuri", "Balaji Sesha Sarath", ""], ["Ghosal", "Sambuddha", ""], ["Kokate", "Apurva", ""], ["Ganapathysubramanian", "Baskar", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1811.06083", "submitter": "Ruidi Chen", "authors": "Ruidi Chen, and Ioannis Paschalidis", "title": "Learning Optimal Personalized Treatment Rules Using Robust Regression\n  Informed K-NN", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a prediction-based prescriptive model for learning optimal\npersonalized treatments for patients based on their Electronic Health Records\n(EHRs). Our approach consists of: (i) predicting future outcomes under each\npossible therapy using a robustified nonlinear model, and (ii) adopting a\nrandomized prescriptive policy determined by the predicted outcomes. We show\ntheoretical results that guarantee the out-of-sample predictive power of the\nmodel, and prove the optimality of the randomized strategy in terms of the\nexpected true future outcome. We apply the proposed methodology to develop\noptimal therapies for patients with type 2 diabetes or hypertension using EHRs\nfrom a major safety-net hospital in New England, and show that our algorithm\nleads to a larger reduction of the HbA1c, for diabetics, or systolic blood\npressure, for patients with hypertension, compared to the alternatives. We\ndemonstrate that our approach outperforms the standard of care under the\nrobustified nonlinear predictive model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 21:46:56 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 18:14:23 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 18:25:30 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Chen", "Ruidi", ""], ["Paschalidis", "Ioannis", ""]]}, {"id": "1811.06094", "submitter": "Soumya Ghosh", "authors": "Kristen Severson, Soumya Ghosh, Kenney Ng", "title": "Unsupervised learning with contrastive latent variable models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unsupervised learning, dimensionality reduction is an important tool for\ndata exploration and visualization. Because these aims are typically\nopen-ended, it can be useful to frame the problem as looking for patterns that\nare enriched in one dataset relative to another. These pairs of datasets occur\ncommonly, for instance a population of interest vs. control or signal vs.\nsignal free recordings.However, there are few methods that work on sets of data\nas opposed to data points or sequences. Here, we present a probabilistic model\nfor dimensionality reduction to discover signal that is enriched in the target\ndataset relative to the background dataset. The data in these sets do not need\nto be paired or grouped beyond set membership. By using a probabilistic model\nwhere some structure is shared amongst the two datasets and some is unique to\nthe target dataset, we are able to recover interesting structure in the latent\nspace of the target dataset. The method also has the advantages of a\nprobabilistic model, namely that it allows for the incorporation of prior\ninformation, handles missing data, and can be generalized to different\ndistributional assumptions. We describe several possible variations of the\nmodel and demonstrate the application of the technique to de-noising, feature\nselection, and subgroup discovery settings.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 22:12:56 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Severson", "Kristen", ""], ["Ghosh", "Soumya", ""], ["Ng", "Kenney", ""]]}, {"id": "1811.06100", "submitter": "Kent Loong Tan", "authors": "Chien-Chih Wang, Kent Loong Tan, Chih-Jen Lin", "title": "Newton Methods for Convolutional Neural Networks", "comments": "Supplementary materials, experimental code and an efficient MATLAB\n  implementation are available at https://www.csie.ntu.edu.tw/~cjlin/cnn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning involves a difficult non-convex optimization problem, which is\noften solved by stochastic gradient (SG) methods. While SG is usually\neffective, it may not be robust in some situations. Recently, Newton methods\nhave been investigated as an alternative optimization technique, but nearly all\nexisting studies consider only fully-connected feedforward neural networks.\nThey do not investigate other types of networks such as Convolutional Neural\nNetworks (CNN), which are more commonly used in deep-learning applications. One\nreason is that Newton methods for CNN involve complicated operations, and so\nfar no works have conducted a thorough investigation. In this work, we give\ndetails of all building blocks including function, gradient, and Jacobian\nevaluation, and Gauss-Newton matrix-vector products. These basic components are\nvery important because with them further developments of Newton methods for CNN\nbecome possible. We show that an efficient MATLAB implementation can be done in\njust several hundred lines of code and demonstrate that the Newton method gives\ncompetitive test accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 22:29:37 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wang", "Chien-Chih", ""], ["Tan", "Kent Loong", ""], ["Lin", "Chih-Jen", ""]]}, {"id": "1811.06103", "submitter": "S. Asim Ahmed", "authors": "S. Asim Ahmed, Subhashish Chakravarty and Michael Newhouse", "title": "Deep Neural Networks based Modrec: Some Results with Inter-Symbol\n  Interference and Adversarial Examples", "comments": "4 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes and advances in Deep Neural Networks (DNN) in machine vision\nand Natural Language Processing (NLP) have motivated their use in traditional\nsignal processing and communications systems. In this paper, we present results\nof such applications to the problem of automatic modulation recognition.\nVariations in wireless communication channels are represented by statistical\nchannel models and their parameterization will increase with the advent of 5G.\nIn this paper, we report effect of simple two path channel model on our naive\ndeep neural network based implementation. We also report impact of adversarial\nperturbation to the input signal.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 22:36:47 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Ahmed", "S. Asim", ""], ["Chakravarty", "Subhashish", ""], ["Newhouse", "Michael", ""]]}, {"id": "1811.06106", "submitter": "Jonathan Rubin", "authors": "Jwala Dhamala, Emmanuel Azuh, Abdullah Al-Dujaili, Jonathan Rubin and\n  Una-May O'Reilly", "title": "Multivariate Time-series Similarity Assessment via Unsupervised\n  Representation Learning and Stratified Locality Sensitive Hashing:\n  Application to Early Acute Hypotensive Episode Detection", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/66", "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely prediction of clinically critical events in Intensive Care Unit (ICU)\nis important for improving care and survival rate. Most of the existing\napproaches are based on the application of various classification methods on\nexplicitly extracted statistical features from vital signals. In this work, we\npropose to eliminate the high cost of engineering hand-crafted features from\nmultivariate time-series of physiologic signals by learning their\nrepresentation with a sequence-to-sequence auto-encoder. We then propose to\nhash the learned representations to enable signal similarity assessment for the\nprediction of critical events. We apply this methodological framework to\npredict Acute Hypotensive Episodes (AHE) on a large and diverse dataset of\nvital signal recordings. Experiments demonstrate the ability of the presented\nframework in accurately predicting an upcoming AHE.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 22:53:40 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 22:11:23 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 15:25:50 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Dhamala", "Jwala", ""], ["Azuh", "Emmanuel", ""], ["Al-Dujaili", "Abdullah", ""], ["Rubin", "Jonathan", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1811.06109", "submitter": "Junxuan Li", "authors": "Junxuan Li, Yung-wen Liu, Yuting Jia, Yifei Ren, Jay Nanduri", "title": "Predictive Modeling with Delayed Information: a Case Study in E-commerce\n  Transaction Fraud Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Business Intelligence, accurate predictive modeling is the key for\nproviding adaptive decisions. We studied predictive modeling problems in this\nresearch which was motivated by real-world cases that Microsoft data scientists\nencountered while dealing with e-commerce transaction fraud control decisions\nusing transaction streaming data in an uncertain probabilistic decision\nenvironment. The values of most online transactions related features can return\ninstantly, while the true fraud labels only return after a stochastic delay.\nUsing partially mature data directly for predictive modeling in an uncertain\nprobabilistic decision environment would lead to significant inaccuracy on risk\ndecision-making. To improve accurate estimation of the probabilistic prediction\nenvironment, which leads to more accurate predictive modeling, two frameworks,\nCurrent Environment Inference (CEI) and Future Environment Inference (FEI), are\nproposed. These frameworks generated decision environment related features\nusing long-term fully mature and short-term partially mature data, and the\nvalues of those features were estimated using varies of learning methods,\nincluding linear regression, random forest, gradient boosted tree, artificial\nneural network, and recurrent neural network. Performance tests were conducted\nusing some e-commerce transaction data from Microsoft. Testing results\nsuggested that proposed frameworks significantly improved the accuracy of\ndecision environment estimation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 23:08:14 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Li", "Junxuan", ""], ["Liu", "Yung-wen", ""], ["Jia", "Yuting", ""], ["Ren", "Yifei", ""], ["Nanduri", "Jay", ""]]}, {"id": "1811.06128", "submitter": "Antoine Prouvost", "authors": "Yoshua Bengio and Andrea Lodi and Antoine Prouvost", "title": "Machine Learning for Combinatorial Optimization: a Methodological Tour\n  d'Horizon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper surveys the recent attempts, both from the machine learning and\noperations research communities, at leveraging machine learning to solve\ncombinatorial optimization problems. Given the hard nature of these problems,\nstate-of-the-art algorithms rely on handcrafted heuristics for making decisions\nthat are otherwise too expensive to compute or mathematically not well defined.\nThus, machine learning looks like a natural candidate to make such decisions in\na more principled and optimized way. We advocate for pushing further the\nintegration of machine learning and combinatorial optimization and detail a\nmethodology to do so. A main point of the paper is seeing generic optimization\nproblems as data points and inquiring what is the relevant distribution of\nproblems to use for learning on a given task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 00:40:32 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 18:53:21 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Bengio", "Yoshua", ""], ["Lodi", "Andrea", ""], ["Prouvost", "Antoine", ""]]}, {"id": "1811.06146", "submitter": "Liang Zhang", "authors": "Liang Zhang, Gang Wang, Georgios B. Giannakis", "title": "Real-time Power System State Estimation and Forecasting via Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2926023", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary power grids are being challenged by rapid voltage fluctuations\nthat are caused by large-scale deployment of renewable generation, electric\nvehicles, and demand response programs. In this context, monitoring the grid's\noperating conditions in real time becomes increasingly critical. With the\nemergent large scale and nonconvexity however, the existing power system state\nestimation (PSSE) schemes become computationally expensive or yield suboptimal\nperformance. To bypass these hurdles, this paper advocates deep neural networks\n(DNNs) for real-time power system monitoring. By unrolling an iterative\nphysics-based prox-linear solver, a novel model-specific DNN is developed for\nreal-time PSSE with affordable training and minimal tuning effort. To further\nenable system awareness even ahead of the time horizon, as well as to endow the\nDNN-based estimator with resilience, deep recurrent neural networks (RNNs) are\nalso pursued for power system state forecasting. Deep RNNs leverage the\nlong-term nonlinear dependencies present in the historical voltage time series\nto enable forecasting, and they are easy to implement. Numerical tests showcase\nimproved performance of the proposed DNN-based estimation and forecasting\napproaches compared with existing alternatives. In real load data experiments\non the IEEE 118-bus benchmark system, the novel model-specific DNN-based PSSE\nscheme outperforms nearly by an order-of-magnitude the competing alternatives,\nincluding the widely adopted Gauss-Newton PSSE solver.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 02:41:01 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 03:02:40 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Liang", ""], ["Wang", "Gang", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1811.06149", "submitter": "Maryam Aziz", "authors": "Maryam Aziz and Kevin Jamieson and Javed Aslam", "title": "Pure-Exploration for Infinite-Armed Bandits with General Arm Reservoirs", "comments": "We found an irrecoverable error in one of the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a multi-armed bandit game where the number of arms is\nmuch larger than the maximum budget and is effectively infinite. We\ncharacterize necessary and sufficient conditions on the total budget for an\nalgorithm to return an {\\epsilon}-good arm with probability at least 1 -\n{\\delta}. In such situations, the sample complexity depends on {\\epsilon},\n{\\delta} and the so-called reservoir distribution {\\nu} from which the means of\nthe arms are drawn iid. While a substantial literature has developed around\nanalyzing specific cases of {\\nu} such as the beta distribution, our analysis\nmakes no assumption about the form of {\\nu}. Our algorithm is based on\nsuccessive halving with the surprising exception that arms start to be\ndiscarded after just a single pull, requiring an analysis that goes beyond\nconcentration alone. The provable correctness of this algorithm also provides\nan explanation for the empirical observation that the most aggressive bracket\nof the Hyperband algorithm of Li et al. (2017) for hyperparameter tuning is\nalmost always best.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 02:51:04 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 00:04:15 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Aziz", "Maryam", ""], ["Jamieson", "Kevin", ""], ["Aslam", "Javed", ""]]}, {"id": "1811.06199", "submitter": "Trung Le", "authors": "Trung Le, Khanh Nguyen, Nhat Ho, Hung Bui, Dinh Phung", "title": "On Deep Domain Adaptation: Some Theoretical Understandings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with shallow domain adaptation, recent progress in deep domain\nadaptation has shown that it can achieve higher predictive performance and\nstronger capacity to tackle structural data (e.g., image and sequential data).\nThe underlying idea of deep domain adaptation is to bridge the gap between\nsource and target domains in a joint space so that a supervised classifier\ntrained on labeled source data can be nicely transferred to the target domain.\nThis idea is certainly intuitive and powerful, however, limited theoretical\nunderstandings have been developed to support its underpinning principle. In\nthis paper, we have provided a rigorous framework to explain why it is possible\nto close the gap of the target and source domains in the joint space. More\nspecifically, we first study the loss incurred when performing transfer\nlearning from the source to the target domain. This provides a theory that\nexplains and generalizes existing work in deep domain adaptation which was\nmainly empirical. This enables us to further explain why closing the gap in the\njoint space can directly minimize the loss incurred for transfer learning\nbetween the two domains. To our knowledge, this offers the first theoretical\nresult that characterizes a direct bound on the joint space and the gain of\ntransfer learning via deep domain adaptation\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 06:27:15 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 00:48:19 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 23:41:40 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Le", "Trung", ""], ["Nguyen", "Khanh", ""], ["Ho", "Nhat", ""], ["Bui", "Hung", ""], ["Phung", "Dinh", ""]]}, {"id": "1811.06210", "submitter": "Yu Nishiyama", "authors": "Shunsuke Tsuzuki and Yu Nishiyama", "title": "Short-Term Wind-Speed Forecasting Using Kernel Spectral Hidden Markov\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, a nonparametric forecasting algorithm for time series\ndata has been proposed, called the kernel spectral hidden Markov model (KSHMM).\nIn this paper, we propose a technique for short-term wind-speed prediction\nbased on KSHMM. We numerically compared the performance of our KSHMM-based\nforecasting technique to other techniques with machine learning, using\nwind-speed data offered by the National Renewable Energy Laboratory. Our\nresults demonstrate that, compared to these methods, the proposed technique\noffers comparable or better performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 07:26:19 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Tsuzuki", "Shunsuke", ""], ["Nishiyama", "Yu", ""]]}, {"id": "1811.06225", "submitter": "Sergey Pankov", "authors": "Sergey Pankov", "title": "Reward-estimation variance elimination in sequential decision processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are very attractive in reinforcement learning due to\ntheir model-free nature and convergence guarantees. These methods, however,\nsuffer from high variance in gradient estimation, resulting in poor sample\nefficiency. To mitigate this issue, a number of variance-reduction approaches\nhave been proposed. Unfortunately, in the challenging problems with delayed\nrewards, these approaches either bring a relatively modest improvement or do\nreduce variance at expense of introducing a bias and undermining convergence.\nThe unbiased methods of gradient estimation, in general, only partially reduce\nvariance, without eliminating it completely even in the limit of exact\nknowledge of the value functions and problem dynamics, as one might have\nwished. In this work we propose an unbiased method that does completely\neliminate variance under some, commonly encountered, conditions. Of practical\ninterest is the limit of deterministic dynamics and small policy stochasticity.\nIn the case of a quadratic value function, as in linear quadratic Gaussian\nmodels, the policy randomness need not be small. We use such a model to analyze\nperformance of the proposed variance-elimination approach and compare it with\nstandard variance-reduction methods. The core idea behind the approach is to\nuse control variates at all future times down the trajectory. We present both a\nmodel-based and model-free formulations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 08:18:33 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Pankov", "Sergey", ""]]}, {"id": "1811.06272", "submitter": "Lars Buesing", "authors": "Lars Buesing, Theophane Weber, Yori Zwols, Sebastien Racaniere, Arthur\n  Guez, Jean-Baptiste Lespiau, Nicolas Heess", "title": "Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning policies on data synthesized by models can in principle quench the\nthirst of reinforcement learning algorithms for large amounts of real\nexperience, which is often costly to acquire. However, simulating plausible\nexperience de novo is a hard problem for many complex environments, often\nresulting in biases for model-based policy evaluation and search. Instead of de\nnovo synthesis of data, here we assume logged, real experience and model\nalternative outcomes of this experience under counterfactual actions, actions\nthat were not actually taken. Based on this, we propose the\nCounterfactually-Guided Policy Search (CF-GPS) algorithm for learning policies\nin POMDPs from off-policy experience. It leverages structural causal models for\ncounterfactual evaluation of arbitrary policies on individual off-policy\nepisodes. CF-GPS can improve on vanilla model-based RL algorithms by making use\nof available logged data to de-bias model predictions. In contrast to\noff-policy algorithms based on Importance Sampling which re-weight data, CF-GPS\nleverages a model to explicitly consider alternative outcomes, allowing the\nalgorithm to make better use of experience data. We find empirically that these\nadvantages translate into improved policy evaluation and search results on a\nnon-trivial grid-world task. Finally, we show that CF-GPS generalizes the\npreviously proposed Guided Policy Search and that reparameterization-based\nalgorithms such Stochastic Value Gradient can be interpreted as counterfactual\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 10:08:58 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Buesing", "Lars", ""], ["Weber", "Theophane", ""], ["Zwols", "Yori", ""], ["Racaniere", "Sebastien", ""], ["Guez", "Arthur", ""], ["Lespiau", "Jean-Baptiste", ""], ["Heess", "Nicolas", ""]]}, {"id": "1811.06321", "submitter": "Mason A. Porter", "authors": "Baichuan Yuan, Hao Li, Andrea L. Bertozzi, P. Jeffrey Brantingham, and\n  Mason A. Porter", "title": "Multivariate Spatiotemporal Hawkes Processes and Network Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI eess.SP nlin.AO physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is often latent network structure in spatial and temporal data and the\ntools of network analysis can yield fascinating insights into such data. In\nthis paper, we develop a nonparametric method for network reconstruction from\nspatiotemporal data sets using multivariate Hawkes processes. In contrast to\nprior work on network reconstruction with point-process models, which has often\nfocused on exclusively temporal information, our approach uses both temporal\nand spatial information and does not assume a specific parametric form of\nnetwork dynamics. This leads to an effective way of recovering an underlying\nnetwork. We illustrate our approach using both synthetic networks and networks\nconstructed from real-world data sets (a location-based social media network, a\nnarrative of crime events, and violent gang crimes). Our results demonstrate\nthat, in comparison to using only temporal data, our spatiotemporal approach\nyields improved network reconstruction, providing a basis for meaningful\nsubsequent analysis --- such as community structure and motif analysis --- of\nthe reconstructed networks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 12:50:36 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Yuan", "Baichuan", ""], ["Li", "Hao", ""], ["Bertozzi", "Andrea L.", ""], ["Brantingham", "P. Jeffrey", ""], ["Porter", "Mason A.", ""]]}, {"id": "1811.06341", "submitter": "Zahra Karevan", "authors": "Zahra Karevan and Johan A. K. Suykens", "title": "Spatio-temporal Stacked LSTM for Temperature Prediction in Weather\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) is a well-known method used widely on sequence\nlearning and time series prediction. In this paper we deployed stacked LSTM\nmodel in an application of weather forecasting. We propose a 2-layer\nspatio-temporal stacked LSTM model which consists of independent LSTM models\nper location in the first LSTM layer. Subsequently, the input of the second\nLSTM layer is formed based on the combination of the hidden states of the first\nlayer LSTM models. The experiments show that by utilizing the spatial\ninformation the prediction performance of the stacked LSTM model improves in\nmost of the cases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 13:42:04 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Karevan", "Zahra", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1811.06366", "submitter": "Samuel Bruno Da Silva Sousa", "authors": "Samuel Bruno da Silva Sousa, Ronaldo de Castro Del-Fiaco, and Lilian\n  Berton", "title": "Cluster analysis of homicide rates in the Brazilian state of Goias from\n  2002 to 2014", "comments": null, "journal-ref": "Proceedings of the 44th Latin American Computing Conference - Clei\n  2018. S\\~ao Paulo, Brazil (2018)", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Homicide mortality is a worldwide concern and has occupied the agenda of\nresearchers and public managers. In Brazil, homicide is the third leading cause\nof death in the general population and the first in the 15-39 age group. In\nSouth America, Brazil has the third highest homicide mortality, behind\nVenezuela and Colombia. To measure the impacts of violence it is important to\nassess health systems and criminal justice, as well as other areas. In this\npaper, we analyze the spatial distribution of homicide mortality in the state\nof Goias, Center-West of Brazil, since the homicide rate increased from 24.5\nper 100,000 in 2002 to 42.6 per 100,000 in 2014 in this location. Moreover,\nthis state had the fifth position of homicides in Brazil in 2014. We considered\nsocio-demographic variables for the state, performed analysis about correlation\nand employed three clustering algorithms: K-means, Density-based and\nHierarchical. The results indicate the homicide rates are higher in cities\nneighbors of large urban centers, although these cities have the best\nsocioeconomic indicators.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 02:10:18 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 10:05:04 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Sousa", "Samuel Bruno da Silva", ""], ["Del-Fiaco", "Ronaldo de Castro", ""], ["Berton", "Lilian", ""]]}, {"id": "1811.06367", "submitter": "Duo Zhang", "authors": "Duo Zhang, Erlend Skullestad Holland, Geir Lindholm, Harsha Ratnaweera", "title": "Enhancing Operation of a Sewage Pumping Station for Inter Catchment\n  Wastewater Transfer by Using Deep Learning and Hydraulic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel Inter Catchment Wastewater Transfer (ICWT) method\nfor mitigating sewer overflow. The ICWT aims at balancing the spatial mismatch\nof sewer flow and treatment capacity of Wastewater Treatment Plant (WWTP),\nthrough collaborative operation of sewer system facilities. Using a hydraulic\nmodel, the effectiveness of ICWT is investigated in a sewer system in Drammen,\nNorway. Concerning the whole system performance, we found that the S{\\o}ren\nLemmich pump station plays a vital role in the ICWT framework. To enhance the\noperation of this pump station, it is imperative to construct a multi-step\nahead water level prediction model. Hence, one of the most promising artificial\nintelligence techniques, Long Short Term Memory (LSTM), is employed to\nundertake this task. Experiments demonstrated that LSTM is superior to Gated\nRecurrent Unit (GRU), Recurrent Neural Network (RNN), Feed-forward Neural\nNetwork (FFNN) and Support Vector Regression (SVR).\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 12:28:53 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Zhang", "Duo", ""], ["Holland", "Erlend Skullestad", ""], ["Lindholm", "Geir", ""], ["Ratnaweera", "Harsha", ""]]}, {"id": "1811.06368", "submitter": "Duo Zhang", "authors": "Duo Zhang, Geir Lindholm, Harsha Ratnaweera", "title": "DeepCSO: Forecasting of Combined Sewer Overflow at a Citywide Level\n  using Multi-task Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combined Sewer Overflow (CSO) is a major problem to be addressed by many\ncities. Understanding the behavior of sewer system through proper urban\nhydrological models is an effective method of enhancing sewer system\nmanagement. Conventional deterministic methods, which heavily rely on physical\nprinciples, is inappropriate for real-time purpose due to their expensive\ncomputation. On the other hand, data-driven methods have gained huge interests,\nbut most studies only focus on modeling a single component of the sewer system\nand supply information at a very abstract level. In this paper, we proposed the\nDeepCSO model, which aims at forecasting CSO events from multiple CSO\nstructures simultaneously in near real time at a citywide level. The proposed\nmodel provided an intermediate methodology that combines the flexibility of\ndata-driven methods and the rich information contained in deterministic methods\nwhile avoiding the drawbacks of these two methods. A comparison of the results\ndemonstrated that the deep learning based multi-task model is superior to the\ntraditional methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 12:27:28 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Zhang", "Duo", ""], ["Lindholm", "Geir", ""], ["Ratnaweera", "Harsha", ""]]}, {"id": "1811.06369", "submitter": "Drahomira Herrmannova", "authors": "Martin Hlosta, Drahomira Herrmannova, Lucie Vachova, Jakub Kuzilek,\n  Zdenek Zdrahal, Annika Wolff", "title": "Modelling student online behaviour in a virtual learning environment", "comments": "In Proceedings of the 2014 Workshop on Learning Analytics and Machine\n  Learning at the 2014 International Conference on Learning Analytics and\n  Knowledge (LAK 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, distance education has enjoyed a major boom. Much work at\nThe Open University (OU) has focused on improving retention rates in these\nmodules by providing timely support to students who are at risk of failing the\nmodule. In this paper we explore methods for analysing student activity in\nonline virtual learning environment (VLE) -- General Unary Hypotheses Automaton\n(GUHA) and Markov chain-based analysis -- and we explain how this analysis can\nbe relevant for module tutors and other student support staff. We show that\nboth methods are a valid approach to modelling student activities. An advantage\nof the Markov chain-based approach is in its graphical output and in the\npossibility to model time dependencies of the student activities.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 16:31:04 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Hlosta", "Martin", ""], ["Herrmannova", "Drahomira", ""], ["Vachova", "Lucie", ""], ["Kuzilek", "Jakub", ""], ["Zdrahal", "Zdenek", ""], ["Wolff", "Annika", ""]]}, {"id": "1811.06407", "submitter": "Bilal Piot", "authors": "Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Bernardo A.\n  Pires and R\\'emi Munos", "title": "Neural Predictive Belief Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised representation learning has succeeded with excellent results in\nmany applications. It is an especially powerful tool to learn a good\nrepresentation of environments with partial or noisy observations. In partially\nobservable domains it is important for the representation to encode a belief\nstate, a sufficient statistic of the observations seen so far. In this paper,\nwe investigate whether it is possible to learn such a belief representation\nusing modern neural architectures. Specifically, we focus on one-step frame\nprediction and two variants of contrastive predictive coding (CPC) as the\nobjective functions to learn the representations. To evaluate these learned\nrepresentations, we test how well they can predict various pieces of\ninformation about the underlying state of the environment, e.g., position of\nthe agent in a 3D maze. We show that all three methods are able to learn belief\nrepresentations of the environment, they encode not only the state information,\nbut also its uncertainty, a crucial aspect of belief states. We also find that\nfor CPC multi-step predictions and action-conditioning are critical for\naccurate belief representations in visually complex environments. The ability\nof neural representations to capture the belief information has the potential\nto spur new advances for learning and planning in partially observable domains,\nwhere leveraging uncertainty is essential for optimal decision making.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 14:51:12 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 15:56:57 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Guo", "Zhaohan Daniel", ""], ["Azar", "Mohammad Gheshlaghi", ""], ["Piot", "Bilal", ""], ["Pires", "Bernardo A.", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1811.06418", "submitter": "Ilya Razenshteyn", "authors": "S\\'ebastien Bubeck, Yin Tat Lee, Eric Price, Ilya Razenshteyn", "title": "Adversarial Examples from Cryptographic Pseudo-Random Generators", "comments": "4 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our recent work (Bubeck, Price, Razenshteyn, arXiv:1805.10204) we argued\nthat adversarial examples in machine learning might be due to an inherent\ncomputational hardness of the problem. More precisely, we constructed a binary\nclassification task for which (i) a robust classifier exists; yet no\nnon-trivial accuracy can be obtained with an efficient algorithm in (ii) the\nstatistical query model. In the present paper we significantly strengthen both\n(i) and (ii): we now construct a task which admits (i') a maximally robust\nclassifier (that is it can tolerate perturbations of size comparable to the\nsize of the examples themselves); and moreover we prove computational hardness\nof learning this task under (ii') a standard cryptographic assumption.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 15:08:12 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Lee", "Yin Tat", ""], ["Price", "Eric", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1811.06437", "submitter": "Pranshu Malviya", "authors": "Yash Pratyush Sinha, Pranshu Malviya, Minerva Panda, Syed Mohd Ali", "title": "Contextual Care Protocol using Neural Networks and Decision Trees", "comments": null, "journal-ref": "2018 Second International Conference on Advances in Electronics,\n  Computers and Communications (ICAECC)", "doi": "10.1109/ICAECC.2018.8479433", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A contextual care protocol is used by a medical practitioner for patient\nhealthcare, given the context or situation that the specified patient is in.\nThis paper proposes a method to build an automated self-adapting protocol which\ncan help make relevant, early decisions for effective healthcare delivery. The\nhybrid model leverages neural networks and decision trees. The neural network\nestimates the chances of each disease and each tree in the decision trees\nrepresents care protocol for a disease. These trees are subject to change in\ncase of aberrations found by the diagnosticians. These corrections or\nprediction errors are clustered into similar groups for scalability and review\nby the experts. The corrections as suggested by the experts are incorporated\ninto the model.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 15:46:02 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Sinha", "Yash Pratyush", ""], ["Malviya", "Pranshu", ""], ["Panda", "Minerva", ""], ["Ali", "Syed Mohd", ""]]}, {"id": "1811.06492", "submitter": "Zehao Dou", "authors": "Zehao Dou, Stanley J. Osher, and Bao Wang", "title": "Mathematical Analysis of Adversarial Attacks", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze efficacy of the fast gradient sign method (FGSM)\nand the Carlini-Wagner's L2 (CW-L2) attack. We prove that, within a certain\nregime, the untargeted FGSM can fool any convolutional neural nets (CNNs) with\nReLU activation; the targeted FGSM can mislead any CNNs with ReLU activation to\nclassify any given image into any prescribed class. For a special two-layer\nneural network: a linear layer followed by the softmax output activation, we\nshow that the CW-L2 attack increases the ratio of the classification\nprobability between the target and ground truth classes. Moreover, we provide\nnumerical results to verify all our theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 17:38:59 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 15:56:12 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Dou", "Zehao", ""], ["Osher", "Stanley J.", ""], ["Wang", "Bao", ""]]}, {"id": "1811.06512", "submitter": "Reazul Hasan Russel", "authors": "Reazul Hasan Russel and Marek Petrik", "title": "Tight Bayesian Ambiguity Sets for Robust MDPs", "comments": "5 pages. Accepted at Infer to Control Workshop at Neural Information\n  Processing Systems (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness is important for sequential decision making in a stochastic\ndynamic environment with uncertain probabilistic parameters. We address the\nproblem of using robust MDPs (RMDPs) to compute policies with provable\nworst-case guarantees in reinforcement learning. The quality and robustness of\nan RMDP solution is determined by its ambiguity set. Existing methods construct\nambiguity sets that lead to impractically conservative solutions. In this\npaper, we propose RSVF, which achieves less conservative solutions with the\nsame worst-case guarantees by 1) leveraging a Bayesian prior, 2) optimizing the\nsize and location of the ambiguity set, and, most importantly, 3) relaxing the\nrequirement that the set is a confidence interval. Our theoretical analysis\nshows the safety of RSVF, and the empirical results demonstrate its practical\npromise.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 18:18:39 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Russel", "Reazul Hasan", ""], ["Petrik", "Marek", ""]]}, {"id": "1811.06521", "submitter": "Jan Leike", "authors": "Borja Ibarz and Jan Leike and Tobias Pohlen and Geoffrey Irving and\n  Shane Legg and Dario Amodei", "title": "Reward learning from human preferences and demonstrations in Atari", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To solve complex real-world problems with reinforcement learning, we cannot\nrely on manually specified reward functions. Instead, we can have humans\ncommunicate an objective to the agent directly. In this work, we combine two\napproaches to learning from human feedback: expert demonstrations and\ntrajectory preferences. We train a deep neural network to model the reward\nfunction and use its predicted reward to train an DQN-based deep reinforcement\nlearning agent on 9 Atari games. Our approach beats the imitation learning\nbaseline in 7 games and achieves strictly superhuman performance on 2 games\nwithout using game rewards. Additionally, we investigate the goodness of fit of\nthe reward model, present some reward hacking problems, and study the effects\nof noise in the human labels.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 18:33:43 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Ibarz", "Borja", ""], ["Leike", "Jan", ""], ["Pohlen", "Tobias", ""], ["Irving", "Geoffrey", ""], ["Legg", "Shane", ""], ["Amodei", "Dario", ""]]}, {"id": "1811.06524", "submitter": "Matthew Klawonn", "authors": "Matthew Klawonn, Eric Heim, James Hendler", "title": "Exploiting Class Learnability in Noisy Data", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains, collecting sufficient labeled training data for supervised\nmachine learning requires easily accessible but noisy sources, such as\ncrowdsourcing services or tagged Web data. Noisy labels occur frequently in\ndata sets harvested via these means, sometimes resulting in entire classes of\ndata on which learned classifiers generalize poorly. For real world\napplications, we argue that it can be beneficial to avoid training on such\nclasses entirely. In this work, we aim to explore the classes in a given data\nset, and guide supervised training to spend time on a class proportional to its\nlearnability. By focusing the training process, we aim to improve model\ngeneralization on classes with a strong signal. To that end, we develop an\nonline algorithm that works in conjunction with classifier and training\nalgorithm, iteratively selecting training data for the classifier based on how\nwell it appears to generalize on each class. Testing our approach on a variety\nof data sets, we show our algorithm learns to focus on classes for which the\nmodel has low generalization error relative to strong baselines, yielding a\nclassifier with good performance on learnable classes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 18:42:30 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Klawonn", "Matthew", ""], ["Heim", "Eric", ""], ["Hendler", "James", ""]]}, {"id": "1811.06569", "submitter": "Elizabeth Newman", "authors": "Elizabeth Newman, Lior Horesh, Haim Avron, Misha Kilmer", "title": "Stable Tensor Neural Networks for Rapid Deep Learning", "comments": "20 pages, 6 figures, submitted to SIMODS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a tensor neural network ($t$-NN) framework that offers an exciting\nnew paradigm for designing neural networks with multidimensional (tensor) data.\nOur network architecture is based on the $t$-product (Kilmer and Martin, 2011),\nan algebraic formulation to multiply tensors via circulant convolution. In this\n$t$-product algebra, we interpret tensors as $t$-linear operators analogous to\nmatrices as linear operators, and hence our framework inherits mimetic matrix\nproperties. To exemplify the elegant, matrix-mimetic algebraic structure of our\n$t$-NNs, we expand on recent work (Haber and Ruthotto, 2017) which interprets\ndeep neural networks as discretizations of non-linear differential equations\nand introduces stable neural networks which promote superior generalization.\nMotivated by this dynamic framework, we introduce a stable $t$-NN which\nfacilitates more rapid learning because of its reduced, more powerful\nparameterization. Through our high-dimensional design, we create a more compact\nparameter space and extract multidimensional correlations otherwise latent in\ntraditional algorithms. We further generalize our $t$-NN framework to a family\nof tensor-tensor products (Kernfeld, Kilmer, and Aeron, 2015) which still\ninduce a matrix-mimetic algebraic structure. Through numerical experiments on\nthe MNIST and CIFAR-10 datasets, we demonstrate the more powerful\nparameterizations and improved generalizability of stable $t$-NNs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 19:37:24 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Newman", "Elizabeth", ""], ["Horesh", "Lior", ""], ["Avron", "Haim", ""], ["Kilmer", "Misha", ""]]}, {"id": "1811.06580", "submitter": "Weiwei Li", "authors": "Weiwei Li, Jan Hannig, Sayan Mukherjee", "title": "Subspace Clustering through Sub-Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of dimension reduction is of increasing importance in modern data\nanalysis. In this paper, we consider modeling the collection of points in a\nhigh dimensional space as a union of low dimensional subspaces. In particular\nwe propose a highly scalable sampling based algorithm that clusters the entire\ndata via first spectral clustering of a small random sample followed by\nclassifying or labeling the remaining out of sample points. The key idea is\nthat this random subset borrows information across the entire data set and that\nthe problem of clustering points can be replaced with the more efficient and\nrobust problem of \"clustering sub-clusters\". We provide theoretical guarantees\nfor our procedure. The numerical results indicate we outperform other\nstate-of-the-art subspace clustering algorithms with respect to accuracy and\nspeed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 20:15:53 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 15:18:06 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Li", "Weiwei", ""], ["Hannig", "Jan", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1811.06588", "submitter": "Arno Solin", "authors": "Arno Solin, James Hensman, Richard E. Turner", "title": "Infinite-Horizon Gaussian Processes", "comments": "To appear in Advances in Neural Information Processing Systems (NIPS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes provide a flexible framework for forecasting, removing\nnoise, and interpreting long temporal datasets. State space modelling (Kalman\nfiltering) enables these non-parametric models to be deployed on long datasets\nby reducing the complexity to linear in the number of data points. The\ncomplexity is still cubic in the state dimension $m$ which is an impediment to\npractical application. In certain special cases (Gaussian likelihood, regular\nspacing) the GP posterior will reach a steady posterior state when the data are\nvery long. We leverage this and formulate an inference scheme for GPs with\ngeneral likelihoods, where inference is based on single-sweep EP (assumed\ndensity filtering). The infinite-horizon model tackles the cubic cost in the\nstate dimensionality and reduces the cost in the state dimension $m$ to\n$\\mathcal{O}(m^2)$ per data point. The model is extended to online-learning of\nhyperparameters. We show examples for large finite-length modelling problems,\nand present how the method runs in real-time on a smartphone on a continuous\ndata stream updated at 100~Hz.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 20:52:40 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Solin", "Arno", ""], ["Hensman", "James", ""], ["Turner", "Richard E.", ""]]}, {"id": "1811.06609", "submitter": "Shivam Garg", "authors": "Shivam Garg, Vatsal Sharan, Brian Hu Zhang, Gregory Valiant", "title": "A Spectral View of Adversarially Robust Features", "comments": "To appear at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the apparent difficulty of learning models that are robust to\nadversarial perturbations, we propose tackling the simpler problem of\ndeveloping adversarially robust features. Specifically, given a dataset and\nmetric of interest, the goal is to return a function (or multiple functions)\nthat 1) is robust to adversarial perturbations, and 2) has significant\nvariation across the datapoints. We establish strong connections between\nadversarially robust features and a natural spectral property of the geometry\nof the dataset and metric of interest. This connection can be leveraged to\nprovide both robust features, and a lower bound on the robustness of any\nfunction that has significant variance across the dataset. Finally, we provide\nempirical evidence that the adversarially robust features given by this\nspectral approach can be fruitfully leveraged to learn a robust (and accurate)\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 22:09:28 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Garg", "Shivam", ""], ["Sharan", "Vatsal", ""], ["Zhang", "Brian Hu", ""], ["Valiant", "Gregory", ""]]}, {"id": "1811.06622", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Concept-Oriented Deep Learning: Generative Concept Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative concept representations have three major advantages over\ndiscriminative ones: they can represent uncertainty, they support integration\nof learning and reasoning, and they are good for unsupervised and\nsemi-supervised learning. We discuss probabilistic and generative deep\nlearning, which generative concept representations are based on, and the use of\nvariational autoencoders and generative adversarial networks for learning\ngenerative concept representations, particularly for concepts whose data are\nsequences, structured data or graphs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 23:13:26 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1811.06626", "submitter": "Raksha Kumaraswamy", "authors": "Vincent Liu, Raksha Kumaraswamy, Lei Le, Martha White", "title": "The Utility of Sparse Representations for Control in Reinforcement\n  Learning", "comments": "Association for the Advancement of Artificial Intelligence 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate sparse representations for control in reinforcement learning.\nWhile these representations are widely used in computer vision, their\nprevalence in reinforcement learning is limited to sparse coding where\nextracting representations for new data can be computationally intensive. Here,\nwe begin by demonstrating that learning a control policy incrementally with a\nrepresentation from a standard neural network fails in classic control domains,\nwhereas learning with a representation obtained from a neural network that has\nsparsity properties enforced is effective. We provide evidence that the reason\nfor this is that the sparse representation provides locality, and so avoids\ncatastrophic interference, and particularly keeps consistent, stable values for\nbootstrapping. We then discuss how to learn such sparse representations. We\nexplore the idea of Distributional Regularizers, where the activation of hidden\nnodes is encouraged to match a particular distribution that results in sparse\nactivation across time. We identify a simple but effective way to obtain sparse\nrepresentations, not afforded by previously proposed strategies, making it more\npractical for further investigation into sparse representations for\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 23:23:36 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Liu", "Vincent", ""], ["Kumaraswamy", "Raksha", ""], ["Le", "Lei", ""], ["White", "Martha", ""]]}, {"id": "1811.06642", "submitter": "Thomas Beckers", "authors": "Thomas Beckers, Jonas Umlauft, Sandra Hirche", "title": "Mean Square Prediction Error of Misspecified Gaussian Process Models", "comments": "Please cite the conference paper (to be published in 2018 IEEE 57th\n  Annual Conference on Decision and Control (CDC))", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric modeling approaches show very promising results in the area of\nsystem identification and control. A naturally provided model confidence is\nhighly relevant for system-theoretical considerations to provide guarantees for\napplication scenarios. Gaussian process regression represents one approach\nwhich provides such an indicator for the model confidence. However, this\nmeasure is only valid if the covariance function and its hyperparameters fit\nthe underlying data generating process. In this paper, we derive an upper bound\nfor the mean square prediction error of misspecified Gaussian process models\nbased on a pseudo-concave optimization problem. We present application\nscenarios and a simulation to compare the derived upper bound with the true\nmean square error.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 01:24:01 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Beckers", "Thomas", ""], ["Umlauft", "Jonas", ""], ["Hirche", "Sandra", ""]]}, {"id": "1811.06665", "submitter": "Long Nguyen Msc", "authors": "Long Nguyen, Jia Zhen, Zhe Lin, Hanxiang Du, Zhou Yang, Wenxuan Guo,\n  Fang Jin", "title": "Spatial-temporal Multi-Task Learning for Within-field Cotton Yield\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and accurately predicting within-field spatial variability of\ncrop yield play a key role in site-specific management of crop inputs such as\nirrigation water and fertilizer for optimized crop production. However, such a\ntask is challenged by the complex interaction between crop growth and\nenvironmental and managerial factors, such as climate, soil conditions,\ntillage, and irrigation. In this paper, we present a novel Spatial-temporal\nMulti-Task Learning algorithms for within-field crop yield prediction in west\nTexas from 2001 to 2003. This algorithm integrates multiple heterogeneous data\nsources to learn different features simultaneously, and to aggregate\nspatial-temporal features by introducing a weighted regularizer to the loss\nfunctions. Our comprehensive experimental results consistently outperform the\nresults of other conventional methods, and suggest a promising approach, which\nimproves the landscape of crop prediction research fields.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 03:20:49 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Nguyen", "Long", ""], ["Zhen", "Jia", ""], ["Lin", "Zhe", ""], ["Du", "Hanxiang", ""], ["Yang", "Zhou", ""], ["Guo", "Wenxuan", ""], ["Jin", "Fang", ""]]}, {"id": "1811.06669", "submitter": "Jonathan Huang J", "authors": "Jonathan J Huang, Juan Jose Alvarado Leanos", "title": "AclNet: efficient end-to-end audio classification CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient end-to-end convolutional neural network architecture,\nAclNet, for audio classification. When trained with our data augmentation and\nregularization, we achieved state-of-the-art performance on the ESC-50 corpus\nwith 85:65% accuracy. Our network allows configurations such that memory and\ncompute requirements are drastically reduced, and a tradeoff analysis of\naccuracy and complexity is presented. The analysis shows high accuracy at\nsignificantly reduced computational complexity compared to existing solutions.\nFor example, a configuration with only 155k parameters and 49:3 million\nmultiply-adds per second is 81:75%, exceeding human accuracy of 81:3%. This\nimproved efficiency can enable always-on inference in energy-efficient\nplatforms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 03:31:35 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Huang", "Jonathan J", ""], ["Leanos", "Juan Jose Alvarado", ""]]}, {"id": "1811.06672", "submitter": "Haruna Isah", "authors": "Sazia Mahfuz, Haruna Isah, Farhana Zulkernine, Peter Nicholls", "title": "Detecting Irregular Patterns in IoT Streaming Data for Fall Detection", "comments": "7 pages", "journal-ref": null, "doi": "10.1109/IEMCON.2018.8614822", "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting patterns in real time streaming data has been an interesting and\nchallenging data analytics problem. With the proliferation of a variety of\nsensor devices, real-time analytics of data from the Internet of Things (IoT)\nto learn regular and irregular patterns has become an important machine\nlearning problem to enable predictive analytics for automated notification and\ndecision support. In this work, we address the problem of learning an irregular\nhuman activity pattern, fall, from streaming IoT data from wearable sensors. We\npresent a deep neural network model for detecting fall based on accelerometer\ndata giving 98.75 percent accuracy using an online physical activity monitoring\ndataset called \"MobiAct\", which was published by Vavoulas et al. The initial\nmodel was developed using IBM Watson studio and then later transferred and\ndeployed on IBM Cloud with the streaming analytics service supported by IBM\nStreams for monitoring real-time IoT data. We also present the systems\narchitecture of the real-time fall detection framework that we intend to use\nwith mbientlabs wearable health monitoring sensors for real time patient\nmonitoring at retirement homes or rehabilitation clinics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 03:59:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Mahfuz", "Sazia", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""], ["Nicholls", "Peter", ""]]}, {"id": "1811.06687", "submitter": "Yaniv Romano", "authors": "Yaniv Romano, Matteo Sesia, Emmanuel J. Cand\\`es", "title": "Deep Knockoffs", "comments": "37 pages, 23 figures, 1 table", "journal-ref": "J. Am. Stat. Assoc., Volume 0, Issue 0, 17 Oct 2019, Pages 1-12", "doi": "10.1080/01621459.2019.1660174", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a machine for sampling approximate model-X knockoffs\nfor arbitrary and unspecified data distributions using deep generative models.\nThe main idea is to iteratively refine a knockoff sampling mechanism until a\ncriterion measuring the validity of the produced knockoffs is optimized; this\ncriterion is inspired by the popular maximum mean discrepancy in machine\nlearning and can be thought of as measuring the distance to pairwise\nexchangeability between original and knockoff features. By building upon the\nexisting model-X framework, we thus obtain a flexible and model-free\nstatistical tool to perform controlled variable selection. Extensive numerical\nexperiments and quantitative tests confirm the generality, effectiveness, and\npower of our deep knockoff machines. Finally, we apply this new method to a\nreal study of mutations linked to changes in drug resistance in the human\nimmunodeficiency virus.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 06:26:33 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Romano", "Yaniv", ""], ["Sesia", "Matteo", ""], ["Cand\u00e8s", "Emmanuel J.", ""]]}, {"id": "1811.06692", "submitter": "Changho Shin", "authors": "Changho Shin, Sunghwan Joo, Jaeryun Yim, Hyoseop Lee, Taesup Moon,\n  Wonjong Rhee", "title": "Subtask Gated Networks for Non-Intrusive Load Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-intrusive load monitoring (NILM), also known as energy disaggregation, is\na blind source separation problem where a household's aggregate electricity\nconsumption is broken down into electricity usages of individual appliances. In\nthis way, the cost and trouble of installing many measurement devices over\nnumerous household appliances can be avoided, and only one device needs to be\ninstalled. The problem has been well-known since Hart's seminal paper in 1992,\nand recently significant performance improvements have been achieved by\nadopting deep networks. In this work, we focus on the idea that appliances have\non/off states, and develop a deep network for further performance improvements.\nSpecifically, we propose a subtask gated network that combines the main\nregression network with an on/off classification subtask network. Unlike\ntypical multitask learning algorithms where multiple tasks simply share the\nnetwork parameters to take advantage of the relevance among tasks, the subtask\ngated network multiply the main network's regression output with the subtask's\nclassification probability. When standby-power is additionally learned, the\nproposed solution surpasses the state-of-the-art performance for most of the\nbenchmark cases. The subtask gated network can be very effective for any\nproblem that inherently has on/off states.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 07:38:48 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Shin", "Changho", ""], ["Joo", "Sunghwan", ""], ["Yim", "Jaeryun", ""], ["Lee", "Hyoseop", ""], ["Moon", "Taesup", ""], ["Rhee", "Wonjong", ""]]}, {"id": "1811.06713", "submitter": "Simon Leglaive", "authors": "Simon Leglaive, Laurent Girin, Radu Horaud", "title": "Semi-supervised multichannel speech enhancement with variational\n  autoencoders and non-negative matrix factorization", "comments": "5 pages, 2 figures, audio examples and code available online at\n  https://team.inria.fr/perception/icassp-2019-mvae/", "journal-ref": "IEEE International Conference on Acoustics Speech and Signal\n  Processing (ICASSP), Brighton, UK, May 2019, pp. 101-105", "doi": "10.1109/ICASSP.2019.8683704", "report-no": "hal-02005102", "categories": "cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address speaker-independent multichannel speech enhancement\nin unknown noisy environments. Our work is based on a well-established\nmultichannel local Gaussian modeling framework. We propose to use a neural\nnetwork for modeling the speech spectro-temporal content. The parameters of\nthis supervised model are learned using the framework of variational\nautoencoders. The noisy recording environment is supposed to be unknown, so the\nnoise spectro-temporal modeling remains unsupervised and is based on\nnon-negative matrix factorization (NMF). We develop a Monte Carlo\nexpectation-maximization algorithm and we experimentally show that the proposed\napproach outperforms its NMF-based counterpart, where speech is modeled using\nsupervised NMF.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 09:11:07 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 14:42:47 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 13:57:02 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Leglaive", "Simon", ""], ["Girin", "Laurent", ""], ["Horaud", "Radu", ""]]}, {"id": "1811.06736", "submitter": "Alon Cohen", "authors": "Alon Cohen, Moran Koren, Argyrios Deligkas", "title": "Incentivizing the Dynamic Workforce: Learning Contracts in the\n  Gig-Economy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG econ.TH stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In principal-agent models, a principal offers a contract to an agent to\nperform a certain task. The agent exerts a level of effort that maximizes her\nutility. The principal is oblivious to the agent's chosen level of effort, and\nconditions her wage only on possible outcomes. In this work, we consider a\nmodel in which the principal is unaware of the agent's utility and action\nspace. She sequentially offers contracts to identical agents, and observes the\nresulting outcomes. We present an algorithm for learning the optimal contract\nunder mild assumptions. We bound the number of samples needed for the principal\nobtain a contract that is within $\\epsilon$ of her optimal net profit for every\n$\\epsilon>0$.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 10:05:42 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Cohen", "Alon", ""], ["Koren", "Moran", ""], ["Deligkas", "Argyrios", ""]]}, {"id": "1811.06746", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Chung-Hao Huang, Georg N\\\"uhrenberg", "title": "nn-dependability-kit: Engineering Neural Networks for Safety-Critical\n  Autonomous Driving Systems", "comments": "Tool available at\n  https://github.com/dependable-ai/nn-dependability-kit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can engineering neural networks be approached in a disciplined way similar to\nhow engineers build software for civil aircraft? We present\nnn-dependability-kit, an open-source toolbox to support safety engineering of\nneural networks for autonomous driving systems. The rationale behind\nnn-dependability-kit is to consider a structured approach (via Goal Structuring\nNotation) to argue the quality of neural networks. In particular, the tool\nrealizes recent scientific results including (a) novel dependability metrics\nfor indicating sufficient elimination of uncertainties in the product life\ncycle, (b) formal reasoning engine for ensuring that the generalization does\nnot lead to undesired behaviors, and (c) runtime monitoring for reasoning\nwhether a decision of a neural network in operation is supported by prior\nsimilarities in the training data. A proprietary version of\nnn-dependability-kit has been used to improve the quality of a level-3\nautonomous driving component developed by Audi for highway maneuvers.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 10:48:07 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 20:02:25 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Huang", "Chung-Hao", ""], ["N\u00fchrenberg", "Georg", ""]]}, {"id": "1811.06753", "submitter": "Tom Veniat", "authors": "Tom V\\'eniat, Olivier Schwander, Ludovic Denoyer", "title": "Stochastic Adaptive Neural Architecture Search for Keyword Spotting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of keyword spotting i.e. identifying keywords in a real-time\naudio stream is mainly solved by applying a neural network over successive\nsliding windows. Due to the difficulty of the task, baseline models are usually\nlarge, resulting in a high computational cost and energy consumption level. We\npropose a new method called SANAS (Stochastic Adaptive Neural Architecture\nSearch) which is able to adapt the architecture of the neural network\non-the-fly at inference time such that small architectures will be used when\nthe stream is easy to process (silence, low noise, ...) and bigger networks\nwill be used when the task becomes more difficult. We show that this adaptive\nmodel can be learned end-to-end by optimizing a trade-off between the\nprediction performance and the average computational cost per unit of time.\nExperiments on the Speech Commands dataset show that this approach leads to a\nhigh recognition level while being much faster (and/or energy saving) than\nclassical approaches where the network architecture is static.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 11:08:26 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["V\u00e9niat", "Tom", ""], ["Schwander", "Olivier", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1811.06763", "submitter": "Dong Liu", "authors": "Dong Liu, Minh Th\\`anh Vu, Saikat Chatterjee, and Lars K. Rasmussen", "title": "Entropy-regularized Optimal Transport Generative Models", "comments": null, "journal-ref": "ICASSP 2019", "doi": "10.1109/ICASSP.2019.8682721", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of entropy-regularized optimal transport (EOT) cost in\ndeveloping generative models to learn implicit distributions. Two generative\nmodels are proposed. One uses EOT cost directly in an one-shot optimization\nproblem and the other uses EOT cost iteratively in an adversarial game. The\nproposed generative models show improved performance over contemporary models\nfor image generation on MNSIT.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 11:33:12 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Liu", "Dong", ""], ["Vu", "Minh Th\u00e0nh", ""], ["Chatterjee", "Saikat", ""], ["Rasmussen", "Lars K.", ""]]}, {"id": "1811.06773", "submitter": "Ashkan Esmaeili", "authors": "Ashkan Esmaeili and Farokh Marvasti", "title": "A Novel Approach to Sparse Inverse Covariance Estimation Using Transform\n  Domain Updates and Exponentially Adaptive Thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Inverse Covariance Estimation (SICE) is useful in many practical data\nanalyses. Recovering the connectivity, non-connectivity graph of covariates is\nclassified amongst the most important data mining and learning problems. In\nthis paper, we introduce a novel SICE approach using adaptive thresholding. Our\nmethod is based on updates in a transformed domain of the desired matrix and\nexponentially decaying adaptive thresholding in the main domain (Inverse\nCovariance matrix domain). In addition to the proposed algorithm, the\nconvergence analysis is also provided. In the Numerical Experiments Section, we\nshow that the proposed method outperforms state-of-the-art methods in terms of\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 12:03:46 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 00:29:49 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Esmaeili", "Ashkan", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1811.06783", "submitter": "Hengyue Pan", "authors": "Hengyue Pan, Hui Jiang, Xin Niu and Yong Dou", "title": "DropFilter: A Novel Regularization Method for Learning Convolutional\n  Neural Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have witnessed the fast development of different\nregularization methods for deep learning models such as fully-connected deep\nneural networks (DNNs) and Convolutional Neural Networks (CNNs). Most of\nprevious methods mainly consider to drop features from input data and hidden\nlayers, such as Dropout, Cutout and DropBlocks. DropConnect select to drop\nconnections between fully-connected layers. By randomly discard some features\nor connections, the above mentioned methods control the overfitting problem and\nimprove the performance of neural networks. In this paper, we proposed two\nnovel regularization methods, namely DropFilter and DropFilter-PLUS, for the\nlearning of CNNs. Different from the previous methods, DropFilter and\nDropFilter-PLUS selects to modify the convolution filters. For DropFilter-PLUS,\nwe find a suitable way to accelerate the learning process based on theoretical\nanalysis. Experimental results on MNIST show that using DropFilter and\nDropFilter-PLUS may improve performance on image classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 12:40:39 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 01:28:42 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Pan", "Hengyue", ""], ["Jiang", "Hui", ""], ["Niu", "Xin", ""], ["Dou", "Yong", ""]]}, {"id": "1811.06805", "submitter": "Szymon Drgas", "authors": "Tomasz Grzywalski and Szymon Drgas", "title": "Using recurrences in time and frequency within U-net architecture for\n  speech enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When designing fully-convolutional neural network, there is a trade-off\nbetween receptive field size, number of parameters and spatial resolution of\nfeatures in deeper layers of the network. In this work we present a novel\nnetwork design based on combination of many convolutional and recurrent layers\nthat solves these dilemmas. We compare our solution with U-nets based models\nknown from the literature and other baseline models on speech enhancement task.\nWe test our solution on TIMIT speech utterances combined with noise segments\nextracted from NOISEX-92 database and show clear advantage of proposed solution\nin terms of SDR (signal-to-distortion ratio), SIR (signal-to-interference\nratio) and STOI (spectro-temporal objective intelligibility) metrics compared\nto the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 13:58:42 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Grzywalski", "Tomasz", ""], ["Drgas", "Szymon", ""]]}, {"id": "1811.06817", "submitter": "Rhiannon Michelmore", "authors": "Rhiannon Michelmore, Marta Kwiatkowska, Yarin Gal", "title": "Evaluating Uncertainty Quantification in End-to-End Autonomous Driving\n  Control", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rise in popularity of Deep Neural Networks (DNNs), attributed to more\npowerful GPUs and widely available datasets, has seen them being increasingly\nused within safety-critical domains. One such domain, self-driving, has\nbenefited from significant performance improvements, with millions of miles\nhaving been driven with no human intervention. Despite this, crashes and\nerroneous behaviours still occur, in part due to the complexity of verifying\nthe correctness of DNNs and a lack of safety guarantees.\n  In this paper, we demonstrate how quantitative measures of uncertainty can be\nextracted in real-time, and their quality evaluated in end-to-end controllers\nfor self-driving cars. To this end we utilise a recent method for gathering\napproximate uncertainty information from DNNs without changing the network's\narchitecture. We propose evaluation techniques for the uncertainty on two\nseparate architectures which use the uncertainty to predict crashes up to five\nseconds in advance. We find that mutual information, a measure of uncertainty\nin classification networks, is a promising indicator of forthcoming crashes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 14:30:30 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Michelmore", "Rhiannon", ""], ["Kwiatkowska", "Marta", ""], ["Gal", "Yarin", ""]]}, {"id": "1811.06837", "submitter": "Zeyu Sun", "authors": "Zeyu Sun, Qihao Zhu, Lili Mou, Yingfei Xiong, Ge Li, Lu Zhang", "title": "A Grammar-Based Structural CNN Decoder for Code Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Code generation maps a program description to executable source code in a\nprogramming language. Existing approaches mainly rely on a recurrent neural\nnetwork (RNN) as the decoder. However, we find that a program contains\nsignificantly more tokens than a natural language sentence, and thus it may be\ninappropriate for RNN to capture such a long sequence. In this paper, we\npropose a grammar-based structural convolutional neural network (CNN) for code\ngeneration. Our model generates a program by predicting the grammar rules of\nthe programming language; we design several CNN modules, including the\ntree-based convolution and pre-order convolution, whose information is further\naggregated by dedicated attentive pooling layers. Experimental results on the\nHearthStone benchmark dataset show that our CNN code generator significantly\noutperforms the previous state-of-the-art method by 5 percentage points;\nadditional experiments on several semantic parsing tasks demonstrate the\nrobustness of our model. We also conduct in-depth ablation test to better\nunderstand each component of our model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 14:45:35 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Sun", "Zeyu", ""], ["Zhu", "Qihao", ""], ["Mou", "Lili", ""], ["Xiong", "Yingfei", ""], ["Li", "Ge", ""], ["Zhang", "Lu", ""]]}, {"id": "1811.06838", "submitter": "Arin Chaudhuri", "authors": "Arin Chaudhuri, Carol Sadek, Deovrat Kakde, Wenhao Hu, Hansi Jiang,\n  Seunghyun Kong, Yuewei Liao, Sergiy Peredriy and Haoyu Wang", "title": "The Trace Criterion for Kernel Bandwidth Selection for Support Vector\n  Data Description", "comments": "note: some text overlap with arXiv:1708.05106 because common\n  background material is covered in both papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector data description (SVDD) is a popular anomaly detection\ntechnique. The SVDD classifier partitions the whole data space into an inlier\nregion, which consists of the region near the training data, and an outlier\nregion, which consists of points away from the training data. The computation\nof the SVDD classifier requires a kernel function, for which the Gaussian\nkernel is a common choice. The Gaussian kernel has a bandwidth parameter, and\nit is important to set the value of this parameter correctly for good results.\nA small bandwidth leads to overfitting such that the resulting SVDD classifier\noverestimates the number of anomalies, whereas a large bandwidth leads to\nunderfitting and an inability to detect many anomalies. In this paper, we\npresent a new unsupervised method for selecting the Gaussian kernel bandwidth.\nOur method exploits a low-rank representation of the kernel matrix to suggest a\nkernel bandwidth value. Our new technique is competitive with the current state\nof the art for low-dimensional data and performs extremely well for many\nclasses of high-dimensional data. Because the mathematical formulation of SVDD\nis identical with the mathematical formulation of one-class support vector\nmachines (OCSVM) when the Gaussian kernel is used, our method is equally\napplicable to Gaussian kernel bandwidth tuning for OCSVM.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 14:16:21 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 00:28:44 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 20:43:09 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Chaudhuri", "Arin", ""], ["Sadek", "Carol", ""], ["Kakde", "Deovrat", ""], ["Hu", "Wenhao", ""], ["Jiang", "Hansi", ""], ["Kong", "Seunghyun", ""], ["Liao", "Yuewei", ""], ["Peredriy", "Sergiy", ""], ["Wang", "Haoyu", ""]]}, {"id": "1811.06847", "submitter": "Karan Aggarwal", "authors": "Karan Aggarwal, Shafiq Joty, Luis Fernandez-Luque, Jaideep Srivastava", "title": "Adversarial Unsupervised Representation Learning for Activity\n  Time-Series", "comments": "Accepted at AAAI'19. arXiv admin note: text overlap with\n  arXiv:1712.09527", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sufficient physical activity and restful sleep play a major role in the\nprevention and cure of many chronic conditions. Being able to proactively\nscreen and monitor such chronic conditions would be a big step forward for\noverall health. The rapid increase in the popularity of wearable devices\nprovides a significant new source, making it possible to track the user's\nlifestyle real-time. In this paper, we propose a novel unsupervised\nrepresentation learning technique called activity2vec that learns and\n\"summarizes\" the discrete-valued activity time-series. It learns the\nrepresentations with three components: (i) the co-occurrence and magnitude of\nthe activity levels in a time-segment, (ii) neighboring context of the\ntime-segment, and (iii) promoting subject-invariance with adversarial training.\nWe evaluate our method on four disorder prediction tasks using linear\nclassifiers. Empirical evaluation demonstrates that our proposed method scales\nand performs better than many strong baselines. The adversarial regime helps\nimprove the generalizability of our representations by promoting subject\ninvariant features. We also show that using the representations at the level of\na day works the best since human activity is structured in terms of daily\nroutines\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 21:33:24 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Aggarwal", "Karan", ""], ["Joty", "Shafiq", ""], ["Fernandez-Luque", "Luis", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "1811.06885", "submitter": "Fayyaz Minhas", "authors": "Amina Asif, Muhammad Dawood, and Fayyaz ul Amir Afsar Minhas", "title": "A Generalized Meta-loss function for regression and classification using\n  privileged information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning using privileged information (LUPI) is a powerful heterogenous\nfeature space machine learning framework that allows a machine learning model\nto learn from highly informative or privileged features which are available\nduring training only to generate test predictions using input space features\nwhich are available both during training and testing. LUPI can significantly\nimprove prediction performance in a variety of machine learning problems.\nHowever, existing large margin and neural network implementations of learning\nusing privileged information are mostly designed for classification tasks. In\nthis work, we have proposed a simple yet effective formulation that allows us\nto perform regression using privileged information through a custom loss\nfunction. Apart from regression, our formulation allows general application of\nLUPI to classification and other related problems as well. We have verified the\ncorrectness, applicability and effectiveness of our method on regression and\nclassification problems over different synthetic and real-world problems. To\ntest the usefulness of the proposed model in real-world problems, we have\nevaluated our method on the problem of protein binding affinity prediction. The\nproposed LUPI regression-based model has shown to outperform the current\nstate-of-the-art predictor.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 16:07:23 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 07:05:04 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Asif", "Amina", ""], ["Dawood", "Muhammad", ""], ["Minhas", "Fayyaz ul Amir Afsar", ""]]}, {"id": "1811.06889", "submitter": "Lisa Lee", "authors": "Maruan Al-Shedivat, Lisa Lee, Ruslan Salakhutdinov, Eric Xing", "title": "On the Complexity of Exploration in Goal-Driven Navigation", "comments": "Relational Representation Learning Workshop (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building agents that can explore their environments intelligently is a\nchallenging open problem. In this paper, we make a step towards understanding\nhow a hierarchical design of the agent's policy can affect its exploration\ncapabilities. First, we design EscapeRoom environments, where the agent must\nfigure out how to navigate to the exit by accomplishing a number of\nintermediate tasks (\\emph{subgoals}), such as finding keys or opening doors.\nOur environments are procedurally generated and vary in complexity, which can\nbe controlled by the number of subgoals and relationships between them. Next,\nwe propose to measure the complexity of each environment by constructing\ndependency graphs between the goals and analytically computing \\emph{hitting\ntimes} of a random walk in the graph. We empirically evaluate Proximal Policy\nOptimization (PPO) with sparse and shaped rewards, a variation of policy\nsketches, and a hierarchical version of PPO (called HiPPO) akin to h-DQN. We\nshow that analytically estimated \\emph{hitting time} in goal dependency graphs\nis an informative metric of the environment complexity. We conjecture that the\nresult should hold for environments other than navigation. Finally, we show\nthat solving environments beyond certain level of complexity requires\nhierarchical approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 16:17:27 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Lee", "Lisa", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric", ""]]}, {"id": "1811.06912", "submitter": "Mengyue Hang", "authors": "Mengyue Hang, Ian Pytlarz and Jennifer Neville", "title": "Exploring Student Check-In Behavior for Improved Point-of-Interest\n  Prediction", "comments": "published in KDD'18", "journal-ref": null, "doi": "10.1145/3219819.3219902", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the availability of vast amounts of user visitation history on\nlocation-based social networks (LBSN), the problem of Point-of-Interest (POI)\nprediction has been extensively studied. However, much of the research has been\nconducted solely on voluntary checkin datasets collected from social apps such\nas Foursquare or Yelp. While these data contain rich information about\nrecreational activities (e.g., restaurants, nightlife, and entertainment),\ninformation about more prosaic aspects of people's lives is sparse. This not\nonly limits our understanding of users' daily routines, but more importantly\nthe modeling assumptions developed based on characteristics of recreation-based\ndata may not be suitable for richer check-in data. In this work, we present an\nanalysis of education \"check-in\" data using WiFi access logs collected at\nPurdue University. We propose a heterogeneous graph-based method to encode the\ncorrelations between users, POIs, and activities, and then jointly learn\nembeddings for the vertices. We evaluate our method compared to previous\nstate-of-the-art POI prediction methods, and show that the assumptions made by\nprevious methods significantly degrade performance on our data with dense(r)\nactivity signals. We also show how our learned embeddings could be used to\nidentify similar students (e.g., for friend suggestions).\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 21:07:18 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Hang", "Mengyue", ""], ["Pytlarz", "Ian", ""], ["Neville", "Jennifer", ""]]}, {"id": "1811.06930", "submitter": "Nicol\\`o Navarin", "authors": "Nicol\\`o Navarin, Dinh V. Tran, Alessandro Sperduti", "title": "Pre-training Graph Neural Networks with Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning techniques have been proposed in the last few years to\nprocess data represented in graph-structured form. Graphs can be used to model\nseveral scenarios, from molecules and materials to RNA secondary structures.\nSeveral kernel functions have been defined on graphs that coupled with\nkernelized learning algorithms, have shown state-of-the-art performances on\nmany tasks. Recently, several definitions of Neural Networks for Graph (GNNs)\nhave been proposed, but their accuracy is not yet satisfying. In this paper, we\npropose a task-independent pre-training methodology that allows a GNN to learn\nthe representation induced by state-of-the-art graph kernels. Then, the\nsupervised learning phase will fine-tune this representation for the task at\nhand. The proposed technique is agnostic on the adopted GNN architecture and\nkernel function, and shows consistent improvements in the predictive\nperformance of GNNs in our preliminary experimental results.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 17:24:58 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Navarin", "Nicol\u00f2", ""], ["Tran", "Dinh V.", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "1811.06931", "submitter": "Sam Cole", "authors": "Sam Cole, Yizhe Zhu", "title": "Exact Recovery in the Hypergraph Stochastic Block Model: a Spectral\n  Algorithm", "comments": null, "journal-ref": "Linear Algebra and its Applications, Volume 593, 2020, Pages 45-73", "doi": "10.1016/j.laa.2020.01.039", "report-no": null, "categories": "cs.LG cs.DM math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exact recovery problem in the hypergraph stochastic block\nmodel (HSBM) with $k$ blocks of equal size. More precisely, we consider a\nrandom $d$-uniform hypergraph $H$ with $n$ vertices partitioned into $k$\nclusters of size $s = n / k$. Hyperedges $e$ are added independently with\nprobability $p$ if $e$ is contained within a single cluster and $q$ otherwise,\nwhere $0 \\leq q < p \\leq 1$. We present a spectral algorithm which recovers the\nclusters exactly with high probability, given mild conditions on $n, k, p, q$,\nand $d$. Our algorithm is based on the adjacency matrix of $H$, which is a\nsymmetric $n \\times n$ matrix whose $(u, v)$-th entry is the number of\nhyperedges containing both $u$ and $v$. To the best of our knowledge, our\nalgorithm is the first to guarantee exact recovery when the number of clusters\n$k=\\Theta(\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 17:26:50 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 21:02:23 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2019 23:06:00 GMT"}, {"version": "v4", "created": "Sun, 2 Feb 2020 23:40:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Cole", "Sam", ""], ["Zhu", "Yizhe", ""]]}, {"id": "1811.06969", "submitter": "Nicholas Frosst", "authors": "Nicholas Frosst, Sara Sabour, Geoffrey Hinton", "title": "DARCCC: Detecting Adversaries by Reconstruction from Class Conditional\n  Capsules", "comments": "To be presented at NIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple technique that allows capsule models to detect\nadversarial images. In addition to being trained to classify images, the\ncapsule model is trained to reconstruct the images from the pose parameters and\nidentity of the correct top-level capsule. Adversarial images do not look like\na typical member of the predicted class and they have much larger\nreconstruction errors when the reconstruction is produced from the top-level\ncapsule for that class. We show that setting a threshold on the $l2$ distance\nbetween the input image and its reconstruction from the winning capsule is very\neffective at detecting adversarial images for three different datasets. The\nsame technique works quite well for CNNs that have been trained to reconstruct\nthe image from all or part of the last hidden layer before the softmax. We then\nexplore a stronger, white-box attack that takes the reconstruction error into\naccount. This attack is able to fool our detection technique but in order to\nmake the model change its prediction to another class, the attack must\ntypically make the \"adversarial\" image resemble images of the other class.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 18:52:58 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Frosst", "Nicholas", ""], ["Sabour", "Sara", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1811.06981", "submitter": "Oren Rippel", "authors": "Oren Rippel, Sanjay Nair, Carissa Lew, Steve Branson, Alexander G.\n  Anderson, Lubomir Bourdev", "title": "Learned Video Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for video coding, learned end-to-end for the\nlow-latency mode. In this setting, our approach outperforms all existing video\ncodecs across nearly the entire bitrate range. To our knowledge, this is the\nfirst ML-based method to do so.\n  We evaluate our approach on standard video compression test sets of varying\nresolutions, and benchmark against all mainstream commercial codecs, in the\nlow-latency mode. On standard-definition videos, relative to our algorithm,\nHEVC/H.265, AVC/H.264 and VP9 typically produce codes up to 60% larger. On\nhigh-definition 1080p videos, H.265 and VP9 typically produce codes up to 20%\nlarger, and H.264 up to 35% larger. Furthermore, our approach does not suffer\nfrom blocking artifacts and pixelation, and thus produces videos that are more\nvisually pleasing.\n  We propose two main contributions. The first is a novel architecture for\nvideo compression, which (1) generalizes motion estimation to perform any\nlearned compensation beyond simple translations, (2) rather than strictly\nrelying on previously transmitted reference frames, maintains a state of\narbitrary information learned by the model, and (3) enables jointly compressing\nall transmitted signals (such as optical flow and residual).\n  Secondly, we present a framework for ML-based spatial rate control: namely, a\nmechanism for assigning variable bitrates across space for each frame. This is\na critical component for video coding, which to our knowledge had not been\ndeveloped within a machine learning setting.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 17:29:51 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Rippel", "Oren", ""], ["Nair", "Sanjay", ""], ["Lew", "Carissa", ""], ["Branson", "Steve", ""], ["Anderson", "Alexander G.", ""], ["Bourdev", "Lubomir", ""]]}, {"id": "1811.06992", "submitter": "Chris Ying", "authors": "Chris Ying, Sameer Kumar, Dehao Chen, Tao Wang, Youlong Cheng", "title": "Image Classification at Supercomputer Scale", "comments": "Presented as part of Systems for ML Workshop @ NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning is extremely computationally intensive, and hardware vendors\nhave responded by building faster accelerators in large clusters. Training deep\nlearning models at petaFLOPS scale requires overcoming both algorithmic and\nsystems software challenges. In this paper, we discuss three systems-related\noptimizations: (1) distributed batch normalization to control per-replica batch\nsizes, (2) input pipeline optimizations to sustain model throughput, and (3)\n2-D torus all-reduce to speed up gradient summation. We combine these\noptimizations to train ResNet-50 on ImageNet to 76.3% accuracy in 2.2 minutes\non a 1024-chip TPU v3 Pod with a training throughput of over 1.05 million\nimages/second and no accuracy drop.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 19:01:40 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 01:30:42 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Ying", "Chris", ""], ["Kumar", "Sameer", ""], ["Chen", "Dehao", ""], ["Wang", "Tao", ""], ["Cheng", "Youlong", ""]]}, {"id": "1811.07006", "submitter": "Melanie F. Pradier", "authors": "Melanie F. Pradier, Weiwei Pan, Jiayu Yao, Soumya Ghosh, Finale\n  Doshi-velez", "title": "Projected BNNs: Avoiding weight-space pathologies by learning latent\n  representations of neural network weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning systems get widely adopted for high-stake decisions,\nquantifying uncertainty over predictions becomes crucial. While modern neural\nnetworks are making remarkable gains in terms of predictive accuracy,\ncharacterizing uncertainty over the parameters of these models is challenging\nbecause of the high dimensionality and complex correlations of the network\nparameter space. This paper introduces a novel variational inference framework\nfor Bayesian neural networks that (1) encodes complex distributions in\nhigh-dimensional parameter space with representations in a low-dimensional\nlatent space, and (2) performs inference efficiently on the low-dimensional\nrepresentations. Across a large array of synthetic and real-world datasets, we\nshow that our method improves uncertainty characterization and model\ngeneralization when compared with methods that work directly in the parameter\nspace.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 19:51:43 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 04:19:46 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 02:18:59 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Pradier", "Melanie F.", ""], ["Pan", "Weiwei", ""], ["Yao", "Jiayu", ""], ["Ghosh", "Soumya", ""], ["Doshi-velez", "Finale", ""]]}, {"id": "1811.07017", "submitter": "Shagun Sodhani", "authors": "Shagun Sodhani, Sarath Chandar, Yoshua Bengio", "title": "Towards Training Recurrent Neural Networks for Lifelong Learning", "comments": "Accepted at Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting and capacity saturation are the central challenges of\nany parametric lifelong learning system. In this work, we study these\nchallenges in the context of sequential supervised learning with an emphasis on\nrecurrent neural networks. To evaluate the models in the lifelong learning\nsetting, we propose a curriculum-based, simple, and intuitive benchmark where\nthe models are trained on tasks with increasing levels of difficulty. To\nmeasure the impact of catastrophic forgetting, the model is tested on all the\nprevious tasks as it completes any task. As a step towards developing true\nlifelong learning systems, we unify Gradient Episodic Memory (a catastrophic\nforgetting alleviation approach) and Net2Net(a capacity expansion approach).\nBoth these models are proposed in the context of feedforward networks and we\nevaluate the feasibility of using them for recurrent networks. Evaluation on\nthe proposed benchmark shows that the unified model is more suitable than the\nconstituent models for lifelong learning setting.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 20:13:23 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 16:21:06 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 05:23:46 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Sodhani", "Shagun", ""], ["Chandar", "Sarath", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1811.07023", "submitter": "Kathleen Greene", "authors": "K. G. Greene", "title": "An Infinite Parade of Giraffes: Expressive Augmentation and Complexity\n  Layers for Cartoon Drawing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore creative image generation constrained by small\ndata. To partially automate the creation of cartoon sketches consistent with a\nspecific designer's style, where acquiring a very large original image set is\nimpossible or cost prohibitive, we exploit domain specific knowledge for a huge\nreduction in original image requirements, creating an effectively infinite\nnumber of cartoon giraffes from just nine original drawings. We introduce\n\"expressive augmentations\" for cartoon sketches, mathematical transformations\nthat create broad domain appropriate variation, far beyond the usual affine\ntransformations, and we show that chained GANs models trained on the temporal\nstages of drawing or \"complexity layers\" can effectively add character\nappropriate details and finish new drawings in the designer's style.\n  We discuss the application of these tools in design processes for textiles,\ngraphics, architectural elements and interior design.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 01:28:12 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Greene", "K. G.", ""]]}, {"id": "1811.07029", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Zhengchao Zhang, Zhen Xiao, and Zhibo Gong", "title": "Modelling the Dynamic Joint Policy of Teammates with Attention\n  Multi-agent DDPG", "comments": "Attention-based Multi-agent DDPG. Experimental results show that it\n  not only outperforms the state-of-the-art RL-based methods and rule-based\n  methods by a large margin, but also achieves better performance in terms of\n  scalability and robustness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modelling and exploiting teammates' policies in cooperative multi-agent\nsystems have long been an interest and also a big challenge for the\nreinforcement learning (RL) community. The interest lies in the fact that if\nthe agent knows the teammates' policies, it can adjust its own policy\naccordingly to arrive at proper cooperations; while the challenge is that the\nagents' policies are changing continuously due to they are learning\nconcurrently, which imposes difficulty to model the dynamic policies of\nteammates accurately. In this paper, we present \\emph{ATTention Multi-Agent\nDeep Deterministic Policy Gradient} (ATT-MADDPG) to address this challenge.\nATT-MADDPG extends DDPG, a single-agent actor-critic RL method, with two\nspecial designs. First, in order to model the teammates' policies, the agent\nshould get access to the observations and actions of teammates. ATT-MADDPG\nadopts a centralized critic to collect such information. Second, to model the\nteammates' policies using the collected information in an effective way,\nATT-MADDPG enhances the centralized critic with an attention mechanism. This\nattention mechanism introduces a special structure to explicitly model the\ndynamic joint policy of teammates, making sure that the collected information\ncan be processed efficiently. We evaluate ATT-MADDPG on both benchmark tasks\nand the real-world packet routing tasks. Experimental results show that it not\nonly outperforms the state-of-the-art RL-based methods and rule-based methods\nby a large margin, but also achieves better performance in terms of scalability\nand robustness.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 11:30:29 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Mao", "Hangyu", ""], ["Zhang", "Zhengchao", ""], ["Xiao", "Zhen", ""], ["Gong", "Zhibo", ""]]}, {"id": "1811.07042", "submitter": "Anton Belyy", "authors": "Mariia Seleznova, Anton Belyy, Aleksei Sholokhov", "title": "Towards Large-Scale Exploratory Search over Heterogeneous Sources", "comments": "5 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since time immemorial, people have been looking for ways to organize\nscientific knowledge into some systems to facilitate search and discovery of\nnew ideas. The problem was partially solved in the pre-Internet era using\nlibrary classifications, but nowadays it is nearly impossible to classify all\nscientific and popular scientific knowledge manually. There is a clear gap\nbetween the diversity and the amount of data available on the Internet and the\nalgorithms for automatic structuring of such data. In our preliminary study, we\napproach the problem of knowledge discovery on web-scale data with diverse text\nsources and propose an algorithm to aggregate multiple collections into a\nsingle hierarchical topic model. We implement a web service named Rysearch to\ndemonstrate the concept of topical exploratory search and make it available\nonline.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 01:48:48 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 10:13:59 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Seleznova", "Mariia", ""], ["Belyy", "Anton", ""], ["Sholokhov", "Aleksei", ""]]}, {"id": "1811.07050", "submitter": "Lingge Li", "authors": "Lingge Li, Nitish Nayak, Jianming Bian, Pierre Baldi", "title": "Gaussian Process Accelerated Feldman-Cousins Approach for Physical\n  Parameter Inference", "comments": "14 pages, 12 figures, APS April Meeting 2019", "journal-ref": "Phys. Rev. D 101, 012001 (2020)", "doi": "10.1103/PhysRevD.101.012001", "report-no": null, "categories": "physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unified approach of Feldman and Cousins allows for exact statistical\ninference of small signals that commonly arise in high energy physics. It has\ngained widespread use, for instance, in measurements of neutrino oscillation\nparameters in long-baseline experiments. However, the approach relies on the\nNeyman construction of the classical confidence interval and is computationally\nintensive as it is typically done in a grid-based fashion over the entire\nparameter space. In this letter, we propose an efficient algorithm for the\nFeldman-Cousins approach using Gaussian processes to construct confidence\nintervals iteratively. We show that in the neutrino oscillation context, one\ncan obtain confidence intervals 5 times faster in one dimension and 10 times\nfaster in two dimensions, while maintaining an accuracy above 99.5%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 22:12:18 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 19:13:48 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 03:55:23 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Li", "Lingge", ""], ["Nayak", "Nitish", ""], ["Bian", "Jianming", ""], ["Baldi", "Pierre", ""]]}, {"id": "1811.07051", "submitter": "Doron Bergman", "authors": "Doron L. Bergman", "title": "Symmetry constrained machine learning", "comments": null, "journal-ref": "In: Bi Y., Bhatia R., Kapoor S. (eds) Intelligent Systems and\n  Applications. IntelliSys 2019. Advances in Intelligent Systems and Computing,\n  vol 1038. Springer, Cham", "doi": "10.1007/978-3-030-29513-4_37", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetry, a central concept in understanding the laws of nature, has been\nused for centuries in physics, mathematics, and chemistry, to help make\nmathematical models tractable. Yet, despite its power, symmetry has not been\nused extensively in machine learning, until rather recently. In this article we\nshow a general way to incorporate symmetries into machine learning models. We\ndemonstrate this with a detailed analysis on a rather simple real world machine\nlearning system - a neural network for classifying handwritten digits, lacking\nbias terms for every neuron. We demonstrate that ignoring symmetries can have\ndire over-fitting consequences, and that incorporating symmetry into the model\nreduces over-fitting, while at the same time reducing complexity, ultimately\nrequiring less training data, and taking less time and resources to train.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 22:25:10 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 16:25:30 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Bergman", "Doron L.", ""]]}, {"id": "1811.07054", "submitter": "Tianyu Zhang", "authors": "Tianyu Zhang, Liwei Zhang, Philip R.O. Payne, Fuhai Li", "title": "Synergistic Drug Combination Prediction by Integrating Multi-omics Data\n  in Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug resistance is still a major challenge in cancer therapy. Drug\ncombination is expected to overcome drug resistance. However, the number of\npossible drug combinations is enormous, and thus it is infeasible to\nexperimentally screen all effective drug combinations considering the limited\nresources. Therefore, computational models to predict and prioritize effective\ndrug combinations is important for combinatory therapy discovery in cancer. In\nthis study, we proposed a novel deep learning model, AuDNNsynergy, to\nprediction drug combinations by integrating multi-omics data and chemical\nstructure data. In specific, three autoencoders were trained using the gene\nexpression, copy number and genetic mutation data of all tumor samples from The\nCancer Genome Atlas. Then the physicochemical properties of drugs combined with\nthe output of the three autoencoders, characterizing the individual cancer\ncell-lines, were used as the input of a deep neural network that predicts the\nsynergy value of given pair-wise drug combinations against the specific cancer\ncell-lines. The comparison results showed the proposed AuDNNsynergy model\noutperforms four state-of-art approaches, namely DeepSynergy, Gradient Boosting\nMachines, Random Forests, and Elastic Nets. Moreover, we conducted the\ninterpretation analysis of the deep learning model to investigate potential\nvital genetic predictors and the underlying mechanism of synergistic drug\ncombinations on specific cancer cell-lines.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 22:40:06 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zhang", "Tianyu", ""], ["Zhang", "Liwei", ""], ["Payne", "Philip R. O.", ""], ["Li", "Fuhai", ""]]}, {"id": "1811.07055", "submitter": "Anastasios Kyrillidis", "authors": "Vatsal Shah, Anastasios Kyrillidis, Sujay Sanghavi", "title": "Minimum weight norm models do not always generalize well for\n  over-parameterized problems", "comments": "This work is substituted by the paper in arXiv:2011.14066", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is substituted by the paper in arXiv:2011.14066.\n  Stochastic gradient descent is the de facto algorithm for training deep\nneural networks (DNNs). Despite its popularity, it still requires fine tuning\nin order to achieve its best performance. This has led to the development of\nadaptive methods, that claim automatic hyper-parameter optimization. Recently,\nresearchers have studied both algorithmic classes via toy examples: e.g., for\nover-parameterized linear regression, Wilson et. al. (2017) shows that, while\nSGD always converges to the minimum-norm solution, adaptive methods show no\nsuch inclination, leading to worse generalization capabilities. Our aim is to\nstudy this conjecture further. We empirically show that the minimum weight norm\nis not necessarily the proper gauge of good generalization in simplified\nscenaria, and different models found by adaptive methods could outperform plain\ngradient methods. In practical DNN settings, we observe that adaptive methods\ncan outperform SGD, with larger weight norm output models, but without\nnecessarily reducing the amount of tuning required.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 22:46:16 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 16:59:54 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 06:54:59 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Shah", "Vatsal", ""], ["Kyrillidis", "Anastasios", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1811.07062", "submitter": "Vardan Papyan", "authors": "Vardan Papyan", "title": "The Full Spectrum of Deepnet Hessians at Scale: Dynamics with SGD\n  Training and Sample Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply state-of-the-art tools in modern high-dimensional numerical linear\nalgebra to approximate efficiently the spectrum of the Hessian of modern\ndeepnets, with tens of millions of parameters, trained on real data. Our\nresults corroborate previous findings, based on small-scale networks, that the\nHessian exhibits \"spiked\" behavior, with several outliers isolated from a\ncontinuous bulk. We decompose the Hessian into different components and study\nthe dynamics with training and sample size of each term individually.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 23:22:37 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 01:12:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Papyan", "Vardan", ""]]}, {"id": "1811.07073", "submitter": "Arash Vahdat", "authors": "Mostafa S. Ibrahim, Arash Vahdat, Mani Ranjbar, William G. Macready", "title": "Semi-Supervised Semantic Image Segmentation with Self-correcting\n  Networks", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a large image dataset with high-quality object masks for semantic\nsegmentation is costly and time consuming. In this paper, we introduce a\nprincipled semi-supervised framework that only uses a small set of fully\nsupervised images (having semantic segmentation labels and box labels) and a\nset of images with only object bounding box labels (we call it the weak set).\nOur framework trains the primary segmentation model with the aid of an\nancillary model that generates initial segmentation labels for the weak set and\na self-correction module that improves the generated labels during training\nusing the increasingly accurate primary model. We introduce two variants of the\nself-correction module using either linear or convolutional functions.\nExperiments on the PASCAL VOC 2012 and Cityscape datasets show that our models\ntrained with a small fully supervised set perform similar to, or better than,\nmodels trained with a large fully supervised set while requiring ~7x less\nannotation effort.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 01:20:03 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 23:11:23 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 04:58:15 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ibrahim", "Mostafa S.", ""], ["Vahdat", "Arash", ""], ["Ranjbar", "Mani", ""], ["Macready", "William G.", ""]]}, {"id": "1811.07131", "submitter": "Sreejith Kallummil", "authors": "Sreejith Kallummil and Sheetal Kalyani", "title": "High SNR Consistent Compressive Sensing Without Signal and Noise\n  Statistics", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering the support of sparse vectors in underdetermined linear regression\nmodels, \\textit{aka}, compressive sensing is important in many signal\nprocessing applications. High SNR consistency (HSC), i.e., the ability of a\nsupport recovery technique to correctly identify the support with increasing\nsignal to noise ratio (SNR) is an increasingly popular criterion to qualify the\nhigh SNR optimality of support recovery techniques. The HSC results available\nin literature for support recovery techniques applicable to underdetermined\nlinear regression models like least absolute shrinkage and selection operator\n(LASSO), orthogonal matching pursuit (OMP) etc. assume \\textit{a priori}\nknowledge of noise variance or signal sparsity. However, both these parameters\nare unavailable in most practical applications. Further, it is extremely\ndifficult to estimate noise variance or signal sparsity in underdetermined\nregression models. This limits the utility of existing HSC results. In this\narticle, we propose two techniques, \\textit{viz.}, residual ratio minimization\n(RRM) and residual ratio thresholding with adaptation (RRTA) to operate OMP\nalgorithm without the \\textit{a priroi} knowledge of noise variance and signal\nsparsity and establish their HSC analytically and numerically. To the best of\nour knowledge, these are the first and only noise statistics oblivious\nalgorithms to report HSC in underdetermined regression models.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 08:58:06 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Kallummil", "Sreejith", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1811.07134", "submitter": "Ambedkar Dukkipati", "authors": "Rohith AP and Ambedkar Dukkipati and Gaurav Pandey", "title": "Deep Discriminative Learning for Unsupervised Domain Adaptation", "comments": "There are some issues with our code and experimentation, hence we are\n  withdrawing the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary objective of domain adaptation methods is to transfer knowledge\nfrom a source domain to a target domain that has similar but different data\ndistributions. Thus, in order to correctly classify the unlabeled target domain\nsamples, the standard approach is to learn a common representation for both\nsource and target domain, thereby indirectly addressing the problem of learning\na classifier in the target domain. However, such an approach does not address\nthe task of classification in the target domain directly. In contrast, we\npropose an approach that directly addresses the problem of learning a\nclassifier in the unlabeled target domain. In particular, we train a classifier\nto correctly classify the training samples while simultaneously classifying the\nsamples in the target domain in an unsupervised manner. The corresponding model\nis referred to as Discriminative Encoding for Domain Adaptation (DEDA). We show\nthat this simple approach for performing unsupervised domain adaptation is\nindeed quite powerful. Our method achieves state of the art results in\nunsupervised adaptation tasks on various image classification benchmarks. We\nalso obtained state of the art performance on domain adaptation in Amazon\nreviews sentiment classification dataset. We perform additional experiments\nwhen the source data has less labeled examples and also on zero-shot domain\nadaptation task where no target domain samples are used for training.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 09:41:01 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 12:42:48 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["AP", "Rohith", ""], ["Dukkipati", "Ambedkar", ""], ["Pandey", "Gaurav", ""]]}, {"id": "1811.07143", "submitter": "Iddo Drori", "authors": "Iddo Drori, Isht Dwivedi, Pranav Shrestha, Jeffrey Wan, Yueqi Wang,\n  Yunchu He, Anthony Mazza, Hugh Krogh-Freeman, Dimitri Leggas, Kendal\n  Sandridge, Linyong Nan, Kaveri Thakoor, Chinmay Joshi, Sonam Goenka, Chen\n  Keasar, Itsik Pe'er", "title": "High Quality Prediction of Protein Q8 Secondary Structure by Diverse\n  Neural Network Architectures", "comments": "NIPS 2018 Workshop on Machine Learning for Molecules and Materials,\n  10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of protein secondary structure prediction using a\ncommon task framework. This lead to the introduction of multiple ideas for\nneural architectures based on state of the art building blocks, used in this\ntask for the first time. We take a principled machine learning approach, which\nprovides genuine, unbiased performance measures, correcting longstanding errors\nin the application domain. We focus on the Q8 resolution of secondary\nstructure, an active area for continuously improving methods. We use an\nensemble of strong predictors to achieve accuracy of 70.7% (on the CB513 test\nset using the CB6133filtered training set). These results are statistically\nindistinguishable from those of the top existing predictors. In the spirit of\nreproducible research we make our data, models and code available, aiming to\nset a gold standard for purity of training and testing sets. Such good\npractices lower entry barriers to this domain and facilitate reproducible,\nextendable research.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 10:47:22 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Drori", "Iddo", ""], ["Dwivedi", "Isht", ""], ["Shrestha", "Pranav", ""], ["Wan", "Jeffrey", ""], ["Wang", "Yueqi", ""], ["He", "Yunchu", ""], ["Mazza", "Anthony", ""], ["Krogh-Freeman", "Hugh", ""], ["Leggas", "Dimitri", ""], ["Sandridge", "Kendal", ""], ["Nan", "Linyong", ""], ["Thakoor", "Kaveri", ""], ["Joshi", "Chinmay", ""], ["Goenka", "Sonam", ""], ["Keasar", "Chen", ""], ["Pe'er", "Itsik", ""]]}, {"id": "1811.07174", "submitter": "Samuel Gomes Fadel", "authors": "Samuel G. Fadel and Ricardo da S. Torres", "title": "Link Prediction in Dynamic Graphs for Recommendation", "comments": "Workshop on Relational Representation Learning (R2L), NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in employing neural networks on graph domains helped push the\nstate of the art in link prediction tasks, particularly in recommendation\nservices. However, the use of temporal contextual information, often modeled as\ndynamic graphs that encode the evolution of user-item relationships over time,\nhas been overlooked in link prediction problems. In this paper, we consider the\nhypothesis that leveraging such information enables models to make better\npredictions, proposing a new neural network approach for this. Our experiments,\nperformed on the widely used ML-100k and ML-1M datasets, show that our approach\nproduces better predictions in scenarios where the pattern of user-item\nrelationships change over time. In addition, they suggest that existing\napproaches are significantly impacted by those changes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 14:56:13 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Fadel", "Samuel G.", ""], ["Torres", "Ricardo da S.", ""]]}, {"id": "1811.07192", "submitter": "Yichuan Zhang", "authors": "Yichuan Zhang", "title": "The Theory and Algorithm of Ergodic Inference", "comments": "Ergodic inference, statistical inference, probability theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Approximate inference algorithm is one of the fundamental research fields in\nmachine learning. The two dominant theoretical inference frameworks in machine\nlearning are variational inference (VI) and Markov chain Monte Carlo (MCMC).\nHowever, because of the fundamental limitation in the theory, it is very\nchallenging to improve existing VI and MCMC methods on both the computational\nscalability and statistical efficiency. To overcome this obstacle, we propose a\nnew theoretical inference framework called ergodic Inference based on the\nfundamental property of ergodic transformations. The key contribution of this\nwork is to establish the theoretical foundation of ergodic inference for the\ndevelopment of practical algorithms in future work.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 17:21:14 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zhang", "Yichuan", ""]]}, {"id": "1811.07199", "submitter": "Vidhi Lalchand Miss", "authors": "Vidhi Lalchand, A.C. Faul", "title": "A Fast and Greedy Subset-of-Data (SoD) Scheme for Sparsification in\n  Gaussian processes", "comments": "38th International Workshop on Bayesian Inference and Maximum Entropy\n  Methods in Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their standard form Gaussian processes (GPs) provide a powerful\nnon-parametric framework for regression and classificaton tasks. Their one\nlimiting property is their $\\mathcal{O}(N^{3})$ scaling where $N$ is the number\nof training data points. In this paper we present a framework for GP training\nwith sequential selection of training data points using an intuitive selection\nmetric. The greedy forward selection strategy is devised to target two factors\n- regions of high predictive uncertainty and underfit. Under this technique the\ncomplexity of GP training is reduced to $\\mathcal{O}(M^{3})$ where $(M \\ll N)$\nif $M$ data points (out of $N$) are eventually selected. The sequential nature\nof the algorithm circumvents the need to invert the covariance matrix of\ndimension $N \\times N$ and enables the use of favourable matrix inverse update\nidentities. We outline the algorithm and sequential updates to the posterior\nmean and variance. We demonstrate our method on selected one dimensional\nfunctions and show that the loss in accuracy due to using a subset of data\npoints is marginal compared to the computational gains.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 18:04:41 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 18:23:00 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Lalchand", "Vidhi", ""], ["Faul", "A. C.", ""]]}, {"id": "1811.07201", "submitter": "John Martin Jr", "authors": "John Martin, Brendan Englot", "title": "Recursive Sparse Pseudo-input Gaussian Process SARSA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of Gaussian Process (GP) methods for Temporal Difference learning\nhas shown promise for data-efficient model-free Reinforcement Learning. In this\npaper, we consider a recent variant of the GP-SARSA algorithm, called Sparse\nPseudo-input Gaussian Process SARSA (SPGP-SARSA), and derive recursive formulas\nfor its predictive moments. This extension promotes greater memory efficiency,\nsince previous computations can be reused and, interestingly, it provides a\ntechnique for updating value estimates on a multiple timescales\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 18:06:37 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Martin", "John", ""], ["Englot", "Brendan", ""]]}, {"id": "1811.07209", "submitter": "Stefan Webb", "authors": "Stefan Webb, Tom Rainforth, Yee Whye Teh, M. Pawan Kumar", "title": "A Statistical Approach to Assessing Neural Network Robustness", "comments": "To appear at the 7th International Conference on Learning\n  Representations (ICLR 2019), New Orleans", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to assessing the robustness of neural networks\nbased on estimating the proportion of inputs for which a property is violated.\nSpecifically, we estimate the probability of the event that the property is\nviolated under an input model. Our approach critically varies from the formal\nverification framework in that when the property can be violated, it provides\nan informative notion of how robust the network is, rather than just the\nconventional assertion that the network is not verifiable. Furthermore, it\nprovides an ability to scale to larger networks than formal verification\napproaches. Though the framework still provides a formal guarantee of\nsatisfiability whenever it successfully finds one or more violations, these\nadvantages do come at the cost of only providing a statistical estimate of\nunsatisfiability whenever no violation is found. Key to the practical success\nof our approach is an adaptation of multi-level splitting, a Monte Carlo\napproach for estimating the probability of rare events, to our statistical\nrobustness framework. We demonstrate that our approach is able to emulate\nformal verification procedures on benchmark problems, while scaling to larger\nnetworks and providing reliable additional information in the form of accurate\nestimates of the violation probability.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 19:13:58 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 14:30:50 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 21:42:11 GMT"}, {"version": "v4", "created": "Thu, 21 Feb 2019 22:29:24 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Webb", "Stefan", ""], ["Rainforth", "Tom", ""], ["Teh", "Yee Whye", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1811.07211", "submitter": "Jacob Springer", "authors": "Jacob M. Springer, Charles S. Strauss, Austin M. Thresher, Edward Kim,\n  Garrett T. Kenyon", "title": "Classifiers Based on Deep Sparse Coding Architectures are Robust to Deep\n  Learning Transferable Examples", "comments": "8 pages, 8 figures, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has shown great success in recent years, researchers\nhave discovered a critical flaw where small, imperceptible changes in the input\nto the system can drastically change the output classification. These attacks\nare exploitable in nearly all of the existing deep learning classification\nframeworks. However, the susceptibility of deep sparse coding models to\nadversarial examples has not been examined. Here, we show that classifiers\nbased on a deep sparse coding model whose classification accuracy is\ncompetitive with a variety of deep neural network models are robust to\nadversarial examples that effectively fool those same deep learning models. We\ndemonstrate both quantitatively and qualitatively that the robustness of deep\nsparse coding models to adversarial examples arises from two key properties.\nFirst, because deep sparse coding models learn general features corresponding\nto generators of the dataset as a whole, rather than highly discriminative\nfeatures for distinguishing specific classes, the resulting classifiers are\nless dependent on idiosyncratic features that might be more easily exploited.\nSecond, because deep sparse coding models utilize fixed point attractor\ndynamics with top-down feedback, it is more difficult to find small changes to\nthe input that drive the resulting representations out of the correct attractor\nbasin.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 19:39:54 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 18:55:55 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Springer", "Jacob M.", ""], ["Strauss", "Charles S.", ""], ["Thresher", "Austin M.", ""], ["Kim", "Edward", ""], ["Kenyon", "Garrett T.", ""]]}, {"id": "1811.07216", "submitter": "Alexandre Yahi", "authors": "Natalia Antropova, Andrew L. Beam, Brett K. Beaulieu-Jones, Irene\n  Chen, Corey Chivers, Adrian Dalca, Sam Finlayson, Madalina Fiterau, Jason\n  Alan Fries, Marzyeh Ghassemi, Mike Hughes, Bruno Jedynak, Jasvinder S.\n  Kandola, Matthew McDermott, Tristan Naumann, Peter Schulam, Farah Shamout,\n  Alexandre Yahi", "title": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume represents the accepted submissions from the Machine Learning for\nHealth (ML4H) workshop at the conference on Neural Information Processing\nSystems (NeurIPS) 2018, held on December 8, 2018 in Montreal, Canada.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 20:14:43 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 19:47:09 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Antropova", "Natalia", ""], ["Beam", "Andrew L.", ""], ["Beaulieu-Jones", "Brett K.", ""], ["Chen", "Irene", ""], ["Chivers", "Corey", ""], ["Dalca", "Adrian", ""], ["Finlayson", "Sam", ""], ["Fiterau", "Madalina", ""], ["Fries", "Jason Alan", ""], ["Ghassemi", "Marzyeh", ""], ["Hughes", "Mike", ""], ["Jedynak", "Bruno", ""], ["Kandola", "Jasvinder S.", ""], ["McDermott", "Matthew", ""], ["Naumann", "Tristan", ""], ["Schulam", "Peter", ""], ["Shamout", "Farah", ""], ["Yahi", "Alexandre", ""]]}, {"id": "1811.07240", "submitter": "Kyle Kastner", "authors": "Kyle Kastner, Jo\\~ao Felipe Santos, Yoshua Bengio, Aaron Courville", "title": "Representation Mixing for TTS Synthesis", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent character and phoneme-based parametric TTS systems using deep learning\nhave shown strong performance in natural speech generation. However, the choice\nbetween character or phoneme input can create serious limitations for practical\ndeployment, as direct control of pronunciation is crucial in certain cases. We\ndemonstrate a simple method for combining multiple types of linguistic\ninformation in a single encoder, named representation mixing, enabling flexible\nchoice between character, phoneme, or mixed representations during inference.\nExperiments and user studies on a public audiobook corpus show the efficacy of\nour approach.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 22:45:15 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 23:16:10 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Kastner", "Kyle", ""], ["Santos", "Jo\u00e3o Felipe", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""]]}, {"id": "1811.07245", "submitter": "Mike Gartrell", "authors": "Mike Gartrell, Elvis Dohmatob, Jon Alberdi", "title": "Deep Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) have attracted significant attention as\nan elegant model that is able to capture the balance between quality and\ndiversity within sets. DPPs are parameterized by a positive semi-definite\nkernel matrix. While DPPs have substantial expressive power, they are\nfundamentally limited by the parameterization of the kernel matrix and their\ninability to capture nonlinear interactions between items within sets. We\npresent the deep DPP model as way to address these limitations, by using a deep\nfeed-forward neural network to learn the kernel matrix. In addition to allowing\nus to capture nonlinear item interactions, the deep DPP also allows easy\nincorporation of item metadata into DPP learning. Since the learning target is\nthe DPP kernel matrix, the deep DPP allows us to use existing DPP algorithms\nfor efficient learning, sampling, and prediction. Through an evaluation on\nseveral real-world datasets, we show experimentally that the deep DPP can\nprovide a considerable improvement in the predictive performance of DPPs, while\nalso outperforming strong baseline models in many cases.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 23:22:51 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 23:54:12 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 14:50:12 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Gartrell", "Mike", ""], ["Dohmatob", "Elvis", ""], ["Alberdi", "Jon", ""]]}, {"id": "1811.07255", "submitter": "James Foulds", "authors": "James Foulds, Rashidul Islam, Kamrun Keya, Shimei Pan", "title": "Bayesian Modeling of Intersectional Fairness: The Variance of Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersectionality is a framework that analyzes how interlocking systems of\npower and oppression affect individuals along overlapping dimensions including\nrace, gender, sexual orientation, class, and disability. Intersectionality\ntheory therefore implies it is important that fairness in artificial\nintelligence systems be protected with regard to multi-dimensional protected\nattributes. However, the measurement of fairness becomes statistically\nchallenging in the multi-dimensional setting due to data sparsity, which\nincreases rapidly in the number of dimensions, and in the values per dimension.\nWe present a Bayesian probabilistic modeling approach for the reliable,\ndata-efficient estimation of fairness with multi-dimensional protected\nattributes, which we apply to two existing intersectional fairness metrics.\nExperimental results on census data and the COMPAS criminal justice recidivism\ndataset demonstrate the utility of our methodology, and show that Bayesian\nmethods are valuable for the modeling and measurement of fairness in an\nintersectional context.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 01:54:24 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 16:58:05 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Foulds", "James", ""], ["Islam", "Rashidul", ""], ["Keya", "Kamrun", ""], ["Pan", "Shimei", ""]]}, {"id": "1811.07266", "submitter": "Yuchen Li", "authors": "Yuchen Li, Safwan Hossain, Kiarash Jamali, Frank Rudzicz", "title": "DeepConsensus: using the consensus of features from multiple layers to\n  attain robust image classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a classifier whose test set is exposed to various perturbations\nthat are not present in the training set. These test samples still contain\nenough features to map them to the same class as their unperturbed counterpart.\nCurrent architectures exhibit rapid degradation of accuracy when trained on\nstandard datasets but then used to classify perturbed samples of that data. To\naddress this, we present a novel architecture named DeepConsensus that\nsignificantly improves generalization to these test-time perturbations. Our key\ninsight is that deep neural networks should directly consider summaries of low\nand high level features when making classifications. Existing convolutional\nneural networks can be augmented with DeepConsensus, leading to improved\nresistance against large and small perturbations on MNIST, EMNIST,\nFashionMNIST, CIFAR10 and SVHN datasets.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 03:37:52 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 18:46:52 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2018 17:39:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Yuchen", ""], ["Hossain", "Safwan", ""], ["Jamali", "Kiarash", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1811.07267", "submitter": "Francesco Fusco", "authors": "Francesco Fusco", "title": "Probabilistic Graphs for Sensor Data-driven Modelling of Power Systems\n  at Scale", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-04303-2_4", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing complexity of the power grid, driven by increasing share of\ndistributed energy resources and by massive deployment of intelligent\ninternet-connected devices, requires new modelling tools for planning and\noperation. Physics-based state estimation models currently used for data\nfiltering, prediction and anomaly detection are hard to maintain and adapt to\nthe ever-changing complex dynamics of the power system. A data-driven approach\nbased on probabilistic graphs is proposed, where custom non-linear, localised\nmodels of the joint density of subset of system variables can be combined to\nmodel arbitrarily large and complex systems. The graphical model allows to\nnaturally embed domain knowledge in the form of variables dependency structure\nor local quantitative relationships. A specific instance where neural-network\nmodels are used to represent the local joint densities is proposed, although\nthe methodology generalises to other model classes. Accuracy and scalability\nare evaluated on a large-scale data set representative of the European\ntransmission grid.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 04:00:32 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Fusco", "Francesco", ""]]}, {"id": "1811.07279", "submitter": "Kyubin Lee", "authors": "Kyubin Lee, Akshay Sood, Mark Craven", "title": "Understanding Learned Models by Identifying Important Features at the\n  Right Resolution", "comments": "First two authors contributed equally to this work, Accepted for\n  presentation at the Thirty-Third AAAI Conference on Artificial Intelligence\n  (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application domains, it is important to characterize how complex\nlearned models make their decisions across the distribution of instances. One\nway to do this is to identify the features and interactions among them that\ncontribute to a model's predictive accuracy. We present a model-agnostic\napproach to this task that makes the following specific contributions. Our\napproach (i) tests feature groups, in addition to base features, and tries to\ndetermine the level of resolution at which important features can be\ndetermined, (ii) uses hypothesis testing to rigorously assess the effect of\neach feature on the model's loss, (iii) employs a hierarchical approach to\ncontrol the false discovery rate when testing feature groups and individual\nbase features for importance, and (iv) uses hypothesis testing to identify\nimportant interactions among features and feature groups. We evaluate our\napproach by analyzing random forest and LSTM neural network models learned in\ntwo challenging biomedical applications.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 05:30:21 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 23:30:46 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Lee", "Kyubin", ""], ["Sood", "Akshay", ""], ["Craven", "Mark", ""]]}, {"id": "1811.07296", "submitter": "Jianlin Su", "authors": "Jianlin Su", "title": "GAN-QP: A Novel GAN Framework without Gradient Vanishing and Lipschitz\n  Constraint", "comments": "simplify some proofs; add reconstruction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We know SGAN may have a risk of gradient vanishing. A significant improvement\nis WGAN, with the help of 1-Lipschitz constraint on discriminator to prevent\nfrom gradient vanishing. Is there any GAN having no gradient vanishing and no\n1-Lipschitz constraint on discriminator? We do find one, called GAN-QP.\n  To construct a new framework of Generative Adversarial Network (GAN) usually\nincludes three steps: 1. choose a probability divergence; 2. convert it into a\ndual form; 3. play a min-max game. In this articles, we demonstrate that the\nfirst step is not necessary. We can analyse the property of divergence and even\nconstruct new divergence in dual space directly. As a reward, we obtain a\nsimpler alternative of WGAN: GAN-QP. We demonstrate that GAN-QP have a better\nperformance than WGAN in theory and practice.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 08:36:03 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 11:44:33 GMT"}, {"version": "v3", "created": "Sat, 8 Dec 2018 04:15:42 GMT"}, {"version": "v4", "created": "Sat, 15 Dec 2018 11:30:28 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Su", "Jianlin", ""]]}, {"id": "1811.07308", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Yilin Shen, Hongxia Jin, William Wang", "title": "A Variational Dirichlet Framework for Out-of-Distribution Detection", "comments": "Tech Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recently rapid development in deep learning, deep neural networks\nhave been widely adopted in many real-life applications. However, deep neural\nnetworks are also known to have very little control over its uncertainty for\nunseen examples, which potentially causes very harmful and annoying\nconsequences in practical scenarios. In this paper, we are particularly\ninterested in designing a higher-order uncertainty metric for deep neural\nnetworks and investigate its effectiveness under the out-of-distribution\ndetection task proposed by~\\cite{hendrycks2016baseline}. Our method first\nassumes there exists an underlying higher-order distribution $\\mathbb{P}(z)$,\nwhich controls label-wise categorical distribution $\\mathbb{P}(y)$ over classes\non the K-dimension simplex, and then approximate such higher-order distribution\nvia parameterized posterior function $p_{\\theta}(z|x)$ under variational\ninference framework, finally we use the entropy of learned posterior\ndistribution $p_{\\theta}(z|x)$ as uncertainty measure to detect\nout-of-distribution examples. Further, we propose an auxiliary objective\nfunction to discriminate against synthesized adversarial examples to further\nincrease the robustness of the proposed uncertainty measure. Through\ncomprehensive experiments on various datasets, our proposed framework is\ndemonstrated to consistently outperform competing algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 10:24:58 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 19:48:44 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2019 01:51:41 GMT"}, {"version": "v4", "created": "Sat, 20 Apr 2019 22:53:10 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Chen", "Wenhu", ""], ["Shen", "Yilin", ""], ["Jin", "Hongxia", ""], ["Wang", "William", ""]]}, {"id": "1811.07311", "submitter": "Yoel Shoshan", "authors": "Yoel Shoshan and Vadim Ratner", "title": "Regularized adversarial examples for model interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As machine learning algorithms continue to improve, there is an increasing\nneed for explaining why a model produces a certain prediction for a certain\ninput. In recent years, several methods for model interpretability have been\ndeveloped, aiming to provide explanation of which subset regions of the model\ninput is the main reason for the model prediction. In parallel, a significant\nresearch community effort is occurring in recent years for developing\nadversarial example generation methods for fooling models, while not altering\nthe true label of the input,as it would have been classified by a human\nannotator. In this paper, we bridge the gap between adversarial example\ngeneration and model interpretability, and introduce a modification to the\nadversarial example generation process which encourages better\ninterpretability. We analyze the proposed method on a public medical imaging\ndataset, both quantitatively and qualitatively, and show that it significantly\noutperforms the leading known alternative method. Our suggested method is\nsimple to implement, and can be easily plugged into most common adversarial\nexample generation frameworks. Additionally, we propose an explanation quality\nmetric - $APE$ - \"Adversarial Perturbative Explanation\", which measures how\nwell an explanation describes model decisions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 10:40:16 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 07:29:32 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Shoshan", "Yoel", ""], ["Ratner", "Vadim", ""]]}, {"id": "1811.07342", "submitter": "Xiao-Yang Liu", "authors": "Weijun Lu, Xiao-Yang Liu, Qingwei Wu, Yue Sun, Anwar Walid", "title": "Transform-Based Multilinear Dynamical System for Tensor Time Series\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel multilinear dynamical system (MLDS) in a transform domain,\nnamed $\\mathcal{L}$-MLDS, to model tensor time series. With transformations\napplied to a tensor data, the latent multidimensional correlations among the\nfrontal slices are built, and thus resulting in the computational independence\nin the transform domain. This allows the exact separability of the\nmulti-dimensional problem into multiple smaller LDS problems. To estimate the\nsystem parameters, we utilize the expectation-maximization (EM) algorithm to\ndetermine the parameters of each LDS. Further, $\\mathcal{L}$-MLDSs\nsignificantly reduce the model parameters and allows parallel processing. Our\ngeneral $\\mathcal{L}$-MLDS model is implemented based on different transforms:\ndiscrete Fourier transform, discrete cosine transform and discrete wavelet\ntransform. Due to the nonlinearity of these transformations, $\\mathcal{L}$-MLDS\nis able to capture the nonlinear correlations within the data unlike the MLDS\n\\cite{rogers2013multilinear} which assumes multi-way linear correlations. Using\nfour real datasets, the proposed $\\mathcal{L}$-MLDS is shown to achieve much\nhigher prediction accuracy than the state-of-the-art MLDS and LDS with an equal\nnumber of parameters under different noise models. In particular, the relative\nerrors are reduced by $50\\% \\sim 99\\%$. Simultaneously, $\\mathcal{L}$-MLDS\nachieves an exponential improvement in the model's training time than MLDS.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 15:45:31 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Lu", "Weijun", ""], ["Liu", "Xiao-Yang", ""], ["Wu", "Qingwei", ""], ["Sun", "Yue", ""], ["Walid", "Anwar", ""]]}, {"id": "1811.07350", "submitter": "Feiyang Pan", "authors": "Feiyang Pan, Qingpeng Cai, An-Xiang Zeng, Chun-Xiang Pan, Qing Da,\n  Hualin He, Qing He, Pingzhong Tang", "title": "Policy Optimization with Model-based Explorations", "comments": "Accepted at AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning methods such as the Proximal Policy\nOptimization algorithm (PPO) have successfully applied in complex\ndecision-making problems such as Atari games. However, these methods suffer\nfrom high variances and high sample complexity. On the other hand, model-based\nreinforcement learning methods that learn the transition dynamics are more\nsample efficient, but they often suffer from the bias of the transition\nestimation. How to make use of both model-based and model-free learning is a\ncentral problem in reinforcement learning. In this paper, we present a new\ntechnique to address the trade-off between exploration and exploitation, which\nregards the difference between model-free and model-based estimations as a\nmeasure of exploration value. We apply this new technique to the PPO algorithm\nand arrive at a new policy optimization method, named Policy Optimization with\nModel-based Explorations (POME). POME uses two components to predict the\nactions' target values: a model-free one estimated by Monte-Carlo sampling and\na model-based one which learns a transition model and predicts the value of the\nnext state. POME adds the error of these two target estimations as the\nadditional exploration value for each state-action pair, i.e, encourages the\nalgorithm to explore the states with larger target errors which are hard to\nestimate. We compare POME with PPO on Atari 2600 games, and it shows that POME\noutperforms PPO on 33 games out of 49 games.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 16:48:40 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Pan", "Feiyang", ""], ["Cai", "Qingpeng", ""], ["Zeng", "An-Xiang", ""], ["Pan", "Chun-Xiang", ""], ["Da", "Qing", ""], ["He", "Hualin", ""], ["He", "Qing", ""], ["Tang", "Pingzhong", ""]]}, {"id": "1811.07375", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Yiren Zhao, Robert Mullins, Ross Anderson", "title": "The Taboo Trap: Behavioural Detection of Adversarial Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Neural Networks (DNNs) have become a powerful toolfor a wide range of\nproblems. Yet recent work has found an increasing variety of adversarial\nsamplesthat can fool them. Most existing detection mechanisms against\nadversarial attacksimpose significant costs, either by using additional\nclassifiers to spot adversarial samples, or by requiring the DNN to be\nrestructured. In this paper, we introduce a novel defence. We train our DNN so\nthat, as long as it is workingas intended on the kind of inputs we expect, its\nbehavior is constrained, in that some set of behaviors are taboo. If it is\nexposed to adversarial samples, they will often cause a taboo behavior, which\nwe can detect. Taboos can be both subtle and diverse, so their choice can\nencode and hide information. It is a well-established design principle that the\nsecurity of a system should not depend on the obscurity of its design, but on\nsome variable (the key) which can differ between implementations and bechanged\nas necessary. We discuss how taboos can be used to equip a classifier with just\nsuch a key, and how to tune the keying mechanism to adversaries of various\ncapabilities. We evaluate the performance of a prototype against a wide range\nof attacks and show how our simple defense can defend against cheap attacks at\nscale with zero run-time computation overhead, making it a suitable defense\nmethod for IoT devices.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 18:43:43 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 16:29:55 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shumailov", "Ilia", ""], ["Zhao", "Yiren", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "1811.07426", "submitter": "Kyle Kastner", "authors": "Kyle Kastner, Rithesh Kumar, Tim Cooijmans, Aaron Courville", "title": "Harmonic Recomposition using Conditional Autoregressive Modeling", "comments": "3 pages, 2 figures. In Proceedings of The Joint Workshop on Machine\n  Learning for Music, ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate a conditional autoregressive pipeline for efficient music\nrecomposition, based on methods presented in van den Oord et al.(2017).\nRecomposition (Casal & Casey, 2010) focuses on reworking existing musical\npieces, adhering to structure at a high level while also re-imagining other\naspects of the work. This can involve reuse of pre-existing themes or parts of\nthe original piece, while also requiring the flexibility to generate new\ncontent at different levels of granularity. Applying the aforementioned\nmodeling pipeline to recomposition, we show diverse and structured generation\nconditioned on chord sequence annotations.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 23:40:53 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Kastner", "Kyle", ""], ["Kumar", "Rithesh", ""], ["Cooijmans", "Tim", ""], ["Courville", "Aaron", ""]]}, {"id": "1811.07428", "submitter": "Georgios Tsitsikas", "authors": "Georgios Tsitsikas, Evangelos E. Papalexakis", "title": "The core consistency of a compressed tensor", "comments": "5 pages, 4 figures, submitted to International Conference on\n  Acoustics, Speech, and Signal Processing ( IEEE ICASSP 2019 )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition on big data has attracted significant attention\nrecently. Among the most popular methods is a class of algorithms that\nleverages compression in order to reduce the size of the tensor and potentially\nparallelize computations. A fundamental requirement for such methods to work\nproperly is that the low-rank tensor structure is retained upon compression. In\nlieu of efficient and realistic means of computing and studying the effects of\ncompression on the low rank of a tensor, we study the effects of compression on\nthe core consistency; a widely used heuristic that has been used as a proxy for\nestimating that low rank. We provide theoretical analysis, where we identify\nsufficient conditions for the compression such that the core consistency is\npreserved, and we conduct extensive experiments that validate our analysis.\nFurther, we explore popular compression schemes and how they affect the core\nconsistency.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 23:56:47 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Tsitsikas", "Georgios", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1811.07429", "submitter": "Gabriel Peyr\\'e", "authors": "Gwendoline de Bie, Gabriel Peyr\\'e, Marco Cuturi", "title": "Stochastic Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is increasingly targeting areas where input data cannot be\naccurately described by a single vector, but can be modeled instead using the\nmore flexible concept of random vectors, namely probability measures or more\nsimply point clouds of varying cardinality. Using deep architectures on\nmeasures poses, however, many challenging issues. Indeed, deep architectures\nare originally designed to handle fixedlength vectors, or, using recursive\nmechanisms, ordered sequences thereof. In sharp contrast, measures describe a\nvarying number of weighted observations with no particular order. We propose in\nthis work a deep framework designed to handle crucial aspects of measures,\nnamely permutation invariances, variations in weights and cardinality.\nArchitectures derived from this pipeline can (i) map measures to measures -\nusing the concept of push-forward operators; (ii) bridge the gap between\nmeasures and Euclidean spaces - through integration steps. This allows to\ndesign discriminative networks (to classify or reduce the dimensionality of\ninput measures), generative architectures (to synthesize measures) and\nrecurrent pipelines (to predict measure dynamics). We provide a theoretical\nanalysis of these building blocks, review our architectures' approximation\nabilities and robustness w.r.t. perturbation, and try them on various\ndiscriminative and generative tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 00:11:06 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 09:25:41 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["de Bie", "Gwendoline", ""], ["Peyr\u00e9", "Gabriel", ""], ["Cuturi", "Marco", ""]]}, {"id": "1811.07455", "submitter": "Hu Ding", "authors": "Hu Ding and Mingquan Ye", "title": "On Geometric Alignment in Low Doubling Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world, many problems can be formulated as the alignment between two\ngeometric patterns. Previously, a great amount of research focus on the\nalignment of 2D or 3D patterns, especially in the field of computer vision.\nRecently, the alignment of geometric patterns in high dimension finds several\nnovel applications, and has attracted more and more attentions. However, the\nresearch is still rather limited in terms of algorithms. To the best of our\nknowledge, most existing approaches for high dimensional alignment are just\nsimple extensions of their counterparts for 2D and 3D cases, and often suffer\nfrom the issues such as high complexities. In this paper, we propose an\neffective framework to compress the high dimensional geometric patterns and\napproximately preserve the alignment quality. As a consequence, existing\nalignment approach can be applied to the compressed geometric patterns and thus\nthe time complexity is significantly reduced. Our idea is inspired by the\nobservation that high dimensional data often has a low intrinsic dimension. We\nadopt the widely used notion \"doubling dimension\" to measure the extents of our\ncompression and the resulting approximation. Finally, we test our method on\nboth random and real datasets, the experimental results reveal that running the\nalignment algorithm on compressed patterns can achieve similar qualities,\ncomparing with the results on the original patterns, but the running times\n(including the times cost for compression) are substantially lower.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 02:03:35 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Ding", "Hu", ""], ["Ye", "Mingquan", ""]]}, {"id": "1811.07457", "submitter": "Farzan Farnia", "authors": "Farzan Farnia, Jesse M. Zhang, David Tse", "title": "Generalizable Adversarial Training via Spectral Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have set benchmarks on a wide array of supervised\nlearning tasks. Trained DNNs, however, often lack robustness to minor\nadversarial perturbations to the input, which undermines their true\npracticality. Recent works have increased the robustness of DNNs by fitting\nnetworks using adversarially-perturbed training samples, but the improved\nperformance can still be far below the performance seen in non-adversarial\nsettings. A significant portion of this gap can be attributed to the decrease\nin generalization performance due to adversarial training. In this work, we\nextend the notion of margin loss to adversarial settings and bound the\ngeneralization error for DNNs trained under several well-known gradient-based\nattack schemes, motivating an effective regularization scheme based on spectral\nnormalization of the DNN's weight matrices. We also provide a\ncomputationally-efficient method for normalizing the spectral norm of\nconvolutional layers with arbitrary stride and padding schemes in deep\nconvolutional networks. We evaluate the power of spectral normalization\nextensively on combinations of datasets, network architectures, and adversarial\ntraining schemes. The code is available at\nhttps://github.com/jessemzhang/dl_spectral_normalization.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 02:06:09 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Farnia", "Farzan", ""], ["Zhang", "Jesse M.", ""], ["Tse", "David", ""]]}, {"id": "1811.07465", "submitter": "Haoran You", "authors": "Haoran You, Yu Cheng, Tianheng Cheng, Chunliang Li, Pan Zhou", "title": "Bayesian Cycle-Consistent Generative Adversarial Networks via\n  Marginalizing Latent Sampling", "comments": "Accepted by IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent techniques built on Generative Adversarial Networks (GANs), such as\nCycle-Consistent GANs, are able to learn mappings among different domains built\nfrom unpaired datasets, through min-max optimization games between generators\nand discriminators. However, it remains challenging to stabilize the training\nprocess and thus cyclic models fall into mode collapse accompanied by the\nsuccess of discriminator. To address this problem, we propose an novel Bayesian\ncyclic model and an integrated cyclic framework for inter-domain mappings. The\nproposed method motivated by Bayesian GAN explores the full posteriors of\ncyclic model via sampling latent variables and optimizes the model with maximum\na posteriori (MAP) estimation. Hence, we name it Bayesian CycleGAN. In\naddition, original CycleGAN cannot generate diversified results. But it is\nfeasible for Bayesian framework to diversify generated images by replacing\nrestricted latent variables in inference process. We evaluate the proposed\nBayesian CycleGAN on multiple benchmark datasets, including Cityscapes, Maps,\nand Monet2photo. The proposed method improve the per-pixel accuracy by 15% for\nthe Cityscapes semantic segmentation task within origin framework and improve\n20% within the proposed integrated framework, showing better resilience to\nimbalance confrontation. The diversified results of Monet2Photo style transfer\nalso demonstrate its superiority over original cyclic model. We provide codes\nfor all of our experiments in https://github.com/ranery/Bayesian-CycleGAN.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 02:22:49 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 06:34:52 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 19:38:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["You", "Haoran", ""], ["Cheng", "Yu", ""], ["Cheng", "Tianheng", ""], ["Li", "Chunliang", ""], ["Zhou", "Pan", ""]]}, {"id": "1811.07476", "submitter": "Anant Gupta", "authors": "Anant Gupta", "title": "Best Arm Identification in Linked Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of best arm identification in a variant of\nmulti-armed bandits called linked bandits. In a single interaction with linked\nbandits, multiple arms are played sequentially until one of them receives a\npositive reward. Since each interaction provides feedback about more than one\narm, the sample complexity can be much lower than in the regular bandit\nsetting. We propose an algorithm for linked bandits, that combines a novel\nsubroutine to perform uniform sampling with a known optimal algorithm for\nregular bandits. We prove almost matching upper and lower bounds on the sample\ncomplexity of best arm identification in linked bandits. These bounds have an\ninteresting structure, with an explicit dependence on the mean rewards of the\narms, not just the gaps. We also corroborate our theoretical results with\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 03:09:30 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 04:27:11 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Gupta", "Anant", ""]]}, {"id": "1811.07490", "submitter": "Yunbo Wang", "authors": "Yunbo Wang, Jianjin Zhang, Hongyu Zhu, Mingsheng Long, Jianmin Wang,\n  Philip S Yu", "title": "Memory In Memory: A Predictive Neural Network for Learning Higher-Order\n  Non-Stationarity from Spatiotemporal Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural spatiotemporal processes can be highly non-stationary in many ways,\ne.g. the low-level non-stationarity such as spatial correlations or temporal\ndependencies of local pixel values; and the high-level variations such as the\naccumulation, deformation or dissipation of radar echoes in precipitation\nforecasting. From Cramer's Decomposition, any non-stationary process can be\ndecomposed into deterministic, time-variant polynomials, plus a zero-mean\nstochastic term. By applying differencing operations appropriately, we may turn\ntime-variant polynomials into a constant, making the deterministic component\npredictable. However, most previous recurrent neural networks for\nspatiotemporal prediction do not use the differential signals effectively, and\ntheir relatively simple state transition functions prevent them from learning\ntoo complicated variations in spacetime. We propose the Memory In Memory (MIM)\nnetworks and corresponding recurrent blocks for this purpose. The MIM blocks\nexploit the differential signals between adjacent recurrent states to model the\nnon-stationary and approximately stationary properties in spatiotemporal\ndynamics with two cascaded, self-renewed memory modules. By stacking multiple\nMIM blocks, we could potentially handle higher-order non-stationarity. The MIM\nnetworks achieve the state-of-the-art results on four spatiotemporal prediction\ntasks across both synthetic and real-world datasets. We believe that the\ngeneral idea of this work can be potentially applied to other time-series\nforecasting tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 04:07:49 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 17:24:36 GMT"}, {"version": "v3", "created": "Sun, 21 Apr 2019 05:11:19 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Wang", "Yunbo", ""], ["Zhang", "Jianjin", ""], ["Zhu", "Hongyu", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Yu", "Philip S", ""]]}, {"id": "1811.07522", "submitter": "Xiao-Yang Liu", "authors": "Zhuoran Xiong, Xiao-Yang Liu, Shan Zhong, Hongyang Yang, and Anwar\n  Walid", "title": "Practical Deep Reinforcement Learning Approach for Stock Trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock trading strategy plays a crucial role in investment companies. However,\nit is challenging to obtain optimal strategy in the complex and dynamic stock\nmarket. We explore the potential of deep reinforcement learning to optimize\nstock trading strategy and thus maximize investment return. 30 stocks are\nselected as our trading stocks and their daily prices are used as the training\nand trading market environment. We train a deep reinforcement learning agent\nand obtain an adaptive trading strategy. The agent's performance is evaluated\nand compared with Dow Jones Industrial Average and the traditional min-variance\nportfolio allocation strategy. The proposed deep reinforcement learning\napproach is shown to outperform the two baselines in terms of both the Sharpe\nratio and cumulative returns.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:43:28 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 00:26:05 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xiong", "Zhuoran", ""], ["Liu", "Xiao-Yang", ""], ["Zhong", "Shan", ""], ["Yang", "Hongyang", ""], ["Walid", "Anwar", ""]]}, {"id": "1811.07533", "submitter": "Yuhang Liu", "authors": "Yuhang Liu, Wenyong Dong, Lei Zhang, Dong Gong and Qinfeng Shi", "title": "Variational Bayesian Dropout with a Hierarchical Prior", "comments": "Accepted by CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational dropout (VD) is a generalization of Gaussian dropout, which aims\nat inferring the posterior of network weights based on a log-uniform prior on\nthem to learn these weights as well as dropout rate simultaneously. The\nlog-uniform prior not only interprets the regularization capacity of Gaussian\ndropout in network training, but also underpins the inference of such\nposterior. However, the log-uniform prior is an improper prior (i.e., its\nintegral is infinite) which causes the inference of posterior to be ill-posed,\nthus restricting the regularization performance of VD. To address this problem,\nwe present a new generalization of Gaussian dropout, termed variational\nBayesian dropout (VBD), which turns to exploit a hierarchical prior on the\nnetwork weights and infer a new joint posterior. Specifically, we implement the\nhierarchical prior as a zero-mean Gaussian distribution with variance sampled\nfrom a uniform hyper-prior. Then, we incorporate such a prior into inferring\nthe joint posterior over network weights and the variance in the hierarchical\nprior, with which both the network training and the dropout rate estimation can\nbe cast into a joint optimization problem. More importantly, the hierarchical\nprior is a proper prior which enables the inference of posterior to be\nwell-posed. In addition, we further show that the proposed VBD can be\nseamlessly applied to network compression. Experiments on both classification\nand network compression tasks demonstrate the superior performance of the\nproposed VBD in terms of regularizing network training.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 07:31:46 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 00:11:31 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 07:48:12 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Liu", "Yuhang", ""], ["Dong", "Wenyong", ""], ["Zhang", "Lei", ""], ["Gong", "Dong", ""], ["Shi", "Qinfeng", ""]]}, {"id": "1811.07555", "submitter": "Yuxin Zhang", "authors": "Yuxin Zhang, Huan Wang, Yang Luo, Lu Yu, Haoji Hu, Hangguan Shan, Tony\n  Q. S. Quek", "title": "Three Dimensional Convolutional Neural Network Pruning with\n  Regularization-Based Method", "comments": "ICIP 2019", "journal-ref": "ICIP 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite enjoying extensive applications in video analysis, three-dimensional\nconvolutional neural networks (3D CNNs)are restricted by their massive\ncomputation and storage consumption. To solve this problem, we propose a\nthreedimensional regularization-based neural network pruning method to assign\ndifferent regularization parameters to different weight groups based on their\nimportance to the network. Further we analyze the redundancy and computation\ncost for each layer to determine the different pruning ratios. Experiments show\nthat pruning based on our method can lead to 2x theoretical speedup with only\n0.41% accuracy loss for 3DResNet18 and 3.28% accuracy loss for C3D. The\nproposed method performs favorably against other popular methods for model\ncompression and acceleration.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 08:40:00 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 03:48:09 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhang", "Yuxin", ""], ["Wang", "Huan", ""], ["Luo", "Yang", ""], ["Yu", "Lu", ""], ["Hu", "Haoji", ""], ["Shan", "Hangguan", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "1811.07557", "submitter": "Kristy Choi", "authors": "Kristy Choi, Kedar Tatwawadi, Aditya Grover, Tsachy Weissman, Stefano\n  Ermon", "title": "Neural Joint Source-Channel Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For reliable transmission across a noisy communication channel, classical\nresults from information theory show that it is asymptotically optimal to\nseparate out the source and channel coding processes. However, this\ndecomposition can fall short in the finite bit-length regime, as it requires\nnon-trivial tuning of hand-crafted codes and assumes infinite computational\npower for decoding. In this work, we propose to jointly learn the encoding and\ndecoding processes using a new discrete variational autoencoder model. By\nadding noise into the latent codes to simulate the channel during training, we\nlearn to both compress and error-correct given a fixed bit-length and\ncomputational budget. We obtain codes that are not only competitive against\nseveral separation schemes, but also learn useful robust representations of the\ndata for downstream tasks such as classification. Finally, inference\namortization yields an extremely fast neural decoder, almost an order of\nmagnitude faster compared to standard decoding methods based on iterative\nbelief propagation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 08:43:15 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 08:51:04 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 04:35:46 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Choi", "Kristy", ""], ["Tatwawadi", "Kedar", ""], ["Grover", "Aditya", ""], ["Weissman", "Tsachy", ""], ["Ermon", "Stefano", ""]]}, {"id": "1811.07579", "submitter": "Yonatan Geifman", "authors": "Yonatan Geifman, Ran El-Yaniv", "title": "Deep Active Learning with a Neural Architecture Search", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider active learning of deep neural networks. Most active learning\nworks in this context have focused on studying effective querying mechanisms\nand assumed that an appropriate network architecture is a priori known for the\nproblem at hand. We challenge this assumption and propose a novel active\nstrategy whereby the learning algorithm searches for effective architectures on\nthe fly, while actively learning. We apply our strategy using three known\nquerying techniques (softmax response, MC-dropout, and coresets) and show that\nthe proposed approach overwhelmingly outperforms active learning using fixed\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 09:45:20 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 11:05:25 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Geifman", "Yonatan", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1811.07591", "submitter": "Leonard Berrada", "authors": "Leonard Berrada, Andrew Zisserman, M. Pawan Kumar", "title": "Deep Frank-Wolfe For Neural Network Optimization", "comments": "Published as a conference paper at ICLR 2019, last version fixing an\n  inaccuracy (details in appendix A.5, Proposition 2)", "journal-ref": "International Conference on Learning Representations 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a deep neural network requires solving a challenging optimization\nproblem: it is a high-dimensional, non-convex and non-smooth minimization\nproblem with a large number of terms. The current practice in neural network\noptimization is to rely on the stochastic gradient descent (SGD) algorithm or\nits adaptive variants. However, SGD requires a hand-designed schedule for the\nlearning rate. In addition, its adaptive variants tend to produce solutions\nthat generalize less well on unseen data than SGD with a hand-designed\nschedule. We present an optimization method that offers empirically the best of\nboth worlds: our algorithm yields good generalization performance while\nrequiring only one hyper-parameter. Our approach is based on a composite\nproximal framework, which exploits the compositional nature of deep neural\nnetworks and can leverage powerful convex optimization algorithms by design.\nSpecifically, we employ the Frank-Wolfe (FW) algorithm for SVM, which computes\nan optimal step-size in closed-form at each time-step. We further show that the\ndescent direction is given by a simple backward pass in the network, yielding\nthe same computational cost per iteration as SGD. We present experiments on the\nCIFAR and SNLI data sets, where we demonstrate the significant superiority of\nour method over Adam, Adagrad, as well as the recently proposed BPGrad and\nAMSGrad. Furthermore, we compare our algorithm to SGD with a hand-designed\nlearning rate schedule, and show that it provides similar generalization while\nconverging faster. The code is publicly available at\nhttps://github.com/oval-group/dfw.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 10:23:27 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 10:52:26 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 18:08:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Berrada", "Leonard", ""], ["Zisserman", "Andrew", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1811.07605", "submitter": "Maciej Zamorski", "authors": "Maciej Zamorski, Maciej Zi\\k{e}ba, Piotr Klukowski, Rafa{\\l} Nowak,\n  Karol Kurach, Wojciech Stokowiec, Tomasz Trzci\\'nski", "title": "Adversarial Autoencoders for Compact Representations of 3D Point Clouds", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative architectures provide a way to model not only images but also\ncomplex, 3-dimensional objects, such as point clouds. In this work, we present\na novel method to obtain meaningful representations of 3D shapes that can be\nused for challenging tasks including 3D points generation, reconstruction,\ncompression, and clustering. Contrary to existing methods for 3D point cloud\ngeneration that train separate decoupled models for representation learning and\ngeneration, our approach is the first end-to-end solution that allows to\nsimultaneously learn a latent space of representation and generate 3D shape out\nof it. Moreover, our model is capable of learning meaningful compact binary\ndescriptors with adversarial training conducted on a latent space. To achieve\nthis goal, we extend a deep Adversarial Autoencoder model (AAE) to accept 3D\ninput and create 3D output. Thanks to our end-to-end training regime, the\nresulting method called 3D Adversarial Autoencoder (3dAAE) obtains either\nbinary or continuous latent space that covers a much wider portion of training\ndata distribution. Finally, our quantitative evaluation shows that 3dAAE\nprovides state-of-the-art results for 3D points clustering and 3D object\nretrieval.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 10:51:09 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 18:00:49 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 19:22:36 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Zamorski", "Maciej", ""], ["Zi\u0119ba", "Maciej", ""], ["Klukowski", "Piotr", ""], ["Nowak", "Rafa\u0142", ""], ["Kurach", "Karol", ""], ["Stokowiec", "Wojciech", ""], ["Trzci\u0144ski", "Tomasz", ""]]}, {"id": "1811.07615", "submitter": "Renato Cordeiro De Amorim", "authors": "Stiphen Chowdhury, Renato Cordeiro de Amorim", "title": "An efficient density-based clustering algorithm using reverse nearest\n  neighbour", "comments": "Accepted in: Computing Conference 2019 in London, UK.\n  http://saiconference.com/Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Density-based clustering is the task of discovering high-density regions of\nentities (clusters) that are separated from each other by contiguous regions of\nlow-density. DBSCAN is, arguably, the most popular density-based clustering\nalgorithm. However, its cluster recovery capabilities depend on the combination\nof the two parameters. In this paper we present a new density-based clustering\nalgorithm which uses reverse nearest neighbour (RNN) and has a single\nparameter. We also show that it is possible to estimate a good value for this\nparameter using a clustering validity index. The RNN queries enable our\nalgorithm to estimate densities taking more than a single entity into account,\nand to recover clusters that are not well-separated or have different\ndensities. Our experiments on synthetic and real-world data sets show our\nproposed algorithm outperforms DBSCAN and its recent variant ISDBSCAN.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 11:11:14 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Chowdhury", "Stiphen", ""], ["de Amorim", "Renato Cordeiro", ""]]}, {"id": "1811.07624", "submitter": "Cristian Rusu", "authors": "Cristian Rusu", "title": "Approximate Eigenvalue Decompositions of Linear Transformations with a\n  Few Householder Reflectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to decompose a signal in an orthonormal basis (a set of\northogonal components, each normalized to have unit length) using a fast\nnumerical procedure rests at the heart of many signal processing methods and\napplications. The classic examples are the Fourier and wavelet transforms that\nenjoy numerically efficient implementations (FFT and FWT, respectively).\nUnfortunately, orthonormal transformations are in general unstructured, and\ntherefore they do not enjoy low computational complexity properties. In this\npaper, based on Householder reflectors, we introduce a class of orthonormal\nmatrices that are numerically efficient to manipulate: we control the\ncomplexity of matrix-vector multiplications with these matrices using a given\nparameter. We provide numerical algorithms that approximate any orthonormal or\nsymmetric transform with a new orthonormal or symmetric structure made up of\nproducts of a given number of Householder reflectors. We show analyses and\nnumerical evidence to highlight the accuracy of the proposed approximations and\nprovide an application to the case of learning fast Mahanalobis distance metric\ntransformations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 11:34:16 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 12:19:05 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Rusu", "Cristian", ""]]}, {"id": "1811.07627", "submitter": "Samuel Murray", "authors": "Samuel Murray and Hedvig Kjellstr\\\"om", "title": "Mixed Likelihood Gaussian Process Latent Variable Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Mixed Likelihood Gaussian process latent variable model\n(GP-LVM), capable of modeling data with attributes of different types. The\nstandard formulation of GP-LVM assumes that each observation is drawn from a\nGaussian distribution, which makes the model unsuited for data with e.g.\ncategorical or nominal attributes. Our model, for which we use a sampling based\nvariational inference, instead assumes a separate likelihood for each observed\ndimension. This formulation results in more meaningful latent representations,\nand give better predictive performance for real world data with dimensions of\ndifferent types.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 11:39:17 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Murray", "Samuel", ""], ["Kjellstr\u00f6m", "Hedvig", ""]]}, {"id": "1811.07674", "submitter": "Wenfang Lin", "authors": "Wenfang Lin, Zhenyu Wu, Yang Ji", "title": "An Adaptive Oversampling Learning Method for Class-Imbalanced Fault\n  Diagnostics and Prognostics", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven fault diagnostics and prognostics suffers from class-imbalance\nproblem in industrial systems and it raises challenges to common machine\nlearning algorithms as it becomes difficult to learn the features of the\nminority class samples. Synthetic oversampling methods are commonly used to\ntackle these problems by generating the minority class samples to balance the\ndistributions between majority and minority classes. However, many of\noversampling methods are inappropriate that they cannot generate effective and\nuseful minority class samples according to different distributions of data,\nwhich further complicate the process of learning samples. Thus, this paper\nproposes a novel adaptive oversampling technique: EM-based Weighted Minority\nOversampling TEchnique (EWMOTE) for industrial fault diagnostics and\nprognostics. The methods comprises a weighted minority sampling strategy to\nidentify hard-to-learn informative minority fault samples and Expectation\nMaximization (EM) based imputation algorithm to generate fault samples. To\nvalidate the performance of the proposed methods, experiments are conducted in\ntwo real datasets. The results show that the method could achieve better\nperformance on not only binary class, but multi-class imbalance learning task\nin different imbalance ratios than other oversampling-based baseline models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 13:33:07 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Lin", "Wenfang", ""], ["Wu", "Zhenyu", ""], ["Ji", "Yang", ""]]}, {"id": "1811.07684", "submitter": "Alice Coucke", "authors": "Alice Coucke, Mohammed Chlieh, Thibault Gisselbrecht, David Leroy,\n  Mathieu Poumeyrol, Thibaut Lavril", "title": "Efficient keyword spotting using dilated convolutions and gating", "comments": "Accepted for publication to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the application of end-to-end stateless temporal modeling to\nsmall-footprint keyword spotting as opposed to recurrent networks that model\nlong-term temporal dependencies using internal states. We propose a model\ninspired by the recent success of dilated convolutions in sequence modeling\napplications, allowing to train deeper architectures in resource-constrained\nconfigurations. Gated activations and residual connections are also added,\nfollowing a similar configuration to WaveNet. In addition, we apply a custom\ntarget labeling that back-propagates loss from specific frames of interest,\ntherefore yielding higher accuracy and only requiring to detect the end of the\nkeyword. Our experimental results show that our model outperforms a max-pooling\nloss trained recurrent neural network using LSTM cells, with a significant\ndecrease in false rejection rate. The underlying dataset - \"Hey Snips\"\nutterances recorded by over 2.2K different speakers - has been made publicly\navailable to establish an open reference for wake-word detection.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 13:51:10 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 16:21:04 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Coucke", "Alice", ""], ["Chlieh", "Mohammed", ""], ["Gisselbrecht", "Thibault", ""], ["Leroy", "David", ""], ["Poumeyrol", "Mathieu", ""], ["Lavril", "Thibaut", ""]]}, {"id": "1811.07691", "submitter": "Zheng Lian", "authors": "Zheng Lian, Ya Li, Jianhua Tao, Jian Huang", "title": "Improving speech emotion recognition via Transformer-based Predictive\n  Coding through transfer learning", "comments": "I have submitted a new version to arXiv:1910.13806. I forget to\n  choose to replace the old version, but submitted a new one. It's my mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I have submitted a new version to arXiv:1910.13806. I forget to choose to\nreplace the old version, but submitted a new one. It's my mistake.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 15:39:13 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 01:15:22 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Lian", "Zheng", ""], ["Li", "Ya", ""], ["Tao", "Jianhua", ""], ["Huang", "Jian", ""]]}, {"id": "1811.07698", "submitter": "Irene Unceta", "authors": "Irene Unceta, Jordi Nin, Oriol Pujol", "title": "Towards Global Explanations for Credit Risk Scoring", "comments": "FEAP-AI4Fin 2018 : NIPS 2018 Worksop on Challenges and Opportunities\n  for AI in Financial Services: the Impact of Fairness, Explainability,\n  Accuracy, and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a method to obtain global explanations for trained\nblack-box classifiers by sampling their decision function to learn alternative\ninterpretable models. The envisaged approach provides a unified solution to\napproximate non-linear decision boundaries with simpler classifiers while\nretaining the original classification accuracy. We use a private residential\nmortgage default dataset as a use case to illustrate the feasibility of this\napproach to ensure the decomposability of attributes during pre-processing.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 14:12:59 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 08:06:40 GMT"}, {"version": "v3", "created": "Fri, 23 Nov 2018 08:24:02 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Unceta", "Irene", ""], ["Nin", "Jordi", ""], ["Pujol", "Oriol", ""]]}, {"id": "1811.07707", "submitter": "Jialin Song", "authors": "Jialin Song, Yury S. Tokpanov, Yuxin Chen, Dagny Fleischman, Kate T.\n  Fountaine, Harry A. Atwater, Yisong Yue", "title": "Optimizing Photonic Nanostructures via Multi-fidelity Gaussian Processes", "comments": "NIPS 2018 Workshop on Machine Learning for Molecules and Materials.\n  arXiv admin note: substantial text overlap with arXiv:1811.00755", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply numerical methods in combination with finite-difference-time-domain\n(FDTD) simulations to optimize transmission properties of plasmonic mirror\ncolor filters using a multi-objective figure of merit over a five-dimensional\nparameter space by utilizing novel multi-fidelity Gaussian processes approach.\nWe compare these results with conventional derivative-free global search\nalgorithms, such as (single-fidelity) Gaussian Processes optimization scheme,\nand Particle Swarm Optimization---a commonly used method in nanophotonics\ncommunity, which is implemented in Lumerical commercial photonics software. We\ndemonstrate the performance of various numerical optimization approaches on\nseveral pre-collected real-world datasets and show that by properly trading off\nexpensive information sources with cheap simulations, one can more effectively\noptimize the transmission properties with a fixed budget.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 22:26:55 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Song", "Jialin", ""], ["Tokpanov", "Yury S.", ""], ["Chen", "Yuxin", ""], ["Fleischman", "Dagny", ""], ["Fountaine", "Kate T.", ""], ["Atwater", "Harry A.", ""], ["Yue", "Yisong", ""]]}, {"id": "1811.07745", "submitter": "Ariel Keselman", "authors": "Ariel Keselman, Sergey Ten, Adham Ghazali, Majed Jubeh", "title": "Reinforcement Learning with A* and a Deep Heuristic", "comments": "6 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A* is a popular path-finding algorithm, but it can only be applied to those\ndomains where a good heuristic function is known. Inspired by recent methods\ncombining Deep Neural Networks (DNNs) and trees, this study demonstrates how to\ntrain a heuristic represented by a DNN and combine it with A*. This new\nalgorithm which we call aleph-star can be used efficiently in domains where the\ninput to the heuristic could be processed by a neural network. We compare\naleph-star to N-Step Deep Q-Learning (DQN Mnih et al. 2013) in a driving\nsimulation with pixel-based input, and demonstrate significantly better\nperformance in this scenario.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 15:15:18 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Keselman", "Ariel", ""], ["Ten", "Sergey", ""], ["Ghazali", "Adham", ""], ["Jubeh", "Majed", ""]]}, {"id": "1811.07746", "submitter": "Kiran Karra", "authors": "Kiran Karra, Samarth Swarup, Justus Graham", "title": "An Empirical Assessment of the Complexity and Realism of Synthetic\n  Social Contact Networks", "comments": "8 pages, 6 figures, accepted at GTA3 2018 in Conjunction with the\n  2018 IEEE Big Data Conference", "journal-ref": null, "doi": "10.1109/BigData.2018.8622199", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use multiple measures of graph complexity to evaluate the realism of\nsynthetically-generated networks of human activity, in comparison with several\nstylized network models as well as a collection of empirical networks from the\nliterature. The synthetic networks are generated by integrating data about\nhuman populations from several sources, including the Census, transportation\nsurveys, and geographical data. The resulting networks represent an\napproximation of daily or weekly human interaction. Our results indicate that\nthe synthetically generated graphs according to our methodology are closer to\nthe real world graphs, as measured across multiple structural measures, than a\nrange of stylized graphs generated using common network models from the\nliterature.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:48:44 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 21:37:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Karra", "Kiran", ""], ["Swarup", "Samarth", ""], ["Graham", "Justus", ""]]}, {"id": "1811.07747", "submitter": "Jinwei Zhao", "authors": "Jinwei Zhao, Qizhou Wang, Yufei Wang, Xinhong Hei, Yu Liu", "title": "How far from automatically interpreting deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning researchers have focused on how to find the\ninterpretability behind deep learning models. However, today cognitive\ncompetence of human has not completely covered the deep learning model. In\nother words, there is a gap between the deep learning model and the cognitive\nmode. How to evaluate and shrink the cognitive gap is a very important issue.\nIn this paper, the interpretability evaluation, the relationship between the\ngeneralization performance and the interpretability of the model and the method\nfor improving the interpretability are concerned. A universal learning\nframework is put forward to solve the equilibrium problem between the two\nperformances. The uniqueness of solution of the problem is proved and condition\nof unique solution is obtained. Probability upper bound of the sum of the two\nperformances is analyzed.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 15:25:02 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Zhao", "Jinwei", ""], ["Wang", "Qizhou", ""], ["Wang", "Yufei", ""], ["Hei", "Xinhong", ""], ["Liu", "Yu", ""]]}, {"id": "1811.07755", "submitter": "Ritchie Zhao", "authors": "Ritchie Zhao, Yuwei Hu, Jordan Dotzel, Christopher De Sa, Zhiru Zhang", "title": "Building Efficient Deep Neural Networks with Unitary Group Convolutions", "comments": "8 pages, 2 figures", "journal-ref": "Computer Vision and Pattern Recognition (CVPR) 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose unitary group convolutions (UGConvs), a building block for CNNs\nwhich compose a group convolution with unitary transforms in feature space to\nlearn a richer set of representations than group convolution alone. UGConvs\ngeneralize two disparate ideas in CNN architecture, channel shuffling (i.e.\nShuffleNet) and block-circulant networks (i.e. CirCNN), and provide unifying\ninsights that lead to a deeper understanding of each technique. We\nexperimentally demonstrate that dense unitary transforms can outperform channel\nshuffling in DNN accuracy. On the other hand, different dense transforms\nexhibit comparable accuracy performance. Based on these observations we propose\nHadaNet, a UGConv network using Hadamard transforms. HadaNets achieve similar\naccuracy to circulant networks with lower computation complexity, and better\naccuracy than ShuffleNets with the same number of parameters and floating-point\nmultiplies.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 15:48:12 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 06:28:33 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Zhao", "Ritchie", ""], ["Hu", "Yuwei", ""], ["Dotzel", "Jordan", ""], ["De Sa", "Christopher", ""], ["Zhang", "Zhiru", ""]]}, {"id": "1811.07763", "submitter": "Raphael F\\'eraud", "authors": "Rapha\\\"el F\\'eraud, R\\'eda Alami, Romain Laroche", "title": "Decentralized Exploration in Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the decentralized exploration problem: a set of players\ncollaborate to identify the best arm by asynchronously interacting with the\nsame stochastic environment. The objective is to insure privacy in the best arm\nidentification problem between asynchronous, collaborative, and thrifty\nplayers. In the context of a digital service, we advocate that this\ndecentralized approach allows a good balance between the interests of users and\nthose of service providers: the providers optimize their services, while\nprotecting the privacy of the users and saving resources. We define the privacy\nlevel as the amount of information an adversary could infer by intercepting the\nmessages concerning a single user. We provide a generic algorithm Decentralized\nElimination, which uses any best arm identification algorithm as a subroutine.\nWe prove that this algorithm insures privacy, with a low communication cost,\nand that in comparison to the lower bound of the best arm identification\nproblem, its sample complexity suffers from a penalty depending on the inverse\nof the probability of the most frequent players. Then, thanks to the genericity\nof the approach, we extend the proposed algorithm to the non-stationary\nbandits. Finally, experiments illustrate and complete the analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 15:56:27 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 14:31:53 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 09:11:24 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 08:52:10 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["F\u00e9raud", "Rapha\u00ebl", ""], ["Alami", "R\u00e9da", ""], ["Laroche", "Romain", ""]]}, {"id": "1811.07765", "submitter": "Aaron Roth", "authors": "Seth Neel, Aaron Roth, Zhiwei Steven Wu", "title": "How to Use Heuristics for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop theory for using heuristics to solve computationally hard problems\nin differential privacy. Heuristic approaches have enjoyed tremendous success\nin machine learning, for which performance can be empirically evaluated.\nHowever, privacy guarantees cannot be evaluated empirically, and must be proven\n--- without making heuristic assumptions. We show that learning problems over\nbroad classes of functions can be solved privately and efficiently, assuming\nthe existence of a non-private oracle for solving the same problem. Our first\nalgorithm yields a privacy guarantee that is contingent on the correctness of\nthe oracle. We then give a reduction which applies to a class of heuristics\nwhich we call certifiable, which allows us to convert oracle-dependent privacy\nguarantees to worst-case privacy guarantee that hold even when the heuristic\nstanding in for the oracle might fail in adversarial ways. Finally, we consider\na broad class of functions that includes most classes of simple boolean\nfunctions studied in the PAC learning literature, including conjunctions,\ndisjunctions, parities, and discrete halfspaces. We show that there is an\nefficient algorithm for privately constructing synthetic data for any such\nclass, given a non-private learning oracle. This in particular gives the first\noracle-efficient algorithm for privately generating synthetic data for\ncontingency tables. The most intriguing question left open by our work is\nwhether or not every problem that can be solved differentially privately can be\nprivately solved with an oracle-efficient algorithm. While we do not resolve\nthis, we give a barrier result that suggests that any generic oracle-efficient\nreduction must fall outside of a natural class of algorithms (which includes\nthe algorithms given in this paper).\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 15:57:08 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1811.07768", "submitter": "Edgard Chammas", "authors": "Edgard Chammas, Chafic Mokbel, Laurence Likforman-Sulem", "title": "Handwriting Recognition of Historical Documents with few labeled data", "comments": null, "journal-ref": null, "doi": "10.1109/DAS.2018.15", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historical documents present many challenges for offline handwriting\nrecognition systems, among them, the segmentation and labeling steps. Carefully\nannotated textlines are needed to train an HTR system. In some scenarios,\ntranscripts are only available at the paragraph level with no text-line\ninformation. In this work, we demonstrate how to train an HTR system with few\nlabeled data. Specifically, we train a deep convolutional recurrent neural\nnetwork (CRNN) system on only 10% of manually labeled text-line data from a\ndataset and propose an incremental training procedure that covers the rest of\nthe data. Performance is further increased by augmenting the training set with\nspecially crafted multiscale data. We also propose a model-based normalization\nscheme which considers the variability in the writing scale at the recognition\nphase. We apply this approach to the publicly available READ dataset. Our\nsystem achieved the second best result during the ICDAR2017 competition.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 23:21:12 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Chammas", "Edgard", ""], ["Mokbel", "Chafic", ""], ["Likforman-Sulem", "Laurence", ""]]}, {"id": "1811.07769", "submitter": "Ilke Demir", "authors": "Ilke Demir, Ramesh Raskar", "title": "Addressing the Invisible: Street Address Generation for Developing\n  Countries with Deep Learning", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than half of the world's roads lack adequate street addressing systems.\nLack of addresses is even more visible in daily lives of people in developing\ncountries. We would like to object to the assumption that having an address is\na luxury, by proposing a generative address design that maps the world in\naccordance with streets. The addressing scheme is designed considering several\ntraditional street addressing methodologies employed in the urban development\nscenarios around the world. Our algorithm applies deep learning to extract\nroads from satellite images, converts the road pixel confidences into a road\nnetwork, partitions the road network to find neighborhoods, and labels the\nregions, roads, and address units using graph- and proximity-based algorithms.\nWe present our results on a sample US city, and several developing cities,\ncompare travel times of users using current ad hoc and new complete addresses,\nand contrast our addressing solution to current industrial and open geocoding\nalternatives.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 07:34:04 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Demir", "Ilke", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1811.07770", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias and Stefanos Zafeiriou", "title": "Aff-Wild2: Extending the Aff-Wild Database for Affect Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic understanding of human affect using visual signals is a problem\nthat has attracted significant interest over the past 20 years. However, human\nemotional states are quite complex. To appraise such states displayed in\nreal-world settings, we need expressive emotional descriptors that are capable\nof capturing and describing this complexity. The circumplex model of affect,\nwhich is described in terms of valence (i.e., how positive or negative is an\nemotion) and arousal (i.e., power of the activation of the emotion), can be\nused for this purpose. Recent progress in the emotion recognition domain has\nbeen achieved through the development of deep neural architectures and the\navailability of very large training databases. To this end, Aff-Wild has been\nthe first large-scale \"in-the-wild\" database, containing around 1,200,000\nframes. In this paper, we build upon this database, extending it with 260 more\nsubjects and 1,413,000 new video frames. We call the union of Aff-Wild with the\nadditional data, Aff-Wild2. The videos are downloaded from Youtube and have\nlarge variations in pose, age, illumination conditions, ethnicity and\nprofession. Both database-specific as well as cross-database experiments are\nperformed in this paper, by utilizing the Aff-Wild2, along with the RECOLA\ndatabase. The developed deep neural architectures are based on the joint\ntraining of state-of-the-art convolutional and recurrent neural networks with\nattention mechanism; thus exploiting both the invariant properties of\nconvolutional features, while modeling temporal dynamics that arise in human\nbehaviour via the recurrent layers. The obtained results show premise for\nutilization of the extended Aff-Wild, as well as of the developed deep neural\narchitectures for visual analysis of human behaviour in terms of continuous\nemotion dimensions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 01:57:15 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:44:20 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1811.07771", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias and Stefanos Zafeiriou", "title": "A Multi-Task Learning & Generation Framework: Valence-Arousal, Action\n  Units & Primary Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years many research efforts have been devoted to the field\nof affect analysis. Various approaches have been proposed for: i) discrete\nemotion recognition in terms of the primary facial expressions; ii) emotion\nanalysis in terms of facial Action Units (AUs), assuming a fixed expression\nintensity; iii) dimensional emotion analysis, in terms of valence and arousal\n(VA). These approaches can only be effective, if they are developed using\nlarge, appropriately annotated databases, showing behaviors of people\nin-the-wild, i.e., in uncontrolled environments. Aff-Wild has been the first,\nlarge-scale, in-the-wild database (including around 1,200,000 frames of 300\nvideos), annotated in terms of VA. In the vast majority of existing emotion\ndatabases, their annotation is limited to either primary expressions, or\nvalence-arousal, or action units. In this paper, we first annotate a part\n(around $234,000$ frames) of the Aff-Wild database in terms of $8$ AUs and\nanother part (around $288,000$ frames) in terms of the $7$ basic emotion\ncategories, so that parts of this database are annotated in terms of VA, as\nwell as AUs, or primary expressions. Then, we set up and tackle multi-task\nlearning for emotion recognition, as well as for facial image generation.\nMulti-task learning is performed using: i) a deep neural network with shared\nhidden layers, which learns emotional attributes by exploiting their\ninter-dependencies; ii) a discriminator of a generative adversarial network\n(GAN). On the other hand, image generation is implemented through the generator\nof the GAN. For these two tasks, we carefully design loss functions that fit\nthe examined set-up. Experiments are presented which illustrate the good\nperformance of the proposed approach when applied to the new annotated parts of\nthe Aff-Wild database.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 15:40:23 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:39:14 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1811.07819", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Abhishek Gupta, Sergey Levine", "title": "Learning Actionable Representations with Goal-Conditioned Policies", "comments": "To be presented at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a central challenge across a range of machine\nlearning areas. In reinforcement learning, effective and functional\nrepresentations have the potential to tremendously accelerate learning progress\nand solve more challenging problems. Most prior work on representation learning\nhas focused on generative approaches, learning representations that capture all\nunderlying factors of variation in the observation space in a more disentangled\nor well-ordered manner. In this paper, we instead aim to learn functionally\nsalient representations: representations that are not necessarily complete in\nterms of capturing all factors of variation in the observation space, but\nrather aim to capture those factors of variation that are important for\ndecision making -- that are \"actionable.\" These representations are aware of\nthe dynamics of the environment, and capture only the elements of the\nobservation that are necessary for decision making rather than all factors of\nvariation, without explicit reconstruction of the observation. We show how\nthese representations can be useful to improve exploration for sparse reward\nproblems, to enable long horizon hierarchical reinforcement learning, and as a\nstate representation for learning policies for downstream tasks. We evaluate\nour method on a number of simulated environments, and compare it to prior\nmethods for representation learning, exploration, and hierarchical\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 17:30:36 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 06:44:13 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ghosh", "Dibya", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""]]}, {"id": "1811.07821", "submitter": "Yihong Wu", "authors": "Jian Ding, Zongming Ma, Yihong Wu, Jiaming Xu", "title": "Efficient random graph matching via degree profiles", "comments": "Proof of Theorem 4 expanded and revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random graph matching refers to recovering the underlying vertex\ncorrespondence between two random graphs with correlated edges; a prominent\nexample is when the two random graphs are given by Erd\\H{o}s-R\\'{e}nyi graphs\n$G(n,\\frac{d}{n})$. This can be viewed as an average-case and noisy version of\nthe graph isomorphism problem. Under this model, the maximum likelihood\nestimator is equivalent to solving the intractable quadratic assignment\nproblem. This work develops an $\\tilde{O}(n d^2+n^2)$-time algorithm which\nperfectly recovers the true vertex correspondence with high probability,\nprovided that the average degree is at least $d = \\Omega(\\log^2 n)$ and the two\ngraphs differ by at most $\\delta = O( \\log^{-2}(n) )$ fraction of edges. For\ndense graphs and sparse graphs, this can be improved to $\\delta = O(\n\\log^{-2/3}(n) )$ and $\\delta = O( \\log^{-2}(d) )$ respectively, both in\npolynomial time. The methodology is based on appropriately chosen distance\nstatistics of the degree profiles (empirical distribution of the degrees of\nneighbors). Before this work, the best known result achieves $\\delta=O(1)$ and\n$n^{o(1)} \\leq d \\leq n^c$ for some constant $c$ with an $n^{O(\\log n)}$-time\nalgorithm \\cite{barak2018nearly} and $\\delta=\\tilde O((d/n)^4)$ and $d =\n\\tilde{\\Omega}(n^{4/5})$ with a polynomial-time algorithm\n\\cite{dai2018performance}.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 17:33:48 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 18:55:50 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ding", "Jian", ""], ["Ma", "Zongming", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1811.07863", "submitter": "Manuel Gomez Rodriguez", "authors": "Khashayar Gatmiry and Manuel Gomez-Rodriguez", "title": "Non-submodular Function Maximization subject to a Matroid Constraint,\n  with Applications", "comments": "Added missing citations and changed strong submodularity ratio to\n  generalized curvature", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DM cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard greedy algorithm has been recently shown to enjoy approximation\nguarantees for constrained non-submodular nondecreasing set function\nmaximization. While these recent results allow to better characterize the\nempirical success of the greedy algorithm, they are only applicable to simple\ncardinality constraints. In this paper, we study the problem of maximizing a\nnon-submodular nondecreasing set function subject to a general matroid\nconstraint. We first show that the standard greedy algorithm offers an\napproximation factor of $\\frac{0.4 {\\gamma}^{2}}{\\sqrt{\\gamma r} + 1}$, where\n$\\gamma$ is the submodularity ratio of the function and $r$ is the rank of the\nmatroid. Then, we show that the same greedy algorithm offers a constant\napproximation factor of $(1 + 1/(1-\\alpha))^{-1}$, where $\\alpha$ is the\ngeneralized curvature of the function. In addition, we demonstrate that these\napproximation guarantees are applicable to several real-world applications in\nwhich the submodularity ratio and the generalized curvature can be bounded.\nFinally, we show that our greedy algorithm does achieve a competitive\nperformance in practice using a variety of experiments on synthetic and\nreal-world data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 18:31:21 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 22:23:02 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 10:09:26 GMT"}, {"version": "v4", "created": "Tue, 21 May 2019 06:27:47 GMT"}, {"version": "v5", "created": "Tue, 8 Oct 2019 15:57:22 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Gatmiry", "Khashayar", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1811.07871", "submitter": "Jan Leike", "authors": "Jan Leike and David Krueger and Tom Everitt and Miljan Martic and\n  Vishal Maini and Shane Legg", "title": "Scalable agent alignment via reward modeling: a research direction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One obstacle to applying reinforcement learning algorithms to real-world\nproblems is the lack of suitable reward functions. Designing such reward\nfunctions is difficult in part because the user only has an implicit\nunderstanding of the task objective. This gives rise to the agent alignment\nproblem: how do we create agents that behave in accordance with the user's\nintentions? We outline a high-level research direction to solve the agent\nalignment problem centered around reward modeling: learning a reward function\nfrom interaction with the user and optimizing the learned reward function with\nreinforcement learning. We discuss the key challenges we expect to face when\nscaling reward modeling to complex and general domains, concrete approaches to\nmitigate these challenges, and ways to establish trust in the resulting agents.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 18:48:04 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Leike", "Jan", ""], ["Krueger", "David", ""], ["Everitt", "Tom", ""], ["Martic", "Miljan", ""], ["Maini", "Vishal", ""], ["Legg", "Shane", ""]]}, {"id": "1811.07886", "submitter": "Hai Leong Chieu Dr.", "authors": "Jing Lim, Joshua Wong, Minn Xuan Wong, Lee Han Eric Tan, Hai Leong\n  Chieu, Davin Choo, Neng Kai Nigel Neo", "title": "Chemical Structure Elucidation from Mass Spectrometry by Matching\n  Substructures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical structure elucidation is a serious bottleneck in analytical\nchemistry today. We address the problem of identifying an unknown chemical\nthreat given its mass spectrum and its chemical formula, a task which might\ntake well trained chemists several days to complete. Given a chemical formula,\nthere could be over a million possible candidate structures. We take a data\ndriven approach to rank these structures by using neural networks to predict\nthe presence of substructures given the mass spectrum, and matching these\nsubstructures to the candidate structures. Empirically, we evaluate our\napproach on a data set of chemical agents built for unknown chemical threat\nidentification. We show that our substructure classifiers can attain over 90%\nmicro F1-score, and we can find the correct structure among the top 20\ncandidates in 88% and 71% of test cases for two compound classes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 16:24:31 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Lim", "Jing", ""], ["Wong", "Joshua", ""], ["Wong", "Minn Xuan", ""], ["Tan", "Lee Han Eric", ""], ["Chieu", "Hai Leong", ""], ["Choo", "Davin", ""], ["Neo", "Neng Kai Nigel", ""]]}, {"id": "1811.07896", "submitter": "Shishira Maiya", "authors": "Shishira R Maiya and Sudharshan Chandra Babu", "title": "Slum Segmentation and Change Detection : A Deep Learning Approach", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than one billion people live in slums around the world. In some\ndeveloping countries, slum residents make up for more than half of the\npopulation and lack reliable sanitation services, clean water, electricity,\nother basic services. Thus, slum rehabilitation and improvement is an important\nglobal challenge, and a significant amount of effort and resources have been\nput into this endeavor. These initiatives rely heavily on slum mapping and\nmonitoring, and it is essential to have robust and efficient methods for\nmapping and monitoring existing slum settlements. In this work, we introduce an\napproach to segment and map individual slums from satellite imagery, leveraging\nregional convolutional neural networks for instance segmentation using transfer\nlearning. In addition, we also introduce a method to perform change detection\nand monitor slum change over time. We show that our approach effectively learns\nslum shape and appearance, and demonstrates strong quantitative results,\nresulting in a maximum AP of 80.0.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 15:45:06 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Maiya", "Shishira R", ""], ["Babu", "Sudharshan Chandra", ""]]}, {"id": "1811.07901", "submitter": "Vivian Lai", "authors": "Vivian Lai, Chenhao Tan", "title": "On Human Predictions with Explanations and Predictions of Machine\n  Learning Models: A Case Study on Deception Detection", "comments": "17 pages, 19 figures, in Proceedings of ACM FAT* 2019, dataset & demo\n  available at https://deception.machineintheloop.com", "journal-ref": null, "doi": "10.1145/3287560.3287590", "report-no": null, "categories": "cs.AI cs.CL cs.CY physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are the final decision makers in critical tasks that involve ethical\nand legal concerns, ranging from recidivism prediction, to medical diagnosis,\nto fighting against fake news. Although machine learning models can sometimes\nachieve impressive performance in these tasks, these tasks are not amenable to\nfull automation. To realize the potential of machine learning for improving\nhuman decisions, it is important to understand how assistance from machine\nlearning models affects human performance and human agency.\n  In this paper, we use deception detection as a testbed and investigate how we\ncan harness explanations and predictions of machine learning models to improve\nhuman performance while retaining human agency. We propose a spectrum between\nfull human agency and full automation, and develop varying levels of machine\nassistance along the spectrum that gradually increase the influence of machine\npredictions. We find that without showing predicted labels, explanations alone\nslightly improve human performance in the end task. In comparison, human\nperformance is greatly improved by showing predicted labels (>20% relative\nimprovement) and can be further improved by explicitly suggesting strong\nmachine performance. Interestingly, when predicted labels are shown,\nexplanations of machine predictions induce a similar level of accuracy as an\nexplicit statement of strong machine performance. Our results demonstrate a\ntradeoff between human performance and human agency and show that explanations\nof machine predictions can moderate this tradeoff.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 19:00:01 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 20:47:12 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 03:52:47 GMT"}, {"version": "v4", "created": "Tue, 8 Jan 2019 21:15:07 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Lai", "Vivian", ""], ["Tan", "Chenhao", ""]]}, {"id": "1811.07939", "submitter": "Xiaokang Zhang", "authors": "Xiaokang Zhang, Inge Jonassen", "title": "EFSIS: Ensemble Feature Selection Integrating Stability", "comments": "20 pages, 3 figures", "journal-ref": "2019 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM), San Diego, CA, USA, 2019, pp. 2792-2798", "doi": "10.1109/BIBM47256.2019.8983310", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning that can be used to combine the predictions from multiple\nlearners has been widely applied in pattern recognition, and has been reported\nto be more robust and accurate than the individual learners. This ensemble\nlogic has recently also been more applied in feature selection. There are\nbasically two strategies for ensemble feature selection, namely data\nperturbation and function perturbation. Data perturbation performs feature\nselection on data subsets sampled from the original dataset and then selects\nthe features consistently ranked highly across those data subsets. This has\nbeen found to improve both the stability of the selector and the prediction\naccuracy for a classifier. Function perturbation frees the user from having to\ndecide on the most appropriate selector for any given situation and works by\naggregating multiple selectors. This has been found to maintain or improve\nclassification performance. Here we propose a framework, EFSIS, combining these\ntwo strategies. Empirical results indicate that EFSIS gives both high\nprediction accuracy and stability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 19:19:55 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhang", "Xiaokang", ""], ["Jonassen", "Inge", ""]]}, {"id": "1811.07957", "submitter": "Yuheng Bu", "authors": "Yuheng Bu, Jiaxun Lu and Venugopal V. Veeravalli", "title": "Model change detection with application to machine learning", "comments": "5 pages, ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model change detection is studied, in which there are two sets of samples\nthat are independently and identically distributed (i.i.d.) according to a\npre-change probabilistic model with parameter $\\theta$, and a post-change model\nwith parameter $\\theta'$, respectively. The goal is to detect whether the\nchange in the model is significant, i.e., whether the difference between the\npre-change parameter and the post-change parameter $\\|\\theta-\\theta'\\|_2$ is\nlarger than a pre-determined threshold $\\rho$. The problem is considered in a\nNeyman-Pearson setting, where the goal is to maximize the probability of\ndetection under a false alarm constraint. Since the generalized likelihood\nratio test (GLRT) is difficult to compute in this problem, we construct an\nempirical difference test (EDT), which approximates the GLRT and has low\ncomputational complexity. Moreover, we provide an approximation method to set\nthe threshold of the EDT to meet the false alarm constraint. Experiments with\nlinear regression and logistic regression are conducted to validate the\nproposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 20:06:18 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Bu", "Yuheng", ""], ["Lu", "Jiaxun", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1811.07971", "submitter": "Jingcheng Liu", "authors": "Jingcheng Liu and Kunal Talwar", "title": "Private Selection from Private Candidates", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially Private algorithms often need to select the best amongst many\ncandidate options. Classical works on this selection problem require that the\ncandidates' goodness, measured as a real-valued score function, does not change\nby much when one person's data changes. In many applications such as\nhyperparameter optimization, this stability assumption is much too strong. In\nthis work, we consider the selection problem under a much weaker stability\nassumption on the candidates, namely that the score functions are\ndifferentially private. Under this assumption, we present algorithms that are\nnear-optimal along the three relevant dimensions: privacy, utility and\ncomputational efficiency.\n  Our result can be seen as a generalization of the exponential mechanism and\nits existing generalizations. We also develop an online version of our\nalgorithm, that can be seen as a generalization of the sparse vector technique\nto this weaker stability assumption. We show how our results imply better\nalgorithms for hyperparameter selection in differentially private machine\nlearning, as well as for adaptive data analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 20:48:42 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Liu", "Jingcheng", ""], ["Talwar", "Kunal", ""]]}, {"id": "1811.07985", "submitter": "Krit Pongpirul", "authors": "Seelwan Sathitratanacheewin (1 and 2) and Krit Pongpirul (1, 2, and 3)\n  ((1) Department of Preventive and Social Medicine, Faculty of Medicine,\n  Chulalongkorn University, Bangkok, Thailand, (2) Thai Health AI Foundation,\n  Bangkok, Thailand, (3) Department of International Health and Department of\n  Health, Behavior, and Society, Johns Hopkins Bloomberg School of Public\n  Health, Baltimore, MD, USA)", "title": "Deep Learning for Automated Classification of Tuberculosis-Related Chest\n  X-Ray: Dataset Specificity Limits Diagnostic Performance Generalizability", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Machine learning has been an emerging tool for various aspects of infectious\ndiseases including tuberculosis surveillance and detection. However, WHO\nprovided no recommendations on using computer-aided tuberculosis detection\nsoftware because of the small number of studies, methodological limitations,\nand limited generalizability of the findings. To quantify the generalizability\nof the machine-learning model, we developed a Deep Convolutional Neural Network\n(DCNN) model using a TB-specific CXR dataset of one population (National\nLibrary of Medicine Shenzhen No.3 Hospital) and tested it with non-TB-specific\nCXR dataset of another population (National Institute of Health Clinical\nCenters). The findings suggested that a supervised deep learning model\ndeveloped by using the training dataset from one population may not have the\nsame diagnostic performance in another population. Technical specification of\nCXR images, disease severity distribution, overfitting, and overdiagnosis\nshould be examined before implementation in other settings.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 16:32:42 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 08:44:47 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sathitratanacheewin", "Seelwan", "", "1 and 2"], ["Pongpirul", "Krit", "", "1, 2, and 3"]]}, {"id": "1811.07988", "submitter": "Zhanli Chen", "authors": "Zhanli Chen, Rashid Ansari, Diana Wilkie", "title": "Automated Pain Detection from Facial Expressions using FACS: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial pain expression is an important modality for assessing pain,\nespecially when the patient's verbal ability to communicate is impaired. The\nfacial muscle-based action units (AUs), which are defined by the Facial Action\nCoding System (FACS), have been widely studied and are highly reliable as a\nmethod for detecting facial expressions (FE) including valid detection of pain.\nUnfortunately, FACS coding by humans is a very time-consuming task that makes\nits clinical use prohibitive. Significant progress on automated facial\nexpression recognition (AFER) has led to its numerous successful applications\nin FACS-based affective computing problems. However, only a handful of studies\nhave been reported on automated pain detection (APD), and its application in\nclinical settings is still far from a reality. In this paper, we review the\nprogress in research that has contributed to automated pain detection, with\nfocus on 1) the framework-level similarity between spontaneous AFER and APD\nproblems; 2) the evolution of system design including the recent development of\ndeep learning methods; 3) the strategies and considerations in developing a\nFACS-based pain detection framework from existing research; and 4) introduction\nof the most relevant databases that are available for AFER and APD studies. We\nattempt to present key considerations in extending a general AFER framework to\nan APD framework in clinical settings. In addition, the performance metrics are\nalso highlighted in evaluating an AFER or an APD system.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 22:59:24 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Chen", "Zhanli", ""], ["Ansari", "Rashid", ""], ["Wilkie", "Diana", ""]]}, {"id": "1811.07996", "submitter": "Abon Chaudhuri", "authors": "Abon Chaudhuri, Paolo Messina, Samrat Kokkula, Aditya Subramanian,\n  Abhinandan Krishnan, Shreyansh Gandhi, Alessandro Magnani, Venkatesh\n  Kandaswamy", "title": "A Smart System for Selection of Optimal Product Images in E-Commerce", "comments": "Accepted in IEEE Big Data Conference 2018 (Industry & Government\n  Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce, content quality of the product catalog plays a key role in\ndelivering a satisfactory experience to the customers. In particular, visual\ncontent such as product images influences customers' engagement and purchase\ndecisions. With the rapid growth of e-commerce and the advent of artificial\nintelligence, traditional content management systems are giving way to\nautomated scalable systems. In this paper, we present a machine learning driven\nvisual content management system for extremely large e-commerce catalogs. For a\ngiven product, the system aggregates images from various suppliers, understands\nand analyzes them to produce a superior image set with optimal image count and\nquality, and arranges them in an order tailored to the demands of the\ncustomers. The system makes use of an array of technologies, ranging from deep\nlearning to traditional computer vision, at different stages of analysis. In\nthis paper, we outline how the system works and discuss the unique challenges\nrelated to applying machine learning techniques to real-world data from\ne-commerce domain. We emphasize how we tune state-of-the-art image\nclassification techniques to develop solutions custom made for a massive,\ndiverse, and constantly evolving product catalog. We also provide the details\nof how we measure the system's impact on various customer engagement metrics.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 02:35:48 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Chaudhuri", "Abon", ""], ["Messina", "Paolo", ""], ["Kokkula", "Samrat", ""], ["Subramanian", "Aditya", ""], ["Krishnan", "Abhinandan", ""], ["Gandhi", "Shreyansh", ""], ["Magnani", "Alessandro", ""], ["Kandaswamy", "Venkatesh", ""]]}, {"id": "1811.07998", "submitter": "Hamed Alemohammad", "authors": "Yoni Nachmany, Hamed Alemohammad", "title": "Generating a Training Dataset for Land Cover Classification to Advance\n  Global Development", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic segmentation of land cover classes is fundamental for agricultural\nand economic development work, from sustainable forestry to urban planning, yet\nexisting training datasets have significant limitations. To generate an open\nand comprehensive training library of high resolution Earth imagery and high\nquality land cover classifications, public Sentinel-2 data at 10 m spatial\nresolution was matched with accurate GlobeLand30 labels from 2010, which were\nfiltered by agreement with an intermediary Sentinel-2 classification at 20 m\nproduced during atmospheric correction. Scene-level classifications were\npredicted by Random Forests trained on valid reflectance data and the filtered\nlabels, and achieved over 80% model accuracy for a variety of locations.\nFurther work is required to aggregate individual scene classifications for\nannual labels and to test the approach in more locations, before crowdsourcing\nhuman validation. The goal is to create a sustained community-wide effort to\ngenerate image labels not only for land cover, but also very specific images\nfor major agriculture crops across the world and other thematic categories of\ninterest to the global development community.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 17:50:46 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Nachmany", "Yoni", ""], ["Alemohammad", "Hamed", ""]]}, {"id": "1811.07999", "submitter": "Steven Kommrusch", "authors": "Steve Kommrusch and Louis-No\\\"el Pouchet", "title": "Synthetic Lung Nodule 3D Image Generation Using Autoencoders", "comments": "19 pages, 12 figures, full paper for work initially presented at\n  IJCAI 2018", "journal-ref": null, "doi": null, "report-no": "CS-18-101", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges of using machine learning techniques with medical data\nis the frequent dearth of source image data on which to train. A representative\nexample is automated lung cancer diagnosis, where nodule images need to be\nclassified as suspicious or benign. In this work we propose an automatic\nsynthetic lung nodule image generator. Our 3D shape generator is designed to\naugment the variety of 3D images. Our proposed system takes root in autoencoder\ntechniques, and we provide extensive experimental characterization that\ndemonstrates its ability to produce quality synthetic images.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 21:51:38 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 05:58:20 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 05:58:21 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Kommrusch", "Steve", ""], ["Pouchet", "Louis-No\u00ebl", ""]]}, {"id": "1811.08010", "submitter": "Hongyang Zhang", "authors": "Hongyang Zhang and Susu Xu and Jiantao Jiao and Pengtao Xie and Ruslan\n  Salakhutdinov and Eric P. Xing", "title": "Stackelberg GAN: Towards Provable Minimax Equilibrium via\n  Multi-Generator Architectures", "comments": "27 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of alleviating the instability issue in the GAN training\nprocedure via new architecture design. The discrepancy between the minimax and\nmaximin objective values could serve as a proxy for the difficulties that the\nalternating gradient descent encounters in the optimization of GANs. In this\nwork, we give new results on the benefits of multi-generator architecture of\nGANs. We show that the minimax gap shrinks to $\\epsilon$ as the number of\ngenerators increases with rate $\\widetilde{O}(1/\\epsilon)$. This improves over\nthe best-known result of $\\widetilde{O}(1/\\epsilon^2)$. At the core of our\ntechniques is a novel application of Shapley-Folkman lemma to the generic\nminimax problem, where in the literature the technique was only known to work\nwhen the objective function is restricted to the Lagrangian function of a\nconstraint optimization problem. Our proposed Stackelberg GAN performs well\nexperimentally in both synthetic and real-world datasets, improving Fr\\'echet\nInception Distance by $14.61\\%$ over the previous multi-generator GANs on the\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 22:38:36 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Zhang", "Hongyang", ""], ["Xu", "Susu", ""], ["Jiao", "Jiantao", ""], ["Xie", "Pengtao", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1811.08035", "submitter": "Kahkashan Afrin", "authors": "Kahkashan Afrin, Parikshit Verma, Sanjay S. Srivatsa, and Satish T.S.\n  Bukkapatnam", "title": "Simultaneous 12-Lead Electrocardiogram Synthesis using a Single-Lead ECG\n  Signal: Application to Handheld ECG Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent introduction of wearable single-lead ECG devices of diverse\nconfigurations has caught the intrigue of the medical community. While these\ndevices provide a highly affordable support tool for the caregivers for\ncontinuous monitoring and to detect acute conditions, such as arrhythmia, their\nutility for cardiac diagnostics remains limited. This is because clinical\ndiagnosis of many cardiac pathologies is rooted in gleaning patterns from\nsynchronous 12-lead ECG. If synchronous 12-lead signals of clinical quality can\nbe synthesized from these single-lead devices, it can transform cardiac care by\nsubstantially reducing the costs and enhancing access to cardiac diagnostics.\nHowever, prior attempts to synthesize synchronous 12-lead ECG have not been\nsuccessful. Vectorcardiography (VCG) analysis suggests that cardiac axis\nsynthesized from earlier attempts deviates significantly from that estimated\nfrom 12-lead and/or Frank lead measurements. This work is perhaps the first\nsuccessful attempt to synthesize clinically equivalent synchronous 12-lead ECG\nfrom single-lead ECG. Our method employs a random forest machine learning model\nthat uses a subject's historical 12-lead recordings to estimate the morphology\nincluding the actual timing of various ECG events (relative to the measured\nsingle-lead ECG) for all 11 missing leads of the subject. Our method was\nvalidated on two benchmark datasets as well as paper ECG and AliveCor-Kardia\ndata obtained from the Heart, Artery, and Vein Center of Fresno, California.\nResults suggest that this approach can synthesize synchronous ECG with\naccuracies (R2) exceeding 90%. Accurate synthesis of 12-lead ECG from a\nsingle-lead device can ultimately enable its wider application and improved\npoint-of-care (POC) diagnostics.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 00:29:34 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Afrin", "Kahkashan", ""], ["Verma", "Parikshit", ""], ["Srivatsa", "Sanjay S.", ""], ["Bukkapatnam", "Satish T. S.", ""]]}, {"id": "1811.08039", "submitter": "Armin Askari", "authors": "Fangda Gu, Armin Askari, Laurent El Ghaoui", "title": "Fenchel Lifted Networks: A Lagrange Relaxation of Neural Network\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent successes of deep neural networks, the corresponding\ntraining problem remains highly non-convex and difficult to optimize. Classes\nof models have been proposed that introduce greater structure to the objective\nfunction at the cost of lifting the dimension of the problem. However, these\nlifted methods sometimes perform poorly compared to traditional neural\nnetworks. In this paper, we introduce a new class of lifted models, Fenchel\nlifted networks, that enjoy the same benefits as previous lifted models,\nwithout suffering a degradation in performance over classical networks. Our\nmodel represents activation functions as equivalent biconvex constraints and\nuses Lagrange Multipliers to arrive at a rigorous lower bound of the\ntraditional neural network training problem. This model is efficiently trained\nusing block-coordinate descent and is parallelizable across data points and/or\nlayers. We compare our model against standard fully connected and convolutional\nnetworks and show that we are able to match or beat their performance.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 00:58:17 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 01:23:18 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 07:06:04 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Gu", "Fangda", ""], ["Askari", "Armin", ""], ["Ghaoui", "Laurent El", ""]]}, {"id": "1811.08045", "submitter": "John Thickstun", "authors": "John Thickstun, Zaid Harchaoui, Dean P. Foster, Sham M. Kakade", "title": "Coupled Recurrent Models for Polyphonic Music Composition", "comments": "13 pages; long version of the paper appearing in ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel recurrent model for music composition that is\ntailored to the structure of polyphonic music. We propose an efficient new\nconditional probabilistic factorization of musical scores, viewing a score as a\ncollection of concurrent, coupled sequences: i.e. voices. To model the\nconditional distributions, we borrow ideas from both convolutional and\nrecurrent neural models; we argue that these ideas are natural for capturing\nmusic's pitch invariances, temporal structure, and polyphony. We train models\nfor single-voice and multi-voice composition on 2,300 scores from the\nKernScores dataset.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 02:45:44 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 21:55:06 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Thickstun", "John", ""], ["Harchaoui", "Zaid", ""], ["Foster", "Dean P.", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1811.08052", "submitter": "Changyou Chen", "authors": "Jianyi Zhang, Yang Zhao, Changyou Chen", "title": "Variance Reduction in Stochastic Particle-Optimization Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic particle-optimization sampling (SPOS) is a recently-developed\nscalable Bayesian sampling framework that unifies stochastic gradient MCMC\n(SG-MCMC) and Stein variational gradient descent (SVGD) algorithms based on\nWasserstein gradient flows. With a rigorous non-asymptotic convergence theory\ndeveloped recently, SPOS avoids the particle-collapsing pitfall of SVGD.\nNevertheless, variance reduction in SPOS has never been studied. In this paper,\nwe bridge the gap by presenting several variance-reduction techniques for SPOS.\nSpecifically, we propose three variants of variance-reduced SPOS, called SAGA\nparticle-optimization sampling (SAGA-POS), SVRG particle-optimization sampling\n(SVRG-POS) and a variant of SVRG-POS which avoids full gradient computations,\ndenoted as SVRG-POS$^+$. Importantly, we provide non-asymptotic convergence\nguarantees for these algorithms in terms of 2-Wasserstein metric and analyze\ntheir complexities. Remarkably, the results show our algorithms yield better\nconvergence rates than existing variance-reduced variants of stochastic\nLangevin dynamics, even though more space is required to store the particles in\ntraining. Our theory well aligns with experimental results on both synthetic\nand real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 03:25:19 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Zhang", "Jianyi", ""], ["Zhao", "Yang", ""], ["Chen", "Changyou", ""]]}, {"id": "1811.08055", "submitter": "Chuxu Zhang", "authors": "Chuxu Zhang, Dongjin Song, Yuncong Chen, Xinyang Feng, Cristian\n  Lumezanu, Wei Cheng, Jingchao Ni, Bo Zong, Haifeng Chen, Nitesh V. Chawla", "title": "A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis\n  in Multivariate Time Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, multivariate time series data are increasingly collected in various\nreal world systems, e.g., power plants, wearable devices, etc. Anomaly\ndetection and diagnosis in multivariate time series refer to identifying\nabnormal status in certain time steps and pinpointing the root causes. Building\nsuch a system, however, is challenging since it not only requires to capture\nthe temporal dependency in each time series, but also need encode the\ninter-correlations between different pairs of time series. In addition, the\nsystem should be robust to noise and provide operators with different levels of\nanomaly scores based upon the severity of different incidents. Despite the fact\nthat a number of unsupervised anomaly detection algorithms have been developed,\nfew of them can jointly address these challenges. In this paper, we propose a\nMulti-Scale Convolutional Recurrent Encoder-Decoder (MSCRED), to perform\nanomaly detection and diagnosis in multivariate time series data. Specifically,\nMSCRED first constructs multi-scale (resolution) signature matrices to\ncharacterize multiple levels of the system statuses in different time steps.\nSubsequently, given the signature matrices, a convolutional encoder is employed\nto encode the inter-sensor (time series) correlations and an attention based\nConvolutional Long-Short Term Memory (ConvLSTM) network is developed to capture\nthe temporal patterns. Finally, based upon the feature maps which encode the\ninter-sensor correlations and temporal information, a convolutional decoder is\nused to reconstruct the input signature matrices and the residual signature\nmatrices are further utilized to detect and diagnose anomalies. Extensive\nempirical studies based on a synthetic dataset and a real power plant dataset\ndemonstrate that MSCRED can outperform state-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 03:36:45 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Zhang", "Chuxu", ""], ["Song", "Dongjin", ""], ["Chen", "Yuncong", ""], ["Feng", "Xinyang", ""], ["Lumezanu", "Cristian", ""], ["Cheng", "Wei", ""], ["Ni", "Jingchao", ""], ["Zong", "Bo", ""], ["Chen", "Haifeng", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "1811.08056", "submitter": "Dae Hoon Park", "authors": "Dae Hoon Park, Chiu Man Ho, Yi Chang, Huaqing Zhang", "title": "Gradient-Coherent Strong Regularization for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization plays an important role in generalization of deep neural\nnetworks, which are often prone to overfitting with their numerous parameters.\nL1 and L2 regularizers are common regularization tools in machine learning with\ntheir simplicity and effectiveness. However, we observe that imposing strong L1\nor L2 regularization with stochastic gradient descent on deep neural networks\neasily fails, which limits the generalization ability of the underlying neural\nnetworks. To understand this phenomenon, we first investigate how and why\nlearning fails when strong regularization is imposed on deep neural networks.\nWe then propose a novel method, gradient-coherent strong regularization, which\nimposes regularization only when the gradients are kept coherent in the\npresence of strong regularization. Experiments are performed with multiple deep\narchitectures on three benchmark data sets for image recognition. Experimental\nresults show that our proposed approach indeed endures strong regularization\nand significantly improves both accuracy and compression (up to 9.9x), which\ncould not be achieved otherwise.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 03:41:56 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 01:52:12 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Park", "Dae Hoon", ""], ["Ho", "Chiu Man", ""], ["Chang", "Yi", ""], ["Zhang", "Huaqing", ""]]}, {"id": "1811.08069", "submitter": "Ka-Ho Chow", "authors": "Ka-Ho Chow, Anish Hiranandani, Yifeng Zhang, S.-H. Gary Chan", "title": "Representation Learning of Pedestrian Trajectories Using Actor-Critic\n  Sequence-to-Sequence Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning of pedestrian trajectories transforms variable-length\ntimestamp-coordinate tuples of a trajectory into a fixed-length vector\nrepresentation that summarizes spatiotemporal characteristics. It is a crucial\ntechnique to connect feature-based data mining with trajectory data. Trajectory\nrepresentation is a challenging problem, because both environmental constraints\n(e.g., wall partitions) and temporal user dynamics should be meticulously\nconsidered and accounted for. Furthermore, traditional sequence-to-sequence\nautoencoders using maximum log-likelihood often require dataset covering all\nthe possible spatiotemporal characteristics to perform well. This is infeasible\nor impractical in reality. We propose TREP, a practical pedestrian trajectory\nrepresentation learning algorithm which captures the environmental constraints\nand the pedestrian dynamics without the need of any training dataset. By\nformulating a sequence-to-sequence autoencoder with a spatial-aware objective\nfunction under the paradigm of actor-critic reinforcement learning, TREP\nintelligently encodes spatiotemporal characteristics of trajectories with the\ncapability of handling diverse trajectory patterns. Extensive experiments on\nboth synthetic and real datasets validate the high fidelity of TREP to\nrepresent trajectories.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 04:28:29 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Chow", "Ka-Ho", ""], ["Hiranandani", "Anish", ""], ["Zhang", "Yifeng", ""], ["Chan", "S. -H. Gary", ""]]}, {"id": "1811.08080", "submitter": "Kazuya Kakizaki", "authors": "Hajime Ono, Tsubasa Takahashi, Kazuya Kakizaki", "title": "Lightweight Lipschitz Margin Training for Certified Defense against\n  Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we make machine learning provably robust against adversarial examples\nin a scalable way? Since certified defense methods, which ensure\n$\\epsilon$-robust, consume huge resources, they can only achieve small degree\nof robustness in practice. Lipschitz margin training (LMT) is a scalable\ncertified defense, but it can also only achieve small robustness due to\nover-regularization. How can we make certified defense more efficiently? We\npresent LC-LMT, a light weight Lipschitz margin training which solves the above\nproblem. Our method has the following properties; (a) efficient: it can achieve\n$\\epsilon$-robustness at early epoch, and (b) robust: it has a potential to get\nhigher robustness than LMT. In the evaluation, we demonstrate the benefits of\nthe proposed method. LC-LMT can achieve required robustness more than 30 epoch\nearlier than LMT in MNIST, and shows more than 90 $\\%$ accuracy against both\nlegitimate and adversarial inputs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 05:22:55 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Ono", "Hajime", ""], ["Takahashi", "Tsubasa", ""], ["Kakizaki", "Kazuya", ""]]}, {"id": "1811.08081", "submitter": "Yuchen Li", "authors": "Safwan Hossain, Kiarash Jamali, Yuchen Li, Frank Rudzicz", "title": "ChainGAN: A sequential approach to GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new architecture and training methodology for generative\nadversarial networks. Current approaches attempt to learn the transformation\nfrom a noise sample to a generated data sample in one shot. Our proposed\ngenerator architecture, called $\\textit{ChainGAN}$, uses a two-step process. It\nfirst attempts to transform a noise vector into a crude sample, similar to a\ntraditional generator. Next, a chain of networks, called $\\textit{editors}$,\nattempt to sequentially enhance this sample. We train each of these units\nindependently, instead of with end-to-end backpropagation on the entire chain.\nOur model is robust, efficient, and flexible as we can apply it to various\nnetwork architectures. We provide rationale for our choices and experimentally\nevaluate our model, achieving competitive results on several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 05:30:32 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 18:56:15 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Hossain", "Safwan", ""], ["Jamali", "Kiarash", ""], ["Li", "Yuchen", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1811.08084", "submitter": "Daiki Suehiro", "authors": "Daiki Suehiro, Kohei Hatano, Eiji Takimoto, Shuji Yamamoto, Kenichi\n  Bannai, Akiko Takeda", "title": "Multiple-Instance Learning by Boosting Infinitely Many Shapelet-based\n  Classifiers", "comments": "The preliminary version of this paper is arXiv:1709.01300. which only\n  focuses on shapelet-based time-series classification but not\n  Muptiple-Instance Learning. Note that the preliminary version has not been\n  published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new formulation of Multiple-Instance Learning (MIL). In typical\nMIL settings, a unit of data is given as a set of instances called a bag and\nthe goal is to find a good classifier of bags based on similarity from a single\nor finitely many \"shapelets\" (or patterns), where the similarity of the bag\nfrom a shapelet is the maximum similarity of instances in the bag. Classifiers\nbased on a single shapelet are not sufficiently strong for certain\napplications. Additionally, previous work with multiple shapelets has\nheuristically chosen some of the instances as shapelets with no theoretical\nguarantee of its generalization ability. Our formulation provides a richer\nclass of the final classifiers based on infinitely many shapelets. We provide\nan efficient algorithm for the new formulation, in addition to generalization\nbound. Our empirical study demonstrates that our approach is effective not only\nfor MIL tasks but also for Shapelet Learning for time-series classification.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 05:51:22 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 04:55:51 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Suehiro", "Daiki", ""], ["Hatano", "Kohei", ""], ["Takimoto", "Eiji", ""], ["Yamamoto", "Shuji", ""], ["Bannai", "Kenichi", ""], ["Takeda", "Akiko", ""]]}, {"id": "1811.08102", "submitter": "Nora Speicher", "authors": "Nora K. Speicher and Nico Pfeifer", "title": "An interpretable multiple kernel learning approach for the discovery of\n  integrative cancer subtypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the complexity of cancer, clustering algorithms have been used to\ndisentangle the observed heterogeneity and identify cancer subtypes that can be\ntreated specifically. While kernel based clustering approaches allow the use of\nmore than one input matrix, which is an important factor when considering a\nmultidimensional disease like cancer, the clustering results remain hard to\nevaluate and, in many cases, it is unclear which piece of information had which\nimpact on the final result. In this paper, we propose an extension of multiple\nkernel learning clustering that enables the characterization of each identified\npatient cluster based on the features that had the highest impact on the\nresult. To this end, we combine feature clustering with multiple kernel\ndimensionality reduction and introduce FIPPA, a score which measures the\nfeature cluster impact on a patient cluster. Results: We applied the approach\nto different cancer types described by four different data types with the aim\nof identifying integrative patient subtypes and understanding which features\nwere most important for their identification. Our results show that our method\ndoes not only have state-of-the-art performance according to standard measures\n(e.g., survival analysis), but, based on the high impact features, it also\nproduces meaningful explanations for the molecular bases of the subtypes. This\ncould provide an important step in the validation of potential cancer subtypes\nand enable the formulation of new hypotheses concerning individual patient\ngroups. Similar analysis are possible for other disease phenotypes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 07:28:13 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Speicher", "Nora K.", ""], ["Pfeifer", "Nico", ""]]}, {"id": "1811.08117", "submitter": "Yi Sun", "authors": "Yi Sun, Yan Tian, Yiping Xu and Jianxiang Li", "title": "Limited Gradient Descent: Learning With Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label noise may affect the generalization of classifiers, and the effective\nlearning of main patterns from samples with noisy labels is an important\nchallenge. Recent studies have shown that deep neural networks tend to\nprioritize the learning of simple patterns over the memorization of noise\npatterns. This suggests a possible method to search for the best generalization\nthat learns the main pattern until the noise begins to be memorized.\nTraditional approaches often employ a clean validation set to find the best\nstop timing of learning, i.e., early stopping. However, the generalization\nperformance of such methods relies on the quality of validation sets. Further,\nin practice, a clean validation set is sometimes difficult to obtain. To solve\nthis problem, we propose a method that can estimate the optimal stopping timing\nwithout a clean validation set, called limited gradient descent. We modified\nthe labels of a few samples in a noisy dataset to obtain false labels and to\ncreate a reverse pattern. By monitoring the learning progress of the noisy and\nreverse samples, we can determine the stop timing of learning. In this paper,\nwe also theoretically provide some necessary conditions on learning with noisy\nlabels. Experimental results on CIFAR-10 and CIFAR-100 datasets demonstrate\nthat our approach has a comparable generalization performance to methods\nrelying on a clean validation set. Thus, on the noisy Clothing-1M dataset, our\napproach surpasses methods that rely on a clean validation set.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 08:24:17 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 15:17:11 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 08:17:00 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 02:55:02 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Sun", "Yi", ""], ["Tian", "Yan", ""], ["Xu", "Yiping", ""], ["Li", "Jianxiang", ""]]}, {"id": "1811.08120", "submitter": "Weiyu Cheng", "authors": "Weiyu Cheng, Yanyan Shen, Yanmin Zhu, Linpeng Huang", "title": "Explaining Latent Factor Models for Recommendation with Influence\n  Functions", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330857", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models (LFMs) such as matrix factorization achieve the\nstate-of-the-art performance among various Collaborative Filtering (CF)\napproaches for recommendation. Despite the high recommendation accuracy of\nLFMs, a critical issue to be resolved is the lack of explainability. Extensive\nefforts have been made in the literature to incorporate explainability into\nLFMs. However, they either rely on auxiliary information which may not be\navailable in practice, or fail to provide easy-to-understand explanations. In\nthis paper, we propose a fast influence analysis method named FIA, which\nsuccessfully enforces explicit neighbor-style explanations to LFMs with the\ntechnique of influence functions stemmed from robust statistics. We first\ndescribe how to employ influence functions to LFMs to deliver neighbor-style\nexplanations. Then we develop a novel influence computation algorithm for\nmatrix factorization with high efficiency. We further extend it to the more\ngeneral neural collaborative filtering and introduce an approximation algorithm\nto accelerate influence analysis over neural network models. Experimental\nresults on real datasets demonstrate the correctness, efficiency and usefulness\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 08:31:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Cheng", "Weiyu", ""], ["Shen", "Yanyan", ""], ["Zhu", "Yanmin", ""], ["Huang", "Linpeng", ""]]}, {"id": "1811.08127", "submitter": "Alireza Abedin Varamin", "authors": "Alireza Abedin Varamin, Ehsan Abbasnejad, Qinfeng Shi, Damith\n  Ranasinghe, Hamid Rezatofighi", "title": "Deep Auto-Set: A Deep Auto-Encoder-Set Network for Activity Recognition\n  Using Wearables", "comments": "Accepted at MobiQuitous 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic recognition of human activities from time-series sensor data\n(referred to as HAR) is a growing area of research in ubiquitous computing.\nMost recent research in the field adopts supervised deep learning paradigms to\nautomate extraction of intrinsic features from raw signal inputs and addresses\nHAR as a multi-class classification problem where detecting a single activity\nclass within the duration of a sensory data segment suffices. However, due to\nthe innate diversity of human activities and their corresponding duration, no\ndata segment is guaranteed to contain sensor recordings of a single activity\ntype. In this paper, we express HAR more naturally as a set prediction problem\nwhere the predictions are sets of ongoing activity elements with unfixed and\nunknown cardinality. For the first time, we address this problem by presenting\na novel HAR approach that learns to output activity sets using deep neural\nnetworks. Moreover, motivated by the limited availability of annotated HAR\ndatasets as well as the unfortunate immaturity of existing unsupervised\nsystems, we complement our supervised set learning scheme with a prior\nunsupervised feature learning process that adopts convolutional auto-encoders\nto exploit unlabeled data. The empirical experiments on two widely adopted HAR\ndatasets demonstrate the substantial improvement of our proposed methodology\nover the baseline models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 08:54:31 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Varamin", "Alireza Abedin", ""], ["Abbasnejad", "Ehsan", ""], ["Shi", "Qinfeng", ""], ["Ranasinghe", "Damith", ""], ["Rezatofighi", "Hamid", ""]]}, {"id": "1811.08150", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Jiaoyang Huang, Leslie Pack Kaelbling", "title": "Effect of Depth and Width on Local Minima in Deep Learning", "comments": null, "journal-ref": "Neural computation, volume 31, pages 1462-1498 (2019)", "doi": "10.1162/neco_a_01195", "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the effects of depth and width on the quality of\nlocal minima, without strong over-parameterization and simplification\nassumptions in the literature. Without any simplification assumption, for deep\nnonlinear neural networks with the squared loss, we theoretically show that the\nquality of local minima tends to improve towards the global minimum value as\ndepth and width increase. Furthermore, with a locally-induced structure on deep\nnonlinear neural networks, the values of local minima of neural networks are\ntheoretically proven to be no worse than the globally optimal values of\ncorresponding classical machine learning models. We empirically support our\ntheoretical observation with a synthetic dataset as well as MNIST, CIFAR-10 and\nSVHN datasets. When compared to previous studies with strong\nover-parameterization assumptions, the results in this paper do not require\nover-parameterization, and instead show the gradual effects of\nover-parameterization as consequences of general results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 09:41:52 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 19:48:28 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 18:40:43 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 15:32:37 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Huang", "Jiaoyang", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1811.08159", "submitter": "Hamed Azarnoush", "authors": "Samaneh Siyar (1,2), Hamed Azarnoush (1,2), Saeid Rashidi (3),\n  Alexandre Winkler-Schwartz (1), Vincent Bissonnette (1), Nirros Ponnudurai\n  (1), Rolando F. Del Maestro (1), ((1) Neurosurgical Simulation Research and\n  Training Centre, McGill University, Canada, (2) Department of Biomedical\n  Engineering, Amirkabir University of Technology, Iran, (3) Science and\n  Research Branch, Islamic Azad University, Iran)", "title": "Machine Learning Distinguishes Neurosurgical Skill Levels in a Virtual\n  Reality Tumor Resection Task", "comments": null, "journal-ref": null, "doi": "10.1007/s11517-020-02155-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Virtual reality simulators and machine learning have the\npotential to augment understanding, assessment and training of psychomotor\nperformance in neurosurgery residents. Objective: This study outlines the first\napplication of machine learning to distinguish \"skilled\" and \"novice\"\npsychomotor performance during a virtual reality neurosurgical task. Methods:\nTwenty-three neurosurgeons and senior neurosurgery residents comprising the\n\"skilled\" group and 92 junior neurosurgery residents and medical students the\n\"novice\" group. The task involved removing a series of virtual brain tumors\nwithout causing injury to surrounding tissue. Over 100 features were extracted\nand 68 selected using t-test analysis. These features were provided to 4\nclassifiers: K-Nearest Neighbors, Parzen Window, Support Vector Machine, and\nFuzzy K-Nearest Neighbors. Equal Error Rate was used to assess classifier\nperformance. Results: Ratios of train set size to test set size from 10% to 90%\nand 5 to 30 features, chosen by the forward feature selection algorithm, were\nemployed. A working point of 50% train to test set size ratio and 15 features\nresulted in an equal error rates as low as 8.3% using the Fuzzy K-Nearest\nNeighbors classifier. Conclusion: Machine learning may be one component helping\nrealign the traditional apprenticeship educational paradigm to a more objective\nmodel based on proven performance standards.\n  Keywords: Artificial intelligence, Classifiers, Machine learning,\nNeurosurgery skill assessment, Surgical education, Tumor resection, Virtual\nreality simulation\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 10:09:02 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Siyar", "Samaneh", ""], ["Azarnoush", "Hamed", ""], ["Rashidi", "Saeid", ""], ["Winkler-Schwartz", "Alexandre", ""], ["Bissonnette", "Vincent", ""], ["Ponnudurai", "Nirros", ""], ["Del Maestro", "Rolando F.", ""]]}, {"id": "1811.08163", "submitter": "Tao Yi", "authors": "Tao Yi, Xingxuan Wang", "title": "Variance Suppression: Balanced Training Process in Deep Learning", "comments": "More experiments are needed to prove this theory, but I'm not quite\n  sure yet", "journal-ref": null, "doi": "10.1088/1742-6596/1207/1/012013", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic gradient descent updates parameters with summation gradient\ncomputed from a random data batch. This summation will lead to unbalanced\ntraining process if the data we obtained is unbalanced. To address this issue,\nthis paper takes the error variance and error mean both into consideration. The\nadaptively adjusting approach of two terms trading off is also given in our\nalgorithm. Due to this algorithm can suppress error variance, we named it\nVariance Suppression Gradient Descent (VSSGD). Experimental results have\ndemonstrated that VSSGD can accelerate the training process, effectively\nprevent overfitting, improve the networks learning capacity from small samples.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 10:16:31 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 09:05:42 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 08:21:15 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Yi", "Tao", ""], ["Wang", "Xingxuan", ""]]}, {"id": "1811.08212", "submitter": "Alexandre Garcia", "authors": "Christelle Marfaing, Alexandre Garcia", "title": "Computer-Assisted Fraud Detection, From Active Learning to Reward\n  Maximization", "comments": "NeurIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic detection of frauds in banking transactions has been recently\nstudied as a way to help the analysts finding fraudulent operations. Due to the\navailability of a human feedback, this task has been studied in the framework\nof active learning: the fraud predictor is allowed to sequentially call on an\noracle. This human intervention is used to label new examples and improve the\nclassification accuracy of the latter. Such a setting is not adapted in the\ncase of fraud detection with financial data in European countries. Actually, as\na human verification is mandatory to consider a fraud as really detected, it is\nnot necessary to focus on improving the classifier. We introduce the setting of\n'Computer-assisted fraud detection' where the goal is to minimize the number of\nnon fraudulent operations submitted to an oracle. The existing methods are\napplied to this task and we show that a simple meta-algorithm provides\ncompetitive results in this scenario on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 12:37:55 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Marfaing", "Christelle", ""], ["Garcia", "Alexandre", ""]]}, {"id": "1811.08214", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Hirotaka Takano and Junichi Murata", "title": "Contingency Training", "comments": null, "journal-ref": "Proc. of SICE Annual Conference 2013", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applied to high-dimensional datasets, feature selection algorithms might\nstill leave dozens of irrelevant variables in the dataset. Therefore, even\nafter feature selection has been applied, classifiers must be prepared to the\npresence of irrelevant variables. This paper investigates a new training method\ncalled Contingency Training which increases the accuracy as well as the\nrobustness against irrelevant attributes. Contingency training is classifier\nindependent. By subsampling and removing information from each sample, it\ncreates a set of constraints. These constraints aid the method to automatically\nfind proper importance weights of the dataset's features. Experiments are\nconducted with the contingency training applied to neural networks over\ntraditional datasets as well as datasets with additional irrelevant variables.\nFor all of the tests, contingency training surpassed the unmodified training on\ndatasets with irrelevant variables and even outperformed slightly when only a\nfew or no irrelevant variables were present.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 12:40:31 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1811.08223", "submitter": "Ramanarayan Mohanty", "authors": "Ramanarayan Mohanty, SL Happy and Aurobinda Routray", "title": "A Semi-supervised Spatial Spectral Regularized Manifold Local Scaling\n  Cut With HGF for Dimensionality Reduction of Hyperspectral Images", "comments": null, "journal-ref": "IEEE Transaction on Geoscience and Remote Sensing, 2018", "doi": "10.1109/TGRS.2018.2884771", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral images (HSI) contain a wealth of information over hundreds of\ncontiguous spectral bands, making it possible to classify materials through\nsubtle spectral discrepancies. However, the classification of this rich\nspectral information is accompanied by the challenges like high dimensionality,\nsingularity, limited training samples, lack of labeled data samples,\nheteroscedasticity and nonlinearity. To address these challenges, we propose a\nsemi-supervised graph based dimensionality reduction method named\n`semi-supervised spatial spectral regularized manifold local scaling cut'\n(S3RMLSC). The underlying idea of the proposed method is to exploit the limited\nlabeled information from both the spectral and spatial domains along with the\nabundant unlabeled samples to facilitate the classification task by retaining\nthe original distribution of the data. In S3RMLSC, a hierarchical guided filter\n(HGF) is initially used to smoothen the pixels of the HSI data to preserve the\nspatial pixel consistency. This step is followed by the construction of linear\npatches from the nonlinear manifold by using the maximal linear patch (MLP)\ncriterion. Then the inter-patch and intra-patch dissimilarity matrices are\nconstructed in both spectral and spatial domains by regularized manifold local\nscaling cut (RMLSC) and neighboring pixel manifold local scaling cut (NPMLSC)\nrespectively. Finally, we obtain the projection matrix by optimizing the\nupdated semi-supervised spatial-spectral between-patch and total-patch\ndissimilarity. The effectiveness of the proposed DR algorithm is illustrated\nwith publicly available real-world HSI datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 12:56:39 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Mohanty", "Ramanarayan", ""], ["Happy", "SL", ""], ["Routray", "Aurobinda", ""]]}, {"id": "1811.08227", "submitter": "Kar-Ann Toh", "authors": "Kar-Ann Toh", "title": "Analytic Network Learning", "comments": "Some of the preliminary ideas of this work has been presented in the\n  IEEE/ACIS 17th International Conference on Computer and Information Science:\n  \"Learning from the kernel and the range space\" (ICIS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the property that solving the system of linear matrix equations via\nthe column space and the row space projections boils down to an approximation\nin the least squares error sense, a formulation for learning the weight\nmatrices of the multilayer network can be derived. By exploiting into the vast\nnumber of feasible solutions of these interdependent weight matrices, the\nlearning can be performed analytically layer by layer without needing of\ngradient computation after an initialization. Possible initialization schemes\ninclude utilizing the data matrix as initial weights and random initialization.\nThe study is followed by an investigation into the representation capability\nand the output variance of the learning scheme. An extensive experimentation on\nsynthetic and real-world data sets validates its numerical feasibility.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:03:07 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Toh", "Kar-Ann", ""]]}, {"id": "1811.08252", "submitter": "Regev Cohen", "authors": "Oren Solomon, Regev Cohen, Yi Zhang, Yi Yang, He Qiong, Jianwen Luo,\n  Ruud J.G. van Sloun and Yonina C. Eldar", "title": "Deep Unfolded Robust PCA with Application to Clutter Suppression in\n  Ultrasound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrast enhanced ultrasound is a radiation-free imaging modality which uses\nencapsulated gas microbubbles for improved visualization of the vascular bed\ndeep within the tissue. It has recently been used to enable imaging with\nunprecedented subwavelength spatial resolution by relying on super-resolution\ntechniques. A typical preprocessing step in super-resolution ultrasound is to\nseparate the microbubble signal from the cluttering tissue signal. This step\nhas a crucial impact on the final image quality. Here, we propose a new\napproach to clutter removal based on robust principle component analysis (PCA)\nand deep learning. We begin by modeling the acquired contrast enhanced\nultrasound signal as a combination of a low rank and sparse components. This\nmodel is used in robust PCA and was previously suggested in the context of\nultrasound Doppler processing and dynamic magnetic resonance imaging. We then\nillustrate that an iterative algorithm based on this model exhibits improved\nseparation of microbubble signal from the tissue signal over commonly practiced\nmethods. Next, we apply the concept of deep unfolding to suggest a deep network\narchitecture tailored to our clutter filtering problem which exhibits improved\nconvergence speed and accuracy with respect to its iterative counterpart. We\ncompare the performance of the suggested deep network on both simulations and\nin-vivo rat brain scans, with a commonly practiced deep-network architecture\nand the fast iterative shrinkage algorithm, and show that our architecture\nexhibits better image quality and contrast.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 14:02:53 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Solomon", "Oren", ""], ["Cohen", "Regev", ""], ["Zhang", "Yi", ""], ["Yang", "Yi", ""], ["Qiong", "He", ""], ["Luo", "Jianwen", ""], ["van Sloun", "Ruud J. G.", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1811.08284", "submitter": "Raghav Menon", "authors": "Raghav Menon, Herman Kamper, Ewald van der Westhuizen, John Quinn,\n  Thomas Niesler", "title": "Feature exploration for almost zero-resource ASR-free keyword spotting\n  using a multilingual bottleneck extractor and correspondence autoencoders", "comments": "5 pages, 2 figures, 2 tables, 38 references, Accepted at Interspeech\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare features for dynamic time warping (DTW) when used to bootstrap\nkeyword spotting (KWS) in an almost zero-resource setting. Such\nquickly-deployable systems aim to support United Nations (UN) humanitarian\nrelief efforts in parts of Africa with severely under-resourced languages. Our\nobjective is to identify acoustic features that provide acceptable KWS\nperformance in such environments. As supervised resource, we restrict ourselves\nto a small, easily acquired and independently compiled set of isolated\nkeywords. For feature extraction, a multilingual bottleneck feature (BNF)\nextractor, trained on well-resourced out-of-domain languages, is integrated\nwith a correspondence autoencoder (CAE) trained on extremely sparse in-domain\ndata. On their own, BNFs and CAE features are shown to achieve a more than 2%\nabsolute performance improvement over baseline MFCCs. However, by using BNFs as\ninput to the CAE, even better performance is achieved, with a more than 11%\nabsolute improvement in ROC AUC over MFCCs and more than twice as many top-10\nretrievals for two evaluated languages, English and Luganda. We conclude that\nintegrating BNFs with the CAE allows both large out-of-domain and sparse\nin-domain resources to be exploited for improved ASR-free keyword spotting.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 09:29:11 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 01:58:31 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Menon", "Raghav", ""], ["Kamper", "Herman", ""], ["van der Westhuizen", "Ewald", ""], ["Quinn", "John", ""], ["Niesler", "Thomas", ""]]}, {"id": "1811.08295", "submitter": "Giorgia Ramponi", "authors": "Giorgia Ramponi, Pavlos Protopapas, Marco Brambilla, Ryan Janssen", "title": "T-CGAN: Conditional Generative Adversarial Network for Data Augmentation\n  in Noisy Time Series with Irregular Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a data augmentation method for time series with\nirregular sampling, Time-Conditional Generative Adversarial Network (T-CGAN).\nOur approach is based on Conditional Generative Adversarial Networks (CGAN),\nwhere the generative step is implemented by a deconvolutional NN and the\ndiscriminative step by a convolutional NN. Both the generator and the\ndiscriminator are conditioned on the sampling timestamps, to learn the hidden\nrelationship between data and timestamps, and consequently to generate new time\nseries. We evaluate our model with synthetic and real-world datasets. For the\nsynthetic data, we compare the performance of a classifier trained with\nT-CGAN-generated data, against the performance of the same classifier trained\non the original data. Results show that classifiers trained on T-CGAN-generated\ndata perform the same as classifiers trained on real data, even with very short\ntime series and small training sets. For the real world datasets, we compare\nour method with other techniques of data augmentation for time series, such as\ntime slicing and time warping, over a classification problem with unbalanced\ndatasets. Results show that our method always outperforms the other approaches,\nboth in case of regularly sampled and irregularly sampled time series. We\nachieve particularly good performance in case with a small training set and\nshort, noisy, irregularly-sampled time series.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 14:54:24 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 15:14:44 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Ramponi", "Giorgia", ""], ["Protopapas", "Pavlos", ""], ["Brambilla", "Marco", ""], ["Janssen", "Ryan", ""]]}, {"id": "1811.08297", "submitter": "Soroush Pakniat", "authors": "Farzad Eskandari and Soroush Pakniat", "title": "Finite Mixture Model of Nonparametric Density Estimation using Sampling\n  Importance Resampling for Persistence Landscape", "comments": "arXiv admin note: text overlap with arXiv:1803.03677", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the creation of persistence landscape on a parametrized curve and\nstructure of sampling, there exists a random process for which a finite mixture\nmodel of persistence landscape (FMMPL) can provide a better description for a\ngiven dataset. In this paper, a nonparametric approach for computing integrated\nmean of square error (IMSE) in persistence landscape has been presented. As a\nresult, FMMPL is more accurate than the another way. Also, the sampling\nimportance resampling (SIR) has been presented a better description of\nimportant landmark from parametrized curve. The result, provides more accuracy\nand less space complexity than the landmarks selected with simple sampling.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 06:55:32 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Eskandari", "Farzad", ""], ["Pakniat", "Soroush", ""]]}, {"id": "1811.08337", "submitter": "Thomas Ryder", "authors": "Tom Ryder, Andrew Golighty, A. Stephen McGough, Dennis Prangle", "title": "Black-Box Autoregressive Density Estimation for State-Space Models", "comments": "V2", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-space models (SSMs) provide a flexible framework for modelling\ntime-series data. Consequently, SSMs are ubiquitously applied in areas such as\nengineering, econometrics and epidemiology. In this paper we provide a fast\napproach for approximate Bayesian inference in SSMs using the tools of deep\nlearning and variational inference.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 16:05:05 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 08:19:51 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Ryder", "Tom", ""], ["Golighty", "Andrew", ""], ["McGough", "A. Stephen", ""], ["Prangle", "Dennis", ""]]}, {"id": "1811.08357", "submitter": "Danica J. Sutherland", "authors": "Li Wenliang, Danica J. Sutherland, Heiko Strathmann, Arthur Gretton", "title": "Learning deep kernels for exponential family densities", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019), PMLR 97:6737-6746", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel exponential family is a rich class of distributions, which can be\nfit efficiently and with statistical guarantees by score matching. Being\nrequired to choose a priori a simple kernel such as the Gaussian, however,\nlimits its practical applicability. We provide a scheme for learning a kernel\nparameterized by a deep network, which can find complex location-dependent\nlocal features of the data geometry. This gives a very rich class of density\nmodels, capable of fitting complex structures on moderate-dimensional problems.\nCompared to deep density models fit via maximum likelihood, our approach\nprovides a complementary set of strengths and tradeoffs: in empirical studies,\nthe former can yield higher likelihoods, whereas the latter gives better\nestimates of the gradient of the log density, the score, which describes the\ndistribution's shape.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 16:40:45 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 18:32:27 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 22:32:00 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 18:37:55 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Wenliang", "Li", ""], ["Sutherland", "Danica J.", ""], ["Strathmann", "Heiko", ""], ["Gretton", "Arthur", ""]]}, {"id": "1811.08382", "submitter": "Matthew Joseph", "authors": "Matthew Joseph, Janardhan Kulkarni, Jieming Mao, Zhiwei Steven Wu", "title": "Locally Private Gaussian Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a basic private estimation problem: each of $n$ users draws a single\ni.i.d. sample from an unknown Gaussian distribution, and the goal is to\nestimate the mean of this Gaussian distribution while satisfying local\ndifferential privacy for each user. Informally, local differential privacy\nrequires that each data point is individually and independently privatized\nbefore it is passed to a learning algorithm. Locally private Gaussian\nestimation is therefore difficult because the data domain is unbounded: users\nmay draw arbitrarily different inputs, but local differential privacy\nnonetheless mandates that different users have (worst-case) similar privatized\noutput distributions. We provide both adaptive two-round solutions and\nnonadaptive one-round solutions for locally private Gaussian estimation. We\nthen partially match these upper bounds with an information-theoretic lower\nbound. This lower bound shows that our accuracy guarantees are tight up to\nlogarithmic factors for all sequentially interactive\n$(\\varepsilon,\\delta)$-locally private protocols.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 17:37:26 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 15:47:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Joseph", "Matthew", ""], ["Kulkarni", "Janardhan", ""], ["Mao", "Jieming", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1811.08393", "submitter": "Kush Bhatia", "authors": "Kush Bhatia, Aldo Pacchiano, Nicolas Flammarion, Peter L. Bartlett,\n  Michael I. Jordan", "title": "Gen-Oja: A Two-time-scale approach for Streaming CCA", "comments": "Accepted at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problems of principal Generalized Eigenvector\ncomputation and Canonical Correlation Analysis in the stochastic setting. We\npropose a simple and efficient algorithm, Gen-Oja, for these problems. We prove\nthe global convergence of our algorithm, borrowing ideas from the theory of\nfast-mixing Markov chains and two-time-scale stochastic approximation, showing\nthat it achieves the optimal rate of convergence. In the process, we develop\ntools for understanding stochastic processes with Markovian noise which might\nbe of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 17:57:13 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 01:19:06 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Bhatia", "Kush", ""], ["Pacchiano", "Aldo", ""], ["Flammarion", "Nicolas", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1811.08413", "submitter": "Yi-An Ma", "authors": "Yi-An Ma, Yuansi Chen, Chi Jin, Nicolas Flammarion, and Michael I.\n  Jordan", "title": "Sampling Can Be Faster Than Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization algorithms and Monte Carlo sampling algorithms have provided the\ncomputational foundations for the rapid growth in applications of statistical\nmachine learning in recent years. There is, however, limited theoretical\nunderstanding of the relationships between these two kinds of methodology, and\nlimited understanding of relative strengths and weaknesses. Moreover, existing\nresults have been obtained primarily in the setting of convex functions (for\noptimization) and log-concave functions (for sampling). In this setting, where\nlocal properties determine global properties, optimization algorithms are\nunsurprisingly more efficient computationally than sampling algorithms. We\ninstead examine a class of nonconvex objective functions that arise in mixture\nmodeling and multi-stable systems. In this nonconvex setting, we find that the\ncomputational complexity of sampling algorithms scales linearly with the model\ndimension while that of optimization algorithms scales exponentially.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 18:41:29 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 21:50:10 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Ma", "Yi-An", ""], ["Chen", "Yuansi", ""], ["Jin", "Chi", ""], ["Flammarion", "Nicolas", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1811.08417", "submitter": "Ananda Theertha Suresh", "authors": "Ehsan Variani, Ananda Theertha Suresh, Mitchel Weintraub", "title": "WEST: Word Encoded Sequence Transducers", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the parameters in large vocabulary models are used in embedding layer\nto map categorical features to vectors and in softmax layer for classification\nweights. This is a bottle-neck in memory constraint on-device training\napplications like federated learning and on-device inference applications like\nautomatic speech recognition (ASR). One way of compressing the embedding and\nsoftmax layers is to substitute larger units such as words with smaller\nsub-units such as characters. However, often the sub-unit models perform poorly\ncompared to the larger unit models. We propose WEST, an algorithm for encoding\ncategorical features and output classes with a sequence of random or domain\ndependent sub-units and demonstrate that this transduction can lead to\nsignificant compression without compromising performance. WEST bridges the gap\nbetween larger unit and sub-unit models and can be interpreted as a MaxEnt\nmodel over sub-unit features, which can be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 18:47:50 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Variani", "Ehsan", ""], ["Suresh", "Ananda Theertha", ""], ["Weintraub", "Mitchel", ""]]}, {"id": "1811.08458", "submitter": "Isay Katsman", "authors": "Qian Huang, Zeqi Gu, Isay Katsman, Horace He, Pian Pawakapan, Zhiqiu\n  Lin, Serge Belongie, Ser-Nam Lim", "title": "Intermediate Level Adversarial Attack for Enhanced Transferability", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarial examples, malicious inputs\ncrafted to fool trained models. Adversarial examples often exhibit black-box\ntransfer, meaning that adversarial examples for one model can fool another\nmodel. However, adversarial examples may be overfit to exploit the particular\narchitecture and feature representation of a source model, resulting in\nsub-optimal black-box transfer attacks to other target models. This leads us to\nintroduce the Intermediate Level Attack (ILA), which attempts to fine-tune an\nexisting adversarial example for greater black-box transferability by\nincreasing its perturbation on a pre-specified layer of the source model. We\nshow that our method can effectively achieve this goal and that we can decide a\nnearly-optimal layer of the source model to perturb without any knowledge of\nthe target models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 19:40:24 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Huang", "Qian", ""], ["Gu", "Zeqi", ""], ["Katsman", "Isay", ""], ["He", "Horace", ""], ["Pawakapan", "Pian", ""], ["Lin", "Zhiqiu", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "1811.08484", "submitter": "Rushil Anirudh", "authors": "Rushil Anirudh, Jayaraman J. Thiagarajan, Bhavya Kailkhura, Timo\n  Bremer", "title": "MimicGAN: Corruption-Mimicking for Blind Image Recovery & Adversarial\n  Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving inverse problems continues to be a central challenge in computer\nvision. Existing techniques either explicitly construct an inverse mapping\nusing prior knowledge about the corruption, or learn the inverse directly using\na large collection of examples. However, in practice, the nature of corruption\nmay be unknown, and thus it is challenging to regularize the problem of\ninferring a plausible solution. On the other hand, collecting task-specific\ntraining data is tedious for known corruptions and impossible for unknown ones.\nWe present MimicGAN, an unsupervised technique to solve general inverse\nproblems based on image priors in the form of generative adversarial networks\n(GANs). Using a GAN prior, we show that one can reliably recover solutions to\nunderdetermined inverse problems through a surrogate network that learns to\nmimic the corruption at test time. Our system successively estimates the\ncorruption and the clean image without the need for supervisory training, while\noutperforming existing baselines in blind image recovery. We also demonstrate\nthat MimicGAN improves upon recent GAN-based defenses against adversarial\nattacks and represents one of the strongest test-time defenses available today.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 20:59:38 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Kailkhura", "Bhavya", ""], ["Bremer", "Timo", ""]]}, {"id": "1811.08511", "submitter": "Yunfeng Zhang", "authors": "Yunfeng Zhang, Irina Gaynanova", "title": "Joint association and classification analysis of multi-view data", "comments": "Major revision of the paper structure. More simulation and data\n  analysis results were added to the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view data, that is matched sets of measurements on the same subjects,\nhave become increasingly common with advances in multi-omics technology. Often,\nit is of interest to find associations between the views that are related to\nthe intrinsic class memberships. Existing association methods cannot directly\nincorporate class information, while existing classification methods do not\ntake into account between-views associations. In this work, we propose a\nframework for Joint Association and Classification Analysis of multi-view data\n(JACA). Our goal is not to merely improve the misclassification rates, but to\nprovide a latent representation of high-dimensional data that is both relevant\nfor the subtype discrimination and coherent across the views. We motivate the\nmethodology by establishing a connection between canonical correlation analysis\nand discriminant analysis. We also establish the estimation consistency of JACA\nin high-dimensional settings. A distinct advantage of JACA is that it can be\napplied to the multi-view data with block-missing structure, that is to cases\nwhere a subset of views or class labels is missing for some subjects. The\napplication of JACA to quantify the associations between RNAseq and miRNA views\nwith respect to consensus molecular subtypes in colorectal cancer data from The\nCancer Genome Atlas project leads to improved misclassification rates and\nstronger found associations compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 22:15:19 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 08:47:23 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Zhang", "Yunfeng", ""], ["Gaynanova", "Irina", ""]]}, {"id": "1811.08537", "submitter": "Till Hartmann", "authors": "Till S. Hartmann", "title": "Seeing in the dark with recurrent convolutional neural networks", "comments": "12 pages (with appendix), 6 figure (main text), 3 supplementary\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical convolutional neural networks (cCNNs) are very good at categorizing\nobjects in images. But, unlike human vision which is relatively robust to noise\nin images, the performance of cCNNs declines quickly as image quality worsens.\nHere we propose to use recurrent connections within the convolutional layers to\nmake networks robust against pixel noise such as could arise from imaging at\nlow light levels, and thereby significantly increase their performance when\ntested with simulated noisy video sequences. We show that cCNNs classify images\nwith high signal to noise ratios (SNRs) well, but are easily outperformed when\ntested with low SNR images (high noise levels) by convolutional neural networks\nthat have recurrency added to convolutional layers, henceforth referred to as\ngruCNNs. Addition of Bayes-optimal temporal integration to allow the cCNN to\nintegrate multiple image frames still does not match gruCNN performance.\nAdditionally, we show that at low SNRs, the probabilities predicted by the\ngruCNN (after calibration) have higher confidence than those predicted by the\ncCNN. We propose to consider recurrent connections in the early stages of\nneural networks as a solution to computer vision under imperfect lighting\nconditions and noisy environments; challenges faced during real-time video\nstreams of autonomous driving at night, during rain or snow, and other\nnon-ideal situations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 01:05:48 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Hartmann", "Till S.", ""]]}, {"id": "1811.08540", "submitter": "Wen Sun", "authors": "Wen Sun, Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford", "title": "Model-based RL in Contextual Decision Processes: PAC bounds and\n  Exponential Improvements over Model-free Approaches", "comments": "COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of model-based reinforcement learning\n(henceforth RL) in general contextual decision processes that require strategic\nexploration to find a near-optimal policy. We design new algorithms for RL with\na generic model class and analyze their statistical properties. Our algorithms\nhave sample complexity governed by a new structural parameter called the\nwitness rank, which we show to be small in several settings of interest,\nincluding factored MDPs. We also show that the witness rank is never larger\nthan the recently proposed Bellman rank parameter governing the sample\ncomplexity of the model-free algorithm OLIVE (Jiang et al., 2017), the only\nother provably sample-efficient algorithm for global exploration at this level\nof generality. Focusing on the special case of factored MDPs, we prove an\nexponential lower bound for a general class of model-free approaches, including\nOLIVE, which, when combined with our algorithmic results, demonstrates\nexponential separation between model-based and model-free RL in some\nrich-observation settings.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 01:48:17 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 04:05:04 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 05:35:14 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Sun", "Wen", ""], ["Jiang", "Nan", ""], ["Krishnamurthy", "Akshay", ""], ["Agarwal", "Alekh", ""], ["Langford", "John", ""]]}, {"id": "1811.08545", "submitter": "Jennifer Wei", "authors": "Jennifer N. Wei, David Belanger, Ryan P. Adams, D. Sculley", "title": "Rapid Prediction of Electron-Ionization Mass Spectrometry using Neural\n  Networks", "comments": "12 pages, 5 figures", "journal-ref": "ACS Cent. Sci. 2019 5 (4) 700-708", "doi": "10.1021/acscentsci.9b00085", "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When confronted with a substance of unknown identity, researchers often\nperform mass spectrometry on the sample and compare the observed spectrum to a\nlibrary of previously-collected spectra to identify the molecule. While\npopular, this approach will fail to identify molecules that are not in the\nexisting library. In response, we propose to improve the library's coverage by\naugmenting it with synthetic spectra that are predicted using machine learning.\nWe contribute a lightweight neural network model that quickly predicts mass\nspectra for small molecules. Achieving high accuracy predictions requires a\nnovel neural network architecture that is designed to capture typical\nfragmentation patterns from electron ionization. We analyze the effects of our\nmodeling innovations on library matching performance and compare our models to\nprior machine learning-based work on spectrum prediction.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 02:02:08 GMT"}, {"version": "v2", "created": "Sun, 17 Mar 2019 18:44:23 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wei", "Jennifer N.", ""], ["Belanger", "David", ""], ["Adams", "Ryan P.", ""], ["Sculley", "D.", ""]]}, {"id": "1811.08549", "submitter": "Alexander Peysakhovich", "authors": "Alexander Peysakhovich", "title": "Reinforcement Learning and Inverse Reinforcement Learning with System 1\n  and System 2", "comments": "Published in AAAI-AIES 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring a person's goal from their behavior is an important problem in\napplications of AI (e.g. automated assistants, recommender systems). The\nworkhorse model for this task is the rational actor model - this amounts to\nassuming that people have stable reward functions, discount the future\nexponentially, and construct optimal plans. Under the rational actor assumption\ntechniques such as inverse reinforcement learning (IRL) can be used to infer a\nperson's goals from their actions. A competing model is the dual-system model.\nHere decisions are the result of an interplay between a fast, automatic,\nheuristic-based system 1 and a slower, deliberate, calculating system 2. We\ngeneralize the dual system framework to the case of Markov decision problems\nand show how to compute optimal plans for dual-system agents. We show that\ndual-system agents exhibit behaviors that are incompatible with rational actor\nassumption. We show that naive applications of rational-actor IRL to the\nbehavior of dual-system agents can generate wrong inference about the agents'\ngoals and suggest interventions that actually reduce the agent's overall\nutility. Finally, we adapt a simple IRL algorithm to correctly infer the goals\nof dual system decision-makers. This allows us to make interventions that help,\nrather than hinder, the dual-system agent's ability to reach their true goals.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 22:36:53 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 18:41:08 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Peysakhovich", "Alexander", ""]]}, {"id": "1811.08568", "submitter": "Jonas Gehring", "authors": "Jonas Gehring, Da Ju, Vegard Mella, Daniel Gant, Nicolas Usunier,\n  Gabriel Synnaeve", "title": "High-Level Strategy Selection under Partial Observability in StarCraft:\n  Brood War", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of high-level strategy selection in the adversarial\nsetting of real-time strategy games from a reinforcement learning perspective,\nwhere taking an action corresponds to switching to the respective strategy.\nHere, a good strategy successfully counters the opponent's current and possible\nfuture strategies which can only be estimated using partial observations. We\ninvestigate whether we can utilize the full game state information during\ntraining time (in the form of an auxiliary prediction task) to increase\nperformance. Experiments carried out within a StarCraft: Brood War bot against\nstrong community bots show substantial win rate improvements over a\nfixed-strategy baseline and encouraging results when learning with the\nauxiliary task.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 02:27:16 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Gehring", "Jonas", ""], ["Ju", "Da", ""], ["Mella", "Vegard", ""], ["Gant", "Daniel", ""], ["Usunier", "Nicolas", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "1811.08577", "submitter": "Utku Ozbulak", "authors": "Utku Ozbulak, Wesley De Neve, Arnout Van Messem", "title": "How the Softmax Output is Misleading for Evaluating the Strength of\n  Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even before deep learning architectures became the de facto models for\ncomplex computer vision tasks, the softmax function was, given its elegant\nproperties, already used to analyze the predictions of feedforward neural\nnetworks. Nowadays, the output of the softmax function is also commonly used to\nassess the strength of adversarial examples: malicious data points designed to\nfail machine learning models during the testing phase. However, in this paper,\nwe show that it is possible to generate adversarial examples that take\nadvantage of some properties of the softmax function, leading to undesired\noutcomes when interpreting the strength of the adversarial examples at hand.\nSpecifically, we argue that the output of the softmax function is a poor\nindicator when the strength of an adversarial example is analyzed and that this\nindicator can be easily tricked by already existing methods for adversarial\nexample generation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 02:52:52 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Ozbulak", "Utku", ""], ["De Neve", "Wesley", ""], ["Van Messem", "Arnout", ""]]}, {"id": "1811.08579", "submitter": "Vishwali Mhasawade", "authors": "Vishwali Mhasawade, Nabeel Abdur Rehman, Rumi Chunara", "title": "Population-aware Hierarchical Bayesian Domain Adaptation", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/105", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population attributes are essential in health for understanding who the data\nrepresents and precision medicine efforts. Even within disease infection\nlabels, patients can exhibit significant variability; \"fever\" may mean\nsomething different when reported in a doctor's office versus from an online\napp, precluding directly learning across different datasets for the same\nprediction task. This problem falls into the domain adaptation paradigm.\nHowever, research in this area has to-date not considered who generates the\ndata; symptoms reported by a woman versus a man, for example, could also have\ndifferent implications. We propose a novel population-aware domain adaptation\napproach by formulating the domain adaptation task as a multi-source\nhierarchical Bayesian framework. The model improves prediction in the case of\nlargely unlabelled target data by harnessing both domain and population\ninvariant information.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 02:59:16 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Mhasawade", "Vishwali", ""], ["Rehman", "Nabeel Abdur", ""], ["Chunara", "Rumi", ""]]}, {"id": "1811.08581", "submitter": "Chuanxing Geng", "authors": "Chuanxing Geng, Sheng-jun Huang and Songcan Chen", "title": "Recent Advances in Open Set Recognition: A Survey", "comments": "Accepted by IEEE TPAMI", "journal-ref": null, "doi": "10.1109/TPAMI.2020.2981604", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world recognition/classification tasks, limited by various objective\nfactors, it is usually difficult to collect training samples to exhaust all\nclasses when training a recognizer or classifier. A more realistic scenario is\nopen set recognition (OSR), where incomplete knowledge of the world exists at\ntraining time, and unknown classes can be submitted to an algorithm during\ntesting, requiring the classifiers to not only accurately classify the seen\nclasses, but also effectively deal with the unseen ones. This paper provides a\ncomprehensive survey of existing open set recognition techniques covering\nvarious aspects ranging from related definitions, representations of models,\ndatasets, evaluation criteria, and algorithm comparisons. Furthermore, we\nbriefly analyze the relationships between OSR and its related tasks including\nzero-shot, one-shot (few-shot) recognition/learning techniques, classification\nwith reject option, and so forth. Additionally, we also overview the open world\nrecognition which can be seen as a natural extension of OSR. Importantly, we\nhighlight the limitations of existing approaches and point out some promising\nsubsequent research directions in this field.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 03:20:47 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 12:51:14 GMT"}, {"version": "v3", "created": "Sun, 23 Feb 2020 01:35:04 GMT"}, {"version": "v4", "created": "Sat, 21 Mar 2020 13:54:47 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Geng", "Chuanxing", ""], ["Huang", "Sheng-jun", ""], ["Chen", "Songcan", ""]]}, {"id": "1811.08633", "submitter": "Kazuki Tachikawa", "authors": "Kazuki Tachikawa, Yuji Kawai, Jihoon Park, Minoru Asada", "title": "Compensated Integrated Gradients to Reliably Interpret EEG\n  Classification", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/63", "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated gradients are widely employed to evaluate the contribution of\ninput features in classification models because it satisfies the axioms for\nattribution of prediction. This method, however, requires an appropriate\nbaseline for reliable determination of the contributions. We propose a\ncompensated integrated gradients method that does not require a baseline. In\nfact, the method compensates the attributions calculated by integrated\ngradients at an arbitrary baseline using Shapley sampling. We prove that the\nmethod retrieves reliable attributions if the processes of input features in a\nclassifier are mutually independent, and they are identical like shared weights\nin convolutional neural networks. Using three electroencephalogram datasets, we\nexperimentally demonstrate that the attributions of the proposed method are\nmore reliable than those of the original integrated gradients, and its\ncomputational complexity is much lower than that of Shapley sampling.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 08:37:40 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Tachikawa", "Kazuki", ""], ["Kawai", "Yuji", ""], ["Park", "Jihoon", ""], ["Asada", "Minoru", ""]]}, {"id": "1811.08674", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan, Thomas Kipf, Max Welling, Antonio Garcia-Uceda\n  Juarez, Jesper H Pedersen, Jens Petersen, Marleen de Bruijne", "title": "Graph Refinement based Airway Extraction using Mean-Field Networks and\n  Graph Neural Networks", "comments": "Accepted for publication at Medical Image Analysis. 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph refinement, or the task of obtaining subgraphs of interest from\nover-complete graphs, can have many varied applications. In this work, we\nextract trees or collection of sub-trees from image data by, first deriving a\ngraph-based representation of the volumetric data and then, posing the tree\nextraction as a graph refinement task. We present two methods to perform graph\nrefinement. First, we use mean-field approximation (MFA) to approximate the\nposterior density over the subgraphs from which the optimal subgraph of\ninterest can be estimated. Mean field networks (MFNs) are used for inference\nbased on the interpretation that iterations of MFA can be seen as feed-forward\noperations in a neural network. This allows us to learn the model parameters\nusing gradient descent. Second, we present a supervised learning approach using\ngraph neural networks (GNNs) which can be seen as generalisations of MFNs.\nSubgraphs are obtained by training a GNN-based graph refinement model to\ndirectly predict edge probabilities. We discuss connections between the two\nclasses of methods and compare them for the task of extracting airways from 3D,\nlow-dose, chest CT data. We show that both the MFN and GNN models show\nsignificant improvement when compared to one baseline method, that is similar\nto a top performing method in the EXACT'09 Challenge, and a 3D U-Net based\nairway segmentation model, in detecting more branches with fewer false\npositives.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 10:50:31 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 16:14:58 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Selvan", "Raghavendra", ""], ["Kipf", "Thomas", ""], ["Welling", "Max", ""], ["Juarez", "Antonio Garcia-Uceda", ""], ["Pedersen", "Jesper H", ""], ["Petersen", "Jens", ""], ["de Bruijne", "Marleen", ""]]}, {"id": "1811.08687", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Konark Jain, Arpit Kapoor, and Ashray Aman", "title": "Surrogate-assisted parallel tempering for Bayesian neural learning", "comments": "Engineering Applications of Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the need for robust uncertainty quantification, Bayesian neural\nlearning has gained attention in the era of deep learning and big data. Markov\nChain Monte-Carlo (MCMC) methods typically implement Bayesian inference which\nfaces several challenges given a large number of parameters, complex and\nmultimodal posterior distributions, and computational complexity of large\nneural network models. Parallel tempering MCMC addresses some of these\nlimitations given that they can sample multimodal posterior distributions and\nutilize high-performance computing. However, certain challenges remain given\nlarge neural network models and big data. Surrogate-assisted optimization\nfeatures the estimation of an objective function for models which are\ncomputationally expensive. In this paper, we address the inefficiency of\nparallel tempering MCMC for large-scale problems by combining parallel\ncomputing features with surrogate assisted likelihood estimation that describes\nthe plausibility of a model parameter value, given specific observed data.\nHence, we present surrogate-assisted parallel tempering for Bayesian neural\nlearning for simple to computationally expensive models. Our results\ndemonstrate that the methodology significantly lowers the computational cost\nwhile maintaining quality in decision making with Bayesian neural networks. The\nmethod has applications for a Bayesian inversion and uncertainty quantification\nfor a broad range of numerical models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 11:14:05 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 06:28:07 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 12:41:47 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Chandra", "Rohitash", ""], ["Jain", "Konark", ""], ["Kapoor", "Arpit", ""], ["Aman", "Ashray", ""]]}, {"id": "1811.08695", "submitter": "Irene Giacomelli", "authors": "Irene Giacomelli, Somesh Jha, Ross Kleiman, David Page, Kyonghwan Yoon", "title": "Privacy-Preserving Collaborative Prediction using Random Forests", "comments": "Accepted at the AMIA Informatics Summit 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of privacy-preserving machine learning (PPML) for\nensemble methods, focusing our effort on random forests. In collaborative\nanalysis, PPML attempts to solve the conflict between the need for data sharing\nand privacy. This is especially important in privacy sensitive applications\nsuch as learning predictive models for clinical decision support from EHR data\nfrom different clinics, where each clinic has a responsibility for its\npatients' privacy. We propose a new approach for ensemble methods: each entity\nlearns a model, from its own data, and then when a client asks the prediction\nfor a new private instance, the answers from all the locally trained models are\nused to compute the prediction in such a way that no extra information is\nrevealed. We implement this approach for random forests and we demonstrate its\nhigh efficiency and potential accuracy benefit via experiments on real-world\ndatasets, including actual EHR data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 11:44:52 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Giacomelli", "Irene", ""], ["Jha", "Somesh", ""], ["Kleiman", "Ross", ""], ["Page", "David", ""], ["Yoon", "Kyonghwan", ""]]}, {"id": "1811.08723", "submitter": "Conor Durkan", "authors": "Conor Durkan, George Papamakarios, Iain Murray", "title": "Sequential Neural Methods for Likelihood-free Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-free inference refers to inference when a likelihood function\ncannot be explicitly evaluated, which is often the case for models based on\nsimulators. Most of the literature is based on sample-based `Approximate\nBayesian Computation' methods, but recent work suggests that approaches based\non deep neural conditional density estimators can obtain state-of-the-art\nresults with fewer simulations. The neural approaches vary in how they choose\nwhich simulations to run and what they learn: an approximate posterior or a\nsurrogate likelihood. This work provides some direct controlled comparisons\nbetween these choices.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 13:39:40 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Durkan", "Conor", ""], ["Papamakarios", "George", ""], ["Murray", "Iain", ""]]}, {"id": "1811.08725", "submitter": "Tatiana Shpakova", "authors": "Tatiana Shpakova, Francis Bach, Anton Osokin", "title": "Marginal Weighted Maximum Log-likelihood for Efficient Learning of\n  Perturb-and-Map models", "comments": "Published in Proceedings of the Conference of Uncertainty in\n  Artificial Intelligence (UAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the structured-output prediction problem through probabilistic\napproaches and generalize the \"perturb-and-MAP\" framework to more challenging\nweighted Hamming losses, which are crucial in applications. While in principle\nour approach is a straightforward marginalization, it requires solving many\nrelated MAP inference problems. We show that for log-supermodular pairwise\nmodels these operations can be performed efficiently using the machinery of\ndynamic graph cuts. We also propose to use double stochastic gradient descent,\nboth on the data and on the perturbations, for efficient learning. Our\nframework can naturally take weak supervision (e.g., partial labels) into\naccount. We conduct a set of experiments on medium-scale character recognition\nand image segmentation, showing the benefits of our algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 13:41:21 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Shpakova", "Tatiana", ""], ["Bach", "Francis", ""], ["Osokin", "Anton", ""]]}, {"id": "1811.08737", "submitter": "Honghui Shi", "authors": "Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana\n  Rosing, Rogerio Feris", "title": "SpotTune: Transfer Learning through Adaptive Fine-tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning, which allows a source task to affect the inductive bias of\nthe target task, is widely used in computer vision. The typical way of\nconducting transfer learning with deep neural networks is to fine-tune a model\npre-trained on the source task using data from the target task. In this paper,\nwe propose an adaptive fine-tuning approach, called SpotTune, which finds the\noptimal fine-tuning strategy per instance for the target data. In SpotTune,\ngiven an image from the target task, a policy network is used to make routing\ndecisions on whether to pass the image through the fine-tuned layers or the\npre-trained layers. We conduct extensive experiments to demonstrate the\neffectiveness of the proposed approach. Our method outperforms the traditional\nfine-tuning approach on 12 out of 14 standard datasets.We also compare SpotTune\nwith other state-of-the-art fine-tuning strategies, showing superior\nperformance. On the Visual Decathlon datasets, our method achieves the highest\nscore across the board without bells and whistles.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 14:02:03 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Guo", "Yunhui", ""], ["Shi", "Honghui", ""], ["Kumar", "Abhishek", ""], ["Grauman", "Kristen", ""], ["Rosing", "Tajana", ""], ["Feris", "Rogerio", ""]]}, {"id": "1811.08764", "submitter": "Etai Littwin", "authors": "Etai Littwin, Lior Wolf", "title": "Regularizing by the Variance of the Activations' Sample-Variances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization techniques play an important role in supporting efficient and\noften more effective training of deep neural networks. While conventional\nmethods explicitly normalize the activations, we suggest to add a loss term\ninstead. This new loss term encourages the variance of the activations to be\nstable and not vary from one random mini-batch to the next. As we prove, this\nencourages the activations to be distributed around a few distinct modes. We\nalso show that if the inputs are from a mixture of two Gaussians, the new loss\nwould either join the two together, or separate between them optimally in the\nLDA sense, depending on the prior probabilities. Finally, we are able to link\nthe new regularization term to the batchnorm method, which provides it with a\nregularization perspective. Our experiments demonstrate an improvement in\naccuracy over the batchnorm technique for both CNNs and fully connected\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 14:58:38 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Littwin", "Etai", ""], ["Wolf", "Lior", ""]]}, {"id": "1811.08769", "submitter": "Yacouba Boubacar Mainassara", "authors": "Yacouba Boubacar Ma\\\"inassara (UFC), Othman Kadmiri, Bruno Saussereau\n  (LMB)", "title": "Portmanteau test for the asymmetric power GARCH model when the power is\n  unknown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now widely accepted that, to model the dynamics of daily financial\nreturns, volatility models have to incorporate the so-called leverage effect.\nWe derive the asymptotic behaviour of the squared residuals autocovariances for\nthe class of asymmetric power GARCH model when the power is unknown and is\njointly estimated with the model's parameters. We then deduce a portmanteau\nadequacy test based on the autocovariances of the squared residuals. These\nasymptotic results are illustrated by Monte Carlo experiments. An application\nto real financial data is also proposed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:04:58 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Ma\u00efnassara", "Yacouba Boubacar", "", "UFC"], ["Kadmiri", "Othman", "", "LMB"], ["Saussereau", "Bruno", "", "LMB"]]}, {"id": "1811.08790", "submitter": "Yan Leng", "authors": "Yan Leng and Xiaowen Dong and Junfeng Wu and Alex Pentland", "title": "Learning Quadratic Games on Networks", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (ICML) 2020", "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals, or organizations, cooperate with or compete against one another\nin a wide range of practical situations. Such strategic interactions are often\nmodeled as games played on networks, where an individual's payoff depends not\nonly on her action but also on that of her neighbors. The current literature\nhas largely focused on analyzing the characteristics of network games in the\nscenario where the structure of the network, which is represented by a graph,\nis known beforehand. It is often the case, however, that the actions of the\nplayers are readily observable while the underlying interaction network remains\nhidden. In this paper, we propose two novel frameworks for learning, from the\nobservations on individual actions, network games with linear-quadratic\npayoffs, and in particular, the structure of the interaction network. Our\nframeworks are based on the Nash equilibrium of such games and involve solving\na joint optimization problem for the graph structure and the individual\nmarginal benefits. Both synthetic and real-world experiments demonstrate the\neffectiveness of the proposed frameworks, which have theoretical as well as\npractical implications for understanding strategic interactions in a network\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:40:57 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 06:33:03 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 04:47:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Leng", "Yan", ""], ["Dong", "Xiaowen", ""], ["Wu", "Junfeng", ""], ["Pentland", "Alex", ""]]}, {"id": "1811.08800", "submitter": "Mahsa Ghorbani", "authors": "Mahsa Ghorbani, Mahdieh Soleymani Baghshah, Hamid R. Rabiee", "title": "MGCN: Semi-supervised Classification in Multi-layer Graphs with Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3341161.3342942", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding is an important approach for graph analysis tasks such as\nnode classification and link prediction. The goal of graph embedding is to find\na low dimensional representation of graph nodes that preserves the graph\ninformation. Recent methods like Graph Convolutional Network (GCN) try to\nconsider node attributes (if available) besides node relations and learn node\nembeddings for unsupervised and semi-supervised tasks on graphs. On the other\nhand, multi-layer graph analysis has been received attention recently. However,\nthe existing methods for multi-layer graph embedding cannot incorporate all\navailable information (like node attributes). Moreover, most of them consider\neither type of nodes or type of edges, and they do not treat within and between\nlayer edges differently. In this paper, we propose a method called MGCN that\nutilizes the GCN for multi-layer graphs. MGCN embeds nodes of multi-layer\ngraphs using both within and between layers relations and nodes attributes. We\nevaluate our method on the semi-supervised node classification task.\nExperimental results demonstrate the superiority of the proposed method to\nother multi-layer and single-layer competitors and also show the positive\neffect of using cross-layer edges.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:54:56 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 09:01:05 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 09:50:18 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Ghorbani", "Mahsa", ""], ["Baghshah", "Mahdieh Soleymani", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1811.08803", "submitter": "Luke O'Connor", "authors": "Luke J. O'Connor and Alkes L. Price", "title": "Distinguishing correlation from causation using genome-wide association\n  studies", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": "O'Connor, Luke J. and Alkes L. Price. \"Distinguishing genetic\n  correlation from causation across 52 diseases and complex traits.\" Nature\n  genetics (2018)", "doi": null, "report-no": "ML4H/2018/4", "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Genome-wide association studies (GWAS) have emerged as a rich source of\ngenetic clues into disease biology, and they have revealed strong genetic\ncorrelations among many diseases and traits. Some of these genetic correlations\nmay reflect causal relationships. We developed a method to quantify causal\nrelationships between genetically correlated traits using GWAS summary\nassociation statistics. In particular, our method quantifies what part of the\ngenetic component of trait 1 is also causal for trait 2 using mixed fourth\nmoments $E(\\alpha_1^2\\alpha_1\\alpha_2)$ and $E(\\alpha_2^2\\alpha_1\\alpha_2)$ of\nthe bivariate effect size distribution. If trait 1 is causal for trait 2, then\nSNPs affecting trait 1 (large $\\alpha_1^2$) will have correlated effects on\ntrait 2 (large $\\alpha_1\\alpha_2$), but not vice versa. We validated this\napproach in extensive simulations. Across 52 traits (average $N=331$k), we\nidentified 30 putative genetically causal relationships, many novel, including\nan effect of LDL cholesterol on decreased bone mineral density. More broadly,\nwe demonstrate that it is possible to distinguish between genetic correlation\nand causation using genetic association data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 16:01:51 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["O'Connor", "Luke J.", ""], ["Price", "Alkes L.", ""]]}, {"id": "1811.08812", "submitter": "Mahsa Ghorbani", "authors": "Ehsan Montahaei, Mahsa Ghorbani, Mahdieh Soleymani Baghshah, Hamid R.\n  Rabiee", "title": "Adversarial Classifier for Imbalanced Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial approach has been widely used for data generation in the last few\nyears. However, this approach has not been extensively utilized for classifier\ntraining. In this paper, we propose an adversarial framework for classifier\ntraining that can also handle imbalanced data. Indeed, a network is trained via\nan adversarial approach to give weights to samples of the majority class such\nthat the obtained classification problem becomes more challenging for the\ndiscriminator and thus boosts its classification capability. In addition to the\ngeneral imbalanced classification problems, the proposed method can also be\nused for problems such as graph representation learning in which it is desired\nto discriminate similar nodes from dissimilar nodes. Experimental results on\nimbalanced data classification and on the tasks like graph link prediction show\nthe superiority of the proposed method compared to the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 16:29:54 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Montahaei", "Ehsan", ""], ["Ghorbani", "Mahsa", ""], ["Baghshah", "Mahdieh Soleymani", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1811.08839", "submitter": "Anuroop Sriram", "authors": "Jure Zbontar, Florian Knoll, Anuroop Sriram, Tullie Murrell, Zhengnan\n  Huang, Matthew J. Muckley, Aaron Defazio, Ruben Stern, Patricia Johnson, Mary\n  Bruno, Marc Parente, Krzysztof J. Geras, Joe Katsnelson, Hersh Chandarana,\n  Zizhao Zhang, Michal Drozdzal, Adriana Romero, Michael Rabbat, Pascal\n  Vincent, Nafissa Yakubova, James Pinkerton, Duo Wang, Erich Owens, C.\n  Lawrence Zitnick, Michael P. Recht, Daniel K. Sodickson, Yvonne W. Lui", "title": "fastMRI: An Open Dataset and Benchmarks for Accelerated MRI", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements\nhas the potential to reduce medical costs, minimize stress to patients and make\nMRI possible in applications where it is currently prohibitively slow or\nexpensive. We introduce the fastMRI dataset, a large-scale collection of both\nraw MR measurements and clinical MR images, that can be used for training and\nevaluation of machine-learning approaches to MR image reconstruction. By\nintroducing standardized evaluation criteria and a freely-accessible dataset,\nour goal is to help the community make rapid advances in the state of the art\nfor MR image reconstruction. We also provide a self-contained introduction to\nMRI for machine learning researchers with no medical imaging background.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 17:32:14 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 10:31:39 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Zbontar", "Jure", ""], ["Knoll", "Florian", ""], ["Sriram", "Anuroop", ""], ["Murrell", "Tullie", ""], ["Huang", "Zhengnan", ""], ["Muckley", "Matthew J.", ""], ["Defazio", "Aaron", ""], ["Stern", "Ruben", ""], ["Johnson", "Patricia", ""], ["Bruno", "Mary", ""], ["Parente", "Marc", ""], ["Geras", "Krzysztof J.", ""], ["Katsnelson", "Joe", ""], ["Chandarana", "Hersh", ""], ["Zhang", "Zizhao", ""], ["Drozdzal", "Michal", ""], ["Romero", "Adriana", ""], ["Rabbat", "Michael", ""], ["Vincent", "Pascal", ""], ["Yakubova", "Nafissa", ""], ["Pinkerton", "James", ""], ["Wang", "Duo", ""], ["Owens", "Erich", ""], ["Zitnick", "C. Lawrence", ""], ["Recht", "Michael P.", ""], ["Sodickson", "Daniel K.", ""], ["Lui", "Yvonne W.", ""]]}, {"id": "1811.08840", "submitter": "Woochan Hwang", "authors": "Sejin Park, Woochan Hwang, Kyu-Hwan Jung", "title": "Integrating Reinforcement Learning to Self Training for Pulmonary Nodule\n  Segmentation in Chest X-rays", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/75", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications in medical imaging are frequently limited by\nthe lack of quality labeled data. In this paper, we explore the self training\nmethod, a form of semi-supervised learning, to address the labeling burden. By\nintegrating reinforcement learning, we were able to expand the application of\nself training to complex segmentation networks without any further human\nannotation. The proposed approach, reinforced self training (ReST), fine tunes\na semantic segmentation networks by introducing a policy network that learns to\ngenerate pseudolabels. We incorporate an expert demonstration network, based on\ninverse reinforcement learning, to enhance clinical validity and convergence of\nthe policy network. The model was tested on a pulmonary nodule segmentation\ntask in chest X-rays and achieved the performance of a standard U-Net while\nusing only 50% of the labeled data, by exploiting unlabeled data. When the same\nnumber of labeled data was used, a moderate to significant cross validation\naccuracy improvement was achieved depending on the absolute number of labels\nused.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 17:37:22 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Park", "Sejin", ""], ["Hwang", "Woochan", ""], ["Jung", "Kyu-Hwan", ""]]}, {"id": "1811.08871", "submitter": "Shali Jiang", "authors": "Shali Jiang, Gustavo Malkomes, Benjamin Moseley, Roman Garnett", "title": "Efficient nonmyopic active search with applications in drug and\n  materials discovery", "comments": "Machine Learning for Molecules and Materials (NeurIPS 2018 Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active search is a learning paradigm for actively identifying as many members\nof a given class as possible. A critical target scenario is high-throughput\nscreening for scientific discovery, such as drug or materials discovery. In\nthis paper, we approach this problem in Bayesian decision framework. We first\nderive the Bayesian optimal policy under a natural utility, and establish a\ntheoretical hardness of active search, proving that the optimal policy can not\nbe approximated for any constant ratio. We also study the batch setting for the\nfirst time, where a batch of $b>1$ points can be queried at each iteration. We\ngive an asymptotic lower bound, linear in batch size, on the adaptivity gap:\nhow much we could lose if we query $b$ points at a time for $t$ iterations,\ninstead of one point at a time for $bt$ iterations. We then introduce a novel\napproach to nonmyopic approximations of the optimal policy that admits\nefficient computation. Our proposed policy can automatically trade off\nexploration and exploitation, without relying on any tuning parameters. We also\ngeneralize our policy to batch setting, and propose two approaches to tackle\nthe combinatorial search challenge. We evaluate our proposed policies on a\nlarge database of drug discovery and materials science. Results demonstrate the\nsuperior performance of our proposed policy in both sequential and batch\nsetting; the nonmyopic behavior is also illustrated in various aspects.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 18:32:33 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 20:26:28 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Jiang", "Shali", ""], ["Malkomes", "Gustavo", ""], ["Moseley", "Benjamin", ""], ["Garnett", "Roman", ""]]}, {"id": "1811.08888", "submitter": "Quanquan Gu", "authors": "Difan Zou, Yuan Cao, Dongruo Zhou, Quanquan Gu", "title": "Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU\n  Networks", "comments": "54 pages. This version relaxes the assumptions on the loss functions\n  and data distribution, and improves the dependency on the problem-specific\n  parameters in the main theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of training deep neural networks with Rectified Linear\nUnit (ReLU) activation function using gradient descent and stochastic gradient\ndescent. In particular, we study the binary classification problem and show\nthat for a broad family of loss functions, with proper random weight\ninitialization, both gradient descent and stochastic gradient descent can find\nthe global minima of the training loss for an over-parameterized deep ReLU\nnetwork, under mild assumption on the training data. The key idea of our proof\nis that Gaussian random initialization followed by (stochastic) gradient\ndescent produces a sequence of iterates that stay inside a small perturbation\nregion centering around the initial weights, in which the empirical loss\nfunction of deep ReLU networks enjoys nice local curvature properties that\nensure the global convergence of (stochastic) gradient descent. Our theoretical\nresults shed light on understanding the optimization for deep learning, and\npave the way for studying the optimization dynamics of training modern deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 18:58:46 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 18:44:38 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 18:57:43 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Zou", "Difan", ""], ["Cao", "Yuan", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "1811.08890", "submitter": "Nils Holzenberger", "authors": "Nils Holzenberger, Shruti Palaskar, Pranava Madhyastha, Florian Metze,\n  Raman Arora", "title": "Learning from Multiview Correlations in Open-Domain Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of datasets contain multiple views, such as video, sound\nand automatic captions. A basic challenge in representation learning is how to\nleverage multiple views to learn better representations. This is further\ncomplicated by the existence of a latent alignment between views, such as\nbetween speech and its transcription, and by the multitude of choices for the\nlearning objective. We explore an advanced, correlation-based representation\nlearning method on a 4-way parallel, multimodal dataset, and assess the quality\nof the learned representations on retrieval-based tasks. We show that the\nproposed approach produces rich representations that capture most of the\ninformation shared across views. Our best models for speech and textual\nmodalities achieve retrieval rates from 70.7% to 96.9% on open-domain,\nuser-generated instructional videos. This shows it is possible to learn\nreliable representations across disparate, unaligned and noisy modalities, and\nencourages using the proposed approach on larger datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 19:57:11 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 18:21:28 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Holzenberger", "Nils", ""], ["Palaskar", "Shruti", ""], ["Madhyastha", "Pranava", ""], ["Metze", "Florian", ""], ["Arora", "Raman", ""]]}, {"id": "1811.08919", "submitter": "Xu Chen", "authors": "Xu Chen, Saratendu Sethi", "title": "Robust Active Learning for Electrocardiographic Signal Classification", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216 3", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/5", "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of electrocardiographic (ECG) signals is a challenging\nproblem for healthcare industry. Traditional supervised learning methods\nrequire a large number of labeled data which is usually expensive and difficult\nto obtain for ECG signals. Active learning is well-suited for ECG signal\nclassification as it aims at selecting the best set of labeled data in order to\nmaximize the classification performance. Motivated by the fact that ECG data\nare usually heavily unbalanced among different classes and the class labels are\nnoisy as they are manually labeled, this paper proposes a novel solution based\non robust active learning for addressing these challenges. The key idea is to\nfirst apply the clustering of the data in a low dimensional embedded space and\nthen select the most information instances within local clusters. By selecting\nthe most informative instances relying on local average minimal distances, the\nalgorithm tends to select the data for labelling in a more diversified way.\nFinally, the robustness of the model is further enhanced by adding a novel\nnoisy label reduction scheme after the selection of the labeled data.\nExperiments on the ECG signal classification from the MIT-BIH arrhythmia\ndatabase demonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 19:24:59 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Chen", "Xu", ""], ["Sethi", "Saratendu", ""]]}, {"id": "1811.08929", "submitter": "Changyou Chen", "authors": "Yang Zhao and Jianyi Zhang and Changyou Chen", "title": "Self-Adversarially Learned Bayesian Sampling", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable Bayesian sampling is playing an important role in modern machine\nlearning, especially in the fast-developed unsupervised-(deep)-learning models.\nWhile tremendous progresses have been achieved via scalable Bayesian sampling\nsuch as stochastic gradient MCMC (SG-MCMC) and Stein variational gradient\ndescent (SVGD), the generated samples are typically highly correlated.\nMoreover, their sample-generation processes are often criticized to be\ninefficient. In this paper, we propose a novel self-adversarial learning\nframework that automatically learns a conditional generator to mimic the\nbehavior of a Markov kernel (transition kernel). High-quality samples can be\nefficiently generated by direct forward passes though a learned generator. Most\nimportantly, the learning process adopts a self-learning paradigm, requiring no\ninformation on existing Markov kernels, e.g., knowledge of how to draw samples\nfrom them. Specifically, our framework learns to use current samples, either\nfrom the generator or pre-provided training data, to update the generator such\nthat the generated samples progressively approach a target distribution, thus\nit is called self-learning. Experiments on both synthetic and real datasets\nverify advantages of our framework, outperforming related methods in terms of\nboth sampling efficiency and sample quality.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 20:03:05 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Zhao", "Yang", ""], ["Zhang", "Jianyi", ""], ["Chen", "Changyou", ""]]}, {"id": "1811.08943", "submitter": "Changhee Lee", "authors": "Changhee Lee, Nicholas Mastronarde, Mihaela van der Schaar", "title": "Estimation of Individual Treatment Effect in Latent Confounder Models\n  via Adversarial Learning", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/33", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the individual treatment effect (ITE) from observational data is\nessential in medicine. A central challenge in estimating the ITE is handling\nconfounders, which are factors that affect both an intervention and its\noutcome. Most previous work relies on the unconfoundedness assumption, which\nposits that all the confounders are measured in the observational data.\nHowever, if there are unmeasurable (latent) confounders, then confounding bias\nis introduced. Fortunately, noisy proxies for the latent confounders are often\navailable and can be used to make an unbiased estimate of the ITE. In this\npaper, we develop a novel adversarial learning framework to make unbiased\nestimates of the ITE using noisy proxies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 20:46:27 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Lee", "Changhee", ""], ["Mastronarde", "Nicholas", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1811.08963", "submitter": "Ganapathy Natarajan", "authors": "Ganapathy S. Natarajan and Aishwarya Ashok", "title": "Multivariate Forecasting of Crude Oil Spot Prices using Neural Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crude oil is a major component in most advanced economies of the world.\nAccurately predicting and understanding the behavior of crude oil prices is\nimportant for economists, analysts, forecasters, and traders, to name a few.\nThe price of crude oil has declined in the past decade and is seeing a phase of\nstability; but will this stability last? This work is an empirical study on how\nmultivariate analysis may be employed to predict crude oil spot prices using\nneural networks. The concept of using neural networks showed promising\npotential. A very simple neural network model was able to perform on par with\nARIMA models - the state-of-the-art model in time-series forecasting. Advanced\nneural network models using larger datasets may be used in the future to extend\nthis proof-of-concept to a full scale framework.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 21:45:52 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Natarajan", "Ganapathy S.", ""], ["Ashok", "Aishwarya", ""]]}, {"id": "1811.08968", "submitter": "Mingtian Zhang", "authors": "Mingtian Zhang, Peter Hayes, Tom Bird, Raza Habib, David Barber", "title": "Spread Divergences", "comments": null, "journal-ref": "Volume 119: International Conference on Machine Learning, 13-18\n  July 2020, Virtual", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For distributions p and q with different supports, the divergence D(p|q) may\nnot exist. We define a spread divergence on modified p and q and describe\nsufficient conditions for the existence of such a divergence. We demonstrate\nhow to maximize the discriminatory power of a given divergence by\nparameterizing and learning the spread. We also give examples of using a spread\ndivergence to train and improve implicit generative models, including linear\nmodels (Independent Components Analysis) and non-linear models (Deep Generative\nNetworks).\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 22:35:08 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 10:29:46 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 13:32:11 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 03:07:02 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Zhang", "Mingtian", ""], ["Hayes", "Peter", ""], ["Bird", "Tom", ""], ["Habib", "Raza", ""], ["Barber", "David", ""]]}, {"id": "1811.08979", "submitter": "Xiangxiang Xu", "authors": "Lichen Wang, Jiaxiang Wu, Shao-Lun Huang, Lizhong Zheng, Xiangxiang\n  Xu, Lin Zhang, Junzhou Huang", "title": "An Efficient Approach to Informative Feature Extraction from Multimodal\n  Data", "comments": "accepted to AAAI 2019, 8 pages; typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One primary focus in multimodal feature extraction is to find the\nrepresentations of individual modalities that are maximally correlated. As a\nwell-known measure of dependence, the Hirschfeld-Gebelein-R\\'{e}nyi (HGR)\nmaximal correlation becomes an appealing objective because of its operational\nmeaning and desirable properties. However, the strict whitening constraints\nformalized in the HGR maximal correlation limit its application. To address\nthis problem, this paper proposes Soft-HGR, a novel framework to extract\ninformative features from multiple data modalities. Specifically, our framework\nprevents the \"hard\" whitening constraints, while simultaneously preserving the\nsame feature geometry as in the HGR maximal correlation. The objective of\nSoft-HGR is straightforward, only involving two inner products, which\nguarantees the efficiency and stability in optimization. We further generalize\nthe framework to handle more than two modalities and missing modalities. When\nlabels are partially available, we enhance the discriminative power of the\nfeature representations by making a semi-supervised adaptation. Empirical\nevaluation implies that our approach learns more informative feature mappings\nand is more efficient to optimize.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 00:43:12 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 05:21:40 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Wang", "Lichen", ""], ["Wu", "Jiaxiang", ""], ["Huang", "Shao-Lun", ""], ["Zheng", "Lizhong", ""], ["Xu", "Xiangxiang", ""], ["Zhang", "Lin", ""], ["Huang", "Junzhou", ""]]}, {"id": "1811.08990", "submitter": "Tao Sun", "authors": "Tao Sun, Yuejiao Sun, Yangyang Xu, Wotao Yin", "title": "Markov Chain Block Coordinate Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of block coordinate gradient descent (BCD) has been a powerful\nmethod for large-scale optimization. This paper considers the BCD method that\nsuccessively updates a series of blocks selected according to a Markov chain.\nThis kind of block selection is neither i.i.d. random nor cyclic. On the other\nhand, it is a natural choice for some applications in distributed optimization\nand Markov decision process, where i.i.d. random and cyclic selections are\neither infeasible or very expensive. By applying mixing-time properties of a\nMarkov chain, we prove convergence of Markov chain BCD for minimizing Lipschitz\ndifferentiable functions, which can be nonconvex. When the functions are convex\nand strongly convex, we establish both sublinear and linear convergence rates,\nrespectively. We also present a method of Markov chain inertial BCD. Finally,\nwe discuss potential applications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 01:51:15 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Sun", "Tao", ""], ["Sun", "Yuejiao", ""], ["Xu", "Yangyang", ""], ["Yin", "Wotao", ""]]}, {"id": "1811.08996", "submitter": "Shipeng Wang", "authors": "Shipeng Wang, Jian Sun and Zongben Xu", "title": "HyperAdam: A Learnable Task-Adaptive Adam for Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are traditionally trained using human-designed\nstochastic optimization algorithms, such as SGD and Adam. Recently, the\napproach of learning to optimize network parameters has emerged as a promising\nresearch topic. However, these learned black-box optimizers sometimes do not\nfully utilize the experience in human-designed optimizers, therefore have\nlimitation in generalization ability. In this paper, a new optimizer, dubbed as\n\\textit{HyperAdam}, is proposed that combines the idea of \"learning to\noptimize\" and traditional Adam optimizer. Given a network for training, its\nparameter update in each iteration generated by HyperAdam is an adaptive\ncombination of multiple updates generated by Adam with varying decay rates. The\ncombination weights and decay rates in HyperAdam are adaptively learned\ndepending on the task. HyperAdam is modeled as a recurrent neural network with\nAdamCell, WeightCell and StateCell. It is justified to be state-of-the-art for\nvarious network training, such as multilayer perceptron, CNN and LSTM.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 02:37:53 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wang", "Shipeng", ""], ["Sun", "Jian", ""], ["Xu", "Zongben", ""]]}, {"id": "1811.09003", "submitter": "Fenglei Fan", "authors": "Fenglei Fan, Dayang Wang, Hengtao Guo, Qikui Zhu, Pingkun Yan, Ge Wang\n  and Hengyong Yu", "title": "On a Sparse Shortcut Topology of Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over recent years, deep learning has become the mainstream data-driven\napproach to solve many important real-world problems. In the successful network\narchitectures, shortcut connections are well established to take the outputs of\nearlier layers as additional inputs to later layers, which have produced\nexcellent results. Despite the extraordinary effectiveness of shortcuts, there\nremain important questions on the underlying mechanism and associated\nfunctionalities. For example, why are shortcuts powerful? Why shortcuts\ngeneralize well? To address these questions, we investigate the representation\nand generalization ability of a sparse shortcut topology. Specifically, we\nfirst demonstrate that this topology can empower a one-neuron-wide deep network\nto approximate any univariate continuous function. Then, we present a novel\nwidth-bounded universal approximator in contrast to depth-bounded universal\napproximators, and also extend the approximation result to a family of networks\nsuch that in the view of approximation ability, these networks are equally\ncompetent. Furthermore, we use the generalization bound theory to show that the\ninvestigated shortcut topology enjoys an excellent generalizability. Finally,\nwe corroborate our theoretical analyses with experiments on some well-known\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 03:23:44 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 03:07:46 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 02:51:08 GMT"}, {"version": "v4", "created": "Thu, 17 Jun 2021 17:58:33 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Fan", "Fenglei", ""], ["Wang", "Dayang", ""], ["Guo", "Hengtao", ""], ["Zhu", "Qikui", ""], ["Yan", "Pingkun", ""], ["Wang", "Ge", ""], ["Yu", "Hengyong", ""]]}, {"id": "1811.09008", "submitter": "Dong Eui Chang", "authors": "Muhammad Usama, Dong Eui Chang", "title": "Towards Robust Neural Networks with Lipschitz Continuity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown remarkable performance across a wide range of\nvision-based tasks, particularly due to the availability of large-scale\ndatasets for training and better architectures. However, data seen in the real\nworld are often affected by distortions that not accounted for by the training\ndatasets. In this paper, we address the challenge of robustness and stability\nof neural networks and propose a general training method that can be used to\nmake the existing neural network architectures more robust and stable to input\nvisual perturbations while using only available datasets for training. Proposed\ntraining method is convenient to use as it does not require data augmentation\nor changes in the network architecture. We provide theoretical proof as well as\nempirical evidence for the efficiency of the proposed training method by\nperforming experiments with existing neural network architectures and\ndemonstrate that same architecture when trained with the proposed training\nmethod perform better than when trained with conventional training approach in\nthe presence of noisy datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 03:42:17 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Usama", "Muhammad", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1811.09013", "submitter": "Eric Graves", "authors": "Ehsan Imani, Eric Graves, Martha White", "title": "An Off-policy Policy Gradient Theorem Using Emphatic Weightings", "comments": "Updated to final NeurIPS version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are widely used for control in reinforcement\nlearning, particularly for the continuous action setting. There have been a\nhost of theoretically sound algorithms proposed for the on-policy setting, due\nto the existence of the policy gradient theorem which provides a simplified\nform for the gradient. In off-policy learning, however, where the behaviour\npolicy is not necessarily attempting to learn and follow the optimal policy for\nthe given task, the existence of such a theorem has been elusive. In this work,\nwe solve this open problem by providing the first off-policy policy gradient\ntheorem. The key to the derivation is the use of $emphatic$ $weightings$. We\ndevelop a new actor-critic algorithm$\\unicode{x2014}$called Actor Critic with\nEmphatic weightings (ACE)$\\unicode{x2014}$that approximates the simplified\ngradients provided by the theorem. We demonstrate in a simple counterexample\nthat previous off-policy policy gradient methods$\\unicode{x2014}$particularly\nOffPAC and DPG$\\unicode{x2014}$converge to the wrong solution whereas ACE finds\nthe optimal solution.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 03:58:11 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 04:58:36 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Imani", "Ehsan", ""], ["Graves", "Eric", ""], ["White", "Martha", ""]]}, {"id": "1811.09026", "submitter": "Priyank Agrawal", "authors": "Priyank Agrawal and Theja Tulabandhula", "title": "Bandits with Temporal Stochastic Constraints", "comments": "An extended abstract appeared in the 4th Multi-disciplinary\n  Conference on Reinforcement Learning and Decision Making (RLDM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of impairment on stochastic multi-armed bandits and\ndevelop new ways to mitigate it. Impairment effect is the phenomena where an\nagent only accrues reward for an action if they have played it at least a few\ntimes in the recent past. It is practically motivated by repetition and recency\neffects in domains such as advertising (here consumer behavior may require\nrepeat actions by advertisers) and vocational training (here actions are\ncomplex skills that can only be mastered with repetition to get a payoff).\nImpairment can be naturally modelled as a temporal constraint on the strategy\nspace, and we provide two novel algorithms that achieve sublinear regret, each\nworking with different assumptions on the impairment effect. We introduce a new\nnotion called bucketing in our algorithm design, and show how it can\neffectively address impairment as well as a broader class of temporal\nconstraints. Our regret bounds explicitly capture the cost of impairment and\nshow that it scales (sub-)linearly with the degree of impairment. Our work\ncomplements recent work on modeling delays and corruptions, and we provide\nexperimental evidence supporting our claims.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 05:40:53 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 01:24:54 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Agrawal", "Priyank", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1811.09054", "submitter": "Ke Wang", "authors": "Jian-Feng Cai, Dong Li, Jiaze Sun, Ke Wang", "title": "Enhanced Expressive Power and Fast Training of Neural Networks by Random\n  Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random projections are able to perform dimension reduction efficiently for\ndatasets with nonlinear low-dimensional structures. One well-known example is\nthat random matrices embed sparse vectors into a low-dimensional subspace\nnearly isometrically, known as the restricted isometric property in compressed\nsensing. In this paper, we explore some applications of random projections in\ndeep neural networks. We provide the expressive power of fully connected neural\nnetworks when the input data are sparse vectors or form a low-dimensional\nsmooth manifold. We prove that the number of neurons required for approximating\na Lipschitz function with a prescribed precision depends on the sparsity or the\ndimension of the manifold and weakly on the dimension of the input vector. The\nkey in our proof is that random projections embed stably the set of sparse\nvectors or a low-dimensional smooth manifold into a low-dimensional subspace.\nBased on this fact, we also propose some new neural network models, where at\neach layer the input is first projected onto a low-dimensional subspace by a\nrandom projection and then the standard linear connection and non-linear\nactivation are applied. In this way, the number of parameters in neural\nnetworks is significantly reduced, and therefore the training of neural\nnetworks can be accelerated without too much performance loss.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 07:52:56 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 10:35:19 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Cai", "Jian-Feng", ""], ["Li", "Dong", ""], ["Sun", "Jiaze", ""], ["Wang", "Ke", ""]]}, {"id": "1811.09065", "submitter": "Oleg Sysoev", "authors": "Oleg Sysoev, Krzysztof Bartoszek, Eva-Charlotte Ekstrom, Katarina\n  Ekholm Selling", "title": "PSICA: decision trees for probabilistic subgroup identification with\n  categorical treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized medicine aims at identifying best treatments for a patient with\ngiven characteristics. It has been shown in the literature that these methods\ncan lead to great improvements in medicine compared to traditional methods\nprescribing the same treatment to all patients. Subgroup identification is a\nbranch of personalized medicine which aims at finding subgroups of the patients\nwith similar characteristics for which some of the investigated treatments have\na better effect than the other treatments. A number of approaches based on\ndecision trees has been proposed to identify such subgroups, but most of them\nfocus on the two-arm trials (control/treatment) while a few methods consider\nquantitative treatments (defined by the dose). However, no subgroup\nidentification method exists that can predict the best treatments in a scenario\nwith a categorical set of treatments. We propose a novel method for subgroup\nidentification in categorical treatment scenarios. This method outputs a\ndecision tree showing the probabilities of a given treatment being the best for\na given group of patients as well as labels showing the possible best\ntreatments. The method is implemented in an R package \\textbf{psica} available\nat CRAN. In addition to numerical simulations based on artificial data, we\npresent an analysis of a community-based nutrition intervention trial that\njustifies the validity of our method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 09:08:22 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Sysoev", "Oleg", ""], ["Bartoszek", "Krzysztof", ""], ["Ekstrom", "Eva-Charlotte", ""], ["Selling", "Katarina Ekholm", ""]]}, {"id": "1811.09067", "submitter": "Kehinde Owoeye Mr", "authors": "Kehinde Owoeye and Stephen Hailes", "title": "Online Collective Animal Movement Activity Recognition", "comments": "5 pages, 2 figures, To be presented at the Workshop on Modeling and\n  Decision-Making in the Spatiotemporal Domain, 32nd Conference on Neural\n  Information Processing Systems (NIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the activities of animals is important for the purpose of monitoring\ntheir welfare vis a vis their behaviour with respect to their environment and\nconspecifics. While previous works have largely focused on activity recognition\nin a single animal, little or no work has been done in learning the collective\nbehaviour of animals. In this work, we address the problem of recognising the\ncollective movement activities of a group of sheep in a flock. We present a\ndiscriminative framework that learns to track the positions and velocities of\nall the animals in the flock in an online manner whilst estimating their\ncollective activity. We investigate the performance of two simple deep network\narchitectures and show that we can learn the collective activities with good\naccuracy even when the distribution of the activities is skewed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 09:14:24 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Owoeye", "Kehinde", ""], ["Hailes", "Stephen", ""]]}, {"id": "1811.09083", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Emily Denton, Arthur Szlam and Rob Fergus", "title": "Learning Goal Embeddings via Self-Play for Hierarchical Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hierarchical reinforcement learning a major challenge is determining\nappropriate low-level policies. We propose an unsupervised learning scheme,\nbased on asymmetric self-play from Sukhbaatar et al. (2018), that automatically\nlearns a good representation of sub-goals in the environment and a low-level\npolicy that can execute them. A high-level policy can then direct the lower one\nby generating a sequence of continuous sub-goal vectors. We evaluate our model\nusing Mazebase and Mujoco environments, including the challenging AntGather\ntask. Visualizations of the sub-goal embeddings reveal a logical decomposition\nof tasks within the environment. Quantitatively, our approach obtains\ncompelling performance gains over non-hierarchical approaches.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 10:15:52 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Denton", "Emily", ""], ["Szlam", "Arthur", ""], ["Fergus", "Rob", ""]]}, {"id": "1811.09112", "submitter": "Philipp Marquetand", "authors": "Julia Westermayr, Michael Gastegger, Maximilian F. S. J. Menger,\n  Sebastian Mai, Leticia Gonz\\'alez, Philipp Marquetand", "title": "Machine learning enables long time scale molecular photodynamics\n  simulations", "comments": null, "journal-ref": null, "doi": "10.1039/C9SC01742A", "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photo-induced processes are fundamental in nature, but accurate simulations\nare seriously limited by the cost of the underlying quantum chemical\ncalculations, hampering their application for long time scales. Here we\nintroduce a method based on machine learning to overcome this bottleneck and\nenable accurate photodynamics on nanosecond time scales, which are otherwise\nout of reach with contemporary approaches. Instead of expensive quantum\nchemistry during molecular dynamics simulations, we use deep neural networks to\nlearn the relationship between a molecular geometry and its high-dimensional\nelectronic properties. As an example, the time evolution of the\nmethylenimmonium cation for one nanosecond is used to demonstrate that machine\nlearning algorithms can outperform standard excited-state molecular dynamics\napproaches in their computational efficiency while delivering the same\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 11:07:33 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 15:02:23 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Westermayr", "Julia", ""], ["Gastegger", "Michael", ""], ["Menger", "Maximilian F. S. J.", ""], ["Mai", "Sebastian", ""], ["Gonz\u00e1lez", "Leticia", ""], ["Marquetand", "Philipp", ""]]}, {"id": "1811.09236", "submitter": "Nikolay Jetchev", "authors": "Nikolay Jetchev, Urs Bergmann, Gokhan Yildirim", "title": "Copy the Old or Paint Anew? An Adversarial Framework for (non-)\n  Parametric Image Stylization", "comments": "Accepted at the NIPS 2018 workshop on Machine Learning for Creativity\n  and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric generative deep models are state-of-the-art for photo and\nnon-photo realistic image stylization. However, learning complicated image\nrepresentations requires compute-intense models parametrized by a huge number\nof weights, which in turn requires large datasets to make learning successful.\nNon-parametric exemplar-based generation is a technique that works well to\nreproduce style from small datasets, but is also compute-intensive. These\naspects are a drawback for the practice of digital AI artists: typically one\nwants to use a small set of stylization images, and needs a fast flexible model\nin order to experiment with it. With this motivation, our work has these\ncontributions: (i) a novel stylization method called Fully Adversarial Mosaics\n(FAMOS) that combines the strengths of both parametric and non-parametric\napproaches; (ii) multiple ablations and image examples that analyze the method\nand show its capabilities; (iii) source code that will empower artists and\nmachine learning researchers to use and modify FAMOS.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 16:54:12 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Jetchev", "Nikolay", ""], ["Bergmann", "Urs", ""], ["Yildirim", "Gokhan", ""]]}, {"id": "1811.09271", "submitter": "Mehmet Emre Ozfatura", "authors": "Emre Ozfatura and Sennur Ulukus and Deniz Gunduz", "title": "Distributed Gradient Descent with Coded Partial Gradient Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coded computation techniques provide robustness against straggling servers in\ndistributed computing, with the following limitations: First, they increase\ndecoding complexity. Second, they ignore computations carried out by straggling\nservers; and they are typically designed to recover the full gradient, and\nthus, cannot provide a balance between the accuracy of the gradient and\nper-iteration completion time. Here we introduce a hybrid approach, called\ncoded partial gradient computation (CPGC), that benefits from the advantages of\nboth coded and uncoded computation schemes, and reduces both the computation\ntime and decoding complexity.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 18:39:40 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Ozfatura", "Emre", ""], ["Ulukus", "Sennur", ""], ["Gunduz", "Deniz", ""]]}, {"id": "1811.09317", "submitter": "Carl Rietschel", "authors": "Carl Rietschel, Jinsung Yoon, Mihaela van der Schaar", "title": "Feature Selection for Survival Analysis with Competing Risks using Deep\n  Learning", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/35", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models for survival analysis have gained significant attention\nin the literature, but they suffer from severe performance deficits when the\ndataset contains many irrelevant features. We give empirical evidence for this\nproblem in real-world medical settings using the state-of-the-art model\nDeepHit. Furthermore, we develop methods to improve the deep learning model\nthrough novel approaches to feature selection in survival analysis. We propose\nfilter methods for hard feature selection and a neural network architecture\nthat weights features for soft feature selection. Our experiments on two\nreal-world medical datasets demonstrate that substantial performance\nimprovements against the original models are achievable.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 22:25:46 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 15:34:05 GMT"}, {"version": "v3", "created": "Wed, 16 Jan 2019 01:31:58 GMT"}, {"version": "v4", "created": "Thu, 7 Mar 2019 15:16:53 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Rietschel", "Carl", ""], ["Yoon", "Jinsung", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1811.09350", "submitter": "Rafael Sousa", "authors": "Rafael T. Sousa, Lucas A. Pereira, Anderson S. Soares", "title": "Predicting Diabetes Disease Evolution Using Financial Records and\n  Recurrent Neural Networks", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/70", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managing patients with chronic diseases is a major and growing healthcare\nchallenge in several countries. A chronic condition, such as diabetes, is an\nillness that lasts a long time and does not go away, and often leads to the\npatient's health gradually getting worse. While recent works involve raw\nelectronic health record (EHR) from hospitals, this work uses only financial\nrecords from health plan providers (medical claims) to predict diabetes disease\nevolution with a self-attentive recurrent neural network. The use of financial\ndata is due to the possibility of being an interface to international\nstandards, as the records standard encodes medical procedures. The main goal\nwas to assess high risk diabetics, so we predict records related to diabetes\nacute complications such as amputations and debridements, revascularization and\nhemodialysis. Our work succeeds to anticipate complications between 60 to 240\ndays with an area under ROC curve ranging from 0.81 to 0.94. In this paper we\ndescribe the first half of a work-in-progress developed within a health plan\nprovider with ROC curve ranging from 0.81 to 0.83. This assessment will give\nhealthcare providers the chance to intervene earlier and head off\nhospitalizations. We are aiming to deliver personalized predictions and\npersonalized recommendations to individual patients, with the goal of improving\noutcomes and reducing costs\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 03:15:05 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 14:21:19 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Sousa", "Rafael T.", ""], ["Pereira", "Lucas A.", ""], ["Soares", "Anderson S.", ""]]}, {"id": "1811.09358", "submitter": "Li Shen", "authors": "Fangyu Zou, Li Shen, Zequn Jie, Weizhong Zhang and Wei Liu", "title": "A Sufficient Condition for Convergences of Adam and RMSProp", "comments": "Accepted by CVPR2019 as an Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam and RMSProp are two of the most influential adaptive stochastic\nalgorithms for training deep neural networks, which have been pointed out to be\ndivergent even in the convex setting via a few simple counterexamples. Many\nattempts, such as decreasing an adaptive learning rate, adopting a big batch\nsize, incorporating a temporal decorrelation technique, seeking an analogous\nsurrogate, etc., have been tried to promote Adam/RMSProp-type algorithms to\nconverge. In contrast with existing approaches, we introduce an alternative\neasy-to-check sufficient condition, which merely depends on the parameters of\nthe base learning rate and combinations of historical second-order moments, to\nguarantee the global convergence of generic Adam/RMSProp for solving\nlarge-scale non-convex stochastic optimization. Moreover, we show that the\nconvergences of several variants of Adam, such as AdamNC, AdaEMA, etc., can be\ndirectly implied via the proposed sufficient condition in the non-convex\nsetting. In addition, we illustrate that Adam is essentially a specifically\nweighted AdaGrad with exponential moving average momentum, which provides a\nnovel perspective for understanding Adam and RMSProp. This observation coupled\nwith this sufficient condition gives much deeper interpretations on their\ndivergences. At last, we validate the sufficient condition by applying Adam and\nRMSProp to tackle a certain counterexample and train deep neural networks.\nNumerical results are exactly in accord with our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 04:26:47 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 08:59:14 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 03:39:53 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zou", "Fangyu", ""], ["Shen", "Li", ""], ["Jie", "Zequn", ""], ["Zhang", "Weizhong", ""], ["Liu", "Wei", ""]]}, {"id": "1811.09380", "submitter": "Yu Cheng", "authors": "Yu Cheng, Ilias Diakonikolas, Rong Ge", "title": "High-Dimensional Robust Mean Estimation in Nearly-Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of high-dimensional mean estimation in a\nrobust model where a constant fraction of the samples are adversarially\ncorrupted. Recent work gave the first polynomial time algorithms for this\nproblem with dimension-independent error guarantees for several families of\nstructured distributions.\n  In this work, we give the first nearly-linear time algorithms for\nhigh-dimensional robust mean estimation. Specifically, we focus on\ndistributions with (i) known covariance and sub-gaussian tails, and (ii)\nunknown bounded covariance. Given $N$ samples on $\\mathbb{R}^d$, an\n$\\epsilon$-fraction of which may be arbitrarily corrupted, our algorithms run\nin time $\\tilde{O}(Nd) / \\mathrm{poly}(\\epsilon)$ and approximate the true mean\nwithin the information-theoretically optimal error, up to constant factors.\nPrevious robust algorithms with comparable error guarantees have running times\n$\\tilde{\\Omega}(N d^2)$, for $\\epsilon = \\Omega(1)$.\n  Our algorithms rely on a natural family of SDPs parameterized by our current\nguess $\\nu$ for the unknown mean $\\mu^\\star$. We give a win-win analysis\nestablishing the following: either a near-optimal solution to the primal SDP\nyields a good candidate for $\\mu^\\star$ -- independent of our current guess\n$\\nu$ -- or the dual SDP yields a new guess $\\nu'$ whose distance from\n$\\mu^\\star$ is smaller by a constant factor. We exploit the special structure\nof the corresponding SDPs to show that they are approximately solvable in\nnearly-linear time. Our approach is quite general, and we believe it can also\nbe applied to obtain nearly-linear time algorithms for other high-dimensional\nrobust learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 07:51:35 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Cheng", "Yu", ""], ["Diakonikolas", "Ilias", ""], ["Ge", "Rong", ""]]}, {"id": "1811.09385", "submitter": "Jishnu Mukhoti", "authors": "Jishnu Mukhoti, Pontus Stenetorp, Yarin Gal", "title": "On the Importance of Strong Baselines in Bayesian Deep Learning", "comments": "Bayesian Deep Learning Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like all sub-fields of machine learning Bayesian Deep Learning is driven by\nempirical validation of its theoretical proposals. Given the many aspects of an\nexperiment it is always possible that minor or even major experimental flaws\ncan slip by both authors and reviewers. One of the most popular experiments\nused to evaluate approximate inference techniques is the regression experiment\non UCI datasets. However, in this experiment, models which have been trained to\nconvergence have often been compared with baselines trained only for a fixed\nnumber of iterations. We find that a well-established baseline, Monte Carlo\ndropout, when evaluated under the same experimental settings shows significant\nimprovements. In fact, the baseline outperforms or performs competitively with\nmethods that claimed to be superior to the very same baseline method when they\nwere introduced. Hence, by exposing this flaw in experimental procedure, we\nhighlight the importance of using identical experimental setups to evaluate,\ncompare, and benchmark methods in Bayesian Deep Learning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 08:22:17 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 19:13:36 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Mukhoti", "Jishnu", ""], ["Stenetorp", "Pontus", ""], ["Gal", "Yarin", ""]]}, {"id": "1811.09409", "submitter": "Florian Pfisterer", "authors": "Florian Pfisterer and Jan N. van Rijn and Philipp Probst and Andreas\n  M\\\"uller and Bernd Bischl", "title": "Learning Multiple Defaults for Machine Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of modern machine learning methods highly depends on their\nhyperparameter configurations. One simple way of selecting a configuration is\nto use default settings, often proposed along with the publication and\nimplementation of a new algorithm. Those default values are usually chosen in\nan ad-hoc manner to work good enough on a wide variety of datasets. To address\nthis problem, different automatic hyperparameter configuration algorithms have\nbeen proposed, which select an optimal configuration per dataset. This\nprincipled approach usually improves performance but adds additional\nalgorithmic complexity and computational costs to the training procedure. As an\nalternative to this, we propose learning a set of complementary default values\nfrom a large database of prior empirical results. Selecting an appropriate\nconfiguration on a new dataset then requires only a simple, efficient and\nembarrassingly parallel search over this set. We demonstrate the effectiveness\nand efficiency of the approach we propose in comparison to random search and\nBayesian Optimization.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 09:48:19 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 11:04:27 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 06:57:13 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Pfisterer", "Florian", ""], ["van Rijn", "Jan N.", ""], ["Probst", "Philipp", ""], ["M\u00fcller", "Andreas", ""], ["Bischl", "Bernd", ""]]}, {"id": "1811.09469", "submitter": "\\\"Omer Deniz Akyildiz", "authors": "\\\"Omer Deniz Akyildiz, Dan Crisan, Joaqu\\'in M\\'iguez", "title": "Parallel sequential Monte Carlo for stochastic gradient-free nonconvex\n  optimization", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze a parallel sequential Monte Carlo methodology for\nthe numerical solution of optimization problems that involve the minimization\nof a cost function that consists of the sum of many individual components. The\nproposed scheme is a stochastic zeroth order optimization algorithm which\ndemands only the capability to evaluate small subsets of components of the cost\nfunction. It can be depicted as a bank of samplers that generate particle\napproximations of several sequences of probability measures. These measures are\nconstructed in such a way that they have associated probability density\nfunctions whose global maxima coincide with the global minima of the original\ncost function. The algorithm selects the best performing sampler and uses it to\napproximate a global minimum of the cost function. We prove analytically that\nthe resulting estimator converges to a global minimum of the cost function\nalmost surely and provide explicit convergence rates in terms of the number of\ngenerated Monte Carlo samples. We show, by way of numerical examples, that the\nalgorithm can tackle cost functions with multiple minima or with broad \"flat\"\nregions which are hard to minimize using gradient-based techniques.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 13:33:08 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 21:49:27 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 14:25:04 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Akyildiz", "\u00d6mer Deniz", ""], ["Crisan", "Dan", ""], ["M\u00edguez", "Joaqu\u00edn", ""]]}, {"id": "1811.09491", "submitter": "Quanming Yao", "authors": "Quanming Yao, Xiawei Guo, James T. Kwok, WeiWei Tu, Yuqiang Chen,\n  Wenyuan Dai, Qiang Yang", "title": "Differential Private Stack Generalization with an Application to\n  Diabetes Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet the standard of differential privacy, noise is usually added into the\noriginal data, which inevitably deteriorates the predicting performance of\nsubsequent learning algorithms. In this paper, motivated by the success of\nimproving predicting performance by ensemble learning, we propose to enhance\nprivacy-preserving logistic regression by stacking. We show that this can be\ndone either by sample-based or feature-based partitioning. However, we prove\nthat when privacy-budgets are the same, feature-based partitioning requires\nfewer samples than sample-based one, and thus likely has better empirical\nperformance. As transfer learning is difficult to be integrated with a\ndifferential privacy guarantee, we further combine the proposed method with\nhypothesis transfer learning to address the problem of learning across\ndifferent organizations. Finally, we not only demonstrate the effectiveness of\nour method on two benchmark data sets, i.e., MNIST and NEWS20, but also apply\nit into a real application of cross-organizational diabetes prediction from\nRUIJIN data set, where privacy is of significant concern.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 14:26:03 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 16:17:41 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 06:57:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yao", "Quanming", ""], ["Guo", "Xiawei", ""], ["Kwok", "James T.", ""], ["Tu", "WeiWei", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Yang", "Qiang", ""]]}, {"id": "1811.09496", "submitter": "Christian Sch\\\"on", "authors": "Christian Sch\\\"on (1), Jens Dittrich (1), Richard M\\\"uller (2) ((1)\n  Saarland Informatics Campus, (2) Deutscher Wetterdienst)", "title": "The Error is the Feature: how to Forecast Lightning using a Model\n  Prediction Error", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": "10.1145/3292500.3330682", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the progress within the last decades, weather forecasting is still a\nchallenging and computationally expensive task. Current satellite-based\napproaches to predict thunderstorms are usually based on the analysis of the\nobserved brightness temperatures in different spectral channels and emit a\nwarning if a critical threshold is reached. Recent progress in data science\nhowever demonstrates that machine learning can be successfully applied to many\nresearch fields in science, especially in areas dealing with large datasets. We\ntherefore present a new approach to the problem of predicting thunderstorms\nbased on machine learning. The core idea of our work is to use the error of\ntwo-dimensional optical flow algorithms applied to images of meteorological\nsatellites as a feature for machine learning models. We interpret that optical\nflow error as an indication of convection potentially leading to thunderstorms\nand lightning. To factor in spatial proximity we use various manual convolution\nsteps. We also consider effects such as the time of day or the geographic\nlocation. We train different tree classifier models as well as a neural network\nto predict lightning within the next few hours (called nowcasting in\nmeteorology) based on these features. In our evaluation section we compare the\npredictive power of the different models and the impact of different features\non the classification result. Our results show a high accuracy of 96% for\npredictions over the next 15 minutes which slightly decreases with increasing\nforecast period but still remains above 83% for forecasts of up to five hours.\nThe high false positive rate of nearly 6% however needs further investigation\nto allow for an operational use of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 14:36:23 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 12:42:40 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Sch\u00f6n", "Christian", ""], ["Dittrich", "Jens", ""], ["M\u00fcller", "Richard", ""]]}, {"id": "1811.09539", "submitter": "Josef Lorenz Rumberger", "authors": "Elias Baumann and Josef Lorenz Rumberger", "title": "State of the Art in Fair ML: From Moral Philosophy and Legislation to\n  Fair Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is becoming an ever present part in our lives as many\ndecisions, e.g. to lend a credit, are no longer made by humans but by machine\nlearning algorithms. However those decisions are often unfair and\ndiscriminating individuals belonging to protected groups based on race or\ngender. With the recent General Data Protection Regulation (GDPR) coming into\neffect, new awareness has been raised for such issues and with computer\nscientists having such a large impact on peoples lives it is necessary that\nactions are taken to discover and prevent discrimination. This work aims to\ngive an introduction into discrimination, legislative foundations to counter it\nand strategies to detect and prevent machine learning algorithms from showing\nsuch behavior.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 12:03:55 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Baumann", "Elias", ""], ["Rumberger", "Josef Lorenz", ""]]}, {"id": "1811.09540", "submitter": "Sokbae Lee", "authors": "Le-Yu Chen and Sokbae Lee", "title": "High Dimensional Classification through $\\ell_0$-Penalized Empirical\n  Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a high dimensional binary classification problem and construct a\nclassification procedure by minimizing the empirical misclassification risk\nwith a penalty on the number of selected features. We derive non-asymptotic\nprobability bounds on the estimated sparsity as well as on the excess\nmisclassification risk. In particular, we show that our method yields a sparse\nsolution whose l0-norm can be arbitrarily close to true sparsity with high\nprobability and obtain the rates of convergence for the excess\nmisclassification risk. The proposed procedure is implemented via the method of\nmixed integer linear programming. Its numerical performance is illustrated in\nMonte Carlo experiments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 16:26:27 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Chen", "Le-Yu", ""], ["Lee", "Sokbae", ""]]}, {"id": "1811.09556", "submitter": "Yan Wu", "authors": "Yan Wu, Greg Wayne, Karol Gregor, Timothy Lillicrap", "title": "Learning Attractor Dynamics for Generative Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge faced by memory systems is the robust retrieval of a\nstored pattern in the presence of interference due to other stored patterns and\nnoise. A theoretically well-founded solution to robust retrieval is given by\nattractor dynamics, which iteratively clean up patterns during recall. However,\nincorporating attractor dynamics into modern deep learning systems poses\ndifficulties: attractor basins are characterised by vanishing gradients, which\nare known to make training neural networks difficult. In this work, we avoid\nthe vanishing gradient problem by training a generative distributed memory\nwithout simulating the attractor dynamics. Based on the idea of memory writing\nas inference, as proposed in the Kanerva Machine, we show that a\nlikelihood-based Lyapunov function emerges from maximising the variational\nlower-bound of a generative memory. Experiments shows it converges to correct\npatterns upon iterative retrieval and achieves competitive performance as both\na memory model and a generative model.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 16:49:02 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wu", "Yan", ""], ["Wayne", "Greg", ""], ["Gregor", "Karol", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1811.09558", "submitter": "Zi Wang", "authors": "Zi Wang and Beomjoon Kim and Leslie Pack Kaelbling", "title": "Regret bounds for meta Bayesian optimization with an unknown Gaussian\n  process prior", "comments": "Proceedings of the Thirty-second Conference on Neural Information\n  Processing Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization usually assumes that a Bayesian prior is given.\nHowever, the strong theoretical guarantees in Bayesian optimization are often\nregrettably compromised in practice because of unknown parameters in the prior.\nIn this paper, we adopt a variant of empirical Bayes and show that, by\nestimating the Gaussian process prior from offline data sampled from the same\nprior and constructing unbiased estimators of the posterior, variants of both\nGP-UCB and probability of improvement achieve a near-zero regret bound, which\ndecreases to a constant proportional to the observational noise as the number\nof offline data and the number of online evaluations increase. Empirically, we\nhave verified our approach on challenging simulated robotic problems featuring\ntask and motion planning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 16:54:45 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wang", "Zi", ""], ["Kim", "Beomjoon", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1811.09562", "submitter": "Amina Houari Phd", "authors": "Amina Houari", "title": "Contributions to Biclustering of Microarray Data Using Formal Concept\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is an unsupervised data mining technique that aims to unveil\npatterns (biclusters) from gene expression data matrices. In the framework of\nthis thesis, we propose new biclustering algorithms for microarray data. The\nlatter is done using data mining techniques. The objective is to identify\npositively and negatively correlated biclusters.\n  This thesis is divided into two part: In the first part, we present an\noverview of the pattern-mining techniques and the biclustering of microarray\ndata. In the second part, we present our proposed biclustering algorithms where\nwe rely on two axes. In the first axis, we initially focus on extracting\nbiclusters of positive correlations. For this, we use both Formal Concept\nAnalysis and Association Rules. In the second axis, we focus on the extraction\nof negatively correlated biclusters.\n  The performed experimental studies highlight the very promising results\noffered by the proposed algorithms. Our biclustering algorithms are evaluated\nand compared statistically and biologically.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 17:05:45 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Houari", "Amina", ""]]}, {"id": "1811.09568", "submitter": "George Moustakides", "authors": "Kalliopi Basioti, George V.Moustakides, Emmanouil Z. Psarakis", "title": "Kernel-Based Training of Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are designed with the help of min-max\noptimization problems that are solved with stochastic gradient-type algorithms\nwhich are known to be non-robust. In this work we revisit a non-adversarial\nmethod based on kernels which relies on a pure minimization problem and propose\na simple stochastic gradient algorithm for the computation of its solution.\nUsing simplified tools from Stochastic Approximation theory we demonstrate that\nbatch versions of the algorithm or smoothing of the gradient do not improve\nconvergence. These observations allow for the development of a training\nalgorithm that enjoys reduced computational complexity and increased robustness\nwhile exhibiting similar synthesis characteristics as classical GANs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 17:18:48 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Basioti", "Kalliopi", ""], ["Moustakides", "George V.", ""], ["Psarakis", "Emmanouil Z.", ""]]}, {"id": "1811.09577", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, Alan Colman, MA Kabir, Jun Han", "title": "Individualized Time-Series Segmentation for Mining Mobile Phone User\n  Behavior", "comments": "20 pages", "journal-ref": "The Computer Journal, Section C: Computational Intelligence,\n  Machine Learning and Data Analytics, Publisher: Oxford University, UK, 2017", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phones can record individual's daily behavioral data as a time-series.\nIn this paper, we present an effective time-series segmentation technique that\nextracts optimal time segments of individual's similar behavioral\ncharacteristics utilizing their mobile phone data. One of the determinants of\nan individual's behavior is the various activities undertaken at various\ntimes-of-the-day and days-of-the-week. In many cases, such behavior will follow\ntemporal patterns. Currently, researchers use either equal or unequal\ninterval-based segmentation of time for mining mobile phone users' behavior.\nMost of them take into account static temporal coverage of 24-h-a-day and few\nof them take into account the number of incidences in time-series data.\nHowever, such segmentations do not necessarily map to the patterns of\nindividual user activity and subsequent behavior because of not taking into\naccount the diverse behaviors of individuals over time-of-the-week. Therefore,\nwe propose a behavior-oriented time segmentation (BOTS) technique that takes\ninto account not only the temporal coverage of the week but also the number of\nincidences of diverse behaviors dynamically for producing similar behavioral\ntime segments over the week utilizing time-series data. Experiments on the real\nmobile phone datasets show that our proposed segmentation technique better\ncaptures the user's dominant behavior at various times-of-the-day and\ndays-of-the-week enabling the generation of high confidence temporal rules in\norder to mine individual mobile phone users' behavior.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 11:09:58 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Colman", "Alan", ""], ["Kabir", "MA", ""], ["Han", "Jun", ""]]}, {"id": "1811.09595", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Xiao Lin, Mohamed R. Amer, Graham W. Taylor", "title": "Spectral Multigraph Networks for Discovering and Fusing Relationships in\n  Molecules", "comments": "11 pages, 5 figures, NIPS 2018 Workshop on Machine Learning for\n  Molecules and Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Graph Convolutional Networks (GCNs) are a generalization of\nconvolutional networks to learning on graph-structured data. Applications of\nspectral GCNs have been successful, but limited to a few problems where the\ngraph is fixed, such as shape correspondence and node classification. In this\nwork, we address this limitation by revisiting a particular family of spectral\ngraph networks, Chebyshev GCNs, showing its efficacy in solving graph\nclassification tasks with a variable graph structure and size. Chebyshev GCNs\nrestrict graphs to have at most one edge between any pair of nodes. To this\nend, we propose a novel multigraph network that learns from multi-relational\ngraphs. We model learned edges with abstract meaning and experiment with\ndifferent ways to fuse the representations extracted from annotated and learned\nedges, achieving competitive results on a variety of chemical classification\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 18:46:59 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Knyazev", "Boris", ""], ["Lin", "Xiao", ""], ["Amer", "Mohamed R.", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1811.09602", "submitter": "Aniruddh Raghu", "authors": "Aniruddh Raghu, Matthieu Komorowski, Sumeetpal Singh", "title": "Model-Based Reinforcement Learning for Sepsis Treatment", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "Report number: ML4H/2018/41", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a dangerous condition that is a leading cause of patient mortality.\nTreating sepsis is highly challenging, because individual patients respond very\ndifferently to medical interventions and there is no universally agreed-upon\ntreatment for sepsis. In this work, we explore the use of continuous\nstate-space model-based reinforcement learning (RL) to discover high-quality\ntreatment policies for sepsis patients. Our quantitative evaluation reveals\nthat by blending the treatment strategy discovered with RL with what clinicians\nfollow, we can obtain improved policies, potentially allowing for better\nmedical treatment for sepsis.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 18:57:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Raghu", "Aniruddh", ""], ["Komorowski", "Matthieu", ""], ["Singh", "Sumeetpal", ""]]}, {"id": "1811.09619", "submitter": "Bianca-Cristina Cristescu", "authors": "Bianca-Cristina Cristescu, Zal\\'an Borsos, John Lygeros, Mar\\'ia\n  Rodr\\'iguez Mart\\'inez, Maria Anna Rapsomaniki", "title": "Inference of the three-dimensional chromatin structure and its temporal\n  behavior", "comments": "10 pages, 7 figures, 1 algorithm. Neural Information Processing\n  Systems, Machine Learning for Molecules and Materials, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the three-dimensional (3D) structure of the genome is essential\nfor elucidating vital biological processes and their links to human disease. To\ndetermine how the genome folds within the nucleus, chromosome conformation\ncapture methods such as HiC have recently been employed. However, computational\nmethods that exploit the resulting high-throughput, high-resolution data are\nstill suffering from important limitations. In this work, we explore the idea\nof manifold learning for the 3D chromatin structure inference and present a\nnovel method, REcurrent Autoencoders for CHromatin 3D structure prediction\n(REACH-3D). Our framework employs autoencoders with recurrent neural units to\nreconstruct the chromatin structure. In comparison to existing methods,\nREACH-3D makes no transfer function assumption and permits dynamic analysis.\nEvaluating REACH-3D on synthetic data indicated high agreement with the ground\ntruth. When tested on real experimental HiC data, REACH-3D recovered most\nfaithfully the expected biological properties and obtained the highest\ncorrelation coefficient with microscopy measurements. Last, REACH-3D was\napplied to dynamic HiC data, where it successfully modeled chromatin\nconformation during the cell cycle.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 15:19:33 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Cristescu", "Bianca-Cristina", ""], ["Borsos", "Zal\u00e1n", ""], ["Lygeros", "John", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""], ["Rapsomaniki", "Maria Anna", ""]]}, {"id": "1811.09620", "submitter": "Sicong(Sheldon) Huang", "authors": "Sicong Huang, Qiyang Li, Cem Anil, Xuchan Bao, Sageev Oore, Roger B.\n  Grosse", "title": "TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre\n  Transfer", "comments": "17 pages, published as a conference paper at ICLR 2019", "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the problem of musical timbre transfer, where the\ngoal is to manipulate the timbre of a sound sample from one instrument to match\nanother instrument while preserving other musical content, such as pitch,\nrhythm, and loudness. In principle, one could apply image-based style transfer\ntechniques to a time-frequency representation of an audio signal, but this\ndepends on having a representation that allows independent manipulation of\ntimbre as well as high-quality waveform generation. We introduce TimbreTron, a\nmethod for musical timbre transfer which applies \"image\" domain style transfer\nto a time-frequency representation of the audio signal, and then produces a\nhigh-quality waveform using a conditional WaveNet synthesizer. We show that the\nConstant Q Transform (CQT) representation is particularly well-suited to\nconvolutional architectures due to its approximate pitch equivariance. Based on\nhuman perceptual evaluations, we confirmed that TimbreTron recognizably\ntransferred the timbre while otherwise preserving the musical content, for both\nmonophonic and polyphonic samples.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 17:46:51 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 02:40:24 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Huang", "Sicong", ""], ["Li", "Qiyang", ""], ["Anil", "Cem", ""], ["Bao", "Xuchan", ""], ["Oore", "Sageev", ""], ["Grosse", "Roger B.", ""]]}, {"id": "1811.09669", "submitter": "Viraj Jayminkumar Shah", "authors": "Rahul Singh, Viraj Shah, Balaji Pokuri, Soumik Sarkar, Baskar\n  Ganapathysubramanian, Chinmay Hegde", "title": "Physics-aware Deep Generative Models for Creating Synthetic\n  Microstructures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in computational material science deals with understanding the\neffect of material distribution (i.e., microstructure) on material performance.\nThe challenge is to synthesize microstructures, given a finite number of\nmicrostructure images, and/or some physical invariances that the microstructure\nexhibits. Conventional approaches are based on stochastic optimization and are\ncomputationally intensive. We introduce three generative models for the fast\nsynthesis of binary microstructure images. The first model is a WGAN model that\nuses a finite number of training images to synthesize new microstructures that\nweakly satisfy the physical invariances respected by the original data. The\nsecond model explicitly enforces known physical invariances by replacing the\ntraditional discriminator in a GAN with an invariance checker. Our third model\ncombines the first two models to reconstruct microstructures that respect both\nexplicit physics invariances as well as implicit constraints learned from the\nimage data. We illustrate these models by reconstructing two-phase\nmicrostructures that exhibit coarsening behavior. The trained models also\nexhibit interesting latent variable interpolation behavior, and the results\nindicate considerable promise for enforcing user-defined physics constraints\nduring microstructure synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 06:47:02 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Singh", "Rahul", ""], ["Shah", "Viraj", ""], ["Pokuri", "Balaji", ""], ["Sarkar", "Soumik", ""], ["Ganapathysubramanian", "Baskar", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1811.09673", "submitter": "Veronica Tozzo", "authors": "Veronica Tozzo, Federico Tomasi, Margherita Squillario, Annalisa Barla", "title": "Group induced graphical lasso allows for discovery of molecular\n  pathways-pathways interactions", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems may contain heterogeneous types of variables that interact in\na multi-level and multi-scale manner. In this context, high-level layers may\nconsidered as groups of variables interacting in lower-level layers. This is\nparticularly true in biology, where, for example, genes are grouped in pathways\nand two types of interactions are present: pathway-pathway interactions and\ngene-gene interactions. However, from data it is only possible to measure the\nexpression of genes while it is impossible to directly measure the activity of\npathways. Nevertheless, the knowledge on the inter-dependence between the\ngroups and the variables allows for a multi-layer network inference, on both\nobserved variables and groups, even if no direct information on the latter is\npresent in the data (hence groups are considered as latent). In this paper, we\npropose an extension of the latent graphical lasso method that leverages on the\nknowledge of the inter-links between the hidden (groups) and observed layers.\nThe method exploits the knowledge of group structure that influence the\nbehaviour of observed variables to retrieve a two layers network. Its efficacy\nwas tested on synthetic data to check its ability in retrieving the network\nstructure compared to the ground truth. We present a case study on\nNeuroblastoma, which shows how our multi-level inference is relevant in real\ncontexts to infer biologically meaningful connections.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 10:39:59 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Tozzo", "Veronica", ""], ["Tomasi", "Federico", ""], ["Squillario", "Margherita", ""], ["Barla", "Annalisa", ""]]}, {"id": "1811.09678", "submitter": "Titouan Parcollet", "authors": "Titouan Parcollet, Mirco Ravanelli, Mohamed Morchid, Georges\n  Linar\\`es, Renato De Mori", "title": "Speech recognition with quaternion neural networks", "comments": "NIPS 2018 (IRASL). arXiv admin note: text overlap with\n  arXiv:1806.04418", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network architectures are at the core of powerful automatic speech\nrecognition systems (ASR). However, while recent researches focus on novel\nmodel architectures, the acoustic input features remain almost unchanged.\nTraditional ASR systems rely on multidimensional acoustic features such as the\nMel filter bank energies alongside with the first, and second order derivatives\nto characterize time-frames that compose the signal sequence. Considering that\nthese components describe three different views of the same element, neural\nnetworks have to learn both the internal relations that exist within these\nfeatures, and external or global dependencies that exist between the\ntime-frames. Quaternion-valued neural networks (QNN), recently received an\nimportant interest from researchers to process and learn such relations in\nmultidimensional spaces. Indeed, quaternion numbers and QNNs have shown their\nefficiency to process multidimensional inputs as entities, to encode internal\ndependencies, and to solve many tasks with up to four times less learning\nparameters than real-valued models. We propose to investigate modern\nquaternion-valued models such as convolutional and recurrent quaternion neural\nnetworks in the context of speech recognition with the TIMIT dataset. The\nexperiments show that QNNs always outperform real-valued equivalent models with\nway less free parameters, leading to a more efficient, compact, and expressive\nrepresentation of the relevant information.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 10:27:02 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Parcollet", "Titouan", ""], ["Ravanelli", "Mirco", ""], ["Morchid", "Mohamed", ""], ["Linar\u00e8s", "Georges", ""], ["De Mori", "Renato", ""]]}, {"id": "1811.09688", "submitter": "Haruna Isah", "authors": "Mandeep Singh Kandhari, Farhana Zulkernine, Haruna Isah", "title": "A Voice Controlled E-Commerce Web Application", "comments": "7 pages", "journal-ref": null, "doi": "10.1109/IEMCON.2018.8614771", "report-no": null, "categories": "cs.CY cs.CL cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic voice-controlled systems have changed the way humans interact with\na computer. Voice or speech recognition systems allow a user to make a\nhands-free request to the computer, which in turn processes the request and\nserves the user with appropriate responses. After years of research and\ndevelopments in machine learning and artificial intelligence, today\nvoice-controlled technologies have become more efficient and are widely applied\nin many domains to enable and improve human-to-human and human-to-computer\ninteractions. The state-of-the-art e-commerce applications with the help of web\ntechnologies offer interactive and user-friendly interfaces. However, there are\nsome instances where people, especially with visual disabilities, are not able\nto fully experience the serviceability of such applications. A voice-controlled\nsystem embedded in a web application can enhance user experience and can\nprovide voice as a means to control the functionality of e-commerce websites.\nIn this paper, we propose a taxonomy of speech recognition systems (SRS) and\npresent a voice-controlled commodity purchase e-commerce application using IBM\nWatson speech-to-text to demonstrate its usability. The prototype can be\nextended to other application scenarios such as government service kiosks and\nenable analytics of the converted text data for scenarios such as medical\ndiagnosis at the clinics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 01:35:09 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Kandhari", "Mandeep Singh", ""], ["Zulkernine", "Farhana", ""], ["Isah", "Haruna", ""]]}, {"id": "1811.09702", "submitter": "Jooyeon Kim", "authors": "Jooyeon Kim, Dongkwan Kim, Alice Oh", "title": "Homogeneity-Based Transmissive Process to Model True and False News in\n  Social Networks", "comments": "To appear in proceedings of the 12th ACM International Conference on\n  Web Search and Data Mining (WSDM 2019)", "journal-ref": null, "doi": "10.1145/3289600.3291009", "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An overwhelming number of true and false news stories are posted and shared\nin social networks, and users diffuse the stories based on multiple factors.\nDiffusion of news stories from one user to another depends not only on the\nstories' content and the genuineness but also on the alignment of the topical\ninterests between the users. In this paper, we propose a novel Bayesian\nnonparametric model that incorporates homogeneity of news stories as the key\ncomponent that regulates the topical similarity between the posting and sharing\nusers' topical interests. Our model extends hierarchical Dirichlet process to\nmodel the topics of the news stories and incorporates Bayesian Gaussian process\nlatent variable model to discover the homogeneity values. We train our model on\na real-world social network dataset and find homogeneity values of news stories\nthat strongly relate to their labels of genuineness and their contents.\nFinally, we show that the supervised version of our model predicts the labels\nof news stories better than the state-of-the-art neural network and Bayesian\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 03:22:53 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Kim", "Jooyeon", ""], ["Kim", "Dongkwan", ""], ["Oh", "Alice", ""]]}, {"id": "1811.09714", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "C\\u{a}t\\u{a}lina Cangea, Arturas Grauslys, Pietro Li\\`o, Francesco\n  Falciani", "title": "Structure-Based Networks for Drug Validation", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/89", "categories": "q-bio.QM cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying chemicals according to putative modes of action (MOAs) is of\nparamount importance in the context of risk assessment. However, current\nmethods are only able to handle a very small proportion of the existing\nchemicals. We address this issue by proposing an integrative deep learning\narchitecture that learns a joint representation from molecular structures of\ndrugs and their effects on human cells. Our choice of architecture is motivated\nby the significant influence of a drug's chemical structure on its MOA. We\nimprove on the strong ability of a unimodal architecture (F1 score of 0.803) to\nclassify drugs by their toxic MOAs (Verhaar scheme) through adding another\nlearning stream that processes transcriptional responses of human cells\naffected by drugs. Our integrative model achieves an even higher classification\nperformance on the LINCS L1000 dataset - the error is reduced by 4.6%. We\nbelieve that our method can be used to extend the current Verhaar scheme and\nconstitute a basis for fast drug validation and risk assessment.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 12:39:19 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Grauslys", "Arturas", ""], ["Li\u00f2", "Pietro", ""], ["Falciani", "Francesco", ""]]}, {"id": "1811.09716", "submitter": "Seyed-Mohsen Moosavi-Dezfooli", "authors": "Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato,\n  Pascal Frossard", "title": "Robustness via curvature regularization, and vice versa", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art classifiers have been shown to be largely vulnerable to\nadversarial perturbations. One of the most effective strategies to improve\nrobustness is adversarial training. In this paper, we investigate the effect of\nadversarial training on the geometry of the classification landscape and\ndecision boundaries. We show in particular that adversarial training leads to a\nsignificant decrease in the curvature of the loss surface with respect to\ninputs, leading to a drastically more \"linear\" behaviour of the network. Using\na locally quadratic approximation, we provide theoretical evidence on the\nexistence of a strong relation between large robustness and small curvature. To\nfurther show the importance of reduced curvature for improving the robustness,\nwe propose a new regularizer that directly minimizes curvature of the loss\nsurface, and leads to adversarial robustness that is on par with adversarial\ntraining. Besides being a more efficient and principled alternative to\nadversarial training, the proposed regularizer confirms our claims on the\nimportance of exhibiting quasi-linear behavior in the vicinity of data points\nin order to achieve robustness.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 22:03:40 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Fawzi", "Alhussein", ""], ["Uesato", "Jonathan", ""], ["Frossard", "Pascal", ""]]}, {"id": "1811.09720", "submitter": "Chih-Kuan Yeh", "authors": "Chih-Kuan Yeh, Joon Sik Kim, Ian E.H. Yen, Pradeep Ravikumar", "title": "Representer Point Selection for Explaining Deep Neural Networks", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to explain the predictions of a deep neural network, by pointing\nto the set of what we call representer points in the training set, for a given\ntest point prediction. Specifically, we show that we can decompose the\npre-activation prediction of a neural network into a linear combination of\nactivations of training points, with the weights corresponding to what we call\nrepresenter values, which thus capture the importance of that training point on\nthe learned parameters of the network. But it provides a deeper understanding\nof the network than simply training point influence: with positive representer\nvalues corresponding to excitatory training points, and negative values\ncorresponding to inhibitory points, which as we show provides considerably more\ninsight. Our method is also much more scalable, allowing for real-time feedback\nin a manner not feasible with influence functions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 22:34:17 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Yeh", "Chih-Kuan", ""], ["Kim", "Joon Sik", ""], ["Yen", "Ian E. H.", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1811.09724", "submitter": "Aditya Balu", "authors": "Rahul Singh, Aayush Sharma, Onur Rauf Bingol, Aditya Balu, Ganesh\n  Balasubramanian, Duane D. Johnson and Soumik Sarkar", "title": "3D Deep Learning with voxelized atomic configurations for modeling\n  atomistic potentials in complex solid-solution alloys", "comments": "Presenting in Machine Learning for Molecules and Materials NeurIPS\n  2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for advanced materials has led to the development of complex,\nmulti-component alloys or solid-solution alloys. These materials have shown\nexceptional properties like strength, toughness, ductility, electrical and\nelectronic properties. Current development of such material systems are\nhindered by expensive experiments and computationally demanding\nfirst-principles simulations. Atomistic simulations can provide reasonable\ninsights on properties in such material systems. However, the issue of\ndesigning robust potentials still exists. In this paper, we explore a deep\nconvolutional neural-network based approach to develop the atomistic potential\nfor such complex alloys to investigate materials for insights into controlling\nproperties. In the present work, we propose a voxel representation of the\natomic configuration of a cell and design a 3D convolutional neural network to\nlearn the interaction of the atoms. Our results highlight the performance of\nthe 3D convolutional neural network and its efficacy in machine-learning the\natomistic potential. We also explore the role of voxel resolution and provide\ninsights into the two bounding box methodologies implemented for voxelization.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 23:12:22 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Singh", "Rahul", ""], ["Sharma", "Aayush", ""], ["Bingol", "Onur Rauf", ""], ["Balu", "Aditya", ""], ["Balasubramanian", "Ganesh", ""], ["Johnson", "Duane D.", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1811.09735", "submitter": "Long Nguyen", "authors": "Sisheng Liang, Long Nguyen, Fang Jin", "title": "A Multi-variable Stacked Long-Short Term Memory Network for Wind Speed\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precisely forecasting wind speed is essential for wind power producers and\ngrid operators. However, this task is challenging due to the stochasticity of\nwind speed. To accurately predict short-term wind speed under uncertainties,\nthis paper proposed a multi-variable stacked LSTMs model (MSLSTM). The proposed\nmethod utilizes multiple historical meteorological variables, such as wind\nspeed, temperature, humidity, pressure, dew point and solar radiation to\naccurately predict wind speeds. The prediction performance is extensively\nassessed using real data collected in West Texas, USA. The experimental results\nshow that the proposed MSLSTM can preferably capture and learn uncertainties\nwhile output competitive performance.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 01:12:31 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Liang", "Sisheng", ""], ["Nguyen", "Long", ""], ["Jin", "Fang", ""]]}, {"id": "1811.09737", "submitter": "Abdul Dakkak", "authors": "Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-Mei Hwu", "title": "Frustrated with Replicating Claims of a Shared Model? A Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) and Deep Learning (DL) innovations are being introduced\nat such a rapid pace that model owners and evaluators are hard-pressed\nanalyzing and studying them. This is exacerbated by the complicated procedures\nfor evaluation. The lack of standard systems and efficient techniques for\nspecifying and provisioning ML/DL evaluation is the main cause of this \"pain\npoint\". This work discusses common pitfalls for replicating DL model\nevaluation, and shows that these subtle pitfalls can affect both accuracy and\nperformance. It then proposes a solution to remedy these pitfalls called\nMLModelScope, a specification for repeatable model evaluation and a runtime to\nprovision and measure experiments. We show that by easing the model\nspecification and evaluation process, MLModelScope facilitates rapid adoption\nof ML/DL innovations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 01:18:00 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 17:15:01 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Dakkak", "Abdul", ""], ["Li", "Cheng", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-Mei", ""]]}, {"id": "1811.09740", "submitter": "Zhiting Hu", "authors": "Bowen Tan, Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Eric Xing", "title": "Connecting the Dots Between MLE and RL for Sequence Prediction", "comments": "Major revision. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence prediction models can be learned from example sequences with a\nvariety of training algorithms. Maximum likelihood learning is simple and\nefficient, yet can suffer from compounding error at test time. Reinforcement\nlearning such as policy gradient addresses the issue but can have prohibitively\npoor exploration efficiency. A rich set of other algorithms such as RAML, SPG,\nand data noising, have also been developed from different perspectives. This\npaper establishes a formal connection between these algorithms. We present a\ngeneralized entropy regularized policy optimization formulation, and show that\nthe apparently distinct algorithms can all be reformulated as special instances\nof the framework, with the only difference being the configurations of a reward\nfunction and a couple of hyperparameters. The unified interpretation offers a\nsystematic view of the varying properties of exploration and learning\nefficiency. Besides, inspired from the framework, we present a new algorithm\nthat dynamically interpolates among the family of algorithms for scheduled\nsequence model learning. Experiments on machine translation, text\nsummarization, and game imitation learning demonstrate the superiority of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 01:33:39 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 19:44:06 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Tan", "Bowen", ""], ["Hu", "Zhiting", ""], ["Yang", "Zichao", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric", ""]]}, {"id": "1811.09747", "submitter": "Ari Pakman", "authors": "Ari Pakman and Liam Paninski", "title": "Amortized Bayesian inference for clustering models", "comments": "Presented at BNP@NeurIPS 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop methods for efficient amortized approximate Bayesian inference\nover posterior distributions of probabilistic clustering models, such as\nDirichlet process mixture models. The approach is based on mapping distributed,\nsymmetry-invariant representations of cluster arrangements into conditional\nprobabilities. The method parallelizes easily, yields iid samples from the\napproximate posterior of cluster assignments with the same computational cost\nof a single Gibbs sampler sweep, and can easily be applied to both conjugate\nand non-conjugate models, as training only requires samples from the generative\nmodel.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 02:17:20 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Pakman", "Ari", ""], ["Paninski", "Liam", ""]]}, {"id": "1811.09751", "submitter": "Zirui Wang", "authors": "Zirui Wang, Zihang Dai, Barnab\\'as P\\'oczos, Jaime Carbonell", "title": "Characterizing and Avoiding Negative Transfer", "comments": "Published at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When labeled data is scarce for a specific target task, transfer learning\noften offers an effective solution by utilizing data from a related source\ntask. However, when transferring knowledge from a less related source, it may\ninversely hurt the target performance, a phenomenon known as negative transfer.\nDespite its pervasiveness, negative transfer is usually described in an\ninformal manner, lacking rigorous definition, careful analysis, or systematic\ntreatment. This paper proposes a formal definition of negative transfer and\nanalyzes three important aspects thereof. Stemming from this analysis, a novel\ntechnique is proposed to circumvent negative transfer by filtering out\nunrelated source data. Based on adversarial networks, the technique is highly\ngeneric and can be applied to a wide range of transfer learning algorithms. The\nproposed approach is evaluated on six state-of-the-art deep transfer methods\nvia experiments on four benchmark datasets with varying levels of difficulty.\nEmpirically, the proposed method consistently improves the performance of all\nbaseline methods and largely avoids negative transfer, even when the source\ndata is degenerate.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 03:26:10 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 21:31:51 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 02:05:54 GMT"}, {"version": "v4", "created": "Sat, 5 Oct 2019 03:43:52 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wang", "Zirui", ""], ["Dai", "Zihang", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1811.09757", "submitter": "Xiu Yang", "authors": "Xiu Yang and David Barajas-Solano and Guzel Tartakovsky and Alexandre\n  Tartakovsky", "title": "Physics-Informed CoKriging: A Gaussian-Process-Regression-Based\n  Multifidelity Method for Data-Model Convergence", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.06.041", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new Gaussian process regression (GPR)-based\nmultifidelity method: physics-informed CoKriging (CoPhIK). In CoKriging-based\nmultifidelity methods, the quantities of interest are modeled as linear\ncombinations of multiple parameterized stationary Gaussian processes (GPs), and\nthe hyperparameters of these GPs are estimated from data via optimization. In\nCoPhIK, we construct a GP representing low-fidelity data using physics-informed\nKriging (PhIK), and model the discrepancy between low- and high-fidelity data\nusing a parameterized GP with hyperparameters identified via optimization. Our\napproach reduces the cost of optimization for inferring hyperparameters by\nincorporating partial physical knowledge. We prove that the physical\nconstraints in the form of deterministic linear operators are satisfied up to\nan error bound. Furthermore, we combine CoPhIK with a greedy active learning\nalgorithm for guiding the selection of additional observation locations. The\nefficiency and accuracy of CoPhIK are demonstrated for reconstructing the\npartially observed modified Branin function, reconstructing the sparsely\nobserved state of a steady state heat transport problem, and learning a\nconservative tracer distribution from sparse tracer concentration measurements.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 03:56:10 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Yang", "Xiu", ""], ["Barajas-Solano", "David", ""], ["Tartakovsky", "Guzel", ""], ["Tartakovsky", "Alexandre", ""]]}, {"id": "1811.09782", "submitter": "Sabri Boughorbel", "authors": "Sabri Boughorbel, Fethi Jarray, Neethu Venugopal, Haithum Elhadi", "title": "Alternating Loss Correction for Preterm-Birth Prediction from EHR Data\n  with Noisy Labels", "comments": "Submission Id: 79, Machine Learning for Health (ML4H) Workshop at\n  NeurIPS 2018 arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/79", "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we are interested in the prediction of preterm birth based on\ndiagnosis codes from longitudinal EHR. We formulate the prediction problem as a\nsupervised classification with noisy labels. Our base classifier is a Recurrent\nNeural Network with an attention mechanism. We assume the availability of a\ndata subset with both noisy and clean labels. For the cohort definition, most\nof the diagnosis codes on mothers' records related to pregnancy are ambiguous\nfor the definition of full-term and preterm classes. On the other hand,\ndiagnosis codes on babies' records provide fine-grained information on\nprematurity. Due to data de-identification, the links between mothers and\nbabies are not available. We developed a heuristic based on admission and\ndischarge times to match babies to their mothers and hence enrich mothers'\nrecords with additional information on delivery status. The obtained additional\ndataset from the matching heuristic has noisy labels and was used to leverage\nthe training of the deep learning model. We propose an Alternating Loss\nCorrection (ALC) method to train deep models with both clean and noisy labels.\nFirst, the label corruption matrix is estimated using the data subset with both\nnoisy and clean labels. Then it is used in the model as a dense output layer to\ncorrect for the label noise. The network is alternately trained on epochs with\nthe clean dataset with a simple cross-entropy loss and on next epoch with the\nnoisy dataset and a loss corrected with the estimated corruption matrix. The\nexperiments for the prediction of preterm birth at 90 days before delivery\nshowed an improvement in performance compared with baseline and state\nof-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 07:47:01 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Boughorbel", "Sabri", ""], ["Jarray", "Fethi", ""], ["Venugopal", "Neethu", ""], ["Elhadi", "Haithum", ""]]}, {"id": "1811.09794", "submitter": "Hyeoncheol Cho", "authors": "Hyeoncheol Cho, Insung S. Choi", "title": "Three-Dimensionally Embedded Graph Convolutional Network (3DGCN) for\n  Molecule Interpretation", "comments": "39 pages, 14 figures, 5 tables", "journal-ref": "ChemMedChem, 2019", "doi": "10.1002/cmdc.201900458", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a three-dimensional graph convolutional network (3DGCN), which\npredicts molecular properties and biochemical activities, based on 3D molecular\ngraph. In the 3DGCN, graph convolution is unified with learning operations on\nthe vector to handle the spatial information from molecular topology. The 3DGCN\nmodel exhibits significantly higher performance on various tasks compared with\nother deep-learning models, and has the ability of generalizing a given\nconformer to targeted features regardless of its rotations in the 3D space.\nMore significantly, our model also can distinguish the 3D rotations of a\nmolecule and predict the target value, depending upon the rotation degree, in\nthe protein-ligand docking problem, when trained with orientation-dependent\ndatasets. The rotation distinguishability of 3DGCN, along with rotation\nequivariance, provides a key milestone in the implementation of\nthree-dimensionality to the field of deep-learning chemistry that solves\nchallenging biochemical problems.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 08:57:26 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 04:22:08 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 11:42:23 GMT"}, {"version": "v4", "created": "Tue, 16 Apr 2019 05:39:57 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Cho", "Hyeoncheol", ""], ["Choi", "Insung S.", ""]]}, {"id": "1811.09813", "submitter": "Aditya Grover", "authors": "Aditya Grover, Tudor Achim, Stefano Ermon", "title": "Streamlining Variational Inference for Constraint Satisfaction Problems", "comments": "NeurIPS 2018", "journal-ref": null, "doi": "10.1088/1742-5468/ab371f", "report-no": null, "categories": "cs.AI cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several algorithms for solving constraint satisfaction problems are based on\nsurvey propagation, a variational inference scheme used to obtain approximate\nmarginal probability estimates for variable assignments. These marginals\ncorrespond to how frequently each variable is set to true among satisfying\nassignments, and are used to inform branching decisions during search; however,\nmarginal estimates obtained via survey propagation are approximate and can be\nself-contradictory. We introduce a more general branching strategy based on\nstreamlining constraints, which sidestep hard assignments to variables. We show\nthat streamlined solvers consistently outperform decimation-based solvers on\nrandom k-SAT instances for several problem sizes, shrinking the gap between\nempirical performance and theoretical limits of satisfiability by 16.3% on\naverage for k=3,4,5,6.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 11:08:14 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Grover", "Aditya", ""], ["Achim", "Tudor", ""], ["Ermon", "Stefano", ""]]}, {"id": "1811.09828", "submitter": "Krzysztof Maziarz", "authors": "Krzysztof Maziarz, Mingxing Tan, Andrey Khorlin, Marin Georgiev,\n  Andrea Gesmundo", "title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search has shown potential to automate the design of\nneural networks. Deep Reinforcement Learning based agents can learn complex\narchitectural patterns, as well as explore a vast and compositional search\nspace. On the other hand, evolutionary algorithms offer higher sample\nefficiency, which is critical for such a resource intensive application. In\norder to capture the best of both worlds, we propose a class of\nEvolutionary-Neural hybrid agents (Evo-NAS). We show that the Evo-NAS agent\noutperforms both neural and evolutionary agents when applied to architecture\nsearch for a suite of text and image classification benchmarks. On a\nhigh-complexity architecture search space for image classification, the Evo-NAS\nagent surpasses the accuracy achieved by commonly used agents with only 1/3 of\nthe search cost.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 13:00:47 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 16:05:51 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 15:27:38 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 13:25:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Maziarz", "Krzysztof", ""], ["Tan", "Mingxing", ""], ["Khorlin", "Andrey", ""], ["Georgiev", "Marin", ""], ["Gesmundo", "Andrea", ""]]}, {"id": "1811.09834", "submitter": "Yongxi Lu", "authors": "Ziyao Tang, Yongxi Lu and Tara Javidi", "title": "Efficient Video Understanding via Layered Multi Frame-Rate Analysis", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the greatest challenges in the design of a real-time perception system\nfor autonomous driving vehicles and drones is the conflicting requirement of\nsafety (high prediction accuracy) and efficiency. Traditional approaches use a\nsingle frame rate for the entire system. Motivated by the observation that the\nlack of robustness against environmental factors is the major weakness of\ncompact ConvNet architectures, we propose a dual frame-rate system that brings\nin the best of both worlds: A modulator stream that executes an expensive\nmodels robust to environmental factors at a low frame rate to extract slowly\nchanging features describing the environment, and a prediction stream that\nexecutes a light-weight model at real-time to extract transient signals that\ndescribes particularities of the current frame. The advantage of our design is\nvalidated by our extensive empirical study, showing that our solution leads to\nconsistent improvements using a variety of backbone architecture choice and\ninput resolutions. These findings suggest multiple frame-rate systems as a\npromising direction in designing efficient perception for autonomous agents.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 13:43:34 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Tang", "Ziyao", ""], ["Lu", "Yongxi", ""], ["Javidi", "Tara", ""]]}, {"id": "1811.09842", "submitter": "Guozhu Dong", "authors": "Guozhu Dong and Sai Kiran Pentukar", "title": "OCLEP+: One-class Anomaly and Intrusion Detection Using Minimal Length\n  of Emerging Patterns", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method called One-class Classification using Length\nstatistics of Emerging Patterns Plus (OCLEP+).\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 14:21:50 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Dong", "Guozhu", ""], ["Pentukar", "Sai Kiran", ""]]}, {"id": "1811.09862", "submitter": "Maxim Naumov", "authors": "Maxim Naumov and Utku Diril and Jongsoo Park and Benjamin Ray and\n  Jedrzej Jablonski and Andrew Tulloch", "title": "On Periodic Functions as Regularizers for Quantization of Neural\n  Networks", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have been successfully used in computer vision and many\nother fields. We propose an unorthodox algorithm for performing quantization of\nthe model parameters. In contrast with popular quantization schemes based on\nthresholds, we use a novel technique based on periodic functions, such as\ncontinuous trigonometric sine or cosine as well as non-continuous hat\nfunctions. We apply these functions component-wise and add the sum over the\nmodel parameters as a regularizer to the model loss during training. The\nfrequency and amplitude hyper-parameters of these functions can be adjusted\nduring training. The regularization pushes the weights into discrete points\nthat can be encoded as integers. We show that using this technique the\nresulting quantized models exhibit the same accuracy as the original ones on\nCIFAR-10 and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 17:24:28 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Naumov", "Maxim", ""], ["Diril", "Utku", ""], ["Park", "Jongsoo", ""], ["Ray", "Benjamin", ""], ["Jablonski", "Jedrzej", ""], ["Tulloch", "Andrew", ""]]}, {"id": "1811.09863", "submitter": "Anton Belyy", "authors": "Anton Belyy, Aleksei Sholokhov", "title": "MEMOIR: Multi-class Extreme Classification with Inexact Margin", "comments": "11 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multi-class classification with a very large number of classes, or extreme\nclassification, is a challenging problem from both statistical and\ncomputational perspectives. Most of the classical approaches to multi-class\nclassification, including one-vs-rest or multi-class support vector machines,\nrequire the exact estimation of the classifier's margin, at both the training\nand the prediction steps making them intractable in extreme classification\nscenarios. In this paper, we study the impact of computing an approximate\nmargin using nearest neighbor (ANN) search structures combined with\nlocality-sensitive hashing (LSH). This approximation allows to dramatically\nreduce both the training and the prediction time without a significant loss in\nperformance. We theoretically prove that this approximation does not lead to a\nsignificant loss of the risk of the model and provide empirical evidence over\nfive publicly available large scale datasets, showing that the proposed\napproach is highly competitive with respect to state-of-the-art approaches on\ntime, memory and performance measures.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 17:26:20 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 22:08:23 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Belyy", "Anton", ""], ["Sholokhov", "Aleksei", ""]]}, {"id": "1811.09886", "submitter": "Jongsoo Park", "authors": "Jongsoo Park, Maxim Naumov, Protonu Basu, Summer Deng, Aravind\n  Kalaiah, Daya Khudia, James Law, Parth Malani, Andrey Malevich, Satish\n  Nadathur, Juan Pino, Martin Schatz, Alexander Sidorov, Viswanath Sivakumar,\n  Andrew Tulloch, Xiaodong Wang, Yiming Wu, Hector Yuen, Utku Diril, Dmytro\n  Dzhulgakov, Kim Hazelwood, Bill Jia, Yangqing Jia, Lin Qiao, Vijay Rao, Nadav\n  Rotem, Sungjoo Yoo, Mikhail Smelyanskiy", "title": "Deep Learning Inference in Facebook Data Centers: Characterization,\n  Performance Optimizations and Hardware Implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning techniques resulted in remarkable\nimprovement of machine learning models. In this paper provides detailed\ncharacterizations of deep learning models used in many Facebook social network\nservices. We present computational characteristics of our models, describe high\nperformance optimizations targeting existing systems, point out their\nlimitations and make suggestions for the future general-purpose/accelerated\ninference hardware. Also, we highlight the need for better co-design of\nalgorithms, numerics and computing platforms to address the challenges of\nworkloads often run in data centers.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 19:52:02 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 07:25:11 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Park", "Jongsoo", ""], ["Naumov", "Maxim", ""], ["Basu", "Protonu", ""], ["Deng", "Summer", ""], ["Kalaiah", "Aravind", ""], ["Khudia", "Daya", ""], ["Law", "James", ""], ["Malani", "Parth", ""], ["Malevich", "Andrey", ""], ["Nadathur", "Satish", ""], ["Pino", "Juan", ""], ["Schatz", "Martin", ""], ["Sidorov", "Alexander", ""], ["Sivakumar", "Viswanath", ""], ["Tulloch", "Andrew", ""], ["Wang", "Xiaodong", ""], ["Wu", "Yiming", ""], ["Yuen", "Hector", ""], ["Diril", "Utku", ""], ["Dzhulgakov", "Dmytro", ""], ["Hazelwood", "Kim", ""], ["Jia", "Bill", ""], ["Jia", "Yangqing", ""], ["Qiao", "Lin", ""], ["Rao", "Vijay", ""], ["Rotem", "Nadav", ""], ["Yoo", "Sungjoo", ""], ["Smelyanskiy", "Mikhail", ""]]}, {"id": "1811.09904", "submitter": "Muhammad Shayan", "authors": "Muhammad Shayan, Clement Fung, Chris J.M. Yoon, Ivan Beschastnikh", "title": "Biscotti: A Ledger for Private and Secure Peer-to-Peer Machine Learning", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is the current state of the art in supporting secure\nmulti-party machine learning (ML): data is maintained on the owner's device and\nthe updates to the model are aggregated through a secure protocol. However,\nthis process assumes a trusted centralized infrastructure for coordination, and\nclients must trust that the central service does not use the byproducts of\nclient data. In addition to this, a group of malicious clients could also harm\nthe performance of the model by carrying out a poisoning attack.\n  As a response, we propose Biscotti: a fully decentralized peer to peer (P2P)\napproach to multi-party ML, which uses blockchain and cryptographic primitives\nto coordinate a privacy-preserving ML process between peering clients. Our\nevaluation demonstrates that Biscotti is scalable, fault tolerant, and defends\nagainst known attacks. For example, Biscotti is able to protect the privacy of\nan individual client's update and the performance of the global model at scale\nwhen 30% of adversaries are trying to poison the model.\n  The implementation can be found at: https://github.com/DistributedML/Biscotti\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 22:24:38 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 21:39:04 GMT"}, {"version": "v3", "created": "Sat, 23 Feb 2019 01:40:22 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 04:29:53 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Shayan", "Muhammad", ""], ["Fung", "Clement", ""], ["Yoon", "Chris J. M.", ""], ["Beschastnikh", "Ivan", ""]]}, {"id": "1811.09923", "submitter": "Ido Nachum", "authors": "Ido Nachum and Amir Yehudayoff", "title": "Average-Case Information Complexity of Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many bits of information are revealed by a learning algorithm for a\nconcept class of VC-dimension $d$? Previous works have shown that even for\n$d=1$ the amount of information may be unbounded (tend to $\\infty$ with the\nuniverse size). Can it be that all concepts in the class require leaking a\nlarge amount of information? We show that typically concepts do not require\nleakage. There exists a proper learning algorithm that reveals $O(d)$ bits of\ninformation for most concepts in the class. This result is a special case of a\nmore general phenomenon we explore. If there is a low information learner when\nthe algorithm {\\em knows} the underlying distribution on inputs, then there is\na learner that reveals little information on an average concept {\\em without\nknowing} the distribution on inputs.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 01:47:24 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Nachum", "Ido", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1811.09955", "submitter": "Binbin Liu", "authors": "Binbin Liu, Jundong Li, Yunquan Song, Xijun Liang, Ling Jian and Huan\n  Liu", "title": "Online Newton Step Algorithm with Estimated Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning with limited information feedback (bandit) tries to solve the\nproblem where an online learner receives partial feedback information from the\nenvironment in the course of learning. Under this setting, Flaxman et al.[8]\nextended Zinkevich's classical Online Gradient Descent (OGD) algorithm [29] by\nproposing the Online Gradient Descent with Expected Gradient (OGDEG) algorithm.\nSpecifically, it uses a simple trick to approximate the gradient of the loss\nfunction $f_t$ by evaluating it at a single point and bounds the expected\nregret as $\\mathcal{O}(T^{5/6})$ [8], where the number of rounds is $T$.\nMeanwhile, past research efforts have shown that compared with the first-order\nalgorithms, second-order online learning algorithms such as Online Newton Step\n(ONS) [11] can significantly accelerate the convergence rate of traditional\nonline learning algorithms. Motivated by this, this paper aims to exploit the\nsecond-order information to speed up the convergence of the OGDEG algorithm. In\nparticular, we extend the ONS algorithm with the trick of expected gradient and\ndevelop a novel second-order online learning algorithm, i.e., Online Newton\nStep with Expected Gradient (ONSEG). Theoretically, we show that the proposed\nONSEG algorithm significantly reduces the expected regret of OGDEG algorithm\nfrom $\\mathcal{O}(T^{5/6})$ to $\\mathcal{O}(T^{2/3})$ in the bandit feedback\nscenario. Empirically, we further demonstrate the advantages of the proposed\nalgorithm on multiple real-world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 05:58:57 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 06:14:05 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 02:01:45 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Liu", "Binbin", ""], ["Li", "Jundong", ""], ["Song", "Yunquan", ""], ["Liang", "Xijun", ""], ["Jian", "Ling", ""], ["Liu", "Huan", ""]]}, {"id": "1811.09956", "submitter": "Gurunath Reddy M", "authors": "Gurunath Reddy M, Tanumay Mandal, Krothapalli Sreenivasa Rao", "title": "Glottal Closure Instants Detection From Pathological Acoustic Speech\n  Signal Using Deep Learning", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/39", "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a classification based glottal closure instants\n(GCI) detection from pathological acoustic speech signal, which finds many\napplications in vocal disorder analysis. Till date, GCI for pathological\ndisorder is extracted from laryngeal (glottal source) signal recorded from\nElectroglottograph, a dedicated device designed to measure the vocal folds\nvibration around the larynx. We have created a pathological dataset which\nconsists of simultaneous recordings of glottal source and acoustic speech\nsignal of six different disorders from vocal disordered patients. The GCI\nlocations are manually annotated for disorder analysis and supervised learning.\nWe have proposed convolutional neural network based GCI detection method by\nfusing deep acoustic speech and linear prediction residual features for robust\nGCI detection. The experimental results showed that the proposed method is\nsignificantly better than the state-of-the-art GCI detection methods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 06:18:24 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["M", "Gurunath Reddy", ""], ["Mandal", "Tanumay", ""], ["Rao", "Krothapalli Sreenivasa", ""]]}, {"id": "1811.09960", "submitter": "Jack Fitzsimons", "authors": "Jack Fitzsimons, Michael Osborne and Stephen Roberts", "title": "Intersectionality: Multiple Group Fairness in Expectation Constraints", "comments": "NeurIPS (previously NIPS) 2018, Workshop on Ethical, Social and\n  Governance Issues in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group fairness is an important concern for machine learning researchers,\ndevelopers, and regulators. However, the strictness to which models must be\nconstrained to be considered fair is still under debate. The focus of this work\nis on constraining the expected outcome of subpopulations in kernel regression\nand, in particular, decision tree regression, with application to random\nforests, boosted trees and other ensemble models. While individual constraints\nwere previously addressed, this work addresses concerns about incorporating\nmultiple constraints simultaneously. The proposed solution does not affect the\norder of computational or memory complexity of the decision trees and is easily\nintegrated into models post training.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 06:31:13 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Fitzsimons", "Jack", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1811.09975", "submitter": "Giuseppe Manco", "authors": "Noveen Sachdeva, Giuseppe Manco, Ettore Ritacco, Vikram Pudi", "title": "Sequential Variational Autoencoders for Collaborative Filtering", "comments": "9 pages, 6 figures, 2 tables, WSDM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders were proven successful in domains such as computer\nvision and speech processing. Their adoption for modeling user preferences is\nstill unexplored, although recently it is starting to gain attention in the\ncurrent literature. In this work, we propose a model which extends variational\nautoencoders by exploiting the rich information present in the past preference\nhistory. We introduce a recurrent version of the VAE, where instead of passing\na subset of the whole history regardless of temporal dependencies, we rather\npass the consumption sequence subset through a recurrent neural network. At\neach time-step of the RNN, the sequence is fed through a series of\nfully-connected layers, the output of which models the probability distribution\nof the most likely future preferences. We show that handling temporal\ninformation is crucial for improving the accuracy of the VAE: In fact, our\nmodel beats the current state-of-the-art by valuable margins because of its\nability to capture temporal dependencies among the user-consumption sequence\nusing the recurrent encoder still keeping the fundamentals of variational\nautoencoders intact.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 09:19:18 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Sachdeva", "Noveen", ""], ["Manco", "Giuseppe", ""], ["Ritacco", "Ettore", ""], ["Pudi", "Vikram", ""]]}, {"id": "1811.09977", "submitter": "Junzi Zhang", "authors": "Andrea Zanette, Junzi Zhang, Mykel J. Kochenderfer", "title": "Robust Super-Level Set Estimation using Gaussian Processes", "comments": "Accepted to ECML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of determining as large a region as\npossible where a function exceeds a given threshold with high probability. We\nassume that we only have access to a noise-corrupted version of the function\nand that function evaluations are costly. To select the next query point, we\npropose maximizing the expected volume of the domain identified as above the\nthreshold as predicted by a Gaussian process, robustified by a variance term.\nWe also give asymptotic guarantees on the exploration effect of the algorithm,\nregardless of the prior misspecification. We show by various numerical examples\nthat our approach also outperforms existing techniques in the literature in\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 09:38:43 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Zanette", "Andrea", ""], ["Zhang", "Junzi", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1811.09982", "submitter": "Battista Biggio", "authors": "Battista Biggio, Ignazio Pillai, Samuel Rota Bul\\`o, Davide Ariu,\n  Marcello Pelillo, Fabio Roli", "title": "Is Data Clustering in Adversarial Settings Secure?", "comments": null, "journal-ref": "Proceedings of the 2013 ACM Workshop on Artificial Intelligence\n  and Security, AISec '13, pages 87-98, New York, NY, USA, 2013. ACM", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms have been increasingly adopted in security applications\nto spot dangerous or illicit activities. However, they have not been originally\ndevised to deal with deliberate attack attempts that may aim to subvert the\nclustering process itself. Whether clustering can be safely adopted in such\nsettings remains thus questionable. In this work we propose a general framework\nthat allows one to identify potential attacks against clustering algorithms,\nand to evaluate their impact, by making specific assumptions on the adversary's\ngoal, knowledge of the attacked system, and capabilities of manipulating the\ninput data. We show that an attacker may significantly poison the whole\nclustering process by adding a relatively small percentage of attack samples to\nthe input data, and that some attack samples may be obfuscated to be hidden\nwithin some existing clusters. We present a case study on single-linkage\nhierarchical clustering, and report experiments on clustering of malware\nsamples and handwritten digits.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 10:21:59 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Biggio", "Battista", ""], ["Pillai", "Ignazio", ""], ["Bul\u00f2", "Samuel Rota", ""], ["Ariu", "Davide", ""], ["Pelillo", "Marcello", ""], ["Roli", "Fabio", ""]]}, {"id": "1811.09985", "submitter": "Battista Biggio", "authors": "Battista Biggio, Konrad Rieck, Davide Ariu, Christian Wressnegger,\n  Igino Corona, Giorgio Giacinto, Fabio Roli", "title": "Poisoning Behavioral Malware Clustering", "comments": null, "journal-ref": "2014 ACM CCS Workshop on Artificial Intelligent and Security,\n  AISec '14, pages 27-36, New York, NY, USA, 2014. ACM", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms have become a popular tool in computer security to\nanalyze the behavior of malware variants, identify novel malware families, and\ngenerate signatures for antivirus systems. However, the suitability of\nclustering algorithms for security-sensitive settings has been recently\nquestioned by showing that they can be significantly compromised if an attacker\ncan exercise some control over the input data. In this paper, we revisit this\nproblem by focusing on behavioral malware clustering approaches, and\ninvestigate whether and to what extent an attacker may be able to subvert these\napproaches through a careful injection of samples with poisoning behavior. To\nthis end, we present a case study on Malheur, an open-source tool for\nbehavioral malware clustering. Our experiments not only demonstrate that this\ntool is vulnerable to poisoning attacks, but also that it can be significantly\ncompromised even if the attacker can only inject a very small percentage of\nattacks into the input data. As a remedy, we discuss possible countermeasures\nand highlight the need for more secure clustering algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 10:31:53 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Biggio", "Battista", ""], ["Rieck", "Konrad", ""], ["Ariu", "Davide", ""], ["Wressnegger", "Christian", ""], ["Corona", "Igino", ""], ["Giacinto", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1811.10052", "submitter": "Alexander Lundervold", "authors": "Alexander Selvikv{\\aa}g Lundervold and Arvid Lundervold", "title": "An overview of deep learning in medical imaging focusing on MRI", "comments": "Minor updates. Close to the version published in Zeitschrift f\\\"ur\n  Medizinische Physik (Available online 13 December 2018)", "journal-ref": "Zeitschrift f\\\"ur Medizinische Physik, Volume 29, Issue 2, May\n  2019", "doi": "10.1016/j.zemedi.2018.11.002", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What has happened in machine learning lately, and what does it mean for the\nfuture of medical image analysis? Machine learning has witnessed a tremendous\namount of attention over the last few years. The current boom started around\n2009 when so-called deep artificial neural networks began outperforming other\nestablished models on a number of important benchmarks. Deep neural networks\nare now the state-of-the-art machine learning models across a variety of areas,\nfrom image analysis to natural language processing, and widely deployed in\nacademia and industry. These developments have a huge potential for medical\nimaging technology, medical data analysis, medical diagnostics and healthcare\nin general, slowly being realized. We provide a short overview of recent\nadvances and some associated challenges in machine learning applied to medical\nimage processing and image analysis. As this has become a very broad and fast\nexpanding field we will not survey the entire landscape of applications, but\nput particular focus on deep learning in MRI.\n  Our aim is threefold: (i) give a brief introduction to deep learning with\npointers to core references; (ii) indicate how deep learning has been applied\nto the entire MRI processing chain, from acquisition to image retrieval, from\nsegmentation to disease prediction; (iii) provide a starting point for people\ninterested in experimenting and perhaps contributing to the field of machine\nlearning for medical imaging by pointing out good educational resources,\nstate-of-the-art open-source code, and interesting sources of data and problems\nrelated medical imaging.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 16:40:42 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 09:58:09 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Lundervold", "Alexander Selvikv\u00e5g", ""], ["Lundervold", "Arvid", ""]]}, {"id": "1811.10072", "submitter": "Nicolas Brosse", "authors": "Nicolas Brosse, Alain Durmus, Eric Moulines", "title": "The promises and pitfalls of Stochastic Gradient Langevin Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Langevin Dynamics (SGLD) has emerged as a key MCMC\nalgorithm for Bayesian learning from large scale datasets. While SGLD with\ndecreasing step sizes converges weakly to the posterior distribution, the\nalgorithm is often used with a constant step size in practice and has\ndemonstrated successes in machine learning tasks. The current practice is to\nset the step size inversely proportional to $N$ where $N$ is the number of\ntraining samples. As $N$ becomes large, we show that the SGLD algorithm has an\ninvariant probability measure which significantly departs from the target\nposterior and behaves like Stochastic Gradient Descent (SGD). This difference\nis inherently due to the high variance of the stochastic gradients. Several\nstrategies have been suggested to reduce this effect; among them, SGLD Fixed\nPoint (SGLDFP) uses carefully designed control variates to reduce the variance\nof the stochastic gradients. We show that SGLDFP gives approximate samples from\nthe posterior distribution, with an accuracy comparable to the Langevin Monte\nCarlo (LMC) algorithm for a computational cost sublinear in the number of data\npoints. We provide a detailed analysis of the Wasserstein distances between\nLMC, SGLD, SGLDFP and SGD and explicit expressions of the means and covariance\nmatrices of their invariant distributions. Our findings are supported by\nlimited numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 18:58:39 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Brosse", "Nicolas", ""], ["Durmus", "Alain", ""], ["Moulines", "Eric", ""]]}, {"id": "1811.10097", "submitter": "Johanna Hansen", "authors": "Johanna Hansen, Kyle Kastner, Aaron Courville, Gregory Dudek", "title": "Planning in Dynamic Environments with Conditional Autoregressive Models", "comments": "6 pages, 1 figure, in Proceedings of the Prediction and Generative\n  Modeling in Reinforcement Learning Workshop at the International Conference\n  on Machine Learning (ICML) in 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate the use of conditional autoregressive generative models (van\nden Oord et al., 2016a) over a discrete latent space (van den Oord et al.,\n2017b) for forward planning with MCTS. In order to test this method, we\nintroduce a new environment featuring varying difficulty levels, along with\nmoving goals and obstacles. The combination of high-quality frame generation\nand classical planning approaches nearly matches true environment performance\nfor our task, demonstrating the usefulness of this method for model-based\nplanning in dynamic environments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 21:10:10 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Hansen", "Johanna", ""], ["Kastner", "Kyle", ""], ["Courville", "Aaron", ""], ["Dudek", "Gregory", ""]]}, {"id": "1811.10106", "submitter": "Sung Min Park", "authors": "Guy Bresler, Sung Min Park, Madalina Persu", "title": "Sparse PCA from Sparse Linear Regression", "comments": "To appear in NeurIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Principal Component Analysis (SPCA) and Sparse Linear Regression (SLR)\nhave a wide range of applications and have attracted a tremendous amount of\nattention in the last two decades as canonical examples of statistical problems\nin high dimension. A variety of algorithms have been proposed for both SPCA and\nSLR, but an explicit connection between the two had not been made. We show how\nto efficiently transform a black-box solver for SLR into an algorithm for SPCA:\nassuming the SLR solver satisfies prediction error guarantees achieved by\nexisting efficient algorithms such as those based on the Lasso, the SPCA\nalgorithm derived from it achieves near state of the art guarantees for testing\nand for support recovery for the single spiked covariance model as obtained by\nthe current best polynomialtime algorithms. Our reduction not only highlights\nthe inherent similarity between the two problems, but also, from a practical\nstandpoint, allows one to obtain a collection of algorithms for SPCA directly\nfrom known algorithms for SLR. We provide experimental results on simulated\ndata comparing our proposed framework to other algorithms for SPCA.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 21:54:08 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Bresler", "Guy", ""], ["Park", "Sung Min", ""], ["Persu", "Madalina", ""]]}, {"id": "1811.10112", "submitter": "R\\'emi Besson", "authors": "R\\'emi Besson, Erwan Le Pennec, St\\'ephanie Allassonni\\`ere, Julien\n  Stirnemann, Emmanuel Spaggiari, Antoine Neuraz", "title": "A Model-Based Reinforcement Learning Approach for a Rare Disease\n  Diagnostic Task", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present our various contributions to the objective of\nbuilding a decision support tool for the diagnosis of rare diseases. Our goal\nis to achieve a state of knowledge where the uncertainty about the patient's\ndisease is below a predetermined threshold. We aim to reach such states while\nminimizing the average number of medical tests to perform. In doing so, we take\ninto account the need, in many medical applications, to avoid, as much as\npossible, any misdiagnosis. To solve this optimization task, we investigate\nseveral reinforcement learning algorithm and make them operable in our\nhigh-dimensional and sparse-reward setting. We also present a way to combine\nexpert knowledge, expressed as conditional probabilities, with real clinical\ndata. This is crucial because the scarcity of data in the field of rare\ndiseases prevents any approach based solely on clinical data. Finally we show\nthat it is possible to integrate the ontological information about symptoms\nwhile remaining in our probabilistic reasoning. It enables our decision support\ntool to process information given at different level of precision by the user.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 22:44:54 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Besson", "R\u00e9mi", ""], ["Pennec", "Erwan Le", ""], ["Allassonni\u00e8re", "St\u00e9phanie", ""], ["Stirnemann", "Julien", ""], ["Spaggiari", "Emmanuel", ""], ["Neuraz", "Antoine", ""]]}, {"id": "1811.10115", "submitter": "Giang Tran", "authors": "Lam Si Tung Ho, Hayden Schaeffer, Giang Tran, Rachel Ward", "title": "Recovery guarantees for polynomial approximation from dependent data\n  with outliers", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning non-linear systems from noisy, limited, and/or dependent data is an\nimportant task across various scientific fields including statistics,\nengineering, computer science, mathematics, and many more. In general, this\nlearning task is ill-posed; however, additional information about the data's\nstructure or on the behavior of the unknown function can make the task\nwell-posed. In this work, we study the problem of learning nonlinear functions\nfrom corrupted and dependent data. The learning problem is recast as a sparse\nrobust linear regression problem where we incorporate both the unknown\ncoefficients and the corruptions in a basis pursuit framework. The main\ncontribution of our paper is to provide a reconstruction guarantee for the\nassociated $\\ell_1$-optimization problem where the sampling matrix is formed\nfrom dependent data. Specifically, we prove that the sampling matrix satisfies\nthe null space property and the stable null space property, provided that the\ndata is compact and satisfies a suitable concentration inequality. We show that\nour recovery results are applicable to various types of dependent data such as\nexponentially strongly $\\alpha$-mixing data, geometrically $\\mathcal{C}$-mixing\ndata, and uniformly ergodic Markov chain. Our theoretical results are verified\nvia several numerical simulations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 23:24:59 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Ho", "Lam Si Tung", ""], ["Schaeffer", "Hayden", ""], ["Tran", "Giang", ""], ["Ward", "Rachel", ""]]}, {"id": "1811.10119", "submitter": "Alexander Amini", "authors": "Alexander Amini, Guy Rosman, Sertac Karaman, Daniela Rus", "title": "Variational End-to-End Navigation and Localization", "comments": "Published in IEEE International Conference on Robotics and Automation\n  (ICRA) 2019. Best Paper Award Finalist", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has revolutionized the ability to learn \"end-to-end\" autonomous\nvehicle control directly from raw sensory data. While there have been recent\nextensions to handle forms of navigation instruction, these works are unable to\ncapture the full distribution of possible actions that could be taken and to\nreason about localization of the robot within the environment. In this paper,\nwe extend end-to-end driving networks with the ability to perform\npoint-to-point navigation as well as probabilistic localization using only\nnoisy GPS data. We define a novel variational network capable of learning from\nraw camera data of the environment as well as higher level roadmaps to predict\n(1) a full probability distribution over the possible control commands; and (2)\na deterministic control command capable of navigating on the route specified\nwithin the map. Additionally, we formulate how our model can be used to\nlocalize the robot according to correspondences between the map and the\nobserved visual road topology, inspired by the rough localization that human\ndrivers can perform. We test our algorithms on real-world driving data that the\nvehicle has never driven through before, and integrate our point-to-point\nnavigation algorithms onboard a full-scale autonomous vehicle for real-time\nperformance. Our localization algorithm is also evaluated over a new set of\nroads and intersections to demonstrates rough pose localization even in\nsituations without any GPS prior.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 23:45:30 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 20:51:25 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Amini", "Alexander", ""], ["Rosman", "Guy", ""], ["Karaman", "Sertac", ""], ["Rus", "Daniela", ""]]}, {"id": "1811.10144", "submitter": "Yang Fu", "authors": "Yang Fu, Yunchao Wei, Guanshuo Wang, Yuqian Zhou, Honghui Shi, Thomas\n  Huang", "title": "Self-similarity Grouping: A Simple Unsupervised Cross Domain Adaptation\n  Approach for Person Re-identification", "comments": "This work has been accepted as an Oral presentation at ICCV2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation in person re-identification (re-ID) has always been a\nchallenging task. In this work, we explore how to harness the natural similar\ncharacteristics existing in the samples from the target domain for learning to\nconduct person re-ID in an unsupervised manner. Concretely, we propose a\nSelf-similarity Grouping (SSG) approach, which exploits the potential\nsimilarity (from global body to local parts) of unlabeled samples to\nautomatically build multiple clusters from different views. These independent\nclusters are then assigned with labels, which serve as the pseudo identities to\nsupervise the training process. We repeatedly and alternatively conduct such a\ngrouping and training process until the model is stable. Despite the apparent\nsimplify, our SSG outperforms the state-of-the-arts by more than 4.6% (DukeMTMC\nto Market1501) and 4.4% (Market1501 to DukeMTMC) in mAP, respectively. Upon our\nSSG, we further introduce a clustering-guided semisupervised approach named SSG\n++ to conduct the one-shot domain adaption in an open set setting (i.e. the\nnumber of independent identities from the target domain is unknown). Without\nspending much effort on labeling, our SSG ++ can further promote the mAP upon\nSSG by 10.7% and 6.9%, respectively. Our Code is available at:\nhttps://github.com/OasisYang/SSG .\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 02:17:17 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 21:34:49 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 03:43:29 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Fu", "Yang", ""], ["Wei", "Yunchao", ""], ["Wang", "Guanshuo", ""], ["Zhou", "Yuqian", ""], ["Shi", "Honghui", ""], ["Huang", "Thomas", ""]]}, {"id": "1811.10146", "submitter": "Zhiqin Xu", "authors": "Zhi-Qin John Xu", "title": "Frequency Principle in Deep Learning with General Loss Functions and Its\n  Potential Application", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have shown that deep neural networks (DNNs) with common\nsettings often capture target functions from low to high frequency, which is\ncalled Frequency Principle (F-Principle). It has also been shown that\nF-Principle can provide an understanding to the often observed good\ngeneralization ability of DNNs. However, previous studies focused on the loss\nfunction of mean square error, while various loss functions are used in\npractice. In this work, we show that the F-Principle holds for a general loss\nfunction (e.g., mean square error, cross entropy, etc.). In addition, DNN's\nF-Principle may be applied to develop numerical schemes for solving various\nproblems which would benefit from a fast converging of low frequency. As an\nexample of the potential usage of F-Principle, we apply DNN in solving\ndifferential equations, in which conventional methods (e.g., Jacobi method) is\nusually slow in solving problems due to the convergence from high to low\nfrequency.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 02:27:44 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Xu", "Zhi-Qin John", ""]]}, {"id": "1811.10154", "submitter": "Cynthia Rudin", "authors": "Cynthia Rudin", "title": "Stop Explaining Black Box Machine Learning Models for High Stakes\n  Decisions and Use Interpretable Models Instead", "comments": "Author's pre-publication version of a 2019 Nature Machine\n  Intelligence article. Shorter Version was published in NIPS 2018 Workshop on\n  Critiquing and Correcting Trends in Machine Learning. Expands also on NSF\n  Statistics at a Crossroads Webinar", "journal-ref": "Nature Machine Intelligence, Vol 1, May 2019, 206-215", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Black box machine learning models are currently being used for high stakes\ndecision-making throughout society, causing problems throughout healthcare,\ncriminal justice, and in other domains. People have hoped that creating methods\nfor explaining these black box models will alleviate some of these problems,\nbut trying to \\textit{explain} black box models, rather than creating models\nthat are \\textit{interpretable} in the first place, is likely to perpetuate bad\npractices and can potentially cause catastrophic harm to society. There is a\nway forward -- it is to design models that are inherently interpretable. This\nmanuscript clarifies the chasm between explaining black boxes and using\ninherently interpretable models, outlines several key reasons why explainable\nblack boxes should be avoided in high-stakes decisions, identifies challenges\nto interpretable machine learning, and provides several example applications\nwhere interpretable models could potentially replace black box models in\ncriminal justice, healthcare, and computer vision.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 03:00:25 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 04:09:42 GMT"}, {"version": "v3", "created": "Sun, 22 Sep 2019 03:05:09 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Rudin", "Cynthia", ""]]}, {"id": "1811.10158", "submitter": "Chenchen Li", "authors": "Chenchen Li, Xiang Yan, Xiaotie Deng, Yuan Qi, Wei Chu, Le Song,\n  Junlong Qiao, Jianshan He, Junwu Xiong", "title": "Reinforcement Learning for Uplift Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling aims to directly model the incremental impact of a treatment\non an individual response. In this work, we address the problem from a new\nangle and reformulate it as a Markov Decision Process (MDP). We conducted\nextensive experiments on both a synthetic dataset and real-world scenarios, and\nshowed that our method can achieve significant improvement over previous\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 03:17:38 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 04:37:45 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Li", "Chenchen", ""], ["Yan", "Xiang", ""], ["Deng", "Xiaotie", ""], ["Qi", "Yuan", ""], ["Chu", "Wei", ""], ["Song", "Le", ""], ["Qiao", "Junlong", ""], ["He", "Jianshan", ""], ["Xiong", "Junwu", ""]]}, {"id": "1811.10201", "submitter": "AnChieh Cheng", "authors": "An-Chieh Cheng, Chieh Hubert Lin, Da-Cheng Juan, Wei Wei, Min Sun", "title": "InstaNAS: Instance-aware Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Neural Architecture Search (NAS) aims at finding a single\narchitecture that achieves the best performance, which usually optimizes task\nrelated learning objectives such as accuracy. However, a single architecture\nmay not be representative enough for the whole dataset with high diversity and\nvariety. Intuitively, electing domain-expert architectures that are proficient\nin domain-specific features can further benefit architecture related objectives\nsuch as latency. In this paper, we propose InstaNAS---an instance-aware NAS\nframework---that employs a controller trained to search for a \"distribution of\narchitectures\" instead of a single architecture; This allows the model to use\nsophisticated architectures for the difficult samples, which usually comes with\nlarge architecture related cost, and shallow architectures for those easy\nsamples. During the inference phase, the controller assigns each of the unseen\ninput samples with a domain expert architecture that can achieve high accuracy\nwith customized inference costs. Experiments within a search space inspired by\nMobileNetV2 show InstaNAS can achieve up to 48.8% latency reduction without\ncompromising accuracy on a series of datasets against MobileNetV2.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 06:29:39 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 14:12:40 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 09:25:04 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Cheng", "An-Chieh", ""], ["Lin", "Chieh Hubert", ""], ["Juan", "Da-Cheng", ""], ["Wei", "Wei", ""], ["Sun", "Min", ""]]}, {"id": "1811.10275", "submitter": "Francois-Xavier Briol", "authors": "Francois-Xavier Briol, Chris J. Oates, Mark Girolami, Michael A.\n  Osborne, Dino Sejdinovic", "title": "Rejoinder for \"Probabilistic Integration: A Role in Statistical\n  Computation?\"", "comments": "Accepted to Statistical Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is the rejoinder for the paper \"Probabilistic Integration: A\nRole in Statistical Computation?\" to appear in Statistical Science with\ndiscussion. We would first like to thank the reviewers and many of our\ncolleagues who helped shape this paper, the editor for selecting our paper for\ndiscussion, and of course all of the discussants for their thoughtful,\ninsightful and constructive comments. In this rejoinder, we respond to some of\nthe points raised by the discussants and comment further on the fundamental\nquestions underlying the paper: (i) Should Bayesian ideas be used in numerical\nanalysis?, and (ii) If so, what role should such approaches have in statistical\ncomputation?\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 10:30:38 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Briol", "Francois-Xavier", ""], ["Oates", "Chris J.", ""], ["Girolami", "Mark", ""], ["Osborne", "Michael A.", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1811.10304", "submitter": "Hao Shen", "authors": "Hao Shen", "title": "A Differential Topological View of Challenges in Learning with\n  Feedforward Neural Networks", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among many unsolved puzzles in theories of Deep Neural Networks (DNNs), there\nare three most fundamental challenges that highly demand solutions, namely,\nexpressibility, optimisability, and generalisability. Although there have been\nsignificant progresses in seeking answers using various theories, e.g.\ninformation bottleneck theory, sparse representation, statistical inference,\nRiemannian geometry, etc., so far there is no single theory that is able to\nprovide solutions to all these challenges. In this work, we propose to engage\nthe theory of differential topology to address the three problems. By modelling\nthe dataset of interest as a smooth manifold, DNNs can be considered as\ncompositions of smooth maps between smooth manifolds. Specifically, our work\noffers a differential topological view of loss landscape of DNNs, interplay\nbetween width and depth in expressibility, and regularisations for\ngeneralisability. Finally, in the setting of deep representation learning, we\nfurther apply the quotient topology to investigate the architecture of DNNs,\nwhich enables to capture nuisance factors in data with respect to a specific\nlearning task.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 11:47:15 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Shen", "Hao", ""]]}, {"id": "1811.10376", "submitter": "Yi-Te Hsu", "authors": "Yi-Te Hsu, Zining Zhu, Chi-Te Wang, Shih-Hau Fang, Frank Rudzicz, Yu\n  Tsao", "title": "Robustness against the channel effect in pathological voice detection", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/200", "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many people are suffering from voice disorders, which can adversely affect\nthe quality of their lives. In response, some researchers have proposed\nalgorithms for automatic assessment of these disorders, based on voice signals.\nHowever, these signals can be sensitive to the recording devices. Indeed, the\nchannel effect is a pervasive problem in machine learning for healthcare. In\nthis study, we propose a detection system for pathological voice, which is\nrobust against the channel effect. This system is based on a bidirectional LSTM\nnetwork. To increase the performance robustness against channel mismatch, we\nintegrate domain adversarial training (DAT) to eliminate the differences\nbetween the devices. When we train on data recorded on a high-quality\nmicrophone and evaluate on smartphone data without labels, our robust detection\nsystem increases the PR-AUC from 0.8448 to 0.9455 (and 0.9522 with target\nsample labels). To the best of our knowledge, this is the first study applying\nunsupervised domain adaptation to pathological voice detection. Notably, our\nsystem does not need target device sample labels, which allows for\ngeneralization to many new devices.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 14:11:12 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 14:52:39 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Hsu", "Yi-Te", ""], ["Zhu", "Zining", ""], ["Wang", "Chi-Te", ""], ["Fang", "Shih-Hau", ""], ["Rudzicz", "Frank", ""], ["Tsao", "Yu", ""]]}, {"id": "1811.10382", "submitter": "Chao Ma", "authors": "Chao Ma, Tamir Bendory, Nicolas Boumal, Fred Sigworth, Amit Singer", "title": "Heterogeneous multireference alignment for images with application to\n  2-D classification in single particle reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the task of 2-D classification in single particle reconstruction\nby cryo-electron microscopy (cryo-EM), we consider the problem of heterogeneous\nmultireference alignment of images. In this problem, the goal is to estimate a\n(typically small) set of target images from a (typically large) collection of\nobservations. Each observation is a rotated, noisy version of one of the target\nimages. For each individual observation, neither the rotation nor which target\nimage has been rotated are known. As the noise level in cryo-EM data is high,\nclustering the observations and estimating individual rotations is challenging.\nWe propose a framework to estimate the target images directly from the\nobservations, completely bypassing the need to cluster or register the images.\nThe framework consists of two steps. First, we estimate rotation-invariant\nfeatures of the images, such as the bispectrum. These features can be estimated\nto any desired accuracy, at any noise level, provided sufficiently many\nobservations are collected. Then, we estimate the images from the invariant\nfeatures. Numerical experiments on synthetic cryo-EM datasets demonstrate the\neffectiveness of the method. Ultimately, we outline future developments\nrequired to apply this method to experimental data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 02:50:21 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 20:17:09 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Ma", "Chao", ""], ["Bendory", "Tamir", ""], ["Boumal", "Nicolas", ""], ["Sigworth", "Fred", ""], ["Singer", "Amit", ""]]}, {"id": "1811.10427", "submitter": "Qunwei Li", "authors": "Qunwei Li, Bhavya Kailkhura, Rushil Anirudh, Yi Zhou, Yingbin Liang,\n  Pramod Varshney", "title": "MR-GAN: Manifold Regularized Generative Adversarial Networks", "comments": "arXiv admin note: text overlap with arXiv:1706.04156 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing interest in generative adversarial networks (GANs),\ntraining GANs remains a challenging problem, both from a theoretical and a\npractical standpoint. To address this challenge, in this paper, we propose a\nnovel way to exploit the unique geometry of the real data, especially the\nmanifold information. More specifically, we design a method to regularize GAN\ntraining by adding an additional regularization term referred to as manifold\nregularizer. The manifold regularizer forces the generator to respect the\nunique geometry of the real data manifold and generate high quality data.\nFurthermore, we theoretically prove that the addition of this regularization\nterm in any class of GANs including DCGAN and Wasserstein GAN leads to improved\nperformance in terms of generalization, existence of equilibrium, and\nstability. Preliminary experiments show that the proposed manifold\nregularization helps in avoiding mode collapse and leads to stable training.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 21:21:02 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Li", "Qunwei", ""], ["Kailkhura", "Bhavya", ""], ["Anirudh", "Rushil", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""], ["Varshney", "Pramod", ""]]}, {"id": "1811.10435", "submitter": "Nicol\\`o Navarin", "authors": "Dinh Van Tran, Nicol\\`o Navarin, Alessandro Sperduti", "title": "On Filter Size in Graph Convolutional Networks", "comments": "arXiv admin note: text overlap with arXiv:1811.06930", "journal-ref": "IEEE Symposium on Deep Learning, 2018 Symposium Series on\n  Computational Intelligence, 18 - 21 November, 2018, Bengaluru, India", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many researchers have been focusing on the definition of neural\nnetworks for graphs. The basic component for many of these approaches remains\nthe graph convolution idea proposed almost a decade ago. In this paper, we\nextend this basic component, following an intuition derived from the well-known\nconvolutional filters over multi-dimensional tensors. In particular, we derive\na simple, efficient and effective way to introduce a hyper-parameter on graph\nconvolutions that influences the filter size, i.e. its receptive field over the\nconsidered graph. We show with experimental results on real-world graph\ndatasets that the proposed graph convolutional filter improves the predictive\nperformance of Deep Graph Convolutional Networks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 13:45:30 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Van Tran", "Dinh", ""], ["Navarin", "Nicol\u00f2", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "1811.10455", "submitter": "Harry Clifford MSci DPhil", "authors": "Geoffroy Dubourg-Felonneau, Timothy Cannings, Fergal Cotter, Hannah\n  Thompson, Nirmesh Patel, John W Cassidy, Harry W Clifford", "title": "A Framework for Implementing Machine Learning on Omics Data", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/102", "categories": "cs.LG cs.AI q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential benefits of applying machine learning methods to -omics data\nare becoming increasingly apparent, especially in clinical settings. However,\nthe unique characteristics of these data are not always well suited to machine\nlearning techniques. These data are often generated across different\ntechnologies in different labs, and frequently with high dimensionality. In\nthis paper we present a framework for combining -omics data sets, and for\nhandling high dimensional data, making -omics research more accessible to\nmachine learning applications. We demonstrate the success of this framework\nthrough integration and analysis of multi-analyte data for a set of 3,533\nbreast cancers. We then use this data-set to predict breast cancer patient\nsurvival for individuals at risk of an impending event, with higher accuracy\nand lower variance than methods trained on individual data-sets. We hope that\nour pipelines for data-set generation and transformation will open up -omics\ndata to machine learning researchers. We have made these freely available for\nnoncommercial use at www.ccg.ai.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 15:35:57 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Dubourg-Felonneau", "Geoffroy", ""], ["Cannings", "Timothy", ""], ["Cotter", "Fergal", ""], ["Thompson", "Hannah", ""], ["Patel", "Nirmesh", ""], ["Cassidy", "John W", ""], ["Clifford", "Harry W", ""]]}, {"id": "1811.10469", "submitter": "Jinwei Zhao", "authors": "Jinwei Zhao, Qizhou Wang, Yufei Wang, Yu Liu, Zhenghao Shi, Xinhong\n  Hei", "title": "How to improve the interpretability of kernel learning", "comments": "arXiv admin note: text overlap with arXiv:1811.07747", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning researchers have focused on methods to\nconstruct flexible and interpretable prediction models. However, an\ninterpretability evaluation, a relationship between generalization performance\nand an interpretability of the model and a method for improving the\ninterpretability have to be considered. In this paper, a quantitative index of\nthe interpretability is proposed and its rationality is proved, and equilibrium\nproblem between the interpretability and the generalization performance is\nanalyzed. Probability upper bound of the sum of the two performances is\nanalyzed. For traditional supervised kernel machine learning problem, a\nuniversal learning framework is put forward to solve the equilibrium problem\nbetween the two performances. The condition for global optimal solution based\non the framework is deduced. The learning framework is applied to the\nleast-squares support vector machine and is evaluated by some experiments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:36:35 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 04:24:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhao", "Jinwei", ""], ["Wang", "Qizhou", ""], ["Wang", "Yufei", ""], ["Liu", "Yu", ""], ["Shi", "Zhenghao", ""], ["Hei", "Xinhong", ""]]}, {"id": "1811.10481", "submitter": "Mariana Souza", "authors": "Rafael M. O. Cruz, Mariana A. Souza, Robert Sabourin and George D. C.\n  Cavalcanti", "title": "ICPRAI 2018 SI: On dynamic ensemble selection and data preprocessing for\n  multi-class imbalance learning", "comments": "Manuscript of the extended journal version of arXiv:1803.03877. This\n  manuscript was accepted for publication in the IJPRAI as a Special Issue\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-imbalance refers to classification problems in which many more\ninstances are available for certain classes than for others. Such imbalanced\ndatasets require special attention because traditional classifiers generally\nfavor the majority class which has a large number of instances. Ensemble of\nclassifiers have been reported to yield promising results. However, the\nmajority of ensemble methods applied to imbalanced learning are static ones.\nMoreover, they only deal with binary imbalanced problems. Hence, this paper\npresents an empirical analysis of dynamic selection techniques and data\npreprocessing methods for dealing with multi-class imbalanced problems. We\nconsidered five variations of preprocessing methods and fourteen dynamic\nselection schemes. Our experiments conducted on 26 multi-class imbalanced\nproblems show that the dynamic ensemble improves the AUC and the G-mean as\ncompared to the static ensemble. Moreover, data preprocessing plays an\nimportant role in such cases.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 14:27:28 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 00:32:07 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Souza", "Mariana A.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1811.10501", "submitter": "Edward De Brouwer", "authors": "Edward De Brouwer, Jaak Simm, Adam Arany and Yves Moreau", "title": "Deep Ensemble Tensor Factorization for Longitudinal Patient Trajectories\n  Classification", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative approach to classify scarcely observed longitudinal\npatient trajectories. The available time series are represented as tensors and\nfactorized using generative deep recurrent neural networks. The learned factors\nrepresent the patient data in a compact way and can then be used in a\ndownstream classification task. For more robustness and accuracy in the\npredictions, we used an ensemble of those deep generative models to mimic\nBayesian posterior sampling. We illustrate the performance of our architecture\non an intensive-care case study of in-hospital mortality prediction with 96\nlongitudinal measurement types measured across the first 48-hour from\nadmission. Our combination of generative and ensemble strategies achieves an\nAUC of over 0.85, and outperforms the SAPS-II mortality score and GRU\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 16:50:41 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 07:56:51 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["De Brouwer", "Edward", ""], ["Simm", "Jaak", ""], ["Arany", "Adam", ""], ["Moreau", "Yves", ""]]}, {"id": "1811.10541", "submitter": "Florian Bernard", "authors": "Florian Bernard, Johan Thunberg, Paul Swoboda, Christian Theobalt", "title": "Higher-order Projected Power Iterations for Scalable Multi-Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The matching of multiple objects (e.g. shapes or images) is a fundamental\nproblem in vision and graphics. In order to robustly handle ambiguities, noise\nand repetitive patterns in challenging real-world settings, it is essential to\ntake geometric consistency between points into account. Computationally, the\nmulti-matching problem is difficult. It can be phrased as simultaneously\nsolving multiple (NP-hard) quadratic assignment problems (QAPs) that are\ncoupled via cycle-consistency constraints. The main limitations of existing\nmulti-matching methods are that they either ignore geometric consistency and\nthus have limited robustness, or they are restricted to small-scale problems\ndue to their (relatively) high computational cost. We address these\nshortcomings by introducing a Higher-order Projected Power Iteration method,\nwhich is (i) efficient and scales to tens of thousands of points, (ii)\nstraightforward to implement, (iii) able to incorporate geometric consistency,\n(iv) guarantees cycle-consistent multi-matchings, and (iv) comes with\ntheoretical convergence guarantees. Experimentally we show that our approach is\nsuperior to existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:44:48 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 09:11:59 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Bernard", "Florian", ""], ["Thunberg", "Johan", ""], ["Swoboda", "Paul", ""], ["Theobalt", "Christian", ""]]}, {"id": "1811.10559", "submitter": "Pravendra Singh", "authors": "Pravendra Singh, Vinay Kumar Verma, Piyush Rai and Vinay P. Namboodiri", "title": "Leveraging Filter Correlations for Deep Model Compression", "comments": "IEEE Winter Conference on Applications of Computer Vision (WACV),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a filter correlation based model compression approach for deep\nconvolutional neural networks. Our approach iteratively identifies pairs of\nfilters with the largest pairwise correlations and drops one of the filters\nfrom each such pair. However, instead of discarding one of the filters from\neach such pair na\\\"{i}vely, the model is re-optimized to make the filters in\nthese pairs maximally correlated, so that discarding one of the filters from\nthe pair results in minimal information loss. Moreover, after discarding the\nfilters in each round, we further finetune the model to recover from the\npotential small loss incurred by the compression. We evaluate our proposed\napproach using a comprehensive set of experiments and ablation studies. Our\ncompression method yields state-of-the-art FLOPs compression rates on various\nbenchmarks, such as LeNet-5, VGG-16, and ResNet-50,56, while still achieving\nexcellent predictive performance for tasks such as object detection on\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 18:05:18 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 20:16:50 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Singh", "Pravendra", ""], ["Verma", "Vinay Kumar", ""], ["Rai", "Piyush", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1811.10561", "submitter": "Jerome Abdelnour", "authors": "Jerome Abdelnour, Giampiero Salvi, Jean Rouat", "title": "CLEAR: A Dataset for Compositional Language and Elementary Acoustic\n  Reasoning", "comments": "NeurIPS 2018 Visually Grounded Interaction and Language (ViGIL)\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of acoustic question answering (AQA) in the area of\nacoustic reasoning. In this task an agent learns to answer questions on the\nbasis of acoustic context. In order to promote research in this area, we\npropose a data generation paradigm adapted from CLEVR (Johnson et al. 2017). We\ngenerate acoustic scenes by leveraging a bank elementary sounds. We also\nprovide a number of functional programs that can be used to compose questions\nand answers that exploit the relationships between the attributes of the\nelementary sounds in each scene. We provide AQA datasets of various sizes as\nwell as the data generation code. As a preliminary experiment to validate our\ndata, we report the accuracy of current state of the art visual question\nanswering models when they are applied to the AQA task without modifications.\nAlthough there is a plethora of question answering tasks based on text, image\nor video data, to our knowledge, we are the first to propose answering\nquestions directly on audio streams. We hope this contribution will facilitate\nthe development of research in the area.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 18:06:36 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Abdelnour", "Jerome", ""], ["Salvi", "Giampiero", ""], ["Rouat", "Jean", ""]]}, {"id": "1811.10574", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G.C.A. Cimino, Gigliola Vaglini", "title": "Using stigmergy to incorporate the time into artificial neural networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-05918-7_22", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A current research trend in neurocomputing involves the design of novel\nartificial neural networks incorporating the concept of time into their\noperating model. In this paper, a novel architecture that employs stigmergy is\nproposed. Computational stigmergy is used to dynamically increase (or decrease)\nthe strength of a connection, or the activation level, of an artificial neuron\nwhen stimulated (or released). This study lays down a basic framework for the\nderivation of a stigmergic NN with a related training algorithm. To show its\npotential, some pilot experiments have been reported. The XOR problem is solved\nby using only one single stigmergic neuron with one input and one output. A\nstatic NN, a stigmergic NN, a recurrent NN and a long short-term memory NN have\nbeen trained to solve the MNIST digits recognition benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 00:12:11 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1811.10581", "submitter": "Nishanth Dikkala", "authors": "Constantinos Daskalakis and Nishanth Dikkala and Siddhartha Jayanti", "title": "HOGWILD!-Gibbs can be PanAccurate", "comments": "19 pages, 3 figures, published at NeurIPS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous Gibbs sampling has been recently shown to be fast-mixing and an\naccurate method for estimating probabilities of events on a small number of\nvariables of a graphical model satisfying Dobrushin's\ncondition~\\cite{DeSaOR16}. We investigate whether it can be used to accurately\nestimate expectations of functions of {\\em all the variables} of the model.\nUnder the same condition, we show that the synchronous (sequential) and\nasynchronous Gibbs samplers can be coupled so that the expected Hamming\ndistance between their (multivariate) samples remains bounded by $O(\\tau \\log\nn),$ where $n$ is the number of variables in the graphical model, and $\\tau$ is\na measure of the asynchronicity. A similar bound holds for any constant power\nof the Hamming distance. Hence, the expectation of any function that is\nLipschitz with respect to a power of the Hamming distance, can be estimated\nwith a bias that grows logarithmically in $n$. Going beyond Lipschitz\nfunctions, we consider the bias arising from asynchronicity in estimating the\nexpectation of polynomial functions of all variables in the model. Using recent\nconcentration of measure results, we show that the bias introduced by the\nasynchronicity is of smaller order than the standard deviation of the function\nvalue already present in the true model. We perform experiments on a\nmulti-processor machine to empirically illustrate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 18:36:51 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Jayanti", "Siddhartha", ""]]}, {"id": "1811.10649", "submitter": "Minghai Qin", "authors": "Minghai Qin, Dejan Vucinic", "title": "Noisy Computations during Inference: Harmful or Helpful?", "comments": "20 pages, 11 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two aspects of noisy computations during inference. The first aspect\nis how to mitigate their side effects for naturally trained deep learning\nsystems. One of the motivations for looking into this problem is to reduce the\nhigh power cost of conventional computing of neural networks through the use of\nanalog neuromorphic circuits. Traditional GPU/CPU-centered deep learning\narchitectures exhibit bottlenecks in power-restricted applications (e.g.,\nembedded systems). The use of specialized neuromorphic circuits, where analog\nsignals passed through memory-cell arrays are sensed to accomplish\nmatrix-vector multiplications, promises large power savings and speed gains but\nbrings with it the problems of limited precision of computations and\nunavoidable analog noise. We manage to improve inference accuracy from 21.1% to\n99.5% for MNIST images, from 29.9% to 89.1% for CIFAR10, and from 15.5% to\n89.6% for MNIST stroke sequences with the presence of strong noise (with\nsignal-to-noise power ratio being 0 dB) by noise-injected training and a voting\nmethod. This observation promises neural networks that are insensitive to\ninference noise, which reduces the quality requirements on neuromorphic\ncircuits and is crucial for their practical usage. The second aspect is how to\nutilize the noisy inference as a defensive architecture against black-box\nadversarial attacks. During inference, by injecting proper noise to signals in\nthe neural networks, the robustness of adversarially-trained neural networks\nagainst black-box attacks has been further enhanced by 0.5% and 1.13% for two\nadversarially trained models for MNIST and CIFAR10, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 19:18:18 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Qin", "Minghai", ""], ["Vucinic", "Dejan", ""]]}, {"id": "1811.10658", "submitter": "Kyle Brown", "authors": "Kyle Brown, Derek Doran, Ryan Kramer, Brad Reynolds", "title": "HELOC Applicant Risk Performance Evaluation by Topological Hierarchical\n  Decomposition", "comments": "10 pages, 4 figures, to be published in the NIPS 2018 Workshop on\n  Challenges and Opportunities for AI in Financial Services: the Impact of\n  Fairness, Explainability, Accuracy, and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong regulations in the financial industry mean that any decisions based on\nmachine learning need to be explained. This precludes the use of powerful\nsupervised techniques such as neural networks. In this study we propose a new\nunsupervised and semi-supervised technique known as the topological\nhierarchical decomposition (THD). This process breaks a dataset down into ever\nsmaller groups, where groups are associated with a simplicial complex that\napproximate the underlying topology of a dataset. We apply THD to the FICO\nmachine learning challenge dataset, consisting of anonymized home equity loan\napplications using the MAPPER algorithm to build simplicial complexes. We\nidentify different groups of individuals unable to pay back loans, and\nillustrate how the distribution of feature values in a simplicial complex can\nbe used to explain the decision to grant or deny a loan by extracting\nillustrative explanations from two THDs on the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 19:35:11 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Brown", "Kyle", ""], ["Doran", "Derek", ""], ["Kramer", "Ryan", ""], ["Reynolds", "Brad", ""]]}, {"id": "1811.10678", "submitter": "Navin Anwani", "authors": "Navin Anwani and Bipin Rajendran", "title": "Training Multi-layer Spiking Neural Networks using NormAD based\n  Spatio-Temporal Error Backpropagation", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) have garnered a great amount of interest for\nsupervised and unsupervised learning applications. This paper deals with the\nproblem of training multi-layer feedforward SNNs. The non-linear\nintegrate-and-fire dynamics employed by spiking neurons make it difficult to\ntrain SNNs to generate desired spike trains in response to a given input. To\ntackle this, first the problem of training a multi-layer SNN is formulated as\nan optimization problem such that its objective function is based on the\ndeviation in membrane potential rather than the spike arrival instants. Then,\nan optimization method named Normalized Approximate Descent (NormAD),\nhand-crafted for such non-convex optimization problems, is employed to derive\nthe iterative synaptic weight update rule. Next, it is reformulated to\nefficiently train multi-layer SNNs, and is shown to be effectively performing\nspatio-temporal error backpropagation. The learning rule is validated by\ntraining $2$-layer SNNs to solve a spike based formulation of the XOR problem\nas well as training $3$-layer SNNs for generic spike based training problems.\nThus, the new algorithm is a key step towards building deep spiking neural\nnetworks capable of efficient event-triggered learning.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:19:44 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 03:37:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Anwani", "Navin", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1811.10689", "submitter": "Ieva Kazlauskaite", "authors": "Ieva Kazlauskaite, Ivan Ustyuzhaninov, Carl Henrik Ek, Neill D. F.\n  Campbell", "title": "Sequence Alignment with Dirichlet Process Mixtures", "comments": "6 pages, 3 figures, \"All Of Bayesian Nonparametrics\" Workshop at the\n  32nd Annual Conference on Neural Information Processing Systems\n  (BNP@NeurIPS2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic model for unsupervised alignment of\nhigh-dimensional time-warped sequences based on the Dirichlet Process Mixture\nModel (DPMM). We follow the approach introduced in (Kazlauskaite, 2018) of\nsimultaneously representing each data sequence as a composition of a true\nunderlying function and a time-warping, both of which are modelled using\nGaussian processes (GPs) (Rasmussen, 2005), and aligning the underlying\nfunctions using an unsupervised alignment method. In (Kazlauskaite, 2018) the\nalignment is performed using the GP latent variable model (GP-LVM) (Lawrence,\n2005) as a model of sequences, while our main contribution is extending this\napproach to using DPMM, which allows us to align the sequences temporally and\ncluster them at the same time. We show that the DPMM achieves competitive\nresults in comparison to the GP-LVM on synthetic and real-world data sets, and\ndiscuss the different properties of the estimated underlying functions and the\ntime-warps favoured by these models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 21:08:54 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Kazlauskaite", "Ieva", ""], ["Ustyuzhaninov", "Ivan", ""], ["Ek", "Carl Henrik", ""], ["Campbell", "Neill D. F.", ""]]}, {"id": "1811.10714", "submitter": "Taylor Killian", "authors": "Justin A. Goodwin, Olivia M. Brown, Taylor W. Killian, Sung-Hyun Son", "title": "Learning Robust Representations for Automatic Target Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio frequency (RF) sensors are used alongside other sensing modalities to\nprovide rich representations of the world. Given the high variability of\ncomplex-valued target responses, RF systems are susceptible to attacks masking\ntrue target characteristics from accurate identification. In this work, we\nevaluate different techniques for building robust classification architectures\nexploiting learned physical structure in received synthetic aperture radar\nsignals of simulated 3D targets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 22:08:21 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Goodwin", "Justin A.", ""], ["Brown", "Olivia M.", ""], ["Killian", "Taylor W.", ""], ["Son", "Sung-Hyun", ""]]}, {"id": "1811.10734", "submitter": "Palash Goyal", "authors": "Palash Goyal, Sujit Rokka Chhetri, Ninareh Mehrabi, Emilio Ferrara,\n  Arquimedes Canedo", "title": "DynamicGEM: A Library for Dynamic Graph Embedding Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DynamicGEM is an open-source Python library for learning node representations\nof dynamic graphs. It consists of state-of-the-art algorithms for defining\nembeddings of nodes whose connections evolve over time. The library also\ncontains the evaluation framework for four downstream tasks on the network:\ngraph reconstruction, static and temporal link prediction, node classification,\nand temporal visualization. We have implemented various metrics to evaluate the\nstate-of-the-art methods, and examples of evolving networks from various\ndomains. We have easy-to-use functions to call and evaluate the methods and\nhave extensive usage documentation. Furthermore, DynamicGEM provides a template\nto add new algorithms with ease to facilitate further research on the topic.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:05:38 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Goyal", "Palash", ""], ["Chhetri", "Sujit Rokka", ""], ["Mehrabi", "Ninareh", ""], ["Ferrara", "Emilio", ""], ["Canedo", "Arquimedes", ""]]}, {"id": "1811.10735", "submitter": "Chapman Siu", "authors": "Chapman Siu", "title": "Automatic Induction of Neural Network Decision Tree Algorithms", "comments": "This is a pre-print of a contribution \"Chapman Siu, Automatic\n  Induction of Neural Network Decision Tree Algorithms.\" To appear in Computing\n  Conference 2019 Proceedings. Advances in Intelligent Systems and Computing.\n  Implementation:\n  https://github.com/chappers/automatic-induction-neural-decision-tree", "journal-ref": null, "doi": "10.1007/978-3-030-22871-2_48", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an approach to automatically induction for non-greedy\ndecision trees constructed from neural network architecture. This construction\ncan be used to transfer weights when growing or pruning a decision tree,\nallowing non-greedy decision tree algorithms to automatically learn and adapt\nto the ideal architecture. In this work, we examine the underpinning ideas\nwithin ensemble modelling and Bayesian model averaging which allow our neural\nnetwork to asymptotically approach the ideal architecture through weights\ntransfer. Experimental results demonstrate that this approach improves models\nover fixed set of hyperparameters for decision tree models and decision forest\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:06:38 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 11:51:26 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 03:09:17 GMT"}, {"version": "v4", "created": "Thu, 25 Apr 2019 03:21:04 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Siu", "Chapman", ""]]}, {"id": "1811.10736", "submitter": "Loren Lugosch", "authors": "Loren Lugosch, Samuel Myer, Vikrant Singh Tomar", "title": "DONUT: CTC-based Query-by-Example Keyword Spotting", "comments": "Accepted to NeurIPS 2018 Workshop on Interpretability and Robustness\n  for Audio, Speech, and Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting--or wakeword detection--is an essential feature for\nhands-free operation of modern voice-controlled devices. With such devices\nbecoming ubiquitous, users might want to choose a personalized custom wakeword.\nIn this work, we present DONUT, a CTC-based algorithm for online\nquery-by-example keyword spotting that enables custom wakeword detection. The\nalgorithm works by recording a small number of training examples from the user,\ngenerating a set of label sequence hypotheses from these training examples, and\ndetecting the wakeword by aggregating the scores of all the hypotheses given a\nnew audio recording. Our method combines the generalization and\ninterpretability of CTC-based keyword spotting with the user-adaptation and\nconvenience of a conventional query-by-example system. DONUT has low\ncomputational requirements and is well-suited for both learning and inference\non embedded systems without requiring private user data to be uploaded to the\ncloud.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:13:25 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Lugosch", "Loren", ""], ["Myer", "Samuel", ""], ["Tomar", "Vikrant Singh", ""]]}, {"id": "1811.10740", "submitter": "Subba Reddy Oota", "authors": "Subba Reddy Oota, Adithya Avvaru, Naresh Manwani, Raju S. Bapi", "title": "Mixture of Regression Experts in fMRI Encoding", "comments": "8 pages, 3 figures, Workshop on Visually Grounded Interaction and\n  Language @ 32nd Conference on Neural Information Processing Systems (NeurIPS\n  2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  fMRI semantic category understanding using linguistic encoding models attempt\nto learn a forward mapping that relates stimuli to the corresponding brain\nactivation. Classical encoding models use linear multi-variate methods to\npredict the brain activation (all voxels) given the stimulus. However, these\nmethods essentially assume multiple regions as one large uniform region or\nseveral independent regions, ignoring connections among them. In this paper, we\npresent a mixture of experts-based model where a group of experts captures\nbrain activity patterns related to particular regions of interest (ROI) and\nalso show the discrimination across different experts. The model is trained\nword stimuli encoded as 25-dimensional feature vectors as input and the\ncorresponding brain responses as output. Given a new word (25-dimensional\nfeature vector), it predicts the entire brain activation as the linear\ncombination of multiple experts brain activations. We argue that each expert\nlearns a certain region of brain activations corresponding to its category of\nwords, which solves the problem of identifying the regions with a simple\nencoding model. We showcase that proposed mixture of experts-based model indeed\nlearns region-based experts to predict the brain activations with high spatial\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:21:30 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 17:14:03 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Oota", "Subba Reddy", ""], ["Avvaru", "Adithya", ""], ["Manwani", "Naresh", ""], ["Bapi", "Raju S.", ""]]}, {"id": "1811.10745", "submitter": "Bao Wang", "authors": "Bao Wang and Binjie Yuan and Zuoqiang Shi and Stanley J. Osher", "title": "ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and\n  Robust Accuracies", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical adversarial risk minimization (EARM) is a widely used mathematical\nframework to robustly train deep neural nets (DNNs) that are resistant to\nadversarial attacks. However, both natural and robust accuracies, in\nclassifying clean and adversarial images, respectively, of the trained robust\nmodels are far from satisfactory. In this work, we unify the theory of optimal\ncontrol of transport equations with the practice of training and testing of\nResNets. Based on this unified viewpoint, we propose a simple yet effective\nResNets ensemble algorithm to boost the accuracy of the robustly trained model\non both clean and adversarial images. The proposed algorithm consists of two\ncomponents: First, we modify the base ResNets by injecting a variance specified\nGaussian noise to the output of each residual mapping. Second, we average over\nthe production of multiple jointly trained modified ResNets to get the final\nprediction. These two steps give an approximation to the Feynman-Kac formula\nfor representing the solution of a transport equation with viscosity, or a\nconvection-diffusion equation. For the CIFAR10 benchmark, this simple algorithm\nleads to a robust model with a natural accuracy of {\\bf 85.62}\\% on clean\nimages and a robust accuracy of ${\\bf 57.94 \\%}$ under the 20 iterations of the\nIFGSM attack, which outperforms the current state-of-the-art in defending\nagainst IFGSM attack on the CIFAR10. Both natural and robust accuracies of the\nproposed ResNets ensemble can be improved dynamically as the building block\nResNet advances. The code is available at:\n\\url{https://github.com/BaoWangMath/EnResNet}.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:46:09 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 05:07:37 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Bao", ""], ["Yuan", "Binjie", ""], ["Shi", "Zuoqiang", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1811.10746", "submitter": "Daniel Jarrett", "authors": "Daniel Jarrett, Jinsung Yoon, Mihaela van der Schaar", "title": "MATCH-Net: Dynamic Prediction in Survival Analysis using Convolutional\n  Neural Networks", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/36", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of disease trajectories is critical for early\nidentification and timely treatment of patients at risk. Conventional methods\nin survival analysis are often constrained by strong parametric assumptions and\nlimited in their ability to learn from high-dimensional data, while existing\nneural network models are not readily-adapted to the longitudinal setting. This\npaper develops a novel convolutional approach that addresses these drawbacks.\nWe present MATCH-Net: a Missingness-Aware Temporal Convolutional Hitting-time\nNetwork, designed to capture temporal dependencies and heterogeneous\ninteractions in covariate trajectories and patterns of missingness. To the best\nof our knowledge, this is the first investigation of temporal convolutions in\nthe context of dynamic prediction for personalized risk prognosis. Using\nreal-world data from the Alzheimer's Disease Neuroimaging Initiative, we\ndemonstrate state-of-the-art performance without making any assumptions\nregarding underlying longitudinal or time-to-event processes attesting to the\nmodel's potential utility in clinical decision support.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:50:24 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Jarrett", "Daniel", ""], ["Yoon", "Jinsung", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1811.10790", "submitter": "Sen Na", "authors": "Sen Na, Mladen Kolar", "title": "High-dimensional Index Volatility Models via Stein's Identity", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation of the parametric components of single and multiple\nindex volatility models. Using the first- and second-order Stein's identities,\nwe develop methods that are applicable for the estimation of the variance index\nin the high-dimensional setting requiring finite moment condition, which allows\nfor heavy-tailed data. Our approach complements the existing literature in the\nlow-dimensional setting, while relaxing the conditions on estimation, and\nprovides a novel approach in the high-dimensional setting. We prove that the\nstatistical rate of convergence of our variance index estimators consists of a\nparametric rate and a nonparametric rate, where the latter appears from the\nestimation of the mean link function. However, under standard assumptions, the\nparametric rate dominates the rate of convergence and our results match the\nminimax optimal rate for the mean index estimation. Simulation results\nillustrate finite sample properties of our methodology and back our theoretical\nconclusions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 03:32:03 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 16:40:28 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 21:22:52 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Na", "Sen", ""], ["Kolar", "Mladen", ""]]}, {"id": "1811.10791", "submitter": "Wenqian Ronny Huang", "authors": "W. Ronny Huang and Miguel A. Perez", "title": "Accurate, Data-Efficient Learning from Noisy, Choice-Based Labels for\n  Inherent Risk Scoring", "comments": "Presented as an oral at the NIPS 2018 Workshop on Challenges and\n  Opportunities for AI in Financial Services: the Impact of Fairness,\n  Explainability, Accuracy, and Privacy (FEAP-AI4Fin 2018). 9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inherent risk scoring is an important function in anti-money laundering, used\nfor determining the riskiness of an individual during onboarding\n$\\textit{before}$ fraudulent transactions occur. It is, however, often fraught\nwith two challenges: (1) inconsistent notions of what constitutes as high or\nlow risk by experts and (2) the lack of labeled data. This paper explores a new\nparadigm of data labeling and data collection to tackle these issues. The data\nlabeling is choice-based; the expert does not provide an absolute risk score\nbut merely chooses the most/least risky example out of a small choice set,\nwhich reduces inconsistency because experts make only relative judgments of\nrisk. The data collection is synthetic; examples are crafted using optimal\nexperimental design methods, obviating the need for real data which is often\ndifficult to obtain due to regulatory concerns. We present the methodology of\nan end-to-end inherent risk scoring algorithm that we built for a large\nfinancial institution. The system was trained on a small set of synthetic data\n(188 examples, 24 features) whose labels are obtained via the choice-based\nparadigm using an efficient number of expert labelers. The system achieves 89%\naccuracy on a test set of 52 examples, with an area under the ROC curve of 93%.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 03:38:54 GMT"}], "update_date": "2018-12-02", "authors_parsed": [["Huang", "W. Ronny", ""], ["Perez", "Miguel A.", ""]]}, {"id": "1811.10792", "submitter": "Mahmoud Assran", "authors": "Mahmoud Assran, Nicolas Loizou, Nicolas Ballas, Michael Rabbat", "title": "Stochastic Gradient Push for Distributed Deep Learning", "comments": "ICML 2019", "journal-ref": "International Conference on Machine Learning 97 (2019) 344-353", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed data-parallel algorithms aim to accelerate the training of deep\nneural networks by parallelizing the computation of large mini-batch gradient\nupdates across multiple nodes. Approaches that synchronize nodes using exact\ndistributed averaging (e.g., via AllReduce) are sensitive to stragglers and\ncommunication delays. The PushSum gossip algorithm is robust to these issues,\nbut only performs approximate distributed averaging. This paper studies\nStochastic Gradient Push (SGP), which combines PushSum with stochastic gradient\nupdates. We prove that SGP converges to a stationary point of smooth,\nnon-convex objectives at the same sub-linear rate as SGD, and that all nodes\nachieve consensus. We empirically validate the performance of SGP on image\nclassification (ResNet-50, ImageNet) and machine translation (Transformer,\nWMT'16 En-De) workloads. Our code will be made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 03:47:26 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:58:36 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 19:59:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Assran", "Mahmoud", ""], ["Loizou", "Nicolas", ""], ["Ballas", "Nicolas", ""], ["Rabbat", "Michael", ""]]}, {"id": "1811.10797", "submitter": "Dimitrios Berberidis", "authors": "Dimitris Berberidis and Georgios B. Giannakis", "title": "Node Embedding with Adaptive Similarities for Scalable Learning over\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node embedding is the task of extracting informative and descriptive features\nover the nodes of a graph. The importance of node embeddings for graph\nanalytics, as well as learning tasks such as node classification, link\nprediction and community detection, has led to increased interest on the\nproblem leading to a number of recent advances. Much like PCA in the feature\ndomain, node embedding is an inherently \\emph{unsupervised} task; in lack of\nmetadata used for validation, practical methods may require standardization and\nlimiting the use of tunable hyperparameters. Finally, node embedding methods\nare faced with maintaining scalability in the face of large-scale real-world\ngraphs of ever-increasing sizes. In the present work, we propose an adaptive\nnode embedding framework that adjusts the embedding process to a given\nunderlying graph, in a fully unsupervised manner. To achieve this, we adopt the\nnotion of a tunable node similarity matrix that assigns weights on paths of\ndifferent length. The design of the multilength similarities ensures that the\nresulting embeddings also inherit interpretable spectral properties. The\nproposed model is carefully studied, interpreted, and numerically evaluated\nusing stochastic block models. Moreover, an algorithmic scheme is proposed for\ntraining the model parameters effieciently and in an unsupervised manner. We\nperform extensive node classification, link prediction, and clustering\nexperiments on many real world graphs from various domains, and compare with\nstate-of-the-art scalable and unsupervised node embedding alternatives. The\nproposed method enjoys superior performance in many cases, while also yielding\ninterpretable information on the underlying structure of the graph.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 04:15:14 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 20:52:13 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 21:29:09 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Berberidis", "Dimitris", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1811.10799", "submitter": "Nicholas Mastronarde", "authors": "Owen Lahav, Nicholas Mastronarde, Mihaela van der Schaar", "title": "What is Interpretable? Using Machine Learning to Design Interpretable\n  Decision-Support Systems", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/28", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts in Machine Learning (ML) interpretability have focused on\ncreating methods for explaining black-box ML models. However, these methods\nrely on the assumption that simple approximations, such as linear models or\ndecision-trees, are inherently human-interpretable, which has not been\nempirically tested. Additionally, past efforts have focused exclusively on\ncomprehension, neglecting to explore the trust component necessary to convince\nnon-technical experts, such as clinicians, to utilize ML models in practice. In\nthis paper, we posit that reinforcement learning (RL) can be used to learn what\nis interpretable to different users and, consequently, build their trust in ML\nmodels. To validate this idea, we first train a neural network to provide risk\nassessments for heart failure patients. We then design a RL-based clinical\ndecision-support system (DSS) around the neural network model, which can learn\nfrom its interactions with users. We conduct an experiment involving a diverse\nset of clinicians from multiple institutions in three different countries. Our\nresults demonstrate that ML experts cannot accurately predict which system\noutputs will maximize clinicians' confidence in the underlying neural network\nmodel, and suggest additional findings that have broad implications to the\nfuture of research into ML interpretability and the use of ML in medicine.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 04:26:36 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 19:37:05 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Lahav", "Owen", ""], ["Mastronarde", "Nicholas", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1811.10811", "submitter": "Mahesh Subedar", "authors": "Mahesh Subedar, Ranganath Krishnan, Paulo Lopez Meyer, Omesh Tickoo,\n  Jonathan Huang", "title": "Uncertainty aware audiovisual activity recognition using deep Bayesian\n  variational inference", "comments": "Accepted at ICCV 2019 for Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) provide state-of-the-art results for a multitude\nof applications, but the approaches using DNNs for multimodal audiovisual\napplications do not consider predictive uncertainty associated with individual\nmodalities. Bayesian deep learning methods provide principled confidence and\nquantify predictive uncertainty. Our contribution in this work is to propose an\nuncertainty aware multimodal Bayesian fusion framework for activity\nrecognition. We demonstrate a novel approach that combines deterministic and\nvariational layers to scale Bayesian DNNs to deeper architectures. Our\nexperiments using in- and out-of-distribution samples selected from a subset of\nMoments-in-Time (MiT) dataset show a more reliable confidence measure as\ncompared to the non-Bayesian baseline and the Monte Carlo dropout (MC dropout)\napproximate Bayesian inference. We also demonstrate the uncertainty estimates\nobtained from the proposed framework can identify out-of-distribution data on\nthe UCF101 and MiT datasets. In the multimodal setting, the proposed framework\nimproved precision-recall AUC by 10.2% on the subset of MiT dataset as compared\nto non-Bayesian baseline.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 04:51:54 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 06:01:04 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 05:35:30 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Subedar", "Mahesh", ""], ["Krishnan", "Ranganath", ""], ["Meyer", "Paulo Lopez", ""], ["Tickoo", "Omesh", ""], ["Huang", "Jonathan", ""]]}, {"id": "1811.10828", "submitter": "Quanquan Gu", "authors": "Jinghui Chen, Dongruo Zhou, Jinfeng Yi, Quanquan Gu", "title": "A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks", "comments": "25 pages, 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depending on how much information an adversary can access to, adversarial\nattacks can be classified as white-box attack and black-box attack. For\nwhite-box attack, optimization-based attack algorithms such as projected\ngradient descent (PGD) can achieve relatively high attack success rates within\nmoderate iterates. However, they tend to generate adversarial examples near or\nupon the boundary of the perturbation set, resulting in large distortion.\nFurthermore, their corresponding black-box attack algorithms also suffer from\nhigh query complexities, thereby limiting their practical usefulness. In this\npaper, we focus on the problem of developing efficient and effective\noptimization-based adversarial attack algorithms. In particular, we propose a\nnovel adversarial attack framework for both white-box and black-box settings\nbased on a variant of Frank-Wolfe algorithm. We show in theory that the\nproposed attack algorithms are efficient with an $O(1/\\sqrt{T})$ convergence\nrate. The empirical results of attacking the ImageNet and MNIST datasets also\nverify the efficiency and effectiveness of the proposed algorithms. More\nspecifically, our proposed algorithms attain the best attack performances in\nboth white-box and black-box attacks among all baselines, and are more time and\nquery efficient than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 06:11:31 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 06:42:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chen", "Jinghui", ""], ["Zhou", "Dongruo", ""], ["Yi", "Jinfeng", ""], ["Gu", "Quanquan", ""]]}, {"id": "1811.10869", "submitter": "Chaim Baskin", "authors": "Natan Liss, Chaim Baskin, Avi Mendelson, Alex M. Bronstein, Raja\n  Giryes", "title": "Efficient non-uniform quantizer for quantized neural network targeting\n  reconfigurable hardware", "comments": "In submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNN) has become more popular choice for\nvarious tasks such as computer vision, speech recognition and natural language\nprocessing. Thanks to their large computational capability and throughput, GPUs\n,which are not power efficient and therefore does not suit low power systems\nsuch as mobile devices, are the most common platform for both training and\ninferencing tasks. Recent studies has shown that FPGAs can provide a good\nalternative to GPUs as a CNN accelerator, due to their re-configurable nature,\nlow power and small latency. In order for FPGA-based accelerators outperform\nGPUs in inference task, both the parameters of the network and the activations\nmust be quantized. While most works use uniform quantizers for both parameters\nand activations, it is not always the optimal one, and a non-uniform quantizer\nneed to be considered. In this work we introduce a custom hardware-friendly\napproach to implement non-uniform quantizers. In addition, we use a single\nscale integer representation of both parameters and activations, for both\ntraining and inference. The combined method yields a hardware efficient\nnon-uniform quantizer, fit for real-time applications. We have tested our\nmethod on CIFAR-10 and CIFAR-100 image classification datasets with ResNet-18\nand VGG-like architectures, and saw little degradation in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 08:28:52 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Liss", "Natan", ""], ["Baskin", "Chaim", ""], ["Mendelson", "Avi", ""], ["Bronstein", "Alex M.", ""], ["Giryes", "Raja", ""]]}, {"id": "1811.10892", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio", "title": "Chasing the Echo State Property", "comments": "This paper is a preprint of the paper presented at ESANN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir Computing (RC) provides an efficient way for designing dynamical\nrecurrent neural models. While training is restricted to a simple output\ncomponent, the recurrent connections are left untrained after initialization,\nsubject to stability constraints specified by the Echo State Property (ESP).\nLiterature conditions for the ESP typically fail to properly account for the\neffects of driving input signals, often limiting the potentialities of the RC\napproach. In this paper, we study the fundamental aspect of asymptotic\nstability of RC models in presence of driving input, introducing an empirical\nESP index that enables to easily analyze the stability regimes of reservoirs.\nResults on two benchmark datasets reveal interesting insights on the dynamical\nproperties of input-driven reservoirs, suggesting that the actual domain of ESP\nvalidity is much wider than what covered by literature conditions commonly used\nin RC practice.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 09:44:35 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:57:00 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gallicchio", "Claudio", ""]]}, {"id": "1811.10900", "submitter": "Sebastian Kauschke", "authors": "Lukas Fleckenstein, Sebastian Kauschke, Johannes F\\\"urnkranz", "title": "Beta Distribution Drift Detection for Adaptive Classifiers", "comments": null, "journal-ref": "Proceedings ESANN 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With today's abundant streams of data, the only constant we can rely on is\nchange. For stream classification algorithms, it is necessary to adapt to\nconcept drift. This can be achieved by monitoring the model error, and\ntriggering counter measures as changes occur. In this paper, we propose a drift\ndetection mechanism that fits a beta distribution to the model error, and\ntreats abnormal behavior as drift. It works with any given model, leverages\nprior knowledge about this model, and allows to set application-specific\nconfidence thresholds. Experiments confirm that it performs well, in particular\nwhen drift occurs abruptly.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 10:17:54 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Fleckenstein", "Lukas", ""], ["Kauschke", "Sebastian", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1811.10902", "submitter": "Xiaoxiao Wang", "authors": "Xiaoxiao Wang, Xueying Guo, Jie Chuai, Zhitang Chen, Xin Liu", "title": "Kernel-based Multi-Task Contextual Bandits in Cellular Network\n  Configuration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular network configuration plays a critical role in network performance.\nIn current practice, network configuration depends heavily on field experience\nof engineers and often remains static for a long period of time. This practice\nis far from optimal. To address this limitation, online-learning-based\napproaches have great potentials to automate and optimize network\nconfiguration. Learning-based approaches face the challenges of learning a\nhighly complex function for each base station and balancing the fundamental\nexploration-exploitation tradeoff while minimizing the exploration cost.\nFortunately, in cellular networks, base stations (BSs) often have similarities\neven though they are not identical. To leverage such similarities, we propose\nkernel-based multi-BS contextual bandit algorithm based on multi-task learning.\nIn the algorithm, we leverage the similarity among different BSs defined by\nconditional kernel embedding. We present theoretical analysis of the proposed\nalgorithm in terms of regret and multi-task-learning efficiency. We evaluate\nthe effectiveness of our algorithm based on a simulator built by real traces.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 10:39:56 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 09:13:23 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Wang", "Xiaoxiao", ""], ["Guo", "Xueying", ""], ["Chuai", "Jie", ""], ["Chen", "Zhitang", ""], ["Liu", "Xin", ""]]}, {"id": "1811.10947", "submitter": "Xiuming Liu", "authors": "Xiuming Liu, Dave Zachariah, Johan W{\\aa}gberg, Thomas B. Sch\\\"on", "title": "Reliable Semi-Supervised Learning when Labels are Missing at Random", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning methods are motivated by the availability of large\ndatasets with unlabeled features in addition to labeled data. Unlabeled data\nis, however, not guaranteed to improve classification performance and has in\nfact been reported to impair the performance in certain cases. A fundamental\nsource of error arises from restrictive assumptions about the unlabeled\nfeatures, which result in unreliable classifiers that underestimate their\nprediction error probabilities. In this paper, we develop a semi-supervised\nlearning approach that relaxes such assumptions and is capable of providing\nclassifiers that reliably quantify the label uncertainty. The approach is\napplicable using any generative model with a supervised learning algorithm. We\nillustrate the approach using both handwritten digit and cloth classification\ndata where the labels are missing at random.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 12:54:46 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 07:19:55 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 20:05:10 GMT"}, {"version": "v4", "created": "Wed, 13 Feb 2019 16:52:18 GMT"}, {"version": "v5", "created": "Thu, 24 Oct 2019 13:43:24 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Liu", "Xiuming", ""], ["Zachariah", "Dave", ""], ["W\u00e5gberg", "Johan", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1811.10949", "submitter": "Oguzhan Gencoglu", "authors": "Oguzhan Gencoglu, Miikka Ermes", "title": "Predicting the Flu from Instagram", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional surveillance systems for monitoring infectious diseases, such as\ninfluenza, face challenges due to shortage of skilled healthcare professionals,\nremoteness of communities and absence of communication infrastructures.\nInternet-based approaches for surveillance are appealing logistically as well\nas economically. Search engine queries and Twitter have been the primarily used\ndata sources in such approaches. The aim of this study is to assess the\npredictive power of an alternative data source, Instagram. By using 317 weeks\nof publicly available data from Instagram, we trained several machine learning\nalgorithms to both nowcast and forecast the number of official influenza-like\nillness incidents in Finland where population-wide official statistics about\nthe weekly incidents are available. In addition to date and hashtag count\nfeatures of online posts, we were able to utilize also the visual content of\nthe posted images with the help of deep convolutional neural networks. Our best\nnowcasting model reached a mean absolute error of 11.33 incidents per week and\na correlation coefficient of 0.963 on the test data. Forecasting models for\npredicting 1 week and 2 weeks ahead showed statistical significance as well by\nreaching correlation coefficients of 0.903 and 0.862, respectively. This study\ndemonstrates how social media and in particular, digital photographs shared in\nthem, can be a valuable source of information for the field of infodemiology.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 13:00:18 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Gencoglu", "Oguzhan", ""], ["Ermes", "Miikka", ""]]}, {"id": "1811.10959", "submitter": "Tongzhou Wang", "authors": "Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, Alexei A. Efros", "title": "Dataset Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model distillation aims to distill the knowledge of a complex model into a\nsimpler one. In this paper, we consider an alternative formulation called\ndataset distillation: we keep the model fixed and instead attempt to distill\nthe knowledge from a large training dataset into a small one. The idea is to\nsynthesize a small number of data points that do not need to come from the\ncorrect data distribution, but will, when given to the learning algorithm as\ntraining data, approximate the model trained on the original data. For example,\nwe show that it is possible to compress 60,000 MNIST training images into just\n10 synthetic distilled images (one per class) and achieve close to original\nperformance with only a few gradient descent steps, given a fixed network\ninitialization. We evaluate our method in various initialization settings and\nwith different learning objectives. Experiments on multiple datasets show the\nadvantage of our approach compared to alternative methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 13:17:45 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2019 14:26:04 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 23:25:50 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wang", "Tongzhou", ""], ["Zhu", "Jun-Yan", ""], ["Torralba", "Antonio", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1811.10978", "submitter": "Sami Remes", "authors": "Sami Remes, Markus Heinonen, Samuel Kaski", "title": "Neural Non-Stationary Spectral Kernel", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard kernels such as Mat\\'ern or RBF kernels only encode simple monotonic\ndependencies within the input space. Spectral mixture kernels have been\nproposed as general-purpose, flexible kernels for learning and discovering more\ncomplicated patterns in the data. Spectral mixture kernels have recently been\ngeneralized into non-stationary kernels by replacing the mixture weights,\nfrequency means and variances by input-dependent functions. These functions\nhave also been modelled as Gaussian processes on their own. In this paper we\npropose modelling the hyperparameter functions with neural networks, and\nprovide an experimental comparison between the stationary spectral mixture and\nthe two non-stationary spectral mixtures. Scalable Gaussian process inference\nis implemented within the sparse variational framework for all the kernels\nconsidered. We show that the neural variant of the kernel is able to achieve\nthe best performance, among alternatives, on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 13:43:37 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Remes", "Sami", ""], ["Heinonen", "Markus", ""], ["Kaski", "Samuel", ""]]}, {"id": "1811.10990", "submitter": "Chenyang Huang", "authors": "Chenyang Huang and Osmar R. Za\\\"iane", "title": "Generating Responses Expressing Emotion in an Open-domain Dialogue\n  System", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-17705-8", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based Open-ended conversational agents automatically generate\nresponses based on predictive models learned from a large number of pairs of\nutterances. The generated responses are typically acceptable as a sentence but\nare often dull, generic, and certainly devoid of any emotion. In this paper, we\npresent neural models that learn to express a given emotion in the generated\nresponse. We propose four models and evaluate them against 3 baselines. An\nencoder-decoder framework-based model with multiple attention layers provides\nthe best overall performance in terms of expressing the required emotion. While\nit does not outperform other models on all emotions, it presents promising\nresults in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 22:59:25 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Huang", "Chenyang", ""], ["Za\u00efane", "Osmar R.", ""]]}, {"id": "1811.10996", "submitter": "Ning Miao", "authors": "Ning Miao, Hao Zhou, Lili Mou, Rui Yan, Lei Li", "title": "CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling", "comments": "AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications of natural language generation, there are often\nconstraints on the target sentences in addition to fluency and naturalness\nrequirements. Existing language generation techniques are usually based on\nrecurrent neural networks (RNNs). However, it is non-trivial to impose\nconstraints on RNNs while maintaining generation quality, since RNNs generate\nsentences sequentially (or with beam search) from the first word to the last.\nIn this paper, we propose CGMH, a novel approach using Metropolis-Hastings\nsampling for constrained sentence generation. CGMH allows complicated\nconstraints such as the occurrence of multiple keywords in the target\nsentences, which cannot be handled in traditional RNN-based approaches.\nMoreover, CGMH works in the inference stage, and does not require parallel\ncorpora for training. We evaluate our method on a variety of tasks, including\nkeywords-to-sentence generation, unsupervised sentence paraphrasing, and\nunsupervised sentence error correction. CGMH achieves high performance compared\nwith previous supervised methods for sentence generation. Our code is released\nat https://github.com/NingMiao/CGMH\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:46:57 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Miao", "Ning", ""], ["Zhou", "Hao", ""], ["Mou", "Lili", ""], ["Yan", "Rui", ""], ["Li", "Lei", ""]]}, {"id": "1811.10999", "submitter": "Zheng Li", "authors": "Zheng Li, Ying Wei, Yu Zhang, Xiang Zhang, Xin Li, Qiang Yang", "title": "Exploiting Coarse-to-Fine Task Transfer for Aspect-level Sentiment\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-level sentiment classification (ASC) aims at identifying sentiment\npolarities towards aspects in a sentence, where the aspect can behave as a\ngeneral Aspect Category (AC) or a specific Aspect Term (AT). However, due to\nthe especially expensive and labor-intensive labeling, existing public corpora\nin AT-level are all relatively small. Meanwhile, most of the previous methods\nrely on complicated structures with given scarce data, which largely limits the\nefficacy of the neural models. In this paper, we exploit a new direction named\ncoarse-to-fine task transfer, which aims to leverage knowledge learned from a\nrich-resource source domain of the coarse-grained AC task, which is more easily\naccessible, to improve the learning in a low-resource target domain of the\nfine-grained AT task. To resolve both the aspect granularity inconsistency and\nfeature mismatch between domains, we propose a Multi-Granularity Alignment\nNetwork (MGAN). In MGAN, a novel Coarse2Fine attention guided by an auxiliary\ntask can help the AC task modeling at the same fine-grained level with the AT\ntask. To alleviate the feature false alignment, a contrastive feature alignment\nmethod is adopted to align aspect-specific feature representations\nsemantically. In addition, a large-scale multi-domain dataset for the AC task\nis provided. Empirically, extensive experiments demonstrate the effectiveness\nof the MGAN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 07:09:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Li", "Zheng", ""], ["Wei", "Ying", ""], ["Zhang", "Yu", ""], ["Zhang", "Xiang", ""], ["Li", "Xin", ""], ["Yang", "Qiang", ""]]}, {"id": "1811.11001", "submitter": "Tianlin Liu", "authors": "Tianlin Liu, Lyle Ungar, Jo\\~ao Sedoc", "title": "Unsupervised Post-processing of Word Vectors via Conceptor Negation", "comments": "Accepted by AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word vectors are at the core of many natural language processing tasks.\nRecently, there has been interest in post-processing word vectors to enrich\ntheir semantic information. In this paper, we introduce a novel word vector\npost-processing technique based on matrix conceptors (Jaeger2014), a family of\nregularized identity maps. More concretely, we propose to use conceptors to\nsuppress those latent features of word vectors having high variances. The\nproposed method is purely unsupervised: it does not rely on any corpus or\nexternal linguistic database. We evaluate the post-processed word vectors on a\nbattery of intrinsic lexical evaluation tasks, showing that the proposed method\nconsistently outperforms existing state-of-the-art alternatives. We also show\nthat post-processed word vectors can be used for the downstream natural\nlanguage processing task of dialogue state tracking, yielding improved results\nin different dialogue domains.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 20:12:40 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 10:27:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Liu", "Tianlin", ""], ["Ungar", "Lyle", ""], ["Sedoc", "Jo\u00e3o", ""]]}, {"id": "1811.11002", "submitter": "Tianlin Liu", "authors": "Tianlin Liu, Jo\\~ao Sedoc, Lyle Ungar", "title": "Correcting the Common Discourse Bias in Linear Representation of\n  Sentences using Conceptors", "comments": "Accepted by the BioCreative/OHNLP workshop of ACM-BCB 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations of words, better known as word embeddings, have\nbecome important building blocks for natural language processing tasks.\nNumerous studies are devoted to transferring the success of unsupervised word\nembeddings to sentence embeddings. In this paper, we introduce a simple\nrepresentation of sentences in which a sentence embedding is represented as a\nweighted average of word vectors followed by a soft projection. We demonstrate\nthe effectiveness of this proposed method on the clinical semantic textual\nsimilarity task of the BioCreative/OHNLP Challenge 2018.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 20:20:20 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Liu", "Tianlin", ""], ["Sedoc", "Jo\u00e3o", ""], ["Ungar", "Lyle", ""]]}, {"id": "1811.11005", "submitter": "Maria Pikoula", "authors": "Spiros Denaxas, Pontus Stenetorp, Sebastian Riedel, Maria Pikoula,\n  Richard Dobson, Harry Hemingway", "title": "Application of Clinical Concept Embeddings for Heart Failure Prediction\n  in UK EHR data", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/37", "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHR) are increasingly being used for constructing\ndisease risk prediction models. Feature engineering in EHR data however is\nchallenging due to their highly dimensional and heterogeneous nature.\nLow-dimensional representations of EHR data can potentially mitigate these\nchallenges. In this paper, we use global vectors (GloVe) to learn word\nembeddings for diagnoses and procedures recorded using 13 million ontology\nterms across 2.7 million hospitalisations in national UK EHR. We demonstrate\nthe utility of these embeddings by evaluating their performance in identifying\npatients which are at higher risk of being hospitalised for congestive heart\nfailure. Our findings indicate that embeddings can enable the creation of\nrobust EHR-derived disease risk prediction models and address some the\nlimitations associated with manual clinical feature engineering.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 13:04:12 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 15:01:56 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Denaxas", "Spiros", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""], ["Pikoula", "Maria", ""], ["Dobson", "Richard", ""], ["Hemingway", "Harry", ""]]}, {"id": "1811.11008", "submitter": "Srikumar Krishnamoorthy", "authors": "Srikumar Krishnamoorthy", "title": "Sentiment Analysis of Financial News Articles using Performance\n  Indicators", "comments": "Knowledge and Information Systems Nov 2017", "journal-ref": null, "doi": "10.1007/s10115-017-1134-1", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining financial text documents and understanding the sentiments of\nindividual investors, institutions and markets is an important and challenging\nproblem in the literature. Current approaches to mine sentiments from financial\ntexts largely rely on domain specific dictionaries. However, dictionary based\nmethods often fail to accurately predict the polarity of financial texts. This\npaper aims to improve the state-of-the-art and introduces a novel sentiment\nanalysis approach that employs the concept of financial and non-financial\nperformance indicators. It presents an association rule mining based\nhierarchical sentiment classifier model to predict the polarity of financial\ntexts as positive, neutral or negative. The performance of the proposed model\nis evaluated on a benchmark financial dataset. The model is also compared\nagainst other state-of-the-art dictionary and machine learning based approaches\nand the results are found to be quite promising. The novel use of performance\nindicators for financial sentiment analysis offers interesting and useful\ninsights.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 01:36:12 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Krishnamoorthy", "Srikumar", ""]]}, {"id": "1811.11017", "submitter": "Mohan Zhang", "authors": "Mohan Zhang, Zhichao Luo, Hai Lu", "title": "Latent Dirichlet Allocation with Residual Convolutional Neural Network\n  Applied in Evaluating Credibility of Chinese Listed Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project demonstrated a methodology to estimating cooperate credibility\nwith a Natural Language Processing approach. As cooperate transparency impacts\nboth the credibility and possible future earnings of the firm, it is an\nimportant factor to be considered by banks and investors on risk assessments of\nlisted firms. This approach of estimating cooperate credibility can bypass\nhuman bias and inconsistency in the risk assessment, the use of large\nquantitative data and neural network models provides more accurate estimation\nin a more efficient manner compare to manual assessment. At the beginning, the\nmodel will employs Latent Dirichlet Allocation and THU Open Chinese Lexicon\nfrom Tsinghua University to classify topics in articles which are potentially\nrelated to corporate credibility. Then with the keywords related to each\ntopics, we trained a residual convolutional neural network with data labeled\naccording to surveys of fund manager and accountant's opinion on corporate\ncredibility. After the training, we run the model with preprocessed news\nreports regarding to all of the 3065 listed companies, the model is supposed to\ngive back companies ranking based on the level of their transparency.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 17:50:41 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Zhang", "Mohan", ""], ["Luo", "Zhichao", ""], ["Lu", "Hai", ""]]}, {"id": "1811.11019", "submitter": "Chenhe Zhang", "authors": "Chenhe Zhang and Peiyuan Sun", "title": "Arena Model: Inference About Competitions", "comments": "31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The authors propose a parametric model called the arena model for prediction\nin paired competitions, i.e. paired comparisons with eliminations and\nbifurcations. The arena model has a number of appealing advantages. First, it\npredicts the results of competitions without rating many individuals. Second,\nit takes full advantage of the structure of competitions. Third, the model\nprovides an easy method to quantify the uncertainty in competitions. Fourth,\nsome of our methods can be directly generalized for comparisons among three or\nmore individuals. Furthermore, the authors identify an invariant Bayes\nestimator with regard to the prior distribution and prove the consistency of\nthe estimations of uncertainty. Currently, the arena model is not effective in\ntracking the change of strengths of individuals, but its basic framework\nprovides a solid foundation for future study of such cases.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 17:35:36 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Zhang", "Chenhe", ""], ["Sun", "Peiyuan", ""]]}, {"id": "1811.11043", "submitter": "Michal Valko", "authors": "Julien Seznec, Andrea Locatelli, Alexandra Carpentier, Alessandro\n  Lazaric, Michal Valko", "title": "Rotting bandits are not harder than stochastic ones", "comments": null, "journal-ref": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic multi-armed bandits, the reward distribution of each arm is\nassumed to be stationary. This assumption is often violated in practice (e.g.,\nin recommendation systems), where the reward of an arm may change whenever is\nselected, i.e., rested bandit setting. In this paper, we consider the\nnon-parametric rotting bandit setting, where rewards can only decrease. We\nintroduce the filtering on expanding window average (FEWA) algorithm that\nconstructs moving averages of increasing windows to identify arms that are more\nlikely to return high rewards when pulled once more. We prove that for an\nunknown horizon $T$, and without any knowledge on the decreasing behavior of\nthe $K$ arms, FEWA achieves problem-dependent regret bound of\n$\\widetilde{\\mathcal{O}}(\\log{(KT)}),$ and a problem-independent one of\n$\\widetilde{\\mathcal{O}}(\\sqrt{KT})$. Our result substantially improves over\nthe algorithm of Levine et al. (2017), which suffers regret\n$\\widetilde{\\mathcal{O}}(K^{1/3}T^{2/3})$. FEWA also matches known bounds for\nthe stochastic bandit setting, thus showing that the rotting bandits are not\nharder. Finally, we report simulations confirming the theoretical improvements\nof FEWA.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 15:07:04 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 19:34:31 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Seznec", "Julien", ""], ["Locatelli", "Andrea", ""], ["Carpentier", "Alexandra", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""]]}, {"id": "1811.11067", "submitter": "Elizaveta Logacheva", "authors": "Pavel Solovev, Vladimir Aliev, Pavel Ostyakov, Gleb Sterkin, Elizaveta\n  Logacheva, Stepan Troeshestov, Roman Suvorov, Anton Mashikhin, Oleg Khomenko,\n  Sergey I. Nikolenko", "title": "Learning State Representations in Complex Systems with Multimodal Data", "comments": "Fixed references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning becomes especially important for complex systems with\nmultimodal data sources such as cameras or sensors. Recent advances in\nreinforcement learning and optimal control make it possible to design control\nalgorithms on these latent representations, but the field still lacks a\nlarge-scale standard dataset for unified comparison. In this work, we present a\nlarge-scale dataset and evaluation framework for representation learning for\nthe complex task of landing an airplane. We implement and compare several\napproaches to representation learning on this dataset in terms of the quality\nof simple supervised learning tasks and disentanglement scores. The resulting\nrepresentations can be used for further tasks such as anomaly detection,\noptimal control, model-based reinforcement learning, and other applications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 15:55:42 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 13:48:24 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 20:13:43 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Solovev", "Pavel", ""], ["Aliev", "Vladimir", ""], ["Ostyakov", "Pavel", ""], ["Sterkin", "Gleb", ""], ["Logacheva", "Elizaveta", ""], ["Troeshestov", "Stepan", ""], ["Suvorov", "Roman", ""], ["Mashikhin", "Anton", ""], ["Khomenko", "Oleg", ""], ["Nikolenko", "Sergey I.", ""]]}, {"id": "1811.11079", "submitter": "Suproteem Sarkar", "authors": "Suproteem K. Sarkar, Kojin Oshiba, Daniel Giebisch, Yaron Singer", "title": "Robust Classification of Financial Risk", "comments": "NIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms are increasingly common components of high-impact decision-making,\nand a growing body of literature on adversarial examples in laboratory settings\nindicates that standard machine learning models are not robust. This suggests\nthat real-world systems are also susceptible to manipulation or\nmisclassification, which especially poses a challenge to machine learning\nmodels used in financial services. We use the loan grade classification problem\nto explore how machine learning models are sensitive to small changes in\nuser-reported data, using adversarial attacks documented in the literature and\nan original, domain-specific attack. Our work shows that a robust optimization\nalgorithm can build models for financial services that are resistant to\nmisclassification on perturbations. To the best of our knowledge, this is the\nfirst study of adversarial attacks and defenses for deep learning in financial\nservices.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 16:28:32 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Sarkar", "Suproteem K.", ""], ["Oshiba", "Kojin", ""], ["Giebisch", "Daniel", ""], ["Singer", "Yaron", ""]]}, {"id": "1811.11083", "submitter": "Kevin Liang", "authors": "Kevin J Liang, Chunyuan Li, Guoyin Wang, Lawrence Carin", "title": "Generative Adversarial Network Training is a Continual Learning Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have proven to be a powerful framework\nfor learning to draw samples from complex distributions. However, GANs are also\nnotoriously difficult to train, with mode collapse and oscillations a common\nproblem. We hypothesize that this is at least in part due to the evolution of\nthe generator distribution and the catastrophic forgetting tendency of neural\nnetworks, which leads to the discriminator losing the ability to remember\nsynthesized samples from previous instantiations of the generator. Recognizing\nthis, our contributions are twofold. First, we show that GAN training makes for\na more interesting and realistic benchmark for continual learning methods\nevaluation than some of the more canonical datasets. Second, we propose\nleveraging continual learning techniques to augment the discriminator,\npreserving its ability to recognize previous generator samples. We show that\nthe resulting methods add only a light amount of computation, involve minimal\nchanges to the model, and result in better overall performance on the examined\nimage and text generation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 16:41:58 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Liang", "Kevin J", ""], ["Li", "Chunyuan", ""], ["Wang", "Guoyin", ""], ["Carin", "Lawrence", ""]]}, {"id": "1811.11095", "submitter": "Xiaobo Zeng", "authors": "Qunbi Zhuge, Xiaobo Zeng, Huazhi Lun, Meng Cai, Xiaomin Liu, Weisheng\n  Hu", "title": "Application of Machine Learning in Fiber Nonlinearity Modeling and\n  Monitoring for Elastic Optical Networks", "comments": "There are some errors, as listed in the following, in the preliminary\n  version(i.e. v1) of this paper with the title of Application of machine\n  learning in fiber nonlinearity modeling and monitoring for elastic optical\n  networks. In order to prevent confusing or some misleading decisions, we\n  decide to withdraw this paper from arXiv. [The errors are listed in the\n  abstract field]", "journal-ref": null, "doi": "10.1109/JLT.2019.2910143", "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fiber nonlinear interference (NLI) modeling and monitoring are the key\nbuilding blocks to support elastic optical networks (EONs). In the past, they\nwere normally developed and investigated separately. Moreover, the accuracy of\nthe previously proposed methods still needs to be improved for heterogenous\ndynamic optical networks. In this paper, we present the application of machine\nlearning (ML) in NLI modeling and monitoring. In particular, we first propose\nto use ML approaches to calibrate the errors of current fiber nonlinearity\nmodels. The Gaussian-noise (GN) model is used as an illustrative example, and\nsignificant improvement is demonstrated with the aid of an artificial neural\nnetwork (ANN). Further, we propose to use ML to combine the modeling and\nmonitoring schemes for a better estimation of NLI variance.\n  The following contents are the listed errors as mentioned in the comments for\nreasons of withdrawal. (1) The works, as mentioned as the title, should be\naddressed is about the elastic optical networks(EON), however, the simulation\nsetup and the results section are focused on the conventional wavelength\ndivision multiplexing(WDM) networks. This error may confuse some researcher,\ngetting the misleading decision for the researches about the elastic optical\nnetworks. (2) There exists some errors in the results rection, such as,\nFig.9(b) and (c) with the wrong captions may result in misleading decision. (3)\nThe split-step-Fourier-method(SSFM) presents good accuracy if the sufficiently\nsmall steps are adopted in the calculation, however this paper has not\nnecessary contents and efforts to optimise the step-length of SSFM. This error\nmay confuse the accuracy of simulation results. Therefore, we decide to\nwithdraw this paper from arXiv. The correct and complete paper with the same\ntitle was published in journal of lightwave technology with doi:\n10.1109/JLT.2019.2910143.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 04:58:24 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 14:52:46 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zhuge", "Qunbi", ""], ["Zeng", "Xiaobo", ""], ["Lun", "Huazhi", ""], ["Cai", "Meng", ""], ["Liu", "Xiaomin", ""], ["Hu", "Weisheng", ""]]}, {"id": "1811.11103", "submitter": "Soumyasundar Pal", "authors": "Yingxue Zhang, Soumyasundar Pal, Mark Coates, Deniz \\\"Ustebay", "title": "Bayesian graph convolutional neural networks for semi-supervised\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, techniques for applying convolutional neural networks to\ngraph-structured data have emerged. Graph convolutional neural networks (GCNNs)\nhave been used to address node and graph classification and matrix completion.\nAlthough the performance has been impressive, the current implementations have\nlimited capability to incorporate uncertainty in the graph structure. Almost\nall GCNNs process a graph as though it is a ground-truth depiction of the\nrelationship between nodes, but often the graphs employed in applications are\nthemselves derived from noisy data or modelling assumptions. Spurious edges may\nbe included; other edges may be missing between nodes that have very strong\nrelationships. In this paper we adopt a Bayesian approach, viewing the observed\ngraph as a realization from a parametric family of random graphs. We then\ntarget inference of the joint posterior of the random graph parameters and the\nnode (or graph) labels. We present the Bayesian GCNN framework and develop an\niterative learning procedure for the case of assortative mixed-membership\nstochastic block models. We present the results of experiments that demonstrate\nthat the Bayesian formulation can provide better performance when there are\nvery few labels available during the training process.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 16:54:47 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Zhang", "Yingxue", ""], ["Pal", "Soumyasundar", ""], ["Coates", "Mark", ""], ["\u00dcstebay", "Deniz", ""]]}, {"id": "1811.11124", "submitter": "Hsin-Pai Cheng", "authors": "Hsin-Pai Cheng, Patrick Yu, Haojing Hu, Feng Yan, Shiyu Li, Hai Li,\n  Yiran Chen", "title": "LEASGD: an Efficient and Privacy-Preserving Decentralized Algorithm for\n  Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning systems have enabled training large-scale models over\nlarge amount of data in significantly shorter time. In this paper, we focus on\ndecentralized distributed deep learning systems and aim to achieve differential\nprivacy with good convergence rate and low communication cost. To achieve this\ngoal, we propose a new learning algorithm LEASGD (Leader-Follower Elastic\nAveraging Stochastic Gradient Descent), which is driven by a novel\nLeader-Follower topology and a differential privacy model.We provide a\ntheoretical analysis of the convergence rate and the trade-off between the\nperformance and privacy in the private setting.The experimental results show\nthat LEASGD outperforms state-of-the-art decentralized learning algorithm DPSGD\nby achieving steadily lower loss within the same iterations and by reducing the\ncommunication cost by 30%. In addition, LEASGD spends less differential privacy\nbudget and has higher final accuracy result than DPSGD under private setting.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 17:34:27 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Cheng", "Hsin-Pai", ""], ["Yu", "Patrick", ""], ["Hu", "Haojing", ""], ["Yan", "Feng", ""], ["Li", "Shiyu", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1811.11148", "submitter": "Gautam Kamath", "authors": "Cl\\'ement L. Canonne, Gautam Kamath, Audra McMillan, Adam Smith,\n  Jonathan Ullman", "title": "The Structure of Optimal Private Tests for Simple Hypotheses", "comments": "To appear in STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing plays a central role in statistical inference, and is used\nin many settings where privacy concerns are paramount. This work answers a\nbasic question about privately testing simple hypotheses: given two\ndistributions $P$ and $Q$, and a privacy level $\\varepsilon$, how many i.i.d.\nsamples are needed to distinguish $P$ from $Q$ subject to\n$\\varepsilon$-differential privacy, and what sort of tests have optimal sample\ncomplexity? Specifically, we characterize this sample complexity up to constant\nfactors in terms of the structure of $P$ and $Q$ and the privacy level\n$\\varepsilon$, and show that this sample complexity is achieved by a certain\nrandomized and clamped variant of the log-likelihood ratio test. Our result is\nan analogue of the classical Neyman-Pearson lemma in the setting of private\nhypothesis testing. We also give an application of our result to the private\nchange-point detection. Our characterization applies more generally to\nhypothesis tests satisfying essentially any notion of algorithmic stability,\nwhich is known to imply strong generalization bounds in adaptive data analysis,\nand thus our results have applications even when privacy is not a primary\nconcern.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 18:21:33 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 21:46:45 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Kamath", "Gautam", ""], ["McMillan", "Audra", ""], ["Smith", "Adam", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1811.11152", "submitter": "Kevin Chen", "authors": "Kevin K. Chen, Anthony C. Gamst, Alden K. Walker", "title": "Knots in random neural networks", "comments": "Presented at the Workshop on Bayesian Deep Learning, NIPS 2016,\n  Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weights of a neural network are typically initialized at random, and one\ncan think of the functions produced by such a network as having been generated\nby a prior over some function space. Studying random networks, then, is useful\nfor a Bayesian understanding of the network evolution in early stages of\ntraining. In particular, one can investigate why neural networks with huge\nnumbers of parameters do not immediately overfit. We analyze the properties of\nrandom scalar-input feed-forward rectified linear unit architectures, which are\nrandom linear splines. With weights and biases sampled from certain common\ndistributions, empirical tests show that the number of knots in the spline\nproduced by the network is equal to the number of neurons, to very close\napproximation. We describe our progress towards a completely analytic\nexplanation of this phenomenon. In particular, we show that random single-layer\nneural networks are equivalent to integrated random walks with variable step\nsizes. That each neuron produces one knot on average is equivalent to the\nassociated integrated random walk having one zero crossing on average. We\nexplore how properties of the integrated random walk, including the step sizes\nand initial conditions, affect the number of crossings. The number of knots in\nrandom neural networks can be related to the behavior of extreme learning\nmachines, but it also establishes a prior preventing optimizers from\nimmediately overfitting to noisy training data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 18:33:24 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Chen", "Kevin K.", ""], ["Gamst", "Anthony C.", ""], ["Walker", "Alden K.", ""]]}, {"id": "1811.11154", "submitter": "Xiaojie Mao", "authors": "Jiahao Chen, Nathan Kallus, Xiaojie Mao, Geoffry Svacha, Madeleine\n  Udell", "title": "Fairness Under Unawareness: Assessing Disparity When Protected Class Is\n  Unobserved", "comments": "13 pages, 11 figures, FAT*' 19: Conference on Fairness,\n  Accountability, and Transparency (FAT*' 19), January 29-31, 2019, Atlanta,\n  GA, USA", "journal-ref": null, "doi": "10.1145/3287560.3287594", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing the fairness of a decision making system with respect to a\nprotected class, such as gender or race, is challenging when class membership\nlabels are unavailable. Probabilistic models for predicting the protected class\nbased on observable proxies, such as surname and geolocation for race, are\nsometimes used to impute these missing labels for compliance assessments.\nEmpirically, these methods are observed to exaggerate disparities, but the\nreason why is unknown. In this paper, we decompose the biases in estimating\noutcome disparity via threshold-based imputation into multiple interpretable\nbias sources, allowing us to explain when over- or underestimation occurs. We\nalso propose an alternative weighted estimator that uses soft classification,\nand show that its bias arises simply from the conditional covariance of the\noutcome with the true class membership. Finally, we illustrate our results with\nnumerical simulations and a public dataset of mortgage applications, using\ngeolocation as a proxy for race. We confirm that the bias of threshold-based\nimputation is generally upward, but its magnitude varies strongly with the\nthreshold chosen. Our new weighted estimator tends to have a negative bias that\nis much simpler to analyze and reason about.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 18:39:09 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Chen", "Jiahao", ""], ["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""], ["Svacha", "Geoffry", ""], ["Udell", "Madeleine", ""]]}, {"id": "1811.11163", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Yoshitaka Ushiku, Tatsuya Harada", "title": "Class-Distinct and Class-Mutual Image Generation with GANs", "comments": "Accepted to BMVC 2019 (Spotlight). Project page:\n  https://takuhirok.github.io/CP-GAN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-conditional extensions of generative adversarial networks (GANs), such\nas auxiliary classifier GAN (AC-GAN) and conditional GAN (cGAN), have garnered\nattention owing to their ability to decompose representations into class labels\nand other factors and to boost the training stability. However, a limitation is\nthat they assume that each class is separable and ignore the relationship\nbetween classes even though class overlapping frequently occurs in a real-world\nscenario when data are collected on the basis of diverse or ambiguous criteria.\nTo overcome this limitation, we address a novel problem called class-distinct\nand class-mutual image generation, in which the goal is to construct a\ngenerator that can capture between-class relationships and generate an image\nselectively conditioned on the class specificity. To solve this problem without\nadditional supervision, we propose classifier's posterior GAN (CP-GAN), in\nwhich we redesign the generator input and the objective function of AC-GAN for\nclass-overlapping data. Precisely, we incorporate the classifier's posterior\ninto the generator input and optimize the generator so that the classifier's\nposterior of generated data corresponds with that of real data. We demonstrate\nthe effectiveness of CP-GAN using both controlled and real-world\nclass-overlapping data with a model configuration analysis and comparative\nstudy. Our code is available at https://github.com/takuhirok/CP-GAN/.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 18:56:19 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 17:51:04 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Ushiku", "Yoshitaka", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1811.11165", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Yoshitaka Ushiku, Tatsuya Harada", "title": "Label-Noise Robust Generative Adversarial Networks", "comments": "Accepted to CVPR 2019 (Oral). Project page:\n  https://takuhirok.github.io/rGAN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a framework that learns a\ngenerative distribution through adversarial training. Recently, their\nclass-conditional extensions (e.g., conditional GAN (cGAN) and auxiliary\nclassifier GAN (AC-GAN)) have attracted much attention owing to their ability\nto learn the disentangled representations and to improve the training\nstability. However, their training requires the availability of large-scale\naccurate class-labeled data, which are often laborious or impractical to\ncollect in a real-world scenario. To remedy this, we propose a novel family of\nGANs called label-noise robust GANs (rGANs), which, by incorporating a noise\ntransition model, can learn a clean label conditional generative distribution\neven when training labels are noisy. In particular, we propose two variants:\nrAC-GAN, which is a bridging model between AC-GAN and the label-noise robust\nclassification model, and rcGAN, which is an extension of cGAN and solves this\nproblem with no reliance on any classifier. In addition to providing the\ntheoretical background, we demonstrate the effectiveness of our models through\nextensive experiments using diverse GAN configurations, various noise settings,\nand multiple evaluation metrics (in which we tested 402 conditions in total).\nOur code is available at https://github.com/takuhirok/rGAN/.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 18:56:21 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 18:42:42 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Ushiku", "Yoshitaka", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1811.11190", "submitter": "Alexander New", "authors": "Alexander New, Sabbir M. Rashid, John S. Erickson, Deborah L.\n  McGuinness, and Kristin P. Bennett", "title": "Semantically-aware population health risk analyses", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One primary task of population health analysis is the identification of risk\nfactors that, for some subpopulation, have a significant association with some\nhealth condition. Examples include finding lifestyle factors associated with\nchronic diseases and finding genetic mutations associated with diseases in\nprecision health. We develop a combined semantic and machine learning system\nthat uses a health risk ontology and knowledge graph (KG) to dynamically\ndiscover risk factors and their associated subpopulations. Semantics and the\nnovel supervised cadre model make our system explainable. Future population\nhealth studies are easily performed and documented with provenance by\nspecifying additional input and output KG cartridges.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:00:07 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["New", "Alexander", ""], ["Rashid", "Sabbir M.", ""], ["Erickson", "John S.", ""], ["McGuinness", "Deborah L.", ""], ["Bennett", "Kristin P.", ""]]}, {"id": "1811.11206", "submitter": "Thang Bui", "authors": "Thang D. Bui, Cuong V. Nguyen, Siddharth Swaroop, Richard E. Turner", "title": "Partitioned Variational Inference: A unified framework encompassing\n  federated and continual learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference (VI) has become the method of choice for fitting many\nmodern probabilistic models. However, practitioners are faced with a fragmented\nliterature that offers a bewildering array of algorithmic options. First, the\nvariational family. Second, the granularity of the updates e.g. whether the\nupdates are local to each data point and employ message passing or global.\nThird, the method of optimization (bespoke or blackbox, closed-form or\nstochastic updates, etc.). This paper presents a new framework, termed\nPartitioned Variational Inference (PVI), that explicitly acknowledges these\nalgorithmic dimensions of VI, unifies disparate literature, and provides\nguidance on usage. Crucially, the proposed PVI framework allows us to identify\nnew ways of performing VI that are ideally suited to challenging learning\nscenarios including federated learning (where distributed computing is\nleveraged to process non-centralized data) and continual learning (where new\ndata and tasks arrive over time and must be accommodated quickly). We showcase\nthese new capabilities by developing communication-efficient federated training\nof Bayesian neural networks and continual learning for Gaussian process models\nwith private pseudo-points. The new methods significantly outperform the\nstate-of-the-art, whilst being almost as straightforward to implement as\nstandard VI.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:16:00 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Bui", "Thang D.", ""], ["Nguyen", "Cuong V.", ""], ["Swaroop", "Siddharth", ""], ["Turner", "Richard E.", ""]]}, {"id": "1811.11210", "submitter": "Buu Phan", "authors": "Buu Phan, Rick Salay, Krzysztof Czarnecki, Vahdat Abdelzad, Taylor\n  Denouden, Sachin Vernekar", "title": "Calibrating Uncertainties in Object Localization Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many safety-critical applications such as autonomous driving and surgical\nrobots, it is desirable to obtain prediction uncertainties from object\ndetection modules to help support safe decision-making. Specifically, such\nmodules need to estimate the probability of each predicted object in a given\nregion and the confidence interval for its bounding box. While recent Bayesian\ndeep learning methods provide a principled way to estimate this uncertainty,\nthe estimates for the bounding boxes obtained using these methods are\nuncalibrated. In this paper, we address this problem for the single-object\nlocalization task by adapting an existing technique for calibrating regression\nmodels. We show, experimentally, that the resulting calibrated model obtains\nmore reliable uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:27:29 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Phan", "Buu", ""], ["Salay", "Rick", ""], ["Czarnecki", "Krzysztof", ""], ["Abdelzad", "Vahdat", ""], ["Denouden", "Taylor", ""], ["Vernekar", "Sachin", ""]]}, {"id": "1811.11212", "submitter": "Neil Houlsby", "authors": "Ting Chen, Xiaohua Zhai, Marvin Ritter, Mario Lucic, Neil Houlsby", "title": "Self-Supervised GANs via Auxiliary Rotation Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional GANs are at the forefront of natural image synthesis. The main\ndrawback of such models is the necessity for labeled data. In this work we\nexploit two popular unsupervised learning techniques, adversarial training and\nself-supervision, and take a step towards bridging the gap between conditional\nand unconditional GANs. In particular, we allow the networks to collaborate on\nthe task of representation learning, while being adversarial with respect to\nthe classic GAN game. The role of self-supervision is to encourage the\ndiscriminator to learn meaningful feature representations which are not\nforgotten during training. We test empirically both the quality of the learned\nimage representations, and the quality of the synthesized images. Under the\nsame conditions, the self-supervised GAN attains a similar performance to\nstate-of-the-art conditional counterparts. Finally, we show that this approach\nto fully unsupervised learning can be scaled to attain an FID of 23.4 on\nunconditional ImageNet generation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:30:40 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 14:25:35 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Chen", "Ting", ""], ["Zhai", "Xiaohua", ""], ["Ritter", "Marvin", ""], ["Lucic", "Mario", ""], ["Houlsby", "Neil", ""]]}, {"id": "1811.11213", "submitter": "Ryan Chard", "authors": "Ryan Chard, Zhuozhao Li, Kyle Chard, Logan Ward, Yadu Babuji, Anna\n  Woodard, Steve Tuecke, Ben Blaiszik, Michael J. Franklin, and Ian Foster", "title": "DLHub: Model and Data Serving for Science", "comments": "10 pages, 8 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While the Machine Learning (ML) landscape is evolving rapidly, there has been\na relative lag in the development of the \"learning systems\" needed to enable\nbroad adoption. Furthermore, few such systems are designed to support the\nspecialized requirements of scientific ML. Here we present the Data and\nLearning Hub for science (DLHub), a multi-tenant system that provides both\nmodel repository and serving capabilities with a focus on science applications.\nDLHub addresses two significant shortcomings in current systems. First, its\nselfservice model repository allows users to share, publish, verify, reproduce,\nand reuse models, and addresses concerns related to model reproducibility by\npackaging and distributing models and all constituent components. Second, it\nimplements scalable and low-latency serving capabilities that can leverage\nparallel and distributed computing resources to democratize access to published\nmodels through a simple web interface. Unlike other model serving frameworks,\nDLHub can store and serve any Python 3-compatible model or processing function,\nplus multiple-function pipelines. We show that relative to other model serving\nsystems including TensorFlow Serving, SageMaker, and Clipper, DLHub provides\ngreater capabilities, comparable performance without memoization and batching,\nand significantly better performance when the latter two techniques can be\nemployed. We also describe early uses of DLHub for scientific applications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:31:29 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Chard", "Ryan", ""], ["Li", "Zhuozhao", ""], ["Chard", "Kyle", ""], ["Ward", "Logan", ""], ["Babuji", "Yadu", ""], ["Woodard", "Anna", ""], ["Tuecke", "Steve", ""], ["Blaiszik", "Ben", ""], ["Franklin", "Michael J.", ""], ["Foster", "Ian", ""]]}, {"id": "1811.11214", "submitter": "Zafarali Ahmed", "authors": "Zafarali Ahmed, Nicolas Le Roux, Mohammad Norouzi, Dale Schuurmans", "title": "Understanding the impact of entropy on policy optimization", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy regularization is commonly used to improve policy optimization in\nreinforcement learning. It is believed to help with \\emph{exploration} by\nencouraging the selection of more stochastic policies. In this work, we analyze\nthis claim using new visualizations of the optimization landscape based on\nrandomly perturbing the loss function. We first show that even with access to\nthe exact gradient, policy optimization is difficult due to the geometry of the\nobjective function. Then, we qualitatively show that in some environments, a\npolicy with higher entropy can make the optimization landscape smoother,\nthereby connecting local optima and enabling the use of larger learning rates.\nThis paper presents new tools for understanding the optimization landscape,\nshows that policy entropy serves as a regularizer, and highlights the challenge\nof designing general-purpose policy optimization algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:32:27 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 04:01:21 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 16:01:48 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 19:13:10 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 18:17:04 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ahmed", "Zafarali", ""], ["Roux", "Nicolas Le", ""], ["Norouzi", "Mohammad", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1811.11222", "submitter": "Egor Kraev", "authors": "Egor Kraev", "title": "Grammars and reinforcement learning for molecule optimization", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We seek to automate the design of molecules based on specific chemical\nproperties. Our primary contributions are a simpler method for generating\nSMILES strings guaranteed to be chemically valid, using a combination of a new\ncontext-free grammar for SMILES and additional masking logic; and casting the\nmolecular property optimization as a reinforcement learning problem,\nspecifically best-of-batch policy gradient applied to a Transformer model\narchitecture. This approach uses substantially fewer model steps per atom than\nearlier approaches, thus enabling generation of larger molecules, and beats\nprevious state-of-the art baselines by a significant margin. Applying\nreinforcement learning to a combination of a custom context-free grammar with\nadditional masking to enforce non-local constraints is applicable to any\noptimization of a graph structure under a mixture of local and nonlocal\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:48:02 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Kraev", "Egor", ""]]}, {"id": "1811.11249", "submitter": "Gaetano Manzo", "authors": "Gaetano Manzo, Juan Sebastian Otalora, Marco Ajmone Marsan, and\n  Gianluca Rizzo", "title": "A Deep Learning Strategy for Vehicular Floating Content Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floating Content (FC) is a communication paradigm for the local dissemination\nof contextualized information through D2D connectivity, in a way which\nminimizes the use of resources while achieving some specified performance\ntarget. Existing approaches to FC dimensioning are based on unrealistic system\nassumptions that make them, highly inaccurate and overly conservative when\napplied in realistic settings. In this paper, we present a first step towards\nthe development of a cognitive approach to efficient dynamic management of FC.\nWe propose a deep learning strategy for FC dimensioning, which exploits a\nConvolutional Neural Network(CNN) to efficiently modulate over time the\nresources employed by FC in a QoS-aware manner. Numerical evaluations show that\nour approach achieves a maximum rejection rate of3%, and resource savings of\n37.5% with respect to the benchmark strategy\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 08:22:51 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Manzo", "Gaetano", ""], ["Otalora", "Juan Sebastian", ""], ["Marsan", "Marco Ajmone", ""], ["Rizzo", "Gianluca", ""]]}, {"id": "1811.11259", "submitter": "Francesco Fraternali", "authors": "Francesco Fraternali, Bharathan Balaji, Rajesh Gupta", "title": "Scaling Configuration of Energy Harvesting Sensors with Reinforcement\n  Learning", "comments": "7 pages, 5 figures", "journal-ref": "ENSsys '18: International Workshop on Energy Harvesting &\n  Energy-Neutral Sensing Systems}{November 4, 2018}{Shenzhen, China", "doi": "10.1145/3279755.3279760", "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of the Internet of Things (IoT), an increasing number of\nenergy harvesting methods are being used to supplement or supplant battery\nbased sensors. Energy harvesting sensors need to be configured according to the\napplication, hardware, and environmental conditions to maximize their\nusefulness. As of today, the configuration of sensors is either manual or\nheuristics based, requiring valuable domain expertise. Reinforcement learning\n(RL) is a promising approach to automate configuration and efficiently scale\nIoT deployments, but it is not yet adopted in practice. We propose solutions to\nbridge this gap: reduce the training phase of RL so that nodes are operational\nwithin a short time after deployment and reduce the computational requirements\nto scale to large deployments. We focus on configuration of the sampling rate\nof indoor solar panel based energy harvesting sensors. We created a simulator\nbased on 3 months of data collected from 5 sensor nodes subject to different\nlighting conditions. Our simulation results show that RL can effectively learn\nenergy availability patterns and configure the sampling rate of the sensor\nnodes to maximize the sensing data while ensuring that energy storage is not\ndepleted. The nodes can be operational within the first day by using our\nmethods. We show that it is possible to reduce the number of RL policies by\nusing a single policy for nodes that share similar lighting conditions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 21:05:43 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Fraternali", "Francesco", ""], ["Balaji", "Bharathan", ""], ["Gupta", "Rajesh", ""]]}, {"id": "1811.11264", "submitter": "Lei Xu", "authors": "Lei Xu, Kalyan Veeramachaneni", "title": "Synthesizing Tabular Data using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) implicitly learn the probability\ndistribution of a dataset and can draw samples from the distribution. This\npaper presents, Tabular GAN (TGAN), a generative adversarial network which can\ngenerate tabular data like medical or educational records. Using the power of\ndeep neural networks, TGAN generates high-quality and fully synthetic tables\nwhile simultaneously generating discrete and continuous variables. When we\nevaluate our model on three datasets, we find that TGAN outperforms\nconventional statistical generative models in both capturing the correlation\nbetween columns and scaling up for large datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 21:13:54 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Xu", "Lei", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1811.11269", "submitter": "Greg Olmschenk", "authors": "Greg Olmschenk, Zhigang Zhu, Hao Tang", "title": "Generalizing semi-supervised generative adversarial networks to\n  regression using feature contrasting", "comments": null, "journal-ref": "Computer Vision and Image Understanding, Volume 186, September\n  2019, Pages 1-12", "doi": "10.1016/j.cviu.2019.06.004", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we generalize semi-supervised generative adversarial networks\n(GANs) from classification problems to regression problems. In the last few\nyears, the importance of improving the training of neural networks using\nsemi-supervised training has been demonstrated for classification problems. We\npresent a novel loss function, called feature contrasting, resulting in a\ndiscriminator which can distinguish between fake and real data based on feature\nstatistics. This method avoids potential biases and limitations of alternative\napproaches. The generalization of semi-supervised GANs to the regime of\nregression problems of opens their use to countless applications as well as\nproviding an avenue for a deeper understanding of how GANs function. We first\ndemonstrate the capabilities of semi-supervised regression GANs on a toy\ndataset which allows for a detailed understanding of how they operate in\nvarious circumstances. This toy dataset is used to provide a theoretical basis\nof the semi-supervised regression GAN. We then apply the semi-supervised\nregression GANs to a number of real-world computer vision applications: age\nestimation, driving steering angle prediction, and crowd counting from single\nimages. We perform extensive tests of what accuracy can be achieved with\nsignificantly reduced annotated data. Through the combination of the\ntheoretical example and real-world scenarios, we demonstrate how\nsemi-supervised GANs can be generalized to regression problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 21:31:33 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 21:37:15 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 17:36:13 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Olmschenk", "Greg", ""], ["Zhu", "Zhigang", ""], ["Tang", "Hao", ""]]}, {"id": "1811.11287", "submitter": "Ben Moews", "authors": "Ben Moews, J. Michael Herrmann, Gbenga Ibikunle", "title": "Lagged correlation-based deep learning for directional trend change\n  prediction in financial time series", "comments": "11 pages, 4 figures", "journal-ref": "Expert Syst. Appl. 120 (2019) 197-206", "doi": "10.1016/j.eswa.2018.11.027", "report-no": null, "categories": "q-fin.CP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trend change prediction in complex systems with a large number of noisy time\nseries is a problem with many applications for real-world phenomena, with stock\nmarkets as a notoriously difficult to predict example of such systems. We\napproach predictions of directional trend changes via complex lagged\ncorrelations between them, excluding any information about the target series\nfrom the respective inputs to achieve predictions purely based on such\ncorrelations with other series. We propose the use of deep neural networks that\nemploy step-wise linear regressions with exponential smoothing in the\npreparatory feature engineering for this task, with regression slopes as trend\nstrength indicators for a given time interval. We apply this method to\nhistorical stock market data from 2011 to 2016 as a use case example of lagged\ncorrelations between large numbers of time series that are heavily influenced\nby externally arising new information as a random factor. The results\ndemonstrate the viability of the proposed approach, with state-of-the-art\naccuracies and accounting for the statistical significance of the results for\nadditional validation, as well as important implications for modern financial\neconomics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 22:03:41 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 09:35:15 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Moews", "Ben", ""], ["Herrmann", "J. Michael", ""], ["Ibikunle", "Gbenga", ""]]}, {"id": "1811.11298", "submitter": "Arash Tavakoli", "authors": "Arash Tavakoli, Vitaly Levdik, Riashat Islam, Christopher M. Smith,\n  Petar Kormushev", "title": "Exploring Restart Distributions", "comments": "RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the generic approach of using an experience memory to help\nexploration by adapting a restart distribution. That is, given the capacity to\nreset the state with those corresponding to the agent's past observations, we\nhelp exploration by promoting faster state-space coverage via restarting the\nagent from a more diverse set of initial states, as well as allowing it to\nrestart in states associated with significant past experiences. This approach\nis compatible with both on-policy and off-policy methods. However, a caveat is\nthat altering the distribution of initial states could change the optimal\npolicies when searching within a restricted class of policies. To reduce this\nunsought learning bias, we evaluate our approach in deep reinforcement learning\nwhich benefits from the high representational capacity of deep neural networks.\nWe instantiate three variants of our approach, each inspired by an idea in the\ncontext of experience replay. Using these variants, we show that performance\ngains can be achieved, especially in hard exploration problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 22:40:01 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 21:28:54 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 03:42:32 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Tavakoli", "Arash", ""], ["Levdik", "Vitaly", ""], ["Islam", "Riashat", ""], ["Smith", "Christopher M.", ""], ["Kormushev", "Petar", ""]]}, {"id": "1811.11310", "submitter": "Kevin McCloskey", "authors": "Kevin McCloskey, Ankur Taly, Federico Monti, Michael P. Brenner, Lucy\n  Colwell", "title": "Using Attribution to Decode Dataset Bias in Neural Network Models for\n  Chemistry", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1820657116", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved state of the art accuracy at classifying\nmolecules with respect to whether they bind to specific protein targets. A key\nbreakthrough would occur if these models could reveal the fragment\npharmacophores that are causally involved in binding. Extracting chemical\ndetails of binding from the networks could potentially lead to scientific\ndiscoveries about the mechanisms of drug actions. But doing so requires shining\nlight into the black box that is the trained neural network model, a task that\nhas proved difficult across many domains. Here we show how the binding\nmechanism learned by deep neural network models can be interrogated, using a\nrecently described attribution method. We first work with carefully constructed\nsynthetic datasets, in which the 'fragment logic' of binding is fully known. We\nfind that networks that achieve perfect accuracy on held out test datasets\nstill learn spurious correlations due to biases in the datasets, and we are\nable to exploit this non-robustness to construct adversarial examples that fool\nthe model. The dataset bias makes these models unreliable for accurately\nrevealing information about the mechanisms of protein-ligand binding. In light\nof our findings, we prescribe a test that checks for dataset bias given a\nhypothesis. If the test fails, it indicates that either the model must be\nsimplified or regularized and/or that the training dataset requires\naugmentation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 23:33:05 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 20:05:44 GMT"}, {"version": "v3", "created": "Sun, 19 May 2019 04:29:23 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["McCloskey", "Kevin", ""], ["Taly", "Ankur", ""], ["Monti", "Federico", ""], ["Brenner", "Michael P.", ""], ["Colwell", "Lucy", ""]]}, {"id": "1811.11339", "submitter": "Hanshen Xiao", "authors": "Nan Du, Zhikang Wang and Hanshen Xiao", "title": "Statistical Robust Chinese Remainder Theorem for Multiple Numbers:\n  Wrapped Gaussian Mixture Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Chinese Remainder Theorem (CRT) has been shown to be a powerful\napproach to solve the ambiguity resolution problem. However, with its close\nrelationship to number theory, study in this area is mainly from a coding\ntheory perspective under deterministic conditions. Nevertheless, it can be\nproved that even with the best deterministic condition known, the probability\nof success in robust reconstruction degrades exponentially as the number of\nestimand increases. In this paper, we present the first rigorous analysis on\nthe underlying statistical model of CRT-based multiple parameter estimation,\nwhere a generalized Gaussian mixture with background knowledge on samplings is\nproposed. To address the problem, two novel approaches are introduced. One is\nto directly calculate the conditional maximal a posteriori probability (MAP)\nestimation of residue clustering, and the other is to iteratively search for\nMAP of both common residues and clustering. Moreover, remainder\nerror-correcting codes are introduced to improve the robustness further. It is\nshown that this statistically based scheme achieves much stronger robustness\ncompared to state-of-the-art deterministic schemes, especially in low and\nmedian Signal Noise Ratio (SNR) scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 01:44:47 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Du", "Nan", ""], ["Wang", "Zhikang", ""], ["Xiao", "Hanshen", ""]]}, {"id": "1811.11347", "submitter": "Humza Haider", "authors": "Humza Haider, Bret Hoehn, Sarah Davis, Russell Greiner", "title": "Effective Ways to Build and Evaluate Individual Survival Distributions", "comments": "34 pages (main text), 12 figures", "journal-ref": "Journal of Machine Learning Research (JMLR) Volume 21 (2020)\n  18-772", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate model of a patient's individual survival distribution can help\ndetermine the appropriate treatment for terminal patients. Unfortunately, risk\nscores (e.g., from Cox Proportional Hazard models) do not provide survival\nprobabilities, single-time probability models (e.g., the Gail model, predicting\n5 year probability) only provide for a single time point, and standard\nKaplan-Meier survival curves provide only population averages for a large class\nof patients meaning they are not specific to individual patients. This\nmotivates an alternative class of tools that can learn a model which provides\nan individual survival distribution which gives survival probabilities across\nall times - such as extensions to the Cox model, Accelerated Failure Time, an\nextension to Random Survival Forests, and Multi-Task Logistic Regression. This\npaper first motivates such \"individual survival distribution\" (ISD) models, and\nexplains how they differ from standard models. It then discusses ways to\nevaluate such models - namely Concordance, 1-Calibration, Brier score, and\nvarious versions of L1-loss - and then motivates and defines a novel approach\n\"D-Calibration\", which determines whether a model's probability estimates are\nmeaningful. We also discuss how these measures differ, and use them to evaluate\nseveral ISD prediction tools, over a range of survival datasets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 02:00:54 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Haider", "Humza", ""], ["Hoehn", "Bret", ""], ["Davis", "Sarah", ""], ["Greiner", "Russell", ""]]}, {"id": "1811.11353", "submitter": "Alex De Sa'", "authors": "Alex G. C. de S\\'a, Cristiano G. Pimenta, Gisele L. Pappa and Alex A.\n  Freitas", "title": "Multi-label classification search space in the MEKA software", "comments": "Supplementary Material (GECCO'2020): Proposed Search Spaces", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This supplementary material aims to describe the proposed multi-label\nclassification (MLC) search spaces based on the MEKA and WEKA softwares. First,\nwe overview 26 MLC algorithms and meta-algorithms in MEKA, presenting their\nmain characteristics, such as hyper-parameters, dependencies and constraints.\nSecond, we review 28 single-label classification (SLC) algorithms,\npreprocessing algorithms and meta-algorithms in the WEKA software. These SLC\nalgorithms were also studied because they are part of the proposed MLC search\nspaces. Fundamentally, this occurs due to the problem transformation nature of\nseveral MLC algorithms used in this work. These algorithms transform an MLC\nproblem into one or several SLC problems in the first place and solve them with\nSLC model(s) in a next step. Therefore, understanding their main\ncharacteristics is crucial to this work. Finally, we present a formal\ndescription of the search spaces by proposing a context-free grammar that\nencompasses the 54 learning algorithms. This grammar basically comprehends the\npossible combinations, the constraints and dependencies among the learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 02:19:33 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 02:42:25 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 13:52:01 GMT"}, {"version": "v4", "created": "Thu, 14 May 2020 14:32:48 GMT"}, {"version": "v5", "created": "Fri, 31 Jul 2020 17:06:56 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["de S\u00e1", "Alex G. C.", ""], ["Pimenta", "Cristiano G.", ""], ["Pappa", "Gisele L.", ""], ["Freitas", "Alex A.", ""]]}, {"id": "1811.11357", "submitter": "Ryan Turner", "authors": "Ryan Turner, Jane Hung, Eric Frank, Yunus Saatci, Jason Yosinski", "title": "Metropolis-Hastings Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Metropolis-Hastings generative adversarial network (MH-GAN),\nwhich combines aspects of Markov chain Monte Carlo and GANs. The MH-GAN draws\nsamples from the distribution implicitly defined by a GAN's\ndiscriminator-generator pair, as opposed to standard GANs which draw samples\nfrom the distribution defined only by the generator. It uses the discriminator\nfrom GAN training to build a wrapper around the generator for improved\nsampling. With a perfect discriminator, this wrapped generator samples from the\ntrue distribution on the data exactly even when the generator is imperfect. We\ndemonstrate the benefits of the improved generator on multiple benchmark\ndatasets, including CIFAR-10 and CelebA, using the DCGAN, WGAN, and progressive\nGAN.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 02:28:33 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 22:33:37 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Turner", "Ryan", ""], ["Hung", "Jane", ""], ["Frank", "Eric", ""], ["Saatci", "Yunus", ""], ["Yosinski", "Jason", ""]]}, {"id": "1811.11359", "submitter": "David Warde-Farley", "authors": "David Warde-Farley, Tom Van de Wiele, Tejas Kulkarni, Catalin Ionescu,\n  Steven Hansen, Volodymyr Mnih", "title": "Unsupervised Control Through Non-Parametric Discriminative Rewards", "comments": "10 pages + references & 5 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to control an environment without hand-crafted rewards or expert\ndata remains challenging and is at the frontier of reinforcement learning\nresearch. We present an unsupervised learning algorithm to train agents to\nachieve perceptually-specified goals using only a stream of observations and\nactions. Our agent simultaneously learns a goal-conditioned policy and a goal\nachievement reward function that measures how similar a state is to the goal\nstate. This dual optimization leads to a co-operative game, giving rise to a\nlearned reward function that reflects similarity in controllable aspects of the\nenvironment instead of distance in the space of observations. We demonstrate\nthe efficacy of our agent to learn, in an unsupervised manner, to reach a\ndiverse set of goals on three domains -- Atari, the DeepMind Control Suite and\nDeepMind Lab.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 02:35:24 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Warde-Farley", "David", ""], ["Van de Wiele", "Tom", ""], ["Kulkarni", "Tejas", ""], ["Ionescu", "Catalin", ""], ["Hansen", "Steven", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "1811.11368", "submitter": "Yichen Zhang", "authors": "Xi Chen, Weidong Liu, Yichen Zhang", "title": "First-order Newton-type Estimator for Distributed Estimation and\n  Inference", "comments": "60 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies distributed estimation and inference for a general\nstatistical problem with a convex loss that could be non-differentiable. For\nthe purpose of efficient computation, we restrict ourselves to stochastic\nfirst-order optimization, which enjoys low per-iteration complexity. To\nmotivate the proposed method, we first investigate the theoretical properties\nof a straightforward Divide-and-Conquer Stochastic Gradient Descent (DC-SGD)\napproach. Our theory shows that there is a restriction on the number of\nmachines and this restriction becomes more stringent when the dimension $p$ is\nlarge. To overcome this limitation, this paper proposes a new multi-round\ndistributed estimation procedure that approximates the Newton step only using\nstochastic subgradient. The key component in our method is the proposal of a\ncomputationally efficient estimator of $\\Sigma^{-1} w$, where $\\Sigma$ is the\npopulation Hessian matrix and $w$ is any given vector. Instead of estimating\n$\\Sigma$ (or $\\Sigma^{-1}$) that usually requires the second-order\ndifferentiability of the loss, the proposed First-Order Newton-type Estimator\n(FONE) directly estimates the vector of interest $\\Sigma^{-1} w$ as a whole and\nis applicable to non-differentiable losses. Our estimator also facilitates the\ninference for the empirical risk minimizer. It turns out that the key term in\nthe limiting covariance has the form of $\\Sigma^{-1} w$, which can be estimated\nby FONE.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 02:58:28 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 17:10:35 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Chen", "Xi", ""], ["Liu", "Weidong", ""], ["Zhang", "Yichen", ""]]}, {"id": "1811.11373", "submitter": "Alessio Lomuscio", "authors": "Panagiotis Kouvaros and Alessio Lomuscio", "title": "Formal Verification of CNN-based Perception Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of verifying neural-based perception systems\nimplemented by convolutional neural networks. We define a notion of local\nrobustness based on affine and photometric transformations. We show the notion\ncannot be captured by previously employed notions of robustness. The method\nproposed is based on reachability analysis for feed-forward neural networks and\nrelies on MILP encodings of both the CNNs and transformations under question.\nWe present an implementation and discuss the experimental results obtained for\na CNN trained from the MNIST data set.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 03:36:25 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Kouvaros", "Panagiotis", ""], ["Lomuscio", "Alessio", ""]]}, {"id": "1811.11402", "submitter": "Siddique Latif", "authors": "Siddique Latif, Rajib Rana, and Junaid Qadir", "title": "Adversarial Machine Learning And Speech Emotion Recognition: Utilizing\n  Generative Adversarial Networks For Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has undoubtedly offered tremendous improvements in the\nperformance of state-of-the-art speech emotion recognition (SER) systems.\nHowever, recent research on adversarial examples poses enormous challenges on\nthe robustness of SER systems by showing the susceptibility of deep neural\nnetworks to adversarial examples as they rely only on small and imperceptible\nperturbations. In this study, we evaluate how adversarial examples can be used\nto attack SER systems and propose the first black-box adversarial attack on SER\nsystems. We also explore potential defenses including adversarial training and\ngenerative adversarial network (GAN) to enhance robustness. Experimental\nevaluations suggest various interesting aspects of the effective utilization of\nadversarial examples useful for achieving robustness for SER systems opening up\nopportunities for researchers to further innovate in this space.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 06:26:03 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 10:44:21 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Latif", "Siddique", ""], ["Rana", "Rajib", ""], ["Qadir", "Junaid", ""]]}, {"id": "1811.11419", "submitter": "Emilie Kaufmann", "authors": "Emilie Kaufmann (SEQUEL), Wouter Koolen (CWI)", "title": "Mixture Martingales Revisited with Applications to Sequential Tests and\n  Confidence Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents new deviation inequalities that are valid uniformly in\ntime under adaptive sampling in a multi-armed bandit model. The deviations are\nmeasured using the Kullback-Leibler divergence in a given one-dimensional\nexponential family, and may take into account several arms at a time. They are\nobtained by constructing for each arm a mixture martingale based on a\nhierarchical prior, and by multiplying those martingales. Our deviation\ninequalities allow us to analyze stopping rules based on generalized likelihood\nratios for a large class of sequential identification problems, and to\nconstruct tight confidence intervals for some functions of the means of the\narms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 07:36:18 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Kaufmann", "Emilie", "", "SEQUEL"], ["Koolen", "Wouter", "", "CWI"]]}, {"id": "1811.11426", "submitter": "Maciej Zamorski", "authors": "Maciej Zamorski and Maciej Zi\\k{e}ba", "title": "Semi-supervised learning with Bidirectional GANs", "comments": "12 pages, 3 figures", "journal-ref": "Intelligent Information and Database Systems. ACIIDS 2019. Lecture\n  Notes in Computer Science, vol 11431 (2019) 649-660", "doi": "10.1007/978-3-030-14799-0_56", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a novel approach to train Bidirectional Generative\nAdversarial Model (BiGAN) in a semi-supervised manner. The presented method\nutilizes triplet loss function as an additional component of the objective\nfunction used to train discriminative data representation in the latent space\nof the BiGAN model. This representation can be further used as a seed for\ngenerating artificial images, but also as a good feature embedding for\nclassification and image retrieval tasks. We evaluate the quality of the\nproposed method in the two mentioned challenging tasks using two benchmark\ndatasets: CIFAR10 and SVHN.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 07:51:21 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Zamorski", "Maciej", ""], ["Zi\u0119ba", "Maciej", ""]]}, {"id": "1811.11427", "submitter": "Ragunathan Mariappan", "authors": "Ragunathan Mariappan and Vaibhav Rajan", "title": "Deep Collective Matrix Factorization for Augmented Multi-View Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning by integrating multiple heterogeneous data sources is a common\nrequirement in many tasks. Collective Matrix Factorization (CMF) is a technique\nto learn shared latent representations from arbitrary collections of matrices.\nIt can be used to simultaneously complete one or more matrices, for predicting\nthe unknown entries. Classical CMF methods assume linearity in the interaction\nof latent factors which can be restrictive and fails to capture complex\nnon-linear interactions. In this paper, we develop the first deep-learning\nbased method, called dCMF, for unsupervised learning of multiple shared\nrepresentations, that can model such non-linear interactions, from an arbitrary\ncollection of matrices. We address optimization challenges that arise due to\ndependencies between shared representations through Multi-Task Bayesian\nOptimization and design an acquisition function adapted for collective learning\nof hyperparameters. Our experiments show that dCMF significantly outperforms\nprevious CMF algorithms in integrating heterogeneous data for predictive\nmodeling. Further, on two tasks - recommendation and prediction of gene-disease\nassociation - dCMF outperforms state-of-the-art matrix completion algorithms\nthat can utilize auxiliary sources of information.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 07:52:48 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 05:28:25 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Mariappan", "Ragunathan", ""], ["Rajan", "Vaibhav", ""]]}, {"id": "1811.11433", "submitter": "Pierre Ablin", "authors": "Pierre Ablin (PARIETAL), Jean-Fran\\c{c}ois Cardoso (CNRS, IAP),\n  Alexandre Gramfort (PARIETAL)", "title": "Beyond Pham's algorithm for joint diagonalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate joint diagonalization of a set of matrices consists in\nfinding a basis in which these matrices are as diagonal as possible. This\nproblem naturally appears in several statistical learning tasks such as blind\nsignal separation. We consider the diagonalization criterion studied in a\nseminal paper by Pham (2001), and propose a new quasi-Newton method for its\noptimization. Through numerical experiments on simulated and real datasets, we\nshow that the proposed method outper-forms Pham's algorithm. An open source\nPython package is released.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 08:03:18 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Ablin", "Pierre", "", "PARIETAL"], ["Cardoso", "Jean-Fran\u00e7ois", "", "CNRS, IAP"], ["Gramfort", "Alexandre", "", "PARIETAL"]]}, {"id": "1811.11441", "submitter": "Sujoy Paul", "authors": "Sujoy Paul and Jeroen van Baar", "title": "Trajectory-based Learning for Ball-in-Maze Games", "comments": "Accepted at NIPS 2018 Workshop on Imitation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has shown tremendous success in solving several\ngames and tasks in robotics. However, unlike humans, it generally requires a\nlot of training instances. Trajectories imitating to solve the task at hand can\nhelp to increase sample-efficiency of deep RL methods. In this paper, we\npresent a simple approach to use such trajectories, applied to the challenging\nBall-in-Maze Games, recently introduced in the literature. We show that in\nspite of not using human-generated trajectories and just using the simulator as\na model to generate a limited number of trajectories, we can get a speed-up of\nabout 2-3x in the learning process. We also discuss some challenges we observed\nwhile using trajectory-based learning for very sparse reward functions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 08:38:40 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 17:03:08 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Paul", "Sujoy", ""], ["van Baar", "Jeroen", ""]]}, {"id": "1811.11456", "submitter": "Soumen Chakrabarti", "authors": "Divam Gupta, Tanmoy Chakraborty, Soumen Chakrabarti", "title": "GIRNet: Interleaved Multi-Task Recurrent State Sequence Models", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several natural language tasks, labeled sequences are available in\nseparate domains (say, languages), but the goal is to label sequences with\nmixed domain (such as code-switched text). Or, we may have available models for\nlabeling whole passages (say, with sentiments), which we would like to exploit\ntoward better position-specific label inference (say, target-dependent\nsentiment annotation). A key characteristic shared across such tasks is that\ndifferent positions in a primary instance can benefit from different `experts'\ntrained from auxiliary data, but labeled primary instances are scarce, and\nlabeling the best expert for each position entails unacceptable cognitive\nburden. We propose GITNet, a unified position-sensitive multi-task recurrent\nneural network (RNN) architecture for such applications. Auxiliary and primary\ntasks need not share training instances. Auxiliary RNNs are trained over\nauxiliary instances. A primary instance is also submitted to each auxiliary\nRNN, but their state sequences are gated and merged into a novel composite\nstate sequence tailored to the primary inference task. Our approach is in sharp\ncontrast to recent multi-task networks like the cross-stitch and sluice\nnetwork, which do not control state transfer at such fine granularity. We\ndemonstrate the superiority of GIRNet using three applications: sentiment\nclassification of code-switched passages, part-of-speech tagging of\ncode-switched text, and target position-sensitive annotation of sentiment in\nmonolingual passages. In all cases, we establish new state-of-the-art\nperformance beyond recent competitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 09:20:13 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2018 07:04:27 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Gupta", "Divam", ""], ["Chakraborty", "Tanmoy", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1811.11474", "submitter": "Jakub Pr\\\"uher", "authors": "Jakub Pr\\\"uher, Toni Karvonen, Chris J. Oates, Ond\\v{r}ej Straka, Simo\n  S\\\"arkk\\\"a", "title": "Improved Calibration of Numerical Integration Error in Sigma-Point\n  Filters", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sigma-point filters, such as the UKF, which exploit numerical quadrature\nto obtain an additional order of accuracy in the moment transformation step,\nare popular alternatives to the ubiquitous EKF. The classical quadrature rules\nused in the sigma-point filters are motivated via polynomial approximation of\nthe integrand, however in the applied context these assumptions cannot always\nbe justified. As a result, quadrature error can introduce bias into estimated\nmoments, for which there is no compensatory mechanism in the classical\nsigma-point filters. This can lead in turn to estimates and predictions that\nare poorly calibrated. In this article, we investigate the Bayes-Sard\nquadrature method in the context of sigma-point filters, which enables\nuncertainty due to quadrature error to be formalised within a probabilistic\nmodel. Our first contribution is to derive the well-known classical quadratures\nas special cases of the Bayes-Sard quadrature method. Then a general-purpose\nmoment transform is developed and utilised in the design of novel sigma-point\nfilters, so that uncertainty due to quadrature error is explicitly quantified.\nNumerical experiments on a challenging tracking example with misspecified\ninitial conditions show that the additional uncertainty quantification built\ninto our method leads to better-calibrated state estimates with improved RMSE.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 10:07:16 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 11:37:33 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Pr\u00fcher", "Jakub", ""], ["Karvonen", "Toni", ""], ["Oates", "Chris J.", ""], ["Straka", "Ond\u0159ej", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "1811.11479", "submitter": "Eunjeong Jeong", "authors": "Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis,\n  and Seong-Lyun Kim", "title": "Communication-Efficient On-Device Machine Learning: Federated\n  Distillation and Augmentation under Non-IID Private Data", "comments": "to be presented at the 32nd Conference on Neural Information\n  Processing Systems (NIPS 2018), 2nd Workshop on Machine Learning on the Phone\n  and other Consumer Devices (MLPCD 2), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device machine learning (ML) enables the training process to exploit a\nmassive amount of user-generated private data samples. To enjoy this benefit,\ninter-device communication overhead should be minimized. With this end, we\npropose federated distillation (FD), a distributed model training algorithm\nwhose communication payload size is much smaller than a benchmark scheme,\nfederated learning (FL), particularly when the model size is large. Moreover,\nuser-generated data samples are likely to become non-IID across devices, which\ncommonly degrades the performance compared to the case with an IID dataset. To\ncope with this, we propose federated augmentation (FAug), where each device\ncollectively trains a generative model, and thereby augments its local data\ntowards yielding an IID dataset. Empirical studies demonstrate that FD with\nFAug yields around 26x less communication overhead while achieving 95-98% test\naccuracy compared to FL.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 10:16:18 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Jeong", "Eunjeong", ""], ["Oh", "Seungeun", ""], ["Kim", "Hyesung", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""]]}, {"id": "1811.11493", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "A randomized gradient-free attack on ReLU networks", "comments": "In GCPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that neural networks but also other classifiers\nare vulnerable to so called adversarial attacks e.g. in object recognition an\nalmost non-perceivable change of the image changes the decision of the\nclassifier. Relatively fast heuristics have been proposed to produce these\nadversarial inputs but the problem of finding the optimal adversarial input,\nthat is with the minimal change of the input, is NP-hard. While methods based\non mixed-integer optimization which find the optimal adversarial input have\nbeen developed, they do not scale to large networks. Currently, the attack\nscheme proposed by Carlini and Wagner is considered to produce the best\nadversarial inputs. In this paper we propose a new attack scheme for the class\nof ReLU networks based on a direct optimization on the resulting linear\nregions. In our experimental validation we improve in all except one experiment\nout of 18 over the Carlini-Wagner attack with a relative improvement of up to\n9\\%. As our approach is based on the geometrical structure of ReLU networks, it\nis less susceptible to defences targeting their functional properties.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 11:03:26 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1811.11540", "submitter": "Austin Benson", "authors": "Austin R. Benson and Jon Kleinberg", "title": "Link Prediction in Networks with Core-Fringe Data", "comments": null, "journal-ref": null, "doi": "10.1145/3308558.3313626", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection often involves the partial measurement of a larger system. A\ncommon example arises in collecting network data: we often obtain network\ndatasets by recording all of the interactions among a small set of core nodes,\nso that we end up with a measurement of the network consisting of these core\nnodes along with a potentially much larger set of fringe nodes that have links\nto the core. Given the ubiquity of this process for assembling network data, it\nis crucial to understand the role of such a `core-fringe' structure.\n  Here we study how the inclusion of fringe nodes affects the standard task of\nnetwork link prediction. One might initially think the inclusion of any\nadditional data is useful, and hence that it should be beneficial to include\nall fringe nodes that are available. However, we find that this is not true; in\nfact, there is substantial variability in the value of the fringe nodes for\nprediction. Once an algorithm is selected, in some datasets, including any\nadditional data from the fringe can actually hurt prediction performance; in\nother datasets, including some amount of fringe information is useful before\nprediction performance saturates or even declines; and in further cases,\nincluding the entire fringe leads to the best performance. While such variety\nmight seem surprising, we show that these behaviors are exhibited by simple\nrandom graph models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 13:22:04 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 17:24:49 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Benson", "Austin R.", ""], ["Kleinberg", "Jon", ""]]}, {"id": "1811.11549", "submitter": "Eli Chien", "authors": "I Chien, Huozhi Zhou, Pan Li", "title": "$HS^2$: Active Learning over Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hypergraph-based active learning scheme which we term $HS^2$,\n$HS^2$ generalizes the previously reported algorithm $S^2$ originally proposed\nfor graph-based active learning with pointwise queries [Dasarathy et al., COLT\n2015]. Our $HS^2$ method can accommodate hypergraph structures and allows one\nto ask both pointwise queries and pairwise queries. Based on a novel parametric\nsystem particularly designed for hypergraphs, we derive theoretical results on\nthe query complexity of $HS^2$ for the above described generalized settings.\nBoth the theoretical and empirical results show that $HS^2$ requires a\nsignificantly fewer number of queries than $S^2$ when one uses $S^2$ over a\ngraph obtained from the corresponding hypergraph via clique expansion.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 18:00:56 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Chien", "I", ""], ["Zhou", "Huozhi", ""], ["Li", "Pan", ""]]}, {"id": "1811.11569", "submitter": "Teofilo de Campos", "authors": "Fabricio Ataides Braz, Nilton Correia da Silva, Teofilo Emidio de\n  Campos, Felipe Borges S. Chaves, Marcelo H. S. Ferreira, Pedro Henrique\n  Inazawa, Victor H. D. Coelho, Bernardo Pablo Sukiennik, Ana Paula Goncalves\n  Soares de Almeida, Flavio Barros Vidal, Davi Alves Bezerra, Davi B. Gusmao,\n  Gabriel G. Ziegler, Ricardo V. C. Fernandes, Roberta Zumblick, Fabiano\n  Hartmann Peixoto", "title": "Document classification using a Bi-LSTM to unclog Brazil's supreme court", "comments": "This work was presented at NIPS 2018 Workshop on Machine Learning for\n  the Developing World (ML4D)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Brazilian court system is currently the most clogged up judiciary system\nin the world. Thousands of lawsuit cases reach the supreme court every day.\nThese cases need to be analyzed in order to be associated to relevant tags and\nallocated to the right team. Most of the cases reach the court as raster\nscanned documents with widely variable levels of quality. One of the first\nsteps for the analysis is to classify these documents. In this paper we present\na Bidirectional Long Short-Term Memory network (Bi-LSTM) to classify these\npieces of legal document.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 11:30:01 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Braz", "Fabricio Ataides", ""], ["da Silva", "Nilton Correia", ""], ["de Campos", "Teofilo Emidio", ""], ["Chaves", "Felipe Borges S.", ""], ["Ferreira", "Marcelo H. S.", ""], ["Inazawa", "Pedro Henrique", ""], ["Coelho", "Victor H. D.", ""], ["Sukiennik", "Bernardo Pablo", ""], ["de Almeida", "Ana Paula Goncalves Soares", ""], ["Vidal", "Flavio Barros", ""], ["Bezerra", "Davi Alves", ""], ["Gusmao", "Davi B.", ""], ["Ziegler", "Gabriel G.", ""], ["Fernandes", "Ricardo V. C.", ""], ["Zumblick", "Roberta", ""], ["Peixoto", "Fabiano Hartmann", ""]]}, {"id": "1811.11597", "submitter": "Pascal Kerschke", "authors": "Pascal Kerschke, Holger H. Hoos, Frank Neumann, Heike Trautmann", "title": "Automated Algorithm Selection: Survey and Perspectives", "comments": "This is the author's final version, and the article has been accepted\n  for publication in Evolutionary Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been observed that for practically any computational problem that\nhas been intensely studied, different instances are best solved using different\nalgorithms. This is particularly pronounced for computationally hard problems,\nwhere in most cases, no single algorithm defines the state of the art; instead,\nthere is a set of algorithms with complementary strengths. This performance\ncomplementarity can be exploited in various ways, one of which is based on the\nidea of selecting, from a set of given algorithms, for each problem instance to\nbe solved the one expected to perform best. The task of automatically selecting\nan algorithm from a given set is known as the per-instance algorithm selection\nproblem and has been intensely studied over the past 15 years, leading to major\nimprovements in the state of the art in solving a growing number of discrete\ncombinatorial problems, including propositional satisfiability and AI planning.\nPer-instance algorithm selection also shows much promise for boosting\nperformance in solving continuous and mixed discrete/continuous optimisation\nproblems.\n  This survey provides an overview of research in automated algorithm\nselection, ranging from early and seminal works to recent and promising\napplication areas. Different from earlier work, it covers applications to\ndiscrete and continuous problems, and discusses algorithm selection in context\nwith conceptually related approaches, such as algorithm configuration,\nscheduling or portfolio selection. Since informative and cheaply computable\nproblem instance features provide the basis for effective per-instance\nalgorithm selection systems, we also provide an overview of such features for\ndiscrete and continuous problems. Finally, we provide perspectives on future\nwork in the area and discuss a number of open research challenges.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 14:43:49 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Kerschke", "Pascal", ""], ["Hoos", "Holger H.", ""], ["Neumann", "Frank", ""], ["Trautmann", "Heike", ""]]}, {"id": "1811.11618", "submitter": "Eric Benhamou", "authors": "Eric Benhamou", "title": "Kalman filter demystified: from intuition to probabilistic graphical\n  model to real case in financial markets", "comments": "44 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the Kalman filter theory. After giving the\nintuition on a simplified financial markets example, we revisit the maths\nunderlying it. We then show that Kalman filter can be presented in a very\ndifferent fashion using graphical models. This enables us to establish the\nconnection between Kalman filter and Hidden Markov Models. We then look at\ntheir application in financial markets and provide various intuitions in terms\nof their applicability for complex systems such as financial markets. Although\nthis paper has been written more like a self contained work connecting Kalman\nfilter to Hidden Markov Models and hence revisiting well known and establish\nresults, it contains new results and brings additional contributions to the\nfield. First, leveraging on the link between Kalman filter and HMM, it gives\nnew algorithms for inference for extended Kalman filters. Second, it presents\nan alternative to the traditional estimation of parameters using EM algorithm\nthanks to the usage of CMA-ES optimization. Third, it examines the application\nof Kalman filter and its Hidden Markov models version to financial markets,\nproviding various dynamics assumptions and tests. We conclude by connecting\nKalman filter approach to trend following technical analysis system and showing\ntheir superior performances for trend following detection.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 15:19:11 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 07:16:05 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Benhamou", "Eric", ""]]}, {"id": "1811.11620", "submitter": "Waddah Waheeb", "authors": "Waddah Waheeb and Rozaida Ghazali", "title": "Multi-step Time Series Forecasting Using Ridge Polynomial Neural Network\n  with Error-Output Feedbacks", "comments": "This is a pre-print of an article published in the International\n  Conference on Soft Computing in Data Science, 2016. The final authenticated\n  version is available online at:\n  http://link.springer.com/chapter/10.1007/978-981-10-2777-2_5", "journal-ref": null, "doi": "10.1007/978-981-10-2777-2_5", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting gets much attention due to its impact on many\npractical applications. Higher-order neural network with recurrent feedback is\na powerful technique which used successfully for forecasting. It maintains fast\nlearning and the ability to learn the dynamics of the series over time. For\nthat, in this paper, we propose a novel model which is called Ridge Polynomial\nNeural Network with Error-Output Feedbacks (RPNN-EOFs) that combines the\nproperties of higher order and error-output feedbacks. The well-known\nMackey-Glass time series is used to test the forecasting capability of\nRPNN-EOFS. Simulation results showed that the proposed RPNN-EOFs provides\nbetter understanding for the Mackey-Glass time series with root mean square\nerror equal to 0.00416. This result is smaller than other models in the\nliterature. Therefore, we can conclude that the RPNN-EOFs can be applied\nsuccessfully for time series forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 15:19:45 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Waheeb", "Waddah", ""], ["Ghazali", "Rozaida", ""]]}, {"id": "1811.11633", "submitter": "Aleksandr Aravkin", "authors": "Robert Baraldi, Rajiv Kumar, and Aleksandr Aravkin", "title": "Basis Pursuit Denoise with Nonsmooth Constraints", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": "10.1109/TSP.2019.2946029", "report-no": null, "categories": "math.OC physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Level-set optimization formulations with data-driven constraints minimize a\nregularization functional subject to matching observations to a given error\nlevel. These formulations are widely used, particularly for matrix completion\nand sparsity promotion in data interpolation and denoising. The misfit level is\ntypically measured in the l2 norm, or other smooth metrics. In this paper, we\npresent a new flexible algorithmic framework that targets nonsmooth level-set\nconstraints, including L1, Linf, and even L0 norms. These constraints give\ngreater flexibility for modeling deviations in observation and denoising, and\nhave significant impact on the solution. Measuring error in the L1 and L0 norms\nmakes the result more robust to large outliers, while matching many\nobservations exactly. We demonstrate the approach for basis pursuit denoise\n(BPDN) problems as well as for extensions of BPDN to matrix factorization, with\napplications to interpolation and denoising of 5D seismic data. The new methods\nare particularly promising for seismic applications, where the amplitude in the\ndata varies significantly, and measurement noise in low-amplitude regions can\nwreak havoc for standard Gaussian error models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 15:38:36 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Baraldi", "Robert", ""], ["Kumar", "Rajiv", ""], ["Aravkin", "Aleksandr", ""]]}, {"id": "1811.11636", "submitter": "Harry Sevi", "authors": "Harry Sevi, Gabriel Rilling, Pierre Borgnat", "title": "Harmonic analysis on directed graphs and applications: from Fourier\n  analysis to wavelets", "comments": "51 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel harmonic analysis for functions defined on the vertices\nof a strongly connected directed graph of which the random walk operator is the\ncornerstone. As a first step, we consider the set of eigenvectors of the random\nwalk operator as a non-orthogonal Fourier-type basis for functions over\ndirected graphs. We found a frequency interpretation by linking the variation\nof the eigenvectors of the random walk operator obtained from their Dirichlet\nenergy to the real part of their associated eigenvalues. From this Fourier\nbasis, we can proceed further and build multi-scale analyses on directed\ngraphs. We propose both a redundant wavelet transform and a decimated wavelet\ntransform by extending the diffusion wavelets framework by Coifman and Maggioni\nfor directed graphs. The development of our harmonic analysis on directed\ngraphs thus leads us to consider both semi-supervised learning problems and\nsignal modeling problems on graphs applied to directed graphs highlighting the\nefficiency of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 15:45:07 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 08:28:52 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Sevi", "Harry", ""], ["Rilling", "Gabriel", ""], ["Borgnat", "Pierre", ""]]}, {"id": "1811.11644", "submitter": "Li Jing", "authors": "Li Jing, Rumen Dangovski, Marin Soljacic", "title": "WaveletNet: Logarithmic Scale Efficient Convolutional Neural Networks\n  for Edge Devices", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a logarithmic-scale efficient convolutional neural network\narchitecture for edge devices, named WaveletNet. Our model is based on the\nwell-known depthwise convolution, and on two new layers, which we introduce in\nthis work: a wavelet convolution and a depthwise fast wavelet transform. By\nbreaking the symmetry in channel dimensions and applying a fast algorithm,\nWaveletNet shrinks the complexity of convolutional blocks by an O(logD/D)\nfactor, where D is the number of channels. Experiments on CIFAR-10 and ImageNet\nclassification show superior and comparable performances of WaveletNet compared\nto state-of-the-art models such as MobileNetV2.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 16:04:30 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Jing", "Li", ""], ["Dangovski", "Rumen", ""], ["Soljacic", "Marin", ""]]}, {"id": "1811.11646", "submitter": "Arghyadip Roy", "authors": "Arghyadip Roy, Vivek Borkar, Abhay Karandikar, Prasanna Chaporkar", "title": "A Structure-aware Online Learning Algorithm for Markov Decision\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To overcome the curse of dimensionality and curse of modeling in Dynamic\nProgramming (DP) methods for solving classical Markov Decision Process (MDP)\nproblems, Reinforcement Learning (RL) algorithms are popular. In this paper, we\nconsider an infinite-horizon average reward MDP problem and prove the\noptimality of the threshold policy under certain conditions. Traditional RL\ntechniques do not exploit the threshold nature of optimal policy while\nlearning. In this paper, we propose a new RL algorithm which utilizes the known\nthreshold structure of the optimal policy while learning by reducing the\nfeasible policy space. We establish that the proposed algorithm converges to\nthe optimal policy. It provides a significant improvement in convergence speed\nand computational and storage complexity over traditional RL algorithms. The\nproposed technique can be applied to a wide variety of optimization problems\nthat include energy efficient data transmission and management of queues. We\nexhibit the improvement in convergence speed of the proposed algorithm over\nother RL algorithms through simulations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 16:05:21 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Roy", "Arghyadip", ""], ["Borkar", "Vivek", ""], ["Karandikar", "Abhay", ""], ["Chaporkar", "Prasanna", ""]]}, {"id": "1811.11668", "submitter": "Sebastian Benthall", "authors": "Sebastian Benthall and Bruce D. Haynes", "title": "Racial categories in machine learning", "comments": null, "journal-ref": null, "doi": "10.1145/3287560.3287575", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controversies around race and machine learning have sparked debate among\ncomputer scientists over how to design machine learning systems that guarantee\nfairness. These debates rarely engage with how racial identity is embedded in\nour social experience, making for sociological and psychological complexity.\nThis complexity challenges the paradigm of considering fairness to be a formal\nproperty of supervised learning with respect to protected personal attributes.\nRacial identity is not simply a personal subjective quality. For people labeled\n\"Black\" it is an ascribed political category that has consequences for social\ndifferentiation embedded in systemic patterns of social inequality achieved\nthrough both social and spatial segregation. In the United States, racial\nclassification can best be understood as a system of inherently unequal status\ncategories that places whites as the most privileged category while signifying\nthe Negro/black category as stigmatized. Social stigma is reinforced through\nthe unequal distribution of societal rewards and goods along racial lines that\nis reinforced by state, corporate, and civic institutions and practices. This\ncreates a dilemma for society and designers: be blind to racial group\ndisparities and thereby reify racialized social inequality by no longer\nmeasuring systemic inequality, or be conscious of racial categories in a way\nthat itself reifies race. We propose a third option. By preceding group\nfairness interventions with unsupervised learning to dynamically detect\npatterns of segregation, machine learning systems can mitigate the root cause\nof social disparities, social segregation and stratification, without further\nanchoring status categories of disadvantage.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 16:47:36 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Benthall", "Sebastian", ""], ["Haynes", "Bruce D.", ""]]}, {"id": "1811.11669", "submitter": "Michael Kl\\\"as", "authors": "Michael Kl\\\"as", "title": "Towards Identifying and Managing Sources of Uncertainty in AI and\n  Machine Learning Models - An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying and managing uncertainties that occur when data-driven models\nsuch as those provided by AI and machine learning methods are applied is\ncrucial. This whitepaper provides a brief motivation and first overview of the\nstate of the art in identifying and quantifying sources of uncertainty for\ndata-driven components as well as means for analyzing their impact.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 16:49:37 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Kl\u00e4s", "Michael", ""]]}, {"id": "1811.11674", "submitter": "Harry Clifford", "authors": "Luke R Harries, Suyi Zhang, Geoffroy Dubourg-Felonneau, James H R\n  Farmery, Jonathan Sinai, Belle Taylor, Nirmesh Patel, John W Cassidy, John\n  Shawe-Taylor, Harry W Clifford", "title": "Interlacing Personal and Reference Genomes for Machine Learning\n  Disease-Variant Detection", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/103", "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA sequencing to identify genetic variants is becoming increasingly valuable\nin clinical settings. Assessment of variants in such sequencing data is\ncommonly implemented through Bayesian heuristic algorithms. Machine learning\nhas shown great promise in improving on these variant calls, but the input for\nthese is still a standardized \"pile-up\" image, which is not always best suited.\nIn this paper, we present a novel method for generating images from DNA\nsequencing data, which interlaces the human reference genome with personalized\nsequencing output, to maximize usage of sequencing reads and improve machine\nlearning algorithm performance. We demonstrate the success of this in improving\nstandard germline variant calling. We also furthered this approach to include\nsomatic variant calling across tumor/normal data with Siamese networks. These\napproaches can be used in machine learning applications on sequencing data with\nthe hope of improving clinical outcomes, and are freely available for\nnoncommercial use at www.ccg.ai.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 15:38:29 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Harries", "Luke R", ""], ["Zhang", "Suyi", ""], ["Dubourg-Felonneau", "Geoffroy", ""], ["Farmery", "James H R", ""], ["Sinai", "Jonathan", ""], ["Taylor", "Belle", ""], ["Patel", "Nirmesh", ""], ["Cassidy", "John W", ""], ["Shawe-Taylor", "John", ""], ["Clifford", "Harry W", ""]]}, {"id": "1811.11682", "submitter": "David Rolnick", "authors": "David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy P. Lillicrap,\n  Greg Wayne", "title": "Experience Replay for Continual Learning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning is the problem of learning new tasks or knowledge while\nprotecting old knowledge and ideally generalizing from old experience to learn\nnew tasks faster. Neural networks trained by stochastic gradient descent often\ndegrade on old tasks when trained successively on new tasks with different data\ndistributions. This phenomenon, referred to as catastrophic forgetting, is\nconsidered a major hurdle to learning with non-stationary data or sequences of\nnew tasks, and prevents networks from continually accumulating knowledge and\nskills. We examine this issue in the context of reinforcement learning, in a\nsetting where an agent is exposed to tasks in a sequence. Unlike most other\nwork, we do not provide an explicit indication to the model of task boundaries,\nwhich is the most general circumstance for a learning agent exposed to\ncontinuous experience. While various methods to counteract catastrophic\nforgetting have recently been proposed, we explore a straightforward, general,\nand seemingly overlooked solution - that of using experience replay buffers for\nall past events - with a mixture of on- and off-policy learning, leveraging\nbehavioral cloning. We show that this strategy can still learn new tasks\nquickly yet can substantially reduce catastrophic forgetting in both Atari and\nDMLab domains, even matching the performance of methods that require task\nidentities. When buffer storage is constrained, we confirm that a simple\nmechanism for randomly discarding data allows a limited size buffer to perform\nalmost as well as an unbounded one.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:04:27 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 13:01:45 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Rolnick", "David", ""], ["Ahuja", "Arun", ""], ["Schwarz", "Jonathan", ""], ["Lillicrap", "Timothy P.", ""], ["Wayne", "Greg", ""]]}, {"id": "1811.11684", "submitter": "Qihong Lu", "authors": "Qihong Lu, Po-Hsuan Chen, Jonathan W. Pillow, Peter J. Ramadge,\n  Kenneth A. Norman, Uri Hasson", "title": "Shared Representational Geometry Across Neural Networks", "comments": "Integration of Deep Learning Theories workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different neural networks trained on the same dataset often learn similar\ninput-output mappings with very different weights. Is there some correspondence\nbetween these neural network solutions? For linear networks, it has been shown\nthat different instances of the same network architecture encode the same\nrepresentational similarity matrix, and their neural activity patterns are\nconnected by orthogonal transformations. However, it is unclear if this holds\nfor non-linear networks. Using a shared response model, we show that different\nneural networks encode the same input examples as different orthogonal\ntransformations of an underlying shared representation. We test this claim\nusing both standard convolutional neural networks and residual networks on\nCIFAR10 and CIFAR100.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:07:30 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 18:02:29 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Lu", "Qihong", ""], ["Chen", "Po-Hsuan", ""], ["Pillow", "Jonathan W.", ""], ["Ramadge", "Peter J.", ""], ["Norman", "Kenneth A.", ""], ["Hasson", "Uri", ""]]}, {"id": "1811.11705", "submitter": "Daniel L. Marino", "authors": "Daniel L. Marino, Chathurika S. Wickramasinghe, Milos Manic", "title": "An Adversarial Approach for Explainable AI in Intrusion Detection\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing popularity of modern machine learning techniques (e.g.\nDeep Neural Networks) in cyber-security applications, most of these models are\nperceived as a black-box for the user. Adversarial machine learning offers an\napproach to increase our understanding of these models. In this paper we\npresent an approach to generate explanations for incorrect classifications made\nby data-driven Intrusion Detection Systems (IDSs). An adversarial approach is\nused to find the minimum modifications (of the input features) required to\ncorrectly classify a given set of misclassified samples. The magnitude of such\nmodifications is used to visualize the most relevant features that explain the\nreason for the misclassification. The presented methodology generated\nsatisfactory explanations that describe the reasoning behind the\nmis-classifications, with descriptions that match expert knowledge. The\nadvantages of the presented methodology are: 1) applicable to any classifier\nwith defined gradients. 2) does not require any modification of the classifier\nmodel. 3) can be extended to perform further diagnosis (e.g. vulnerability\nassessment) and gain further understanding of the system. Experimental\nevaluation was conducted on the NSL-KDD99 benchmark dataset using Linear and\nMultilayer perceptron classifiers. The results are shown using intuitive\nvisualizations in order to improve the interpretability of the results.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:48:11 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Marino", "Daniel L.", ""], ["Wickramasinghe", "Chathurika S.", ""], ["Manic", "Milos", ""]]}, {"id": "1811.11714", "submitter": "Brooke Husic", "authors": "Martin K. Scherer, Brooke E. Husic, Moritz Hoffmann, Fabian Paul, Hao\n  Wu, Frank No\\'e", "title": "Variational Selection of Features for Molecular Kinetics", "comments": "13 pages, 8 figures", "journal-ref": "J. Chem. Phys. 2019, 150, 194108", "doi": "10.1063/1.5083040", "report-no": null, "categories": "physics.bio-ph physics.chem-ph q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modeling of atomistic biomolecular simulations using kinetic models such\nas Markov state models (MSMs) has had many notable algorithmic advances in\nrecent years. The variational principle has opened the door for a nearly fully\nautomated toolkit for selecting models that predict the long-time kinetics from\nmolecular dynamics simulations. However, one yet-unoptimized step of the\npipeline involves choosing the features, or collective variables, from which\nthe model should be constructed. In order to build intuitive models, these\ncollective variables are often sought to be interpretable and familiar\nfeatures, such as torsional angles or contact distances in a protein structure.\nHowever, previous approaches for evaluating the chosen features rely on\nconstructing a full MSM, which in turn requires additional hyperparameters to\nbe chosen, and hence leads to a computationally expensive framework. Here, we\npresent a method to optimize the feature choice directly, without requiring the\nconstruction of the final kinetic model. We demonstrate our rigorous\npreprocessing algorithm on a canonical set of twelve fast-folding protein\nsimulations, and show that our procedure leads to more efficient model\nselection.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 18:09:57 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 20:33:02 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Scherer", "Martin K.", ""], ["Husic", "Brooke E.", ""], ["Hoffmann", "Moritz", ""], ["Paul", "Fabian", ""], ["Wu", "Hao", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1811.11788", "submitter": "Steven McDonagh", "authors": "Steven McDonagh, Sarah Parisot, Fengwei Zhou, Xing Zhang, Ales\n  Leonardis, Zhenguo Li, Gregory Slabaugh", "title": "Formulating Camera-Adaptive Color Constancy as a Few-shot Meta-Learning\n  Problem", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital camera pipelines employ color constancy methods to estimate an\nunknown scene illuminant, in order to re-illuminate images as if they were\nacquired under an achromatic light source. Fully-supervised learning approaches\nexhibit state-of-the-art estimation accuracy with camera-specific labelled\ntraining imagery. Resulting models typically suffer from domain gaps and fail\nto generalise across imaging devices. In this work, we propose a new approach\nthat affords fast adaptation to previously unseen cameras, and robustness to\nchanges in capture device by leveraging annotated samples across different\ncameras and datasets. We present a general approach that utilizes the concept\nof color temperature to frame color constancy as a set of distinct, homogeneous\nfew-shot regression tasks, each associated with an intuitive physical meaning.\nWe integrate this novel formulation within a meta-learning framework, enabling\nfast generalisation to previously unseen cameras using only handfuls of camera\nspecific training samples. Consequently, the time spent for data collection and\nannotation substantially diminishes in practice whenever a new sensor is used.\nTo quantify this gain, we evaluate our pipeline on three publicly available\ndatasets comprising 12 different cameras and diverse scene content. Our\napproach delivers competitive results both qualitatively and quantitatively\nwhile requiring a small fraction of the camera-specific samples compared to\nstandard approaches.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 19:16:41 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 19:08:48 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["McDonagh", "Steven", ""], ["Parisot", "Sarah", ""], ["Zhou", "Fengwei", ""], ["Zhang", "Xing", ""], ["Leonardis", "Ales", ""], ["Li", "Zhenguo", ""], ["Slabaugh", "Gregory", ""]]}, {"id": "1811.11790", "submitter": "Miriam Shiffman", "authors": "Miriam Shiffman, William T. Stephenson, Geoffrey Schiebinger, Jonathan\n  Huggins, Trevor Campbell, Aviv Regev, Tamara Broderick", "title": "Reconstructing probabilistic trees of cellular differentiation from\n  single-cell RNA-seq data", "comments": "18 pages, 6 figures. Preliminary work appeared in the 2017 NeurIPS\n  workshops in Advances in Approximate Bayesian Inference\n  (http://approximateinference.org/2017) and Machine Learning for Computational\n  Biology (https://mlcb.github.io)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until recently, transcriptomics was limited to bulk RNA sequencing, obscuring\nthe underlying expression patterns of individual cells in favor of a global\naverage. Thanks to technological advances, we can now profile gene expression\nacross thousands or millions of individual cells in parallel. This new type of\ndata has led to the intriguing discovery that individual cell profiles can\nreflect the imprint of time or dynamic processes. However, synthesizing this\ninformation to reconstruct dynamic biological phenomena from data that are\nnoisy, heterogenous, and sparse---and from processes that may unfold\nasynchronously---poses a complex computational and statistical challenge. Here,\nwe develop a full generative model for probabilistically reconstructing trees\nof cellular differentiation from single-cell RNA-seq data. Specifically, we\nextend the framework of the classical Dirichlet diffusion tree to\nsimultaneously infer branch topology and latent cell states along continuous\ntrajectories over the full tree. In tandem, we construct a novel Markov chain\nMonte Carlo sampler that interleaves Metropolis-Hastings and message passing to\nleverage model structure for efficient inference. Finally, we demonstrate that\nthese techniques can recover latent trajectories from simulated single-cell\ntranscriptomes. While this work is motivated by cellular differentiation, we\nderive a tractable model that provides flexible densities for any data (coupled\nwith an appropriate noise model) that arise from continuous evolution along a\nlatent nonparametric tree.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 19:20:42 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Shiffman", "Miriam", ""], ["Stephenson", "William T.", ""], ["Schiebinger", "Geoffrey", ""], ["Huggins", "Jonathan", ""], ["Campbell", "Trevor", ""], ["Regev", "Aviv", ""], ["Broderick", "Tamara", ""]]}, {"id": "1811.11813", "submitter": "Juan B Gutierrez", "authors": "Saeid Safaei, Vahid Safaei, Solmazi Safaei, Zerotti Woods, Hamid R.\n  Arabnia and Juan B. Gutierrez", "title": "The SWAG Algorithm; a Mathematical Approach that Outperforms Traditional\n  Deep Learning. Theory and Implementation", "comments": "20 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of artificial neural networks (ANNs) is influenced by weight\ninitialization, the nature of activation functions, and their architecture.\nThere is a wide range of activation functions that are traditionally used to\ntrain a neural network, e.g. sigmoid, tanh, and Rectified Linear Unit (ReLU). A\nwidespread practice is to use the same type of activation function in all\nneurons in a given layer. In this manuscript, we present a type of neural\nnetwork in which the activation functions in every layer form a polynomial\nbasis; we name this method SWAG after the initials of the last names of the\nauthors. We tested SWAG on three complex highly non-linear functions as well as\nthe MNIST handwriting data set. SWAG outperforms and converges faster than the\nstate of the art performance in fully connected neural networks. Given the low\ncomputational complexity of SWAG, and the fact that it was capable of solving\nproblems current architectures cannot, it has the potential to change the way\nthat we approach deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 20:25:18 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Safaei", "Saeid", ""], ["Safaei", "Vahid", ""], ["Safaei", "Solmazi", ""], ["Woods", "Zerotti", ""], ["Arabnia", "Hamid R.", ""], ["Gutierrez", "Juan B.", ""]]}, {"id": "1811.11818", "submitter": "Sina Rashidian", "authors": "Sina Rashidian, Janos Hajagos, Richard Moffitt, Fusheng Wang, Xinyu\n  Dong, Kayley Abell-Hart, Kimberly Noel, Rajarsi Gupta, Mathew Tharakan, Veena\n  Lingam, Joel Saltz, Mary Saltz", "title": "Disease phenotyping using deep learning: A diabetes case study", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/38", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterization of a patient clinical phenotype is central to biomedical\ninformatics. ICD codes, assigned to inpatient encounters by coders, is\nimportant for population health and cohort discovery when clinical information\nis limited. While ICD codes are assigned to patients by professionals trained\nand certified in coding there is substantial variability in coding. We present\na methodology that uses deep learning methods to model coder decision making\nand that predicts ICD codes. Our approach predicts codes based on demographics,\nlab results, and medications, as well as codes from previous encounters. We are\nable to predict existing codes with high accuracy for all three of the test\ncases we investigated: diabetes, acute renal failure, and chronic kidney\ndisease. We employed a panel of clinicians, in a blinded manner, to assess\nground truth and compared the predictions of coders, model and clinicians. When\ndisparities between the model prediction and coder assigned codes were\nreviewed, our model outperformed coder assigned ICD codes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 20:37:04 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Rashidian", "Sina", ""], ["Hajagos", "Janos", ""], ["Moffitt", "Richard", ""], ["Wang", "Fusheng", ""], ["Dong", "Xinyu", ""], ["Abell-Hart", "Kayley", ""], ["Noel", "Kimberly", ""], ["Gupta", "Rajarsi", ""], ["Tharakan", "Mathew", ""], ["Lingam", "Veena", ""], ["Saltz", "Joel", ""], ["Saltz", "Mary", ""]]}, {"id": "1811.11829", "submitter": "Tianbao Yang", "authors": "Yi Xu, Qi Qi, Qihang Lin, Rong Jin, Tianbao Yang", "title": "Stochastic Optimization for DC Functions and Non-smooth Non-convex\n  Regularizers with Non-asymptotic Convergence", "comments": "In the revised version, we present some improved complexity results\n  for non-smooth and non-convex regularizers and for functions with known\n  H\\\"{o}lder continuity parameter $\\nu\\in(0,1]$ by a simple change of an\n  algorithmic parameter", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Difference of convex (DC) functions cover a broad family of non-convex and\npossibly non-smooth and non-differentiable functions, and have wide\napplications in machine learning and statistics. Although deterministic\nalgorithms for DC functions have been extensively studied, stochastic\noptimization that is more suitable for learning with big data remains\nunder-explored. In this paper, we propose new stochastic optimization\nalgorithms and study their first-order convergence theories for solving a broad\nfamily of DC functions. We improve the existing algorithms and theories of\nstochastic optimization for DC functions from both practical and theoretical\nperspectives. On the practical side, our algorithm is more user-friendly\nwithout requiring a large mini-batch size and more efficient by saving\nunnecessary computations. On the theoretical side, our convergence analysis\ndoes not necessarily require the involved functions to be smooth with Lipschitz\ncontinuous gradient. Instead, the convergence rate of the proposed stochastic\nalgorithm is automatically adaptive to the H\\\"{o}lder continuity of the\ngradient of one component function. Moreover, we extend the proposed stochastic\nalgorithms for DC functions to solve problems with a general non-convex\nnon-differentiable regularizer, which does not necessarily have a DC\ndecomposition but enjoys an efficient proximal mapping. To the best of our\nknowledge, this is the first work that gives the first non-asymptotic\nconvergence for solving non-convex optimization whose objective has a general\nnon-convex non-differentiable regularizer.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 20:58:21 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 16:14:09 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Xu", "Yi", ""], ["Qi", "Qi", ""], ["Lin", "Qihang", ""], ["Jin", "Rong", ""], ["Yang", "Tianbao", ""]]}, {"id": "1811.11880", "submitter": "Andrew McGough", "authors": "Daniel Justus, John Brennan, Stephen Bonner, Andrew Stephen McGough", "title": "Predicting the Computational Cost of Deep Learning Models", "comments": "Accepted for publication at the IEEE International Conference on Big\n  Data, (C) IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is rapidly becoming a go-to tool for many artificial\nintelligence problems due to its ability to outperform other approaches and\neven humans at many problems. Despite its popularity we are still unable to\naccurately predict the time it will take to train a deep learning network to\nsolve a given problem. This training time can be seen as the product of the\ntraining time per epoch and the number of epochs which need to be performed to\nreach the desired level of accuracy. Some work has been carried out to predict\nthe training time for an epoch -- most have been based around the assumption\nthat the training time is linearly related to the number of floating point\noperations required. However, this relationship is not true and becomes\nexacerbated in cases where other activities start to dominate the execution\ntime. Such as the time to load data from memory or loss of performance due to\nnon-optimal parallel execution. In this work we propose an alternative approach\nin which we train a deep learning network to predict the execution time for\nparts of a deep learning network. Timings for these individual parts can then\nbe combined to provide a prediction for the whole execution time. This has\nadvantages over linear approaches as it can model more complex scenarios. But,\nalso, it has the ability to predict execution times for scenarios unseen in the\ntraining data. Therefore, our approach can be used not only to infer the\nexecution time for a batch, or entire epoch, but it can also support making a\nwell-informed choice for the appropriate hardware and model.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 23:36:50 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Justus", "Daniel", ""], ["Brennan", "John", ""], ["Bonner", "Stephen", ""], ["McGough", "Andrew Stephen", ""]]}, {"id": "1811.11881", "submitter": "Karthik Abinav Sankararaman", "authors": "Nicole Immorlica and Karthik Abinav Sankararaman and Robert Schapire\n  and Aleksandrs Slivkins", "title": "Adversarial Bandits with Knapsacks", "comments": "Extended abstract appeared in FOCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Bandits with Knapsacks (henceforth, BwK), a general model for\nmulti-armed bandits under supply/budget constraints. In particular, a bandit\nalgorithm needs to solve a well-known knapsack problem: find an optimal packing\nof items into a limited-size knapsack. The BwK problem is a common\ngeneralization of numerous motivating examples, which range from dynamic\npricing to repeated auctions to dynamic ad allocation to network routing and\nscheduling. While the prior work on BwK focused on the stochastic version, we\npioneer the other extreme in which the outcomes can be chosen adversarially.\nThis is a considerably harder problem, compared to both the stochastic version\nand the \"classic\" adversarial bandits, in that regret minimization is no longer\nfeasible. Instead, the objective is to minimize the competitive ratio: the\nratio of the benchmark reward to the algorithm's reward.\n  We design an algorithm with competitive ratio O(log T) relative to the best\nfixed distribution over actions, where T is the time horizon; we also prove a\nmatching lower bound. The key conceptual contribution is a new perspective on\nthe stochastic version of the problem. We suggest a new algorithm for the\nstochastic version, which builds on the framework of regret minimization in\nrepeated games and admits a substantially simpler analysis compared to prior\nwork. We then analyze this algorithm for the adversarial version and use it as\na subroutine to solve the latter.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 23:43:11 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 02:13:00 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 17:12:51 GMT"}, {"version": "v4", "created": "Fri, 22 Mar 2019 22:17:04 GMT"}, {"version": "v5", "created": "Sun, 13 Oct 2019 05:01:32 GMT"}, {"version": "v6", "created": "Fri, 6 Nov 2020 19:18:05 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Immorlica", "Nicole", ""], ["Sankararaman", "Karthik Abinav", ""], ["Schapire", "Robert", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "1811.11891", "submitter": "Samson Koelle", "authors": "Samson Koelle, Hanyu Zhang, Marina Meila, Yu-Chia Chen", "title": "Manifold Coordinates with Physical Meaning", "comments": "Submitted to JMLR. Improved over v2 (added appendix). Improved over\n  v1 (revisions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold embedding algorithms map high-dimensional data down to coordinates\nin a much lower-dimensional space. One of the aims of dimension reduction is to\nfind intrinsic coordinates that describe the data manifold. The coordinates\nreturned by the embedding algorithm are abstract, and finding their physical or\ndomain-related meaning is not formalized and often left to domain experts. This\npaper studies the problem of recovering the meaning of the new low-dimensional\nrepresentation in an automatic, principled fashion. We propose a method to\nexplain embedding coordinates of a manifold as non-linear compositions of\nfunctions from a user-defined dictionary. We show that this problem can be set\nup as a sparse linear Group Lasso recovery problem, find sufficient recovery\nconditions, and demonstrate its effectiveness on data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 00:32:25 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 16:44:49 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 16:32:13 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Koelle", "Samson", ""], ["Zhang", "Hanyu", ""], ["Meila", "Marina", ""], ["Chen", "Yu-Chia", ""]]}, {"id": "1811.11896", "submitter": "Pai Liu", "authors": "Pai Liu, Jingwei Gan, and Rajan K. Chakrabarty", "title": "Variational Autoencoding the Lagrangian Trajectories of Particles in a\n  Combustion System", "comments": "2nd version: typo corrected, corresponding author changed 19 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep learning method to simulate the motion of particles\ntrapped in a chaotic recirculating flame. The Lagrangian trajectories of\nparticles, captured using a high-speed camera and subsequently reconstructed in\n3-dimensional space, were used to train a variational autoencoder (VAE) which\ncomprises multiple layers of convolutional neural networks. We show that the\ntrajectories, which are statistically representative of those determined in\nexperiments, can be generated using the VAE network. The performance of our\nmodel is evaluated with respect to the accuracy and generalization of the\noutputs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 00:44:58 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 03:18:25 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Liu", "Pai", ""], ["Gan", "Jingwei", ""], ["Chakrabarty", "Rajan K.", ""]]}, {"id": "1811.11922", "submitter": "Zhuoyi Yang", "authors": "Xiaozhou Wang, Zhuoyi Yang, Xi Chen, Weidong Liu", "title": "Distributed Inference for Linear Support Vector Machine", "comments": "50 pages, 11 figures", "journal-ref": "Journal of Machine Learning Research (JMLR), v20(113):1-41, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing size of modern data brings many new challenges to existing\nstatistical inference methodologies and theories, and calls for the development\nof distributed inferential approaches. This paper studies distributed inference\nfor linear support vector machine (SVM) for the binary classification task.\nDespite a vast literature on SVM, much less is known about the inferential\nproperties of SVM, especially in a distributed setting. In this paper, we\npropose a multi-round distributed linear-type (MDL) estimator for conducting\ninference for linear SVM. The proposed estimator is computationally efficient.\nIn particular, it only requires an initial SVM estimator and then successively\nrefines the estimator by solving simple weighted least squares problem.\nTheoretically, we establish the Bahadur representation of the estimator. Based\non the representation, the asymptotic normality is further derived, which shows\nthat the MDL estimator achieves the optimal statistical efficiency, i.e., the\nsame efficiency as the classical linear SVM applying to the entire data set in\na single machine setup. Moreover, our asymptotic result avoids the condition on\nthe number of machines or data batches, which is commonly assumed in\ndistributed estimation literature, and allows the case of diverging dimension.\nWe provide simulation studies to demonstrate the performance of the proposed\nMDL estimator.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 02:05:09 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 20:23:16 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Xiaozhou", ""], ["Yang", "Zhuoyi", ""], ["Chen", "Xi", ""], ["Liu", "Weidong", ""]]}, {"id": "1811.11925", "submitter": "Vaneet Aggarwal", "authors": "Mridul Agarwal and Vaneet Aggarwal", "title": "Regret Bounds for Stochastic Combinatorial Multi-Armed Bandits with\n  Linear Space Complexity", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems face the dilemma of choosing best $K$ out of $N$\noptions at a given time instant. This setup can be modelled as combinatorial\nbandit which chooses $K$ out of $N$ arms at each time, with an aim to achieve\nan efficient tradeoff between exploration and exploitation. This is the first\nwork for combinatorial bandit where the reward received can be a non-linear\nfunction of the chosen $K$ arms. The direct use of multi-armed bandit requires\nchoosing among $N$-choose-$K$ options making the state space large. In this\npaper, we present a novel algorithm which is computationally efficient and the\nstorage is linear in $N$. The proposed algorithm is a divide-and-conquer based\nstrategy, that we call CMAB-SM. Further, the proposed algorithm achieves a\nregret bound of $\\tilde O(K^\\frac{1}{2}N^\\frac{1}{3}T^\\frac{2}{3})$ for a time\nhorizon $T$, which is sub-linear in all parameters $T$, $N$, and $K$. The\nevaluation results on different reward functions and arm distribution functions\nshow significantly improved performance as compared to standard multi-armed\nbandit approach with $\\binom{N}{K}$ choices.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 02:12:37 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1811.11926", "submitter": "Dustin Tran", "authors": "Matthew D. Hoffman and Matthew J. Johnson and Dustin Tran", "title": "Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific\n  Language", "comments": "Appears in Neural Information Processing Systems, 2018. Code\n  available at https://github.com/google-research/autoconj", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deriving conditional and marginal distributions using conjugacy relationships\ncan be time consuming and error prone. In this paper, we propose a strategy for\nautomating such derivations. Unlike previous systems which focus on\nrelationships between pairs of random variables, our system (which we call\nAutoconj) operates directly on Python functions that compute log-joint\ndistribution functions. Autoconj provides support for conjugacy-exploiting\nalgorithms in any Python embedded PPL. This paves the way for accelerating\ndevelopment of novel inference algorithms and structure-exploiting modeling\nstrategies.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 02:13:37 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Hoffman", "Matthew D.", ""], ["Johnson", "Matthew J.", ""], ["Tran", "Dustin", ""]]}, {"id": "1811.11960", "submitter": "Gaurav Sheni", "authors": "Gaurav Sheni, Benjamin Schreck, Roy Wedge, James Max Kanter, Kalyan\n  Veeramachaneni", "title": "Prediction Factory: automated development and collaborative evaluation\n  of predictive models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a data science automation system called Prediction\nFactory. The system uses several key automation algorithms to enable data\nscientists to rapidly develop predictive models and share them with domain\nexperts. To assess the system's impact, we implemented 3 different interfaces\nfor creating predictive modeling projects: baseline automation, full\nautomation, and optional automation. With a dataset of online grocery shopper\nbehaviors, we divided data scientists among the interfaces to specify\nprediction problems, learn and evaluate models, and write a report for domain\nexperts to judge whether or not to fund to continue working on. In total, 22\ndata scientists created 94 reports that were judged 296 times by 26 experts. In\na head-to-head trial, reports generated utilizing full data science automation\ninterface reports were funded 57.5% of the time, while the ones that used\nbaseline automation were only funded 42.5% of the time. An intermediate\ninterface which supports optional automation generated reports were funded\n58.6% more often compared to the baseline. Full automation and optional\nautomation reports were funded about equally when put head-to-head. These\nresults demonstrate that Prediction Factory has implemented a critical amount\nof automation to augment the role of data scientists and improve business\noutcomes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 04:34:48 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Sheni", "Gaurav", ""], ["Schreck", "Benjamin", ""], ["Wedge", "Roy", ""], ["Kanter", "James Max", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1811.11971", "submitter": "Shujian Yu", "authors": "Shujian Yu and Jose C. Principe", "title": "Simple stopping criteria for information theoretic feature selection", "comments": "Paper published in the journal of Entropy", "journal-ref": "Entropy 2019, 21(1), 99", "doi": "10.3390/e21010099", "report-no": null, "categories": "cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection aims to select the smallest feature subset that yields the\nminimum generalization error. In the rich literature in feature selection,\ninformation theory-based approaches seek a subset of features such that the\nmutual information between the selected features and the class labels is\nmaximized. Despite the simplicity of this objective, there still remain several\nopen problems in optimization. These include, for example, the automatic\ndetermination of the optimal subset size (i.e., the number of features) or a\nstopping criterion if the greedy searching strategy is adopted. In this paper,\nwe suggest two stopping criteria by just monitoring the conditional mutual\ninformation (CMI) among groups of variables. Using the recently developed\nmultivariate matrix-based Renyi's \\alpha-entropy functional, which can be\ndirectly estimated from data samples, we showed that the CMI among groups of\nvariables can be easily computed without any decomposition or approximation,\nhence making our criteria easy to implement and seamlessly integrated into any\nexisting information theoretic feature selection methods with a greedy search\nstrategy.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 05:24:28 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 10:38:02 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Yu", "Shujian", ""], ["Principe", "Jose C.", ""]]}, {"id": "1811.11987", "submitter": "Laurent Bou\\'e", "authors": "Laurent Bou\\'e", "title": "Deep learning for pedestrians: backpropagation in CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this document is to provide a pedagogical introduction to the\nmain concepts underpinning the training of deep neural networks using gradient\ndescent; a process known as backpropagation. Although we focus on a very\ninfluential class of architectures called \"convolutional neural networks\"\n(CNNs) the approach is generic and useful to the machine learning community as\na whole. Motivated by the observation that derivations of backpropagation are\noften obscured by clumsy index-heavy narratives that appear somewhat\nmathemagical, we aim to offer a conceptually clear, vectorized description that\narticulates well the higher level logic. Following the principle of \"writing is\nnature's way of letting you know how sloppy your thinking is\", we try to make\nthe calculations meticulous, self-contained and yet as intuitive as possible.\nTaking nothing for granted, ample illustrations serve as visual guides and an\nextensive bibliography is provided for further explorations.\n  (For the sake of clarity, long mathematical derivations and visualizations\nhave been broken up into short \"summarized views\" and longer \"detailed views\"\nencoded into the PDF as optional content groups. Some figures contain\nanimations designed to illustrate important concepts in a more engaging style.\nFor these reasons, we advise to download the document locally and open it using\nAdobe Acrobat Reader. Other viewers were not tested and may not render the\ndetailed views, animations correctly.)\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 07:00:09 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Bou\u00e9", "Laurent", ""]]}, {"id": "1811.11989", "submitter": "Quanquan Gu", "authors": "Dongruo Zhou, Pan Xu, Quanquan Gu", "title": "Sample Efficient Stochastic Variance-Reduced Cubic Regularization Method", "comments": "24 pages, 2 figures, 1 table. The first version of this paper was\n  submitted to UAI 2018 on March 9, 2018. This is the second version with\n  improved presentation and additional baselines in the experiments, and was\n  submitted to NeurIPS 2018 on May 18, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a sample efficient stochastic variance-reduced cubic\nregularization (Lite-SVRC) algorithm for finding the local minimum efficiently\nin nonconvex optimization. The proposed algorithm achieves a lower sample\ncomplexity of Hessian matrix computation than existing cubic regularization\nbased methods. At the heart of our analysis is the choice of a constant batch\nsize of Hessian matrix computation at each iteration and the stochastic\nvariance reduction techniques. In detail, for a nonconvex function with $n$\ncomponent functions, Lite-SVRC converges to the local minimum within\n$\\tilde{O}(n+n^{2/3}/\\epsilon^{3/2})$ Hessian sample complexity, which is\nfaster than all existing cubic regularization based methods. Numerical\nexperiments with different nonconvex optimization problems conducted on real\ndatasets validate our theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 07:10:44 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Zhou", "Dongruo", ""], ["Xu", "Pan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1811.12019", "submitter": "Kazuki Osawa", "authors": "Kazuki Osawa, Yohei Tsuji, Yuichiro Ueno, Akira Naruse, Rio Yokota,\n  and Satoshi Matsuoka", "title": "Large-Scale Distributed Second-Order Optimization Using\n  Kronecker-Factored Approximate Curvature for Deep Convolutional Neural\n  Networks", "comments": "10 pages, 7 figures. Accepted at CVPR 2019, Long Beach, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale distributed training of deep neural networks suffer from the\ngeneralization gap caused by the increase in the effective mini-batch size.\nPrevious approaches try to solve this problem by varying the learning rate and\nbatch size over epochs and layers, or some ad hoc modification of the batch\nnormalization. We propose an alternative approach using a second-order\noptimization method that shows similar generalization capability to first-order\nmethods, but converges faster and can handle larger mini-batches. To test our\nmethod on a benchmark where highly optimized first-order methods are available\nas references, we train ResNet-50 on ImageNet. We converged to 75% Top-1\nvalidation accuracy in 35 epochs for mini-batch sizes under 16,384, and\nachieved 75% even with a mini-batch size of 131,072, which took only 978\niterations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 08:52:04 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 12:46:17 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 08:45:32 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 08:20:19 GMT"}, {"version": "v5", "created": "Sat, 30 Mar 2019 04:24:57 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Osawa", "Kazuki", ""], ["Tsuji", "Yohei", ""], ["Ueno", "Yuichiro", ""], ["Naruse", "Akira", ""], ["Yokota", "Rio", ""], ["Matsuoka", "Satoshi", ""]]}, {"id": "1811.12044", "submitter": "David Charte", "authors": "David Charte (1) and Francisco Charte (2) and Salvador Garc\\'ia (1)\n  and Francisco Herrera (1) ((1) Universidad de Granada, (2) Universidad de\n  Ja\\'en)", "title": "A snapshot on nonstandard supervised learning problems: taxonomy,\n  relationships and methods", "comments": null, "journal-ref": "Charte, D., Charte, F., Garc\\'ia, S. et al. Prog Artif Intell\n  (2018)", "doi": "10.1007/s13748-018-00167-7", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a field which studies how machines can alter and adapt\ntheir behavior, improving their actions according to the information they are\ngiven. This field is subdivided into multiple areas, among which the best known\nare supervised learning (e.g. classification and regression) and unsupervised\nlearning (e.g. clustering and association rules).\n  Within supervised learning, most studies and research are focused on well\nknown standard tasks, such as binary classification, multiclass classification\nand regression with one dependent variable. However, there are many other less\nknown problems. These are what we generically call nonstandard supervised\nlearning problems. The literature about them is much more sparse, and each\nstudy is directed to a specific task. Therefore, the definitions, relations and\napplications of this kind of learners are hard to find.\n  The goal of this paper is to provide the reader with a broad view on the\ndistinct variations of nonstandard supervised problems. A comprehensive\ntaxonomy summarizing their traits is proposed. A review of the common\napproaches followed to accomplish them and their main applications is provided\nas well.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 10:03:06 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Charte", "David", ""], ["Charte", "Francisco", ""], ["Garc\u00eda", "Salvador", ""], ["Herrera", "Francisco", ""]]}, {"id": "1811.12050", "submitter": "Daniel J. Trosten", "authors": "Daniel J. Trosten, Andreas S. Strauman, Michael Kampffmeyer, Robert\n  Jenssen", "title": "Recurrent Deep Divergence-based Clustering for simultaneous feature\n  learning and clustering of variable length time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of clustering unlabeled time series and sequences entails a\nparticular set of challenges, namely to adequately model temporal relations and\nvariable sequence lengths. If these challenges are not properly handled, the\nresulting clusters might be of suboptimal quality. As a key solution, we\npresent a joint clustering and feature learning framework for time series based\non deep learning. For a given set of time series, we train a recurrent network\nto represent, or embed, each time series in a vector space such that a\ndivergence-based clustering loss function can discover the underlying cluster\nstructure in an end-to-end manner. Unlike previous approaches, our model\ninherently handles multivariate time series of variable lengths and does not\nrequire specification of a distance-measure in the input space. On a diverse\nset of benchmark datasets we illustrate that our proposed Recurrent Deep\nDivergence-based Clustering approach outperforms, or performs comparable to,\nprevious approaches.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 10:23:01 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 12:50:43 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Trosten", "Daniel J.", ""], ["Strauman", "Andreas S.", ""], ["Kampffmeyer", "Michael", ""], ["Jenssen", "Robert", ""]]}, {"id": "1811.12064", "submitter": "David Saltiel", "authors": "David Saltiel, Eric Benhamou", "title": "Feature selection with optimal coordinate ascent (OCA)", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, Feature Selection (FS) is a major part of efficient\nalgorithm. It fuels the algorithm and is the starting block for our prediction.\nIn this paper, we present a new method, called Optimal Coordinate Ascent (OCA)\nthat allows us selecting features among block and individual features. OCA\nrelies on coordinate ascent to find an optimal solution for gradient boosting\nmethods score (number of correctly classified samples). OCA takes into account\nthe notion of dependencies between variables forming blocks in our\noptimization. The coordinate ascent optimization solves the issue of the NP\nhard original problem where the number of combinations rapidly explode making a\ngrid search unfeasible. It reduces considerably the number of iterations\nchanging this NP hard problem into a polynomial search one. OCA brings\nsubstantial differences and improvements compared to previous coordinate ascent\nfeature selection method: we group variables into block and individual\nvariables instead of a binary selection. Our initial guess is based on the\nk-best group variables making our initial point more robust. We also introduced\nnew stopping criteria making our optimization faster. We compare these two\nmethods on our data set. We found that our method outperforms the initial one.\nWe also compare our method to the Recursive Feature Elimination (RFE) method\nand find that OCA leads to the minimum feature set with the highest score. This\nis a nice byproduct of our method as it provides empirically the most compact\ndata set with optimal performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 11:04:44 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 07:51:06 GMT"}, {"version": "v3", "created": "Mon, 3 Dec 2018 08:25:53 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Saltiel", "David", ""], ["Benhamou", "Eric", ""]]}, {"id": "1811.12081", "submitter": "Fernando Fernandes Neto", "authors": "Fernando Fernandes Neto, Alemayehu Admasu Solomon, Rodrigo de Losso,\n  Claudio Garcia, Pedro Delano Cavalcanti", "title": "Deep Haar Scattering Networks in Pattern Recognition: A promising\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to discuss the use of Haar scattering networks,\nwhich is a very simple architecture that naturally supports a large number of\nstacked layers, yet with very few parameters, in a relatively broad set of\npattern recognition problems, including regression and classification tasks.\nThis architecture, basically, consists of stacking convolutional filters, that\ncan be thought as a generalization of Haar wavelets, followed by non-linear\noperators which aim to extract symmetries and invariances that are later fed in\na classification/regression algorithm. We show that good results can be\nobtained with the proposed method for both kind of tasks. We have outperformed\nthe best available algorithms in 4 out of 18 important data classification\nproblems, and have obtained a more robust performance than ARIMA and ETS time\nseries methods in regression problems for data with strong periodicities.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 11:50:58 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Neto", "Fernando Fernandes", ""], ["Solomon", "Alemayehu Admasu", ""], ["de Losso", "Rodrigo", ""], ["Garcia", "Claudio", ""], ["Cavalcanti", "Pedro Delano", ""]]}, {"id": "1811.12142", "submitter": "Xu Li", "authors": "Chunlin Gong, Xu Li, Hua Su, Jinlei Guo, Liangxian Gu", "title": "Global optimization of expensive black-box models based on asynchronous\n  hybrid-criterion with interval reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, a new sequential surrogate-based optimization (SSBO) algorithm\nis developed, which aims to improve the global search ability and local search\nefficiency for the global optimization of expensive black-box models. The\nproposed method involves three basic sub-criteria to infill new samples\nasynchronously to balance the global exploration and local exploitation. First,\nto capture the promising possible global optimal region, searching for the\nglobal optimum with genetic algorithm (GA) based on the current surrogate\nmodels of the objective and constraint functions. Second, to infill samples in\nthe region with sparse samples to improve the global accuracy of the surrogate\nmodels, a grid searching with Latin hypercube sampling (LHS) with the current\nsurrogate model is adopted to explore the sample space. Third, to accelerate\nthe local searching efficiency, searching for a local optimum with sequential\nquadratic programming (SQP) based on the local surrogate models in the reduced\ninterval, which involves some samples near the current optimum. When the new\nsample is too close to the existing ones, the new sample should be abandoned,\ndue to the poor additional information. According to the three sub-criteria,\nthe new samples are placed in the regions which have not been fully explored\nand includes the possible global optimum point. When a possible global optimum\npoint is found, the local searching sub-criterion captures the local optimum\naround it rapidly. Numerical and engineering examples are used to verify the\nefficiency of the proposed method. The statistical results show that the\nproposed method has good global searching ability and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 13:50:47 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Gong", "Chunlin", ""], ["Li", "Xu", ""], ["Su", "Hua", ""], ["Guo", "Jinlei", ""], ["Gu", "Liangxian", ""]]}, {"id": "1811.12143", "submitter": "Imanol Schlag", "authors": "Imanol Schlag, J\\\"urgen Schmidhuber", "title": "Learning to Reason with Third-Order Tensor Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We combine Recurrent Neural Networks with Tensor Product Representations to\nlearn combinatorial representations of sequential data. This improves symbolic\ninterpretation and systematic generalisation. Our architecture is trained\nend-to-end through gradient descent on a variety of simple natural language\nreasoning tasks, significantly outperforming the latest state-of-the-art models\nin single-task and all-tasks settings. We also augment a subset of the data\nsuch that training and test data exhibit large systematic differences and show\nthat our approach generalises better than the previous state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 13:50:58 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 10:36:24 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Schlag", "Imanol", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1811.12156", "submitter": "Jayaraman J. Thiagarajan", "authors": "Huan Song and Jayaraman J. Thiagarajan", "title": "Improved Deep Embeddings for Inferencing with Multi-Layered Networks", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferencing with network data necessitates the mapping of its nodes into a\nvector space, where the relationships are preserved. However, with\nmulti-layered networks, where multiple types of relationships exist for the\nsame set of nodes, it is crucial to exploit the information shared between\nlayers, in addition to the distinct aspects of each layer. In this paper, we\npropose a novel approach that first obtains node embeddings in all layers\njointly via DeepWalk on a \\textit{supra} graph, which allows interactions\nbetween layers, and then fine-tunes the embeddings to encourage cohesive\nstructure in the latent space. With empirical studies in node classification,\nlink prediction and multi-layered community detection, we show that the\nproposed approach outperforms existing single- and multi-layered network\nembedding algorithms on several benchmarks. In addition to effectively scaling\nto a large number of layers (tested up to $37$), our approach consistently\nproduces highly modular community structure, even when compared to methods that\ndirectly optimize for the modularity function.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:07:45 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 22:40:17 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Song", "Huan", ""], ["Thiagarajan", "Jayaraman J.", ""]]}, {"id": "1811.12159", "submitter": "Remy Cazabet", "authors": "Aakash Sinha, R\\'emy Cazabet (NII), R\\'emi Vaudaine (LOMA)", "title": "Systematic Biases in Link Prediction: comparing heuristic and graph\n  embedding based methods", "comments": null, "journal-ref": "Complex networks 2018 - The 7th International Conference on\n  Complex Networks and Their Applications, 2018, Cambridge, United Kingdom", "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is a popular research topic in network analysis. In the last\nfew years, new techniques based on graph embedding have emerged as a powerful\nalternative to heuristics. In this article, we study the problem of systematic\nbiases in the prediction, and show that some methods based on graph embedding\noffer less biased results than those based on heuristics, despite reaching\nlower scores according to usual quality scores. We discuss the relevance of\nthis finding in the context of the filter bubble problem and the algorithmic\nfairness of recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 09:32:39 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Sinha", "Aakash", "", "NII"], ["Cazabet", "R\u00e9my", "", "NII"], ["Vaudaine", "R\u00e9mi", "", "LOMA"]]}, {"id": "1811.12160", "submitter": "Jianguo Chen", "authors": "Jianguo Chen, Kenli Li, Kashif Bilal, Ahmed A. Metwally, Keqin Li,\n  Philip S. Yu", "title": "Parallel Protein Community Detection in Large-scale PPI Networks Based\n  on Multi-source Learning", "comments": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,\n  2018", "journal-ref": null, "doi": "10.1109/TCBB.2018.2868088", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein interactions constitute the fundamental building block of almost\nevery life activity. Identifying protein communities from Protein-Protein\nInteraction (PPI) networks is essential to understand the principles of\ncellular organization and explore the causes of various diseases. It is\ncritical to integrate multiple data resources to identify reliable protein\ncommunities that have biological significance and improve the performance of\ncommunity detection methods for large-scale PPI networks. In this paper, we\npropose a Multi-source Learning based Protein Community Detection (MLPCD)\nalgorithm by integrating Gene Expression Data (GED) and a parallel solution of\nMLPCD using cloud computing technology. To effectively discover the biological\nfunctions of proteins that participating in different cellular processes, GED\nunder different conditions is integrated with the original PPI network to\nreconstruct a Weighted-PPI (WPPI) network. To flexibly identify protein\ncommunities of different scales, we define community modularity and functional\ncohesion measurements and detect protein communities from WPPI using an\nagglomerative method. In addition, we respectively compare the detected\ncommunities with known protein complexes and evaluate the functional enrichment\nof protein function modules using Gene Ontology annotations. Moreover, we\nimplement a parallel version of the MLPCD algorithm on the Apache Spark\nplatform to enhance the performance of the algorithm for large-scale realistic\nPPI networks. Extensive experimental results indicate the superiority and\nnotable advantages of the MLPCD algorithm over the relevant algorithms in terms\nof accuracy and performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:43:50 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Bilal", "Kashif", ""], ["Metwally", "Ahmed A.", ""], ["Li", "Keqin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1811.12162", "submitter": "Jonathan Eskreis-Winkler", "authors": "Jonathan Eskreis-Winkler and Risi Kondor", "title": "Effective Resistance-based Germination of Seed Sets for Community\n  Detection", "comments": "10 pages, 4 figures, currently under review for conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is, at its core, an attempt to attach an interpretable\nfunction to an otherwise indecipherable form. The importance of labeling\ncommunities has obvious implications for identifying clusters in social\nnetworks, but it has a number of equally relevant applications in product\nrecommendations, biological systems, and many forms of classification. The\nlocal variety of community detection starts with a small set of labeled seed\nnodes, and aims to estimate the community containing these nodes. One of the\nmost ubiquitous methods - due to its simplicity and efficiency - is\npersonalized PageRank. The most obvious bottleneck for deploying this form of\nPageRank successfully is the quality of the seeds. We introduce a \"germination\"\nstage for these seeds, where an effective resistance-based approach is used to\nincrease the quality and number of seeds from which a community is detected. By\nbreaking seed set expansion into a two-step process, we aim to utilize two\ndistinct random walk-based approaches in the regimes in which they excel. In\nsynthetic and real network data, a simple, greedy algorithm which minimizes the\neffective resistance diameter combined with PageRank achieves clear\nimprovements in precision and recall over a standalone PageRank procedure.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 13:32:22 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Eskreis-Winkler", "Jonathan", ""], ["Kondor", "Risi", ""]]}, {"id": "1811.12166", "submitter": "Ryohei Hisano", "authors": "Ryohei Hisano, Didier Sornette and Takayuki Mizuno", "title": "Prediction of ESG Compliance using a Heterogeneous Information Network", "comments": null, "journal-ref": "J Big Data 7, 22 (2020)", "doi": "10.1186/s40537-020-00295-9", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negative screening is one method to avoid interactions with inappropriate\nentities. For example, financial institutions keep investment exclusion lists\nof inappropriate firms that have environmental, social, and government (ESG)\nproblems. They create their investment exclusion lists by gathering information\nfrom various news sources to keep their portfolios profitable as well as green.\nInternational organizations also maintain smart sanctions lists that are used\nto prohibit trade with entities that are involved in illegal activities. In the\npresent paper, we focus on the prediction of investment exclusion lists in the\nfinance domain. We construct a vast heterogeneous information network that\ncovers the necessary information surrounding each firm, which is assembled\nusing seven professionally curated datasets and two open datasets, which\nresults in approximately 50 million nodes and 400 million edges in total.\nExploiting these vast datasets and motivated by how professional investigators\nand journalists undertake their daily investigations, we propose a model that\ncan learn to predict firms that are more likely to be added to an investment\nexclusion list in the near future. Our approach is tested using the negative\nnews investment exclusion list data of more than 35,000 firms worldwide from\nJanuary 2012 to May 2018. Comparing with the state-of-the-art methods with and\nwithout using the network, we show that the predictive accuracy is\nsubstantially improved when using the vast information stored in the\nheterogeneous information network. This work suggests new ways to consolidate\nthe diffuse information contained in big data to monitor dominant firms on a\nglobal scale for better risk management and more socially responsible\ninvestment.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 16:54:18 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 04:51:16 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 12:33:08 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Hisano", "Ryohei", ""], ["Sornette", "Didier", ""], ["Mizuno", "Takayuki", ""]]}, {"id": "1811.12169", "submitter": "Zhou Yang", "authors": "Zhou Yang, Long Nguyen and Fang Jin", "title": "Predicting Opioid Relapse Using Social Media Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opioid addiction is a severe public health threat in the U.S, causing massive\ndeaths and many social problems. Accurate relapse prediction is of practical\nimportance for recovering patients since relapse prediction promotes timely\nrelapse preventions that help patients stay clean. In this paper, we introduce\na Generative Adversarial Networks (GAN) model to predict the addiction relapses\nbased on sentiment images and social influences. Experimental results on real\nsocial media data from Reddit.com demonstrate that the GAN model delivers a\nbetter performance than comparable alternative techniques. The sentiment images\ngenerated by the model show that relapse is closely connected with two emotions\n`joy' and `negative'. This work is one of the first attempts to predict\nrelapses using massive social media data and generative adversarial nets. The\nproposed method, combined with knowledge of social media mining, has the\npotential to revolutionize the practice of opioid addiction prevention and\ntreatment.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 00:20:49 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Yang", "Zhou", ""], ["Nguyen", "Long", ""], ["Jin", "Fang", ""]]}, {"id": "1811.12181", "submitter": "Irene Li", "authors": "Irene Li, Alexander R. Fabbri, Robert R. Tung and Dragomir R. Radev", "title": "What Should I Learn First: Introducing LectureBank for NLP Education and\n  Prerequisite Chain Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the rising popularity of Natural Language\nProcessing (NLP) and related fields such as Artificial Intelligence (AI) and\nMachine Learning (ML). Many online courses and resources are available even for\nthose without a strong background in the field. Often the student is curious\nabout a specific topic but does not quite know where to begin studying. To\nanswer the question of \"what should one learn first,\" we apply an\nembedding-based method to learn prerequisite relations for course concepts in\nthe domain of NLP. We introduce LectureBank, a dataset containing 1,352 English\nlecture files collected from university courses which are each classified\naccording to an existing taxonomy as well as 208 manually-labeled prerequisite\nrelation topics, which is publicly available. The dataset will be useful for\neducational purposes such as lecture preparation and organization as well as\napplications such as reading list generation. Additionally, we experiment with\nneural graph-based networks and non-neural classifiers to learn these\nprerequisite relations from our dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 21:09:20 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Li", "Irene", ""], ["Fabbri", "Alexander R.", ""], ["Tung", "Robert R.", ""], ["Radev", "Dragomir R.", ""]]}, {"id": "1811.12182", "submitter": "Vahid Pourahmadi Dr.", "authors": "Peyman Yazdanian and Vahid Pourahmadi", "title": "DeepPos: Deep Supervised Autoencoder Network for CSI Based Indoor\n  Localization", "comments": "10 pages, 15 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread mobile devices facilitated the emergence of many new\napplications and services. Among them are location-based services (LBS) that\nprovide services based on user's location. Several techniques have been\npresented to enable LBS even in indoor environments where Global Positioning\nSystem (GPS) has low localization accuracy. These methods use some environment\nmeasurements (like Channel State Information (CSI) or Received Signal Strength\n(RSS)) for user localization. In this paper, we will use CSI and a novel deep\nlearning algorithm to design a robust and efficient system for indoor\nlocalization. More precisely, we use supervised autoencoder (SAE) to model the\nenvironment using the data collected during the training phase. Then, during\nthe testing phase, we use the trained model and estimate the coordinates of the\nunknown point by checking different possible labels. Unlike the previous\nfingerprinting approaches, in this work, we do not store the {CSI/RSS} of\nfingerprints and instead we model the environment only with a single SAE. The\nperformance of the proposed scheme is then evaluated in two indoor environments\nand compared with that of similar approaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 20:30:36 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Yazdanian", "Peyman", ""], ["Pourahmadi", "Vahid", ""]]}, {"id": "1811.12188", "submitter": "Tim Pearce", "authors": "Tim Pearce, Mohamed Zaki, Andy Neely", "title": "Bayesian Neural Network Ensembles", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.05546", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of neural networks (NNs) have long been used to estimate predictive\nuncertainty; a small number of NNs are trained from different initialisations\nand sometimes on differing versions of the dataset. The variance of the\nensemble's predictions is interpreted as its epistemic uncertainty. The appeal\nof ensembling stems from being a collection of regular NNs - this makes them\nboth scalable and easily implementable. They have achieved strong empirical\nresults in recent years, often presented as a practical alternative to more\ncostly Bayesian NNs (BNNs). The departure from Bayesian methodology is of\nconcern since the Bayesian framework provides a principled, widely-accepted\napproach to handling uncertainty. In this extended abstract we derive and\nimplement a modified NN ensembling scheme, which provides a consistent\nestimator of the Bayesian posterior in wide NNs - regularising parameters about\nvalues drawn from a prior distribution.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:16:09 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Pearce", "Tim", ""], ["Zaki", "Mohamed", ""], ["Neely", "Andy", ""]]}, {"id": "1811.12194", "submitter": "Antonio H. Ribeiro", "authors": "Ant\\^onio H. Ribeiro, Manoel Horta Ribeiro, Gabriela Paix\\~ao, Derick\n  Oliveira, Paulo R. Gomes, J\\'essica A. Canazart, Milton Pifano, Wagner Meira\n  Jr., Thomas B. Sch\\\"on, Antonio Luiz Ribeiro", "title": "Automatic Diagnosis of Short-Duration 12-Lead ECG using a Deep\n  Convolutional Network", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/82", "categories": "eess.SP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model for predicting electrocardiogram (ECG) abnormalities in\nshort-duration 12-lead ECG signals which outperformed medical doctors on the\n4th year of their cardiology residency. Such exams can provide a full\nevaluation of heart activity and have not been studied in previous end-to-end\nmachine learning papers. Using the database of a large telehealth network, we\nbuilt a novel dataset with more than 2 million ECG tracings, orders of\nmagnitude larger than those used in previous studies. Moreover, our dataset is\nmore realistic, as it consist of 12-lead ECGs recorded during standard\nin-clinics exams. Using this data, we trained a residual neural network with 9\nconvolutional layers to map 7 to 10 second ECG signals to 6 classes of ECG\nabnormalities. Future work should extend these results to cover a large range\nof ECG abnormalities, which could improve the accessibility of this diagnostic\ntool and avoid wrong diagnosis from medical doctors.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 07:39:10 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 07:18:36 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Ribeiro", "Ant\u00f4nio H.", ""], ["Ribeiro", "Manoel Horta", ""], ["Paix\u00e3o", "Gabriela", ""], ["Oliveira", "Derick", ""], ["Gomes", "Paulo R.", ""], ["Canazart", "J\u00e9ssica A.", ""], ["Pifano", "Milton", ""], ["Meira", "Wagner", "Jr."], ["Sch\u00f6n", "Thomas B.", ""], ["Ribeiro", "Antonio Luiz", ""]]}, {"id": "1811.12210", "submitter": "Arpit Arun Dhobale", "authors": "Kathleen Campbell Garwood, Ph.D., Arpit Arun Dhobale", "title": "A comparison of cluster algorithms as applied to unsupervised surveys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When considering answering important questions with data, unsupervised data\noffers extensive insight opportunity and unique challenges. This study\nconsiders student survey data with a specific goal of clustering students into\nlike groups with underlying concept of identifying different poverty levels.\nFuzzy logic is considered during the data cleaning and organizing phase helping\nto create a logical dependent variable for analysis comparison. Using multiple\ndata reduction techniques, the survey was reduced and cleaned. Finally,\nmultiple clustering techniques (k-means, k-modes, and hierarchical clustering)\nare applied and compared. Though each method has strengths, the goal was to\nidentify which was most viable when applied to survey data and specifically\nwhen trying to identify the most impoverished students.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 06:48:55 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 05:23:48 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Garwood", "Kathleen Campbell", ""], ["D.", "Ph.", ""], ["Dhobale", "Arpit Arun", ""]]}, {"id": "1811.12223", "submitter": "Wenfu Wang", "authors": "Wenfu Wang, Weijie Yang, An Chen, Zhijie Pan", "title": "A Scoring Method for Driving Safety Credit Using Trajectory Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban traffic systems worldwide are suffering from severe traffic safety\nproblems. Traffic safety is affected by many complex factors, and heavily\nrelated to all drivers' behaviors involved in traffic system. Drivers with\naggressive driving behaviors increase the risk of traffic accidents. In order\nto manage the safety level of traffic system, we propose Driving Safety Credit\ninspired by credit score in financial security field, and design a scoring\nmethod using trajectory data and violation records. First, we extract driving\nhabits, aggressive driving behaviors and traffic violation behaviors from\ndriver's trajectories and traffic violation records. Next, we train a\nclassification model to filtered out irrelevant features. And at last, we score\neach driver with selected features. We verify our proposed scoring method using\n40 days of traffic simulation, and proves the effectiveness of our scoring\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 11:54:20 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Wang", "Wenfu", ""], ["Yang", "Weijie", ""], ["Chen", "An", ""], ["Pan", "Zhijie", ""]]}, {"id": "1811.12227", "submitter": "Wen Wang", "authors": "Wen Wang, Rema Padman, Nirav Shah", "title": "Early Stratification of Patients at Risk for Postoperative Complications\n  after Elective Colectomy", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/55", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stratifying patients at risk for postoperative complications may facilitate\ntimely and accurate workups and reduce the burden of adverse events on patients\nand the health system. Currently, a widely-used surgical risk calculator\ncreated by the American College of Surgeons, NSQIP, uses 21 preoperative\ncovariates to assess risk of postoperative complications, but lacks dynamic,\nreal-time capabilities to accommodate postoperative information. We propose a\nnew Hidden Markov Model sequence classifier for analyzing patients'\npostoperative temperature sequences that incorporates their time-invariant\ncharacteristics in both transition probability and initial state probability in\norder to develop a postoperative \"real-time\" complication detector. Data from\nelective Colectomy surgery indicate that our method has improved classification\nperformance compared to 8 other machine learning classifiers when using the\nfull temperature sequence associated with the patients' length of stay.\nAdditionally, within 44 hours after surgery, the performance of the model is\nclose to that of full-length temperature sequence.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:00:30 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Wang", "Wen", ""], ["Padman", "Rema", ""], ["Shah", "Nirav", ""]]}, {"id": "1811.12231", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge,\n  Felix A. Wichmann, Wieland Brendel", "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias\n  improves accuracy and robustness", "comments": "Accepted at ICLR 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are commonly thought to recognise\nobjects by learning increasingly complex representations of object shapes. Some\nrecent studies suggest a more important role of image textures. We here put\nthese conflicting hypotheses to a quantitative test by evaluating CNNs and\nhuman observers on images with a texture-shape cue conflict. We show that\nImageNet-trained CNNs are strongly biased towards recognising textures rather\nthan shapes, which is in stark contrast to human behavioural evidence and\nreveals fundamentally different classification strategies. We then demonstrate\nthat the same standard architecture (ResNet-50) that learns a texture-based\nrepresentation on ImageNet is able to learn a shape-based representation\ninstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\nThis provides a much better fit for human behavioural performance in our\nwell-controlled psychophysical lab setting (nine experiments totalling 48,560\npsychophysical trials across 97 observers) and comes with a number of\nunexpected emergent benefits such as improved object detection performance and\npreviously unseen robustness towards a wide range of image distortions,\nhighlighting advantages of a shape-based representation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:04:05 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 13:59:09 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Geirhos", "Robert", ""], ["Rubisch", "Patricia", ""], ["Michaelis", "Claudio", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""], ["Brendel", "Wieland", ""]]}, {"id": "1811.12234", "submitter": "Thomas Janssoone", "authors": "Thomas Janssoone and Cl\\'emence Bic and Dorra Kanoun and Pierre Hornus\n  and Pierre Rinder", "title": "Machine Learning on Electronic Health Records: Models and Features\n  Usages to predict Medication Non-Adherence", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adherence can be defined as \"the extent to which patients take their\nmedications as prescribed by their healthcare providers\"[Osterberg and\nBlaschke, 2005]. World Health Organization's reports point out that, in\ndeveloped countries, only about 50% of patients with chronic diseases correctly\nfollow their treatments. This severely compromises the efficiency of long-term\ntherapy and increases the cost of health services. We propose in this paper\ndifferent models of patient drug consumption in breast cancer treatments. The\naim of these different approaches is to predict medication non-adherence while\ngiving insights to doctors of the underlying reasons of these illegitimate\ndrop-outs. Working with oncologists, we show the interest of Machine- Learning\nalgorithms fined tune by the feedback of experts to estimate a risk score of a\npatient's non-adherence and thus improve support throughout their care path.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:08:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Janssoone", "Thomas", ""], ["Bic", "Cl\u00e9mence", ""], ["Kanoun", "Dorra", ""], ["Hornus", "Pierre", ""], ["Rinder", "Pierre", ""]]}, {"id": "1811.12239", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence and Stefan Riezler", "title": "Counterfactual Learning from Human Proofreading Feedback for Semantic\n  Parsing", "comments": "\"Learning by Instruction\" Workshop at the 32nd Conference on Neural\n  Information Processing Systems (NIPS 2018), Montr\\'eal, Canada. arXiv admin\n  note: substantial text overlap with arXiv:1805.01252", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semantic parsing for question-answering, it is often too expensive to\ncollect gold parses or even gold answers as supervision signals. We propose to\nconvert model outputs into a set of human-understandable statements which allow\nnon-expert users to act as proofreaders, providing error markings as learning\nsignals to the parser. Because model outputs were suggested by a historic\nsystem, we operate in a counterfactual, or off-policy, learning setup. We\nintroduce new estimators which can effectively leverage the given feedback and\nwhich avoid known degeneracies in counterfactual learning, while still being\napplicable to stochastic gradient optimization for neural semantic parsing.\nFurthermore, we discuss how our feedback collection method can be seamlessly\nintegrated into deployed virtual personal assistants that embed a semantic\nparser. Our work is the first to show that semantic parsers can be improved\nsignificantly by counterfactual learning from logged human feedback data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:20:30 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Lawrence", "Carolin", ""], ["Riezler", "Stefan", ""]]}, {"id": "1811.12253", "submitter": "Anshuka Rangi", "authors": "Anshuka Rangi, Massimo Franceschetti and Long Tran-Thanh", "title": "Unifying the stochastic and the adversarial Bandits with Knapsack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the adversarial Bandits with Knapsack (BwK) online\nlearning problem, where a player repeatedly chooses to perform an action, pays\nthe corresponding cost, and receives a reward associated with the action. The\nplayer is constrained by the maximum budget $B$ that can be spent to perform\nactions, and the rewards and the costs of the actions are assigned by an\nadversary. This problem has only been studied in the restricted setting where\nthe reward of an action is greater than the cost of the action, while we\nprovide a solution in the general setting. Namely, we propose EXP3.BwK, a novel\nalgorithm that achieves order optimal regret. We also propose EXP3++.BwK, which\nis order optimal in the adversarial BwK setup, and incurs an almost optimal\nexpected regret with an additional factor of $\\log(B)$ in the stochastic BwK\nsetup. Finally, we investigate the case of having large costs for the actions\n(i.e., they are comparable to the budget size $B$), and show that for the\nadversarial setting, achievable regret bounds can be significantly worse,\ncompared to the case of having costs bounded by a constant, which is a common\nassumption within the BwK literature.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:34:30 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Rangi", "Anshuka", ""], ["Franceschetti", "Massimo", ""], ["Tran-Thanh", "Long", ""]]}, {"id": "1811.12254", "submitter": "Aparna Balagopalan", "authors": "Aparna Balagopalan, Jekaterina Novikova, Frank Rudzicz and Marzyeh\n  Ghassemi", "title": "The Effect of Heterogeneous Data for Alzheimer's Disease Detection from\n  Speech", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/147", "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech datasets for identifying Alzheimer's disease (AD) are generally\nrestricted to participants performing a single task, e.g. describing an image\nshown to them. As a result, models trained on linguistic features derived from\nsuch datasets may not be generalizable across tasks. Building on prior work\ndemonstrating that same-task data of healthy participants helps improve AD\ndetection on a single-task dataset of pathological speech, we augment an\nAD-specific dataset consisting of subjects describing a picture with multi-task\nhealthy data. We demonstrate that normative data from multiple speech-based\ntasks helps improve AD detection by up to 9%. Visualization of decision\nboundaries reveals that models trained on a combination of structured picture\ndescriptions and unstructured conversational speech have the least out-of-task\nerror and show the most potential to generalize to multiple tasks. We analyze\nthe impact of age of the added samples and if they affect fairness in\nclassification. We also provide explanations for a possible inductive bias\neffect across tasks using model-agnostic feature anchors. This work highlights\nthe need for heterogeneous datasets for encoding changes in multiple facets of\ncognition and for developing a task-independent AD detection model.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:37:45 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Balagopalan", "Aparna", ""], ["Novikova", "Jekaterina", ""], ["Rudzicz", "Frank", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1811.12257", "submitter": "Adriano Pastore", "authors": "Adriano Pastore, Michael Gastpar", "title": "Locally Differentially-Private Randomized Response for Discrete\n  Distribution Learning", "comments": "47 pages, under revision at JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a setup in which confidential i.i.d. samples $X_1,\\dotsc,X_n$\nfrom an unknown finite-support distribution $\\boldsymbol{p}$ are passed through\n$n$ copies of a discrete privatization channel (a.k.a. mechanism) producing\noutputs $Y_1,\\dotsc,Y_n$. The channel law guarantees a local differential\nprivacy of $\\epsilon$. Subject to a prescribed privacy level $\\epsilon$, the\noptimal channel should be designed such that an estimate of the source\ndistribution based on the channel outputs $Y_1,\\dotsc,Y_n$ converges as fast as\npossible to the exact value $\\boldsymbol{p}$. For this purpose we study the\nconvergence to zero of three distribution distance metrics: $f$-divergence,\nmean-squared error and total variation. We derive the respective normalized\nfirst-order terms of convergence (as $n\\to\\infty$), which for a given target\nprivacy $\\epsilon$ represent a rule-of-thumb factor by which the sample size\nmust be augmented so as to achieve the same estimation accuracy as that of a\nnon-randomizing channel. We formulate the privacy-fidelity trade-off problem as\nbeing that of minimizing said first-order term under a privacy constraint\n$\\epsilon$. We further identify a scalar quantity that captures the essence of\nthis trade-off, and prove bounds and data-processing inequalities on this\nquantity. For some specific instances of the privacy-fidelity trade-off\nproblem, we derive inner and outer bounds on the optimal trade-off curve.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:39:38 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Pastore", "Adriano", ""], ["Gastpar", "Michael", ""]]}, {"id": "1811.12258", "submitter": "Olga Isupova", "authors": "Olga Isupova and Yunpeng Li and Danil Kuzin and Stephen J Roberts and\n  Katherine Willis and Steven Reece", "title": "BCCNet: Bayesian classifier combination neural network", "comments": "Presented at NeurIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning research for developing countries can demonstrate clear\nsustainable impact by delivering actionable and timely information to\nin-country government organisations (GOs) and NGOs in response to their\ncritical information requirements. We co-create products with UK and in-country\ncommercial, GO and NGO partners to ensure the machine learning algorithms\naddress appropriate user needs whether for tactical decision making or\nevidence-based policy decisions. In one particular case, we developed and\ndeployed a novel algorithm, BCCNet, to quickly process large quantities of\nunstructured data to prevent and respond to natural disasters. Crowdsourcing\nprovides an efficient mechanism to generate labels from unstructured data to\nprime machine learning algorithms for large scale data analysis. However, these\nlabels are often imperfect with qualities varying among different citizen\nscientists, which prohibits their direct use with many state-of-the-art machine\nlearning techniques. We describe BCCNet, a framework that simultaneously\naggregates biased and contradictory labels from the crowd and trains an\nautomatic classifier to process new data. Our case studies, mosquito sound\ndetection for malaria prevention and damage detection for disaster response,\nshow the efficacy of our method in the challenging context of developing world\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:40:03 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Isupova", "Olga", ""], ["Li", "Yunpeng", ""], ["Kuzin", "Danil", ""], ["Roberts", "Stephen J", ""], ["Willis", "Katherine", ""], ["Reece", "Steven", ""]]}, {"id": "1811.12273", "submitter": "Haytham Fayek", "authors": "Haytham M. Fayek, Lawrence Cavedon, Hong Ren Wu", "title": "On the Transferability of Representations in Neural Networks Between\n  Datasets and Tasks", "comments": "Accepted Paper in the Continual Learning Workshop, NeurIPS 2018", "journal-ref": "Continual Learning Workshop, 32nd Neural Information Processing\n  Systems (NeurIPS 2018), Montreal, Canada", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks, composed of multiple layers of hierarchical distributed\nrepresentations, tend to learn low-level features in initial layers and\ntransition to high-level features towards final layers. Paradigms such as\ntransfer learning, multi-task learning, and continual learning leverage this\nnotion of generic hierarchical distributed representations to share knowledge\nacross datasets and tasks. Herein, we study the layer-wise transferability of\nrepresentations in deep networks across a few datasets and tasks and note some\ninteresting empirical observations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 16:06:57 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Fayek", "Haytham M.", ""], ["Cavedon", "Lawrence", ""], ["Wu", "Hong Ren", ""]]}, {"id": "1811.12290", "submitter": "Quan Wang", "authors": "Li Wan, Prashant Sridhar, Yang Yu, Quan Wang, Ignacio Lopez Moreno", "title": "Tuplemax Loss for Language Identification", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scenarios of a language identification task, the user will specify a\nsmall set of languages which he/she can speak instead of a large set of all\npossible languages. We want to model such prior knowledge into the way we train\nour neural networks, by replacing the commonly used softmax loss function with\na novel loss function named tuplemax loss. As a matter of fact, a typical\nlanguage identification system launched in North America has about 95% users\nwho could speak no more than two languages. Using the tuplemax loss, our system\nachieved a 2.33% error rate, which is a relative 39.4% improvement over the\n3.85% error rate of standard softmax loss method.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 16:28:49 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 20:07:06 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Wan", "Li", ""], ["Sridhar", "Prashant", ""], ["Yu", "Yang", ""], ["Wang", "Quan", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1811.12295", "submitter": "Sim\\'on Ram\\'irez-Amaya", "authors": "Adolfo Quiroz, Sim\\'on Ram\\'irez-Amaya, \\'Alvaro Riascos", "title": "Regression by clustering using Metropolis-Hastings", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality risk adjustment in health insurance markets weakens insurer\nincentives to engage in inefficient behavior to attract lower-cost enrollees.\nWe propose a novel methodology based on Markov Chain Monte Carlo methods to\nimprove risk adjustment by clustering diagnostic codes into risk groups optimal\nfor health expenditure prediction. We test the performance of our methodology\nagainst common alternatives using panel data from 500 thousand enrollees of the\nColombian Healthcare System. Results show that our methodology outperforms\ncommon alternatives and suggest that it has potential to improve access to\nquality healthcare for the chronically ill.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 16:36:32 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 19:06:17 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Quiroz", "Adolfo", ""], ["Ram\u00edrez-Amaya", "Sim\u00f3n", ""], ["Riascos", "\u00c1lvaro", ""]]}, {"id": "1811.12323", "submitter": "C\\'edric Beaulac", "authors": "C\\'edric Beaulac, Jeffrey S. Rosenthal, David Hodgson", "title": "A Deep Latent-Variable Model Application to Select Treatment Intensity\n  in Survival Analysis", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/53", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the following short article we adapt a new and popular machine learning\nmodel for inference on medical data sets. Our method is based on the\nVariational AutoEncoder (VAE) framework that we adapt to survival analysis on\nsmall data sets with missing values. In our model, the true health status\nappears as a set of latent variables that affects the observed covariates and\nthe survival chances. We show that this flexible model allows insightful\ndecision-making using a predicted distribution and outperforms a classic\nsurvival analysis model.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 17:19:04 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Beaulac", "C\u00e9dric", ""], ["Rosenthal", "Jeffrey S.", ""], ["Hodgson", "David", ""]]}, {"id": "1811.12335", "submitter": "Artur Bekasov", "authors": "Artur Bekasov, Iain Murray", "title": "Bayesian Adversarial Spheres: Bayesian Inference and Adversarial\n  Examples in a Noiseless Setting", "comments": "To appear in the third workshop on Bayesian Deep Learning (NeurIPS\n  2018), Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural network models suffer from adversarial examples, i.e.\nconfidently misclassified points in the input space. It has been shown that\nBayesian neural networks are a promising approach for detecting adversarial\npoints, but careful analysis is problematic due to the complexity of these\nmodels. Recently Gilmer et al. (2018) introduced adversarial spheres, a toy\nset-up that simplifies both practical and theoretical analysis of the problem.\nIn this work, we use the adversarial sphere set-up to understand the properties\nof approximate Bayesian inference methods for a linear model in a noiseless\nsetting. We compare predictions of Bayesian and non-Bayesian methods,\nshowcasing the advantages of the former, although revealing open challenges for\ndeep learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 17:37:22 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Bekasov", "Artur", ""], ["Murray", "Iain", ""]]}, {"id": "1811.12337", "submitter": "Freweyni Kidane Teklehaymanot", "authors": "Freweyni K. Teklehaymanot, Michael Muma, and Abdelhak M. Zoubir", "title": "Robust Bayesian Cluster Enumeration Based on the $t$ Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in cluster analysis is that the number of data clusters is\nmostly unknown and it must be estimated prior to clustering the observed data.\nIn real-world applications, the observed data is often subject to heavy tailed\nnoise and outliers which obscure the true underlying structure of the data.\nConsequently, estimating the number of clusters becomes challenging. To this\nend, we derive a robust cluster enumeration criterion by formulating the\nproblem of estimating the number of clusters as maximization of the posterior\nprobability of multivariate $t_\\nu$ distributed candidate models. We utilize\nBayes' theorem and asymptotic approximations to come up with a robust criterion\nthat possesses a closed-form expression. Further, we refine the derivation and\nprovide a robust cluster enumeration criterion for data sets with finite sample\nsize. The robust criteria require an estimate of cluster parameters for each\ncandidate model as an input. Hence, we propose a two-step cluster enumeration\nalgorithm that uses the expectation maximization algorithm to partition the\ndata and estimate cluster parameters prior to the calculation of one of the\nrobust criteria. The performance of the proposed algorithm is tested and\ncompared to existing cluster enumeration methods using numerical and real data\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 17:38:27 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 09:41:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Teklehaymanot", "Freweyni K.", ""], ["Muma", "Michael", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1811.12346", "submitter": "Xi-Lin Li", "authors": "Xi-Lin Li", "title": "A Multiclass Multiple Instance Learning Method with Exact Likelihood", "comments": "McMIL maximizing exact model likelihood. Implementation:\n  https://github.com/lixilinx/MCMIL", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multiclass multiple instance learning (MIL) problem where the\nlabels only suggest whether any instance of a class exists or does not exist in\na training sample or example. No further information, e.g., the number of\ninstances of each class, relative locations or orders of all instances in a\ntraining sample, is exploited. Such a weak supervision learning problem can be\nexactly solved by maximizing the model likelihood fitting given observations,\nand finds applications to tasks like multiple object detection and localization\nfor image understanding. We discuss its relationship to the classic\nclassification problem, the traditional MIL, and connectionist temporal\nclassification (CTC). We use image recognition as the example task to develop\nour method, although it is applicable to data with higher or lower dimensions\nwithout much modification. Experimental results show that our method can be\nused to learn all convolutional neural networks for solving real-world multiple\nobject detection and localization tasks with weak annotations, e.g.,\ntranscribing house number sequences from the Google street view imagery\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 17:51:24 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 21:52:34 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Li", "Xi-Lin", ""]]}, {"id": "1811.12351", "submitter": "Nils M\\\"onning", "authors": "Nils M\\\"onning and Suresh Manandhar", "title": "Evaluation of Complex-Valued Neural Networks on Real-Valued\n  Classification Tasks", "comments": "preprint, 18 pages, 8 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex-valued neural networks are not a new concept, however, the use of\nreal-valued models has often been favoured over complex-valued models due to\ndifficulties in training and performance. When comparing real-valued versus\ncomplex-valued neural networks, existing literature often ignores the number of\nparameters, resulting in comparisons of neural networks with vastly different\nsizes. We find that when real and complex neural networks of similar capacity\nare compared, complex models perform equal to or slightly worse than\nreal-valued models for a range of real-valued classification tasks. The use of\ncomplex numbers allows neural networks to handle noise on the complex plane.\nWhen classifying real-valued data with a complex-valued neural network, the\nimaginary parts of the weights follow their real parts. This behaviour is\nindicative for a task that does not require a complex-valued model. We further\ninvestigated this in a synthetic classification task. We can transfer many\nactivation functions from the real to the complex domain using different\nstrategies. The weight initialisation of complex neural networks, however,\nremains a significant problem.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 17:57:45 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["M\u00f6nning", "Nils", ""], ["Manandhar", "Suresh", ""]]}, {"id": "1811.12359", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar R\\\"atsch,\n  Sylvain Gelly, Bernhard Sch\\\"olkopf, Olivier Bachem", "title": "Challenging Common Assumptions in the Unsupervised Learning of\n  Disentangled Representations", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key idea behind the unsupervised learning of disentangled representations\nis that real-world data is generated by a few explanatory factors of variation\nwhich can be recovered by unsupervised learning algorithms. In this paper, we\nprovide a sober look at recent progress in the field and challenge some common\nassumptions. We first theoretically show that the unsupervised learning of\ndisentangled representations is fundamentally impossible without inductive\nbiases on both the models and the data. Then, we train more than 12000 models\ncovering most prominent methods and evaluation metrics in a reproducible\nlarge-scale experimental study on seven different data sets. We observe that\nwhile the different methods successfully enforce properties ``encouraged'' by\nthe corresponding losses, well-disentangled models seemingly cannot be\nidentified without supervision. Furthermore, increased disentanglement does not\nseem to lead to a decreased sample complexity of learning for downstream tasks.\nOur results suggest that future work on disentanglement learning should be\nexplicit about the role of inductive biases and (implicit) supervision,\ninvestigate concrete benefits of enforcing disentanglement of the learned\nrepresentations, and consider a reproducible experimental setup covering\nseveral data sets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:10:40 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 16:42:28 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 17:15:53 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 08:58:18 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Locatello", "Francesco", ""], ["Bauer", "Stefan", ""], ["Lucic", "Mario", ""], ["R\u00e4tsch", "Gunnar", ""], ["Gelly", "Sylvain", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""]]}, {"id": "1811.12361", "submitter": "Aravindan Vijayaraghavan", "authors": "Aditya Bhaskara, Aidao Chen, Aidan Perreault and Aravindan\n  Vijayaraghavan", "title": "Smoothed Analysis in Unsupervised Learning via Decoupling", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothed analysis is a powerful paradigm in overcoming worst-case\nintractability in unsupervised learning and high-dimensional data analysis.\nWhile polynomial time smoothed analysis guarantees have been obtained for\nworst-case intractable problems like tensor decompositions and learning\nmixtures of Gaussians, such guarantees have been hard to obtain for several\nother important problems in unsupervised learning. A core technical challenge\nin analyzing algorithms is obtaining lower bounds on the least singular value\nfor random matrix ensembles with dependent entries, that are given by\nlow-degree polynomials of a few base underlying random variables.\n  In this work, we address this challenge by obtaining high-confidence lower\nbounds on the least singular value of new classes of structured random matrix\nensembles of the above kind. We then use these bounds to design algorithms with\npolynomial time smoothed analysis guarantees for the following three important\nproblems in unsupervised learning:\n  1. Robust subspace recovery, when the fraction $\\alpha$ of inliers in the\nd-dimensional subspace $T \\subset \\mathbb{R}^n$ is at least $\\alpha >\n(d/n)^\\ell$ for any constant integer $\\ell>0$. This contrasts with the known\nworst-case intractability when $\\alpha< d/n$, and the previous smoothed\nanalysis result which needed $\\alpha > d/n$ (Hardt and Moitra, 2013).\n  2. Learning overcomplete hidden markov models, where the size of the state\nspace is any polynomial in the dimension of the observations. This gives the\nfirst polynomial time guarantees for learning overcomplete HMMs in a smoothed\nanalysis model.\n  3. Higher order tensor decompositions, where we generalize the so-called\nFOOBI algorithm of Cardoso to find order-$\\ell$ rank-one tensors in a subspace.\nThis allows us to obtain polynomially robust decomposition algorithms for\n$2\\ell$'th order tensors with rank $O(n^{\\ell})$.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:12:32 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 02:12:23 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Chen", "Aidao", ""], ["Perreault", "Aidan", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1811.12386", "submitter": "Josue Nassar", "authors": "Josue Nassar, Scott W. Linderman, Monica Bugallo, Il Memming Park", "title": "Tree-Structured Recurrent Switching Linear Dynamical Systems for\n  Multi-Scale Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world systems studied are governed by complex, nonlinear dynamics.\nBy modeling these dynamics, we can gain insight into how these systems work,\nmake predictions about how they will behave, and develop strategies for\ncontrolling them. While there are many methods for modeling nonlinear dynamical\nsystems, existing techniques face a trade off between offering interpretable\ndescriptions and making accurate predictions. Here, we develop a class of\nmodels that aims to achieve both simultaneously, smoothly interpolating between\nsimple descriptions and more complex, yet also more accurate models. Our\nprobabilistic model achieves this multi-scale property through a hierarchy of\nlocally linear dynamics that jointly approximate global nonlinear dynamics. We\ncall it the tree-structured recurrent switching linear dynamical system. To fit\nthis model, we present a fully-Bayesian sampling procedure using Polya-Gamma\ndata augmentation to allow for fast and conjugate Gibbs sampling. Through a\nvariety of synthetic and real examples, we show how these models outperform\nexisting methods in both interpretability and predictive capability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:53:11 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 16:28:33 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 15:31:45 GMT"}, {"version": "v4", "created": "Wed, 30 Jan 2019 04:00:31 GMT"}, {"version": "v5", "created": "Fri, 22 Feb 2019 22:43:13 GMT"}, {"version": "v6", "created": "Tue, 4 Jun 2019 16:11:31 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Nassar", "Josue", ""], ["Linderman", "Scott W.", ""], ["Bugallo", "Monica", ""], ["Park", "Il Memming", ""]]}, {"id": "1811.12395", "submitter": "Tsui-Wei Weng", "authors": "Akhilan Boopathy, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu and Luca\n  Daniel", "title": "CNN-Cert: An Efficient Framework for Certifying Robustness of\n  Convolutional Neural Networks", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying robustness of neural network classifiers has attracted great\ninterests and attention due to the success of deep neural networks and their\nunexpected vulnerability to adversarial perturbations. Although finding minimum\nadversarial distortion of neural networks (with ReLU activations) has been\nshown to be an NP-complete problem, obtaining a non-trivial lower bound of\nminimum distortion as a provable robustness guarantee is possible. However,\nmost previous works only focused on simple fully-connected layers (multilayer\nperceptrons) and were limited to ReLU activations. This motivates us to propose\na general and efficient framework, CNN-Cert, that is capable of certifying\nrobustness on general convolutional neural networks. Our framework is general\n-- we can handle various architectures including convolutional layers,\nmax-pooling layers, batch normalization layer, residual blocks, as well as\ngeneral activation functions; our approach is efficient -- by exploiting the\nspecial structure of convolutional layers, we achieve up to 17 and 11 times of\nspeed-up compared to the state-of-the-art certification algorithms (e.g.\nFast-Lin, CROWN) and 366 times of speed-up compared to the dual-LP approach\nwhile our algorithm obtains similar or even better verification bounds. In\naddition, CNN-Cert generalizes state-of-the-art algorithms e.g. Fast-Lin and\nCROWN. We demonstrate by extensive experiments that our method outperforms\nstate-of-the-art lower-bound-based certification algorithms in terms of both\nbound quality and speed.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:57:43 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Boopathy", "Akhilan", ""], ["Weng", "Tsui-Wei", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Daniel", "Luca", ""]]}, {"id": "1811.12402", "submitter": "Ke Li", "authors": "Ke Li and Jitendra Malik", "title": "On the Implicit Assumptions of GANs", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial nets (GANs) have generated a lot of excitement.\nDespite their popularity, they exhibit a number of well-documented issues in\npractice, which apparently contradict theoretical guarantees. A number of\nenlightening papers have pointed out that these issues arise from unjustified\nassumptions that are commonly made, but the message seems to have been lost\namid the optimism of recent years. We believe the identified problems deserve\nmore attention, and highlight the implications on both the properties of GANs\nand the trajectory of research on probabilistic models. We recently proposed an\nalternative method that sidesteps these problems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:59:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1811.12408", "submitter": "Dorien Herremans", "authors": "Ching-Hua Chuan, Kat Agres, Dorien Herremans", "title": "From Context to Concept: Exploring Semantic Relationships in Music with\n  Word2Vec", "comments": "Accepted for publication in Neural Computing and Applications,\n  Springer. In Press", "journal-ref": "Neural Computing and Applications, Springer. 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the potential of a popular distributional semantics vector space\nmodel, word2vec, for capturing meaningful relationships in ecological (complex\npolyphonic) music. More precisely, the skip-gram version of word2vec is used to\nmodel slices of music from a large corpus spanning eight musical genres. In\nthis newly learned vector space, a metric based on cosine distance is able to\ndistinguish between functional chord relationships, as well as harmonic\nassociations in the music. Evidence, based on cosine distance between\nchord-pair vectors, suggests that an implicit circle-of-fifths exists in the\nvector space. In addition, a comparison between pieces in different keys\nreveals that key relationships are represented in word2vec space. These results\nsuggest that the newly learned embedded vector representation does in fact\ncapture tonal and harmonic characteristics of music, without receiving explicit\ninformation about the musical content of the constituent slices. In order to\ninvestigate whether proximity in the discovered space of embeddings is\nindicative of `semantically-related' slices, we explore a music generation\ntask, by automatically replacing existing slices from a given piece of music\nwith new slices. We propose an algorithm to find substitute slices based on\nspatial proximity and the pitch class distribution inferred in the chosen\nsubspace. The results indicate that the size of the subspace used has a\nsignificant effect on whether slices belonging to the same key are selected. In\nsum, the proposed word2vec model is able to learn music-vector embeddings that\ncapture meaningful tonal and harmonic relationships in music, thereby providing\na useful tool for exploring musical properties and comparisons across pieces,\nas a potential input representation for deep learning models, and as a music\ngeneration device.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 13:52:13 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Chuan", "Ching-Hua", ""], ["Agres", "Kat", ""], ["Herremans", "Dorien", ""]]}, {"id": "1811.12444", "submitter": "Xian Yeow Lee", "authors": "Xian Yeow Lee, Aditya Balu, Daniel Stoecklein, Baskar\n  Ganapathysubramanian and Soumik Sarkar", "title": "Flow Shape Design for Microfluidic Devices Using Deep Reinforcement\n  Learning", "comments": "Neurips 2018 Deep RL workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microfluidic devices are utilized to control and direct flow behavior in a\nwide variety of applications, particularly in medical diagnostics. A\nparticularly popular form of microfluidics -- called inertial microfluidic flow\nsculpting -- involves placing a sequence of pillars to controllably deform an\ninitial flow field into a desired one. Inertial flow sculpting can be formally\ndefined as an inverse problem, where one identifies a sequence of pillars\n(chosen, with replacement, from a finite set of pillars, each of which produce\na specific transformation) whose composite transformation results in a\nuser-defined desired transformation. Endemic to most such problems in\nengineering, inverse problems are usually quite computationally intractable,\nwith most traditional approaches based on search and optimization strategies.\nIn this paper, we pose this inverse problem as a Reinforcement Learning (RL)\nproblem. We train a DoubleDQN agent to learn from this environment. The results\nsuggest that learning is possible using a DoubleDQN model with the success\nfrequency reaching 90% in 200,000 episodes and the rewards converging. While\nmost of the results are obtained by fixing a particular target flow shape to\nsimplify the learning problem, we later demonstrate how to transfer the\nlearning of an agent based on one target shape to another, i.e. from one design\nto another and thus be useful for a generic design of a flow shape.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 19:29:24 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Lee", "Xian Yeow", ""], ["Balu", "Aditya", ""], ["Stoecklein", "Daniel", ""], ["Ganapathysubramanian", "Baskar", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1811.12465", "submitter": "Danil Kuzin", "authors": "Danil Kuzin and Olga Isupova and Lyudmila Mihaylova", "title": "Uncertainty propagation in neural networks for sparse coding", "comments": "Presented at the third workshop on Bayesian Deep Learning (NeurIPS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method to propagate uncertainty through the soft-thresholding\nnonlinearity is proposed in this paper. At every layer the current distribution\nof the target vector is represented as a spike and slab distribution, which\nrepresents the probabilities of each variable being zero, or\nGaussian-distributed. Using the proposed method of uncertainty propagation, the\ngradients of the logarithms of normalisation constants are derived, that can be\nused to update a weight distribution. A novel Bayesian neural network for\nsparse coding is designed utilising both the proposed method of uncertainty\npropagation and Bayesian inference algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 20:16:03 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Kuzin", "Danil", ""], ["Isupova", "Olga", ""], ["Mihaylova", "Lyudmila", ""]]}, {"id": "1811.12469", "submitter": "Vitaly Feldman", "authors": "\\'Ulfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan,\n  Kunal Talwar, Abhradeep Thakurta", "title": "Amplification by Shuffling: From Local to Central Differential Privacy\n  via Anonymity", "comments": "Stated amplification bounds for epsilon > 1 explicitly and also\n  stated the bounds for for Renyi DP. Fixed an incorrect statement in one of\n  the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitive statistics are often collected across sets of users, with repeated\ncollection of reports done over time. For example, trends in users' private\npreferences or software usage may be monitored via such reports. We study the\ncollection of such statistics in the local differential privacy (LDP) model,\nand describe an algorithm whose privacy cost is polylogarithmic in the number\nof changes to a user's value.\n  More fundamentally---by building on anonymity of the users' reports---we also\ndemonstrate how the privacy cost of our LDP algorithm can actually be much\nlower when viewed in the central model of differential privacy. We show, via a\nnew and general privacy amplification technique, that any permutation-invariant\nalgorithm satisfying $\\varepsilon$-local differential privacy will satisfy\n$(O(\\varepsilon \\sqrt{\\log(1/\\delta)/n}), \\delta)$-central differential\nprivacy. By this, we explain how the high noise and $\\sqrt{n}$ overhead of LDP\nprotocols is a consequence of them being significantly more private in the\ncentral model. As a practical corollary, our results imply that several\nLDP-based industrial deployments may have much lower privacy cost than their\nadvertised $\\varepsilon$ would indicate---at least if reports are anonymized.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 20:24:45 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 01:37:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Erlingsson", "\u00dalfar", ""], ["Feldman", "Vitaly", ""], ["Mironov", "Ilya", ""], ["Raghunathan", "Ananth", ""], ["Talwar", "Kunal", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "1811.12470", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, Seraphin\n  Calo", "title": "Analyzing Federated Learning through an Adversarial Lens", "comments": "Extended version of paper accepted to ICML 2019, code available at\n  https://github.com/inspire-group/ModelPoisoning; 19 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning distributes model training among a multitude of agents,\nwho, guided by privacy concerns, perform training using their local data but\nshare only model parameter updates, for iterative aggregation at the server. In\nthis work, we explore the threat of model poisoning attacks on federated\nlearning initiated by a single, non-colluding malicious agent where the\nadversarial objective is to cause the model to misclassify a set of chosen\ninputs with high confidence. We explore a number of strategies to carry out\nthis attack, starting with simple boosting of the malicious agent's update to\novercome the effects of other agents' updates. To increase attack stealth, we\npropose an alternating minimization strategy, which alternately optimizes for\nthe training loss and the adversarial objective. We follow up by using\nparameter estimation for the benign agents' updates to improve on attack\nsuccess. Finally, we use a suite of interpretability techniques to generate\nvisual explanations of model decisions for both benign and malicious models and\nshow that the explanations are nearly visually indistinguishable. Our results\nindicate that even a highly constrained adversary can carry out model poisoning\nattacks while simultaneously maintaining stealth, thus highlighting the\nvulnerability of the federated learning setting and the need to develop\neffective defense strategies.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 20:27:14 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 17:14:03 GMT"}, {"version": "v3", "created": "Sat, 2 Mar 2019 22:04:18 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 00:34:14 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["Chakraborty", "Supriyo", ""], ["Mittal", "Prateek", ""], ["Calo", "Seraphin", ""]]}, {"id": "1811.12488", "submitter": "Fahad Shamshad", "authors": "Fahad Shamshad, Muhammad Awais, Muhammad Asim, Zain ul Aabidin Lodhi,\n  Muhammad Umair, Ali Ahmed", "title": "Leveraging Deep Stein's Unbiased Risk Estimator for Unsupervised X-ray\n  Denoising", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/223", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the plethora of techniques devised to curb the prevalence of noise in\nmedical images, deep learning based approaches have shown the most promise.\nHowever, one critical limitation of these deep learning based denoisers is the\nrequirement of high-quality noiseless ground truth images that are difficult to\nobtain in many medical imaging applications such as X-rays. To circumvent this\nissue, we leverage recently proposed approach of [7] that incorporates Stein's\nUnbiased Risk Estimator (SURE) to train a deep convolutional neural network\nwithout requiring denoised ground truth X-ray data. Our experimental results\ndemonstrate the effectiveness of SURE based approach for denoising X-ray\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 21:04:38 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Shamshad", "Fahad", ""], ["Awais", "Muhammad", ""], ["Asim", "Muhammad", ""], ["Lodhi", "Zain ul Aabidin", ""], ["Umair", "Muhammad", ""], ["Ahmed", "Ali", ""]]}, {"id": "1811.12495", "submitter": "Dushyant Mehta", "authors": "Dushyant Mehta, Kwang In Kim, Christian Theobalt", "title": "On Implicit Filter Level Sparsity in Convolutional Neural Networks", "comments": "Accepted at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate filter level sparsity that emerges in convolutional neural\nnetworks (CNNs) which employ Batch Normalization and ReLU activation, and are\ntrained with adaptive gradient descent techniques and L2 regularization or\nweight decay. We conduct an extensive experimental study casting our initial\nfindings into hypotheses and conclusions about the mechanisms underlying the\nemergent filter level sparsity. This study allows new insight into the\nperformance gap obeserved between adapative and non-adaptive gradient descent\nmethods in practice. Further, analysis of the effect of training strategies and\nhyperparameters on the sparsity leads to practical suggestions in designing CNN\ntraining strategies enabling us to explore the tradeoffs between feature\nselectivity, network capacity, and generalization performance. Lastly, we show\nthat the implicit sparsity can be harnessed for neural network speedup at par\nor better than explicit sparsification / pruning approaches, with no\nmodifications to the typical training pipeline required.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 21:29:31 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 15:40:40 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Mehta", "Dushyant", ""], ["Kim", "Kwang In", ""], ["Theobalt", "Christian", ""]]}, {"id": "1811.12500", "submitter": "Tiehang Duan", "authors": "Tiehang Duan, Qi Lou, Sargur N. Srihari, Xiaohui Xie", "title": "Sequential Embedding Induced Text Clustering, a Non-parametric Bayesian\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art nonparametric Bayesian text clustering methods model\ndocuments through multinomial distribution on bags of words. Although these\nmethods can effectively utilize the word burstiness representation of documents\nand achieve decent performance, they do not explore the sequential information\nof text and relationships among synonyms. In this paper, the documents are\nmodeled as the joint of bags of words, sequential features and word embeddings.\nWe proposed Sequential Embedding induced Dirichlet Process Mixture Model\n(SiDPMM) to effectively exploit this joint document representation in text\nclustering. The sequential features are extracted by the encoder-decoder\ncomponent. Word embeddings produced by the continuous-bag-of-words (CBOW) model\nare introduced to handle synonyms. Experimental results demonstrate the\nbenefits of our model in two major aspects: 1) improved performance across\nmultiple diverse text datasets in terms of the normalized mutual information\n(NMI); 2) more accurate inference of ground truth cluster numbers with\nregularization effect on tiny outlier clusters.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 21:39:44 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Duan", "Tiehang", ""], ["Lou", "Qi", ""], ["Srihari", "Sargur N.", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1811.12507", "submitter": "Bangalore Ravi Kiran", "authors": "Jean Serra, Jesus Angulo, B Ravi Kiran", "title": "Regression and Classification by Zonal Kriging", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a family $Z=\\{\\boldsymbol{x_{i}},y_{i}$,$1\\leq i\\leq N\\}$ of $N$\npairs of vectors $\\boldsymbol{x_{i}} \\in \\mathbb{R}^d$ and scalars $y_{i}$ that\nwe aim to predict for a new sample vector $\\mathbf{x}_0$. Kriging models $y$ as\na sum of a deterministic function $m$, a drift which depends on the point\n$\\boldsymbol{x}$, and a random function $z$ with zero mean. The zonality\nhypothesis interprets $y$ as a weighted sum of $d$ random functions of a single\nindependent variables, each of which is a kriging, with a quadratic form for\nthe variograms drift. We can therefore construct an unbiased estimator\n$y^{*}(\\boldsymbol{x_{0}})=\\sum_{i}\\lambda^{i}z(\\boldsymbol{x_{i}})$ de\n$y(\\boldsymbol{x_{0}})$ with minimal variance\n$E[y^{*}(\\boldsymbol{x_{0}})-y(\\boldsymbol{x_{0}})]^{2}$, with the help of the\nknown training set points. We give the explicitly closed form for $\\lambda^{i}$\nwithout having calculated the inverse of the matrices.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 22:00:26 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 17:57:57 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Serra", "Jean", ""], ["Angulo", "Jesus", ""], ["Kiran", "B Ravi", ""]]}, {"id": "1811.12520", "submitter": "Eli Sherman", "authors": "Eli Sherman, Hitinder Gurm, Ulysses Balis, Scott Owens, Jenna Wiens", "title": "Leveraging Clinical Time-Series Data for Prediction: A Cautionary Tale", "comments": "In Proceedings of American Medical Informatics Annual Symposium 2017\n  PMID: 29854227", "journal-ref": "AMIA Annu Symp Proc. 2018 Apr 16;2017:1571-1580. eCollection 2017", "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare, patient risk stratification models are often learned using\ntime-series data extracted from electronic health records. When extracting data\nfor a clinical prediction task, several formulations exist, depending on how\none chooses the time of prediction and the prediction horizon. In this paper,\nwe show how the formulation can greatly impact both model performance and\nclinical utility. Leveraging a publicly available ICU dataset, we consider two\nclinical prediction tasks: in-hospital mortality, and hypokalemia. Through\nthese case studies, we demonstrate the necessity of evaluating models using an\noutcome-independent reference point, since choosing the time of prediction\nrelative to the event can result in unrealistic performance. Further, an\noutcome-independent scheme outperforms an outcome-dependent scheme on both\ntasks (In-Hospital Mortality AUROC .882 vs. .831; Serum Potassium: AUROC .829\nvs. .740) when evaluated on test sets that mimic real-world use.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 22:43:23 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Sherman", "Eli", ""], ["Gurm", "Hitinder", ""], ["Balis", "Ulysses", ""], ["Owens", "Scott", ""], ["Wiens", "Jenna", ""]]}, {"id": "1811.12530", "submitter": "Anurag Koul", "authors": "Anurag Koul, Sam Greydanus, Alan Fern", "title": "Learning Finite State Representations of Recurrent Policy Networks", "comments": "Preprint. Under review at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are an effective representation of control\npolicies for a wide range of reinforcement and imitation learning problems. RNN\npolicies, however, are particularly difficult to explain, understand, and\nanalyze due to their use of continuous-valued memory vectors and observation\nfeatures. In this paper, we introduce a new technique, Quantized Bottleneck\nInsertion, to learn finite representations of these vectors and features. The\nresult is a quantized representation of the RNN that can be analyzed to improve\nour understanding of memory use and general behavior. We present results of\nthis approach on synthetic environments and six Atari games. The resulting\nfinite representations are surprisingly small in some cases, using as few as 3\ndiscrete memory states and 10 observations for a perfect Pong policy. We also\nshow that these finite policy representations lead to improved\ninterpretability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 23:07:59 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Koul", "Anurag", ""], ["Greydanus", "Sam", ""], ["Fern", "Alan", ""]]}, {"id": "1811.12535", "submitter": "Jiaming Zeng", "authors": "Jiaming Zeng, Adam Lesnikowski, Jose M. Alvarez", "title": "The Relevance of Bayesian Layer Positioning to Model Uncertainty in Deep\n  Bayesian Active Learning", "comments": null, "journal-ref": "Third workshop on Bayesian Deep Learning (NeurIPS 2018)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges of deep learning tools is their inability to\ncapture model uncertainty. While Bayesian deep learning can be used to tackle\nthe problem, Bayesian neural networks often require more time and computational\npower to train than deterministic networks. Our work explores whether fully\nBayesian networks are needed to successfully capture model uncertainty. We vary\nthe number and position of Bayesian layers in a network and compare their\nperformance on active learning with the MNIST dataset. We found that we can\nfully capture the model uncertainty by using only a few Bayesian layers near\nthe output of the network, combining the advantages of deterministic and\nBayesian networks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 23:36:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zeng", "Jiaming", ""], ["Lesnikowski", "Adam", ""], ["Alvarez", "Jose M.", ""]]}, {"id": "1811.12556", "submitter": "Dhaval Adjodah", "authors": "Dhaval Adjodah, Dan Calacci, Abhimanyu Dubey, Peter Krafft, Esteban\n  Moro, Alex `Sandy' Pentland", "title": "How to Organize your Deep Reinforcement Learning Agents: The Importance\n  of Communication Topology", "comments": "please refer to arXiv:1902.06740 for updated paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this empirical paper, we investigate how learning agents can be arranged\nin more efficient communication topologies for improved learning. This is an\nimportant problem because a common technique to improve speed and robustness of\nlearning in deep reinforcement learning and many other machine learning\nalgorithms is to run multiple learning agents in parallel. The standard\ncommunication architecture typically involves all agents intermittently\ncommunicating with each other (fully connected topology) or with a centralized\nserver (star topology). Unfortunately, optimizing the topology of communication\nover the space of all possible graphs is a hard problem, so we borrow results\nfrom the networked optimization and collective intelligence literatures which\nsuggest that certain families of network topologies can lead to strong\nimprovements over fully-connected networks. We start by introducing alternative\nnetwork topologies to DRL benchmark tasks under the Evolution Strategies\nparadigm which we call Network Evolution Strategies. We explore the relative\nperformance of the four main graph families and observe that one such family\n(Erdos-Renyi random graphs) empirically outperforms all other families,\nincluding the de facto fully-connected communication topologies. Additionally,\nthe use of alternative network topologies has a multiplicative performance\neffect: we observe that when 1000 learning agents are arranged in a carefully\ndesigned communication topology, they can compete with 3000 agents arranged in\nthe de facto fully-connected topology. Overall, our work suggests that\ndistributed machine learning algorithms would learn more efficiently if the\ncommunication topology between learning agents was optimized.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 00:36:34 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 21:10:11 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Adjodah", "Dhaval", ""], ["Calacci", "Dan", ""], ["Dubey", "Abhimanyu", ""], ["Krafft", "Peter", ""], ["Moro", "Esteban", ""], ["Pentland", "Alex `Sandy'", ""]]}, {"id": "1811.12560", "submitter": "Vincent Francois-Lavet", "authors": "Vincent Francois-Lavet, Peter Henderson, Riashat Islam, Marc G.\n  Bellemare, Joelle Pineau", "title": "An Introduction to Deep Reinforcement Learning", "comments": null, "journal-ref": "Foundations and Trends in Machine Learning: Vol. 11, No. 3-4, 2018", "doi": "10.1561/2200000071", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is the combination of reinforcement learning (RL)\nand deep learning. This field of research has been able to solve a wide range\nof complex decision-making tasks that were previously out of reach for a\nmachine. Thus, deep RL opens up many new applications in domains such as\nhealthcare, robotics, smart grids, finance, and many more. This manuscript\nprovides an introduction to deep reinforcement learning models, algorithms and\ntechniques. Particular focus is on the aspects related to generalization and\nhow deep RL can be used for practical applications. We assume the reader is\nfamiliar with basic machine learning concepts.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 00:57:30 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 09:10:53 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Francois-Lavet", "Vincent", ""], ["Henderson", "Peter", ""], ["Islam", "Riashat", ""], ["Bellemare", "Marc G.", ""], ["Pineau", "Joelle", ""]]}, {"id": "1811.12565", "submitter": "Juhan Bae", "authors": "Juhan Bae, Guodong Zhang, Roger Grosse", "title": "Eigenvalue Corrected Noisy Natural Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian neural networks combine the flexibility of deep learning\nwith Bayesian uncertainty estimation. However, inference procedures for\nflexible variational posteriors are computationally expensive. A recently\nproposed method, noisy natural gradient, is a surprisingly simple method to fit\nexpressive posteriors by adding weight noise to regular natural gradient\nupdates. Noisy K-FAC is an instance of noisy natural gradient that fits a\nmatrix-variate Gaussian posterior with minor changes to ordinary K-FAC.\nNevertheless, a matrix-variate Gaussian posterior does not capture an accurate\ndiagonal variance. In this work, we extend on noisy K-FAC to obtain a more\nflexible posterior distribution called eigenvalue corrected matrix-variate\nGaussian. The proposed method computes the full diagonal re-scaling factor in\nKronecker-factored eigenbasis. Empirically, our approach consistently\noutperforms existing algorithms (e.g., noisy K-FAC) on regression and\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 01:12:51 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Bae", "Juhan", ""], ["Zhang", "Guodong", ""], ["Grosse", "Roger", ""]]}, {"id": "1811.12569", "submitter": "Kailas Vodrahalli", "authors": "Kailas Vodrahalli, Ke Li, Jitendra Malik", "title": "Are All Training Examples Created Equal? An Empirical Study", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computer vision algorithms often rely on very large training datasets.\nHowever, it is conceivable that a carefully selected subsample of the dataset\nis sufficient for training. In this paper, we propose a gradient-based\nimportance measure that we use to empirically analyze relative importance of\ntraining images in four datasets of varying complexity. We find that in some\ncases, a small subsample is indeed sufficient for training. For other datasets,\nhowever, the relative differences in importance are negligible. These results\nhave important implications for active learning on deep networks. Additionally,\nour analysis method can be used as a general tool to better understand\ndiversity of training examples in datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 01:16:42 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Vodrahalli", "Kailas", ""], ["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1811.12583", "submitter": "Bret Nestor", "authors": "Bret Nestor, Matthew B. A. McDermott, Geeticka Chauhan, Tristan\n  Naumann, Michael C. Hughes, Anna Goldenberg, Marzyeh Ghassemi", "title": "Rethinking clinical prediction: Why machine learning must consider year\n  of care and feature aggregation", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/189", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for healthcare often trains models on de-identified datasets\nwith randomly-shifted calendar dates, ignoring the fact that data were\ngenerated under hospital operation practices that change over time. These\nchanging practices induce definitive changes in observed data which confound\nevaluations which do not account for dates and limit the generalisability of\ndate-agnostic models. In this work, we establish the magnitude of this problem\non MIMIC, a public hospital dataset, and showcase a simple solution. We augment\nMIMIC with the year in which care was provided and show that a model trained\nusing standard feature representations will significantly degrade in quality\nover time. We find a deterioration of 0.3 AUC when evaluating mortality\nprediction on data from 10 years later. We find a similar deterioration of 0.15\nAUC for length-of-stay. In contrast, we demonstrate that clinically-oriented\naggregates of raw features significantly mitigate future deterioration. Our\nsuggested aggregated representations, when retrained yearly, have prediction\nquality comparable to year-agnostic models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 02:30:10 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Nestor", "Bret", ""], ["McDermott", "Matthew B. A.", ""], ["Chauhan", "Geeticka", ""], ["Naumann", "Tristan", ""], ["Hughes", "Michael C.", ""], ["Goldenberg", "Anna", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1811.12587", "submitter": "Muneki Yasuda", "authors": "Yuuki Yokoyama, Tomu Katsumata, Muneki Yasuda", "title": "Restricted Boltzmann Machine with Multivalued Hidden Variables: a model\n  suppressing over-fitting", "comments": null, "journal-ref": "The Review of Socionetwork Strategies, Vol.13, no.2, pp.253-266,\n  2019", "doi": "10.1007/s12626-019-00042-4", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is one of the most important issues in machine learning\nproblems. In this study, we consider generalization in restricted Boltzmann\nmachines (RBMs). We propose an RBM with multivalued hidden variables, which is\na simple extension of conventional RBMs. We demonstrate that the proposed model\nis better than the conventional model via numerical experiments for contrastive\ndivergence learning with artificial data and a classification problem with\nMNIST.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 02:40:40 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 03:27:26 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 13:22:58 GMT"}, {"version": "v4", "created": "Wed, 8 Jan 2020 07:32:04 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Yokoyama", "Yuuki", ""], ["Katsumata", "Tomu", ""], ["Yasuda", "Muneki", ""]]}, {"id": "1811.12589", "submitter": "Benjamin Glicksberg", "authors": "Beau Norgeot, Dmytro Lituiev, Benjamin S. Glicksberg, Atul J. Butte", "title": "Time Aggregation and Model Interpretation for Deep Multivariate\n  Longitudinal Patient Outcome Forecasting Systems in Chronic Ambulatory Care", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/121", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical data for ambulatory care, which accounts for 90% of the nations\nhealthcare spending, is characterized by relatively small sample sizes of\nlongitudinal data, unequal spacing between visits for each patient, with\nunequal numbers of data points collected across patients. While deep learning\nhas become state-of-the-art for sequence modeling, it is unknown which methods\nof time aggregation may be best suited for these challenging temporal use\ncases. Additionally, deep models are often considered uninterpretable by\nphysicians which may prevent the clinical adoption, even of well performing\nmodels. We show that time-distributed-dense layers combined with GRUs produce\nthe most generalizable models. Furthermore, we provide a framework for the\nclinical interpretation of the models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 02:43:33 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Norgeot", "Beau", ""], ["Lituiev", "Dmytro", ""], ["Glicksberg", "Benjamin S.", ""], ["Butte", "Atul J.", ""]]}, {"id": "1811.12591", "submitter": "Yuheng Bu", "authors": "Yuheng Bu, Kevin Small", "title": "Active Learning in Recommendation Systems with Multi-level User\n  Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recommendation systems generally observe user behavior passively, there\nhas been an increased interest in directly querying users to learn their\nspecific preferences. In such settings, considering queries at different levels\nof granularity to optimize user information acquisition is crucial to\nefficiently providing a good user experience. In this work, we study the active\nlearning problem with multi-level user preferences within the collective matrix\nfactorization (CMF) framework. CMF jointly captures multi-level user\npreferences with respect to items and relations between items (e.g., book\ngenre, cuisine type), generally resulting in improved predictions. Motivated by\nfinite-sample analysis of the CMF model, we propose a theoretically optimal\nactive learning strategy based on the Fisher information matrix and use this to\nderive a realizable approximation algorithm for practical recommendations.\nExperiments are conducted using both the Yelp dataset directly and an\nillustrative synthetic dataset in the three settings of personalized active\nlearning, cold-start recommendations, and noisy data -- demonstrating strong\nimprovements over several widely used active learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 03:05:51 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Bu", "Yuheng", ""], ["Small", "Kevin", ""]]}, {"id": "1811.12601", "submitter": "Angus Galloway", "authors": "Angus Galloway and Anna Golubeva and Graham W. Taylor", "title": "Adversarial Examples as an Input-Fault Tolerance Problem", "comments": "NIPS 2018 Workshop on Security and Machine Learning. Source available\n  at https://github.com/uoguelph-mlrg/nips18-secml-advex-input-fault", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the adversarial examples problem in terms of a model's fault\ntolerance with respect to its input. Whereas previous work focuses on\narbitrarily strict threat models, i.e., $\\epsilon$-perturbations, we consider\narbitrary valid inputs and propose an information-based characteristic for\nevaluating tolerance to diverse input faults.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 03:32:44 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Galloway", "Angus", ""], ["Golubeva", "Anna", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1811.12615", "submitter": "Kangcheng Lin", "authors": "Chaofan Chen, Kangcheng Lin, Cynthia Rudin, Yaron Shaposhnik, Sijia\n  Wang, Tong Wang", "title": "An Interpretable Model with Globally Consistent Explanations for Credit\n  Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a possible solution to a public challenge posed by the Fair Isaac\nCorporation (FICO), which is to provide an explainable model for credit risk\nassessment. Rather than present a black box model and explain it afterwards, we\nprovide a globally interpretable model that is as accurate as other neural\nnetworks. Our \"two-layer additive risk model\" is decomposable into subscales,\nwhere each node in the second layer represents a meaningful subscale, and all\nof the nonlinearities are transparent. We provide three types of explanations\nthat are simpler than, but consistent with, the global model. One of these\nexplanation methods involves solving a minimum set cover problem to find\nhigh-support globally-consistent explanations. We present a new online\nvisualization tool to allow users to explore the global model and its\nexplanations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 04:59:00 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Chen", "Chaofan", ""], ["Lin", "Kangcheng", ""], ["Rudin", "Cynthia", ""], ["Shaposhnik", "Yaron", ""], ["Wang", "Sijia", ""], ["Wang", "Tong", ""]]}, {"id": "1811.12624", "submitter": "Elham J. Barezi Ms", "authors": "Elham J. Barezi, Pascale Fung", "title": "Modality-based Factorization for Multimodal Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method, Modality-based Redundancy Reduction Fusion (MRRF),\nfor understanding and modulating the relative contribution of each modality in\nmultimodal inference tasks. This is achieved by obtaining an $(M+1)$-way tensor\nto consider the high-order relationships between $M$ modalities and the output\nlayer of a neural network model. Applying a modality-based tensor factorization\nmethod, which adopts different factors for different modalities, results in\nremoving information present in a modality that can be compensated by other\nmodalities, with respect to model outputs. This helps to understand the\nrelative utility of information in each modality. In addition it leads to a\nless complicated model with less parameters and therefore could be applied as a\nregularizer avoiding overfitting. We have applied this method to three\ndifferent multimodal datasets in sentiment analysis, personality trait\nrecognition, and emotion recognition. We are able to recognize relationships\nand relative importance of different modalities in these tasks and achieves a\n1\\% to 4\\% improvement on several evaluation measures compared to the\nstate-of-the-art for all three tasks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 05:43:10 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 04:15:48 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Barezi", "Elham J.", ""], ["Fung", "Pascale", ""]]}, {"id": "1811.12629", "submitter": "Dianbo Liu Dr", "authors": "Li Huang, Yifeng Yin, Zeng Fu, Shifa Zhang, Hao Deng, Dianbo Liu", "title": "LoAdaBoost: loss-based AdaBoost federated machine learning with reduced\n  computational complexity on IID and non-IID intensive care data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensive care data are valuable for improvement of health care, policy\nmaking and many other purposes. Vast amount of such data are stored in\ndifferent locations, on many different devices and in different data silos.\nSharing data among different sources is a big challenge due to regulatory,\noperational and security reasons. One potential solution is federated machine\nlearning, which is a method that sends machine learning algorithms\nsimultaneously to all data sources, trains models in each source and aggregates\nthe learned models. This strategy allows utilization of valuable data without\nmoving them. One challenge in applying federated machine learning is the\npossibly different distributions of data from diverse sources. To tackle this\nproblem, we proposed an adaptive boosting method named LoAdaBoost that\nincreases the efficiency of federated machine learning. Using intensive care\nunit data from hospitals, we investigated the performance of learning in IID\nand non-IID data distribution scenarios, and showed that the proposed\nLoAdaBoost method achieved higher predictive accuracy with lower computational\ncomplexity than the baseline method.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 06:05:21 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 16:39:50 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 17:17:27 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 06:14:13 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Huang", "Li", ""], ["Yin", "Yifeng", ""], ["Fu", "Zeng", ""], ["Zhang", "Shifa", ""], ["Deng", "Hao", ""], ["Liu", "Dianbo", ""]]}, {"id": "1811.12634", "submitter": "Sooyeon Lee", "authors": "Sooyeon Lee, Huy Kang Kim", "title": "ADSaS: Comprehensive Real-time Anomaly Detection System", "comments": "6 pages, 4 figures, In Proceedings of the 19th World Conference on\n  Information Security and Applications (WISA) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since with massive data growth, the need for autonomous and generic anomaly\ndetection system is increased. However, developing one stand-alone generic\nanomaly detection system that is accurate and fast is still a challenge. In\nthis paper, we propose conventional time-series analysis approaches, the\nSeasonal Autoregressive Integrated Moving Average (SARIMA) model and Seasonal\nTrend decomposition using Loess (STL), to detect complex and various anomalies.\nUsually, SARIMA and STL are used only for stationary and periodic time-series,\nbut by combining, we show they can detect anomalies with high accuracy for data\nthat is even noisy and non-periodic. We compared the algorithm to Long Short\nTerm Memory (LSTM), a deep-learning-based algorithm used for anomaly detection\nsystem. We used a total of seven real-world datasets and four artificial\ndatasets with different time-series properties to verify the performance of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 06:27:44 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Lee", "Sooyeon", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1811.12640", "submitter": "Sudeshna Roy", "authors": "Sudeshna Roy, Meghana Madhyastha, Sheril Lawrence, Vaibhav Rajan", "title": "Inferring Concept Prerequisite Relations from Online Educational\n  Resources", "comments": "Accepted at the AAAI Conference on Innovative Applications of\n  Artificial Intelligence (IAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has rich and rapidly increasing sources of high quality\neducational content. Inferring prerequisite relations between educational\nconcepts is required for modern large-scale online educational technology\napplications such as personalized recommendations and automatic curriculum\ncreation. We present PREREQ, a new supervised learning method for inferring\nconcept prerequisite relations. PREREQ is designed using latent representations\nof concepts obtained from the Pairwise Latent Dirichlet Allocation model, and a\nneural network based on the Siamese network architecture. PREREQ can learn\nunknown concept prerequisites from course prerequisites and labeled concept\nprerequisite data. It outperforms state-of-the-art approaches on benchmark\ndatasets and can effectively learn from very less training data. PREREQ can\nalso use unlabeled video playlists, a steadily growing source of training data,\nto learn concept prerequisites, thus obviating the need for manual annotation\nof course prerequisites.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 06:55:20 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 00:39:00 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Roy", "Sudeshna", ""], ["Madhyastha", "Meghana", ""], ["Lawrence", "Sheril", ""], ["Rajan", "Vaibhav", ""]]}, {"id": "1811.12693", "submitter": "Oliver Joseph David Barrowclough", "authors": "Konstantinos Gavriil, Georg Muntingh and Oliver J. D. Barrowclough", "title": "Void Filling of Digital Elevation Models with Deep Generative Models", "comments": "5 pages; 4 figures; corrected names in references; clarifications\n  regarding the two generators in the paper; added reference (Borji 2018) on\n  GAN evaluation measures; extended future work discussion; changed (Fig. 4.f)\n  to show a failure case", "journal-ref": null, "doi": "10.1109/LGRS.2019.2902222", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, advances in machine learning algorithms, cheap computational\nresources, and the availability of big data have spurred the deep learning\nrevolution in various application domains. In particular, supervised learning\ntechniques in image analysis have led to superhuman performance in various\ntasks, such as classification, localization, and segmentation, while\nunsupervised learning techniques based on increasingly advanced generative\nmodels have been applied to generate high-resolution synthetic images\nindistinguishable from real images.\n  In this paper we consider a state-of-the-art machine learning model for image\ninpainting, namely a Wasserstein Generative Adversarial Network based on a\nfully convolutional architecture with a contextual attention mechanism. We show\nthat this model can successfully be transferred to the setting of digital\nelevation models (DEMs) for the purpose of generating semantically plausible\ndata for filling voids. Training, testing and experimentation is done on\nGeoTIFF data from various regions in Norway, made openly available by the\nNorwegian Mapping Authority.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 10:04:30 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 13:24:22 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Gavriil", "Konstantinos", ""], ["Muntingh", "Georg", ""], ["Barrowclough", "Oliver J. D.", ""]]}, {"id": "1811.12739", "submitter": "Yedid Hoshen", "authors": "Tavi Halperin and Ariel Ephrat and Yedid Hoshen", "title": "Neural separation of observed and unobserved distributions", "comments": "ICML'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating mixed distributions is a long standing challenge for machine\nlearning and signal processing. Most current methods either rely on making\nstrong assumptions on the source distributions or rely on having training\nsamples of each source in the mixture. In this work, we introduce a new\nmethod---Neural Egg Separation---to tackle the scenario of extracting a signal\nfrom an unobserved distribution additively mixed with a signal from an observed\ndistribution. Our method iteratively learns to separate the known distribution\nfrom progressively finer estimates of the unknown distribution. In some\nsettings, Neural Egg Separation is initialization sensitive, we therefore\nintroduce Latent Mixture Masking which ensures a good initialization. Extensive\nexperiments on audio and image separation tasks show that our method\noutperforms current methods that use the same level of supervision, and often\nachieves similar performance to full supervision.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 11:38:54 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 12:17:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Halperin", "Tavi", ""], ["Ephrat", "Ariel", ""], ["Hoshen", "Yedid", ""]]}, {"id": "1811.12752", "submitter": "Debarghya Ghoshdastidar", "authors": "Debarghya Ghoshdastidar, Ulrike von Luxburg", "title": "Practical methods for graph two-sample testing", "comments": "To appear in Neural Information Processing Systems 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing for graphs has been an important tool in applied research\nfields for more than two decades, and still remains a challenging problem as\none often needs to draw inference from few replicates of large graphs. Recent\nstudies in statistics and learning theory have provided some theoretical\ninsights about such high-dimensional graph testing problems, but the\npracticality of the developed theoretical methods remains an open question.\n  In this paper, we consider the problem of two-sample testing of large graphs.\nWe demonstrate the practical merits and limitations of existing theoretical\ntests and their bootstrapped variants. We also propose two new tests based on\nasymptotic distributions. We show that these tests are computationally less\nexpensive and, in some cases, more reliable than the existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 12:04:33 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Ghoshdastidar", "Debarghya", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1811.12783", "submitter": "Shuai Li", "authors": "Shuai Li", "title": "Measure, Manifold, Learning, and Optimization: A Theory Of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal measure-theoretical theory of neural networks (NN) built\non probability coupling theory. Our main contributions are summarized as\nfollows.\n  * Built on the formalism of probability coupling theory, we derive an\nalgorithm framework, named Hierarchical Measure Group and Approximate System\n(HMGAS), nicknamed S-System, that is designed to learn the complex\nhierarchical, statistical dependency in the physical world.\n  * We show that NNs are special cases of S-System when the probability kernels\nassume certain exponential family distributions. Activation Functions are\nderived formally. We further endow geometry on NNs through information\ngeometry, show that intermediate feature spaces of NNs are stochastic\nmanifolds, and prove that \"distance\" between samples is contracted as layers\nstack up.\n  * S-System shows NNs are inherently stochastic, and under a set of realistic\nboundedness and diversity conditions, it enables us to prove that for large\nsize nonlinear deep NNs with a class of losses, including the hinge loss, all\nlocal minima are global minima with zero loss errors, and regions around the\nminima are flat basins where all eigenvalues of Hessians are concentrated\naround zero, using tools and ideas from mean field theory, random matrix\ntheory, and nonlinear operator equations.\n  * S-System, the information-geometry structure and the optimization behaviors\ncombined completes the analog between Renormalization Group (RG) and NNs. It\nshows that a NN is a complex adaptive system that estimates the statistic\ndependency of microscopic object, e.g., pixels, in multiple scales. Unlike\nclear-cut physical quantity produced by RG in physics, e.g., temperature, NNs\nrenormalize/recompose manifolds emerging through learning/optimization that\ndivide the sample space into highly semantically meaningful groups that are\ndictated by supervised labels (in supervised NNs).\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 13:22:01 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Li", "Shuai", ""]]}, {"id": "1811.12799", "submitter": "Anna Guitart", "authors": "Pei Pei Chen, Anna Guitart, Ana Fern\\'andez del R\\'io and \\'Africa\n  Peri\\'a\\~nez", "title": "Customer Lifetime Value in Video Games Using Deep Learning and\n  Parametric Models", "comments": null, "journal-ref": "IEEE International Conference on Big Data (Big Data), p. 2134-2140\n  , 2018", "doi": "10.1109/BigData.2018.8622151", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, video game developers record every virtual action performed by\ntheir players. As each player can remain in the game for years, this results in\nan exceptionally rich dataset that can be used to understand and predict player\nbehavior. In particular, this information may serve to identify the most\nvaluable players and foresee the amount of money they will spend in in-app\npurchases during their lifetime. This is crucial in free-to-play games, where\nup to 50% of the revenue is generated by just around 2% of the players, the\nso-called whales.\n  To address this challenge, we explore how deep neural networks can be used to\npredict customer lifetime value in video games, and compare their performance\nto parametric models such as Pareto/NBD. Our results suggest that convolutional\nneural network structures are the most efficient in predicting the economic\nvalue of individual players. They not only perform better in terms of accuracy,\nbut also scale to big data and significantly reduce computational time, as they\ncan work directly with raw sequential data and thus do not require any feature\nengineering process. This becomes important when datasets are very large, as is\noften the case with video game logs.\n  Moreover, convolutional neural networks are particularly well suited to\nidentify potential whales. Such an early identification is of paramount\nimportance for business purposes, as it would allow developers to implement\nin-game actions aimed at retaining big spenders and maximizing their lifetime,\nwhich would ultimately translate into increased revenue.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 09:41:35 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Chen", "Pei Pei", ""], ["Guitart", "Anna", ""], ["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1811.12801", "submitter": "Vaibhav Kulkarni", "authors": "Vaibhav Kulkarni, Natasa Tagasovska, Thibault Vatter, Benoit Garbinato", "title": "Generative Models for Simulating Mobility Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobility datasets are fundamental for evaluating algorithms pertaining to\ngeographic information systems and facilitating experimental reproducibility.\nBut privacy implications restrict sharing such datasets, as even aggregated\nlocation-data is vulnerable to membership inference attacks. Current synthetic\nmobility dataset generators attempt to superficially match a priori modeled\nmobility characteristics which do not accurately reflect the real-world\ncharacteristics. Modeling human mobility to generate synthetic yet semantically\nand statistically realistic trajectories is therefore crucial for publishing\ntrajectory datasets having satisfactory utility level while preserving user\nprivacy. Specifically, long-range dependencies inherent to human mobility are\nchallenging to capture with both discriminative and generative models. In this\npaper, we benchmark the performance of recurrent neural architectures (RNNs),\ngenerative adversarial networks (GANs) and nonparametric copulas to generate\nsynthetic mobility traces. We evaluate the generated trajectories with respect\nto their geographic and semantic similarity, circadian rhythms, long-range\ndependencies, training and generation time. We also include two sample tests to\nassess statistical similarity between the observed and simulated distributions,\nand we analyze the privacy tradeoffs with respect to membership inference and\nlocation-sequence attacks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 14:14:44 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Kulkarni", "Vaibhav", ""], ["Tagasovska", "Natasa", ""], ["Vatter", "Thibault", ""], ["Garbinato", "Benoit", ""]]}, {"id": "1811.12802", "submitter": "Qiuyi Wu", "authors": "Qiuyi Wu, Ernest Fokoue", "title": "Naive Dictionary On Musical Corpora: From Knowledge Representation To\n  Pattern Recognition", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and develop the novel idea of treating musical\nsheets as literary documents in the traditional text analytics parlance, to\nfully benefit from the vast amount of research already existing in statistical\ntext mining and topic modelling. We specifically introduce the idea of\nrepresenting any given piece of music as a collection of \"musical words\" that\nwe codenamed \"muselets\", which are essentially musical words of various\nlengths. Given the novelty and therefore the extremely difficulty of properly\nforming a complete version of a dictionary of muselets, the present paper\nfocuses on a simpler albeit naive version of the ultimate dictionary, which we\nrefer to as a Naive Dictionary because of the fact that all the words are of\nthe same length. We specifically herein construct a naive dictionary featuring\na corpus made up of African American, Chinese, Japanese and Arabic music, on\nwhich we perform both topic modelling and pattern recognition. Although some of\nthe results based on the Naive Dictionary are reasonably good, we anticipate\nphenomenal predictive performances once we get around to actually building a\nfull scale complete version of our intended dictionary of muselets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 02:10:57 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Wu", "Qiuyi", ""], ["Fokoue", "Ernest", ""]]}, {"id": "1811.12804", "submitter": "Chen Cheng", "authors": "Yuxin Chen, Chen Cheng, Jianqing Fan", "title": "Asymmetry Helps: Eigenvalue and Eigenvector Analyses of Asymmetrically\n  Perturbed Low-Rank Matrices", "comments": "accepted to Annals of Statistics, 2020. 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.NA eess.SP math.IT math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the interplay between statistical asymmetry and\nspectral methods. Suppose we are interested in estimating a rank-1 and\nsymmetric matrix $\\mathbf{M}^{\\star}\\in \\mathbb{R}^{n\\times n}$, yet only a\nrandomly perturbed version $\\mathbf{M}$ is observed. The noise matrix\n$\\mathbf{M}-\\mathbf{M}^{\\star}$ is composed of zero-mean independent (but not\nnecessarily homoscedastic) entries and is, therefore, not symmetric in general.\nThis might arise, for example, when we have two independent samples for each\nentry of $\\mathbf{M}^{\\star}$ and arrange them into an {\\em asymmetric} data\nmatrix $\\mathbf{M}$. The aim is to estimate the leading eigenvalue and\neigenvector of $\\mathbf{M}^{\\star}$. We demonstrate that the leading eigenvalue\nof the data matrix $\\mathbf{M}$ can be $O(\\sqrt{n})$ times more accurate --- up\nto some log factor --- than its (unadjusted) leading singular value in\neigenvalue estimation. Further, the perturbation of any linear form of the\nleading eigenvector of $\\mathbf{M}$ --- say, entrywise eigenvector perturbation\n--- is provably well-controlled. This eigen-decomposition approach is fully\nadaptive to heteroscedasticity of noise without the need of careful bias\ncorrection or any prior knowledge about the noise variance. We also provide\npartial theory for the more general rank-$r$ case. The takeaway message is\nthis: arranging the data samples in an asymmetric manner and performing\neigen-decomposition could sometimes be beneficial.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 14:18:26 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 14:50:03 GMT"}, {"version": "v3", "created": "Tue, 1 Jan 2019 07:52:48 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 01:25:22 GMT"}, {"version": "v5", "created": "Sun, 23 Feb 2020 08:41:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chen", "Yuxin", ""], ["Cheng", "Chen", ""], ["Fan", "Jianqing", ""]]}, {"id": "1811.12808", "submitter": "Sebastian Raschka", "authors": "Sebastian Raschka", "title": "Model Evaluation, Model Selection, and Algorithm Selection in Machine\n  Learning", "comments": "v3 (Nov 2020): Fixes SD from pooled proportions in Sec 4.2 Fixes\n  exact binomial p-value in Sec 4.4 by using max(B, C) instead of B in the sum.\n  Fixes typo using wrong symbols in Looney's F-test's SSA in Sec 4.7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correct use of model evaluation, model selection, and algorithm selection\ntechniques is vital in academic machine learning research as well as in many\nindustrial settings. This article reviews different techniques that can be used\nfor each of these three subtasks and discusses the main advantages and\ndisadvantages of each technique with references to theoretical and empirical\nstudies. Further, recommendations are given to encourage best yet feasible\npractices in research and applications of machine learning. Common methods such\nas the holdout method for model evaluation and selection are covered, which are\nnot recommended when working with small datasets. Different flavors of the\nbootstrap technique are introduced for estimating the uncertainty of\nperformance estimates, as an alternative to confidence intervals via normal\napproximation if bootstrapping is computationally feasible. Common\ncross-validation techniques such as leave-one-out cross-validation and k-fold\ncross-validation are reviewed, the bias-variance trade-off for choosing k is\ndiscussed, and practical tips for the optimal choice of k are given based on\nempirical evidence. Different statistical tests for algorithm comparisons are\npresented, and strategies for dealing with multiple comparisons such as omnibus\ntests and multiple-comparison corrections are discussed. Finally, alternative\nmethods for algorithm selection, such as the combined F-test 5x2\ncross-validation and nested cross-validation, are recommended for comparing\nmachine learning algorithms when datasets are small.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 15:36:42 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 02:03:11 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 00:59:17 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Raschka", "Sebastian", ""]]}, {"id": "1811.12809", "submitter": "Luis Lamb", "authors": "Felipe Grando and Luis C. Lamb", "title": "Computing Vertex Centrality Measures in Massive Real Networks with a\n  Neural Learning Model", "comments": "8 pages, 5 tables, 2 figures, version accepted at IJCNN 2018. arXiv\n  admin note: text overlap with arXiv:1810.11760", "journal-ref": "IEEE International Joint Conference on Neural Networks, IJCNN\n  2018: 1-8", "doi": "10.1109/IJCNN.2018.8489690", "report-no": null, "categories": "cs.SI cs.LG cs.NE cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertex centrality measures are a multi-purpose analysis tool, commonly used\nin many application environments to retrieve information and unveil knowledge\nfrom the graphs and network structural properties. However, the algorithms of\nsuch metrics are expensive in terms of computational resources when running\nreal-time applications or massive real world networks. Thus, approximation\ntechniques have been developed and used to compute the measures in such\nscenarios. In this paper, we demonstrate and analyze the use of neural network\nlearning algorithms to tackle such task and compare their performance in terms\nof solution quality and computation time with other techniques from the\nliterature. Our work offers several contributions. We highlight both the pros\nand cons of approximating centralities though neural learning. By empirical\nmeans and statistics, we then show that the regression model generated with a\nfeedforward neural networks trained by the Levenberg-Marquardt algorithm is not\nonly the best option considering computational resources, but also achieves the\nbest solution quality for relevant applications and large-scale networks.\nKeywords: Vertex Centrality Measures, Neural Networks, Complex Network Models,\nMachine Learning, Regression Model\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 03:37:44 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Grando", "Felipe", ""], ["Lamb", "Luis C.", ""]]}, {"id": "1811.12823", "submitter": "Daniil Polykovskiy", "authors": "Daniil Polykovskiy, Alexander Zhebrak, Benjamin Sanchez-Lengeling,\n  Sergey Golovanov, Oktai Tatanov, Stanislav Belyaev, Rauf Kurbanov, Aleksey\n  Artamonov, Vladimir Aladinskiy, Mark Veselov, Artur Kadurin, Simon Johansson,\n  Hongming Chen, Sergey Nikolenko, Alan Aspuru-Guzik, Alex Zhavoronkov", "title": "Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generative models are becoming a tool of choice for exploring the molecular\nspace. These models learn on a large training dataset and produce novel\nmolecular structures with similar properties. Generated structures can be\nutilized for virtual screening or training semi-supervised predictive models in\nthe downstream tasks. While there are plenty of generative models, it is\nunclear how to compare and rank them. In this work, we introduce a benchmarking\nplatform called Molecular Sets (MOSES) to standardize training and comparison\nof molecular generative models. MOSES provides a training and testing datasets,\nand a set of metrics to evaluate the quality and diversity of generated\nstructures. We have implemented and compared several molecular generation\nmodels and suggest to use our results as reference points for further\nadvancements in generative chemistry research. The platform and source code are\navailable at https://github.com/molecularsets/moses.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 08:48:20 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 20:03:21 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 07:23:45 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 16:15:59 GMT"}, {"version": "v5", "created": "Wed, 28 Oct 2020 14:11:16 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Polykovskiy", "Daniil", ""], ["Zhebrak", "Alexander", ""], ["Sanchez-Lengeling", "Benjamin", ""], ["Golovanov", "Sergey", ""], ["Tatanov", "Oktai", ""], ["Belyaev", "Stanislav", ""], ["Kurbanov", "Rauf", ""], ["Artamonov", "Aleksey", ""], ["Aladinskiy", "Vladimir", ""], ["Veselov", "Mark", ""], ["Kadurin", "Artur", ""], ["Johansson", "Simon", ""], ["Chen", "Hongming", ""], ["Nikolenko", "Sergey", ""], ["Aspuru-Guzik", "Alan", ""], ["Zhavoronkov", "Alex", ""]]}, {"id": "1811.12852", "submitter": "Odysseas Kanavetas", "authors": "Apostolos N. Burnetas, Odysseas Kanavetas, Michael N. Katehakis", "title": "Optimal Data Driven Resource Allocation under Multi-Armed Bandit\n  Observations", "comments": "arXiv admin note: text overlap with arXiv:1509.02857", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the first asymptotically optimal strategy for a multi\narmed bandit (MAB) model under side constraints. The side constraints model\nsituations in which bandit activations are limited by the availability of\ncertain resources that are replenished at a constant rate. The main result\ninvolves the derivation of an asymptotic lower bound for the regret of feasible\nuniformly fast policies and the construction of policies that achieve this\nlower bound, under pertinent conditions. Further, we provide the explicit form\nof such policies for the case in which the unknown distributions are Normal\nwith unknown means and known variances, for the case of Normal distributions\nwith unknown means and unknown variances and for the case of arbitrary discrete\ndistributions with finite support.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 17:28:31 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 05:21:13 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Burnetas", "Apostolos N.", ""], ["Kanavetas", "Odysseas", ""], ["Katehakis", "Michael N.", ""]]}, {"id": "1811.12911", "submitter": "Mehdi Shafiei", "authors": "Mehdi Shafiei, Aaron Liu, Gerard Ledwich, Geoffery Walker, Gian-Marco\n  Morosini, Jack Terry", "title": "Solar Enablement Initiative in Australia: Report on Efficiently\n  Identifying Critical Cases for Evaluating the Voltage Impact of Large PV\n  Investment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing quantity of PV generation connected to distribution networks\nis creating challenges in maintaining and controlling voltages in those\ndistribution networks. Determining the maximum hosting capacity for new PV\ninstallations based on the historical data is an essential task for\ndistribution networks. Analyzing all historical data in large distribution\nnetworks is impractical. Therefore, this paper focuses on how to time\nefficiently identify the critical cases for evaluating the voltage impacts of\nthe new large PV applications in medium voltage (MV) distribution networks. A\nsystematic approach is proposed to cluster medium voltage nodes based on\nelectrical adjacency and time blocks. MV nodes are clustered along with the\nvoltage magnitudes and time blocks. Critical cases of each cluster can be used\nfor further power flow study. This method is scalable and can time efficiently\nidentify cases for evaluating PV investment on medium voltage networks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 01:10:36 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Shafiei", "Mehdi", ""], ["Liu", "Aaron", ""], ["Ledwich", "Gerard", ""], ["Walker", "Geoffery", ""], ["Morosini", "Gian-Marco", ""], ["Terry", "Jack", ""]]}, {"id": "1811.12929", "submitter": "Ondrej Biza", "authors": "Ondrej Biza and Robert Platt", "title": "Online Abstraction with MDP Homomorphisms for Deep Learning", "comments": null, "journal-ref": "Proceedings of the 18th International Conference on Autonomous\n  Agents and MultiAgent Systems (AAMAS '19). 2019. 1125 - 1133", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction of Markov Decision Processes is a useful tool for solving complex\nproblems, as it can ignore unimportant aspects of an environment, simplifying\nthe process of learning an optimal policy. In this paper, we propose a new\nalgorithm for finding abstract MDPs in environments with continuous state\nspaces. It is based on MDP homomorphisms, a structure-preserving mapping\nbetween MDPs. We demonstrate our algorithm's ability to learn abstractions from\ncollected experience and show how to reuse the abstractions to guide\nexploration in new tasks the agent encounters. Our novel task transfer method\noutperforms baselines based on a deep Q-network in the majority of our\nexperiments. The source code is at https://github.com/ondrejba/aamas_19.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 18:29:29 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 11:20:50 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Biza", "Ondrej", ""], ["Platt", "Robert", ""]]}, {"id": "1811.12932", "submitter": "Arthur Pesah", "authors": "Arthur Pesah, Antoine Wehenkel, Gilles Louppe", "title": "Recurrent machines for likelihood-free inference", "comments": "2nd Workshop on Meta-Learning at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ph physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Likelihood-free inference is concerned with the estimation of the parameters\nof a non-differentiable stochastic simulator that best reproduce real\nobservations. In the absence of a likelihood function, most of the existing\ninference methods optimize the simulator parameters through a handcrafted\niterative procedure that tries to make the simulated data more similar to the\nobservations. In this work, we explore whether meta-learning can be used in the\nlikelihood-free context, for learning automatically from data an iterative\noptimization procedure that would solve likelihood-free inference problems. We\ndesign a recurrent inference machine that learns a sequence of parameter\nupdates leading to good parameter estimates, without ever specifying some\nexplicit notion of divergence between the simulated data and the real data\ndistributions. We demonstrate our approach on toy simulators, showing promising\nresults both in terms of performance and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 18:39:12 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 14:00:10 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Pesah", "Arthur", ""], ["Wehenkel", "Antoine", ""], ["Louppe", "Gilles", ""]]}, {"id": "1811.12938", "submitter": "Marek Rei", "authors": "Marek Rei, Joshua Oppenheimer, Marek Sirendi", "title": "Advance Prediction of Ventricular Tachyarrhythmias using Patient\n  Metadata and Multi-Task Networks", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/158", "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel neural network architecture for the prediction of\nventricular tachyarrhythmias. The model receives input features that capture\nthe change in RR intervals and ectopic beats, along with features based on\nheart rate variability and frequency analysis. Patient age is also included as\na trainable embedding, while the whole network is optimized with multi-task\nobjectives. Each of these modifications provides a consistent improvement to\nthe model performance, achieving 74.02% prediction accuracy and 77.22%\nspecificity 60 seconds in advance of the episode.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 18:51:41 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Rei", "Marek", ""], ["Oppenheimer", "Joshua", ""], ["Sirendi", "Marek", ""]]}, {"id": "1811.12941", "submitter": "Kai Rothauge", "authors": "Noah Golmant and Nikita Vemuri and Zhewei Yao and Vladimir Feinberg\n  and Amir Gholami and Kai Rothauge and Michael W. Mahoney and Joseph Gonzalez", "title": "On the Computational Inefficiency of Large Batch Sizes for Stochastic\n  Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the mini-batch size for stochastic gradient descent offers\nsignificant opportunities to reduce wall-clock training time, but there are a\nvariety of theoretical and systems challenges that impede the widespread\nsuccess of this technique. We investigate these issues, with an emphasis on\ntime to convergence and total computational cost, through an extensive\nempirical analysis of network training across several architectures and problem\ndomains, including image classification, image segmentation, and language\nmodeling. Although it is common practice to increase the batch size in order to\nfully exploit available computational resources, we find a substantially more\nnuanced picture. Our main finding is that across a wide range of network\narchitectures and problem domains, increasing the batch size beyond a certain\npoint yields no decrease in wall-clock time to convergence for \\emph{either}\ntrain or test loss. This batch size is usually substantially below the capacity\nof current systems. We show that popular training strategies for large batch\nsize optimization begin to fail before we can populate all available compute\nresources, and we show that the point at which these methods break down depends\nmore on attributes like model architecture and data complexity than it does\ndirectly on the size of the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 18:58:59 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Golmant", "Noah", ""], ["Vemuri", "Nikita", ""], ["Yao", "Zhewei", ""], ["Feinberg", "Vladimir", ""], ["Gholami", "Amir", ""], ["Rothauge", "Kai", ""], ["Mahoney", "Michael W.", ""], ["Gonzalez", "Joseph", ""]]}]