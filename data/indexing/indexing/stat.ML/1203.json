[{"id": "1203.0038", "submitter": "Michael Alan Dewar", "authors": "Michael Dewar, Chris Wiggins, Frank Wood", "title": "Inference in Hidden Markov Models with Explicit State Duration\n  Distributions", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2012.2184795", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter we borrow from the inference techniques developed for\nunbounded state-cardinality (nonparametric) variants of the HMM and use them to\ndevelop a tuning-parameter free, black-box inference procedure for\nExplicit-state-duration hidden Markov models (EDHMM). EDHMMs are HMMs that have\nlatent states consisting of both discrete state-indicator and discrete\nstate-duration random variables. In contrast to the implicit geometric state\nduration distribution possessed by the standard HMM, EDHMMs allow the direct\nparameterisation and estimation of per-state duration distributions. As most\nduration distributions are defined over the positive integers, truncation or\nother approximations are usually required to perform EDHMM inference.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 22:40:56 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Dewar", "Michael", ""], ["Wiggins", "Chris", ""], ["Wood", "Frank", ""]]}, {"id": "1203.0106", "submitter": "Francois Caron", "authors": "Fran\\c{c}ois Caron (INRIA Bordeaux - Sud-Ouest, IMB), Luke Bornn\n  (Statistics), Arnaud Doucet", "title": "Sparsity-Promoting Bayesian Dynamic Linear Models", "comments": null, "journal-ref": "N&deg; RR-7895 (2012)", "doi": null, "report-no": "RR-7895", "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity-promoting priors have become increasingly popular over recent years\ndue to an increased number of regression and classification applications\ninvolving a large number of predictors. In time series applications where\nobservations are collected over time, it is often unrealistic to assume that\nthe underlying sparsity pattern is fixed. We propose here an original class of\nflexible Bayesian linear models for dynamic sparsity modelling. The proposed\nclass of models expands upon the existing Bayesian literature on sparse\nregression using generalized multivariate hyperbolic distributions. The\nproperties of the models are explored through both analytic results and\nsimulation studies. We demonstrate the model on a financial application where\nit is shown that it accurately represents the patterns seen in the analysis of\nstock and derivative data, and is able to detect major events by filtering an\nartificial portfolio of assets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2012 07:39:21 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Caron", "Fran\u00e7ois", "", "INRIA Bordeaux - Sud-Ouest, IMB"], ["Bornn", "Luke", "", "Statistics"], ["Doucet", "Arnaud", ""]]}, {"id": "1203.0117", "submitter": "Satoshi Hara", "authors": "Satoshi Hara, Takashi Washio", "title": "Learning a Common Substructure of Multiple Graphical Gaussian Models", "comments": "47 pages, 6 figures, elsarticle.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Properties of data are frequently seen to vary depending on the sampled\nsituations, which usually changes along a time evolution or owing to\nenvironmental effects. One way to analyze such data is to find invariances, or\nrepresentative features kept constant over changes. The aim of this paper is to\nidentify one such feature, namely interactions or dependencies among variables\nthat are common across multiple datasets collected under different conditions.\nTo that end, we propose a common substructure learning (CSSL) framework based\non a graphical Gaussian model. We further present a simple learning algorithm\nbased on the Dual Augmented Lagrangian and the Alternating Direction Method of\nMultipliers. We confirm the performance of CSSL over other existing techniques\nin finding unchanging dependency structures in multiple datasets through\nnumerical simulations on synthetic data and through a real world application to\nanomaly detection in automobile sensors.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2012 08:34:30 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2012 13:45:58 GMT"}, {"version": "v3", "created": "Tue, 25 Sep 2012 03:44:33 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Hara", "Satoshi", ""], ["Washio", "Takashi", ""]]}, {"id": "1203.0203", "submitter": "Gabriel Dulac-Arnold", "authors": "Gabriel Dulac-Arnold, Ludovic Denoyer, Philippe Preux, Patrick\n  Gallinari", "title": "Fast Reinforcement Learning with Large Action Sets using\n  Error-Correcting Output Codes for MDP Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Reinforcement Learning in real-world scenarios is strongly limited\nby issues of scale. Most RL learning algorithms are unable to deal with\nproblems composed of hundreds or sometimes even dozens of possible actions, and\ntherefore cannot be applied to many real-world problems. We consider the RL\nproblem in the supervised classification framework where the optimal policy is\nobtained through a multiclass classifier, the set of classes being the set of\nactions of the problem. We introduce error-correcting output codes (ECOCs) in\nthis setting and propose two new methods for reducing complexity when using\nrollouts-based approaches. The first method consists in using an ECOC-based\nclassifier as the multiclass classifier, reducing the learning complexity from\nO(A2) to O(Alog(A)). We then propose a novel method that profits from the\nECOC's coding dictionary to split the initial MDP into O(log(A)) seperate\ntwo-action MDPs. This second method reduces learning complexity even further,\nfrom O(A2) to O(log(A)), thus rendering problems with large action sets\ntractable. We finish by experimentally demonstrating the advantages of our\napproach on a set of benchmark problems, both in speed and performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 17:23:15 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Dulac-Arnold", "Gabriel", ""], ["Denoyer", "Ludovic", ""], ["Preux", "Philippe", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1203.0453", "submitter": "Song Liu Mr", "authors": "Song Liu, Makoto Yamada, Nigel Collier, Masashi Sugiyama", "title": "Change-Point Detection in Time-Series Data by Relative Density-Ratio\n  Estimation", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2013.01.012", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of change-point detection is to discover abrupt property\nchanges lying behind time-series data. In this paper, we present a novel\nstatistical change-point detection algorithm based on non-parametric divergence\nestimation between time-series samples from two retrospective segments. Our\nmethod uses the relative Pearson divergence as a divergence measure, and it is\naccurately and efficiently estimated by a method of direct density-ratio\nestimation. Through experiments on artificial and real-world datasets including\nhuman-activity sensing, speech, and Twitter messages, we demonstrate the\nusefulness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2012 13:12:03 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 06:44:58 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Liu", "Song", ""], ["Yamada", "Makoto", ""], ["Collier", "Nigel", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1203.0565", "submitter": "Taiji Suzuki", "authors": "Taiji Suzuki, Masashi Sugiyama", "title": "Fast learning rate of multiple kernel learning: Trade-off between\n  sparsity and smoothness", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1095 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org). arXiv admin note: text overlap with\n  arXiv:1103.0431", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1381-1405", "doi": "10.1214/13-AOS1095", "report-no": "IMS-AOS-AOS1095", "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the learning rate of multiple kernel learning (MKL) with\n$\\ell_1$ and elastic-net regularizations. The elastic-net regularization is a\ncomposition of an $\\ell_1$-regularizer for inducing the sparsity and an\n$\\ell_2$-regularizer for controlling the smoothness. We focus on a sparse\nsetting where the total number of kernels is large, but the number of nonzero\ncomponents of the ground truth is relatively small, and show sharper\nconvergence rates than the learning rates have ever shown for both $\\ell_1$ and\nelastic-net regularizations. Our analysis reveals some relations between the\nchoice of a regularization function and the performance. If the ground truth is\nsmooth, we show a faster convergence rate for the elastic-net regularization\nwith less conditions than $\\ell_1$-regularization; otherwise, a faster\nconvergence rate for the $\\ell_1$-regularization is shown.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2012 20:58:11 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2013 05:13:06 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Suzuki", "Taiji", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1203.0683", "submitter": "Daniel Hsu", "authors": "Animashree Anandkumar, Daniel Hsu, Sham M. Kakade", "title": "A Method of Moments for Mixture Models and Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture models are a fundamental tool in applied statistics and machine\nlearning for treating data taken from multiple subpopulations. The current\npractice for estimating the parameters of such models relies on local search\nheuristics (e.g., the EM algorithm) which are prone to failure, and existing\nconsistent methods are unfavorable due to their high computational and sample\ncomplexity which typically scale exponentially with the number of mixture\ncomponents. This work develops an efficient method of moments approach to\nparameter estimation for a broad class of high-dimensional mixture models with\nmany components, including multi-view mixtures of Gaussians (such as mixtures\nof axis-aligned Gaussians) and hidden Markov models. The new method leads to\nrigorous unsupervised learning results for mixture models that were not\nachieved by previous works; and, because of its simplicity, it offers a viable\nalternative to EM for practical deployment.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2012 20:55:54 GMT"}, {"version": "v2", "created": "Fri, 25 May 2012 03:12:28 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2012 21:41:59 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Anandkumar", "Animashree", ""], ["Hsu", "Daniel", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1203.0697", "submitter": "Animashree Anandkumar", "authors": "A. Anandkumar, D. Hsu, F. Huang and S. M. Kakade", "title": "Learning High-Dimensional Mixtures of Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unsupervised estimation of mixtures of discrete graphical models,\nwhere the class variable corresponding to the mixture components is hidden and\neach mixture component over the observed variables can have a potentially\ndifferent Markov graph structure and parameters. We propose a novel approach\nfor estimating the mixture components, and our output is a tree-mixture model\nwhich serves as a good approximation to the underlying graphical model mixture.\nOur method is efficient when the union graph, which is the union of the Markov\ngraphs of the mixture components, has sparse vertex separators between any pair\nof observed variables. This includes tree mixtures and mixtures of bounded\ndegree graphs. For such models, we prove that our method correctly recovers the\nunion graph structure and the tree structures corresponding to\nmaximum-likelihood tree approximations of the mixture components. The sample\nand computational complexities of our method scale as $\\poly(p, r)$, for an\n$r$-component mixture of $p$-variate graphical models. We further extend our\nresults to the case when the union graph has sparse local separators between\nany pair of observed variables, such as mixtures of locally tree-like graphs,\nand the mixture components are in the regime of correlation decay.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2012 01:19:25 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2012 18:54:30 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Anandkumar", "A.", ""], ["Hsu", "D.", ""], ["Huang", "F.", ""], ["Kakade", "S. M.", ""]]}, {"id": "1203.0786", "submitter": "Michael Mahoney", "authors": "Michael W. Mahoney", "title": "Approximate Computation and Implicit Regularization for Very Large-scale\n  Data Analysis", "comments": "To appear in the Proceedings of the 2012 ACM Symposium on Principles\n  of Database Systems (PODS 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database theory and database practice are typically the domain of computer\nscientists who adopt what may be termed an algorithmic perspective on their\ndata. This perspective is very different than the more statistical perspective\nadopted by statisticians, scientific computers, machine learners, and other who\nwork on what may be broadly termed statistical data analysis. In this article,\nI will address fundamental aspects of this algorithmic-statistical disconnect,\nwith an eye to bridging the gap between these two very different approaches. A\nconcept that lies at the heart of this disconnect is that of statistical\nregularization, a notion that has to do with how robust is the output of an\nalgorithm to the noise properties of the input data. Although it is nearly\ncompletely absent from computer science, which historically has taken the input\ndata as given and modeled algorithms discretely, regularization in one form or\nanother is central to nearly every application domain that applies algorithms\nto noisy data. By using several case studies, I will illustrate, both\ntheoretically and empirically, the nonobvious fact that approximate\ncomputation, in and of itself, can implicitly lead to statistical\nregularization. This and other recent work suggests that, by exploiting in a\nmore principled way the statistical properties implicit in worst-case\nalgorithms, one can in many cases satisfy the bicriteria of having algorithms\nthat are scalable to very large-scale databases and that also have good\ninferential or predictive properties.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2012 23:29:06 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Mahoney", "Michael W.", ""]]}, {"id": "1203.0970", "submitter": "Yuyang Wang", "authors": "Yuyang Wang, Roni Khardon, Pavlos Protopapas", "title": "Infinite Shift-invariant Grouped Multi-task Learning for Gaussian\n  Processes", "comments": "This is an extended version of our ECML 2010 paper entitled\n  \"Shift-invariant Grouped Multi-task Learning for Gaussian Processes\"; ECML\n  PKDD'10 Proceedings of the 2010 European conference on Machine learning and\n  knowledge discovery in databases: Part III", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning leverages shared information among data sets to improve\nthe learning performance of individual tasks. The paper applies this framework\nfor data where each task is a phase-shifted periodic time series. In\nparticular, we develop a novel Bayesian nonparametric model capturing a mixture\nof Gaussian processes where each task is a sum of a group-specific function and\na component capturing individual variation, in addition to each task being\nphase shifted. We develop an efficient \\textsc{em} algorithm to learn the\nparameters of the model. As a special case we obtain the Gaussian mixture model\nand \\textsc{em} algorithm for phased-shifted periodic time series. Furthermore,\nwe extend the proposed model by using a Dirichlet Process prior and thereby\nleading to an infinite mixture model that is capable of doing automatic model\nselection. A Variational Bayesian approach is developed for inference in this\nmodel. Experiments in regression, classification and class discovery\ndemonstrate the performance of the proposed models using both synthetic data\nand real-world time series data from astrophysics. Our methods are particularly\nuseful when the time series are sparsely and non-synchronously sampled.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 17:07:10 GMT"}, {"version": "v2", "created": "Mon, 20 May 2013 04:07:12 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Wang", "Yuyang", ""], ["Khardon", "Roni", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "1203.1005", "submitter": "Ehsan Elhamifar", "authors": "Ehsan Elhamifar and Rene Vidal", "title": "Sparse Subspace Clustering: Algorithm, Theory, and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.IT cs.LG math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world problems, we are dealing with collections of\nhigh-dimensional data, such as images, videos, text and web documents, DNA\nmicroarray data, and more. Often, high-dimensional data lie close to\nlow-dimensional structures corresponding to several classes or categories the\ndata belongs to. In this paper, we propose and study an algorithm, called\nSparse Subspace Clustering (SSC), to cluster data points that lie in a union of\nlow-dimensional subspaces. The key idea is that, among infinitely many possible\nrepresentations of a data point in terms of other points, a sparse\nrepresentation corresponds to selecting a few points from the same subspace.\nThis motivates solving a sparse optimization program whose solution is used in\na spectral clustering framework to infer the clustering of data into subspaces.\nSince solving the sparse optimization program is in general NP-hard, we\nconsider a convex relaxation and show that, under appropriate conditions on the\narrangement of subspaces and the distribution of data, the proposed\nminimization program succeeds in recovering the desired sparse representations.\nThe proposed algorithm can be solved efficiently and can handle data points\nnear the intersections of subspaces. Another key advantage of the proposed\nalgorithm with respect to the state of the art is that it can deal with data\nnuisances, such as noise, sparse outlying entries, and missing entries,\ndirectly by incorporating the model of the data into the sparse optimization\nprogram. We demonstrate the effectiveness of the proposed algorithm through\nexperiments on synthetic data as well as the two real-world problems of motion\nsegmentation and face clustering.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 18:58:32 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2012 17:29:45 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2013 03:22:00 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Elhamifar", "Ehsan", ""], ["Vidal", "Rene", ""]]}, {"id": "1203.1007", "submitter": "Stephane Ross", "authors": "Stephane Ross, J. Andrew Bagnell", "title": "Agnostic System Identification for Model-Based Reinforcement Learning", "comments": "8 pages, published in ICML 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in control is to learn a model of a system from\nobservations that is useful for controller synthesis. To provide good\nperformance guarantees, existing methods must assume that the real system is in\nthe class of models considered during learning. We present an iterative method\nwith strong guarantees even in the agnostic case where the system is not in the\nclass. In particular, we show that any no-regret online learning algorithm can\nbe used to obtain a near-optimal policy, provided some model achieves low\ntraining error and access to a good exploration distribution. Our approach\napplies to both discrete and continuous domains. We demonstrate its efficacy\nand scalability on a challenging helicopter domain from the literature.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 18:58:49 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2012 13:48:40 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Ross", "Stephane", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1203.1065", "submitter": "Giovanni Montana", "authors": "Brian McWilliams and Giovanni Montana", "title": "Subspace clustering of high-dimensional data: a predictive approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several application domains, high-dimensional observations are collected\nand then analysed in search for naturally occurring data clusters which might\nprovide further insights about the nature of the problem. In this paper we\ndescribe a new approach for partitioning such high-dimensional data. Our\nassumption is that, within each cluster, the data can be approximated well by a\nlinear subspace estimated by means of a principal component analysis (PCA). The\nproposed algorithm, Predictive Subspace Clustering (PSC) partitions the data\ninto clusters while simultaneously estimating cluster-wise PCA parameters. The\nalgorithm minimises an objective function that depends upon a new measure of\ninfluence for PCA models. A penalised version of the algorithm is also\ndescribed for carrying our simultaneous subspace clustering and variable\nselection. The convergence of PSC is discussed in detail, and extensive\nsimulation results and comparisons to competing methods are presented. The\ncomparative performance of PSC has been assessed on six real gene expression\ndata sets for which PSC often provides state-of-art results.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 22:10:02 GMT"}], "update_date": "2012-03-07", "authors_parsed": [["McWilliams", "Brian", ""], ["Montana", "Giovanni", ""]]}, {"id": "1203.1078", "submitter": "Pritam Ranjan", "authors": "Hugh Chipman, Pritam Ranjan and Weiwei Wang", "title": "Sequential Design for Computer Experiments with a Flexible Bayesian\n  Additive Model", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer experiments, a mathematical model implemented on a computer is\nused to represent complex physical phenomena. These models, known as computer\nsimulators, enable experimental study of a virtual representation of the\ncomplex phenomena. Simulators can be thought of as complex functions that take\nmany inputs and provide an output. Often these simulators are themselves\nexpensive to compute, and may be approximated by \"surrogate models\" such as\nstatistical regression models. In this paper we consider a new kind of\nsurrogate model, a Bayesian ensemble of trees (Chipman et al. 2010), with the\nspecific goal of learning enough about the simulator that a particular feature\nof the simulator can be estimated. We focus on identifying the simulator's\nglobal minimum. Utilizing the Bayesian version of the Expected Improvement\ncriterion (Jones et al. 1998), we show that this ensemble is particularly\neffective when the simulator is ill-behaved, exhibiting nonstationarity or\nabrupt changes in the response. A number of illustrations of the approach are\ngiven, including a tidal power application.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2012 00:45:50 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2012 10:46:44 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Chipman", "Hugh", ""], ["Ranjan", "Pritam", ""], ["Wang", "Weiwei", ""]]}, {"id": "1203.1269", "submitter": "Pritam Ranjan", "authors": "Mark Franey, Pritam Ranjan, and Hugh Chipman", "title": "A Short Note on Gaussian Process Modeling for Large Datasets using\n  Graphics Processing Units", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graphics processing unit (GPU) has emerged as a powerful and cost\neffective processor for general performance computing. GPUs are capable of an\norder of magnitude more floating-point operations per second as compared to\nmodern central processing units (CPUs), and thus provide a great deal of\npromise for computationally intensive statistical applications. Fitting complex\nstatistical models with a large number of parameters and/or for large datasets\nis often very computationally expensive. In this study, we focus on Gaussian\nprocess (GP) models -- statistical models commonly used for emulating expensive\ncomputer simulators. We demonstrate that the computational cost of implementing\nGP models can be significantly reduced by using a CPU+GPU heterogeneous\ncomputing system over an analogous implementation on a traditional computing\nsystem with no GPU acceleration. Our small study suggests that GP models are\nfertile ground for further implementation on CPU+GPU systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2012 18:19:10 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2012 21:13:38 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Franey", "Mark", ""], ["Ranjan", "Pritam", ""], ["Chipman", "Hugh", ""]]}, {"id": "1203.1365", "submitter": "Matthew Johnson", "authors": "Matthew J. Johnson and Alan S. Willsky", "title": "Bayesian Nonparametric Hidden Semi-Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is much interest in the Hierarchical Dirichlet Process Hidden Markov\nModel (HDP-HMM) as a natural Bayesian nonparametric extension of the ubiquitous\nHidden Markov Model for learning from sequential and time-series data. However,\nin many settings the HDP-HMM's strict Markovian constraints are undesirable,\nparticularly if we wish to learn or encode non-geometric state durations. We\ncan extend the HDP-HMM to capture such structure by drawing upon\nexplicit-duration semi-Markovianity, which has been developed mainly in the\nparametric frequentist setting, to allow construction of highly interpretable\nmodels that admit natural prior information on state durations.\n  In this paper we introduce the explicit-duration Hierarchical Dirichlet\nProcess Hidden semi-Markov Model (HDP-HSMM) and develop sampling algorithms for\nefficient posterior inference. The methods we introduce also provide new\nmethods for sampling inference in the finite Bayesian HSMM. Our modular Gibbs\nsampling methods can be embedded in samplers for larger hierarchical Bayesian\nmodels, adding semi-Markov chain modeling as another tool in the Bayesian\ninference toolbox. We demonstrate the utility of the HDP-HSMM and our inference\nmethods on both synthetic and real experiments.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 01:53:14 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2012 22:21:25 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Johnson", "Matthew J.", ""], ["Willsky", "Alan S.", ""]]}, {"id": "1203.1515", "submitter": "Azadeh Khaleghi", "authors": "Azadeh Khaleghi and Daniil Ryabko", "title": "Multiple Change Point Estimation in Stationary Ergodic Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a heterogeneous time-series sample, the objective is to find points in\ntime (called change points) where the probability distribution generating the\ndata has changed. The data are assumed to have been generated by arbitrary\nunknown stationary ergodic distributions. No modelling, independence or mixing\nassumptions are made. A novel, computationally efficient, nonparametric method\nis proposed, and is shown to be asymptotically consistent in this general\nframework. The theoretical results are complemented with experimental\nevaluations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 16:09:24 GMT"}, {"version": "v10", "created": "Mon, 11 May 2015 23:41:32 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2012 17:34:47 GMT"}, {"version": "v3", "created": "Mon, 14 May 2012 23:43:40 GMT"}, {"version": "v4", "created": "Thu, 17 May 2012 20:28:34 GMT"}, {"version": "v5", "created": "Wed, 24 Oct 2012 13:06:42 GMT"}, {"version": "v6", "created": "Thu, 25 Oct 2012 13:35:05 GMT"}, {"version": "v7", "created": "Fri, 26 Oct 2012 15:19:50 GMT"}, {"version": "v8", "created": "Sun, 12 May 2013 00:08:12 GMT"}, {"version": "v9", "created": "Tue, 14 May 2013 10:28:30 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Khaleghi", "Azadeh", ""], ["Ryabko", "Daniil", ""]]}, {"id": "1203.1570", "submitter": "Gonzalo Mateos", "authors": "Morteza Mardani, Gonzalo Mateos, and Georgios B. Giannakis", "title": "In-network Sparsity-regularized Rank Minimization: Algorithms and\n  Applications", "comments": "30 pages, submitted for publication on the IEEE Trans. Signal Process", "journal-ref": null, "doi": "10.1109/TSP.2013.2279080", "report-no": null, "categories": "cs.MA cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a limited number of entries from the superposition of a low-rank matrix\nplus the product of a known fat compression matrix times a sparse matrix,\nrecovery of the low-rank and sparse components is a fundamental task subsuming\ncompressed sensing, matrix completion, and principal components pursuit. This\npaper develops algorithms for distributed sparsity-regularized rank\nminimization over networks, when the nuclear- and $\\ell_1$-norm are used as\nsurrogates to the rank and nonzero entry counts of the sought matrices,\nrespectively. While nuclear-norm minimization has well-documented merits when\ncentralized processing is viable, non-separability of the singular-value sum\nchallenges its distributed minimization. To overcome this limitation, an\nalternative characterization of the nuclear norm is adopted which leads to a\nseparable, yet non-convex cost minimized via the alternating-direction method\nof multipliers. The novel distributed iterations entail reduced-complexity\nper-node tasks, and affordable message passing among single-hop neighbors.\nInterestingly, upon convergence the distributed (non-convex) estimator provably\nattains the global optimum of its centralized counterpart, regardless of\ninitialization. Several application domains are outlined to highlight the\ngenerality and impact of the proposed framework. These include unveiling\ntraffic anomalies in backbone networks, predicting networkwide path latencies,\nand mapping the RF ambiance using wireless cognitive radios. Simulations with\nsynthetic and real network data corroborate the convergence of the novel\ndistributed algorithm, and its centralized performance guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 19:14:32 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Mardani", "Morteza", ""], ["Mateos", "Gonzalo", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1203.1596", "submitter": "Hachem Kadri", "authors": "Hachem Kadri (INRIA Lille - Nord Europe), Alain Rakotomamonjy (LITIS),\n  Francis Bach (INRIA Paris - Rocquencourt, LIENS), Philippe Preux (INRIA Lille\n  - Nord Europe)", "title": "Multiple Operator-valued Kernel Learning", "comments": "No. RR-7900 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive definite operator-valued kernels generalize the well-known notion of\nreproducing kernels, and are naturally adapted to multi-output learning\nsituations. This paper addresses the problem of learning a finite linear\ncombination of infinite-dimensional operator-valued kernels which are suitable\nfor extending functional data analysis methods to nonlinear contexts. We study\nthis problem in the case of kernel ridge regression for functional responses\nwith an lr-norm constraint on the combination coefficients. The resulting\noptimization problem is more involved than those of multiple scalar-valued\nkernel learning since operator-valued kernels pose more technical and\ntheoretical issues. We propose a multiple operator-valued kernel learning\nalgorithm based on solving a system of linear operator equations by using a\nblock coordinatedescent procedure. We experimentally validate our approach on a\nfunctional regression task in the context of finger movement prediction in\nbrain-computer interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 20:31:17 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2012 18:44:49 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Kadri", "Hachem", "", "INRIA Lille - Nord Europe"], ["Rakotomamonjy", "Alain", "", "LITIS"], ["Bach", "Francis", "", "INRIA Paris - Rocquencourt, LIENS"], ["Preux", "Philippe", "", "INRIA Lille\n  - Nord Europe"]]}, {"id": "1203.1828", "submitter": "Bo Wahlberg", "authors": "Bo Wahlberg, Stephen Boyd, Mariette Annergren, Yang Wang", "title": "An ADMM Algorithm for a Class of Total Variation Regularized Estimation\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternating augmented Lagrangian method for convex optimization\nproblems where the cost function is the sum of two terms, one that is separable\nin the variable blocks, and a second that is separable in the difference\nbetween consecutive variable blocks. Examples of such problems include Fused\nLasso estimation, total variation denoising, and multi-period portfolio\noptimization with transaction costs. In each iteration of our method, the first\nstep involves separately optimizing over each variable block, which can be\ncarried out in parallel. The second step is not separable in the variables, but\ncan be carried out very efficiently. We apply the algorithm to segmentation of\ndata based on changes inmean (l_1 mean filtering) or changes in variance (l_1\nvariance filtering). In a numerical example, we show that our implementation is\naround 10000 times faster compared with the generic optimization solver SDPT3.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2012 15:34:08 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Wahlberg", "Bo", ""], ["Boyd", "Stephen", ""], ["Annergren", "Mariette", ""], ["Wang", "Yang", ""]]}, {"id": "1203.2177", "submitter": "Masrour Zoghi", "authors": "Nando de Freitas, Alex Smola, Masrour Zoghi", "title": "Regret Bounds for Deterministic Gaussian Process Bandits", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper analyses the problem of Gaussian process (GP) bandits with\ndeterministic observations. The analysis uses a branch and bound algorithm that\nis related to the UCB algorithm of (Srinivas et al., 2010). For GPs with\nGaussian observation noise, with variance strictly greater than zero, (Srinivas\net al., 2010) proved that the regret vanishes at the approximate rate of\n$O(\\frac{1}{\\sqrt{t}})$, where t is the number of observations. To complement\ntheir result, we attack the deterministic case and attain a much faster\nexponential convergence rate. Under some regularity assumptions, we show that\nthe regret decreases asymptotically according to $O(e^{-\\frac{\\tau t}{(\\ln\nt)^{d/4}}})$ with high probability. Here, d is the dimension of the search\nspace and $\\tau$ is a constant that depends on the behaviour of the objective\nfunction near its global maximum.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2012 20:51:37 GMT"}], "update_date": "2012-03-12", "authors_parsed": [["de Freitas", "Nando", ""], ["Smola", "Alex", ""], ["Zoghi", "Masrour", ""]]}, {"id": "1203.2200", "submitter": "Ryan Rossi", "authors": "Ryan Rossi, Brian Gallagher, Jennifer Neville, Keith Henderson", "title": "Role-Dynamics: Fast Mining of Large Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the structural dynamics of a large-scale social, biological or\ntechnological network, it may be useful to discover behavioral roles\nrepresenting the main connectivity patterns present over time. In this paper,\nwe propose a scalable non-parametric approach to automatically learn the\nstructural dynamics of the network and individual nodes. Roles may represent\nstructural or behavioral patterns such as the center of a star, peripheral\nnodes, or bridge nodes that connect different communities. Our novel approach\nlearns the appropriate structural role dynamics for any arbitrary network and\ntracks the changes over time. In particular, we uncover the specific global\nnetwork dynamics and the local node dynamics of a technological, communication,\nand social network. We identify interesting node and network patterns such as\nstationary and non-stationary roles, spikes/steps in role-memberships (perhaps\nindicating anomalies), increasing/decreasing role trends, among many others.\nOur results indicate that the nodes in each of these networks have distinct\nconnectivity patterns that are non-stationary and evolve considerably over\ntime. Overall, the experiments demonstrate the effectiveness of our approach\nfor fast mining and tracking of the dynamics in large networks. Furthermore,\nthe dynamic structural representation provides a basis for building more\nsophisticated models and tools that are fast for exploring large dynamic\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2012 22:45:34 GMT"}], "update_date": "2012-03-13", "authors_parsed": [["Rossi", "Ryan", ""], ["Gallagher", "Brian", ""], ["Neville", "Jennifer", ""], ["Henderson", "Keith", ""]]}, {"id": "1203.2394", "submitter": "Mohamed Ahmed", "authors": "Mohamed Osama Ahmed, Pouyan T. Bibalan, Nando de Freitas and Simon\n  Fauvel", "title": "Decentralized, Adaptive, Look-Ahead Particle Filtering", "comments": "16 pages, 11 figures, Authorship in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decentralized particle filter (DPF) was proposed recently to increase the\nlevel of parallelism of particle filtering. Given a decomposition of the state\nspace into two nested sets of variables, the DPF uses a particle filter to\nsample the first set and then conditions on this sample to generate a set of\nsamples for the second set of variables. The DPF can be understood as a variant\nof the popular Rao-Blackwellized particle filter (RBPF), where the second step\nis carried out using Monte Carlo approximations instead of analytical\ninference. As a result, the range of applications of the DPF is broader than\nthe one for the RBPF. In this paper, we improve the DPF in two ways. First, we\nderive a Monte Carlo approximation of the optimal proposal distribution and,\nconsequently, design and implement a more efficient look-ahead DPF. Although\nthe decentralized filters were initially designed to capitalize on parallel\nimplementation, we show that the look-ahead DPF can outperform the standard\nparticle filter even on a single machine. Second, we propose the use of bandit\nalgorithms to automatically configure the state space decomposition of the DPF.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2012 02:09:32 GMT"}], "update_date": "2012-03-13", "authors_parsed": [["Ahmed", "Mohamed Osama", ""], ["Bibalan", "Pouyan T.", ""], ["de Freitas", "Nando", ""], ["Fauvel", "Simon", ""]]}, {"id": "1203.2507", "submitter": "Dong Dai", "authors": "Dong Dai, Philippe Rigollet, Tong Zhang", "title": "Deviation optimal learning using greedy Q-aggregation", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1025 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1878-1905", "doi": "10.1214/12-AOS1025", "report-no": "IMS-AOS-AOS1025", "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite family of functions, the goal of model selection aggregation\nis to construct a procedure that mimics the function from this family that is\nthe closest to an unknown regression function. More precisely, we consider a\ngeneral regression model with fixed design and measure the distance between\nfunctions by the mean squared error at the design points. While procedures\nbased on exponential weights are known to solve the problem of model selection\naggregation in expectation, they are, surprisingly, sub-optimal in deviation.\nWe propose a new formulation called Q-aggregation that addresses this\nlimitation; namely, its solution leads to sharp oracle inequalities that are\noptimal in a minimax sense. Moreover, based on the new formulation, we design\ngreedy Q-aggregation procedures that produce sparse aggregation models\nachieving the optimal rate. The convergence and performance of these greedy\nprocedures are illustrated and compared with other standard methods on\nsimulated examples.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2012 14:50:55 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2012 10:11:08 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Dai", "Dong", ""], ["Rigollet", "Philippe", ""], ["Zhang", "Tong", ""]]}, {"id": "1203.2570", "submitter": "Rob Hall", "authors": "Rob Hall, Alessandro Rinaldo, Larry Wasserman", "title": "Differential Privacy for Functions and Functional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a framework for privately releasing summaries of a\ndatabase. Previous work has focused mainly on methods for which the output is a\nfinite dimensional vector, or an element of some discrete set. We develop\nmethods for releasing functions while preserving differential privacy.\nSpecifically, we show that adding an appropriate Gaussian process to the\nfunction of interest yields differential privacy. When the functions lie in the\nsame RKHS as the Gaussian process, then the correct noise level is established\nby measuring the \"sensitivity\" of the function in the RKHS norm. As examples we\nconsider kernel density estimation, kernel support vector machines, and\nfunctions in reproducing kernel Hilbert spaces.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2012 18:00:49 GMT"}], "update_date": "2012-03-13", "authors_parsed": [["Hall", "Rob", ""], ["Rinaldo", "Alessandro", ""], ["Wasserman", "Larry", ""]]}, {"id": "1203.3002", "submitter": "Tong Zhang", "authors": "Lin Xiao and Tong Zhang", "title": "A Proximal-Gradient Homotopy Method for the Sparse Least-Squares Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider solving the $\\ell_1$-regularized least-squares ($\\ell_1$-LS)\nproblem in the context of sparse recovery, for applications such as compressed\nsensing. The standard proximal gradient method, also known as iterative\nsoft-thresholding when applied to this problem, has low computational cost per\niteration but a rather slow convergence rate. Nevertheless, when the solution\nis sparse, it often exhibits fast linear convergence in the final stage. We\nexploit the local linear convergence using a homotopy continuation strategy,\ni.e., we solve the $\\ell_1$-LS problem for a sequence of decreasing values of\nthe regularization parameter, and use an approximate solution at the end of\neach stage to warm start the next stage. Although similar strategies have been\nstudied in the literature, there have been no theoretical analysis of their\nglobal iteration complexity. This paper shows that under suitable assumptions\nfor sparse recovery, the proposed homotopy strategy ensures that all iterates\nalong the homotopy solution path are sparse. Therefore the objective function\nis effectively strongly convex along the solution path, and geometric\nconvergence at each stage can be established. As a result, the overall\niteration complexity of our method is $O(\\log(1/\\epsilon))$ for finding an\n$\\epsilon$-optimal solution, which can be interpreted as global geometric rate\nof convergence. We also present empirical results to support our theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2012 05:34:38 GMT"}], "update_date": "2012-03-15", "authors_parsed": [["Xiao", "Lin", ""], ["Zhang", "Tong", ""]]}, {"id": "1203.3391", "submitter": "Takanori Sugiyama", "authors": "Takanori Sugiyama, Peter S. Turner, Mio Murao", "title": "Adaptive experimental design for one-qubit state estimation with finite\n  data based on a statistical update criterion", "comments": "15 pages, 7 figures", "journal-ref": "Phys. Rev. A 85, 052107 (2012)", "doi": "10.1103/PhysRevA.85.052107", "report-no": null, "categories": "quant-ph math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider 1-qubit mixed quantum state estimation by adaptively updating\nmeasurements according to previously obtained outcomes and measurement\nsettings. Updates are determined by the average-variance-optimality\n(A-optimality) criterion, known in the classical theory of experimental design\nand applied here to quantum state estimation. In general, A-optimization is a\nnonlinear minimization problem; however, we find an analytic solution for\n1-qubit state estimation using projective measurements, reducing computational\neffort. We compare numerically two adaptive and two nonadaptive schemes for\nfinite data sets and show that the A-optimality criterion gives more precise\nestimates than standard quantum tomography.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 15:26:30 GMT"}, {"version": "v2", "created": "Fri, 18 May 2012 09:09:26 GMT"}], "update_date": "2012-05-21", "authors_parsed": [["Sugiyama", "Takanori", ""], ["Turner", "Peter S.", ""], ["Murao", "Mio", ""]]}, {"id": "1203.3461", "submitter": "Kaizhu Huang", "authors": "Kaizhu Huang, Rong Jin, Zenglin Xu, Cheng-Lin Liu", "title": "Robust Metric Learning by Smooth Optimization", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-244-251", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing distance metric learning methods assume perfect side\ninformation that is usually given in pairwise or triplet constraints. Instead,\nin many real-world applications, the constraints are derived from side\ninformation, such as users' implicit feedbacks and citations among articles. As\na result, these constraints are usually noisy and contain many mistakes. In\nthis work, we aim to learn a distance metric from noisy constraints by robust\noptimization in a worst-case scenario, to which we refer as robust metric\nlearning. We formulate the learning task initially as a combinatorial\noptimization problem, and show that it can be elegantly transformed to a convex\nprogramming problem. We present an efficient learning algorithm based on smooth\noptimization [7]. It has a worst-case convergence rate of\nO(1/{\\surd}{\\varepsilon}) for smooth optimization problems, where {\\varepsilon}\nis the desired error of the approximate solution. Finally, our empirical study\nwith UCI data sets demonstrate the effectiveness of the proposed method in\ncomparison to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Huang", "Kaizhu", ""], ["Jin", "Rong", ""], ["Xu", "Zenglin", ""], ["Liu", "Cheng-Lin", ""]]}, {"id": "1203.3462", "submitter": "Amrudin Agovic", "authors": "Amrudin Agovic, Arindam Banerjee", "title": "Gaussian Process Topic Models", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-10-19", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Gaussian Process Topic Models (GPTMs), a new family of topic\nmodels which can leverage a kernel among documents while extracting correlated\ntopics. GPTMs can be considered a systematic generalization of the Correlated\nTopic Models (CTMs) using ideas from Gaussian Process (GP) based embedding.\nSince GPTMs work with both a topic covariance matrix and a document kernel\nmatrix, learning GPTMs involves a novel component-solving a suitable Sylvester\nequation capturing both topic and document dependencies. The efficacy of GPTMs\nis demonstrated with experiments evaluating the quality of both topic modeling\nand embedding.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Agovic", "Amrudin", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1203.3463", "submitter": "Amr Ahmed", "authors": "Amr Ahmed, Eric P. Xing", "title": "Timeline: A Dynamic Hierarchical Dirichlet Process Model for Recovering\n  Birth/Death and Evolution of Topics in Text Stream", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-20-29", "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have proven to be a useful tool for discovering latent\nstructures in document collections. However, most document collections often\ncome as temporal streams and thus several aspects of the latent structure such\nas the number of topics, the topics' distribution and popularity are\ntime-evolving. Several models exist that model the evolution of some but not\nall of the above aspects. In this paper we introduce infinite dynamic topic\nmodels, iDTM, that can accommodate the evolution of all the aforementioned\naspects. Our model assumes that documents are organized into epochs, where the\ndocuments within each epoch are exchangeable but the order between the\ndocuments is maintained across epochs. iDTM allows for unbounded number of\ntopics: topics can die or be born at any epoch, and the representation of each\ntopic can evolve according to a Markovian dynamics. We use iDTM to analyze the\nbirth and evolution of topics in the NIPS community and evaluated the efficacy\nof our model on both simulated and real datasets with favorable outcome.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Ahmed", "Amr", ""], ["Xing", "Eric P.", ""]]}, {"id": "1203.3468", "submitter": "Charles Blundell", "authors": "Charles Blundell, Yee Whye Teh, Katherine A. Heller", "title": "Bayesian Rose Trees", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-65-72", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical structure is ubiquitous in data across many domains. There are\nmany hierarchical clustering methods, frequently used by domain experts, which\nstrive to discover this structure. However, most of these methods limit\ndiscoverable hierarchies to those with binary branching structure. This\nlimitation, while computationally convenient, is often undesirable. In this\npaper we explore a Bayesian hierarchical clustering algorithm that can produce\ntrees with arbitrary branching structure at each node, known as rose trees. We\ninterpret these trees as mixtures over partitions of a data set, and use a\ncomputationally efficient, greedy agglomerative algorithm to find the rose\ntrees which have high marginal likelihood given the data. Lastly, we perform\nexperiments which demonstrate that rose trees are better models of data than\nthe typical binary trees returned by other hierarchical clustering algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Blundell", "Charles", ""], ["Teh", "Yee Whye", ""], ["Heller", "Katherine A.", ""]]}, {"id": "1203.3471", "submitter": "Kamalika Chaudhuri", "authors": "Kamalika Chaudhuri, Yoav Freund, Daniel Hsu", "title": "An Online Learning-based Framework for Tracking", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-101-108", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the tracking problem, namely, estimating the hidden state of an\nobject over time, from unreliable and noisy measurements. The standard\nframework for the tracking problem is the generative framework, which is the\nbasis of solutions such as the Bayesian algorithm and its approximation, the\nparticle filters. However, these solutions can be very sensitive to model\nmismatches. In this paper, motivated by online learning, we introduce a new\nframework for tracking. We provide an efficient tracking algorithm for this\nframework. We provide experimental results comparing our algorithm to the\nBayesian algorithm on simulated data. Our experiments show that when there are\nslight model mismatches, our algorithm outperforms the Bayesian algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Chaudhuri", "Kamalika", ""], ["Freund", "Yoav", ""], ["Hsu", "Daniel", ""]]}, {"id": "1203.3472", "submitter": "Yutian Chen", "authors": "Yutian Chen, Max Welling, Alex Smola", "title": "Super-Samples from Kernel Herding", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-109-116", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the herding algorithm to continuous spaces by using the kernel\ntrick. The resulting \"kernel herding\" algorithm is an infinite memory\ndeterministic process that learns to approximate a PDF with a collection of\nsamples. We show that kernel herding decreases the error of expectations of\nfunctions in the Hilbert space at a rate O(1/T) which is much faster than the\nusual O(1/pT) for iid random samples. We illustrate kernel herding by\napproximating Bayesian predictive distributions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Chen", "Yutian", ""], ["Welling", "Max", ""], ["Smola", "Alex", ""]]}, {"id": "1203.3475", "submitter": "Povilas Daniusis", "authors": "Povilas Daniusis, Dominik Janzing, Joris Mooij, Jakob Zscheischler,\n  Bastian Steudel, Kun Zhang, Bernhard Schoelkopf", "title": "Inferring deterministic causal relations", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-143-150", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two variables that are related to each other by an invertible\nfunction. While it has previously been shown that the dependence structure of\nthe noise can provide hints to determine which of the two variables is the\ncause, we presently show that even in the deterministic (noise-free) case,\nthere are asymmetries that can be exploited for causal inference. Our method is\nbased on the idea that if the function and the probability density of the cause\nare chosen independently, then the distribution of the effect will, in a\ncertain sense, depend on the function. We provide a theoretical analysis of\nthis method, showing that it also works in the low noise regime, and link it to\ninformation geometry. We report strong empirical results on various real-world\ndata sets from different domains.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Daniusis", "Povilas", ""], ["Janzing", "Dominik", ""], ["Mooij", "Joris", ""], ["Zscheischler", "Jakob", ""], ["Steudel", "Bastian", ""], ["Zhang", "Kun", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1203.3476", "submitter": "Gal Elidan", "authors": "Gal Elidan", "title": "Inference-less Density Estimation using Copula Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-151-159", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning continuous probabilistic graphical models in the face of\nmissing data. For non-Gaussian models, learning the parameters and structure of\nsuch models depends on our ability to perform efficient inference, and can be\nprohibitive even for relatively modest domains. Recently, we introduced the\nCopula Bayesian Network (CBN) density model - a flexible framework that\ncaptures complex high-dimensional dependency structures while offering direct\ncontrol over the univariate marginals, leading to improved generalization. In\nthis work we show that the CBN model also offers significant computational\nadvantages when training data is partially observed. Concretely, we leverage on\nthe specialized form of the model to derive a computationally amenable learning\nobjective that is a lower bound on the log-likelihood function. Importantly,\nour energy-like bound circumvents the need for costly inference of an auxiliary\ndistribution, thus facilitating practical learning of highdimensional\ndensities. We demonstrate the effectiveness of our approach for learning the\nstructure and parameters of a CBN model for two reallife continuous domains.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Elidan", "Gal", ""]]}, {"id": "1203.3481", "submitter": "Robert Glaubius", "authors": "Robert Glaubius, Terry Tidwell, Christopher Gill, William D. Smart", "title": "Real-Time Scheduling via Reinforcement Learning", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-201-209", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems, such as mobile robots, must respond adaptively to\ndynamic operating conditions. Effective operation of these systems requires\nthat sensing and actuation tasks are performed in a timely manner.\nAdditionally, execution of mission specific tasks such as imaging a room must\nbe balanced against the need to perform more general tasks such as obstacle\navoidance. This problem has been addressed by maintaining relative utilization\nof shared resources among tasks near a user-specified target level. Producing\noptimal scheduling strategies requires complete prior knowledge of task\nbehavior, which is unlikely to be available in practice. Instead, suitable\nscheduling strategies must be learned online through interaction with the\nsystem. We consider the sample complexity of reinforcement learning in this\ndomain, and demonstrate that while the problem state space is countably\ninfinite, we may leverage the problem's structure to guarantee efficient\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Glaubius", "Robert", ""], ["Tidwell", "Terry", ""], ["Gill", "Christopher", ""], ["Smart", "William D.", ""]]}, {"id": "1203.3483", "submitter": "Mithun Das Gupta", "authors": "Mithun Das Gupta, Thomas S. Huang", "title": "Regularized Maximum Likelihood for Intrinsic Dimension Estimation", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-220-227", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for estimating the intrinsic dimension of a dataset\nby applying the principle of regularized maximum likelihood to the distances\nbetween close neighbors. We propose a regularization scheme which is motivated\nby divergence minimization principles. We derive the estimator by a Poisson\nprocess approximation, argue about its convergence properties and apply it to a\nnumber of simulated and real datasets. We also show it has the best overall\nperformance compared with two other intrinsic dimension estimators.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Gupta", "Mithun Das", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1203.3485", "submitter": "Matthew J. Johnson", "authors": "Matthew J. Johnson, Alan Willsky", "title": "The Hierarchical Dirichlet Process Hidden Semi-Markov Model", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-252-259", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is much interest in the Hierarchical Dirichlet Process Hidden Markov\nModel (HDP-HMM) as a natural Bayesian nonparametric extension of the\ntraditional HMM. However, in many settings the HDP-HMM's strict Markovian\nconstraints are undesirable, particularly if we wish to learn or encode\nnon-geometric state durations. We can extend the HDP-HMM to capture such\nstructure by drawing upon explicit-duration semi-Markovianity, which has been\ndeveloped in the parametric setting to allow construction of highly\ninterpretable models that admit natural prior information on state durations.\nIn this paper we introduce the explicitduration HDP-HSMM and develop posterior\nsampling algorithms for efficient inference in both the direct-assignment and\nweak-limit approximation settings. We demonstrate the utility of the model and\nour inference methods on synthetic data as well as experiments on a speaker\ndiarization problem and an example of learning the patterns in Morse code.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Johnson", "Matthew J.", ""], ["Willsky", "Alan", ""]]}, {"id": "1203.3486", "submitter": "Berk Kapicioglu", "authors": "Berk Kapicioglu, Robert E. Schapire, Martin Wikelski, Tamara Broderick", "title": "Combining Spatial and Telemetric Features for Learning Animal Movement\n  Models", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-260-267", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new graphical model for tracking radio-tagged animals and\nlearning their movement patterns. The model provides a principled way to\ncombine radio telemetry data with an arbitrary set of userdefined, spatial\nfeatures. We describe an efficient stochastic gradient algorithm for fitting\nmodel parameters to data and demonstrate its effectiveness via asymptotic\nanalysis and synthetic experiments. We also apply our model to real datasets,\nand show that it outperforms the most popular radio telemetry software package\nused in ecology. We conclude that integration of different data sources under a\nsingle statistical framework, coupled with appropriate parameter and state\nestimation procedures, produces both accurate location estimates and an\ninterpretable statistical model of animal movement.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Kapicioglu", "Berk", ""], ["Schapire", "Robert E.", ""], ["Wikelski", "Martin", ""], ["Broderick", "Tamara", ""]]}, {"id": "1203.3488", "submitter": "Kevin T. Kelly", "authors": "Kevin T. Kelly, Conor Mayo-Wilson", "title": "Causal Conclusions that Flip Repeatedly and Their Justification", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-277-285", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past two decades, several consistent procedures have been designed\nto infer causal conclusions from observational data. We prove that if the true\ncausal network might be an arbitrary, linear Gaussian network or a discrete\nBayes network, then every unambiguous causal conclusion produced by a\nconsistent method from non-experimental data is subject to reversal as the\nsample size increases any finite number of times. That result, called the\ncausal flipping theorem, extends prior results to the effect that causal\ndiscovery cannot be reliable on a given sample size. We argue that since\nrepeated flipping of causal conclusions is unavoidable in principle for\nconsistent methods, the best possible discovery methods are consistent methods\nthat retract their earlier conclusions no more than necessary. A series of\nsimulations of various methods across a wide range of sample sizes illustrates\nconcretely both the theorem and the principle of comparing methods in terms of\nretractions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Kelly", "Kevin T.", ""], ["Mayo-Wilson", "Conor", ""]]}, {"id": "1203.3489", "submitter": "Arto Klami", "authors": "Arto Klami, Seppo Virtanen, Samuel Kaski", "title": "Bayesian exponential family projections for coupled data sources", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-286-293", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential family extensions of principal component analysis (EPCA) have\nreceived a considerable amount of attention in recent years, demonstrating the\ngrowing need for basic modeling tools that do not assume the squared loss or\nGaussian distribution. We extend the EPCA model toolbox by presenting the first\nexponential family multi-view learning methods of the partial least squares and\ncanonical correlation analysis, based on a unified representation of EPCA as\nmatrix factorization of the natural parameters of exponential family. The\nmodels are based on a new family of priors that are generally usable for all\nsuch factorizations. We also introduce new inference strategies, and\ndemonstrate how the methods outperform earlier ones when the Gaussianity\nassumption does not hold.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Klami", "Arto", ""], ["Virtanen", "Seppo", ""], ["Kaski", "Samuel", ""]]}, {"id": "1203.3491", "submitter": "Ping Li", "authors": "Ping Li", "title": "Robust LogitBoost and Adaptive Base Class (ABC) LogitBoost", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-302-311", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logitboost is an influential boosting algorithm for classification. In this\npaper, we develop robust logitboost to provide an explicit formulation of\ntree-split criterion for building weak learners (regression trees) for\nlogitboost. This formulation leads to a numerically stable implementation of\nlogitboost. We then propose abc-logitboost for multi-class classification, by\ncombining robust logitboost with the prior work of abc-boost. Previously,\nabc-boost was implemented as abc-mart using the mart algorithm. Our extensive\nexperiments on multi-class classification compare four algorithms: mart,\nabcmart, (robust) logitboost, and abc-logitboost, and demonstrate the\nsuperiority of abc-logitboost. Comparisons with other learning methods\nincluding SVM and deep learning are also available through prior publications.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Li", "Ping", ""]]}, {"id": "1203.3492", "submitter": "Ping Li", "authors": "Ping Li, Michael W. Mahoney, Yiyuan She", "title": "Approximating Higher-Order Distances Using Random Projections", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-312-321", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a simple method and relevant theoretical analysis for efficiently\nestimating higher-order lp distances. While the analysis mainly focuses on l4,\nour methodology extends naturally to p = 6,8,10..., (i.e., when p is even).\nDistance-based methods are popular in machine learning. In large-scale\napplications, storing, computing, and retrieving the distances can be both\nspace and time prohibitive. Efficient algorithms exist for estimating lp\ndistances if 0 < p <= 2. The task for p > 2 is known to be difficult. Our work\npartially fills this gap.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Li", "Ping", ""], ["Mahoney", "Michael W.", ""], ["She", "Yiyuan", ""]]}, {"id": "1203.3494", "submitter": "Qiang Liu", "authors": "Qiang Liu, Alexander T. Ihler", "title": "Negative Tree Reweighted Belief Propagation", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-332-339", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of lower bounds on the log partition function of a\nMarkov random field which makes use of a reversed Jensen's inequality. In\nparticular, our method approximates the intractable distribution using a linear\ncombination of spanning trees with negative weights. This technique is a\nlower-bound counterpart to the tree-reweighted belief propagation algorithm,\nwhich uses a convex combination of spanning trees with positive weights to\nprovide corresponding upper bounds. We develop algorithms to optimize and\ntighten the lower bounds over the non-convex set of valid parameter values. Our\nalgorithm generalizes mean field approaches (including naive and structured\nmean field approximations), which it includes as a limiting case.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Liu", "Qiang", ""], ["Ihler", "Alexander T.", ""]]}, {"id": "1203.3495", "submitter": "Qi Mao", "authors": "Qi Mao, Ivor W. Tsang", "title": "Parameter-Free Spectral Kernel Learning", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-350-357", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the growing ubiquity of unlabeled data, learning with unlabeled data\nis attracting increasing attention in machine learning. In this paper, we\npropose a novel semi-supervised kernel learning method which can seamlessly\ncombine manifold structure of unlabeled data and Regularized Least-Squares\n(RLS) to learn a new kernel. Interestingly, the new kernel matrix can be\nobtained analytically with the use of spectral decomposition of graph Laplacian\nmatrix. Hence, the proposed algorithm does not require any numerical\noptimization solvers. Moreover, by maximizing kernel target alignment on\nlabeled data, we can also learn model parameters automatically with a\nclosed-form solution. For a given graph Laplacian matrix, our proposed method\ndoes not need to tune any model parameter including the tradeoff parameter in\nRLS and the balance parameter for unlabeled data. Extensive experiments on ten\nbenchmark datasets show that our proposed two-stage parameter-free spectral\nkernel learning algorithm can obtain comparable performance with fine-tuned\nmanifold regularization methods in transductive setting, and outperform\nmultiple kernel learning in supervised setting.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Mao", "Qi", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1203.3496", "submitter": "Marina Meila", "authors": "Marina Meila, Harr Chen", "title": "Dirichlet Process Mixtures of Generalized Mallows Models", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-358-367", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Dirichlet process mixture model over discrete incomplete\nrankings and study two Gibbs sampling inference techniques for estimating\nposterior clusterings. The first approach uses a slice sampling subcomponent\nfor estimating cluster parameters. The second approach marginalizes out several\ncluster parameters by taking advantage of approximations to the conditional\nposteriors. We empirically demonstrate (1) the effectiveness of this\napproximation for improving convergence, (2) the benefits of the Dirichlet\nprocess model over alternative clustering techniques for ranked data, and (3)\nthe applicability of the approach to exploring large realworld ranking\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Meila", "Marina", ""], ["Chen", "Harr", ""]]}, {"id": "1203.3497", "submitter": "Tetsuro Morimura", "authors": "Tetsuro Morimura, Masashi Sugiyama, Hisashi Kashima, Hirotaka Hachiya,\n  Toshiyuki Tanaka", "title": "Parametric Return Density Estimation for Reinforcement Learning", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-368-375", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most conventional Reinforcement Learning (RL) algorithms aim to optimize\ndecision-making rules in terms of the expected returns. However, especially for\nrisk management purposes, other risk-sensitive criteria such as the\nvalue-at-risk or the expected shortfall are sometimes preferred in real\napplications. Here, we describe a parametric method for estimating density of\nthe returns, which allows us to handle various criteria in a unified manner. We\nfirst extend the Bellman equation for the conditional expected return to cover\na conditional probability density of the returns. Then we derive an extension\nof the TD-learning algorithm for estimating the return densities in an unknown\nenvironment. As test instances, several parametric density estimation\nalgorithms are presented for the Gaussian, Laplace, and skewed Laplace\ndistributions. We show that these algorithms lead to risk-sensitive as well as\nrobust RL paradigms through numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Morimura", "Tetsuro", ""], ["Sugiyama", "Masashi", ""], ["Kashima", "Hisashi", ""], ["Hachiya", "Hirotaka", ""], ["Tanaka", "Toshiyuki", ""]]}, {"id": "1203.3501", "submitter": "Sebastian Ordyniak", "authors": "Sebastian Ordyniak, Stefan Szeider", "title": "Algorithms and Complexity Results for Exact Bayesian Structure Learning", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-401-408", "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian structure learning is the NP-hard problem of discovering a Bayesian\nnetwork that optimally represents a given set of training data. In this paper\nwe study the computational worst-case complexity of exact Bayesian structure\nlearning under graph theoretic restrictions on the super-structure. The\nsuper-structure (a concept introduced by Perrier, Imoto, and Miyano, JMLR 2008)\nis an undirected graph that contains as subgraphs the skeletons of solution\nnetworks. Our results apply to several variants of score-based Bayesian\nstructure learning where the score of a network decomposes into local scores of\nits nodes. Results: We show that exact Bayesian structure learning can be\ncarried out in non-uniform polynomial time if the super-structure has bounded\ntreewidth and in linear time if in addition the super-structure has bounded\nmaximum degree. We complement this with a number of hardness results. We show\nthat both restrictions (treewidth and degree) are essential and cannot be\ndropped without loosing uniform polynomial time tractability (subject to a\ncomplexity-theoretic assumption). Furthermore, we show that the restrictions\nremain essential if we do not search for a globally optimal network but we aim\nto improve a given network by means of at most k arc additions, arc deletions,\nor arc reversals (k-neighborhood local search).\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Ordyniak", "Sebastian", ""], ["Szeider", "Stefan", ""]]}, {"id": "1203.3506", "submitter": "Miika Pihlaja", "authors": "Miika Pihlaja, Michael Gutmann, Aapo Hyvarinen", "title": "A Family of Computationally Efficient and Simple Estimators for\n  Unnormalized Statistical Models", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-442-449", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new family of estimators for unnormalized statistical models.\nOur family of estimators is parameterized by two nonlinear functions and uses a\nsingle sample from an auxiliary distribution, generalizing Maximum Likelihood\nMonte Carlo estimation of Geyer and Thompson (1992). The family is such that we\ncan estimate the partition function like any other parameter in the model. The\nestimation is done by optimizing an algebraically simple, well defined\nobjective function, which allows for the use of dedicated optimization methods.\nWe establish consistency of the estimator family and give an expression for the\nasymptotic covariance matrix, which enables us to further analyze the influence\nof the nonlinearities and the auxiliary density on estimation performance. Some\nestimators in our family are particularly stable for a wide range of auxiliary\ndensities. Interestingly, a specific choice of the nonlinearity establishes a\nconnection between density estimation and classification by nonlinear logistic\nregression. Finally, the optimal amount of auxiliary samples relative to the\ngiven amount of the data is considered from the perspective of computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Pihlaja", "Miika", ""], ["Gutmann", "Michael", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1203.3507", "submitter": "Yuan (Alan) Qi", "authors": "Yuan (Alan) Qi, Ahmed H. Abdel-Gawad, Thomas P. Minka", "title": "Sparse-posterior Gaussian Processes for general likelihoods", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-450-457", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) provide a probabilistic nonparametric representation\nof functions in regression, classification, and other problems. Unfortunately,\nexact learning with GPs is intractable for large datasets. A variety of\napproximate GP methods have been proposed that essentially map the large\ndataset into a small set of basis points. Among them, two state-of-the-art\nmethods are sparse pseudo-input Gaussian process (SPGP) (Snelson and\nGhahramani, 2006) and variablesigma GP (VSGP) Walder et al. (2008), which\ngeneralizes SPGP and allows each basis point to have its own length scale.\nHowever, VSGP was only derived for regression. In this paper, we propose a new\nsparse GP framework that uses expectation propagation to directly approximate\ngeneral GP likelihoods using a sparse and smooth basis. It includes both SPGP\nand VSGP for regression as special cases. Plus as an EP algorithm, it inherits\nthe ability to process data online. As a particular choice of approximating\nfamily, we blur each basis point with a Gaussian distribution that has a full\ncovariance matrix representing the data distribution around that basis point;\nas a result, we can summarize local data manifold information with a small set\nof basis points. Our experiments demonstrate that this framework outperforms\nprevious GP classification methods on benchmark datasets in terms of minimizing\ndivergence to the non-sparse GP solution as well as lower misclassification\nrate.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Yuan", "", "", "Alan"], ["Qi", "", ""], ["Abdel-Gawad", "Ahmed H.", ""], ["Minka", "Thomas P.", ""]]}, {"id": "1203.3510", "submitter": "Michael Ramati", "authors": "Michael Ramati, Yuval Shahar", "title": "Irregular-Time Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-484-491", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields observations are performed irregularly along time, due to\neither measurement limitations or lack of a constant immanent rate. While\ndiscrete-time Markov models (as Dynamic Bayesian Networks) introduce either\ninefficient computation or an information loss to reasoning about such\nprocesses, continuous-time Markov models assume either a discrete state space\n(as Continuous-Time Bayesian Networks), or a flat continuous state space (as\nstochastic differential equations). To address these problems, we present a new\nmodeling class called Irregular-Time Bayesian Networks (ITBNs), generalizing\nDynamic Bayesian Networks, allowing substantially more compact representations,\nand increasing the expressivity of the temporal dynamics. In addition, a\nglobally optimal solution is guaranteed when learning temporal systems,\nprovided that they are fully observed at the same irregularly spaced\ntime-points, and a semiparametric subclass of ITBNs is introduced to allow\nfurther adaptation to the irregular nature of the available data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Ramati", "Michael", ""], ["Shahar", "Yuval", ""]]}, {"id": "1203.3511", "submitter": "Sebastian Riedel", "authors": "Sebastian Riedel, David A. Smith, Andrew McCallum", "title": "Inference by Minimizing Size, Divergence, or their Sum", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-492-499", "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We speed up marginal inference by ignoring factors that do not significantly\ncontribute to overall accuracy. In order to pick a suitable subset of factors\nto ignore, we propose three schemes: minimizing the number of model factors\nunder a bound on the KL divergence between pruned and full models; minimizing\nthe KL divergence under a bound on factor count; and minimizing the weighted\nsum of KL divergence and factor count. All three problems are solved using an\napproximation of the KL divergence than can be calculated in terms of marginals\ncomputed on a simple seed graph. Applied to synthetic image denoising and to\nthree different types of NLP parsing models, this technique performs marginal\ninference up to 11 times faster than loopy BP, with graph sizes reduced up to\n98%-at comparable error in marginals and parsing accuracy. We also show that\nminimizing the weighted sum of divergence and size is substantially faster than\nminimizing either of the other objectives based on the approximation to\ndivergence presented here.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Riedel", "Sebastian", ""], ["Smith", "David A.", ""], ["McCallum", "Andrew", ""]]}, {"id": "1203.3516", "submitter": "Aleksandr Simma", "authors": "Aleksandr Simma, Michael I. Jordan", "title": "Modeling Events with Cascades of Poisson Processes", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-546-555", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic model of events in continuous time in which each\nevent triggers a Poisson process of successor events. The ensemble of observed\nevents is thereby modeled as a superposition of Poisson processes. Efficient\ninference is feasible under this model with an EM algorithm. Moreover, the EM\nalgorithm can be implemented as a distributed algorithm, permitting the model\nto be applied to very large datasets. We apply these techniques to the modeling\nof Twitter messages and the revision history of Wikipedia.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Simma", "Aleksandr", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1203.3517", "submitter": "Ajit P. Singh", "authors": "Ajit P. Singh, Geoffrey Gordon", "title": "A Bayesian Matrix Factorization Model for Relational Data", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-556-563", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational learning can be used to augment one data source with other\ncorrelated sources of information, to improve predictive accuracy. We frame a\nlarge class of relational learning problems as matrix factorization problems,\nand propose a hierarchical Bayesian model. Training our Bayesian model using\nrandom-walk Metropolis-Hastings is impractically slow, and so we develop a\nblock Metropolis-Hastings sampler which uses the gradient and Hessian of the\nlikelihood to dynamically tune the proposal. We demonstrate that a predictive\nmodel of brain response to stimuli can be improved by augmenting it with side\ninformation about the stimuli.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Singh", "Ajit P.", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1203.3518", "submitter": "Jonathan Sorg", "authors": "Jonathan Sorg, Satinder Singh, Richard L. Lewis", "title": "Variance-Based Rewards for Approximate Bayesian Reinforcement Learning", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-564-571", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explore{exploit dilemma is one of the central challenges in Reinforcement\nLearning (RL). Bayesian RL solves the dilemma by providing the agent with\ninformation in the form of a prior distribution over environments; however,\nfull Bayesian planning is intractable. Planning with the mean MDP is a common\nmyopic approximation of Bayesian planning. We derive a novel reward bonus that\nis a function of the posterior distribution over environments, which, when\nadded to the reward in planning with the mean MDP, results in an agent which\nexplores efficiently and effectively. Although our method is similar to\nexisting methods when given an uninformative or unstructured prior, unlike\nexisting methods, our method can exploit structured priors. We prove that our\nmethod results in a polynomial sample complexity and empirically demonstrate\nits advantages in a structured exploration task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Sorg", "Jonathan", ""], ["Singh", "Satinder", ""], ["Lewis", "Richard L.", ""]]}, {"id": "1203.3519", "submitter": "Gerald Tesauro", "authors": "Gerald Tesauro, V T Rajan, Richard Segal", "title": "Bayesian Inference in Monte-Carlo Tree Search", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-580-588", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte-Carlo Tree Search (MCTS) methods are drawing great interest after\nyielding breakthrough results in computer Go. This paper proposes a Bayesian\napproach to MCTS that is inspired by distributionfree approaches such as UCT\n[13], yet significantly differs in important respects. The Bayesian framework\nallows potentially much more accurate (Bayes-optimal) estimation of node values\nand node uncertainties from a limited number of simulation trials. We further\npropose propagating inference in the tree via fast analytic Gaussian\napproximation methods: this can make the overhead of Bayesian inference\nmanageable in domains such as Go, while preserving high accuracy of\nexpected-value estimates. We find substantial empirical outperformance of UCT\nin an idealized bandit-tree test environment, where we can obtain valuable\ninsights by comparing with known ground truth. Additionally we rigorously prove\non-policy and off-policy convergence of the proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Tesauro", "Gerald", ""], ["Rajan", "V T", ""], ["Segal", "Richard", ""]]}, {"id": "1203.3520", "submitter": "Jin Tian", "authors": "Jin Tian, Ru He, Lavanya Ram", "title": "Bayesian Model Averaging Using the k-best Bayesian Network Structures", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-589-597", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning Bayesian network structures from data. We\ndevelop an algorithm for finding the k-best Bayesian network structures. We\npropose to compute the posterior probabilities of hypotheses of interest by\nBayesian model averaging over the k-best Bayesian networks. We present\nempirical results on structural discovery over several real and synthetic data\nsets and show that the method outperforms the model selection method and the\nstate of-the-art MCMC methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Tian", "Jin", ""], ["He", "Ru", ""], ["Ram", "Lavanya", ""]]}, {"id": "1203.3521", "submitter": "Maomi Ueno", "authors": "Maomi Ueno", "title": "Learning networks determined by the ratio of prior and data", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-598-605", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reports have described that the equivalent sample size (ESS) in a\nDirichlet prior plays an important role in learning Bayesian networks. This\npaper provides an asymptotic analysis of the marginal likelihood score for a\nBayesian network. Results show that the ratio of the ESS and sample size\ndetermine the penalty of adding arcs in learning Bayesian networks. The number\nof arcs increases monotonically as the ESS increases; the number of arcs\nmonotonically decreases as the ESS decreases. Furthermore, the marginal\nlikelihood score provides a unified expression of various score metrics by\nchanging prior knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Ueno", "Maomi", ""]]}, {"id": "1203.3522", "submitter": "Michal Valko", "authors": "Michal Valko, Branislav Kveton, Ling Huang, Daniel Ting", "title": "Online Semi-Supervised Learning on Quantized Graphs", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-606-614", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of online semi-supervised learning\n(SSL). When data arrive in a stream, the dual problems of computation and data\nstorage arise for any SSL method. We propose a fast approximate online SSL\nalgorithm that solves for the harmonic solution on an approximate graph. We\nshow, both empirically and theoretically, that good behavior can be achieved by\ncollapsing nearby points into a set of local \"representative points\" that\nminimize distortion. Moreover, we regularize the harmonic solution to achieve\nbetter stability properties. We apply our algorithm to face recognition and\noptical character recognition applications to show that we can take advantage\nof the manifold structure to outperform the previous methods. Unlike previous\nheuristic approaches, we show that our method yields provable performance\nbounds.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Valko", "Michal", ""], ["Kveton", "Branislav", ""], ["Huang", "Ling", ""], ["Ting", "Daniel", ""]]}, {"id": "1203.3524", "submitter": "Jarno Vanhatalo", "authors": "Jarno Vanhatalo, Aki Vehtari", "title": "Speeding up the binary Gaussian process classification", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-623-631", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) are attractive building blocks for many probabilistic\nmodels. Their drawbacks, however, are the rapidly increasing inference time and\nmemory requirement alongside increasing data. The problem can be alleviated\nwith compactly supported (CS) covariance functions, which produce sparse\ncovariance matrices that are fast in computations and cheap to store. CS\nfunctions have previously been used in GP regression but here the focus is in a\nclassification problem. This brings new challenges since the posterior\ninference has to be done approximately. We utilize the expectation propagation\nalgorithm and show how its standard implementation has to be modified to obtain\ncomputational benefits from the sparse covariance matrices. We study four CS\ncovariance functions and show that they may lead to substantial speed up in the\ninference time compared to globally supported functions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Vanhatalo", "Jarno", ""], ["Vehtari", "Aki", ""]]}, {"id": "1203.3526", "submitter": "Tomas Werner", "authors": "Tomas Werner", "title": "Primal View on Belief Propagation", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-651-657", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that fixed points of loopy belief propagation (BP) correspond to\nstationary points of the Bethe variational problem, where we minimize the Bethe\nfree energy subject to normalization and marginalization constraints.\nUnfortunately, this does not entirely explain BP because BP is a dual rather\nthan primal algorithm to solve the Bethe variational problem -- beliefs are\ninfeasible before convergence. Thus, we have no better understanding of BP than\nas an algorithm to seek for a common zero of a system of non-linear functions,\nnot explicitly related to each other. In this theoretical paper, we show that\nthese functions are in fact explicitly related -- they are the partial\nderivatives of a single function of reparameterizations. That means, BP seeks\nfor a stationary point of a single function, without any constraints. This\nfunction has a very natural form: it is a linear combination of local\nlog-partition functions, exactly as the Bethe entropy is the same linear\ncombination of local entropies.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Werner", "Tomas", ""]]}, {"id": "1203.3529", "submitter": "Yan Yan", "authors": "Yan Yan, Romer Rosales, Glenn Fung, Jennifer Dy", "title": "Modeling Multiple Annotator Expertise in the Semi-Supervised Learning\n  Scenario", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-674-682", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms normally assume that there is at most one annotation or\nlabel per data point. However, in some scenarios, such as medical diagnosis and\non-line collaboration,multiple annotations may be available. In either case,\nobtaining labels for data points can be expensive and time-consuming (in some\ncircumstances ground-truth may not exist). Semi-supervised learning approaches\nhave shown that utilizing the unlabeled data is often beneficial in these\ncases. This paper presents a probabilistic semi-supervised model and algorithm\nthat allows for learning from both unlabeled and labeled data in the presence\nof multiple annotators. We assume that it is known what annotator labeled which\ndata points. The proposed approach produces annotator models that allow us to\nprovide (1) estimates of the true label and (2) annotator variable expertise\nfor both labeled and unlabeled data. We provide numerical comparisons under\nvarious scenarios and with respect to standard semi-supervised learning.\nExperiments showed that the presented approach provides clear advantages over\nmulti-annotator methods that do not use the unlabeled data and over methods\nthat do not use multi-labeler information.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Yan", "Yan", ""], ["Rosales", "Romer", ""], ["Fung", "Glenn", ""], ["Dy", "Jennifer", ""]]}, {"id": "1203.3530", "submitter": "Shuang Hong Yang", "authors": "Shuang Hong Yang, Jiang Bian, Hongyuan Zha", "title": "Hybrid Generative/Discriminative Learning for Automatic Image Annotation", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-683-690", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic image annotation (AIA) raises tremendous challenges to machine\nlearning as it requires modeling of data that are both ambiguous in input and\noutput, e.g., images containing multiple objects and labeled with multiple\nsemantic tags. Even more challenging is that the number of candidate tags is\nusually huge (as large as the vocabulary size) yet each image is only related\nto a few of them. This paper presents a hybrid generative-discriminative\nclassifier to simultaneously address the extreme data-ambiguity and\noverfitting-vulnerability issues in tasks such as AIA. Particularly: (1) an\nExponential-Multinomial Mixture (EMM) model is established to capture both the\ninput and output ambiguity and in the meanwhile to encourage prediction\nsparsity; and (2) the prediction ability of the EMM model is explicitly\nmaximized through discriminative learning that integrates variational inference\nof graphical models and the pairwise formulation of ordinal regression.\nExperiments show that our approach achieves both superior annotation\nperformance and better tag scalability.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Yang", "Shuang Hong", ""], ["Bian", "Jiang", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1203.3532", "submitter": "Bai Zhang", "authors": "Bai Zhang, Yue Wang", "title": "Learning Structural Changes of Gaussian Graphical Models in Controlled\n  Experiments", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-701-708", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models are widely used in scienti fic and engineering research to\nrepresent conditional independence structures between random variables. In many\ncontrolled experiments, environmental changes or external stimuli can often\nalter the conditional dependence between the random variables, and potentially\nproduce significant structural changes in the corresponding graphical models.\nTherefore, it is of great importance to be able to detect such structural\nchanges from data, so as to gain novel insights into where and how the\nstructural changes take place and help the system adapt to the new environment.\nHere we report an effective learning strategy to extract structural changes in\nGaussian graphical model using l1-regularization based convex optimization. We\ndiscuss the properties of the problem formulation and introduce an efficient\nimplementation by the block coordinate descent algorithm. We demonstrate the\nprinciple of the approach on a numerical simulation experiment, and we then\napply the algorithm to the modeling of gene regulatory networks under different\nconditions and obtain promising yet biologically plausible results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Zhang", "Bai", ""], ["Wang", "Yue", ""]]}, {"id": "1203.3533", "submitter": "Kun Zhang", "authors": "Kun Zhang, Aapo Hyvarinen", "title": "Source Separation and Higher-Order Causal Analysis of MEG and EEG", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-709-716", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation of the sources and analysis of their connectivity have been an\nimportant topic in EEG/MEG analysis. To solve this problem in an automatic\nmanner, we propose a two-layer model, in which the sources are conditionally\nuncorrelated from each other, but not independent; the dependence is caused by\nthe causality in their time-varying variances (envelopes). The model is\nidentified in two steps. We first propose a new source separation technique\nwhich takes into account the autocorrelations (which may be time-varying) and\ntime-varying variances of the sources. The causality in the envelopes is then\ndiscovered by exploiting a special kind of multivariate GARCH (generalized\nautoregressive conditional heteroscedasticity) model. The resulting causal\ndiagram gives the effective connectivity between the separated sources; in our\nexperimental results on MEG data, sources with similar functions are grouped\ntogether, with negative influences between groups, and the groups are connected\nvia some interesting sources.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Zhang", "Kun", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1203.3534", "submitter": "Kun Zhang", "authors": "Kun Zhang, Bernhard Schoelkopf, Dominik Janzing", "title": "Invariant Gaussian Process Latent Variable Models and Application in\n  Causal Discovery", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-717-724", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nonlinear latent variable models or dynamic models, if we consider the\nlatent variables as confounders (common causes), the noise dependencies imply\nfurther relations between the observed variables. Such models are then closely\nrelated to causal discovery in the presence of nonlinear confounders, which is\na challenging problem. However, generally in such models the observation noise\nis assumed to be independent across data dimensions, and consequently the noise\ndependencies are ignored. In this paper we focus on the Gaussian process latent\nvariable model (GPLVM), from which we develop an extended model called\ninvariant GPLVM (IGPLVM), which can adapt to arbitrary noise covariances. With\nthe Gaussian process prior put on a particular transformation of the latent\nnonlinear functions, instead of the original ones, the algorithm for IGPLVM\ninvolves almost the same computational loads as that for the original GPLVM.\nBesides its potential application in causal discovery, IGPLVM has the advantage\nthat its estimated latent nonlinear manifold is invariant to any nonsingular\nlinear transformation of the data. Experimental results on both synthetic and\nrealworld data show its encouraging performance in nonlinear manifold learning\nand causal discovery.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Zhang", "Kun", ""], ["Schoelkopf", "Bernhard", ""], ["Janzing", "Dominik", ""]]}, {"id": "1203.3536", "submitter": "Yu Zhang", "authors": "Yu Zhang, Dit-Yan Yeung", "title": "A Convex Formulation for Learning Task Relationships in Multi-Task\n  Learning", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-733-742", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning is a learning paradigm which seeks to improve the\ngeneralization performance of a learning task with the help of some other\nrelated tasks. In this paper, we propose a regularization formulation for\nlearning the relationships between tasks in multi-task learning. This\nformulation can be viewed as a novel generalization of the regularization\nframework for single-task learning. Besides modeling positive task correlation,\nour method, called multi-task relationship learning (MTRL), can also describe\nnegative task correlation and identify outlier tasks based on the same\nunderlying principle. Under this regularization framework, the objective\nfunction of MTRL is convex. For efficiency, we use an alternating method to\nlearn the optimal model parameters for each task as well as the relationships\nbetween tasks. We study MTRL in the symmetric multi-task learning setting and\nthen generalize it to the asymmetric setting as well. We also study the\nrelationships between MTRL and some existing multi-task learning methods.\nExperiments conducted on a toy problem as well as several benchmark data sets\ndemonstrate the effectiveness of MTRL.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Zhang", "Yu", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1203.3537", "submitter": "Qian Zhu", "authors": "Qian Zhu, Branislav Kveton, Lily Mummert, Padmanabhan Pillai", "title": "Automatic Tuning of Interactive Perception Applications", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-743-751", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive applications incorporating high-data rate sensing and computer\nvision are becoming possible due to novel runtime systems and the use of\nparallel computation resources. To allow interactive use, such applications\nrequire careful tuning of multiple application parameters to meet required\nfidelity and latency bounds. This is a nontrivial task, often requiring expert\nknowledge, which becomes intractable as resources and application load\ncharacteristics change. This paper describes a method for automatic performance\ntuning that learns application characteristics and effects of tunable\nparameters online, and constructs models that are used to maximize fidelity for\na given latency constraint. The paper shows that accurate latency models can be\nlearned online, knowledge of application structure can be used to reduce the\ncomplexity of the learning task, and operating points can be found that achieve\n90% of the optimal fidelity by exploring the parameter space only 3% of the\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 11:17:56 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Zhu", "Qian", ""], ["Kveton", "Branislav", ""], ["Mummert", "Lily", ""], ["Pillai", "Padmanabhan", ""]]}, {"id": "1203.3783", "submitter": "Gr\\'egoire Montavon", "authors": "Gr\\'egoire Montavon and Klaus-Robert M\\\"uller", "title": "Learning Feature Hierarchies with Centered Deep Boltzmann Machines", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-35289-8_33", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Boltzmann machines are in principle powerful models for extracting the\nhierarchical structure of data. Unfortunately, attempts to train layers jointly\n(without greedy layer-wise pretraining) have been largely unsuccessful. We\npropose a modification of the learning algorithm that initially recenters the\noutput of the activation functions to zero. This modification leads to a better\nconditioned Hessian and thus makes learning easier. We test the algorithm on\nreal data and demonstrate that our suggestion, the centered deep Boltzmann\nmachine, learns a hierarchy of increasingly abstract representations and a\nbetter generative model of data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 19:01:10 GMT"}], "update_date": "2012-12-19", "authors_parsed": [["Montavon", "Gr\u00e9goire", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1203.3887", "submitter": "Animashree Anandkumar", "authors": "Animashree Anandkumar, Ragupathyraj Valluvan", "title": "Learning loopy graphical models with latent variables: Efficient methods\n  and guarantees", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1070 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 2, 401-435", "doi": "10.1214/12-AOS1070", "report-no": "IMS-AOS-AOS1070", "categories": "stat.ML cs.AI cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of structure estimation in graphical models with latent variables\nis considered. We characterize conditions for tractable graph estimation and\ndevelop efficient methods with provable guarantees. We consider models where\nthe underlying Markov graph is locally tree-like, and the model is in the\nregime of correlation decay. For the special case of the Ising model, the\nnumber of samples $n$ required for structural consistency of our method scales\nas $n=\\Omega(\\theta_{\\min}^{-\\delta\\eta(\\eta+1)-2}\\log p)$, where p is the\nnumber of variables, $\\theta_{\\min}$ is the minimum edge potential, $\\delta$ is\nthe depth (i.e., distance from a hidden node to the nearest observed nodes),\nand $\\eta$ is a parameter which depends on the bounds on node and edge\npotentials in the Ising model. Necessary conditions for structural consistency\nunder any algorithm are derived and our method nearly matches the lower bound\non sample requirements. Further, the proposed method is practical to implement\nand provides flexibility to control the number of latent variables and the\ncycle lengths in the output graph.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2012 19:09:41 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2012 19:42:33 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2012 18:32:38 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2013 13:43:39 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Anandkumar", "Animashree", ""], ["Valluvan", "Ragupathyraj", ""]]}, {"id": "1203.3896", "submitter": "Xi Luo", "authors": "Weidong Liu and Xi Luo", "title": "Fast and Adaptive Sparse Precision Matrix Estimation in High Dimensions", "comments": "Maintext: 24 pages. Supplement: 13 pages. R package scio implementing\n  the proposed method is available on CRAN at\n  https://cran.r-project.org/package=scio . Published in J of Multivariate\n  Analysis at\n  http://www.sciencedirect.com/science/article/pii/S0047259X14002607", "journal-ref": "Journal of Multivariate Analysis. 2015; 135:153 -62", "doi": "10.1016/J.Jmva.2014.11.005", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new method for estimating sparse precision matrices in\nthe high dimensional setting. It has been popular to study fast computation and\nadaptive procedures for this problem. We propose a novel approach, called\nSparse Column-wise Inverse Operator, to address these two issues. We analyze an\nadaptive procedure based on cross validation, and establish its convergence\nrate under the Frobenius norm. The convergence rates under other matrix norms\nare also established. This method also enjoys the advantage of fast computation\nfor large-scale problems, via a coordinate descent algorithm. Numerical merits\nare illustrated using both simulated and real datasets. In particular, it\nperforms favorably on an HIV brain tissue dataset and an ADHD resting-state\nfMRI dataset.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2012 21:58:02 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 07:09:46 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Liu", "Weidong", ""], ["Luo", "Xi", ""]]}, {"id": "1203.4326", "submitter": "Shuichi Kawano", "authors": "Shuichi Kawano", "title": "Selection of tuning parameters in bridge regression models via Bayesian\n  information criterion", "comments": "20 pages, 5 figures", "journal-ref": "Statistical Papers 55 (2014) 1207-1223", "doi": "10.1007/s00362-013-0561-7", "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the bridge linear regression modeling, which can produce a sparse\nor non-sparse model. A crucial point in the model building process is the\nselection of adjusted parameters including a regularization parameter and a\ntuning parameter in bridge regression models. The choice of the adjusted\nparameters can be viewed as a model selection and evaluation problem. We\npropose a model selection criterion for evaluating bridge regression models in\nterms of Bayesian approach. This selection criterion enables us to select the\nadjusted parameters objectively. We investigate the effectiveness of our\nproposed modeling strategy through some numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 06:41:16 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2012 00:11:15 GMT"}, {"version": "v3", "created": "Sat, 14 Apr 2012 02:29:41 GMT"}], "update_date": "2015-02-19", "authors_parsed": [["Kawano", "Shuichi", ""]]}, {"id": "1203.4345", "submitter": "Marc Deisenroth", "authors": "Marc Peter Deisenroth, Ryan Turner, Marco F. Huber, Uwe D. Hanebeck,\n  Carl Edward Rasmussen", "title": "Robust Filtering and Smoothing with Gaussian Processes", "comments": "7 pages, 1 figure, draft version of paper accepted at IEEE\n  Transactions on Automatic Control", "journal-ref": null, "doi": "10.1109/TAC.2011.2179426", "report-no": null, "categories": "cs.SY cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a principled algorithm for robust Bayesian filtering and smoothing\nin nonlinear stochastic dynamic systems when both the transition function and\nthe measurement function are described by non-parametric Gaussian process (GP)\nmodels. GPs are gaining increasing importance in signal processing, machine\nlearning, robotics, and control for representing unknown system functions by\nposterior probability distributions. This modern way of \"system identification\"\nis more robust than finding point estimates of a parametric function\nrepresentation. In this article, we present a principled algorithm for robust\nanalytic smoothing in GP dynamic systems, which are increasingly used in\nrobotics and control. Our numerical evaluations demonstrate the robustness of\nthe proposed approach in situations where other state-of-the-art Gaussian\nfilters and smoothers can fail.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 08:51:50 GMT"}], "update_date": "2012-08-13", "authors_parsed": [["Deisenroth", "Marc Peter", ""], ["Turner", "Ryan", ""], ["Huber", "Marco F.", ""], ["Hanebeck", "Uwe D.", ""], ["Rasmussen", "Carl Edward", ""]]}, {"id": "1203.4354", "submitter": "Robert Hable", "authors": "Robert Hable", "title": "Asymptotic Confidence Sets for General Nonparametric Regression and\n  Classification by Regularized Kernel Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized kernel methods such as, e.g., support vector machines and\nleast-squares support vector regression constitute an important class of\nstandard learning algorithms in machine learning. Theoretical investigations\nconcerning asymptotic properties have manly focused on rates of convergence\nduring the last years but there are only very few and limited (asymptotic)\nresults on statistical inference so far. As this is a serious limitation for\ntheir use in mathematical statistics, the goal of the article is to fill this\ngap. Based on asymptotic normality of many of these methods, the article\nderives a strongly consistent estimator for the unknown covariance matrix of\nthe limiting normal distribution. In this way, we obtain asymptotically correct\nconfidence sets for $\\psi(f_{P,\\lambda_0})$ where $f_{P,\\lambda_0}$ denotes the\nminimizer of the regularized risk in the reproducing kernel Hilbert space $H$\nand $\\psi:H\\rightarrow\\mathds{R}^m$ is any Hadamard-differentiable functional.\nApplications include (multivariate) pointwise confidence sets for values of\n$f_{P,\\lambda_0}$ and confidence sets for gradients, integrals, and norms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 09:28:49 GMT"}], "update_date": "2012-03-21", "authors_parsed": [["Hable", "Robert", ""]]}, {"id": "1203.4422", "submitter": "Tomer Michaeli", "authors": "Tomer Michaeli, Yonina C. Eldar, Guillermo Sapiro", "title": "Semi-Supervised Single- and Multi-Domain Regression with Multi-Domain\n  Training", "comments": "24 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problems of multi-domain and single-domain regression based on\ndistinct and unpaired labeled training sets for each of the domains and a large\nunlabeled training set from all domains. We formulate these problems as a\nBayesian estimation with partial knowledge of statistical relations. We propose\na worst-case design strategy and study the resulting estimators. Our analysis\nexplicitly accounts for the cardinality of the labeled sets and includes the\nspecial cases in which one of the labeled sets is very large or, in the other\nextreme, completely missing. We demonstrate our estimators in the context of\nremoving expressions from facial images and in the context of audio-visual word\nrecognition, and provide comparisons to several recently proposed multi-modal\nlearning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 13:11:32 GMT"}], "update_date": "2012-03-21", "authors_parsed": [["Michaeli", "Tomer", ""], ["Eldar", "Yonina C.", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1203.4523", "submitter": "Francis Bach", "authors": "Francis Bach (INRIA Paris - Rocquencourt, LIENS), Simon Lacoste-Julien\n  (INRIA Paris - Rocquencourt, LIENS), Guillaume Obozinski (INRIA Paris -\n  Rocquencourt, LIENS)", "title": "On the Equivalence between Herding and Conditional Gradient Algorithms", "comments": null, "journal-ref": "ICML 2012 International Conference on Machine Learning, Edimburgh\n  : Royaume-Uni (2012)", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the herding procedure of Welling (2009) takes exactly the form\nof a standard convex optimization algorithm--namely a conditional gradient\nalgorithm minimizing a quadratic moment discrepancy. This link enables us to\ninvoke convergence results from convex optimization and to consider faster\nalternatives for the task of approximating integrals in a reproducing kernel\nHilbert space. We study the behavior of the different variants through\nnumerical simulations. The experiments indicate that while we can improve over\nherding on the task of approximating integrals, the original herding algorithm\ntends to approach more often the maximum entropy distribution, shedding more\nlight on the learning bias behind herding.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 17:49:56 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2012 08:35:39 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Bach", "Francis", "", "INRIA Paris - Rocquencourt, LIENS"], ["Lacoste-Julien", "Simon", "", "INRIA Paris - Rocquencourt, LIENS"], ["Obozinski", "Guillaume", "", "INRIA Paris -\n  Rocquencourt, LIENS"]]}, {"id": "1203.4597", "submitter": "Suleyman Kozat Dr.", "authors": "Huseyin Ozkan, Arda Akman, Suleyman S. Kozat", "title": "A Novel Training Algorithm for HMMs with Partial and Noisy Access to the\n  States", "comments": "Submitted to Digital Signal Processing, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new estimation algorithm for the parameters of an HMM\nas to best account for the observed data. In this model, in addition to the\nobservation sequence, we have \\emph{partial} and \\emph{noisy} access to the\nhidden state sequence as side information. This access can be seen as \"partial\nlabeling\" of the hidden states. Furthermore, we model possible mislabeling in\nthe side information in a joint framework and derive the corresponding EM\nupdates accordingly. In our simulations, we observe that using this side\ninformation, we considerably improve the state recognition performance, up to\n70%, with respect to the \"achievable margin\" defined by the baseline\nalgorithms. Moreover, our algorithm is shown to be robust to the training\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 21:31:48 GMT"}], "update_date": "2012-03-22", "authors_parsed": [["Ozkan", "Huseyin", ""], ["Akman", "Arda", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1203.4723", "submitter": "Nicolas Dobigeon", "authors": "Se Un Park and Nicolas Dobigeon and Alfred O. Hero", "title": "Semi-blind Sparse Image Reconstruction with Application to MRFM", "comments": "This work has been submitted to the IEEE Trans. Image Processing for\n  possible publication", "journal-ref": null, "doi": "10.1109/TIP.2012.2199505", "report-no": null, "categories": "physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a solution to the image deconvolution problem where the\nconvolution kernel or point spread function (PSF) is assumed to be only\npartially known. Small perturbations generated from the model are exploited to\nproduce a few principal components explaining the PSF uncertainty in a high\ndimensional space. Unlike recent developments on blind deconvolution of natural\nimages, we assume the image is sparse in the pixel basis, a natural sparsity\narising in magnetic resonance force microscopy (MRFM). Our approach adopts a\nBayesian Metropolis-within-Gibbs sampling framework. The performance of our\nBayesian semi-blind algorithm for sparse images is superior to previously\nproposed semi-blind algorithms such as the alternating minimization (AM)\nalgorithm and blind algorithms developed for natural images. We illustrate our\nmyopic algorithm on real MRFM tobacco virus data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2012 12:38:34 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Park", "Se Un", ""], ["Dobigeon", "Nicolas", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1203.5181", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "$k$-MLE: A fast algorithm for learning statistical mixture models", "comments": "31 pages, Extend preliminary paper presented at IEEE ICASSP 2012", "journal-ref": null, "doi": "10.1109/ICASSP.2012.6288022", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe $k$-MLE, a fast and efficient local search algorithm for learning\nfinite statistical mixtures of exponential families such as Gaussian mixture\nmodels. Mixture models are traditionally learned using the\nexpectation-maximization (EM) soft clustering technique that monotonically\nincreases the incomplete (expected complete) likelihood. Given prescribed\nmixture weights, the hard clustering $k$-MLE algorithm iteratively assigns data\nto the most likely weighted component and update the component models using\nMaximum Likelihood Estimators (MLEs). Using the duality between exponential\nfamilies and Bregman divergences, we prove that the local convergence of the\ncomplete likelihood of $k$-MLE follows directly from the convergence of a dual\nadditively weighted Bregman hard clustering. The inner loop of $k$-MLE can be\nimplemented using any $k$-means heuristic like the celebrated Lloyd's batched\nor Hartigan's greedy swap updates. We then show how to update the mixture\nweights by minimizing a cross-entropy criterion that implies to update weights\nby taking the relative proportion of cluster points, and reiterate the mixture\nparameter update and mixture weight update processes until convergence. Hard EM\nis interpreted as a special case of $k$-MLE when both the component update and\nthe weight update are performed successively in the inner loop. To initialize\n$k$-MLE, we propose $k$-MLE++, a careful initialization of $k$-MLE guaranteeing\nprobabilistically a global bound on the best possible complete likelihood.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2012 06:11:24 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "1203.5405", "submitter": "Daniel Straub Daniel Straub", "authors": "Daniel Straub", "title": "Reliability updating with equality information", "comments": null, "journal-ref": "Probabilistic Engineering Mechanics, 2011, 26(2): 254-258", "doi": "10.1016/j.probengmech.2010.08.003", "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many instances, information on engineering systems can be obtained through\nmeasurements, monitoring or direct observations of system performances and can\nbe used to update the system reliability estimate. In structural reliability\nanalysis, such information is expressed either by inequalities (e.g. for the\nobservation that no defect is present) or by equalities (e.g. for quantitative\nmeasurements of system characteristics). When information Z is of the equality\ntype, the a-priori probability of Z is zero and most structural reliability\nmethods (SRM) are not directly applicable to the computation of the updated\nreliability. Hitherto, the computation of the reliability of engineering\nsystems conditional on equality information was performed through first- and\nsecond order approximations. In this paper, it is shown how equality\ninformation can be transformed into inequality information, which enables\nreliability updating by solving a standard structural system reliability\nproblem. This approach enables the use of any SRM, including those based on\nsimulation, for reliability updating with equality information. It is\ndemonstrated on three numerical examples, including an application to fatigue\nreliability.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2012 11:06:22 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["Straub", "Daniel", ""]]}, {"id": "1203.5438", "submitter": "Emile Richard", "authors": "Emile Richard, Andreas Argyriou, Theodoros Evgeniou and Nicolas\n  Vayatis", "title": "A Regularization Approach for Prediction of Edges and Node Features in\n  Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the two problems of predicting links in a dynamic graph sequence\nand predicting functions defined at each node of the graph. In many\napplications, the solution of one problem is useful for solving the other.\nIndeed, if these functions reflect node features, then they are related through\nthe graph structure. In this paper, we formulate a hybrid approach that\nsimultaneously learns the structure of the graph and predicts the values of the\nnode-related functions. Our approach is based on the optimization of a joint\nregularization objective. We empirically test the benefits of the proposed\nmethod with both synthetic and real data. The results indicate that joint\nregularization improves prediction performance over the graph evolution and the\nnode features.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2012 18:59:55 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["Richard", "Emile", ""], ["Argyriou", "Andreas", ""], ["Evgeniou", "Theodoros", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "1203.5483", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani, Bhiksha Raj, and Petros Boufounos", "title": "Greedy Sparsity-Constrained Optimization", "comments": null, "journal-ref": "Journal of Machine Learning Research, 14(3):807--841, 2013", "doi": null, "report-no": null, "categories": "stat.ML math.NA math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity-constrained optimization has wide applicability in machine learning,\nstatistics, and signal processing problems such as feature selection and\ncompressive Sensing. A vast body of work has studied the sparsity-constrained\noptimization from theoretical, algorithmic, and application aspects in the\ncontext of sparse estimation in linear models where the fidelity of the\nestimate is measured by the squared error. In contrast, relatively less effort\nhas been made in the study of sparsity-constrained optimization in cases where\nnonlinear models are involved or the cost function is not quadratic. In this\npaper we propose a greedy algorithm, Gradient Support Pursuit (GraSP), to\napproximate sparse minima of cost functions of arbitrary form. Should a cost\nfunction have a Stable Restricted Hessian (SRH) or a Stable Restricted\nLinearization (SRL), both of which are introduced in this paper, our algorithm\nis guaranteed to produce a sparse vector within a bounded distance from the\ntrue sparse optimum. Our approach generalizes known results for quadratic cost\nfunctions that arise in sparse linear regression and Compressive Sensing. We\nalso evaluate the performance of GraSP through numerical simulations on\nsynthetic data, where the algorithm is employed for sparse logistic regression\nwith and without $\\ell_2$-regularization.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2012 10:01:01 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2012 14:54:12 GMT"}, {"version": "v3", "created": "Sun, 6 Jan 2013 15:18:28 GMT"}], "update_date": "2013-07-17", "authors_parsed": [["Bahmani", "Sohail", ""], ["Raj", "Bhiksha", ""], ["Boufounos", "Petros", ""]]}, {"id": "1203.5647", "submitter": "Peter K\\\"oves\\'arki", "authors": "P\\'eter K\\\"oves\\'arki", "title": "Polynomial expansion of the binary classification function", "comments": "6 pages, 6 figures. Submitted to JMLR, pending decision", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel method to approximate the polynomial\ncoefficients of regression functions, with particular interest on\nmulti-dimensional classification. The derivation is simple, and offers a fast,\nrobust classification technique that is resistant to over-fitting.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2012 12:43:19 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["K\u00f6ves\u00e1rki", "P\u00e9ter", ""]]}, {"id": "1203.5986", "submitter": "Daniel Straub Daniel Straub", "authors": "Daniel Straub, Armen Der Kiureghian", "title": "Bayesian Network Enhanced with Structural Reliability Methods:\n  Methodology", "comments": null, "journal-ref": "Journal of Engineering Mechanics, Trans. ASCE, 2010, 136(10):\n  1248-1258", "doi": "10.1061/(ASCE)EM.1943-7889.0000173", "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine Bayesian networks (BNs) and structural reliability methods (SRMs)\nto create a new computational framework, termed enhanced Bayesian network\n(eBN), for reliability and risk analysis of engineering structures and\ninfrastructure. BNs are efficient in representing and evaluating complex\nprobabilistic dependence structures, as present in infrastructure and\nstructural systems, and they facilitate Bayesian updating of the model when new\ninformation becomes available. On the other hand, SRMs enable accurate\nassessment of probabilities of rare events represented by computationally\ndemanding, physically-based models. By combining the two methods, the eBN\nframework provides a unified and powerful tool for efficiently computing\nprobabilities of rare events in complex structural and infrastructure systems\nin which information evolves in time. Strategies for modeling and efficiently\nanalyzing the eBN are described by way of several conceptual examples. The\ncompanion paper applies the eBN methodology to example structural and\ninfrastructure systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2012 14:50:56 GMT"}], "update_date": "2012-03-28", "authors_parsed": [["Straub", "Daniel", ""], ["Der Kiureghian", "Armen", ""]]}, {"id": "1203.6098", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi and David F. Gleich", "title": "Dynamic PageRank using Evolving Teleportation", "comments": "WAW 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR math.DS physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of nodes in a network constantly fluctuates based on changes\nin the network structure as well as changes in external interest. We propose an\nevolving teleportation adaptation of the PageRank method to capture how changes\nin external interest influence the importance of a node. This framework\nseamlessly generalizes PageRank because the importance of a node will converge\nto the PageRank values if the external influence stops changing. We demonstrate\nthe effectiveness of the evolving teleportation on the Wikipedia graph and the\nTwitter social network. The external interest is given by the number of hourly\nvisitors to each page and the number of monthly tweets for each user.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2012 22:44:56 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Gleich", "David F.", ""]]}, {"id": "1203.6130", "submitter": "Jordan Rodu", "authors": "Dean P. Foster, Jordan Rodu, Lyle H. Ungar", "title": "Spectral dimensionality reduction for HMMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov Models (HMMs) can be accurately approximated using\nco-occurrence frequencies of pairs and triples of observations by using a fast\nspectral method in contrast to the usual slow methods like EM or Gibbs\nsampling. We provide a new spectral method which significantly reduces the\nnumber of model parameters that need to be estimated, and generates a sample\ncomplexity that does not depend on the size of the observation vocabulary. We\npresent an elementary proof giving bounds on the relative accuracy of\nprobability estimates from our model. (Correlaries show our bounds can be\nweakened to provide either L1 bounds or KL bounds which provide easier direct\ncomparisons to previous work.) Our theorem uses conditions that are checkable\nfrom the data, instead of putting conditions on the unobservable Markov\ntransition matrix.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 01:56:32 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Foster", "Dean P.", ""], ["Rodu", "Jordan", ""], ["Ungar", "Lyle H.", ""]]}, {"id": "1203.6345", "submitter": "Nikolay Nikolaev", "authors": "Mark A. Kon and Nikolay Nikolaev", "title": "Empirical Normalization for Quadratic Discriminant Analysis and\n  Classifying Cancer Subtypes", "comments": "2011 10th International Conference on Machine Learning and\n  Applications and Workshops", "journal-ref": null, "doi": "10.1109/ICMLA.2011.160", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new discriminant analysis method (Empirical Discriminant\nAnalysis or EDA) for binary classification in machine learning. Given a dataset\nof feature vectors, this method defines an empirical feature map transforming\nthe training and test data into new data with components having Gaussian\nempirical distributions. This map is an empirical version of the Gaussian\ncopula used in probability and mathematical finance. The purpose is to form a\nfeature mapped dataset as close as possible to Gaussian, after which standard\nquadratic discriminants can be used for classification. We discuss this method\nin general, and apply it to some datasets in computational biology.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 19:24:35 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2012 05:21:41 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Kon", "Mark A.", ""], ["Nikolaev", "Nikolay", ""]]}, {"id": "1203.6452", "submitter": "David Ginsbourger", "authors": "Cl\\'ement Chevalier (IRSN-SEC), David Ginsbourger", "title": "Corrected Kriging update formulae for batch-sequential data assimilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a lot of effort has been paid to the efficient computation of\nKriging predictors when observations are assimilated sequentially. In\nparticular, Kriging update formulae enabling significant computational savings\nwere derived in Barnes and Watson (1992), Gao et al. (1996), and Emery (2009).\nTaking advantage of the previous Kriging mean and variance calculations helps\navoiding a costly $(n+1) \\times (n+1)$ matrix inversion when adding one\nobservation to the $n$ already available ones. In addition to traditional\nupdate formulae taking into account a single new observation, Emery (2009) also\nproposed formulae for the batch-sequential case, i.e. when $r > 1$ new\nobservations are simultaneously assimilated. However, the Kriging variance and\ncovariance formulae given without proof in Emery (2009) for the\nbatch-sequential case are not correct. In this paper we fix this issue and\nestablish corrected expressions for updated Kriging variances and covariances\nwhen assimilating several observations in parallel.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2012 07:41:52 GMT"}], "update_date": "2012-03-30", "authors_parsed": [["Chevalier", "Cl\u00e9ment", "", "IRSN-SEC"], ["Ginsbourger", "David", ""]]}]