[{"id": "1812.00002", "submitter": "Sen Na", "authors": "Mingyuan Ma, Sen Na, Hongyu Wang, Congzhou Chen, Jin Xu", "title": "The Graph-Based Behavior-Aware Recommendation for Interactive News", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive news recommendation has been launched and attracted much\nattention recently. In this scenario, user's behavior evolves from single click\nbehavior to multiple behaviors including like, comment, share etc. However,\nmost of the existing methods still use single click behavior as the unique\ncriterion of judging user's preferences. Further, although heterogeneous graphs\nhave been applied in different areas, a proper way to construct a heterogeneous\ngraph for interactive news data with an appropriate learning mechanism on it is\nstill desired. To address the above concerns, we propose a graph-based\nbehavior-aware network, which simultaneously considers six different types of\nbehaviors as well as user's demand on the news diversity. We have three main\nsteps. First, we build an interaction behavior graph for multi-level and\nmulti-category data. Second, we apply DeepWalk on the behavior graph to obtain\nentity semantics, then build a graph-based convolutional neural network called\nG-CNN to learn news representations, and an attention-based LSTM to learn\nbehavior sequence representations. Third, we introduce core and coritivity\nfeatures for the behavior graph, which measure the concentration degree of\nuser's interests. These features affect the trade-off between accuracy and\ndiversity of our personalized recommendation system. Taking these features into\naccount, our system finally achieves recommending news to different users at\ntheir different levels of concentration degrees.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 05:13:43 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 10:11:58 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Ma", "Mingyuan", ""], ["Na", "Sen", ""], ["Wang", "Hongyu", ""], ["Chen", "Congzhou", ""], ["Xu", "Jin", ""]]}, {"id": "1812.00029", "submitter": "Cencheng Shen", "authors": "Cencheng Shen and Sambit Panda and Joshua T. Vogelstein", "title": "Learning Interpretable Characteristic Kernels via Decision Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision forests are popular tools for classification and regression. These\nforests naturally produce proximity matrices measuring how often each pair of\nobservations lies in the same leaf node. It has been demonstrated that these\nproximity matrices can be thought of as kernels, connecting the decision forest\nliterature to the extensive kernel machine literature. While other kernels are\nknown to have strong theoretical properties such as being characteristic, no\nsimilar result is available for any decision forest based kernel. In this\nmanuscript,we prove that the decision forest induced proximity can be made\ncharacteristic, which can be used to yield a universally consistent statistic\nfor testing independence. We demonstrate the performance of the induced kernel\non a suite of 20 high-dimensional independence test settings. We also show how\nthis learning kernel offers insights into relative feature importance. The\ndecision forest induced kernel typically achieves substantially higher testing\npower than existing popular methods in statistical tests.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 19:31:17 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:46:38 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Shen", "Cencheng", ""], ["Panda", "Sambit", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1812.00030", "submitter": "Aaron Masino", "authors": "Aaron J. Masino, Kaitlin A. Folweiler", "title": "Unsupervised learning with GLRM feature selection reveals novel\n  traumatic brain injury phenotypes", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/24", "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Baseline injury categorization is important to traumatic brain injury (TBI)\nresearch and treatment. Current categorization is dominated by symptom-based\nscores that insufficiently capture injury heterogeneity. In this work, we apply\nunsupervised clustering to identify novel TBI phenotypes. Our approach uses a\ngeneralized low-rank model (GLRM) model for feature selection in a procedure\nanalogous to wrapper methods. The resulting clusters reveal four novel TBI\nphenotypes with distinct feature profiles and that correlate to 90-day\nfunctional and cognitive status.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 19:38:35 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Masino", "Aaron J.", ""], ["Folweiler", "Kaitlin A.", ""]]}, {"id": "1812.00033", "submitter": "Tong Yu", "authors": "Tong Yu, Didier Mutter, Jacques Marescaux, Nicolas Padoy", "title": "Learning from a tiny dataset of manual annotations: a teacher/student\n  approach for surgical phase recognition", "comments": "Accepted at IPCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision algorithms capable of interpreting scenes from a real-time video\nstream are necessary for computer-assisted surgery systems to achieve\ncontext-aware behavior. In laparoscopic procedures one particular algorithm\nneeded for such systems is the identification of surgical phases, for which the\ncurrent state of the art is a model based on a CNN-LSTM. A number of previous\nworks using models of this kind have trained them in a fully supervised manner,\nrequiring a fully annotated dataset. Instead, our work confronts the problem of\nlearning surgical phase recognition in scenarios presenting scarce amounts of\nannotated data (under 25% of all available video recordings). We propose a\nteacher/student type of approach, where a strong predictor called the teacher,\ntrained beforehand on a small dataset of ground truth-annotated videos,\ngenerates synthetic annotations for a larger dataset, which another model - the\nstudent - learns from. In our case, the teacher features a novel CNN-biLSTM-CRF\narchitecture, designed for offline inference only. The student, on the other\nhand, is a CNN-LSTM capable of making real-time predictions. Results for\nvarious amounts of manually annotated videos demonstrate the superiority of the\nnew CNN-biLSTM-CRF predictor as well as improved performance from the CNN-LSTM\ntrained using synthetic labels generated for unannotated videos. For both\noffline and online surgical phase recognition with very few annotated\nrecordings available, this new teacher/student strategy provides a valuable\nperformance improvement by efficiently leveraging the unannotated data.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 19:50:05 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 16:04:22 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 14:22:43 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Yu", "Tong", ""], ["Mutter", "Didier", ""], ["Marescaux", "Jacques", ""], ["Padoy", "Nicolas", ""]]}, {"id": "1812.00050", "submitter": "Michael Rapp", "authors": "Eneldo Loza Menc\\'ia, Johannes F\\\"urnkranz, Eyke H\\\"ullermeier,\n  Michael Rapp", "title": "Learning Interpretable Rules for Multi-label Classification", "comments": "Preprint version. To appear in: Explainable and Interpretable Models\n  in Computer Vision and Machine Learning. The Springer Series on Challenges in\n  Machine Learning. Springer (2018). See\n  http://www.ke.tu-darmstadt.de/bibtex/publications/show/3077 for further\n  information", "journal-ref": "In Jair Escalante, H., Escalera, S., Guyon, I., Bar\\'o, X.,\n  G\\\"u\\c{c}l\\\"ut\\\"urk, Y., G\\\"u\\c{c}l\\\"u, U., van Gerven, M.A.J. (Eds.)\n  Explainable and Interpretable Models in Computer Vision and Machine Learning,\n  Springer-Verlag, 2018, pp.81-113", "doi": "10.1007/978-3-319-98131-4_4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) is a supervised learning problem in which,\ncontrary to standard multiclass classification, an instance can be associated\nwith several class labels simultaneously. In this chapter, we advocate a\nrule-based approach to multi-label classification. Rule learning algorithms are\noften employed when one is not only interested in accurate predictions, but\nalso requires an interpretable theory that can be understood, analyzed, and\nqualitatively evaluated by domain experts. Ideally, by revealing patterns and\nregularities contained in the data, a rule-based theory yields new insights in\nthe application domain. Recently, several authors have started to investigate\nhow rule-based models can be used for modeling multi-label data. Discussing\nthis task in detail, we highlight some of the problems that make rule learning\nconsiderably more challenging for MLC than for conventional classification.\nWhile mainly focusing on our own previous work, we also provide a short\noverview of related work in this area.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 20:48:12 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 12:50:59 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Menc\u00eda", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""], ["H\u00fcllermeier", "Eyke", ""], ["Rapp", "Michael", ""]]}, {"id": "1812.00058", "submitter": "Sven Giesselbach", "authors": "Sven Giesselbach, Katrin Ullrich, Michael Kamp, Daniel Paurat and\n  Thomas G\\\"artner", "title": "Corresponding Projections for Orphan Screening", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/155", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel transfer learning approach for orphan screening called\ncorresponding projections. In orphan screening the learning task is to predict\nthe binding affinities of compounds to an orphan protein, i.e., one for which\nno training data is available. The identification of compounds with high\naffinity is a central concern in medicine since it can be used for drug\ndiscovery and design. Given a set of prediction models for proteins with\nlabelled training data and a similarity between the proteins, corresponding\nprojections constructs a model for the orphan protein from them such that the\nsimilarity between models resembles the one between proteins. Under the\nassumption that the similarity resemblance holds, we derive an efficient\nalgorithm for kernel methods. We empirically show that the approach outperforms\nthe state-of-the-art in orphan screening.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 21:07:33 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Giesselbach", "Sven", ""], ["Ullrich", "Katrin", ""], ["Kamp", "Michael", ""], ["Paurat", "Daniel", ""], ["G\u00e4rtner", "Thomas", ""]]}, {"id": "1812.00068", "submitter": "Mohamed Elfeki", "authors": "Mohamed Elfeki, Camille Couprie, Morgane Riviere, and Mohamed\n  Elhoseiny", "title": "GDPP: Learning Diverse Generations Using Determinantal Point Process", "comments": null, "journal-ref": "International Conference on Machine Learning 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models have proven to be an outstanding tool for representing\nhigh-dimensional probability distributions and generating realistic-looking\nimages. An essential characteristic of generative models is their ability to\nproduce multi-modal outputs. However, while training, they are often\nsusceptible to mode collapse, that is models are limited in mapping input noise\nto only a few modes of the true data distribution. In this work, we draw\ninspiration from Determinantal Point Process (DPP) to propose an unsupervised\npenalty loss that alleviates mode collapse while producing higher quality\nsamples. DPP is an elegant probabilistic measure used to model negative\ncorrelations within a subset and hence quantify its diversity. We use DPP\nkernel to model the diversity in real data as well as in synthetic data. Then,\nwe devise an objective term that encourages generators to synthesize data with\nsimilar diversity to real data. In contrast to previous state-of-the-art\ngenerative models that tend to use additional trainable parameters or complex\ntraining paradigms, our method does not change the original training scheme.\nEmbedded in an adversarial training and variational autoencoder, our Generative\nDPP approach shows a consistent resistance to mode-collapse on a wide variety\nof synthetic data and natural image datasets including MNIST, CIFAR10, and\nCelebA, while outperforming state-of-the-art methods for data-efficiency,\ngeneration quality, and convergence-time whereas being 5.8x faster than its\nclosest competitor.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 21:54:48 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 20:47:48 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 19:07:40 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 20:45:48 GMT"}, {"version": "v5", "created": "Mon, 25 Nov 2019 01:37:16 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Elfeki", "Mohamed", ""], ["Couprie", "Camille", ""], ["Riviere", "Morgane", ""], ["Elhoseiny", "Mohamed", ""]]}, {"id": "1812.00071", "submitter": "Victor Gallego", "authors": "Victor Gallego and David Rios Insua", "title": "Stochastic Gradient MCMC with Repulsive Forces", "comments": "Extends the workshop version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unifying view of two different Bayesian inference algorithms,\nStochastic Gradient Markov Chain Monte Carlo (SG-MCMC) and Stein Variational\nGradient Descent (SVGD), leading to improved and efficient novel sampling\nschemes. We show that SVGD combined with a noise term can be framed as a\nmultiple chain SG-MCMC method. Instead of treating each parallel chain\nindependently from others, our proposed algorithm implements a repulsive force\nbetween particles, avoiding collapse and facilitating a better exploration of\nthe parameter space. We also show how the addition of this noise term is\nnecessary to obtain a valid SG-MCMC sampler, a significant difference with\nSVGD. Experiments with both synthetic distributions and real datasets\nillustrate the benefits of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 22:06:15 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 12:35:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gallego", "Victor", ""], ["Insua", "David Rios", ""]]}, {"id": "1812.00086", "submitter": "Li Zhang", "authors": "Li Zhang, Heda Song, Haiping Lu", "title": "Graph Node-Feature Convolution for Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) is an emerging neural network approach. It\nlearns new representation of a node by aggregating feature vectors of all\nneighbors in the aggregation process without considering whether the neighbors\nor features are useful or not. Recent methods have improved solutions by\nsampling a fixed size set of neighbors, or assigning different weights to\ndifferent neighbors in the aggregation process, but features within a feature\nvector are still treated equally in the aggregation process. In this paper, we\nintroduce a new convolution operation on regular size feature maps constructed\nfrom features of a fixed node bandwidth via sampling to get the first-level\nnode representation, which is then passed to a standard GCN to learn the\nsecond-level node representation. Experiments show that our method outperforms\ncompeting methods in semi-supervised node classification tasks. Furthermore,\nour method opens new doors for exploring new GCN architectures, particularly\ndeeper GCN models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 22:58:50 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Zhang", "Li", ""], ["Song", "Heda", ""], ["Lu", "Haiping", ""]]}, {"id": "1812.00098", "submitter": "Danielle Maddix", "authors": "Danielle C. Maddix and Yuyang Wang and Alex Smola", "title": "Deep Factors with Gaussian Processes for Forecasting", "comments": "Third workshop on Bayesian Deep Learning (NeurIPS 2018), Montreal,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large collection of time series poses significant challenges for classical\nand neural forecasting approaches. Classical time series models fail to fit\ndata well and to scale to large problems, but succeed at providing uncertainty\nestimates. The converse is true for deep neural networks. In this paper, we\npropose a hybrid model that incorporates the benefits of both approaches. Our\nnew method is data-driven and scalable via a latent, global, deep component. It\nalso handles uncertainty through a local classical Gaussian Process model. Our\nexperiments demonstrate that our method obtains higher accuracy than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 23:42:53 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Maddix", "Danielle C.", ""], ["Wang", "Yuyang", ""], ["Smola", "Alex", ""]]}, {"id": "1812.00099", "submitter": "Kush Varshney", "authors": "Vidya Muthukumar, Tejaswini Pedapati, Nalini Ratha, Prasanna\n  Sattigeri, Chai-Wah Wu, Brian Kingsbury, Abhishek Kumar, Samuel Thomas,\n  Aleksandra Mojsilovic, and Kush R. Varshney", "title": "Understanding Unequal Gender Classification Accuracy from Face Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work shows unequal performance of commercial face classification\nservices in the gender classification task across intersectional groups defined\nby skin type and gender. Accuracy on dark-skinned females is significantly\nworse than on any other group. In this paper, we conduct several analyses to\ntry to uncover the reason for this gap. The main finding, perhaps surprisingly,\nis that skin type is not the driver. This conclusion is reached via stability\nexperiments that vary an image's skin type via color-theoretic methods, namely\nluminance mode-shift and optimal transport. A second suspect, hair length, is\nalso shown not to be the driver via experiments on face images cropped to\nexclude the hair. Finally, using contrastive post-hoc explanation techniques\nfor neural networks, we bring forth evidence suggesting that differences in\nlip, eye and cheek structure across ethnicity lead to the differences. Further,\nlip and eye makeup are seen as strong predictors for a female face, which is a\ntroubling propagation of a gender stereotype.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 23:47:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Muthukumar", "Vidya", ""], ["Pedapati", "Tejaswini", ""], ["Ratha", "Nalini", ""], ["Sattigeri", "Prasanna", ""], ["Wu", "Chai-Wah", ""], ["Kingsbury", "Brian", ""], ["Kumar", "Abhishek", ""], ["Thomas", "Samuel", ""], ["Mojsilovic", "Aleksandra", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1812.00116", "submitter": "Honglei Liu", "authors": "Honglei Liu, Anuj Kumar, Wenhai Yang, Benoit Dumoulin", "title": "Explore-Exploit: A Framework for Interactive and Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive user interfaces need to continuously evolve based on the\ninteractions that a user has (or does not have) with the system. This may\nrequire constant exploration of various options that the system may have for\nthe user and obtaining signals of user preferences on those. However, such an\nexploration, especially when the set of available options itself can change\nfrequently, can lead to sub-optimal user experiences. We present\nExplore-Exploit: a framework designed to collect and utilize user feedback in\nan interactive and online setting that minimizes regressions in end-user\nexperience. This framework provides a suite of online learning operators for\nvarious tasks such as personalization ranking, candidate selection and active\nlearning. We demonstrate how to integrate this framework with run-time services\nto leverage online and interactive machine learning out-of-the-box. We also\npresent results demonstrating the efficiencies that can be achieved using the\nExplore-Exploit framework.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 01:16:24 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Liu", "Honglei", ""], ["Kumar", "Anuj", ""], ["Yang", "Wenhai", ""], ["Dumoulin", "Benoit", ""]]}, {"id": "1812.00139", "submitter": "Sewoong Oh", "authors": "Ashish Khetan, Harshay Shah, and Sewoong Oh", "title": "Number of Connected Components in a Graph: Estimation via Counting\n  Patterns", "comments": "31 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the limited resources and the scale of the graphs in modern datasets,\nwe often get to observe a sampled subgraph of a larger original graph of\ninterest, whether it is the worldwide web that has been crawled or social\nconnections that have been surveyed. Inferring a global property of the\noriginal graph from such a sampled subgraph is of a fundamental interest. In\nthis work, we focus on estimating the number of connected components. It is a\nchallenging problem and, for general graphs, little is known about the\nconnection between the observed subgraph and the number of connected components\nof the original graph. In order to make this connection, we propose a highly\nredundant and large-dimensional representation of the subgraph, which at first\nglance seems counter-intuitive. A subgraph is represented by the counts of\npatterns, known as network motifs. This representation is crucial in\nintroducing a novel estimator for the number of connected components for\ngeneral graphs, under the knowledge of the spectral gap of the original graph.\nThe connection is made precise via the Schatten $k$-norms of the graph\nLaplacian and the spectral representation of the number of connected\ncomponents. We provide a guarantee on the resulting mean squared error that\ncharacterizes the bias variance tradeoff. Experiments on synthetic and\nreal-world graphs suggest that we improve upon competing algorithms for graphs\nwith spectral gaps bounded away from zero.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 04:08:46 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Khetan", "Ashish", ""], ["Shah", "Harshay", ""], ["Oh", "Sewoong", ""]]}, {"id": "1812.00141", "submitter": "Jiqian Dong", "authors": "Jiqian Dong, Gopaljee Atulya, Kartikeya Bhardwaj, and Radu Marculescu", "title": "A Dynamic Network and Representation LearningApproach for Quantifying\n  Economic Growth fromSatellite Imagery", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the improvement in human living standard, as well as the city\ngrowth in developing countries, is a challenging problem due to the lack of\nreliable economic data. Therefore, there is a fundamental need for alternate,\nlargely unsupervised, computational methods that can estimate the economic\nconditions in the developing regions. To this end, we propose a new network\nscience- and representation learning-based approach that can quantify economic\nindicators and visualize the growth of various regions. More precisely, we\nfirst create a dynamic network drawn out of high-resolution nightlight\nsatellite images. We then demonstrate that using representation learning to\nmine the resulting network, our proposed approach can accurately predict\nspatial gross economic expenditures over large regions. Our method, which\nrequires only nightlight images and limited survey data, can capture\ncity-growth, as well as how people's living standard is changing; this can\nultimately facilitate the decision makers' understanding of growth without\nheavily relying on expensive and time-consuming surveys.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 04:20:21 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Dong", "Jiqian", ""], ["Atulya", "Gopaljee", ""], ["Bhardwaj", "Kartikeya", ""], ["Marculescu", "Radu", ""]]}, {"id": "1812.00149", "submitter": "Mohammad Ariful Haque", "authors": "Md. Shamim Hussain, Mohammad Ariful Haque", "title": "SwishNet: A Fast Convolutional Neural Network for Speech, Music and\n  Noise Classification and Segmentation", "comments": "7 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech, Music and Noise classification/segmentation is an important\npreprocessing step for audio processing/indexing. To this end, we propose a\nnovel 1D Convolutional Neural Network (CNN) - SwishNet. It is a fast and\nlightweight architecture that operates on MFCC features which is suitable to be\nadded to the front-end of an audio processing pipeline. We showed that the\nperformance of our network can be improved by distilling knowledge from a 2D\nCNN, pretrained on ImageNet. We investigated the performance of our network on\nthe MUSAN corpus - an openly available comprehensive collection of noise, music\nand speech samples, suitable for deep learning. The proposed network achieved\nhigh overall accuracy in clip (length of 0.5-2s) classification (>97% accuracy)\nand frame-wise segmentation (>93% accuracy) tasks with even higher accuracy\n(>99%) in speech/non-speech discrimination task. To verify the robustness of\nour model, we trained it on MUSAN and evaluated it on a different corpus -\nGTZAN and found good accuracy with very little fine-tuning. We also\ndemonstrated that our model is fast on both CPU and GPU, consumes a low amount\nof memory and is suitable for implementation in embedded systems.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 05:39:07 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Hussain", "Md. Shamim", ""], ["Haque", "Mohammad Ariful", ""]]}, {"id": "1812.00151", "submitter": "Qi Lei", "authors": "Qi Lei, Lingfei Wu, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S.\n  Dhillon, Michael Witbrock", "title": "Discrete Adversarial Attacks and Submodular Optimization with\n  Applications to Text Classification", "comments": "In SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are carefully constructed modifications to an input that\ncompletely change the output of a classifier but are imperceptible to humans.\nDespite these successful attacks for continuous data (such as image and audio\nsamples), generating adversarial examples for discrete structures such as text\nhas proven significantly more challenging. In this paper we formulate the\nattacks with discrete input on a set function as an optimization task. We prove\nthat this set function is submodular for some popular neural network text\nclassifiers under simplifying assumption. This finding guarantees a $1-1/e$\napproximation factor for attacks that use the greedy algorithm. Meanwhile, we\nshow how to use the gradient of the attacked classifier to guide the greedy\nsearch. Empirical studies with our proposed optimization scheme show\nsignificantly improved attack ability and efficiency, on three different text\nclassification tasks over various baselines. We also use a joint sentence and\nword paraphrasing technique to maintain the original semantics and syntax of\nthe text. This is validated by a human subject evaluation in subjective metrics\non the quality and semantic coherence of our generated adversarial text.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 05:48:16 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 19:56:23 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Lei", "Qi", ""], ["Wu", "Lingfei", ""], ["Chen", "Pin-Yu", ""], ["Dimakis", "Alexandros G.", ""], ["Dhillon", "Inderjit S.", ""], ["Witbrock", "Michael", ""]]}, {"id": "1812.00172", "submitter": "Jonathan Warrell", "authors": "Jonathan Warrell, Hussein Mohsen, Mark Gerstein", "title": "Rank Projection Trees for Multilevel Neural Network Interpretation", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/186", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of methods have been proposed for interpreting nodes in deep neural\nnetworks, which typically involve scoring nodes at lower layers with respect to\ntheir effects on the output of higher-layer nodes (where lower and higher\nlayers are closer to the input and output layers, respectively). However, we\nmay be interested in picking out a prioritized collection of subsets of the\ninputs across a range of scales according to their importance for an output\nnode, and not simply a prioritized ranking across the inputs as singletons.\nSuch a situation may arise in biological applications, for instance, where we\nare interested in epistatic effects between groups of genes in determining a\ntrait of interest. Here, we outline a flexible framework which may be used to\ngenerate multiscale network interpretations, using any previously defined\nscoring function. We demonstrate the ability of our method to pick out\nbiologically important genes and gene sets in the domains of cancer and\npsychiatric genomics.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 08:07:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Warrell", "Jonathan", ""], ["Mohsen", "Hussein", ""], ["Gerstein", "Mark", ""]]}, {"id": "1812.00174", "submitter": "Qi Sun", "authors": "Qi Sun, Yunzhe Tao, and Qiang Du", "title": "Stochastic Training of Residual Networks: a Differential Equation\n  Viewpoint", "comments": "20 pages, 8 figures, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last few years, significant attention has been paid to the\nstochastic training of artificial neural networks, which is known as an\neffective regularization approach that helps improve the generalization\ncapability of trained models. In this work, the method of modified equations is\napplied to show that the residual network and its variants with noise injection\ncan be regarded as weak approximations of stochastic differential equations.\nSuch observations enable us to bridge the stochastic training processes with\nthe optimal control of backward Kolmogorov's equations. This not only offers a\nnovel perspective on the effects of regularization from the loss landscape\nviewpoint but also sheds light on the design of more reliable and efficient\nstochastic training strategies. As an example, we propose a new way to utilize\nBernoulli dropout within the plain residual network architecture and conduct\nexperiments on a real-world image classification task to substantiate our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 08:12:01 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Sun", "Qi", ""], ["Tao", "Yunzhe", ""], ["Du", "Qiang", ""]]}, {"id": "1812.00181", "submitter": "Sean Saito", "authors": "Sean Saito, Sujoy Roy", "title": "Effects of Loss Functions And Target Representations on Adversarial\n  Robustness", "comments": "8 pages, 4 figures. Accepted at MLSys 2020 First Workshop on Secure\n  and Resilient Autonomy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and evaluating the robustness of neural networks under\nadversarial settings is a subject of growing interest. Attacks proposed in the\nliterature usually work with models trained to minimize cross-entropy loss and\noutput softmax probabilities. In this work, we present interesting experimental\nresults that suggest the importance of considering other loss functions and\ntarget representations, specifically, (1) training on mean-squared error and\n(2) representing targets as codewords generated from a random codebook. We\nevaluate the robustness of neural networks that implement these proposed\nmodifications using existing attacks, showing an increase in accuracy against\nuntargeted attacks of up to 98.7\\% and a decrease of targeted attack success\nrates of up to 99.8\\%. Our model demonstrates more robustness compared to its\nconventional counterpart even against attacks that are tailored to our\nmodifications. Furthermore, we find that the parameters of our modified model\nhave significantly smaller Lipschitz bounds, an important measure correlated\nwith a model's sensitivity to adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 09:53:50 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 06:36:34 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 15:31:13 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Saito", "Sean", ""], ["Roy", "Sujoy", ""]]}, {"id": "1812.00209", "submitter": "Andrew Miller", "authors": "Andrew C. Miller, Ziad Obermeyer, David M. Blei, John P. Cunningham,\n  Sendhil Mullainathan", "title": "A Probabilistic Model of Cardiac Physiology and Electrocardiograms", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/97", "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An electrocardiogram (EKG) is a common, non-invasive test that measures the\nelectrical activity of a patient's heart. EKGs contain useful diagnostic\ninformation about patient health that may be absent from other electronic\nhealth record (EHR) data. As multi-dimensional waveforms, they could be modeled\nusing generic machine learning tools, such as a linear factor model or a\nvariational autoencoder. We take a different approach:~we specify a model that\ndirectly represents the underlying electrophysiology of the heart and the EKG\nmeasurement process. We apply our model to two datasets, including a sample of\nemergency department EKG reports with missing data. We show that our model can\nmore accurately reconstruct missing data (measured by test reconstruction\nerror) than a standard baseline when there is significant missing data. More\nbroadly, this physiological representation of heart function may be useful in a\nvariety of settings, including prediction, causal analysis, and discovery.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 14:24:47 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Miller", "Andrew C.", ""], ["Obermeyer", "Ziad", ""], ["Blei", "David M.", ""], ["Cunningham", "John P.", ""], ["Mullainathan", "Sendhil", ""]]}, {"id": "1812.00210", "submitter": "Andrew Miller", "authors": "Andrew C. Miller, Ziad Obermeyer, Sendhil Mullainathan", "title": "Measuring the Stability of EHR- and EKG-based Predictive Models", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/188", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Databases of electronic health records (EHRs) are increasingly used to inform\nclinical decisions. Machine learning methods can find patterns in EHRs that are\npredictive of future adverse outcomes. However, statistical models may be built\nupon patterns of health-seeking behavior that vary across patient\nsubpopulations, leading to poor predictive performance when training on one\npatient population and predicting on another. This note proposes two tests to\nbetter measure and understand model generalization. We use these tests to\ncompare models derived from two data sources: (i) historical medical records,\nand (ii) electrocardiogram (EKG) waveforms. In a predictive task, we show that\nEKG-based models can be more stable than EHR-based models across different\npatient populations.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 14:32:06 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Miller", "Andrew C.", ""], ["Obermeyer", "Ziad", ""], ["Mullainathan", "Sendhil", ""]]}, {"id": "1812.00237", "submitter": "Kumar Sricharan", "authors": "Kumar Sricharan, Kumar Kallurupalli, Ashok Srivastava", "title": "Improving robustness of classifiers by training against live traffic", "comments": "Third workshop on Bayesian Deep Learning (NeurIPS 2018), Montr\\'eal,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are known to be overconfident in their predictions on\nout of distribution inputs. This is a challenge when a model is trained on a\nparticular input dataset, but receives out of sample data when deployed in\npractice. Recently, there has been work on building classifiers that are robust\nto out of distribution samples by adding a regularization term that maximizes\nthe entropy of the classifier output on out of distribution data. However,\ngiven the challenge that it is not always possible to obtain out of\ndistribution samples, the authors suggest a GAN based alternative that is\nindependent of specific knowledge of out of distribution samples. From this\nexisting work, we also know that having access to the true out of sample\ndistribution for regularization works significantly better than using samples\nfrom the GAN. In this paper, we make the following observation: in practice,\nthe out of distribution samples are contained in the traffic that hits a\ndeployed classifier. However, the traffic will also contain a unknown\nproportion of in-distribution samples. If the entropy over of all of the\ntraffic data were to be naively maximized, this will hurt the classifier\nperformance on in-distribution data. To effectively leverage this traffic data,\nwe propose an adaptive regularization technique (based on the maximum\npredictive probability score of a sample) which penalizes out of distribution\nsamples more heavily than in distribution samples in the incoming traffic. This\nensures that the overall performance of the classifier does not degrade on\nin-distribution data, while detection of out-of-distribution samples is\nsignificantly improved by leveraging the unlabeled traffic data. We show the\neffectiveness of our method via experiments on natural image datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 18:41:19 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Sricharan", "Kumar", ""], ["Kallurupalli", "Kumar", ""], ["Srivastava", "Ashok", ""]]}, {"id": "1812.00239", "submitter": "Kumar Sricharan", "authors": "Kumar Sricharan, Ashok Srivastava", "title": "Building robust classifiers through generation of confident out of\n  distribution examples", "comments": "Third workshop on Bayesian Deep Learning (NeurIPS 2018), Montr\\'eal,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are known to be overconfident in their predictions on\nout of distribution inputs. There have been several pieces of work to address\nthis issue, including a number of approaches for building Bayesian neural\nnetworks, as well as closely related work on detection of out of distribution\nsamples. Recently, there has been work on building classifiers that are robust\nto out of distribution samples by adding a regularization term that maximizes\nthe entropy of the classifier output on out of distribution data. To\napproximate out of distribution samples (which are not known apriori), a GAN\nwas used for generation of samples at the edges of the training distribution.\nIn this paper, we introduce an alternative GAN based approach for building a\nrobust classifier, where the idea is to use the GAN to explicitly generate out\nof distribution samples that the classifier is confident on (low entropy), and\nhave the classifier maximize the entropy for these samples. We showcase the\neffectiveness of our approach relative to state-of-the-art on hand-written\ncharacters as well as on a variety of natural image datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 18:51:26 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Sricharan", "Kumar", ""], ["Srivastava", "Ashok", ""]]}, {"id": "1812.00249", "submitter": "Karttikeya Mangalam", "authors": "Karttikeya Mangalam, Mathieu Salzamann", "title": "On Compressing U-net Using Knowledge Distillation", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of knowledge distillation to compress the U-net\narchitecture. We show that, while standard distillation is not sufficient to\nreliably train a compressed U-net, introducing other regularization methods,\nsuch as batch normalization and class re-weighting, in knowledge distillation\nsignificantly improves the training process. This allows us to compress a U-net\nby over 1000x, i.e., to 0.1% of its original number of parameters, at a\nnegligible decrease in performance.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 19:30:55 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Mangalam", "Karttikeya", ""], ["Salzamann", "Mathieu", ""]]}, {"id": "1812.00257", "submitter": "Mohamed Medhat Gaber", "authors": "Diana Haidar, Mohamed Medhat Gaber, Yevgeniya Kovalchuk", "title": "AnyThreat: An Opportunistic Knowledge Discovery Approach to Insider\n  Threat Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insider threat detection is getting an increased concern from academia,\nindustry, and governments due to the growing number of malicious insider\nincidents. The existing approaches proposed for detecting insider threats still\nhave a common shortcoming, which is the high number of false alarms (false\npositives). The challenge in these approaches is that it is essential to detect\nall anomalous behaviours which belong to a particular threat. To address this\nshortcoming, we propose an opportunistic knowledge discovery system, namely\nAnyThreat, with the aim to detect any anomalous behaviour in all malicious\ninsider threats. We design the AnyThreat system with four components. (1) A\nfeature engineering component, which constructs community data sets from the\nactivity logs of a group of users having the same role. (2) An oversampling\ncomponent, where we propose a novel oversampling technique named Artificial\nMinority Oversampling and Trapper REmoval (AMOTRE). AMOTRE first removes the\nminority (anomalous) instances that have a high resemblance with normal\n(majority) instances to reduce the number of false alarms, then it\nsynthetically oversamples the minority class by shielding the border of the\nmajority class. (3) A class decomposition component, which is introduced to\ncluster the instances of the majority class into subclasses to weaken the\neffect of the majority class without information loss. (4) A classification\ncomponent, which applies a classification method on the subclasses to achieve a\nbetter separation between the majority class(es) and the minority class(es).\nAnyThreat is evaluated on synthetic data sets generated by Carnegie Mellon\nUniversity. It detects approximately 87.5% of malicious insider threats, and\nachieves the minimum of false positives=3.36%.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 20:20:49 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Haidar", "Diana", ""], ["Gaber", "Mohamed Medhat", ""], ["Kovalchuk", "Yevgeniya", ""]]}, {"id": "1812.00259", "submitter": "Edmond Cunningham", "authors": "Edmond Cunningham and Dana Schlegel and Andrew DeOrio", "title": "Explainable Genetic Inheritance Pattern Prediction", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/56", "categories": "stat.ML cs.LG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosing an inherited disease often requires identifying the pattern of\ninheritance in a patient's family. We represent family trees with genetic\npatterns of inheritance using hypergraphs and latent state space models to\nprovide explainable inheritance pattern predictions. Our approach allows for\nexact causal inference over a patient's possible genotypes given their\nrelatives' phenotypes. By design, inference can be examined at a low level to\nprovide explainable predictions. Furthermore, we make use of human intuition by\nproviding a method to assign hypothetical evidence to any inherited gene\nalleles. Our analysis supports the application of latent state space models to\nimprove patient care in cases of rare inherited diseases where access to\ngenetic specialists is limited.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 20:23:52 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 03:27:16 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 01:47:20 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Cunningham", "Edmond", ""], ["Schlegel", "Dana", ""], ["DeOrio", "Andrew", ""]]}, {"id": "1812.00262", "submitter": "Irene C\\'ordoba", "authors": "Irene C\\'ordoba, Concha Bielza, Pedro Larra\\~naga", "title": "Towards Gaussian Bayesian Network Fusion", "comments": "10 pages, 3 figures, 2015 conference", "journal-ref": "Springer Lecture Notes in Artificial Intelligence (ECSQARU 2015),\n  vol 9161, pages 519-528", "doi": "10.1007/978-3-319-20807-7_47", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sets are growing in complexity thanks to the increasing facilities we\nhave nowadays to both generate and store data. This poses many challenges to\nmachine learning that are leading to the proposal of new methods and paradigms,\nin order to be able to deal with what is nowadays referred to as Big Data. In\nthis paper we propose a method for the aggregation of different Bayesian\nnetwork structures that have been learned from separate data sets, as a first\nstep towards mining data sets that need to be partitioned in an horizontal way,\ni.e. with respect to the instances, in order to be processed. Considerations\nthat should be taken into account when dealing with this situation are\ndiscussed. Scalable learning of Bayesian networks is slowly emerging, and our\nmethod constitutes one of the first insights into Gaussian Bayesian network\naggregation from different sources. Tested on synthetic data it obtains good\nresults that surpass those from individual learning. Future research will be\nfocused on expanding the method and testing more diverse data sets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 20:59:03 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["C\u00f3rdoba", "Irene", ""], ["Bielza", "Concha", ""], ["Larra\u00f1aga", "Pedro", ""]]}, {"id": "1812.00265", "submitter": "Phillip Pope", "authors": "Phillip Pope, Soheil Kolouri, Mohammad Rostrami, Charles Martin, Heiko\n  Hoffmann", "title": "Discovering Molecular Functional Groups Using Graph Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional groups (FGs) are molecular substructures that are served as a\nfoundation for analyzing and predicting chemical properties of molecules.\nAutomatic discovery of FGs will impact various fields of research, including\nmedicinal chemistry and material sciences, by reducing the amount of lab\nexperiments required for discovery or synthesis of new molecules. In this\npaper, we investigate methods based on graph convolutional neural networks\n(GCNNs) for localizing FGs that contribute to specific chemical properties of\ninterest. In our framework, molecules are modeled as undirected relational\ngraphs with atoms as nodes and bonds as edges. Using this relational graph\nstructure, we trained GCNNs in a supervised way on experimentally-validated\nmolecular training sets to predict specific chemical properties, e.g.,\ntoxicity. Upon learning a GCNN, we analyzed its activation patterns to\nautomatically identify FGs using four different explainability methods that we\nhave developed: gradient-based saliency maps, Class Activation Mapping (CAM),\ngradient-weighted CAM (Grad-CAM), and Excitation Back-Propagation. Although\nthese methods are originally derived for convolutional neural networks (CNNs),\nwe adapt them to develop the corresponding suitable versions for GCNNs. We\nevaluated the contrastive power of these methods with respect to the\nspecificity of the identified molecular substructures and their relevance for\nchemical functions. Grad-CAM had the highest contrastive power and generated\nqualitatively the best FGs. This work paves the way for automatic analysis and\ndesign of new molecules.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 21:06:45 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 19:18:53 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 20:37:35 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Pope", "Phillip", ""], ["Kolouri", "Soheil", ""], ["Rostrami", "Mohammad", ""], ["Martin", "Charles", ""], ["Hoffmann", "Heiko", ""]]}, {"id": "1812.00268", "submitter": "Mingjie Mai", "authors": "Chun-Hao Chang, Mingjie Mai, Anna Goldenberg", "title": "Dynamic Measurement Scheduling for Adverse Event Forecasting using Deep\n  RL", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/143", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current clinical practice to monitor patients' health follows either regular\nor heuristic-based lab test (e.g. blood test) scheduling. Such practice not\nonly gives rise to redundant measurements accruing cost, but may even lead to\nunnecessary patient discomfort. From the computational perspective,\nheuristic-based test scheduling might lead to reduced accuracy of clinical\nforecasting models. Computationally learning an optimal clinical test\nscheduling and measurement collection, is likely to lead to both, better\npredictive models and patient outcome improvement. We address the scheduling\nproblem using deep reinforcement learning (RL) to achieve high predictive gain\nand low measurement cost, by scheduling fewer, but strategically timed tests.\nWe first show that in the simulation our policy outperforms heuristic-based\nmeasurement scheduling with higher predictive gain or lower cost measured by\naccumulated reward. We then learn a scheduling policy for mortality forecasting\nin the real-world clinical dataset (MIMIC3), our learned policy is able to\nprovide useful clinical insights. To our knowledge, this is the first RL\napplication on multi-measurement scheduling problem in the clinical setting.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 21:31:53 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Chang", "Chun-Hao", ""], ["Mai", "Mingjie", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1812.00273", "submitter": "Hugo Prol Pereira", "authors": "Hugo Prol, Vincent Dumoulin, Luis Herranz", "title": "Cross-Modulation Networks for Few-Shot Learning", "comments": "Accepted at NIPS 2018 Workshop on Meta-Learning. Source code\n  available at https://github.com/hprop/cross-modulation-nets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A family of recent successful approaches to few-shot learning relies on\nlearning an embedding space in which predictions are made by computing\nsimilarities between examples. This corresponds to combining information\nbetween support and query examples at a very late stage of the prediction\npipeline. Inspired by this observation, we hypothesize that there may be\nbenefits to combining the information at various levels of abstraction along\nthe pipeline. We present an architecture called Cross-Modulation Networks which\nallows support and query examples to interact throughout the feature extraction\nprocess via a feature-wise modulation mechanism. We adapt the Matching Networks\narchitecture to take advantage of these interactions and show encouraging\ninitial results on miniImageNet in the 5-way, 1-shot setting, where we close\nthe gap with state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 22:02:04 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Prol", "Hugo", ""], ["Dumoulin", "Vincent", ""], ["Herranz", "Luis", ""]]}, {"id": "1812.00279", "submitter": "Daniel Neil", "authors": "Daniel Neil, Joss Briody, Alix Lacoste, Aaron Sim, Paidi Creed, Amir\n  Saffari", "title": "Interpretable Graph Convolutional Neural Networks for Inference on Noisy\n  Knowledge Graphs", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide a new formulation for Graph Convolutional Neural\nNetworks (GCNNs) for link prediction on graph data that addresses common\nchallenges for biomedical knowledge graphs (KGs). We introduce a regularized\nattention mechanism to GCNNs that not only improves performance on clean\ndatasets, but also favorably accommodates noise in KGs, a pervasive issue in\nreal-world applications. Further, we explore new visualization methods for\ninterpretable modelling and to illustrate how the learned representation can be\nexploited to automate dataset denoising. The results are demonstrated on a\nsynthetic dataset, the common benchmark dataset FB15k-237, and a large\nbiomedical knowledge graph derived from a combination of noisy and clean data\nsources. Using these improvements, we visualize a learned model's\nrepresentation of the disease cystic fibrosis and demonstrate how to\ninterrogate a neural network to show the potential of PPARG as a candidate\ntherapeutic target for rheumatoid arthritis.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 23:04:30 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Neil", "Daniel", ""], ["Briody", "Joss", ""], ["Lacoste", "Alix", ""], ["Sim", "Aaron", ""], ["Creed", "Paidi", ""], ["Saffari", "Amir", ""]]}, {"id": "1812.00285", "submitter": "Sanmit Narvekar", "authors": "Sanmit Narvekar and Peter Stone", "title": "Learning Curriculum Policies for Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 18th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning in reinforcement learning is a training methodology that\nseeks to speed up learning of a difficult target task, by first training on a\nseries of simpler tasks and transferring the knowledge acquired to the target\ntask. Automatically choosing a sequence of such tasks (i.e. a curriculum) is an\nopen problem that has been the subject of much recent work in this area. In\nthis paper, we build upon a recent method for curriculum design, which\nformulates the curriculum sequencing problem as a Markov Decision Process. We\nextend this model to handle multiple transfer learning algorithms, and show for\nthe first time that a curriculum policy over this MDP can be learned from\nexperience. We explore various representations that make this possible, and\nevaluate our approach by learning curriculum policies for multiple agents in\ntwo different domains. The results show that our method produces curricula that\ncan train agents to perform on a target task as fast or faster than existing\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 23:22:18 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Narvekar", "Sanmit", ""], ["Stone", "Peter", ""]]}, {"id": "1812.00293", "submitter": "Matthew O'Kelly", "authors": "Matthew O'Kelly, Aman Sinha, Justin Norden, Hongseok Namkoong", "title": "In-silico Risk Analysis of Personalized Artificial Pancreas Controllers\n  via Rare-event Simulation", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern treatments for Type 1 diabetes (T1D) use devices known as artificial\npancreata (APs), which combine an insulin pump with a continuous glucose\nmonitor (CGM) operating in a closed-loop manner to control blood glucose\nlevels. In practice, poor performance of APs (frequent hyper- or hypoglycemic\nevents) is common enough at a population level that many T1D patients modify\nthe algorithms on existing AP systems with unregulated open-source software.\nAnecdotally, the patients in this group have shown superior outcomes compared\nwith standard of care, yet we do not understand how safe any AP system is since\nadverse outcomes are rare. In this paper, we construct generative models of\nindividual patients' physiological characteristics and eating behaviors. We\nthen couple these models with a T1D simulator approved for pre-clinical trials\nby the FDA. Given the ability to simulate patient outcomes in-silico, we\nutilize techniques from rare-event simulation theory in order to efficiently\nquantify the performance of a device with respect to a particular patient. We\nshow a 72,000$\\times$ speedup in simulation speed over real-time and up to 2-10\ntimes increase in the frequency which we are able to sample adverse conditions\nrelative to standard Monte Carlo sampling. In practice our toolchain enables\nestimates of the likelihood of hypoglycemic events with approximately an order\nof magnitude fewer simulations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 00:19:25 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["O'Kelly", "Matthew", ""], ["Sinha", "Aman", ""], ["Norden", "Justin", ""], ["Namkoong", "Hongseok", ""]]}, {"id": "1812.00308", "submitter": "Dongha Kim", "authors": "Yongdai Kim and Dongha Kim", "title": "On variation of gradients of deep neural networks", "comments": "30 pages, 6 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a theoretical explanation of the role of the number of nodes at\neach layer in deep neural networks. We prove that the largest variation of a\ndeep neural network with ReLU activation function arises when the layer with\nthe fewest nodes changes its activation pattern. An important implication is\nthat deep neural network is a useful tool to generate functions most of whose\nvariations are concentrated on a smaller area of the input space near the\nboundaries corresponding to the layer with the fewest nodes. In turn, this\nproperty makes the function more invariant to input transformation. That is,\nour theoretical result gives a clue about how to design the architecture of a\ndeep neural network to increase complexity and transformation invariancy\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 02:37:56 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Kim", "Yongdai", ""], ["Kim", "Dongha", ""]]}, {"id": "1812.00332", "submitter": "Han Cai", "authors": "Han Cai, Ligeng Zhu, Song Han", "title": "ProxylessNAS: Direct Neural Architecture Search on Target Task and\n  Hardware", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural architecture search (NAS) has a great impact by automatically\ndesigning effective neural network architectures. However, the prohibitive\ncomputational demand of conventional NAS algorithms (e.g. $10^4$ GPU hours)\nmakes it difficult to \\emph{directly} search the architectures on large-scale\ntasks (e.g. ImageNet). Differentiable NAS can reduce the cost of GPU hours via\na continuous representation of network architecture but suffers from the high\nGPU memory consumption issue (grow linearly w.r.t. candidate set size). As a\nresult, they need to utilize~\\emph{proxy} tasks, such as training on a smaller\ndataset, or learning with only a few blocks, or training just for a few epochs.\nThese architectures optimized on proxy tasks are not guaranteed to be optimal\non the target task. In this paper, we present \\emph{ProxylessNAS} that can\n\\emph{directly} learn the architectures for large-scale target tasks and target\nhardware platforms. We address the high memory consumption issue of\ndifferentiable NAS and reduce the computational cost (GPU hours and GPU memory)\nto the same level of regular training while still allowing a large candidate\nset. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of\ndirectness and specialization. On CIFAR-10, our model achieves 2.08\\% test\nerror with only 5.7M parameters, better than the previous state-of-the-art\narchitecture AmoebaNet-B, while using 6$\\times$ fewer parameters. On ImageNet,\nour model achieves 3.1\\% better top-1 accuracy than MobileNetV2, while being\n1.2$\\times$ faster with measured GPU latency. We also apply ProxylessNAS to\nspecialize neural architectures for hardware with direct hardware metrics (e.g.\nlatency) and provide insights for efficient CNN architecture design.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 05:29:53 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 01:36:47 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cai", "Han", ""], ["Zhu", "Ligeng", ""], ["Han", "Song", ""]]}, {"id": "1812.00335", "submitter": "Shaojie Wang", "authors": "Wentian Zhao, Shaojie Wang, Zhihuai Xie, Jing Shi, Chenliang Xu", "title": "GAN-EM: GAN based EM learning framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Expectation maximization (EM) algorithm is to find maximum likelihood\nsolution for models having latent variables. A typical example is Gaussian\nMixture Model (GMM) which requires Gaussian assumption, however, natural images\nare highly non-Gaussian so that GMM cannot be applied to perform clustering\ntask on pixel space. To overcome such limitation, we propose a GAN based EM\nlearning framework that can maximize the likelihood of images and estimate the\nlatent variables with only the constraint of L-Lipschitz continuity. We call\nthis model GAN-EM, which is a framework for image clustering, semi-supervised\nclassification and dimensionality reduction. In M-step, we design a novel loss\nfunction for discriminator of GAN to perform maximum likelihood estimation\n(MLE) on data with soft class label assignments. Specifically, a conditional\ngenerator captures data distribution for $K$ classes, and a discriminator tells\nwhether a sample is real or fake for each class. Since our model is\nunsupervised, the class label of real data is regarded as latent variable,\nwhich is estimated by an additional network (E-net) in E-step. The proposed\nGAN-EM achieves state-of-the-art clustering and semi-supervised classification\nresults on MNIST, SVHN and CelebA, as well as comparable quality of generated\nimages to other recently developed generative models.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 06:04:59 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Zhao", "Wentian", ""], ["Wang", "Shaojie", ""], ["Xie", "Zhihuai", ""], ["Shi", "Jing", ""], ["Xu", "Chenliang", ""]]}, {"id": "1812.00338", "submitter": "Liang Mi", "authors": "Liang Mi, Wen Zhang, and Yalin Wang", "title": "Regularized Wasserstein Means for Aligning Distributional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to align distributional data from the perspective of Wasserstein\nmeans. We raise the problem of regularizing Wasserstein means and propose\nseveral terms tailored to tackle different problems. Our formulation is based\non the variational transportation to distribute a sparse discrete measure into\nthe target domain. The resulting sparse representation well captures the\ndesired property of the domain while reducing the mapping cost. We demonstrate\nthe scalability and robustness of our method with examples in domain\nadaptation, point set registration, and skeleton layout.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 06:15:44 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 04:08:07 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Mi", "Liang", ""], ["Zhang", "Wen", ""], ["Wang", "Yalin", ""]]}, {"id": "1812.00342", "submitter": "Abhishek Panigrahi", "authors": "Abhishek Panigrahi, Yueru Chen and C.-C. Jay Kuo", "title": "Analysis on Gradient Propagation in Batch Normalized Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct mathematical analysis on the effect of batch normalization (BN) on\ngradient backpropogation in residual network training, which is believed to\nplay a critical role in addressing the gradient vanishing/explosion problem, in\nthis work. By analyzing the mean and variance behavior of the input and the\ngradient in the forward and backward passes through the BN and residual\nbranches, respectively, we show that they work together to confine the gradient\nvariance to a certain range across residual blocks in backpropagation. As a\nresult, the gradient vanishing/explosion problem is avoided. We also show the\nrelative importance of batch normalization w.r.t. the residual branches in\nresidual networks.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 06:41:28 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Panigrahi", "Abhishek", ""], ["Chen", "Yueru", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1812.00353", "submitter": "Yuefu Zhou", "authors": "Yuefu Zhou, Ya Zhang, Yanfeng Wang, Qi Tian", "title": "Accelerate CNN via Recursive Bayesian Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel Pruning, widely used for accelerating Convolutional Neural Networks,\nis an NP-hard problem due to the inter-layer dependency of channel redundancy.\nExisting methods generally ignored the above dependency for computation\nsimplicity. To solve the problem, under the Bayesian framework, we here propose\na layer-wise Recursive Bayesian Pruning method (RBP). A new dropout-based\nmeasurement of redundancy, which facilitate the computation of posterior\nassuming inter-layer dependency, is introduced. Specifically, we model the\nnoise across layers as a Markov chain and target its posterior to reflect the\ninter-layer dependency. Considering the closed form solution for posterior is\nintractable, we derive a sparsity-inducing Dirac-like prior which regularizes\nthe distribution of the designed noise to automatically approximate the\nposterior. Compared with the existing methods, no additional overhead is\nrequired when the inter-layer dependency assumed. The redundant channels can be\nsimply identified by tiny dropout noise and directly pruned layer by layer.\nExperiments on popular CNN architectures have shown that the proposed method\noutperforms several state-of-the-arts. Particularly, we achieve up to\n$\\bf{5.0\\times}$ and $\\bf{2.2\\times}$ FLOPs reduction with little accuracy loss\non the large scale dataset ILSVRC2012 for VGG16 and ResNet50, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 08:13:10 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 10:55:18 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Zhou", "Yuefu", ""], ["Zhang", "Ya", ""], ["Wang", "Yanfeng", ""], ["Tian", "Qi", ""]]}, {"id": "1812.00365", "submitter": "Jun Geng", "authors": "Jun Geng and Lifeng Lai", "title": "Quick Best Action Identification in Linear Bandit Problems", "comments": "8 pages, 2 figures. Submitted to Asilomar 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a best action identification problem in the\nstochastic linear bandit setup with a fixed confident constraint. In the\nconsidered best action identification problem, instead of minimizing the\naccumulative regret as done in existing works, the learner aims to obtain an\naccurate estimate of the underlying parameter based on his action and reward\nsequences. To improve the estimation efficiency, the learner is allowed to\nselect his action based his historical information; hence the whole procedure\nis designed in a sequential adaptive manner. We first show that the existing\nalgorithms designed to minimize the accumulative regret is not a consistent\nestimator and hence is not a good policy for our problem. We then characterize\na lower bound on the estimation error for any policy. We further design a\nsimple policy and show that the estimation error of the designed policy\nachieves the same scaling order as that of the derived lower bound.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 10:38:45 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Geng", "Jun", ""], ["Lai", "Lifeng", ""]]}, {"id": "1812.00371", "submitter": "Thao Nguyen", "authors": "Anand Avati, Stephen Pfohl, Chris Lin, Thao Nguyen, Meng Zhang, Philip\n  Hwang, Jessica Wetstone, Kenneth Jung, Andrew Ng, Nigam H. Shah", "title": "Predicting Inpatient Discharge Prioritization With Electronic Health\n  Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying patients who will be discharged within 24 hours can improve\nhospital resource management and quality of care. We studied this problem using\neight years of Electronic Health Records (EHR) data from Stanford Hospital. We\nfit models to predict 24 hour discharge across the entire inpatient population.\nThe best performing models achieved an area under the receiver-operator\ncharacteristic curve (AUROC) of 0.85 and an AUPRC of 0.53 on a held out test\nset. This model was also well calibrated. Finally, we analyzed the utility of\nthis model in a decision theoretic framework to identify regions of ROC space\nin which using the model increases expected utility compared to the trivial\nalways negative or always positive classifiers.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 11:31:50 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Avati", "Anand", ""], ["Pfohl", "Stephen", ""], ["Lin", "Chris", ""], ["Nguyen", "Thao", ""], ["Zhang", "Meng", ""], ["Hwang", "Philip", ""], ["Wetstone", "Jessica", ""], ["Jung", "Kenneth", ""], ["Ng", "Andrew", ""], ["Shah", "Nigam H.", ""]]}, {"id": "1812.00401", "submitter": "Pawe{\\l} Gora", "authors": "Pawe{\\l} Gora, Maciej Brzeski, Marcin Mo\\.zejko, Arkadiusz Klemenko,\n  Adrian Kocha\\'nski", "title": "Investigating performance of neural networks and gradient boosting\n  models approximating microscopic traffic simulations in traffic optimization\n  tasks", "comments": "Presented at NeurIPS 2018 Workshop \"Machine Learning for Intelligent\n  Transportation Systems\" https://sites.google.com/site/nips2018mlits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the accuracy of traffic simulations metamodels based on neural\nnetworks and gradient boosting models (LightGBM), applied to traffic\noptimization as fitness functions of genetic algorithms. Our metamodels\napproximate outcomes of traffic simulations (the total time of waiting on a red\nsignal) taking as an input different traffic signal settings, in order to\nefficiently find (sub)optimal settings. Their accuracy was proven to be very\ngood on randomly selected test sets, but it turned out that the accuracy may\ndrop in case of settings expected (according to genetic algorithms) to be close\nto local optima, which makes the traffic optimization process more difficult.\nIn this work, we investigate 16 different metamodels and 20 settings of genetic\nalgorithms, in order to understand what are the reasons of this phenomenon,\nwhat is its scale, how it can be mitigated and what can be potentially done to\ndesign better real-time traffic optimization methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 15:14:39 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 12:13:24 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 03:25:02 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Gora", "Pawe\u0142", ""], ["Brzeski", "Maciej", ""], ["Mo\u017cejko", "Marcin", ""], ["Klemenko", "Arkadiusz", ""], ["Kocha\u0144ski", "Adrian", ""]]}, {"id": "1812.00415", "submitter": "Mehul Motani", "authors": "Shiyu Liu and Mehul Motani", "title": "Feature Selection Based on Unique Relevant Information for Health Data", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/172", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection, which searches for the most representative features in\nobserved data, is critical for health data analysis. Unlike feature extraction,\nsuch as PCA and autoencoder based methods, feature selection preserves\ninterpretability, meaning that the selected features provide direct information\nabout certain health conditions (i.e., the label). Thus, feature selection\nallows domain experts, such as clinicians, to understand the predictions made\nby machine learning based systems, as well as improve their own diagnostic\nskills. Mutual information is often used as a basis for feature selection since\nit measures dependencies between features and labels. In this paper, we\nintroduce a novel mutual information based feature selection (MIBFS) method\ncalled SURI, which boosts features with high unique relevant information. We\ncompare SURI to existing MIBFS methods using 3 different classifiers on 6\npublicly available healthcare data sets. The results indicate that, in addition\nto preserving interpretability, SURI selects more relevant feature subsets\nwhich lead to higher classification performance. More importantly, we explore\nthe dynamics of mutual information on a public low-dimensional health data set\nvia exhaustive search. The results suggest the important role of unique\nrelevant information in feature selection and verify the principles behind\nSURI.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 16:13:59 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Liu", "Shiyu", ""], ["Motani", "Mehul", ""]]}, {"id": "1812.00417", "submitter": "Stephen Bach", "authors": "Stephen H. Bach, Daniel Rodriguez, Yintao Liu, Chong Luo, Haidong\n  Shao, Cassandra Xia, Souvik Sen, Alexander Ratner, Braden Hancock, Houman\n  Alborzi, Rahul Kuchhal, Christopher R\\'e, Rob Malkin", "title": "Snorkel DryBell: A Case Study in Deploying Weak Supervision at\n  Industrial Scale", "comments": null, "journal-ref": "Proceedings of the International Conference on Management of Data\n  (SIGMOD), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling training data is one of the most costly bottlenecks in developing\nmachine learning-based applications. We present a first-of-its-kind study\nshowing how existing knowledge resources from across an organization can be\nused as weak supervision in order to bring development time and cost down by an\norder of magnitude, and introduce Snorkel DryBell, a new weak supervision\nmanagement system for this setting. Snorkel DryBell builds on the Snorkel\nframework, extending it in three critical aspects: flexible, template-based\ningestion of diverse organizational knowledge, cross-feature production\nserving, and scalable, sampling-free execution. On three classification tasks\nat Google, we find that Snorkel DryBell creates classifiers of comparable\nquality to ones trained with tens of thousands of hand-labeled examples,\nconverts non-servable organizational resources to servable models for an\naverage 52% performance improvement, and executes over millions of data points\nin tens of minutes.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 16:23:36 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 22:52:25 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Bach", "Stephen H.", ""], ["Rodriguez", "Daniel", ""], ["Liu", "Yintao", ""], ["Luo", "Chong", ""], ["Shao", "Haidong", ""], ["Xia", "Cassandra", ""], ["Sen", "Souvik", ""], ["Ratner", "Alexander", ""], ["Hancock", "Braden", ""], ["Alborzi", "Houman", ""], ["Kuchhal", "Rahul", ""], ["R\u00e9", "Christopher", ""], ["Malkin", "Rob", ""]]}, {"id": "1812.00418", "submitter": "Colin Pawlowski", "authors": "Dimitris Bertsimas, Agni Orfanoudaki, Colin Pawlowski", "title": "Imputation of Clinical Covariates in Time Series", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/107", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data is a common problem in real-world settings and particularly\nrelevant in healthcare applications where researchers use Electronic Health\nRecords (EHR) and results of observational studies to apply analytics methods.\nThis issue becomes even more prominent for longitudinal data sets, where\nmultiple instances of the same individual correspond to different observations\nin time. Standard imputation methods do not take into account patient specific\ninformation incorporated in multivariate panel data. We introduce the novel\nimputation algorithm MedImpute that addresses this problem, extending the\nflexible framework of OptImpute suggested by Bertsimas et al. (2018). Our\nalgorithm provides imputations for data sets with missing continuous and\ncategorical features, and we present the formulation and implement scalable\nfirst-order methods for a $K$-NN model. We test the performance of our\nalgorithm on longitudinal data from the Framingham Heart Study when data are\nmissing completely at random (MCAR). We demonstrate that MedImpute leads to\nsignificant improvements in both imputation accuracy and downstream model AUC\ncompared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 16:24:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Orfanoudaki", "Agni", ""], ["Pawlowski", "Colin", ""]]}, {"id": "1812.00420", "submitter": "Arslan Chaudhry", "authors": "Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, Mohamed\n  Elhoseiny", "title": "Efficient Lifelong Learning with A-GEM", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In lifelong learning, the learner is presented with a sequence of tasks,\nincrementally building a data-driven prior which may be leveraged to speed up\nlearning of a new task. In this work, we investigate the efficiency of current\nlifelong approaches, in terms of sample complexity, computational and memory\ncost. Towards this end, we first introduce a new and a more realistic\nevaluation protocol, whereby learners observe each example only once and\nhyper-parameter selection is done on a small and disjoint set of tasks, which\nis not used for the actual learning experience and evaluation. Second, we\nintroduce a new metric measuring how quickly a learner acquires a new skill.\nThird, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017),\ndubbed Averaged GEM (A-GEM), which enjoys the same or even better performance\nas GEM, while being almost as computationally and memory efficient as EWC\n(Kirkpatrick et al., 2016) and other regularization-based methods. Finally, we\nshow that all algorithms including A-GEM can learn even more quickly if they\nare provided with task descriptors specifying the classification tasks under\nconsideration. Our experiments on several standard lifelong learning benchmarks\ndemonstrate that A-GEM has the best trade-off between accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 16:39:19 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 11:11:47 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Chaudhry", "Arslan", ""], ["Ranzato", "Marc'Aurelio", ""], ["Rohrbach", "Marcus", ""], ["Elhoseiny", "Mohamed", ""]]}, {"id": "1812.00441", "submitter": "Ligin Solamen", "authors": "Ligin Solamen, Yipeng Shi, Justice Amoh", "title": "Dual Objective Approach Using A Convolutional Neural Network for\n  Magnetic Resonance Elastography", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/197", "categories": "physics.med-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, nonlinear inversion, direct inversion, or wave estimation\nmethods have been used for reconstructing images from MRE displacement data. In\nthis work, we propose a convolutional neural network architecture that can map\nMRE displacement data directly into elastograms, circumventing the costly and\ncomputationally intensive classical approaches. In addition to the mean squared\nerror reconstruction objective, we also introduce a secondary loss inspired by\nthe MRE mechanical models for training the neural network. Our network is\ndemonstrated to be effective for generating MRE images that compare well with\nequivalents from the nonlinear inversion method.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 18:31:17 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Solamen", "Ligin", ""], ["Shi", "Yipeng", ""], ["Amoh", "Justice", ""]]}, {"id": "1812.00448", "submitter": "Stefan Konigorski", "authors": "Stefan Konigorski, Shahryar Khorasani, Christoph Lippert", "title": "Integrating omics and MRI data with kernel-based tests and CNNs to\n  identify rare genetic markers for Alzheimer's disease", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018,\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/129", "categories": "stat.ML cs.LG q-bio.GN", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For precision medicine and personalized treatment, we need to identify\npredictive markers of disease. We focus on Alzheimer's disease (AD), where\nmagnetic resonance imaging scans provide information about the disease status.\nBy combining imaging with genome sequencing, we aim at identifying rare genetic\nmarkers associated with quantitative traits predicted from convolutional neural\nnetworks (CNNs), which traditionally have been derived manually by experts.\nKernel-based tests are a powerful tool for associating sets of genetic\nvariants, but how to optimally model rare genetic variants is still an open\nresearch question. We propose a generalized set of kernels that incorporate\nprior information from various annotations and multi-omics data. In the\nanalysis of data from the Alzheimer's Disease Neuroimaging Initiative (ADNI),\nwe evaluate whether (i) CNNs yield precise and reliable brain traits, and (ii)\nthe novel kernel-based tests can help to identify loci associated with AD. The\nresults indicate that CNNs provide a fast, scalable and precise tool to derive\nquantitative AD traits and that new kernels integrating domain knowledge can\nyield higher power in association tests of very rare variants.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 19:10:22 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 17:50:09 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Konigorski", "Stefan", ""], ["Khorasani", "Shahryar", ""], ["Lippert", "Christoph", ""]]}, {"id": "1812.00456", "submitter": "Zhao Song", "authors": "Zhao Song and Ronald E. Parr and Lawrence Carin", "title": "Revisiting the Softmax Bellman Operator: New Benefits and New\n  Perspective", "comments": "To appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of softmax on the value function itself in reinforcement learning\n(RL) is often viewed as problematic because it leads to sub-optimal value (or\nQ) functions and interferes with the contraction properties of the Bellman\noperator. Surprisingly, despite these concerns, and independent of its effect\non exploration, the softmax Bellman operator when combined with Deep\nQ-learning, leads to Q-functions with superior policies in practice, even\noutperforming its double Q-learning counterpart. To better understand how and\nwhy this occurs, we revisit theoretical properties of the softmax Bellman\noperator, and prove that $(i)$ it converges to the standard Bellman operator\nexponentially fast in the inverse temperature parameter, and $(ii)$ the\ndistance of its Q function from the optimal one can be bounded. These alone do\nnot explain its superior performance, so we also show that the softmax operator\ncan reduce the overestimation error, which may give some insight into why a\nsub-optimal operator leads to better performance in the presence of value\nfunction approximation. A comparison among different Bellman operators is then\npresented, showing the trade-offs when selecting them.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 19:45:38 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 18:01:20 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Song", "Zhao", ""], ["Parr", "Ronald E.", ""], ["Carin", "Lawrence", ""]]}, {"id": "1812.00463", "submitter": "Sabina Tomkins", "authors": "Sabina Tomkins, Predrag Klasnja, Susan Murphy", "title": "Personalizing Intervention Probabilities By Pooling", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/90", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many mobile health interventions, treatments should only be delivered in a\nparticular context, for example when a user is currently stressed, walking or\nsedentary. Even in an optimal context, concerns about user burden can restrict\nwhich treatments are sent. To diffuse the treatment delivery over times when a\nuser is in a desired context, it is critical to predict the future number of\ntimes the context will occur. The focus of this paper is on whether\npersonalization can improve predictions in these settings. Though the variance\nbetween individuals' behavioral patterns suggest that personalization should be\nuseful, the amount of individual-level data limits its capabilities. Thus, we\ninvestigate several methods which pool data across users to overcome these\ndeficiencies and find that pooling lowers the overall error rate relative to\nboth personalized and batch approaches.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 20:58:30 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Tomkins", "Sabina", ""], ["Klasnja", "Predrag", ""], ["Murphy", "Susan", ""]]}, {"id": "1812.00475", "submitter": "Divya Shanmugam", "authors": "Divya Shanmugam, Davis Blalock, John Guttag", "title": "Multiple Instance Learning for ECG Risk Stratification", "comments": "Machine Learning for Healthcare Conference (MLHC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients who suffer an acute coronary syndrome are at elevated risk for\nadverse cardiovascular events such as myocardial infarction and cardiovascular\ndeath. Accurate assessment of this risk is crucial to their course of care. We\nfocus on estimating a patient's risk of cardiovascular death after an acute\ncoronary syndrome based on a patient's raw electrocardiogram (ECG) signal.\nLearning from this signal is challenging for two reasons: 1) positive examples\nsignifying a downstream cardiovascular event are scarce, causing drastic class\nimbalance, and 2) each patient's ECG signal consists of thousands of\nheartbeats, accompanied by a single label for the downstream outcome. Machine\nlearning has been previously applied to this task, but most approaches rely on\nhand-crafted features and domain knowledge. We propose a method that learns a\nrepresentation from the raw ECG signal by using a multiple instance learning\nframework. We present a learned risk score for cardiovascular death that\noutperforms existing risk metrics in predicting cardiovascular death within 30,\n60, 90, and 365 days on a dataset of 5000 patients.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 21:55:53 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:58:39 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 13:46:29 GMT"}, {"version": "v4", "created": "Wed, 25 Mar 2020 12:29:52 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Shanmugam", "Divya", ""], ["Blalock", "Davis", ""], ["Guttag", "John", ""]]}, {"id": "1812.00490", "submitter": "Xinrui Lyu", "authors": "Xinrui Lyu, Matthias Hueser, Stephanie L. Hyland, George Zerveas,\n  Gunnar Raetsch", "title": "Improving Clinical Predictions through Unsupervised Time Series\n  Representation Learning", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/171", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate unsupervised representation learning on medical\ntime series, which bears the promise of leveraging copious amounts of existing\nunlabeled data in order to eventually assist clinical decision making. By\nevaluating on the prediction of clinically relevant outcomes, we show that in a\npractical setting, unsupervised representation learning can offer clear\nperformance benefits over end-to-end supervised architectures. We experiment\nwith using sequence-to-sequence (Seq2Seq) models in two different ways, as an\nautoencoder and as a forecaster, and show that the best performance is achieved\nby a forecasting Seq2Seq model with an integrated attention mechanism, proposed\nhere for the first time in the setting of unsupervised learning for medical\ntime series.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 23:59:36 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Lyu", "Xinrui", ""], ["Hueser", "Matthias", ""], ["Hyland", "Stephanie L.", ""], ["Zerveas", "George", ""], ["Raetsch", "Gunnar", ""]]}, {"id": "1812.00497", "submitter": "John Hughes", "authors": "J. Weston Hughes, Taylor Sittler, Anthony D. Joseph, Jeffrey E. Olgin,\n  Joseph E. Gonzalez, Geoffrey H. Tison", "title": "Using Multitask Learning to Improve 12-Lead Electrocardiogram\n  Classification", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/209", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a multi-task convolutional neural network (CNN) to classify\nmultiple diagnoses from 12-lead electrocardiograms (ECGs) using a dataset\ncomprised of over 40,000 ECGs, with labels derived from cardiologist clinical\ninterpretations. Since many clinically important classes can occur in low\nfrequencies, approaches are needed to improve performance on rare classes. We\ncompare the performance of several single-class classifiers on rare classes to\na multi-headed classifier across all available classes. We demonstrate that the\naddition of common classes can significantly improve CNN performance on rarer\nclasses when compared to a model trained on the rarer class in isolation. Using\nthis method, we develop a model with high performance as measured by F1 score\non multiple clinically relevant classes compared against the gold-standard\ncardiologist interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 00:32:07 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 05:12:30 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hughes", "J. Weston", ""], ["Sittler", "Taylor", ""], ["Joseph", "Anthony D.", ""], ["Olgin", "Jeffrey E.", ""], ["Gonzalez", "Joseph E.", ""], ["Tison", "Geoffrey H.", ""]]}, {"id": "1812.00506", "submitter": "Angeline Yasodhara", "authors": "Angeline Yasodhara, Mamatha Bhat, Anna Goldenberg", "title": "Prediction of New Onset Diabetes after Liver Transplant", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216. This paper is being withdrawn due to a mistake made while\n  training the survival models. A wrong time variable was used while training\n  and thus, the survival models were not predicting what was expected and their\n  reported performance should be disregarded. The performance of the\n  classifiers was reported correctly", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/185", "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  25% of people who received a liver transplant will go on to develop diabetes\nwithin the next 5 years. These thousands of individuals are at 2-fold higher\nrisk of cardiovascular events, graft loss, infections, as well as lower\nlong-term survival. This is partly due to the medication used during and/or\nafter transplant that significantly impacts metabolic balance. To assess which\nmedication best suits the patient's condition, clinicians need an accurate\nestimate of diabetes risk. Both patient's historical data and observations at\nthe current visit are informative in predicting whether the patient will\ndevelop diabetes within the following year. In this work we compared a variety\nof time-to-event prediction models as well as classifiers predicting the\nlikelihood of the event within a year from the current checkup. We are\nparticularly interested in comparing two types of models: 1) standard\ntime-to-event predictors where the historical measurements are merely\nconcatenated, 2) incorporating Deep Markov Model to first obtain\nlow-dimensional embedding of historical data and then using this embedding as\nan additional input into the model. We compared a variety of algorithms\nincluding standard and regularized Cox proportional-hazards model (CPH), mixed\neffect random forests, survival-forests and Weibull Time-To-Event Recurrent\nNeural Network (WTTE-RNN). The results show that although all methods'\nperformances varied from year to year and there was no clear winner across all\nthe time points, regularized CPH model that used 1 to 3 years of historical\nvisits data on average achieved a high, clinically relevant Concordance Index\nof .863. We thus recommend this model for further prospective clinical\nvalidation and hopefully, an eventual use in the clinic to improve clinicians'\nability to personalize post-operative care and reduce the incidence of\nnew-onset diabetes post liver transplant.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 01:31:11 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 14:03:01 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Yasodhara", "Angeline", ""], ["Bhat", "Mamatha", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1812.00509", "submitter": "Parvathy Sudhir Pillai", "authors": "Parvathy Sudhir Pillai and Tze-Yun Leong", "title": "Knowledge-driven generative subspaces for modeling multi-view\n  dependencies in medical data", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/84", "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Early detection of Alzheimer's disease (AD) and identification of potential\nrisk/beneficial factors are important for planning and administering timely\ninterventions or preventive measures. In this paper, we learn a disease model\nfor AD that combines genotypic and phenotypic profiles, and cognitive health\nmetrics of patients. We propose a probabilistic generative subspace that\ndescribes the correlative, complementary and domain-specific semantics of the\ndependencies in multi-view, multi-modality medical data. Guided by domain\nknowledge and using the latent consensus between abstractions of multi-view\ndata, we model the fusion as a data generating process. We show that our\napproach can potentially lead to i) explainable clinical predictions and ii)\nimproved AD diagnoses.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 01:47:13 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Pillai", "Parvathy Sudhir", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "1812.00524", "submitter": "Niki Kilbertus", "authors": "Niki Kilbertus, Giambattista Parascandolo, Bernhard Sch\\\"olkopf", "title": "Generalization in anti-causal learning", "comments": "A shorter version of this paper appeared at the workshop on\n  `Critiquing and correcting trends in machine learning` at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn and act in novel situations is still a prerogative of\nanimate intelligence, as current machine learning methods mostly fail when\nmoving beyond the standard i.i.d. setting. What is the reason for this\ndiscrepancy? Most machine learning tasks are anti-causal, i.e., we infer causes\n(labels) from effects (observations). Typically, in supervised learning we\nbuild systems that try to directly invert causal mechanisms. Instead, in this\npaper we argue that strong generalization capabilities crucially hinge on\nsearching and validating meaningful hypotheses, requiring access to a causal\nmodel. In such a framework, we want to find a cause that leads to the observed\neffect. Anti-causal models are used to drive this search, but a causal model is\nrequired for validation. We investigate the fundamental differences between\ncausal and anti-causal tasks, discuss implications for topics ranging from\nadversarial attacks to disentangling factors of variation, and provide\nextensive evidence from the literature to substantiate our view. We advocate\nfor incorporating causal models in supervised learning to shift the paradigm\nfrom inference only, to search and validation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 02:26:35 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Kilbertus", "Niki", ""], ["Parascandolo", "Giambattista", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1812.00528", "submitter": "Aman Verma", "authors": "Aman Verma, Guido Powell, Yu Luo, David Stephens, David L. Buckeridge", "title": "Modeling disease progression in longitudinal EHR data using\n  continuous-time hidden Markov models", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/145", "categories": "cs.LG q-bio.PE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modeling disease progression in healthcare administrative databases is\ncomplicated by the fact that patients are observed only at irregular intervals\nwhen they seek healthcare services. In a longitudinal cohort of 76,888 patients\nwith chronic obstructive pulmonary disease (COPD), we used a continuous-time\nhidden Markov model with a generalized linear model to model healthcare\nutilization events. We found that the fitted model provides interpretable\nresults suitable for summarization and hypothesis generation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 02:34:37 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Verma", "Aman", ""], ["Powell", "Guido", ""], ["Luo", "Yu", ""], ["Stephens", "David", ""], ["Buckeridge", "David L.", ""]]}, {"id": "1812.00531", "submitter": "Satya Narayan Shukla", "authors": "Satya Narayan Shukla and Benjamin M. Marlin", "title": "Modeling Irregularly Sampled Clinical Time Series", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/111", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the volume of electronic health records (EHR) data continues to grow,\nit remains rare for hospital systems to capture dense physiological data\nstreams, even in the data-rich intensive care unit setting. Instead, typical\nEHR records consist of sparse and irregularly observed multivariate time\nseries, which are well understood to present particularly challenging problems\nfor machine learning methods. In this paper, we present a new deep learning\narchitecture for addressing this problem based on the use of a semi-parametric\ninterpolation network followed by the application of a prediction network. The\ninterpolation network allows for information to be shared across multiple\ndimensions during the interpolation stage, while any standard deep learning\nmodel can be used for the prediction network. We investigate the performance of\nthis architecture on the problems of mortality and length of stay prediction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 02:53:30 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "1812.00532", "submitter": "Yiming Sun", "authors": "Yiming Sun, Yige Li, Amy Kuceyeski, Sumanta Basu", "title": "Large Spectral Density Matrix Estimation by Thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral density matrix estimation of multivariate time series is a classical\nproblem in time series and signal processing. In modern neuroscience, spectral\ndensity based metrics are commonly used for analyzing functional connectivity\namong brain regions. In this paper, we develop a non-asymptotic theory for\nregularized estimation of high-dimensional spectral density matrices of\nGaussian and linear processes using thresholded versions of averaged\nperiodograms. Our theoretical analysis ensures that consistent estimation of\nspectral density matrix of a $p$-dimensional time series using $n$ samples is\npossible under high-dimensional regime $\\log p / n \\rightarrow 0$ as long as\nthe true spectral density is approximately sparse. A key technical component of\nour analysis is a new concentration inequality of average periodogram around\nits expectation, which is of independent interest. Our estimation consistency\nresults complement existing results for shrinkage based estimators of\nmultivariate spectral density, which require no assumption on sparsity but only\nensure consistent estimation in a regime $p^2/n \\rightarrow 0$. In addition,\nour proposed thresholding based estimators perform consistent and automatic\nedge selection when learning coherence networks among the components of a\nmultivariate time series. We demonstrate the advantage of our estimators using\nsimulation studies and a real data application on functional connectivity\nanalysis with fMRI data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 03:04:08 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Sun", "Yiming", ""], ["Li", "Yige", ""], ["Kuceyeski", "Amy", ""], ["Basu", "Sumanta", ""]]}, {"id": "1812.00539", "submitter": "Holly Wiberg", "authors": "Dimitris Bertsimas, Agni Orfanoudaki, Holly Wiberg", "title": "Interpretable Clustering via Optimal Trees", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art clustering algorithms use heuristics to partition the\nfeature space and provide little insight into the rationale for cluster\nmembership, limiting their interpretability. In healthcare applications, the\nlatter poses a barrier to the adoption of these methods since medical\nresearchers are required to provide detailed explanations of their decisions in\norder to gain patient trust and limit liability. We present a new unsupervised\nlearning algorithm that leverages Mixed Integer Optimization techniques to\ngenerate interpretable tree-based clustering models. Utilizing the flexible\nframework of Optimal Trees, our method approximates the globally optimal\nsolution leading to high quality partitions of the feature space. Our\nalgorithm, can incorporate various internal validation metrics, naturally\ndetermines the optimal number of clusters, and is able to account for mixed\nnumeric and categorical data. It achieves comparable or superior performance on\nboth synthetic and real world datasets when compared to K-Means while offering\nsignificantly higher interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 03:22:42 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Orfanoudaki", "Agni", ""], ["Wiberg", "Holly", ""]]}, {"id": "1812.00542", "submitter": "Xiaowu Dai", "authors": "Xiaowu Dai and Yuhua Zhu", "title": "Towards Theoretical Understanding of Large Batch Training in Stochastic\n  Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is almost ubiquitously used for training\nnon-convex optimization tasks. Recently, a hypothesis proposed by Keskar et al.\n[2017] that large batch methods tend to converge to sharp minimizers has\nreceived increasing attention. We theoretically justify this hypothesis by\nproviding new properties of SGD in both finite-time and asymptotic regimes. In\nparticular, we give an explicit escaping time of SGD from a local minimum in\nthe finite-time regime and prove that SGD tends to converge to flatter minima\nin the asymptotic regime (although may take exponential time to converge)\nregardless of the batch size. We also find that SGD with a larger ratio of\nlearning rate to batch size tends to converge to a flat minimum faster,\nhowever, its generalization performance could be worse than the SGD with a\nsmaller ratio of learning rate to batch size. We include numerical experiments\nto corroborate these theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 03:39:08 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Dai", "Xiaowu", ""], ["Zhu", "Yuhua", ""]]}, {"id": "1812.00543", "submitter": "Junfeng Wen", "authors": "Junfeng Wen, Yanshuai Cao, Ruitong Huang", "title": "Few-Shot Self Reminder to Overcome Catastrophic Forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are known to suffer the catastrophic forgetting problem,\nwhere they tend to forget the knowledge from the previous tasks when\nsequentially learning new tasks. Such failure hinders the application of deep\nlearning based vision system in continual learning settings. In this work, we\npresent a simple yet surprisingly effective way of preventing catastrophic\nforgetting. Our method, called Few-shot Self Reminder (FSR), regularizes the\nneural net from changing its learned behaviour by performing logit matching on\nselected samples kept in episodic memory from the old tasks. Surprisingly, this\nsimplistic approach only requires to retrain a small amount of data in order to\noutperform previous methods in knowledge retention. We demonstrate the\nsuperiority of our method to the previous ones in two different continual\nlearning settings on popular benchmarks, as well as a new continual learning\nproblem where tasks are designed to be more dissimilar.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 03:54:09 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Wen", "Junfeng", ""], ["Cao", "Yanshuai", ""], ["Huang", "Ruitong", ""]]}, {"id": "1812.00546", "submitter": "Vipul Satone", "authors": "Vipul Satone, Rachneet Kaur, Faraz Faghri, Mike A Nalls, Andrew B\n  Singleton, Roy H Campbell", "title": "Learning the progression and clinical subtypes of Alzheimer's disease\n  from longitudinal clinical data", "comments": "This volume represents the accepted submissions from the Machine\n  Learning for Health (ML4H) workshop at the conference on Neural Information\n  Processing Systems (NeurIPS) 2018, held on December 8, 2018 in Montreal,\n  Canada", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/206", "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Alzheimer's disease (AD) is a degenerative brain disease impairing a person's\nability to perform day to day activities. The clinical manifestations of\nAlzheimer's disease are characterized by heterogeneity in age, disease span,\nprogression rate, impairment of memory and cognitive abilities. Due to these\nvariabilities, personalized care and treatment planning, as well as patient\ncounseling about their individual progression is limited. Recent developments\nin machine learning to detect hidden patterns in complex, multi-dimensional\ndatasets provides significant opportunities to address this critical need. In\nthis work, we use unsupervised and supervised machine learning approaches for\nsubtype identification and prediction. We apply machine learning methods to the\nextensive clinical observations available at the Alzheimer's Disease\nNeuroimaging Initiative (ADNI) data set to identify patient subtypes and to\npredict disease progression. Our analysis depicts the progression space for the\nAlzheimer's disease into low, moderate and high disease progression zones. The\nproposed work will enable early detection and characterization of distinct\ndisease subtypes based on clinical heterogeneity. We anticipate that our models\nwill enable patient counseling, clinical trial design, and ultimately\nindividualized clinical care.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 04:09:20 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 17:49:21 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 01:13:44 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Satone", "Vipul", ""], ["Kaur", "Rachneet", ""], ["Faghri", "Faraz", ""], ["Nalls", "Mike A", ""], ["Singleton", "Andrew B", ""], ["Campbell", "Roy H", ""]]}, {"id": "1812.00547", "submitter": "Wenyuan Li", "authors": "Wenyuan Li, Yunlong Wang, Yong Cai, Corey Arnold, Emily Zhao, Yilian\n  Yuan", "title": "Semi-supervised Rare Disease Detection Using Generative Adversarial\n  Network", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare diseases affect a relatively small number of people, which limits\ninvestment in research for treatments and cures. Developing an efficient method\nfor rare disease detection is a crucial first step towards subsequent clinical\nresearch. In this paper, we present a semi-supervised learning framework for\nrare disease detection using generative adversarial networks. Our method takes\nadvantage of the large amount of unlabeled data for disease detection and\nachieves the best results in terms of precision-recall score compared to\nbaseline techniques.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 04:10:05 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Wenyuan", ""], ["Wang", "Yunlong", ""], ["Cai", "Yong", ""], ["Arnold", "Corey", ""], ["Zhao", "Emily", ""], ["Yuan", "Yilian", ""]]}, {"id": "1812.00554", "submitter": "Yunlong Wang", "authors": "Weiyu Huang, Yunlong Wang, Li Zhou, Emily Zhao, Yilian Yuan, and\n  Alejandro Ribero", "title": "Modeling Treatment Delays for Patients using Feature Label Pairs in a\n  Time Series", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pharmaceutical targeting is one of key inputs for making sales and marketing\nstrategy planning. Targeting list is built on predicting physician's sales\npotential of certain type of patient. In this paper, we present a\ntime-sensitive targeting framework leveraging time series model to predict\npatient's disease and treatment progression. We create time features by\nextracting service history within a certain period, and record whether the\nevent happens in a look-forward period. Such feature-label pairs are examined\nacross all time periods and all patients to train a model. It keeps the\ninherent order of services and evaluates features associated to the imminent\nfuture, which contribute to improved accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 04:58:56 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Huang", "Weiyu", ""], ["Wang", "Yunlong", ""], ["Zhou", "Li", ""], ["Zhao", "Emily", ""], ["Yuan", "Yilian", ""], ["Ribero", "Alejandro", ""]]}, {"id": "1812.00557", "submitter": "Viraj Jayminkumar Shah", "authors": "Viraj Shah and Chinmay Hegde", "title": "Signal Reconstruction from Modulo Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing a signal from under-determined\nmodulo observations (or measurements). This observation model is inspired by a\n(relatively) less well-known imaging mechanism called modulo imaging, which can\nbe used to extend the dynamic range of imaging systems; variations of this\nmodel have also been studied under the category of phase unwrapping. Signal\nreconstruction in the under-determined regime with modulo observations is a\nchallenging ill-posed problem, and existing reconstruction methods cannot be\nused directly. In this paper, we propose a novel approach to solving the\ninverse problem limited to two modulo periods, inspired by recent advances in\nalgorithms for phase retrieval under sparsity constraints. We show that given a\nsufficient number of measurements, our algorithm perfectly recovers the\nunderlying signal and provides improved performance over other existing\nalgorithms. We also provide experiments validating our approach on both\nsynthetic and real data to depict its superior performance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 05:05:18 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 03:04:46 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Shah", "Viraj", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1812.00564", "submitter": "Praneeth Vepakomma", "authors": "Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, Ramesh Raskar", "title": "Split learning for health: Distributed deep learning without sharing raw\n  patient data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can health entities collaboratively train deep learning models without\nsharing sensitive raw data? This paper proposes several configurations of a\ndistributed deep learning method called SplitNN to facilitate such\ncollaborations. SplitNN does not share raw data or model details with\ncollaborating institutions. The proposed configurations of splitNN cater to\npractical settings of i) entities holding different modalities of patient data,\nii) centralized and local health entities collaborating on multiple tasks and\niii) learning without sharing labels. We compare performance and resource\nefficiency trade-offs of splitNN and other distributed deep learning methods\nlike federated learning, large batch synchronous stochastic gradient descent\nand show highly encouraging results for splitNN.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 05:43:20 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Vepakomma", "Praneeth", ""], ["Gupta", "Otkrist", ""], ["Swedish", "Tristan", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1812.00584", "submitter": "Khadija Musayeva", "authors": "Khadija Musayeva (ABC), Fabien Lauer (ABC), Yann Guermeur (ABC)", "title": "Rademacher Complexity and Generalization Performance of Multi-category\n  Margin Classifiers", "comments": "Neurocomputing, Elsevier, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main open problems in the theory of multi-category margin\nclassification is the form of the optimal dependency of a guaranteed risk on\nthe number C of categories, the sample size m and the margin parameter gamma.\nFrom a practical point of view, the theoretical analysis of generalization\nperformance contributes to the development of new learning algorithms. In this\npaper, we focus only on the theoretical aspect of the question posed. More\nprecisely, under minimal learnability assumptions, we derive a new risk bound\nfor multi-category margin classifiers. We improve the dependency on C over the\nstate of the art when the margin loss function considered satisfies the\nLipschitz condition. We start with the basic supremum inequality that involves\na Rademacher complexity as a capacity measure. This capacity measure is then\nlinked to the metric entropy through the chaining method. In this context, our\nimprovement is based on the introduction of a new combinatorial metric entropy\nbound.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 07:41:07 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Musayeva", "Khadija", "", "ABC"], ["Lauer", "Fabien", "", "ABC"], ["Guermeur", "Yann", "", "ABC"]]}, {"id": "1812.00596", "submitter": "Ramesh Manyam", "authors": "Ramesh B. Manyam, Yanqing Zhang, William B. Keeling, Jose Binongo,\n  Michael Kayatta, and Seth Carter", "title": "Deep Learning Approach for Predicting 30 Day Readmissions after Coronary\n  Artery Bypass Graft Surgery", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/222", "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hospital Readmissions within 30 days after discharge following Coronary\nArtery Bypass Graft (CABG) Surgery are substantial contributors to healthcare\ncosts. Many predictive models were developed to identify risk factors for\nreadmissions. However, majority of the existing models use statistical analysis\ntechniques with data available at discharge. We propose an ensembled model to\npredict CABG readmissions using pre-discharge perioperative data and machine\nlearning survival analysis techniques. Firstly, we applied fifty one potential\nreadmission risk variables to Cox Proportional Hazard (CPH) survival regression\nunivariate analysis. Fourteen of them turned out to be significant (with p\nvalue < 0.05), contributing to readmissions. Subsequently, we applied these 14\npredictors to multivariate CPH model and Deep Learning Neural Network (NN)\nrepresentation of the CPH model, DeepSurv. We validated this new ensembled\nmodel with 453 isolated adult CABG cases. Nine of the fourteen perioperative\nrisk variables were identified as the most significant with Hazard Ratios (HR)\nof greater than 1.0. The concordance index metrics for CPH, DeepSurv, and\nensembled models were then evaluated with training and validation datasets. Our\nensembled model yielded promising results in terms of c-statistics, as we\nraised the the number of iterations and data set sizes. 30 day all-cause\nreadmissions among isolated CABG patients can be predicted more effectively\nwith perioperative pre-discharge data, using machine learning survival analysis\ntechniques. Prediction accuracy levels could be improved further with deep\nlearning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 08:20:36 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Manyam", "Ramesh B.", ""], ["Zhang", "Yanqing", ""], ["Keeling", "William B.", ""], ["Binongo", "Jose", ""], ["Kayatta", "Michael", ""], ["Carter", "Seth", ""]]}, {"id": "1812.00600", "submitter": "Abhinav Bhatia", "authors": "Abhinav Bhatia, Pradeep Varakantham and Akshat Kumar", "title": "Resource Constrained Deep Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the International Conference on Automated Planning\n  and Scheduling. 29, 1 (Jul. 2019), 610-620", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In urban environments, supply resources have to be constantly matched to the\n\"right\" locations (where customer demand is present) so as to improve quality\nof life. For instance, ambulances have to be matched to base stations regularly\nso as to reduce response time for emergency incidents in EMS (Emergency\nManagement Systems); vehicles (cars, bikes, scooters etc.) have to be matched\nto docking stations so as to reduce lost demand in shared mobility systems.\nSuch problem domains are challenging owing to the demand uncertainty,\ncombinatorial action spaces (due to allocation) and constraints on allocation\nof resources (e.g., total resources, minimum and maximum number of resources at\nlocations and regions).\n  Existing systems typically employ myopic and greedy optimization approaches\nto optimize allocation of supply resources to locations. Such approaches\ntypically are unable to handle surges or variances in demand patterns well.\nRecent research has demonstrated the ability of Deep RL methods in adapting\nwell to highly uncertain environments. However, existing Deep RL methods are\nunable to handle combinatorial action spaces and constraints on allocation of\nresources. To that end, we have developed three approaches on top of the well\nknown actor critic approach, DDPG (Deep Deterministic Policy Gradient) that are\nable to handle constraints on resource allocation. More importantly, we\ndemonstrate that they are able to outperform leading approaches on simulators\nvalidated on semi-real and real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 08:34:36 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Bhatia", "Abhinav", ""], ["Varakantham", "Pradeep", ""], ["Kumar", "Akshat", ""]]}, {"id": "1812.00602", "submitter": "Panagiotis Stalidis", "authors": "Panagiotis Stalidis, Theodoros Semertzidis and Petros Daras", "title": "Examining Deep Learning Architectures for Crime Classification and\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a detailed study on crime classification and prediction using\ndeep learning architectures is presented. We examine the effectiveness of deep\nlearning algorithms on this domain and provide recommendations for designing\nand training deep learning systems for predicting crime areas, using open data\nfrom police reports. Having as training data time-series of crime types per\nlocation, a comparative study of 10 state-of-the-art methods against 3\ndifferent deep learning configurations is conducted. In our experiments with\nfive publicly available datasets, we demonstrate that the deep learning-based\nmethods consistently outperform the existing best-performing methods. Moreover,\nwe evaluate the effectiveness of different parameters in the deep learning\narchitectures and give insights for configuring them in order to achieve\nimproved performance in crime classification and finally crime prediction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 08:40:50 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Stalidis", "Panagiotis", ""], ["Semertzidis", "Theodoros", ""], ["Daras", "Petros", ""]]}, {"id": "1812.00699", "submitter": "Wei-Hung Weng", "authors": "Uma M. Girkar, Ryo Uchimido, Li-wei H. Lehman, Peter Szolovits, Leo\n  Celi, and Wei-Hung Weng", "title": "Predicting Blood Pressure Response to Fluid Bolus Therapy Using\n  Attention-Based Neural Networks for Clinical Interpretability", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.med-ph q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining whether hypotensive patients in intensive care units (ICUs)\nshould receive fluid bolus therapy (FBT) has been an extremely challenging task\nfor intensive care physicians as the corresponding increase in blood pressure\nhas been hard to predict. Our study utilized regression models and\nattention-based recurrent neural network (RNN) algorithms and a multi-clinical\ninformation system large-scale database to build models that can predict the\nsuccessful response to FBT among hypotensive patients in ICUs. We investigated\nboth time-aggregated modeling using logistic regression algorithms with\nregularization and time-series modeling using the long short term memory\nnetwork (LSTM) and the gated recurrent units network (GRU) with the attention\nmechanism for clinical interpretability. Among all modeling strategies, the\nstacked LSTM with the attention mechanism yielded the most predictable model\nwith the highest accuracy of 0.852 and area under the curve (AUC) value of\n0.925. The study results may help identify hypotensive patients in ICUs who\nwill have sufficient blood pressure recovery after FBT.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 12:17:22 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Girkar", "Uma M.", ""], ["Uchimido", "Ryo", ""], ["Lehman", "Li-wei H.", ""], ["Szolovits", "Peter", ""], ["Celi", "Leo", ""], ["Weng", "Wei-Hung", ""]]}, {"id": "1812.00715", "submitter": "Sayan Putatunda PhD", "authors": "Sayan Putatunda", "title": "Care2Vec: A Deep learning approach for the classification of self-care\n  problems in physically disabled children", "comments": "14 pages, 1 figure, submitted to a journal. Added References in the\n  new version", "journal-ref": "Putatunda, S. Care2Vec: a hybrid autoencoder-based approach for\n  the classification of self-care problems in physically disabled children.\n  Neural Comput & Applic (2020). https://doi.org/10.1007/s00521-020-04943-2", "doi": "10.1007/s00521-020-04943-2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate classification of self-care problems in children who suffer from\nphysical and motor affliction is an important problem in the healthcare\nindustry. This is a difficult and a time consumming process and it needs the\nexpertise of occupational therapists. In recent years, healthcare professionals\nhave opened up to the idea of using expert systems and artificial intelligence\nin the diagnosis and classification of self care problems. In this study, we\npropose a new deep learning based approach named Care2Vec for solving these\nkind of problems and use a real world self care activities dataset that is\nbased on a conceptual framework designed by the World Health Organization\n(WHO). Care2Vec is a mix of unsupervised and supervised learning where we use\nAutoencoders and Deep neural networks as a two step modeling process. We found\nthat Care2Vec has a better prediction accuracy than some of the traditional\nmethods reported in the literature for solving the self care classification\nproblem viz. Decision trees and Artificial neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 12:59:28 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 05:28:42 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Putatunda", "Sayan", ""]]}, {"id": "1812.00717", "submitter": "Aliaksandr Siarohin", "authors": "Aliaksandr Siarohin, Gloria Zen, Nicu Sebe, Elisa Ricci", "title": "Enhancing Perceptual Attributes with Bayesian Style Generation", "comments": "ACCV-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has brought an unprecedented progress in computer vision and\nsignificant advances have been made in predicting subjective properties\ninherent to visual data (e.g., memorability, aesthetic quality, evoked\nemotions, etc.). Recently, some research works have even proposed deep learning\napproaches to modify images such as to appropriately alter these properties.\nFollowing this research line, this paper introduces a novel deep learning\nframework for synthesizing images in order to enhance a predefined perceptual\nattribute. Our approach takes as input a natural image and exploits recent\nmodels for deep style transfer and generative adversarial networks to change\nits style in order to modify a specific high-level attribute. Differently from\nprevious works focusing on enhancing a specific property of a visual content,\nwe propose a general framework and demonstrate its effectiveness in two use\ncases, i.e. increasing image memorability and generating scary pictures. We\nevaluate the proposed approach on publicly available benchmarks, demonstrating\nits advantages over state of the art methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 13:06:32 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Siarohin", "Aliaksandr", ""], ["Zen", "Gloria", ""], ["Sebe", "Nicu", ""], ["Ricci", "Elisa", ""]]}, {"id": "1812.00740", "submitter": "David Stutz", "authors": "David Stutz, Matthias Hein, Bernt Schiele", "title": "Disentangling Adversarial Robustness and Generalization", "comments": "Conference on Computer Vision and Pattern Recognition 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining deep networks that are robust against adversarial examples and\ngeneralize well is an open problem. A recent hypothesis even states that both\nrobust and accurate models are impossible, i.e., adversarial robustness and\ngeneralization are conflicting goals. In an effort to clarify the relationship\nbetween robustness and generalization, we assume an underlying, low-dimensional\ndata manifold and show that: 1. regular adversarial examples leave the\nmanifold; 2. adversarial examples constrained to the manifold, i.e.,\non-manifold adversarial examples, exist; 3. on-manifold adversarial examples\nare generalization errors, and on-manifold adversarial training boosts\ngeneralization; 4. regular robustness and generalization are not necessarily\ncontradicting goals. These assumptions imply that both robust and accurate\nmodels are possible. However, different models (architectures, training\nstrategies etc.) can exhibit different robustness and generalization\ncharacteristics. To confirm our claims, we present extensive experiments on\nsynthetic data (with known manifold) as well as on EMNIST, Fashion-MNIST and\nCelebA.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 14:04:35 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 10:25:38 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Stutz", "David", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "1812.00786", "submitter": "Bradley Gram-Hansen", "authors": "Patrick Helber, Bradley Gram-Hansen, Indhu Varatharajan, Faiza Azam,\n  Alejandro Coca-Castro, Veronika Kopackova, Piotr Bilinski", "title": "Generating Material Maps to Map Informal Settlements", "comments": "Appeared at the 32nd Conference on Neural Information Processing\n  Systems (NeurlPS 2018) Machine Learning for the Developing World (ML4DW)\n  Workshop", "journal-ref": "NeurlPS workshop on Machine Learning for the Developing World\n  (ML4DW), 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and mapping informal settlements encompasses several of the United\nNations sustainable development goals. This is because informal settlements are\nhome to the most socially and economically vulnerable people on the planet.\nThus, understanding where these settlements are is of paramount importance to\nboth government and non-government organizations (NGOs), such as the United\nNations Children's Fund (UNICEF), who can use this information to deliver\neffective social and economic aid. We propose a method that detects and maps\nthe locations of informal settlements using only freely available, Sentinel-2\nlow-resolution satellite spectral data and socio-economic data. This is in\ncontrast to previous studies that only use costly very-high resolution (VHR)\nsatellite and aerial imagery. We show how we can detect informal settlements by\ncombining both domain knowledge and machine learning techniques, to build a\nclassifier that looks for known roofing materials used in informal settlements.\nPlease find additional material at\nhttps://frontierdevelopmentlab.github.io/informal-settlements/.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 09:09:41 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 12:19:50 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Helber", "Patrick", ""], ["Gram-Hansen", "Bradley", ""], ["Varatharajan", "Indhu", ""], ["Azam", "Faiza", ""], ["Coca-Castro", "Alejandro", ""], ["Kopackova", "Veronika", ""], ["Bilinski", "Piotr", ""]]}, {"id": "1812.00793", "submitter": "Holden Lee", "authors": "Rong Ge, Holden Lee, Andrej Risteski", "title": "Simulated Tempering Langevin Monte Carlo II: An Improved Proof using\n  Soft Markov Chain Decomposition", "comments": "69 pages. arXiv admin note: text overlap with arXiv:1710.02736", "journal-ref": "Advances in Neural Information Processing Systems 31 (2018)", "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key task in Bayesian machine learning is sampling from distributions that\nare only specified up to a partition function (i.e., constant of\nproportionality). One prevalent example of this is sampling posteriors in\nparametric distributions, such as latent-variable generative models. However\nsampling (even very approximately) can be #P-hard.\n  Classical results going back to Bakry and \\'Emery (1985) on sampling focus on\nlog-concave distributions, and show a natural Markov chain called Langevin\ndiffusion mixes in polynomial time. However, all log-concave distributions are\nuni-modal, while in practice it is very common for the distribution of interest\nto have multiple modes. In this case, Langevin diffusion suffers from torpid\nmixing.\n  We address this problem by combining Langevin diffusion with simulated\ntempering. The result is a Markov chain that mixes more rapidly by\ntransitioning between different temperatures of the distribution. We analyze\nthis Markov chain for a mixture of (strongly) log-concave distributions of the\nsame shape. In particular, our technique applies to the canonical multi-modal\ndistribution: a mixture of gaussians (of equal variance). Our algorithm\nefficiently samples from these distributions given only access to the gradient\nof the log-pdf.\n  For the analysis, we introduce novel techniques for proving spectral gaps\nbased on decomposing the action of the generator of the diffusion. Previous\napproaches rely on decomposing the state space as a partition of sets, while\nour approach can be thought of as decomposing the stationary measure as a\nmixture of distributions (a \"soft partition\").\n  Additional materials for the paper can be found at\nhttp://holdenlee.github.io/Simulated%20tempering%20Langevin%20Monte%20Carlo.html.\nThe proof and results have been improved and generalized from the precursor at\narXiv:1710.02736.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 19:27:33 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:39:09 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 12:44:05 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Holden", ""], ["Risteski", "Andrej", ""]]}, {"id": "1812.00797", "submitter": "Shahin Khobahi", "authors": "Shahin Khobahi, Naveed Naimipour, Mojtaba Soltanalian and Yonina C.\n  Eldar", "title": "Deep Signal Recovery with One-Bit Quantization", "comments": "This paper has been submitted to the 44th International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP 2019)", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683876", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning, and more specifically deep learning, have shown remarkable\nperformance in sensing, communications, and inference. In this paper, we\nconsider the application of the deep unfolding technique in the problem of\nsignal reconstruction from its one-bit noisy measurements. Namely, we propose a\nmodel-based machine learning method and unfold the iterations of an inference\noptimization algorithm into the layers of a deep neural network for one-bit\nsignal recovery. The resulting network, which we refer to as DeepRec, can\nefficiently handle the recovery of high-dimensional signals from acquired\none-bit noisy measurements. The proposed method results in an improvement in\naccuracy and computational efficiency with respect to the original framework as\nshown through numerical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 00:02:46 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Khobahi", "Shahin", ""], ["Naimipour", "Naveed", ""], ["Soltanalian", "Mojtaba", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1812.00804", "submitter": "Yingcong Tan", "authors": "Yingcong Tan, Andrew Delong, Daria Terekhov", "title": "Deep Inverse Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of observations generated by an optimization process, the goal of\ninverse optimization is to determine likely parameters of that process. We cast\ninverse optimization as a form of deep learning. Our method, called deep\ninverse optimization, is to unroll an iterative optimization process and then\nuse backpropagation to learn parameters that generate the observations. We\ndemonstrate that by backpropagating through the interior point algorithm we can\nlearn the coefficients determining the cost vector and the constraints,\nindependently or jointly, for both non-parametric and parametric linear\nprograms, starting from one or multiple observations. With this approach,\ninverse optimization can leverage concepts and algorithms from deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 14:56:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Tan", "Yingcong", ""], ["Delong", "Andrew", ""], ["Terekhov", "Daria", ""]]}, {"id": "1812.00812", "submitter": "Patrick Helber", "authors": "Patrick Helber, Bradley Gram-Hansen, Indhu Varatharajan, Faiza Azam,\n  Alejandro Coca-Castro, Veronika Kopackova, Piotr Bilinski", "title": "Mapping Informal Settlements in Developing Countries with\n  Multi-resolution, Multi-spectral Data", "comments": "arXiv admin note: text overlap with arXiv:1812.00786", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and mapping informal settlements encompasses several of the United\nNations sustainable development goals. This is because informal settlements are\nhome to the most socially and economically vulnerable people on the planet.\nThus, understanding where these settlements are is of paramount importance to\nboth government and non-government organizations (NGOs), such as the United\nNations Children's Fund (UNICEF), who can use this information to deliver\neffective social and economic aid. We propose two effective methods for\ndetecting and mapping the locations of informal settlements. One uses only\nlow-resolution (LR), freely available, Sentinel-2 multispectral satellite\nimagery with noisy annotations, whilst the other is a deep learning approach\nthat uses only costly very-high-resolution (VHR) satellite imagery. To our\nknowledge, we are the first to map informal settlements successfully with\nlow-resolution satellite imagery. We extensively evaluate and compare the\nproposed methods. Please find additional material at\nhttps://frontierdevelopmentlab.github.io/informal-settlements/.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 10:38:37 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Helber", "Patrick", ""], ["Gram-Hansen", "Bradley", ""], ["Varatharajan", "Indhu", ""], ["Azam", "Faiza", ""], ["Coca-Castro", "Alejandro", ""], ["Kopackova", "Veronika", ""], ["Bilinski", "Piotr", ""]]}, {"id": "1812.00855", "submitter": "Ruo Yu Tao", "authors": "Ruo Yu Tao, Marc-Alexandre C\\^ot\\'e, Xingdi Yuan, Layla El Asri", "title": "Towards Solving Text-based Games by Producing Adaptive Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve a text-based game, an agent needs to formulate valid text commands\nfor a given context and find the ones that lead to success. Recent attempts at\nsolving text-based games with deep reinforcement learning have focused on the\nlatter, i.e., learning to act optimally when valid actions are known in\nadvance. In this work, we propose to tackle the first task and train a model\nthat generates the set of all valid commands for a given context. We try three\ngenerative models on a dataset generated with Textworld. The best model can\ngenerate valid commands which were unseen at training and achieve high $F_1$\nscore on the test set.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 16:00:48 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Tao", "Ruo Yu", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Yuan", "Xingdi", ""], ["Asri", "Layla El", ""]]}, {"id": "1812.00856", "submitter": "Andrew Stirn", "authors": "Andrew Stirn, Tony Jebara", "title": "Thompson Sampling for Noncompliant Bandits", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling, a Bayesian method for balancing exploration and\nexploitation in bandit problems, has theoretical guarantees and exhibits strong\nempirical performance in many domains. Traditional Thompson sampling, however,\nassumes perfect compliance, where an agent's chosen action is treated as the\nimplemented action. This article introduces a stochastic noncompliance model\nthat relaxes this assumption. We prove that any noncompliance in a 2-armed\nBernoulli bandit increases existing regret bounds. With our noncompliance\nmodel, we derive Thompson sampling variants that explicitly handle both\nobserved and latent noncompliance. With extensive empirical analysis, we\ndemonstrate that our algorithms either match or outperform traditional Thompson\nsampling in both compliant and noncompliant environments.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 16:01:43 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Stirn", "Andrew", ""], ["Jebara", "Tony", ""]]}, {"id": "1812.00877", "submitter": "Glib Kechyn", "authors": "Glib Kechyn", "title": "Automatic lesion boundary detection in dermoscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript addresses the problem of the automatic lesion boundary\ndetection in dermoscopy, using deep neural networks. An approach is based on\nthe adaptation of the U-net convolutional neural network with skip connections\nfor lesion boundary segmentation task. I hope this paper could serve, to some\nextent, as an experiment of using deep convolutional networks in biomedical\nsegmentation task and as a guideline of the boundary detection benchmark,\ninspiring further attempts and researches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 22:36:36 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Kechyn", "Glib", ""]]}, {"id": "1812.00879", "submitter": "Sa\\'ul Alonso-Monsalve", "authors": "Sa\\'ul Alonso-Monsalve and Leigh H. Whitehead", "title": "Image-based model parameter optimization using Model-Assisted Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.2969327", "report-no": null, "categories": "cs.CV cs.LG hep-ex stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose and demonstrate the use of a model-assisted generative adversarial\nnetwork (GAN) to produce fake images that accurately match true images through\nthe variation of the parameters of the model that describes the features of the\nimages. The generator learns the model parameter values that produce fake\nimages that best match the true images. Two case studies show excellent\nagreement between the generated best match parameters and the true parameters.\nThe best match model parameter values can be used to retune the default\nsimulation to minimize any bias when applying image recognition techniques to\nfake and true images. In the case of a real-world experiment, the true images\nare experimental data with unknown true model parameter values, and the fake\nimages are produced by a simulation that takes the model parameters as input.\nThe model-assisted GAN uses a convolutional neural network to emulate the\nsimulation for all parameter values that, when trained, can be used as a\nconditional generator for fast fake-image production.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 17:27:53 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 08:58:22 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Alonso-Monsalve", "Sa\u00fal", ""], ["Whitehead", "Leigh H.", ""]]}, {"id": "1812.00880", "submitter": "Jonathan P. Chen", "authors": "Jonathan P. Chen, Fritz Obermeyer, Vladimir Lyapunov, Lionel Gueguen,\n  Noah D. Goodman", "title": "Joint Mapping and Calibration via Differentiable Sensor Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage automatic differentiation (AD) and probabilistic programming to\ndevelop an end-to-end optimization algorithm for batch triangulation of a large\nnumber of unknown objects. Given noisy detections extracted from noisily\ngeo-located street level imagery without depth information, we jointly estimate\nthe number and location of objects of different types, together with parameters\nfor sensor noise characteristics and prior distribution of objects conditioned\non side information. The entire algorithm is framed as nested stochastic\nvariational inference. An inner loop solves a soft data association problem via\nloopy belief propagation; a middle loop performs soft EM clustering using a\nregularized Newton solver (leveraging an AD framework); an outer loop\nbackpropagates through the inner loops to train global parameters. We place\npriors over sensor parameters for different traffic object types, and\ndemonstrate improvements with richer priors incorporating knowledge of the\nenvironment.\n  We test our algorithm on detections of road signs observed by cars with\nmounted cameras, though in practice this technique can be used for any\ngeo-tagged images. The detections were extracted by neural image detectors and\nclassifiers, and we independently triangulate each type of sign (e.g. stop,\ntraffic light). We find that our model is more robust to DNN misclassifications\nthan current methods, generalizes across sign types, and can use geometric\ninformation to increase precision. Our algorithm outperforms our current\nproduction baseline based on k-means clustering. We show that variational\ninference training allows generalization by learning sign-specific parameters.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 06:22:06 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 04:58:10 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Chen", "Jonathan P.", ""], ["Obermeyer", "Fritz", ""], ["Lyapunov", "Vladimir", ""], ["Gueguen", "Lionel", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1812.00883", "submitter": "Shishira Maiya", "authors": "Sudharshan Chandra Babu, Shishira R Maiya, Sivasankar Elango", "title": "Relation Networks for Optic Disc and Fovea Localization in Retinal\n  Images", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic Retinopathy is the leading cause of blindness in the world. At least\n90\\% of new cases can be reduced with proper treatment and monitoring of the\neyes. However, scanning the entire population of patients is a difficult\nendeavor. Computer-aided diagnosis tools in retinal image analysis can make the\nprocess scalable and efficient. In this work, we focus on the problem of\nlocalizing the centers of the Optic disc and Fovea, a task crucial to the\nanalysis of retinal scans. Current systems recognize the Optic disc and Fovea\nindividually, without exploiting their relations during learning. We propose a\nnovel approach to localizing the centers of the Optic disc and Fovea by\nsimultaneously processing them and modeling their relative geometry and\nappearance. We show that our approach improves localization and recognition by\nincorporating object-object relations efficiently, and achieves highly\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 14:51:55 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Babu", "Sudharshan Chandra", ""], ["Maiya", "Shishira R", ""], ["Elango", "Sivasankar", ""]]}, {"id": "1812.00884", "submitter": "Shazia Akbar", "authors": "Shazia Akbar, Anne L. Martel", "title": "Cluster-Based Learning from Weakly Labeled Bags in Digital Pathology", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/27", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To alleviate the burden of gathering detailed expert annotations when\ntraining deep neural networks, we propose a weakly supervised learning approach\nto recognize metastases in microscopic images of breast lymph nodes. We\ndescribe an alternative training loss which clusters weakly labeled bags in\nlatent space to inform relevance of patch-instances during training of a\nconvolutional neural network. We evaluate our method on the Camelyon dataset\nwhich contains high-resolution digital slides of breast lymph nodes, where\nlabels are provided at the image-level and only subsets of patches are made\navailable during training.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 15:05:22 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Akbar", "Shazia", ""], ["Martel", "Anne L.", ""]]}, {"id": "1812.00887", "submitter": "Donghui Yan", "authors": "Donghui Yan, Timothy W. Randolph, Jian Zou and Peng Gong", "title": "Incorporating Deep Features in the Analysis of Tissue Microarray Images", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tissue microarray (TMA) images have been used increasingly often in cancer\nstudies and the validation of biomarkers. TACOMA---a cutting-edge automatic\nscoring algorithm for TMA images---is comparable to pathologists in terms of\naccuracy and repeatability. Here we consider how this algorithm may be further\nimproved. Inspired by the recent success of deep learning, we propose to\nincorporate representations learnable through computation. We explore\nrepresentations of a group nature through unsupervised learning, e.g.,\nhierarchical clustering and recursive space partition. Information carried by\nclustering or spatial partitioning may be more concrete than the labels when\nthe data are heterogeneous, or could help when the labels are noisy. The use of\nsuch information could be viewed as regularization in model fitting. It is\nmotivated by major challenges in TMA image scoring---heterogeneity and label\nnoise, and the cluster assumption in semi-supervised learning. Using this\ninformation on TMA images of breast cancer, we have reduced the error rate of\nTACOMA by about 6%. Further simulations on synthetic data provide insights on\nwhen such representations would likely help. Although we focus on TMAs,\nlearnable representations of this type are expected to be applicable in other\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 04:18:17 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Yan", "Donghui", ""], ["Randolph", "Timothy W.", ""], ["Zou", "Jian", ""], ["Gong", "Peng", ""]]}, {"id": "1812.00898", "submitter": "Aishwarya Agrawal", "authors": "Aishwarya Agrawal, Mateusz Malinowski, Felix Hill, Ali Eslami, Oriol\n  Vinyals, Tejas Kulkarni", "title": "Generating Diverse Programs with Instruction Conditioned Reinforced\n  Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Deep Reinforcement Learning have led to agents that perform well\nacross a variety of sensory-motor domains. In this work, we study the setting\nin which an agent must learn to generate programs for diverse scenes\nconditioned on a given symbolic instruction. Final goals are specified to our\nagent via images of the scenes. A symbolic instruction consistent with the goal\nimages is used as the conditioning input for our policies. Since a single\ninstruction corresponds to a diverse set of different but still consistent\nend-goal images, the agent needs to learn to generate a distribution over\nprograms given an instruction. We demonstrate that with simple changes to the\nreinforced adversarial learning objective, we can learn instruction conditioned\npolicies to achieve the corresponding diverse set of goals. Most importantly,\nour agent's stochastic policy is shown to more accurately capture the diversity\nin the goal distribution than a fixed pixel-based reward function baseline. We\ndemonstrate the efficacy of our approach on two domains: (1) drawing MNIST\ndigits with a paint software conditioned on instructions and (2) constructing\nscenes in a 3D editor that satisfies a certain instruction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 16:51:35 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Agrawal", "Aishwarya", ""], ["Malinowski", "Mateusz", ""], ["Hill", "Felix", ""], ["Eslami", "Ali", ""], ["Vinyals", "Oriol", ""], ["Kulkarni", "Tejas", ""]]}, {"id": "1812.00910", "submitter": "Reza Shokri", "authors": "Milad Nasr, Reza Shokri, Amir Houmansadr", "title": "Comprehensive Privacy Analysis of Deep Learning: Passive and Active\n  White-box Inference Attacks against Centralized and Federated Learning", "comments": "2019 IEEE Symposium on Security and Privacy (SP)", "journal-ref": null, "doi": "10.1109/SP.2019.00065", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are susceptible to various inference attacks as they\nremember information about their training data. We design white-box inference\nattacks to perform a comprehensive privacy analysis of deep learning models. We\nmeasure the privacy leakage through parameters of fully trained models as well\nas the parameter updates of models during training. We design inference\nalgorithms for both centralized and federated learning, with respect to passive\nand active inference attackers, and assuming different adversary prior\nknowledge.\n  We evaluate our novel white-box membership inference attacks against deep\nlearning algorithms to trace their training data records. We show that a\nstraightforward extension of the known black-box attacks to the white-box\nsetting (through analyzing the outputs of activation functions) is ineffective.\nWe therefore design new algorithms tailored to the white-box setting by\nexploiting the privacy vulnerabilities of the stochastic gradient descent\nalgorithm, which is the algorithm used to train deep neural networks. We\ninvestigate the reasons why deep learning models may leak information about\ntheir training data. We then show that even well-generalized models are\nsignificantly susceptible to white-box membership inference attacks, by\nanalyzing state-of-the-art pre-trained and publicly available models for the\nCIFAR dataset. We also show how adversarial participants, in the federated\nlearning setting, can successfully run active membership inference attacks\nagainst other participants, even when the global model achieves high prediction\naccuracies.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:11:21 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 18:22:55 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Nasr", "Milad", ""], ["Shokri", "Reza", ""], ["Houmansadr", "Amir", ""]]}, {"id": "1812.00914", "submitter": "Minghan Li", "authors": "Minghan Li, Tanli Zuo, Ruicheng Li, Martha White, Weishi Zheng", "title": "Accelerating Large Scale Knowledge Distillation via Dynamic Importance\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is an effective technique that transfers knowledge\nfrom a large teacher model to a shallow student. However, just like massive\nclassification, large scale knowledge distillation also imposes heavy\ncomputational costs on training models of deep neural networks, as the softmax\nactivations at the last layer involve computing probabilities over numerous\nclasses. In this work, we apply the idea of importance sampling which is often\nused in Neural Machine Translation on large scale knowledge distillation. We\npresent a method called dynamic importance sampling, where ranked classes are\nsampled from a dynamic distribution derived from the interaction between the\nteacher and student in full distillation. We highlight the utility of our\nproposal prior which helps the student capture the main information in the loss\nfunction. Our approach manages to reduce the computational cost at training\ntime while maintaining the competitive performance on CIFAR-100 and Market-1501\nperson re-identification datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:15:44 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Minghan", ""], ["Zuo", "Tanli", ""], ["Li", "Ruicheng", ""], ["White", "Martha", ""], ["Zheng", "Weishi", ""]]}, {"id": "1812.00922", "submitter": "Ozsel Kilinc", "authors": "Ozsel Kilinc, Giovanni Montana", "title": "Multi-agent Deep Reinforcement Learning with Extremely Noisy\n  Observations", "comments": "To appear in Deep Reinforcement Learning Workshop, NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning systems aim to provide interacting agents\nwith the ability to collaboratively learn and adapt to the behaviour of other\nagents. In many real-world applications, the agents can only acquire a partial\nview of the world. Here we consider a setting whereby most agents' observations\nare also extremely noisy, hence only weakly correlated to the true state of the\nenvironment. Under these circumstances, learning an optimal policy becomes\nparticularly challenging, even in the unrealistic case that an agent's policy\ncan be made conditional upon all other agents' observations. To overcome these\ndifficulties, we propose a multi-agent deep deterministic policy gradient\nalgorithm enhanced by a communication medium (MADDPG-M), which implements a\ntwo-level, concurrent learning mechanism. An agent's policy depends on its own\nprivate observations as well as those explicitly shared by others through a\ncommunication medium. At any given point in time, an agent must decide whether\nits private observations are sufficiently informative to be shared with others.\nHowever, our environments provide no explicit feedback informing an agent\nwhether a communication action is beneficial, rather the communication policies\nmust also be learned through experience concurrently to the main policies. Our\nexperimental results demonstrate that the algorithm performs well in six highly\nnon-stationary environments of progressively higher complexity, and offers\nsubstantial performance gains compared to the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:27:41 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Kilinc", "Ozsel", ""], ["Montana", "Giovanni", ""]]}, {"id": "1812.00950", "submitter": "Yijie Guo", "authors": "Yijie Guo, Junhyuk Oh, Satinder Singh, Honglak Lee", "title": "Generative Adversarial Self-Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a simple regularizer for reinforcement learning by\nproposing Generative Adversarial Self-Imitation Learning (GASIL), which\nencourages the agent to imitate past good trajectories via generative\nadversarial imitation learning framework. Instead of directly maximizing\nrewards, GASIL focuses on reproducing past good trajectories, which can\npotentially make long-term credit assignment easier when rewards are sparse and\ndelayed. GASIL can be easily combined with any policy gradient objective by\nusing GASIL as a learned shaped reward function. Our experimental results show\nthat GASIL improves the performance of proximal policy optimization on 2D Point\nMass and MuJoCo environments with delayed reward and stochastic dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:21:18 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Guo", "Yijie", ""], ["Oh", "Junhyuk", ""], ["Singh", "Satinder", ""], ["Lee", "Honglak", ""]]}, {"id": "1812.00974", "submitter": "Yanning Shen", "authors": "Yanning Shen, Geert Leus, Georgios B. Giannakis", "title": "Online Graph-Adaptive Learning with Scalability and Privacy", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2904922", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are widely adopted for modeling complex systems, including financial,\nbiological, and social networks. Nodes in networks usually entail attributes,\nsuch as the age or gender of users in a social network. However, real-world\nnetworks can have very large size, and nodal attributes can be unavailable to a\nnumber of nodes, e.g., due to privacy concerns. Moreover, new nodes can emerge\nover time, which can necessitate real-time evaluation of their nodal\nattributes. In this context, the present paper deals with scalable learning of\nnodal attributes by estimating a nodal function based on noisy observations at\na subset of nodes. A multikernel-based approach is developed which is scalable\nto large-size networks. Unlike most existing methods that re-solve the function\nestimation problem over all existing nodes whenever a new node joins the\nnetwork, the novel method is capable of providing real-time evaluation of the\nfunction values on newly-joining nodes without resorting to a batch solver.\nInterestingly, the novel scheme only relies on an encrypted version of each\nnode's connectivity in order to learn the nodal attributes, which promotes\nprivacy. Experiments on both synthetic and real datasets corroborate the\neffectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:49:29 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Shen", "Yanning", ""], ["Leus", "Geert", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1812.00975", "submitter": "Ahmed Abdelatty", "authors": "Ahmed Abdelatty, Pracheta Sahoo, Chiradeep Roy", "title": "Structure Learning Using Forced Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Markov networks are widely used in many Machine Learning applications\nincluding natural language processing, computer vision, and bioinformatics .\nLearning Markov networks have many complications ranging from intractable\ncomputations involved to the possibility of learning a model with a huge number\nof parameters. In this report, we provide a computationally tractable greedy\nheuristic for learning Markov networks structure. The proposed heuristic\nresults in a model with a limited predefined number of parameters. We ran our\nmethod on 3 fully-observed real datasets, and we observed that our method is\ndoing comparably good to the state of the art methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:49:31 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Abdelatty", "Ahmed", ""], ["Sahoo", "Pracheta", ""], ["Roy", "Chiradeep", ""]]}, {"id": "1812.00979", "submitter": "Xiao-Yang Liu", "authors": "Xiao-Yang Liu, Zihan Ding, Sem Borst, Anwar Walid", "title": "Deep Reinforcement Learning for Intelligent Transportation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Transportation Systems (ITSs) are envisioned to play a critical\nrole in improving traffic flow and reducing congestion, which is a pervasive\nissue impacting urban areas around the globe. Rapidly advancing vehicular\ncommunication and edge cloud computation technologies provide key enablers for\nsmart traffic management. However, operating viable real-time actuation\nmechanisms on a practically relevant scale involves formidable challenges,\ne.g., policy iteration and conventional Reinforcement Learning (RL) techniques\nsuffer from poor scalability due to state space explosion. Motivated by these\nissues, we explore the potential for Deep Q-Networks (DQN) to optimize traffic\nlight control policies. As an initial benchmark, we establish that the DQN\nalgorithms yield the \"thresholding\" policy in a single-intersection. Next, we\nexamine the scalability properties of DQN algorithms and their performance in a\nlinear network topology with several intersections along a main artery. We\ndemonstrate that DQN algorithms produce intelligent behavior, such as the\nemergence of \"greenwave\" patterns, reflecting their ability to learn favorable\ntraffic light actuations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:55:53 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Liu", "Xiao-Yang", ""], ["Ding", "Zihan", ""], ["Borst", "Sem", ""], ["Walid", "Anwar", ""]]}, {"id": "1812.00984", "submitter": "John Duchi", "authors": "Abhishek Bhowmick, John Duchi, Julien Freudiger, Gaurav Kapoor, Ryan\n  Rogers", "title": "Protection Against Reconstruction and Its Applications in Private\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale statistical learning, data collection and model fitting are\nmoving increasingly toward peripheral devices---phones, watches, fitness\ntrackers---away from centralized data collection. Concomitant with this rise in\ndecentralized data are increasing challenges of maintaining privacy while\nallowing enough information to fit accurate, useful statistical models. This\nmotivates local notions of privacy---most significantly, local differential\nprivacy, which provides strong protections against sensitive data\ndisclosures---where data is obfuscated before a statistician or learner can\neven observe it, providing strong protections to individuals' data. Yet local\nprivacy as traditionally employed may prove too stringent for practical use,\nespecially in modern high-dimensional statistical and machine learning\nproblems. Consequently, we revisit the types of disclosures and adversaries\nagainst which we provide protections, considering adversaries with limited\nprior information and ensuring that with high probability, ensuring they cannot\nreconstruct an individual's data within useful tolerances. By reconceptualizing\nthese protections, we allow more useful data release---large privacy parameters\nin local differential privacy---and we design new (minimax) optimal locally\ndifferentially private mechanisms for statistical learning problems for\n\\emph{all} privacy levels. We thus present practicable approaches to\nlarge-scale locally private model training that were previously impossible,\nshowing theoretically and empirically that we can fit large-scale image\nclassification and language models with little degradation in utility.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:59:16 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:48:00 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bhowmick", "Abhishek", ""], ["Duchi", "John", ""], ["Freudiger", "Julien", ""], ["Kapoor", "Gaurav", ""], ["Rogers", "Ryan", ""]]}, {"id": "1812.01029", "submitter": "Enguerrand Horel", "authors": "Enguerrand Horel, Virgile Mison, Tao Xiong, Kay Giesecke, Lidia Mangu", "title": "Sensitivity based Neural Networks Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural networks can achieve very high predictive performance on\nvarious different tasks such as image recognition or natural language\nprocessing, they are often considered as opaque \"black boxes\". The difficulty\nof interpreting the predictions of a neural network often prevents its use in\nfields where explainability is important, such as the financial industry where\nregulators and auditors often insist on this aspect. In this paper, we present\na way to assess the relative input features importance of a neural network\nbased on the sensitivity of the model output with respect to its input. This\nmethod has the advantage of being fast to compute, it can provide both global\nand local levels of explanations and is applicable for many types of neural\nnetwork architectures. We illustrate the performance of this method on both\nsynthetic and real data and compare it with other interpretation techniques.\nThis method is implemented into an open-source Python package that allows its\nusers to easily generate and visualize explanations for their neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 19:05:25 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Horel", "Enguerrand", ""], ["Mison", "Virgile", ""], ["Xiong", "Tao", ""], ["Giesecke", "Kay", ""], ["Mangu", "Lidia", ""]]}, {"id": "1812.01054", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag, Pablo G. Moreno, Neil D. Lawrence, Andreas\n  Damianou", "title": "Transferring Knowledge across Learning Processes", "comments": "Published as a conference paper at ICLR 2019; 23 pages, 8 figures, 6\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex transfer learning scenarios new tasks might not be tightly linked\nto previous tasks. Approaches that transfer information contained only in the\nfinal parameters of a source model will therefore struggle. Instead, transfer\nlearning at a higher level of abstraction is needed. We propose Leap, a\nframework that achieves this by transferring knowledge across learning\nprocesses. We associate each task with a manifold on which the training process\ntravels from initialization to final parameters and construct a meta-learning\nobjective that minimizes the expected length of this path. Our framework\nleverages only information obtained during training and can be computed on the\nfly at negligible cost. We demonstrate that our framework outperforms competing\nmethods, both in meta-learning and transfer learning, on a set of computer\nvision tasks. Finally, we demonstrate that Leap can transfer knowledge across\nlearning processes in demanding reinforcement learning environments (Atari)\nthat involve millions of gradient steps.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 19:43:16 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:28:01 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 13:44:59 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Moreno", "Pablo G.", ""], ["Lawrence", "Neil D.", ""], ["Damianou", "Andreas", ""]]}, {"id": "1812.01060", "submitter": "Nikhil Kotecha", "authors": "Nikhil Kotecha", "title": "Bach2Bach: Generating Music Using A Deep Reinforcement Learning Approach", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of music needs to have the ability to recall past details and have a\nclear, coherent understanding of musical structure. Detailed in the paper is a\ndeep reinforcement learning architecture that predicts and generates polyphonic\nmusic aligned with musical rules. The probabilistic model presented is a\nBi-axial LSTM trained with a pseudo-kernel reminiscent of a convolutional\nkernel. To encourage exploration and impose greater global coherence on the\ngenerated music, a deep reinforcement learning approach DQN is adopted. When\nanalyzed quantitatively and qualitatively, this approach performs well in\ncomposing polyphonic music.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:09:05 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Kotecha", "Nikhil", ""]]}, {"id": "1812.01063", "submitter": "Azin Asgarian", "authors": "Azin Asgarian, Parinaz Sobhani, Ji Chao Zhang, Madalin Mihailescu,\n  Ariel Sibilia, Ahmed Bilal Ashraf, Babak Taati", "title": "A Hybrid Instance-based Transfer Learning Method", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/174", "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, supervised machine learning models have demonstrated\ntremendous success in a variety of application domains. Despite the promising\nresults, these successful models are data hungry and their performance relies\nheavily on the size of training data. However, in many healthcare applications\nit is difficult to collect sufficiently large training datasets. Transfer\nlearning can help overcome this issue by transferring the knowledge from\nreadily available datasets (source) to a new dataset (target). In this work, we\npropose a hybrid instance-based transfer learning method that outperforms a set\nof baselines including state-of-the-art instance-based transfer learning\napproaches. Our method uses a probabilistic weighting strategy to fuse\ninformation from the source domain to the model learned in the target domain.\nOur method is generic, applicable to multiple source domains, and robust with\nrespect to negative transfer. We demonstrate the effectiveness of our approach\nthrough extensive experiments for two different applications.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:15:05 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Asgarian", "Azin", ""], ["Sobhani", "Parinaz", ""], ["Zhang", "Ji Chao", ""], ["Mihailescu", "Madalin", ""], ["Sibilia", "Ariel", ""], ["Ashraf", "Ahmed Bilal", ""], ["Taati", "Babak", ""]]}, {"id": "1812.01070", "submitter": "Wengong Jin", "authors": "Wengong Jin, Kevin Yang, Regina Barzilay, Tommi Jaakkola", "title": "Learning Multimodal Graph-to-Graph Translation for Molecular\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view molecular optimization as a graph-to-graph translation problem. The\ngoal is to learn to map from one molecular graph to another with better\nproperties based on an available corpus of paired molecules. Since molecules\ncan be optimized in different ways, there are multiple viable translations for\neach input graph. A key challenge is therefore to model diverse translation\noutputs. Our primary contributions include a junction tree encoder-decoder for\nlearning diverse graph translations along with a novel adversarial training\nmethod for aligning distributions of molecules. Diverse output distributions in\nour model are explicitly realized by low-dimensional latent vectors that\nmodulate the translation process. We evaluate our model on multiple molecular\noptimization tasks and show that our model outperforms previous\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:28:09 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 22:19:13 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 19:38:39 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Jin", "Wengong", ""], ["Yang", "Kevin", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1812.01074", "submitter": "Peter Henderson", "authors": "Peter Henderson and Emma Brunskill", "title": "Distilling Information from a Flood: A Possibility for the Use of\n  Meta-Analysis and Systematic Review in Machine Learning Research", "comments": "Accepted to the Critiquing and Correcting Trends in Machine Learning\n  Workshop (CRACT) at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current flood of information in all areas of machine learning research,\nfrom computer vision to reinforcement learning, has made it difficult to make\naggregate scientific inferences. It can be challenging to distill a myriad of\nsimilar papers into a set of useful principles, to determine which new\nmethodologies to use for a particular application, and to be confident that one\nhas compared against all relevant related work when developing new ideas.\nHowever, such a rapidly growing body of research literature is a problem that\nother fields have already faced - in particular, medicine and epidemiology. In\nthose fields, systematic reviews and meta-analyses have been used exactly for\ndealing with these issues and it is not uncommon for entire journals to be\ndedicated to such analyses. Here, we suggest the field of machine learning\nmight similarly benefit from meta-analysis and systematic review, and we\nencourage further discussion and development along this direction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:37:21 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Henderson", "Peter", ""], ["Brunskill", "Emma", ""]]}, {"id": "1812.01077", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute, Martin Minnoni", "title": "Brief survey of Mobility Analyses based on Mobile Phone Datasets", "comments": "Workshop on Urban Computing and Society. Petropolis, RJ, Brazil. Nov\n  28, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This is a brief survey of the research performed by Grandata Labs in\ncollaboration with numerous academic groups around the world on the topic of\nhuman mobility. A driving theme in these projects is to use and improve Data\nScience techniques to understand mobility, as it can be observed through the\nlens of mobile phone datasets. We describe applications of mobility analyses\nfor urban planning, prediction of data traffic usage, building delay tolerant\nnetworks, generating epidemiologic risk maps and measuring the predictability\nof human mobility.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:46:27 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Sarraute", "Carlos", ""], ["Minnoni", "Martin", ""]]}, {"id": "1812.01087", "submitter": "Nathaniel Braman", "authors": "Nathaniel Braman, David Beymer, Ehsan Dehghan", "title": "Disease Detection in Weakly Annotated Volumetric Medical Images using a\n  Convolutional LSTM Network", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216 Medical Imaging Meets NeurIPS Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/19", "categories": "cs.CV cs.LG q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a solution for learning disease signatures from weakly, yet easily\nobtainable, annotated volumetric medical imaging data by analyzing 3D volumes\nas a sequence of 2D images. We demonstrate the performance of our solution in\nthe detection of emphysema in lung cancer screening low-dose CT images. Our\napproach utilizes convolutional long short-term memory (LSTM) to \"scan\"\nsequentially through an imaging volume for the presence of disease in a portion\nof scanned region. This framework allowed effective learning given only\nvolumetric images and binary disease labels, thus enabling training from a\nlarge dataset of 6,631 un-annotated image volumes from 4,486 patients. When\nevaluated in a testing set of 2,163 volumes from 2,163 patients, our model\ndistinguished emphysema with area under the receiver operating characteristic\ncurve (AUC) of .83. This approach was found to outperform 2D convolutional\nneural networks (CNN) implemented with various multiple-instance learning\nschemes (AUC=0.69-0.76) and a 3D CNN (AUC=.77).\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 21:32:28 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Braman", "Nathaniel", ""], ["Beymer", "David", ""], ["Dehghan", "Ehsan", ""]]}, {"id": "1812.01097", "submitter": "Sebastian Caldas", "authors": "Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub\n  Kone\\v{c}n\\'y, H. Brendan McMahan, Virginia Smith and Ameet Talwalkar", "title": "LEAF: A Benchmark for Federated Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern federated networks, such as those comprised of wearable devices,\nmobile phones, or autonomous vehicles, generate massive amounts of data each\nday. This wealth of data can help to learn models that can improve the user\nexperience on each device. However, the scale and heterogeneity of federated\ndata presents new challenges in research areas such as federated learning,\nmeta-learning, and multi-task learning. As the machine learning community\nbegins to tackle these challenges, we are at a critical time to ensure that\ndevelopments made in these areas are grounded with realistic benchmarks. To\nthis end, we propose LEAF, a modular benchmarking framework for learning in\nfederated settings. LEAF includes a suite of open-source federated datasets, a\nrigorous evaluation framework, and a set of reference implementations, all\ngeared towards capturing the obstacles and intricacies of practical federated\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 21:59:41 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:34:03 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 20:02:37 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Caldas", "Sebastian", ""], ["Duddu", "Sai Meher Karthik", ""], ["Wu", "Peter", ""], ["Li", "Tian", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["McMahan", "H. Brendan", ""], ["Smith", "Virginia", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1812.01101", "submitter": "Yu Zeng", "authors": "Yu Zeng, Kebei Jiang, Jie Chen", "title": "Automatic Seismic Salt Interpretation with Deep Convolutional Neural\n  Networks", "comments": "11 pages, 7 figures", "journal-ref": "ICISDM 2019 - The 3rd International Conference on Information\n  System and Data Mining", "doi": "10.1145/3325917.3325926", "report-no": null, "categories": "physics.geo-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most crucial tasks in seismic reflection imaging is to identify\nthe salt bodies with high precision. Traditionally, this is accomplished by\nvisually picking the salt/sediment boundaries, which requires a great amount of\nmanual work and may introduce systematic bias. With recent progress of deep\nlearning algorithm and growing computational power, a great deal of efforts\nhave been made to replace human effort with machine power in salt body\ninterpretation. Currently, the method of Convolutional neural networks (CNN) is\nrevolutionizing the computer vision field and has been a hot topic in the image\nanalysis. In this paper, the benefits of CNN-based classification are\ndemonstrated by using a state-of-art network structure U-Net, along with the\nresidual learning framework ResNet, to delineate salt body with high precision.\nNetwork adjustments, including the Exponential Linear Units (ELU) activation\nfunction, the Lov\\'{a}sz-Softmax loss function, and stratified $K$-fold\ncross-validation, have been deployed to further improve the prediction\naccuracy. The preliminary result using SEG Advanced Modeling (SEAM) data shows\ngood agreement between the predicted salt body and manually interpreted salt\nbody, especially in areas with weak reflections. This indicates the great\npotential of applying CNN for salt-related interpretations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 05:01:13 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Zeng", "Yu", ""], ["Jiang", "Kebei", ""], ["Chen", "Jie", ""]]}, {"id": "1812.01102", "submitter": "Sayedmasoud Hashemi Amroabadi", "authors": "Greg Kirczenow, Masoud Hashemi, Ali Fathi and Matt Davison", "title": "Machine Learning for Yield Curve Feature Extraction: Application to\n  Illiquid Corporate Bonds", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.01731", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an application of machine learning in extracting features\nfrom the historical market implied corporate bond yields. We consider an\nexample of a hypothetical illiquid fixed income market. After choosing a\nsurrogate liquid market, we apply the Denoising Autoencoder (DAE) algorithm to\nlearn the features of the missing yield parameters from the historical data of\nthe instruments traded in the chosen liquid market. The DAE algorithm is then\nchallenged by two \"point-in-time\" inpainting algorithms taken from the image\nprocessing and computer vision domain. It is observed that, when tested on\nunobserved rate surfaces, the DAE algorithm exhibits superior performance\nthanks to the features it has learned from the historical shapes of yield\ncurves.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 00:56:42 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Kirczenow", "Greg", ""], ["Hashemi", "Masoud", ""], ["Fathi", "Ali", ""], ["Davison", "Matt", ""]]}, {"id": "1812.01105", "submitter": "Hsiang Hsu", "authors": "Hsiang Hsu, Flavio P. Calmon, Jos\\'e C\\^andido Silveira Santos Filho,\n  Andre P. Calmon, Salman Salamatian", "title": "Correspondence Analysis of Government Expenditure Patterns", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze expenditure patterns of discretionary funds by Brazilian congress\nmembers. This analysis is based on a large dataset containing over $7$ million\nexpenses made publicly available by the Brazilian government. This dataset has,\nup to now, remained widely untouched by machine learning methods. Our main\ncontributions are two-fold: (i) we provide a novel dataset benchmark for\nmachine learning-based efforts for government transparency to the broader\nresearch community, and (ii) introduce a neural network-based approach for\nanalyzing and visualizing outlying expense patterns. Our hope is that the\napproach presented here can inspire new machine learning methodologies for\ngovernment transparency applicable to other developing nations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 19:30:08 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hsu", "Hsiang", ""], ["Calmon", "Flavio P.", ""], ["Filho", "Jos\u00e9 C\u00e2ndido Silveira Santos", ""], ["Calmon", "Andre P.", ""], ["Salamatian", "Salman", ""]]}, {"id": "1812.01106", "submitter": "Jo\\~ao Caldeira", "authors": "Jo\\~ao Caldeira, Alex Fout, Aniket Kesari, Raesetje Sefala, Joseph\n  Walsh, Katy Dupre, Muhammad Rizal Khaefi, Setiaji, George Hodge, Zakiya\n  Aryana Pramestri, Muhammad Adib Imtiyazi", "title": "Improving Traffic Safety Through Video Analysis in Jakarta, Indonesia", "comments": "6 pages; LaTeX; Presented at NeurIPS 2018 Workshop on Machine\n  Learning for the Developing World; Presented at NeurIPS 2018 Workshop on AI\n  for Social Good", "journal-ref": "Proceedings of the 2019 Intelligent Systems Conference\n  (IntelliSys) Volume 2, 642-649", "doi": "10.1007/978-3-030-29513-4_48", "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project presents the results of a partnership between the Data Science\nfor Social Good fellowship, Jakarta Smart City and Pulse Lab Jakarta to create\na video analysis pipeline for the purpose of improving traffic safety in\nJakarta. The pipeline transforms raw traffic video footage into databases that\nare ready to be used for traffic analysis. By analyzing these patterns, the\ncity of Jakarta will better understand how human behavior and built\ninfrastructure contribute to traffic challenges and safety risks. The results\nof this work should also be broadly applicable to smart city initiatives around\nthe globe as they improve urban planning and sustainability through data\nscience approaches.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 18:51:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Caldeira", "Jo\u00e3o", ""], ["Fout", "Alex", ""], ["Kesari", "Aniket", ""], ["Sefala", "Raesetje", ""], ["Walsh", "Joseph", ""], ["Dupre", "Katy", ""], ["Khaefi", "Muhammad Rizal", ""], ["Setiaji", "", ""], ["Hodge", "George", ""], ["Pramestri", "Zakiya Aryana", ""], ["Imtiyazi", "Muhammad Adib", ""]]}, {"id": "1812.01114", "submitter": "Kevin Schawinski", "authors": "Kevin Schawinski, M. Dennis Turp, Ce Zhang", "title": "Exploring galaxy evolution with generative models", "comments": "Published in A&A. For code and further details, see\n  http://space.ml/proj/explore", "journal-ref": null, "doi": "10.1051/0004-6361/201833800", "report-no": null, "categories": "astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context. Generative models open up the possibility to interrogate scientific\ndata in a more data-driven way. Aims: We propose a method that uses generative\nmodels to explore hypotheses in astrophysics and other areas. We use a neural\nnetwork to show how we can independently manipulate physical attributes by\nencoding objects in latent space. Methods: By learning a latent space\nrepresentation of the data, we can use this network to forward model and\nexplore hypotheses in a data-driven way. We train a neural network to generate\nartificial data to test hypotheses for the underlying physical processes.\nResults: We demonstrate this process using a well-studied process in\nastrophysics, the quenching of star formation in galaxies as they move from\nlow-to high-density environments. This approach can help explore astrophysical\nand other phenomena in a way that is different from current methods based on\nsimulations and observations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 22:28:06 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 07:18:14 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Schawinski", "Kevin", ""], ["Turp", "M. Dennis", ""], ["Zhang", "Ce", ""]]}, {"id": "1812.01115", "submitter": "Cristian Rusu", "authors": "Cristian Rusu", "title": "On learning with shift-invariant structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe new results and algorithms for two different, but related,\nproblems which deal with circulant matrices: learning shift-invariant\ncomponents from training data and calculating the shift (or alignment) between\ntwo given signals. In the first instance, we deal with the shift-invariant\ndictionary learning problem while the latter bears the name of (compressive)\nshift retrieval. We formulate these problems using circulant and convolutional\nmatrices (including unions of such matrices), define optimization problems that\ndescribe our goals and propose efficient ways to solve them. Based on these\nfindings, we also show how to learn a wavelet-like dictionary from training\ndata. We connect our work with various previous results from the literature and\nwe show the effectiveness of our proposed algorithms using synthetic, ECG\nsignals and images.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 22:31:47 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 21:00:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Rusu", "Cristian", ""]]}, {"id": "1812.01137", "submitter": "Dhruva Kartik", "authors": "Dhruva Kartik, Ashutosh Nayyar, Urbashi Mitra", "title": "Sequential Experiment Design for Hypothesis Verification", "comments": "52nd Annual Asilomar Conference on Signals, Systems, and Computers.\n  arXiv admin note: text overlap with arXiv:1810.04859", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing is an important problem with applications in target\nlocalization, clinical trials etc. Many active hypothesis testing strategies\noperate in two phases: an exploration phase and a verification phase. In the\nexploration phase, selection of experiments is such that a moderate level of\nconfidence on the true hypothesis is achieved. Subsequent experiment design\naims at improving the confidence level on this hypothesis to the desired level.\nIn this paper, the focus is on the verification phase. A confidence measure is\ndefined and active hypothesis testing is formulated as a confidence\nmaximization problem in an infinite-horizon average-reward Partially Observable\nMarkov Decision Process (POMDP) setting. The problem of maximizing confidence\nconditioned on a particular hypothesis is referred to as the hypothesis\nverification problem. The relationship between hypothesis testing and\nverification problems is established. The verification problem can be\nformulated as a Markov Decision Process (MDP). Optimal solutions for the\nverification MDP are characterized and a simple heuristic adaptive strategy for\nverification is proposed based on a zero-sum game interpretation of\nKullback-Leibler divergences. It is demonstrated through numerical experiments\nthat the heuristic performs better in some scenarios compared to existing\nmethods in literature.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 00:09:17 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Kartik", "Dhruva", ""], ["Nayyar", "Ashutosh", ""], ["Mitra", "Urbashi", ""]]}, {"id": "1812.01161", "submitter": "Aditya Ramesh", "authors": "Aditya Ramesh, Youngduck Choi, Yann LeCun", "title": "A Spectral Regularizer for Unsupervised Disentanglement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A generative model with a disentangled representation allows for independent\ncontrol over different aspects of the output. Learning disentangled\nrepresentations has been a recent topic of great interest, but it remains\npoorly understood. We show that even for GANs that do not possess disentangled\nrepresentations, one can find curved trajectories in latent space over which\nlocal disentanglement occurs. These trajectories are found by iteratively\nfollowing the leading right-singular vectors of the Jacobian of the generator\nwith respect to its input. Based on this insight, we describe an efficient\nregularizer that aligns these vectors with the coordinate axes, and show that\nit can be used to induce disentangled representations in GANs, in a completely\nunsupervised manner.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 01:35:40 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 02:23:54 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Ramesh", "Aditya", ""], ["Choi", "Youngduck", ""], ["LeCun", "Yann", ""]]}, {"id": "1812.01164", "submitter": "Sourya Dey", "authors": "Sourya Dey, Kuan-Wen Huang, Peter A. Beerel, Keith M. Chugg", "title": "Pre-Defined Sparse Neural Networks with Hardware Acceleration", "comments": "This work has been submitted to the IEEE Journal on Emerging and\n  Selected Topics in Circuits and Systems for possible publication. Copyright\n  may be transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": "10.1109/JETCAS.2019.2910864", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have proven to be extremely powerful tools for modern\nartificial intelligence applications, but computational and storage complexity\nremain limiting factors. This paper presents two compatible contributions\ntowards reducing the time, energy, computational, and storage complexities\nassociated with multilayer perceptrons. Pre-defined sparsity is proposed to\nreduce the complexity during both training and inference, regardless of the\nimplementation platform. Our results show that storage and computational\ncomplexity can be reduced by factors greater than 5X without significant\nperformance loss. The second contribution is an architecture for hardware\nacceleration that is compatible with pre-defined sparsity. This architecture\nsupports both training and inference modes and is flexible in the sense that it\nis not tied to a specific number of neurons. For example, this flexibility\nimplies that various sized neural networks can be supported on various sized\nField Programmable Gate Array (FPGA)s.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 02:10:37 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Dey", "Sourya", ""], ["Huang", "Kuan-Wen", ""], ["Beerel", "Peter A.", ""], ["Chugg", "Keith M.", ""]]}, {"id": "1812.01181", "submitter": "Rui Luo", "authors": "Rui Luo, Qiang Zhang, and Yuanyuan Liu", "title": "Parallel-tempered Stochastic Gradient Hamiltonian Monte Carlo for\n  Approximate Multimodal Posterior Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new sampler that integrates the protocol of parallel tempering\nwith the Nos\\'e-Hoover (NH) dynamics. The proposed method can efficiently draw\nrepresentative samples from complex posterior distributions with multiple\nisolated modes in the presence of noise arising from stochastic gradient. It\npotentially facilitates deep Bayesian learning on large datasets where complex\nmultimodal posteriors and mini-batch gradient are encountered.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 02:58:30 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 18:35:26 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Luo", "Rui", ""], ["Zhang", "Qiang", ""], ["Liu", "Yuanyuan", ""]]}, {"id": "1812.01186", "submitter": "Yang Wu", "authors": "Xu Cai, Yang Wu, Guanbin Li, Ziliang Chen, Liang Lin", "title": "FRAME Revisited: An Interpretation View Based on Particle Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  FRAME (Filters, Random fields, And Maximum Entropy) is an energy-based\ndescriptive model that synthesizes visual realism by capturing mutual patterns\nfrom structural input signals. The maximum likelihood estimation (MLE) is\napplied by default, yet conventionally causes the unstable training energy that\nwrecks the generated structures, which remains unexplained. In this paper, we\nprovide a new theoretical insight to analyze FRAME, from a perspective of\nparticle physics ascribing the weird phenomenon to KL-vanishing issue. In order\nto stabilize the energy dissipation, we propose an alternative Wasserstein\ndistance in discrete time based on the conclusion that the\nJordan-Kinderlehrer-Otto (JKO) discrete flow approximates KL discrete flow when\nthe time step size tends to 0. Besides, this metric can still maintain the\nmodel's statistical consistency. Quantitative and qualitative experiments have\nbeen respectively conducted on several widely used datasets. The empirical\nstudies have evidenced the effectiveness and superiority of our method.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 03:01:14 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 03:17:41 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 02:01:17 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2019 03:08:48 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Cai", "Xu", ""], ["Wu", "Yang", ""], ["Li", "Guanbin", ""], ["Chen", "Ziliang", ""], ["Lin", "Liang", ""]]}, {"id": "1812.01190", "submitter": "Wenjin Wu", "authors": "Wenjin Wu, Guojun Liu, Hui Ye, Chenshuang Zhang, Tianshu Wu, Daorui\n  Xiao, Wei Lin, Xiaoyu Zhu", "title": "EENMF: An End-to-End Neural Matching Framework for E-Commerce Sponsored\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  E-commerce sponsored search contributes an important part of revenue for the\ne-commerce company. In consideration of effectiveness and efficiency, a\nlarge-scale sponsored search system commonly adopts a multi-stage architecture.\nWe name these stages as ad retrieval, ad pre-ranking and ad ranking. Ad\nretrieval and ad pre-ranking are collectively referred to as ad matching in\nthis paper. We propose an end-to-end neural matching framework (EENMF) to model\ntwo tasks---vector-based ad retrieval and neural networks based ad pre-ranking.\nUnder the deep matching framework, vector-based ad retrieval harnesses user\nrecent behavior sequence to retrieve relevant ad candidates without the\nconstraint of keyword bidding. Simultaneously, the deep model is employed to\nperform the global pre-ranking of ad candidates from multiple retrieval paths\neffectively and efficiently. Besides, the proposed model tries to optimize the\npointwise cross-entropy loss which is consistent with the objective of predict\nmodels in the ranking stage. We conduct extensive evaluation to validate the\nperformance of the proposed framework. In the real traffic of a large-scale\ne-commerce sponsored search, the proposed approach significantly outperforms\nthe baseline.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 03:10:18 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 05:53:05 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 06:18:19 GMT"}, {"version": "v4", "created": "Sun, 9 Dec 2018 06:00:41 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Wu", "Wenjin", ""], ["Liu", "Guojun", ""], ["Ye", "Hui", ""], ["Zhang", "Chenshuang", ""], ["Wu", "Tianshu", ""], ["Xiao", "Daorui", ""], ["Lin", "Wei", ""], ["Zhu", "Xiaoyu", ""]]}, {"id": "1812.01194", "submitter": "Tatsunori Hashimoto", "authors": "Tatsunori B. Hashimoto and Kelvin Guu and Yonatan Oren and Percy Liang", "title": "A Retrieve-and-Edit Framework for Predicting Structured Outputs", "comments": "To appear, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the task of generating complex outputs such as source code, editing\nexisting outputs can be easier than generating complex outputs from scratch.\nWith this motivation, we propose an approach that first retrieves a training\nexample based on the input (e.g., natural language description) and then edits\nit to the desired output (e.g., code). Our contribution is a computationally\nefficient method for learning a retrieval model that embeds the input in a\ntask-dependent way without relying on a hand-crafted metric or incurring the\nexpense of jointly training the retriever with the editor. Our\nretrieve-and-edit framework can be applied on top of any base model. We show\nthat on a new autocomplete task for GitHub Python code and the Hearthstone\ncards benchmark, retrieve-and-edit significantly boosts the performance of a\nvanilla sequence-to-sequence model on both tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 03:15:43 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hashimoto", "Tatsunori B.", ""], ["Guu", "Kelvin", ""], ["Oren", "Yonatan", ""], ["Liang", "Percy", ""]]}, {"id": "1812.01198", "submitter": "Isay Katsman", "authors": "Horace He, Aaron Lou, Qingxuan Jiang, Isay Katsman, Serge Belongie,\n  Ser-Nam Lim", "title": "Adversarial Example Decomposition", "comments": "ICML 2019 Workshop, Security and Privacy of Machine Learning,\n  camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research has shown that widely used deep neural networks are vulnerable to\ncarefully crafted adversarial perturbations. Moreover, these adversarial\nperturbations often transfer across models. We hypothesize that adversarial\nweakness is composed of three sources of bias: architecture, dataset, and\nrandom initialization. We show that one can decompose adversarial examples into\nan architecture-dependent component, data-dependent component, and\nnoise-dependent component and that these components behave intuitively. For\nexample, noise-dependent components transfer poorly to all other models, while\narchitecture-dependent components transfer better to retrained models with the\nsame architecture. In addition, we demonstrate that these components can be\nrecombined to improve transferability without sacrificing efficacy on the\noriginal model.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 03:25:50 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 09:24:32 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["He", "Horace", ""], ["Lou", "Aaron", ""], ["Jiang", "Qingxuan", ""], ["Katsman", "Isay", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "1812.01199", "submitter": "Sina Dabiri", "authors": "Sina Dabiri, Kevin Heaslip", "title": "Twitter-based traffic information system based on vector representations\n  for words", "comments": "17 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers have shown an increased interest in harnessing Twitter\ndata for dynamic monitoring of traffic conditions. Bag-of-words representation\nis a common method in literature for tweet modeling and retrieving traffic\ninformation, yet it suffers from the curse of dimensionality and sparsity. To\naddress these issues, our specific objective is to propose a simple and robust\nframework on the top of word embedding for distinguishing traffic-related\ntweets against non-traffic-related ones. In our proposed model, a tweet is\nclassified as traffic-related if semantic similarity between its words and a\nsmall set of traffic keywords exceeds a threshold value. Semantic similarity\nbetween words is captured by means of word-embedding models, which is an\nunsupervised learning tool. The proposed model is as simple as having only one\ntrainable parameter. The model takes advantage of outstanding merits, which are\ndemonstrated through several evaluation steps. The state-of-the-art test\naccuracy for our proposed model is 95.9%.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 03:28:28 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Dabiri", "Sina", ""], ["Heaslip", "Kevin", ""]]}, {"id": "1812.01214", "submitter": "Sascha Saralajew", "authors": "Sascha Saralajew and Lars Holdijk and Maike Rees and Thomas Villmann", "title": "Prototype-based Neural Network Layers: Incorporating Vector Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks currently dominate the machine learning community and they do\nso for good reasons. Their accuracy on complex tasks such as image\nclassification is unrivaled at the moment and with recent improvements they are\nreasonably easy to train. Nevertheless, neural networks are lacking robustness\nand interpretability. Prototype-based vector quantization methods on the other\nhand are known for being robust and interpretable. For this reason, we propose\ntechniques and strategies to merge both approaches. This contribution will\nparticularly highlight the similarities between them and outline how to\nconstruct a prototype-based classification layer for multilayer networks.\nAdditionally, we provide an alternative, prototype-based, approach to the\nclassical convolution operation. Numerical results are not part of this report,\ninstead the focus lays on establishing a strong theoretical framework. By\npublishing our framework and the respective theoretical considerations and\njustifications before finalizing our numerical experiments we hope to\njump-start the incorporation of prototype-based learning in neural networks and\nvice versa.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 04:33:12 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 11:07:39 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Saralajew", "Sascha", ""], ["Holdijk", "Lars", ""], ["Rees", "Maike", ""], ["Villmann", "Thomas", ""]]}, {"id": "1812.01217", "submitter": "Masataro Asai", "authors": "Masataro Asai", "title": "Set Cross Entropy: Likelihood-based Permutation Invariant Loss Function\n  for Probability Distributions", "comments": "The source code will be available at\n  https://github.com/guicho271828/perminv . (comment for the revision: the\n  result table was not correctly updated)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a permutation-invariant loss function designed for the neural\nnetworks reconstructing a set of elements without considering the order within\nits vector representation. Unlike popular approaches for encoding and decoding\na set, our work does not rely on a carefully engineered network topology nor by\nany additional sequential algorithm. The proposed method, Set Cross Entropy,\nhas a natural information-theoretic interpretation and is related to the\nmetrics defined for sets. We evaluate the proposed approach in two object\nreconstruction tasks and a rule learning task.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 04:55:15 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 10:29:53 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Asai", "Masataro", ""]]}, {"id": "1812.01222", "submitter": "Julian B\\\"uchel", "authors": "Julian B\\\"uchel and Okan Ersoy", "title": "Ladder Networks for Semi-Supervised Hyperspectral Image Classification", "comments": "Technical Report, 5 pages, 8 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.33254.27208", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We used the Ladder Network [Rasmus et al. (2015)] to perform Hyperspectral\nImage Classification in a semi-supervised setting. The Ladder Network\ndistinguishes itself from other semi-supervised methods by jointly optimizing a\nsupervised and unsupervised cost. In many settings this has proven to be more\nsuccessful than other semi-supervised techniques, such as pretraining using\nunlabeled data. We furthermore show that the convolutional Ladder Network\noutperforms most of the current techniques used in hyperspectral image\nclassification and achieves new state-of-the-art performance on the Pavia\nUniversity dataset given only 5 labeled data points per class.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 05:24:47 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["B\u00fcchel", "Julian", ""], ["Ersoy", "Okan", ""]]}, {"id": "1812.01226", "submitter": "Yi Sun", "authors": "Yi Sun, Alfredo Cuesta-Infante, Kalyan Veeramachaneni", "title": "Learning Vine Copula Models For Synthetic Data Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vine copula model is a flexible high-dimensional dependence model which\nuses only bivariate building blocks. However, the number of possible\nconfigurations of a vine copula grows exponentially as the number of variables\nincreases, making model selection a major challenge in development. In this\nwork, we formulate a vine structure learning problem with both vector and\nreinforcement learning representation. We use neural network to find the\nembeddings for the best possible vine model and generate a structure.\nThroughout experiments on synthetic and real-world datasets, we show that our\nproposed approach fits the data better in terms of log-likelihood. Moreover, we\ndemonstrate that the model is able to generate high-quality samples in a\nvariety of applications, making it a good candidate for synthetic data\ngeneration.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 05:34:26 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Sun", "Yi", ""], ["Cuesta-Infante", "Alfredo", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1812.01278", "submitter": "Dorien Herremans", "authors": "Kin Wah Edward Lin, Balamurali B.T., Enyan Koh, Simon Lui, Dorien\n  Herremans", "title": "Singing Voice Separation Using a Deep Convolutional Neural Network\n  Trained by Ideal Binary Mask and Cross Entropy", "comments": "In Press, Neural Computing and Applications, Springer. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating a singing voice from its music accompaniment remains an important\nchallenge in the field of music information retrieval. We present a unique\nneural network approach inspired by a technique that has revolutionized the\nfield of vision: pixel-wise image classification, which we combine with cross\nentropy loss and pretraining of the CNN as an autoencoder on singing voice\nspectrograms. The pixel-wise classification technique directly estimates the\nsound source label for each time-frequency (T-F) bin in our spectrogram image,\nthus eliminating common pre- and postprocessing tasks. The proposed network is\ntrained by using the Ideal Binary Mask (IBM) as the target output label. The\nIBM identifies the dominant sound source in each T-F bin of the magnitude\nspectrogram of a mixture signal, by considering each T-F bin as a pixel with a\nmulti-label (for each sound source). Cross entropy is used as the training\nobjective, so as to minimize the average probability error between the target\nand predicted label for each pixel. By treating the singing voice separation\nproblem as a pixel-wise classification task, we additionally eliminate one of\nthe commonly used, yet not easy to comprehend, postprocessing steps: the Wiener\nfilter postprocessing.\n  The proposed CNN outperforms the first runner up in the Music Information\nRetrieval Evaluation eXchange (MIREX) 2016 and the winner of MIREX 2014 with a\ngain of 2.2702 ~ 5.9563 dB global normalized source to distortion ratio (GNSDR)\nwhen applied to the iKala dataset. An experiment with the DSD100 dataset on the\nfull-tracks song evaluation task also shows that our model is able to compete\nwith cutting-edge singing voice separation systems which use multi-channel\nmodeling, data augmentation, and model blending.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 08:47:41 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Lin", "Kin Wah Edward", ""], ["T.", "Balamurali B.", ""], ["Koh", "Enyan", ""], ["Lui", "Simon", ""], ["Herremans", "Dorien", ""]]}, {"id": "1812.01339", "submitter": "Christian Knoll", "authors": "Christian Knoll and Adrian Weller and Franz Pernkopf", "title": "Self-Guided Belief Propagation -- A Homotopy Continuation Method", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief propagation (BP) is a popular method for performing probabilistic\ninference on graphical models. In this work, we enhance BP and propose\nself-guided belief propagation (SBP) that incorporates the pairwise potentials\nonly gradually. This homotopy continuation method converges to a unique\nsolution and increases the accuracy without increasing the computational\nburden. We provide a formal analysis to demonstrate that SBP finds the global\noptimum of the Bethe approximation for attractive models where all variables\nfavor the same state. Moreover, we apply SBP to various graphs with random\npotentials and empirically show that: (i) SBP is superior in terms of accuracy\nwhenever BP converges, and (ii) SBP obtains a unique, stable, and accurate\nsolution whenever BP does not converge.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 11:12:45 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 11:14:57 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Knoll", "Christian", ""], ["Weller", "Adrian", ""], ["Pernkopf", "Franz", ""]]}, {"id": "1812.01353", "submitter": "Chenglei Niu", "authors": "Chenglei Niu, Guojing Zhong, Ying Liu, Yandong Zhang, Yongsheng Sun,\n  Ailong He, Zhaoji Chen", "title": "Structured Semantic Model supported Deep Neural Network for\n  Click-Through Rate Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of online advertising and recommendation systems,\nclick-through rate prediction is expected to play an increasingly important\nrole.Recently many DNN-based models which follow a similar Embedding&MLP\nparadigm have been proposed, and have achieved good result in image/voice and\nnlp fields. In these methods the Wide&Deep model announced by Google plays a\nkey role.Most models first map large scale sparse input features into\nlow-dimensional vectors which are transformed to fixed-length vectors, then\nconcatenated together before being fed into a multilayer perceptron (MLP) to\nlearn non-linear relations among input features. The number of trainable\nvariables normally grow dramatically the number of feature fields and the\nembedding dimension grow. It is a big challenge to get state-of-the-art result\nthrough training deep neural network and embedding together, which falls into\nlocal optimal or overfitting easily. In this paper, we propose an Structured\nSemantic Model (SSM) to tackles this challenge by designing a orthogonal base\nconvolution and pooling model which adaptively learn the multi-scale base\nsemantic representation between features supervised by the click label.The\noutput of SSM are then used in the Wide&Deep for CTR prediction.Experiments on\ntwo public datasets as well as real Weibo production dataset with over 1\nbillion samples have demonstrated the effectiveness of our proposed approach\nwith superior performance comparing to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 12:03:52 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 08:32:41 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 03:35:09 GMT"}, {"version": "v4", "created": "Fri, 1 Mar 2019 08:18:38 GMT"}, {"version": "v5", "created": "Tue, 30 Apr 2019 03:14:33 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Niu", "Chenglei", ""], ["Zhong", "Guojing", ""], ["Liu", "Ying", ""], ["Zhang", "Yandong", ""], ["Sun", "Yongsheng", ""], ["He", "Ailong", ""], ["Chen", "Zhaoji", ""]]}, {"id": "1812.01388", "submitter": "Jan Brabec", "authors": "Jan Brabec, Lukas Machlica", "title": "Bad practices in evaluation methodology relevant to class-imbalanced\n  problems", "comments": "Accepted to Critiquing and Correcting Trends in Machine Learning\n  workshop at NeurIPS 2018 (https://ml-critique-correct.github.io/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For research to go in the right direction, it is essential to be able to\ncompare and quantify performance of different algorithms focused on the same\nproblem. Choosing a suitable evaluation metric requires deep understanding of\nthe pursued task along with all of its characteristics. We argue that in the\ncase of applied machine learning, proper evaluation metric is the basic\nbuilding block that should be in the spotlight and put under thorough\nexamination. Here, we address tasks with class imbalance, in which the class of\ninterest is the one with much lower number of samples. We encountered\nnon-insignificant amount of recent papers, in which improper evaluation methods\nare used, borrowed mainly from the field of balanced problems. Such bad\npractices may heavily bias the results in favour of inappropriate algorithms\nand give false expectations of the state of the field.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 13:01:38 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Brabec", "Jan", ""], ["Machlica", "Lukas", ""]]}, {"id": "1812.01389", "submitter": "Roman Rolon ReR", "authors": "R.E. Rol\\'on, L.E. Di Persia, R.D. Spies and H.L. Rufiner", "title": "A multi-class structured dictionary learning method using discriminant\n  atom selection", "comments": "18 pages, 8 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, traditional dictionary learning methods have been\nsuccessfully applied to various pattern classification tasks. Although these\nmethods produce sparse representations of signals which are robust against\ndistortions and missing data, such representations quite often turn out to be\nunsuitable if the final objective is signal classification. In order to\novercome or at least to attenuate such a weakness, several new methods which\nincorporate discriminative information into sparse-inducing models have emerged\nin recent years. In particular, methods for discriminative dictionary learning\nhave shown to be more accurate (in terms of signal classification) than the\ntraditional ones, which are only focused on minimizing the total representation\nerror. In this work, we present both a novel multi-class discriminative measure\nand an innovative dictionary learning method. For a given dictionary, this new\nmeasure, which takes into account not only when a particular atom is used for\nrepresenting signals coming from a certain class and the magnitude of its\ncorresponding representation coefficient, but also the effect that such an atom\nhas in the total representation error, is capable of efficiently quantifying\nthe degree of discriminability of each one of the atoms. On the other hand, the\nnew dictionary construction method yields dictionaries which are highly\nsuitable for multi-class classification tasks. Our method was tested with a\nwidely used database for handwritten digit recognition and compared with three\nstate-of-the-art classification methods. The results show that our method\nsignificantly outperforms the other three achieving good recognition rates and\nadditionally, reducing the computational cost of the classifier.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 13:02:40 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Rol\u00f3n", "R. E.", ""], ["Di Persia", "L. E.", ""], ["Spies", "R. D.", ""], ["Rufiner", "H. L.", ""]]}, {"id": "1812.01410", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "Compressive Classification (Machine Learning without learning)", "comments": "in Proceedings of iTWIST'18, Paper-ID: 8, Marseille, France,\n  November, 21-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive learning is a framework where (so far unsupervised) learning\ntasks use not the entire dataset but a compressed summary (sketch) of it. We\npropose a compressive learning classification method, and a novel sketch\nfunction for images.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 13:50:11 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "1812.01429", "submitter": "Leonid Kozinkin", "authors": "Mikhail Karchevskiy, Insaf Ashrapov and Leonid Kozinkin", "title": "Automatic salt deposits segmentation: A deep learning approach", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important applications of seismic reflection is the\nhydrocarbon exploration which is closely related to salt deposits analysis.\nThis problem is very important even nowadays due to it's non-linear nature.\nTaking into account the recent developments in deep learning networks TGS-NOPEC\nGeophysical Company hosted the Kaggle competition for salt deposits\nsegmentation problem in seismic image data. In this paper, we demonstrate the\ngreat performance of several novel deep learning techniques merged into a\nsingle neural network which achieved the 27th place (top 1%) in the mentioned\ncompetition. Using a U-Net with ResNeXt-50 encoder pre-trained on ImageNet as\nour base architecture, we implemented Spatial-Channel Squeeze & Excitation,\nLovasz loss, CoordConv and Hypercolumn methods. The source code for our\nsolution is made publicly available at\nhttps://github.com/K-Mike/Automatic-salt-deposits-segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 11:39:30 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Karchevskiy", "Mikhail", ""], ["Ashrapov", "Insaf", ""], ["Kozinkin", "Leonid", ""]]}, {"id": "1812.01478", "submitter": "Duc Nguyen", "authors": "Duc Minh Nguyen and Evaggelia Tsiligianni and Nikos Deligiannis", "title": "Matrix Factorization via Deep Learning", "comments": "in Proceedings of iTWIST'18, Paper-ID: 27, Marseille, France,\n  November, 21-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is one of the key problems in signal processing and machine\nlearning. In recent years, deep-learning-based models have achieved\nstate-of-the-art results in matrix completion. Nevertheless, they suffer from\ntwo drawbacks: (i) they can not be extended easily to rows or columns unseen\nduring training; and (ii) their results are often degraded in case discrete\npredictions are required. This paper addresses these two drawbacks by\npresenting a deep matrix factorization model and a generic method to allow\njoint training of the factorization model and the discretization operator.\nExperiments on a real movie rating dataset show the efficacy of the proposed\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:15:23 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1812.01483", "submitter": "Thomas Kipf", "authors": "Thomas Kipf, Yujia Li, Hanjun Dai, Vinicius Zambaldi, Alvaro\n  Sanchez-Gonzalez, Edward Grefenstette, Pushmeet Kohli, Peter Battaglia", "title": "CompILE: Compositional Imitation Learning and Execution", "comments": "ICML (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Compositional Imitation Learning and Execution (CompILE): a\nframework for learning reusable, variable-length segments of\nhierarchically-structured behavior from demonstration data. CompILE uses a\nnovel unsupervised, fully-differentiable sequence segmentation module to learn\nlatent encodings of sequential data that can be re-composed and executed to\nperform new tasks. Once trained, our model generalizes to sequences of longer\nlength and from environment instances not seen during training. We evaluate\nCompILE in a challenging 2D multi-task environment and a continuous control\ntask, and show that it can find correct task boundaries and event encodings in\nan unsupervised manner. Latent codes and associated behavior policies\ndiscovered by CompILE can be used by a hierarchical agent, where the high-level\npolicy selects actions in the latent code space, and the low-level,\ntask-specific policies are simply the learned decoders. We found that our\nCompILE-based agent could learn given only sparse rewards, where agents without\ntask-specific policies struggle.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:23:50 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 12:04:13 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Kipf", "Thomas", ""], ["Li", "Yujia", ""], ["Dai", "Hanjun", ""], ["Zambaldi", "Vinicius", ""], ["Sanchez-Gonzalez", "Alvaro", ""], ["Grefenstette", "Edward", ""], ["Kohli", "Pushmeet", ""], ["Battaglia", "Peter", ""]]}, {"id": "1812.01484", "submitter": "Brett Beaulieu-Jones", "authors": "Brett K. Beaulieu-Jones, William Yuan, Samuel G. Finlayson, Zhiwei\n  Steven Wu", "title": "Privacy-Preserving Distributed Deep Learning for Clinical Data", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning with medical data often requires larger samples sizes than are\navailable at single providers. While data sharing among institutions is\ndesirable to train more accurate and sophisticated models, it can lead to\nsevere privacy concerns due the sensitive nature of the data. This problem has\nmotivated a number of studies on distributed training of neural networks that\ndo not require direct sharing of the training data. However, simple distributed\ntraining does not offer provable privacy guarantees to satisfy technical safe\nstandards and may reveal information about the underlying patients. We present\na method to train neural networks for clinical data in a distributed fashion\nunder differential privacy. We demonstrate these methods on two datasets that\ninclude information from multiple independent sites, the eICU collaborative\nResearch Database and The Cancer Genome Atlas.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:25:29 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Beaulieu-Jones", "Brett K.", ""], ["Yuan", "William", ""], ["Finlayson", "Samuel G.", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1812.01487", "submitter": "Saket Tiwari", "authors": "Saket Tiwari, M. Prannoy", "title": "Hyperbolic Embeddings for Learning Options in Hierarchical Reinforcement\n  Learning", "comments": "We are redoing some of the experiments to obtain better results and\n  to change the approach a bit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning deals with the problem of breaking down\nlarge tasks into meaningful sub-tasks. Autonomous discovery of these sub-tasks\nhas remained a challenging problem. We propose a novel method of learning\nsub-tasks by combining paradigms of routing in computer networks and graph\nbased skill discovery within the options framework to define meaningful\nsub-goals. We apply the recent advancements of learning embeddings using\nRiemannian optimisation in the hyperbolic space to embed the state set into the\nhyperbolic space and create a model of the environment. In doing so we enforce\na global topology on the states and are able to exploit this topology to learn\nmeaningful sub-tasks. We demonstrate empirically, both in discrete and\ncontinuous domains, how these embeddings can improve the learning of meaningful\nsub-tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:30:23 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 01:19:48 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Tiwari", "Saket", ""], ["Prannoy", "M.", ""]]}, {"id": "1812.01488", "submitter": "Saket Tiwari", "authors": "Saket Tiwari and Philip S. Thomas", "title": "Natural Option Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed option-critic architecture Bacon et al. provide a\nstochastic policy gradient approach to hierarchical reinforcement learning.\nSpecifically, they provide a way to estimate the gradient of the expected\ndiscounted return with respect to parameters that define a finite number of\ntemporally extended actions, called \\textit{options}. In this paper we show how\nthe option-critic architecture can be extended to estimate the natural gradient\nof the expected discounted return. To this end, the central questions that we\nconsider in this paper are: 1) what is the definition of the natural gradient\nin this context, 2) what is the Fisher information matrix associated with an\noption's parameterized policy, 3) what is the Fisher information matrix\nassociated with an option's parameterized termination function, and 4) how can\na compatible function approximation approach be leveraged to obtain natural\ngradient estimates for both the parameterized policy and parameterized\ntermination functions of an option with per-time-step time and space complexity\nlinear in the total number of parameters. Based on answers to these questions\nwe introduce the natural option critic algorithm. Experimental results showcase\nimprovement over the vanilla gradient approach.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:33:26 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Tiwari", "Saket", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1812.01495", "submitter": "Bronwyn Woods", "authors": "Bronwyn Woods", "title": "Expanding search in the space of empirical ML", "comments": "Presented at the Critiquing and Correcting Trends in Machine Learning\n  workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As researchers and practitioners of applied machine learning, we are given a\nset of requirements on the problem to be solved, the plausibly obtainable data,\nand the computational resources available. We aim to find (within those bounds)\nreliably useful combinations of problem, data, and algorithm. An emphasis on\nalgorithmic or technical novelty in ML conference publications leads to\nexploration of one dimension of this space. Data collection and ML deployment\nat scale in industry settings offers an environment for exploring the others.\nOur conferences and reviewing criteria can better support empirical ML by\nsoliciting and incentivizing experimentation and synthesis independent of\nalgorithmic innovation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:51:28 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Woods", "Bronwyn", ""]]}, {"id": "1812.01504", "submitter": "Bashir Rastegarpanah", "authors": "Bashir Rastegarpanah (1), Krishna P. Gummadi (2), Mark Crovella (1)\n  ((1) Boston University, (2) MPI-SWS)", "title": "Fighting Fire with Fire: Using Antidote Data to Improve Polarization and\n  Fairness of Recommender Systems", "comments": "References to appendices are fixed", "journal-ref": null, "doi": "10.1145/3289600.3291002", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing role of recommender systems in many aspects of society makes\nit essential to consider how such systems may impact social good. Various\nmodifications to recommendation algorithms have been proposed to improve their\nperformance for specific socially relevant measures. However, previous\nproposals are often not easily adapted to different measures, and they\ngenerally require the ability to modify either existing system inputs, the\nsystem's algorithm, or the system's outputs. As an alternative, in this paper\nwe introduce the idea of improving the social desirability of recommender\nsystem outputs by adding more data to the input, an approach we view as\nproviding `antidote' data to the system. We formalize the antidote data\nproblem, and develop optimization-based solutions. We take as our model system\nthe matrix factorization approach to recommendation, and we propose a set of\nmeasures to capture the polarization or fairness of recommendations. We then\nshow how to generate antidote data for each measure, pointing out a number of\ncomputational efficiencies, and discuss the impact on overall system accuracy.\nOur experiments show that a modest budget for antidote data can lead to\nsignificant improvements in the polarization or fairness of recommendations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 22:15:29 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 23:30:01 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 01:13:54 GMT"}, {"version": "v4", "created": "Fri, 25 Jan 2019 21:49:05 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Rastegarpanah", "Bashir", "", "Boston University"], ["Gummadi", "Krishna P.", "", "MPI-SWS"], ["Crovella", "Mark", "", "Boston University"]]}, {"id": "1812.01528", "submitter": "Yue Zhao", "authors": "Yue Zhao, Zain Nasrullah, Maciej K. Hryniewicki, Zheng Li", "title": "LSCP: Locally Selective Combination in Parallel Outlier Ensembles", "comments": "Proceedings of the 2019 SIAM International Conference on Data Mining\n  (SDM)", "journal-ref": null, "doi": "10.1137/1.9781611975673.66", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unsupervised outlier ensembles, the absence of ground truth makes the\ncombination of base outlier detectors a challenging task. Specifically,\nexisting parallel outlier ensembles lack a reliable way of selecting competent\nbase detectors, affecting accuracy and stability, during model combination. In\nthis paper, we propose a framework---called Locally Selective Combination in\nParallel Outlier Ensembles (LSCP)---which addresses the issue by defining a\nlocal region around a test instance using the consensus of its nearest\nneighbors in randomly selected feature subspaces. The top-performing base\ndetectors in this local region are selected and combined as the model's final\noutput. Four variants of the LSCP framework are compared with seven widely used\nparallel frameworks. Experimental results demonstrate that one of these\nvariants, LSCP_AOM, consistently outperforms baselines on the majority of\ntwenty real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 17:02:30 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 02:49:05 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zhao", "Yue", ""], ["Nasrullah", "Zain", ""], ["Hryniewicki", "Maciej K.", ""], ["Li", "Zheng", ""]]}, {"id": "1812.01551", "submitter": "Evgeny Postnikov", "authors": "E. B. Postnikov (1), I. V. Bychkov (2 and 3), J. Y. Dubenskaya (1), O.\n  L. Fedorov (4), Y. A. Kazarina (4), E. E. Korosteleva (1), A. P. Kryukov (1),\n  A. A. Mikhailov (2), M. D. Nguyen (1), S. P. Polyakov (1), A. O. Shigarov (2\n  and 3), D. A. Shipilov (4), D.P. Zhurov (4) ((1) Lomonosov Moscow State\n  University Skobeltsyn Institute of Nuclear Physics (MSU SINP), Moscow,\n  Russia, (2) Matrosov Institute for System Dynamics and Control Theory,\n  Siberian Branch of Russian Academy of Sciences, Irkutsk, Russia, (3) Irkutsk\n  State University (ISU), Irkutsk, Russia, (4) Applied Physics Institute of\n  Irkutsk State University (API ISU), Irkutsk, Russia)", "title": "Particle identification in ground-based gamma-ray astronomy using\n  convolutional neural networks", "comments": "5 pages, 2 figures. Submitted to CEUR Workshop Proceedings, 8th\n  International Conference \"Distributed Computing and Grid-technologies in\n  Science and Education\" GRID 2018, 10 - 14 September 2018, Dubna, Russia", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern detectors of cosmic gamma-rays are a special type of imaging\ntelescopes (air Cherenkov telescopes) supplied with cameras with a relatively\nlarge number of photomultiplier-based pixels. For example, the camera of the\nTAIGA-IACT telescope has 560 pixels of hexagonal structure. Images in such\ncameras can be analysed by deep learning techniques to extract numerous\nphysical and geometrical parameters and/or for incoming particle\nidentification. The most powerful deep learning technique for image analysis,\nthe so-called convolutional neural network (CNN), was implemented in this\nstudy. Two open source libraries for machine learning, PyTorch and TensorFlow,\nwere tested as possible software platforms for particle identification in\nimaging air Cherenkov telescopes. Monte Carlo simulation was performed to\nanalyse images of gamma-rays and background particles (protons) as well as\nestimate identification accuracy. Further steps of implementation and\nimprovement of this technique are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 17:43:21 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Postnikov", "E. B.", "", "2 and 3"], ["Bychkov", "I. V.", "", "2 and 3"], ["Dubenskaya", "J. Y.", "", "2\n  and 3"], ["Fedorov", "O. L.", "", "2\n  and 3"], ["Kazarina", "Y. A.", "", "2\n  and 3"], ["Korosteleva", "E. E.", "", "2\n  and 3"], ["Kryukov", "A. P.", "", "2\n  and 3"], ["Mikhailov", "A. A.", "", "2\n  and 3"], ["Nguyen", "M. D.", "", "2\n  and 3"], ["Polyakov", "S. P.", "", "2\n  and 3"], ["Shigarov", "A. O.", "", "2\n  and 3"], ["Shipilov", "D. A.", ""], ["Zhurov", "D. P.", ""]]}, {"id": "1812.01553", "submitter": "Edward Wagstaff", "authors": "Ed Wagstaff and Saad Hamid and Michael Osborne", "title": "Batch Selection for Parallelisation of Bayesian Quadrature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integration over non-negative integrands is a central problem in machine\nlearning (e.g. for model averaging, (hyper-)parameter marginalisation, and\ncomputing posterior predictive distributions). Bayesian Quadrature is a\nprobabilistic numerical integration technique that performs promisingly when\ncompared to traditional Markov Chain Monte Carlo methods. However, in contrast\nto easily-parallelised MCMC methods, Bayesian Quadrature methods have, thus\nfar, been essentially serial in nature, selecting a single point to sample at\neach step of the algorithm. We deliver methods to select batches of points at\neach step, based upon those recently presented in the Batch Bayesian\nOptimisation literature. Such parallelisation significantly reduces computation\ntime, especially when the integrand is expensive to sample.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 17:47:30 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Wagstaff", "Ed", ""], ["Hamid", "Saad", ""], ["Osborne", "Michael", ""]]}, {"id": "1812.01608", "submitter": "Jacob Menick", "authors": "Jacob Menick, Nal Kalchbrenner", "title": "Generating High Fidelity Images with Subscale Pixel Networks and\n  Multidimensional Upscaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unconditional generation of high fidelity images is a longstanding\nbenchmark for testing the performance of image decoders. Autoregressive image\nmodels have been able to generate small images unconditionally, but the\nextension of these methods to large images where fidelity can be more readily\nassessed has remained an open problem. Among the major challenges are the\ncapacity to encode the vast previous context and the sheer difficulty of\nlearning a distribution that preserves both global semantic coherence and\nexactness of detail. To address the former challenge, we propose the Subscale\nPixel Network (SPN), a conditional decoder architecture that generates an image\nas a sequence of sub-images of equal size. The SPN compactly captures\nimage-wide spatial dependencies and requires a fraction of the memory and the\ncomputation required by other fully autoregressive models. To address the\nlatter challenge, we propose to use Multidimensional Upscaling to grow an image\nin both size and depth via intermediate stages utilising distinct SPNs. We\nevaluate SPNs on the unconditional generation of CelebAHQ of size 256 and of\nImageNet from size 32 to 256. We achieve state-of-the-art likelihood results in\nmultiple settings, set up new benchmark results in previously unexplored\nsettings and are able to generate very high fidelity large scale samples on the\nbasis of both datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:47:44 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Menick", "Jacob", ""], ["Kalchbrenner", "Nal", ""]]}, {"id": "1812.01609", "submitter": "Stef Garasto", "authors": "Wilhelm E. Sorteberg (1), Stef Garasto (1), Alison S. Pouplin (1),\n  Chris D. Cantwell (2) and Anil A. Bharath (1) ((1) Dept. of Bioengineering,\n  Imperial College London, (2) Dept. of Aeronautics, Imperial College London)", "title": "Approximating the solution to wave propagation using deep neural\n  networks", "comments": "Accepted to the NeurIPS 2018 Workshop \"Modeling the Physical World:\n  Perception, Learning, and Control\" (extended abstract)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans gain an implicit understanding of physical laws through observing and\ninteracting with the world. Endowing an autonomous agent with an understanding\nof physical laws through experience and observation is seldom practical: we\nshould seek alternatives. Fortunately, many of the laws of behaviour of the\nphysical world can be derived from prior knowledge of dynamical systems,\nexpressed through the use of partial differential equations. In this work, we\nsuggest a neural network capable of understanding a specific physical\nphenomenon: wave propagation in a two-dimensional medium. We define\n`understanding' in this context as the ability to predict the future evolution\nof the spatial patterns of rendered wave amplitude from a relatively small set\nof initial observations. The inherent complexity of the wave equations --\ntogether with the existence of reflections and interference -- makes the\nprediction problem non-trivial. A network capable of making approximate\npredictions also unlocks the opportunity to speed-up numerical simulations for\nwave propagation. To this aim, we created a novel dataset of simulated wave\nmotion and built a predictive deep neural network comprising of three main\nblocks: an encoder, a propagator made by 3 LSTMs, and a decoder. Results show\nreasonable predictions for as long as 80 time steps into the future on a\ndataset not seen during training. Furthermore, the network is able to\ngeneralize to an initial condition that is qualitatively different from those\nseen during training.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 16:32:01 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Sorteberg", "Wilhelm E.", ""], ["Garasto", "Stef", ""], ["Pouplin", "Alison S.", ""], ["Cantwell", "Chris D.", ""], ["Bharath", "Anil A.", ""]]}, {"id": "1812.01647", "submitter": "Jonathan Uesato", "authors": "Jonathan Uesato, Ananya Kumar, Csaba Szepesvari, Tom Erez, Avraham\n  Ruderman, Keith Anderson, Krishmamurthy (Dj) Dvijotham, Nicolas Heess,\n  Pushmeet Kohli", "title": "Rigorous Agent Evaluation: An Adversarial Approach to Uncover\n  Catastrophic Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of evaluating learning systems in safety\ncritical domains such as autonomous driving, where failures can have\ncatastrophic consequences. We focus on two problems: searching for scenarios\nwhen learned agents fail and assessing their probability of failure. The\nstandard method for agent evaluation in reinforcement learning, Vanilla Monte\nCarlo, can miss failures entirely, leading to the deployment of unsafe agents.\nWe demonstrate this is an issue for current agents, where even matching the\ncompute used for training is sometimes insufficient for evaluation. To address\nthis shortcoming, we draw upon the rare event probability estimation literature\nand propose an adversarial evaluation approach. Our approach focuses evaluation\non adversarially chosen situations, while still providing unbiased estimates of\nfailure probabilities. The key difficulty is in identifying these adversarial\nsituations -- since failures are rare there is little signal to drive\noptimization. To solve this we propose a continuation approach that learns\nfailure modes in related but less robust agents. Our approach also allows reuse\nof data already collected for training the agent. We demonstrate the efficacy\nof adversarial evaluation on two standard domains: humanoid control and\nsimulated driving. Experimental results show that our methods can find\ncatastrophic failures and estimate failures rates of agents multiple orders of\nmagnitude faster than standard evaluation schemes, in minutes to hours rather\nthan days.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 19:39:53 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Uesato", "Jonathan", "", "Dj"], ["Kumar", "Ananya", "", "Dj"], ["Szepesvari", "Csaba", "", "Dj"], ["Erez", "Tom", "", "Dj"], ["Ruderman", "Avraham", "", "Dj"], ["Anderson", "Keith", "", "Dj"], ["Krishmamurthy", "", "", "Dj"], ["Dvijotham", "", ""], ["Heess", "Nicolas", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1812.01655", "submitter": "\\\"Omer Deniz Akyildiz", "authors": "\\\"Omer Deniz Akyildiz, \\'Emilie Chouzenoux, V\\'ictor Elvira, Joaqu\\'in\n  M\\'iguez", "title": "A probabilistic incremental proximal gradient method", "comments": "5 pages, includes an extra numerical experiment", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a probabilistic optimization method, named\nprobabilistic incremental proximal gradient (PIPG) method, by developing a\nprobabilistic interpretation of the incremental proximal gradient algorithm. We\nexplicitly model the update rules of the incremental proximal gradient method\nand develop a systematic approach to propagate the uncertainty of the solution\nestimate over iterations. The PIPG algorithm takes the form of Bayesian\nfiltering updates for a state-space model constructed by using the cost\nfunction. Our framework makes it possible to utilize well-known exact or\napproximate Bayesian filters, such as Kalman or extended Kalman filters, to\nsolve large-scale regularized optimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 19:49:46 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 12:43:28 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 12:03:33 GMT"}, {"version": "v4", "created": "Tue, 23 Apr 2019 13:01:22 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2019 13:42:34 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Akyildiz", "\u00d6mer Deniz", ""], ["Chouzenoux", "\u00c9milie", ""], ["Elvira", "V\u00edctor", ""], ["M\u00edguez", "Joaqu\u00edn", ""]]}, {"id": "1812.01662", "submitter": "Radha Kopparti", "authors": "Tillman Weyde and Radha Manisha Kopparti", "title": "Feed-Forward Neural Networks Need Inductive Bias to Learn Equality\n  Relations", "comments": "Relational Representation Learning Workshop, NeurIPS 2018", "journal-ref": "Relational Representation Learning (R2L) Workshop, NeurIPS 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Basic binary relations such as equality and inequality are fundamental to\nrelational data structures. Neural networks should learn such relations and\ngeneralise to new unseen data. We show in this study, however, that this\ngeneralisation fails with standard feed-forward networks on binary vectors.\nEven when trained with maximal training data, standard networks do not reliably\ndetect equality.We introduce differential rectifier (DR) units that we add to\nthe network in different configurations. The DR units create an inductive bias\nin the networks, so that they do learn to generalise, even from small numbers\nof examples and we have not found any negative effect of their inclusion in the\nnetwork. Given the fundamental nature of these relations, we hypothesize that\nfeed-forward neural network learning benefits from inductive bias in other\nrelations as well. Consequently, the further development of suitable inductive\nbiases will be beneficial to many tasks in relational learning with neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 20:02:38 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Weyde", "Tillman", ""], ["Kopparti", "Radha Manisha", ""]]}, {"id": "1812.01664", "submitter": "Adam Spannaus", "authors": "Vasileios Maroulas and Cassie Putman Micucci and Adam Spannaus", "title": "A Stable Cardinality Distance for Topological Classification", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work incorporates topological features via persistence diagrams to\nclassify point cloud data arising from materials science. Persistence diagrams\nare multisets summarizing the connectedness and holes of given data. A new\ndistance on the space of persistence diagrams generates relevant input features\nfor a classification algorithm for materials science data. This distance\nmeasures the similarity of persistence diagrams using the cost of matching\npoints and a regularization term corresponding to cardinality differences\nbetween diagrams. Establishing stability properties of this distance provides\ntheoretical justification for the use of the distance in comparisons of such\ndiagrams. The classification scheme succeeds in determining the crystal\nstructure of materials on noisy and sparse data retrieved from synthetic atom\nprobe tomography experiments.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 20:16:21 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 17:45:22 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Maroulas", "Vasileios", ""], ["Micucci", "Cassie Putman", ""], ["Spannaus", "Adam", ""]]}, {"id": "1812.01672", "submitter": "Chuteng Zhou", "authors": "Paul Whatmough, Chuteng Zhou, Patrick Hansen, Matthew Mattina", "title": "Energy Efficient Hardware for On-Device CNN Inference via Transfer\n  Learning", "comments": "4 pages, 2 figures, NeurIPS 2018 on-device ML workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device CNN inference for real-time computer vision applications can result\nin computational demands that far exceed the energy budgets of mobile devices.\nThis paper proposes FixyNN, a co-designed hardware accelerator platform which\nsplits a CNN model into two parts: a set of layers that are fixed in the\nhardware platform as a front-end fixed-weight feature extractor, and the\nremaining layers which become a back-end classifier running on a conventional\nprogrammable CNN accelerator. The common front-end provides ubiquitous CNN\nfeatures for all FixyNN models, while the back-end is programmable and specific\nto a given dataset. Image classification models for FixyNN are trained\nend-to-end via transfer learning, with front-end layers fixed for the shared\nfeature extractor, and back-end layers fine-tuned for a specific task. Over a\nsuite of six datasets, we trained models via transfer learning with an accuracy\nloss of <1%, resulting in a FixyNN hardware platform with nearly 2 times better\nenergy efficiency than a conventional programmable CNN accelerator of the same\nsilicon area (i.e. hardware cost).\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 20:44:18 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 23:02:11 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Whatmough", "Paul", ""], ["Zhou", "Chuteng", ""], ["Hansen", "Patrick", ""], ["Mattina", "Matthew", ""]]}, {"id": "1812.01677", "submitter": "Ning Jin", "authors": "Ning Jin, Yilin Zhu, Zhenglin Geng and Ronald Fedkiw", "title": "A Pixel-Based Framework for Data-Driven Clothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the aim of creating virtual cloth deformations more similar to real\nworld clothing, we propose a new computational framework that recasts three\ndimensional cloth deformation as an RGB image in a two dimensional pattern\nspace. Then a three dimensional animation of cloth is equivalent to a sequence\nof two dimensional RGB images, which in turn are driven/choreographed via\nanimation parameters such as joint angles. This allows us to leverage popular\nCNNs to learn cloth deformations in image space. The two dimensional cloth\npixels are extended into the real world via standard body skinning techniques,\nafter which the RGB values are interpreted as texture offsets and displacement\nmaps. Notably, we illustrate that our approach does not require accurate\nunclothed body shapes or robust skinning techniques. Additionally, we discuss\nhow standard image based techniques such as image partitioning for higher\nresolution, GANs for merging partitioned image regions back together, etc., can\nreadily be incorporated into our framework.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 04:52:10 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Jin", "Ning", ""], ["Zhu", "Yilin", ""], ["Geng", "Zhenglin", ""], ["Fedkiw", "Ronald", ""]]}, {"id": "1812.01681", "submitter": "Fabio De Sousa Ribeiro", "authors": "Fabio De Sousa Ribeiro, Francesco Caliva, Mark Swainson, Kjartan\n  Gudmundsson, Georgios Leontidis, Stefanos Kollias", "title": "Deep Bayesian Self-Training", "comments": "16 pages, 10 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised Deep Learning has been highly successful in recent years,\nachieving state-of-the-art results in most tasks. However, with the ongoing\nuptake of such methods in industrial applications, the requirement for large\namounts of annotated data is often a challenge. In most real world problems,\nmanual annotation is practically intractable due to time/labour constraints,\nthus the development of automated and adaptive data annotation systems is\nhighly sought after. In this paper, we propose both a (i) Deep Bayesian\nSelf-Training methodology for automatic data annotation, by leveraging\npredictive uncertainty estimates using variational inference and modern Neural\nNetwork architectures, as well as (ii) a practical adaptation procedure for\nhandling high label variability between different dataset distributions through\nclustering of Neural Network latent variable representations. An experimental\nstudy on both public and private datasets is presented illustrating the\nsuperior performance of the proposed approach over standard Self-Training\nbaselines, highlighting the importance of predictive uncertainty estimates in\nsafety-critical domains.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 19:59:06 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 16:04:57 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 15:38:40 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Ribeiro", "Fabio De Sousa", ""], ["Caliva", "Francesco", ""], ["Swainson", "Mark", ""], ["Gudmundsson", "Kjartan", ""], ["Leontidis", "Georgios", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1812.01690", "submitter": "Tatsuki Koga", "authors": "Tatsuki Koga, Naoki Nonaka, Jun Sakuma, Jun Seita", "title": "General-to-Detailed GAN for Infrequent Class Medical Images", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/64", "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has significant potential for medical imaging. However, since\nthe incident rate of each disease varies widely, the frequency of classes in a\nmedical image dataset is imbalanced, leading to poor accuracy for such\ninfrequent classes. One possible solution is data augmentation of infrequent\nclasses using synthesized images created by Generative Adversarial Networks\n(GANs), but conventional GANs also require certain amount of images to learn.\nTo overcome this limitation, here we propose General-to-detailed GAN (GDGAN),\nserially connected two GANs, one for general labels and the other for detailed\nlabels. GDGAN produced diverse medical images, and the network trained with an\naugmented dataset outperformed other networks using existing methods with\nrespect to Area-Under-Curve (AUC) of Receiver Operating Characteristic (ROC)\ncurve.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 05:40:15 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Koga", "Tatsuki", ""], ["Nonaka", "Naoki", ""], ["Sakuma", "Jun", ""], ["Seita", "Jun", ""]]}, {"id": "1812.01696", "submitter": "Haraldur Hallgr\\'imsson", "authors": "Haraldur T. Hallgr\\'imsson, Filip Jankovic, Tim Althoff, Luca Foschini", "title": "Learning Individualized Cardiovascular Responses from Large-scale\n  Wearable Sensors Data", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/238", "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of modeling cardiovascular responses to physical\nactivity and sleep changes captured by wearable sensors in free living\nconditions. We use an attentional convolutional neural network to learn\nparsimonious signatures of individual cardiovascular response from data\nrecorded at the minute level resolution over several months on a cohort of 80k\npeople. We demonstrate internal validity by showing that signatures generated\non an individual's 2017 data generalize to predict minute-level heart rate from\nphysical activity and sleep for the same individual in 2018, outperforming\nseveral time-series forecasting baselines. We also show external validity\ndemonstrating that signatures outperform plain resting heart rate (RHR) in\npredicting variables associated with cardiovascular functions, such as age and\nBody Mass Index (BMI). We believe that the computed cardiovascular signatures\nhave utility in monitoring cardiovascular health over time, including detecting\nabnormalities and quantifying recovery from acute events.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 21:25:59 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Hallgr\u00edmsson", "Haraldur T.", ""], ["Jankovic", "Filip", ""], ["Althoff", "Tim", ""], ["Foschini", "Luca", ""]]}, {"id": "1812.01699", "submitter": "Jay Taneja", "authors": "Gabriel Cadamuro, Aggrey Muhebwa and Jay Taneja", "title": "Assigning a Grade: Accurate Measurement of Road Quality Using Satellite\n  Imagery", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Roads are critically important infrastructure to societal and economic\ndevelopment, with huge investments made by governments every year. However,\nmethods for monitoring those investments tend to be time-consuming, laborious,\nand expensive, placing them out of reach for many developing regions. In this\nwork, we develop a model for monitoring the quality of road infrastructure\nusing satellite imagery. For this task, we harness two trends: the increasing\navailability of high-resolution, often-updated satellite imagery, and the\nenormous improvement in speed and accuracy of convolutional neural\nnetwork-based methods for performing computer vision tasks. We employ a unique\ndataset of road quality information on 7000km of roads in Kenya combined with\n50cm resolution satellite imagery. We create models for a binary classification\ntask as well as a comprehensive 5-category classification task, with accuracy\nscores of 88 and 73 percent respectively. We also provide evidence of the\nrobustness of our methods with challenging held-out scenarios, though we note\nsome improvement is still required for confident analysis of a never before\nseen road. We believe these results are well-positioned to have substantial\nimpact on a broad set of transport applications.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 01:43:26 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 02:38:23 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Cadamuro", "Gabriel", ""], ["Muhebwa", "Aggrey", ""], ["Taneja", "Jay", ""]]}, {"id": "1812.01710", "submitter": "Sebastian Bujwid", "authors": "Sebastian Bujwid, Miquel Mart\\'i, Hossein Azizpour, Alessandro\n  Pieropan", "title": "GANtruth - an unpaired image-to-image translation method for driving\n  scenarios", "comments": "32nd Conference on Neural Information Processing Systems (NeurIPS),\n  Machine Learning for Intelligent Transportation Systems Workshop, Montr\\'eal,\n  Canada. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic image translation has significant potentials in autonomous\ntransportation systems. That is due to the expense of data collection and\nannotation as well as the unmanageable diversity of real-words situations. The\nmain issue with unpaired image-to-image translation is the ill-posed nature of\nthe problem. In this work, we propose a novel method for constraining the\noutput space of unpaired image-to-image translation. We make the assumption\nthat the environment of the source domain is known (e.g. synthetically\ngenerated), and we propose to explicitly enforce preservation of the\nground-truth labels on the translated images.\n  We experiment on preserving ground-truth information such as semantic\nsegmentation, disparity, and instance segmentation. We show significant\nevidence that our method achieves improved performance over the\nstate-of-the-art model of UNIT for translating images from SYNTHIA to\nCityscapes. The generated images are perceived as more realistic in human\nsurveys and outperforms UNIT when used in a domain adaptation scenario for\nsemantic segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:19:43 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Bujwid", "Sebastian", ""], ["Mart\u00ed", "Miquel", ""], ["Azizpour", "Hossein", ""], ["Pieropan", "Alessandro", ""]]}, {"id": "1812.01711", "submitter": "Yingxue Zhang", "authors": "Yingxue Zhang, Michael Rabbat", "title": "A Graph-CNN for 3D Point Cloud Classification", "comments": "Published as a conference paper at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (Graph-CNNs) extend traditional CNNs to\nhandle data that is supported on a graph. Major challenges when working with\ndata on graphs are that the support set (the vertices of the graph) do not\ntypically have a natural ordering, and in general, the topology of the graph is\nnot regular (i.e., vertices do not all have the same number of neighbors).\nThus, Graph-CNNs have huge potential to deal with 3D point cloud data which has\nbeen obtained from sampling a manifold. In this paper, we develop a Graph-CNN\nfor classifying 3D point cloud data, called PointGCN. The architecture combines\nlocalized graph convolutions with two types of graph downsampling operations\n(also known as pooling). By the effective exploration of the point cloud local\nstructure using the Graph-CNN, the proposed architecture achieves competitive\nperformance on the 3D object classification benchmark ModelNet, and our\narchitecture is more stable than competing schemes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:00:34 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Zhang", "Yingxue", ""], ["Rabbat", "Michael", ""]]}, {"id": "1812.01712", "submitter": "Ye Zhu", "authors": "Ye Zhu and Sven Ewan Shepstone and Pablo Mart\\'inez-Nuevo and Miklas\n  Str{\\o}m Kristoffersen and Fabien Moutarde and Zhuang Fu", "title": "Multiview Based 3D Scene Understanding On Partial Point Sets", "comments": "This paper has been submitted to IEEE Transactions on Neural Networks\n  and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning within the context of point clouds has gained much research\ninterest in recent years mostly due to the promising results that have been\nachieved on a number of challenging benchmarks, such as 3D shape recognition\nand scene semantic segmentation. In many realistic settings however, snapshots\nof the environment are often taken from a single view, which only contains a\npartial set of the scene due to the field of view restriction of commodity\ncameras. 3D scene semantic understanding on partial point clouds is considered\nas a challenging task. In this work, we propose a processing approach for 3D\npoint cloud data based on a multiview representation of the existing 360{\\deg}\npoint clouds. By fusing the original 360{\\deg} point clouds and their\ncorresponding 3D multiview representations as input data, a neural network is\nable to recognize partial point sets while improving the general performance on\ncomplete point sets, resulting in an overall increase of 31.9% and 4.3% in\nsegmentation accuracy for partial and complete scene semantic understanding,\nrespectively. This method can also be applied in a wider 3D recognition context\nsuch as 3D part segmentation.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 12:23:59 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Zhu", "Ye", ""], ["Shepstone", "Sven Ewan", ""], ["Mart\u00ednez-Nuevo", "Pablo", ""], ["Kristoffersen", "Miklas Str\u00f8m", ""], ["Moutarde", "Fabien", ""], ["Fu", "Zhuang", ""]]}, {"id": "1812.01713", "submitter": "Haibin Zheng", "authors": "Jinyin Chen, Haibin Zheng, Hui Xiong, Mengmeng Su", "title": "FineFool: Fine Object Contour Attack via Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been shown vulnerable to adversarial attacks\nlaunched by adversarial examples which are carefully crafted by attacker to\ndefeat classifiers. Deep learning models cannot escape the attack either. Most\nof adversarial attack methods are focused on success rate or perturbations\nsize, while we are more interested in the relationship between adversarial\nperturbation and the image itself. In this paper, we put forward a novel\nadversarial attack based on contour, named FineFool. Finefool not only has\nbetter attack performance compared with other state-of-art white-box attacks in\naspect of higher attack success rate and smaller perturbation, but also capable\nof visualization the optimal adversarial perturbation via attention on object\ncontour. To the best of our knowledge, Finefool is for the first time combines\nthe critical feature of the original clean image with the optimal perturbations\nin a visible manner. Inspired by the correlations between adversarial\nperturbations and object contour, slighter perturbations is produced via\nfocusing on object contour features, which is more imperceptible and difficult\nto be defended, especially network add-on defense methods with the trade-off\nbetween perturbations filtering and contour feature loss. Compared with\nexisting state-of-art attacks, extensive experiments are conducted to show that\nFinefool is capable of efficient attack against defensive deep models.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 12:58:56 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Chen", "Jinyin", ""], ["Zheng", "Haibin", ""], ["Xiong", "Hui", ""], ["Su", "Mengmeng", ""]]}, {"id": "1812.01716", "submitter": "Shehroz Khan", "authors": "Ahmed Ashraf, Shehroz Khan, Nikhil Bhagwat, Mallar Chakravarty, Babak\n  Taati", "title": "Learning to Unlearn: Building Immunity to Dataset Bias in Medical\n  Imaging Studies", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216 Submission Id: 207", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/207", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical imaging machine learning algorithms are usually evaluated on a single\ndataset. Although training and testing are performed on different subsets of\nthe dataset, models built on one study show limited capability to generalize to\nother studies. While database bias has been recognized as a serious problem in\nthe computer vision community, it has remained largely unnoticed in medical\nimaging research. Transfer learning thus remains confined to the re-use of\nfeature representations requiring re-training on the new dataset. As a result,\nmachine learning models do not generalize even when trained on imaging datasets\nthat were captured to study the same variable of interest. The ability to\ntransfer knowledge gleaned from one study to another, without the need for\nre-training, if possible, would provide reassurance that the models are\nlearning knowledge fundamental to the problem under study instead of latching\nonto the idiosyncracies of a dataset. In this paper, we situate the problem of\ndataset bias in the context of medical imaging studies. We show empirical\nevidence that such a problem exists in medical datasets. We then present a\nframework to unlearn study membership as a means to handle the problem of\ndatabase bias. Our main idea is to take the data from the original feature\nspace to an intermediate space where the data points are indistinguishable in\nterms of which study they come from, while maintaining the recognition\ncapability with respect to the variable of interest. This will promote models\nwhich learn the more general properties of the etiology under study instead of\naligning to dataset-specific peculiarities. Essentially, our proposed model\nlearns to unlearn the dataset bias.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 04:46:35 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Ashraf", "Ahmed", ""], ["Khan", "Shehroz", ""], ["Bhagwat", "Nikhil", ""], ["Chakravarty", "Mallar", ""], ["Taati", "Babak", ""]]}, {"id": "1812.01717", "submitter": "Sjoerd van Steenkiste", "authors": "Thomas Unterthiner, Sjoerd van Steenkiste, Karol Kurach, Raphael\n  Marinier, Marcin Michalski, Sylvain Gelly", "title": "Towards Accurate Generative Models of Video: A New Metric & Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in deep generative models have lead to remarkable progress in\nsynthesizing high quality images. Following their successful application in\nimage processing and representation learning, an important next step is to\nconsider videos. Learning generative models of video is a much harder task,\nrequiring a model to capture the temporal dynamics of a scene, in addition to\nthe visual presentation of objects. While recent attempts at formulating\ngenerative models of video have had some success, current progress is hampered\nby (1) the lack of qualitative metrics that consider visual quality, temporal\ncoherence, and diversity of samples, and (2) the wide gap between purely\nsynthetic video data sets and challenging real-world data sets in terms of\ncomplexity. To this extent we propose Fr\\'{e}chet Video Distance (FVD), a new\nmetric for generative models of video, and StarCraft 2 Videos (SCV), a\nbenchmark of game play from custom starcraft 2 scenarios that challenge the\ncurrent capabilities of generative models of video. We contribute a large-scale\nhuman study, which confirms that FVD correlates well with qualitative human\njudgment of generated videos, and provide initial benchmark results on SCV.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 03:57:42 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 16:43:17 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Unterthiner", "Thomas", ""], ["van Steenkiste", "Sjoerd", ""], ["Kurach", "Karol", ""], ["Marinier", "Raphael", ""], ["Michalski", "Marcin", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1812.01718", "submitter": "David Ha", "authors": "Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb,\n  Kazuaki Yamamoto, David Ha", "title": "Deep Learning for Classical Japanese Literature", "comments": "To appear at Neural Information Processing Systems 2018 Workshop on\n  Machine Learning for Creativity and Design", "journal-ref": null, "doi": "10.20676/00000341", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much of machine learning research focuses on producing models which perform\nwell on benchmark tasks, in turn improving our understanding of the challenges\nassociated with those tasks. From the perspective of ML researchers, the\ncontent of the task itself is largely irrelevant, and thus there have\nincreasingly been calls for benchmark tasks to more heavily focus on problems\nwhich are of social or cultural relevance. In this work, we introduce\nKuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as\nwell as two larger, more challenging datasets, Kuzushiji-49 and\nKuzushiji-Kanji. Through these datasets, we wish to engage the machine learning\ncommunity into the world of classical Japanese literature. Dataset available at\nhttps://github.com/rois-codh/kmnist\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 12:37:31 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Clanuwat", "Tarin", ""], ["Bober-Irizar", "Mikel", ""], ["Kitamoto", "Asanobu", ""], ["Lamb", "Alex", ""], ["Yamamoto", "Kazuaki", ""], ["Ha", "David", ""]]}, {"id": "1812.01719", "submitter": "Patrick McClure", "authors": "Patrick McClure, Nao Rho, John A. Lee, Jakub R. Kaczmarzyk, Charles\n  Zheng, Satrajit S. Ghosh, Dylan Nielson, Adam G. Thomas, Peter Bandettini,\n  and Francisco Pereira", "title": "Knowing what you know in brain segmentation using Bayesian deep neural\n  networks", "comments": "Submitted to Frontiers in Neuroinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a Bayesian deep neural network (DNN) for\npredicting FreeSurfer segmentations of structural MRI volumes, in minutes\nrather than hours. The network was trained and evaluated on a large dataset (n\n= 11,480), obtained by combining data from more than a hundred different sites,\nand also evaluated on another completely held-out dataset (n = 418). The\nnetwork was trained using a novel spike-and-slab dropout-based variational\ninference approach. We show that, on these datasets, the proposed Bayesian DNN\noutperforms previously proposed methods, in terms of the similarity between the\nsegmentation predictions and the FreeSurfer labels, and the usefulness of the\nestimate uncertainty of these predictions. In particular, we demonstrated that\nthe prediction uncertainty of this network at each voxel is a good indicator of\nwhether the network has made an error and that the uncertainty across the whole\nbrain can predict the manual quality control ratings of a scan. The proposed\nBayesian DNN method should be applicable to any new network architecture for\naddressing the segmentation problem.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 13:23:30 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 20:29:08 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 18:55:28 GMT"}, {"version": "v4", "created": "Sun, 16 Jun 2019 20:50:59 GMT"}, {"version": "v5", "created": "Wed, 18 Sep 2019 10:30:08 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["McClure", "Patrick", ""], ["Rho", "Nao", ""], ["Lee", "John A.", ""], ["Kaczmarzyk", "Jakub R.", ""], ["Zheng", "Charles", ""], ["Ghosh", "Satrajit S.", ""], ["Nielson", "Dylan", ""], ["Thomas", "Adam G.", ""], ["Bandettini", "Peter", ""], ["Pereira", "Francisco", ""]]}, {"id": "1812.01729", "submitter": "Frank Noe", "authors": "Frank No\\'e, Simon Olsson, Jonas K\\\"ohler and Hao Wu", "title": "Boltzmann Generators -- Sampling Equilibrium States of Many-Body Systems\n  with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing equilibrium states in condensed-matter many-body systems, such as\nsolvated proteins, is a long-standing challenge. Lacking methods for generating\nstatistically independent equilibrium samples in \"one shot\", vast computational\neffort is invested for simulating these system in small steps, e.g., using\nMolecular Dynamics. Combining deep learning and statistical mechanics, we here\ndevelop Boltzmann Generators, that are shown to generate unbiased one-shot\nequilibrium samples of representative condensed matter systems and proteins.\nBoltzmann Generators use neural networks to learn a coordinate transformation\nof the complex configurational equilibrium distribution to a distribution that\ncan be easily sampled. Accurate computation of free energy differences and\ndiscovery of new configurations are demonstrated, providing a statistical\nmechanics tool that can avoid rare events during sampling without prior\nknowledge of reaction coordinates.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 22:41:33 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 11:38:54 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["No\u00e9", "Frank", ""], ["Olsson", "Simon", ""], ["K\u00f6hler", "Jonas", ""], ["Wu", "Hao", ""]]}, {"id": "1812.01735", "submitter": "Dmytro Karamshuk", "authors": "Dmytro Karamshuk and David Matthews", "title": "Learning Cheap and Novel Flight Itineraries", "comments": null, "journal-ref": "The European Conference on Machine Learning and Principles and\n  Practice of Knowledge Discovery in Databases (ECML PKDD 2018)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of efficiently constructing cheap and novel round\ntrip flight itineraries by combining legs from different airlines. We analyse\nthe factors that contribute towards the price of such itineraries and find that\nmany result from the combination of just 30% of airlines and that the closer\nthe departure of such itineraries is to the user's search date the more likely\nthey are to be cheaper than the tickets from one airline. We use these insights\nto formulate the problem as a trade-off between the recall of cheap itinerary\nconstructions and the costs associated with building them.\n  We propose a supervised learning solution with location embeddings which\nachieves an AUC=80.48, a substantial improvement over simpler baselines. We\ndiscuss various practical considerations for dealing with the staleness and the\nstability of the model and present the design of the machine learning pipeline.\nFinally, we present an analysis of the model's performance in production and\nits impact on Skyscanner's users.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 22:48:27 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Karamshuk", "Dmytro", ""], ["Matthews", "David", ""]]}, {"id": "1812.01736", "submitter": "Cecilia Clementi", "authors": "Jiang Wang, Simon Olsson, Christoph Wehmeyer, Adria Perez, Nicholas E.\n  Charron, Gianni de Fabritiis, Frank Noe, Cecilia Clementi", "title": "Machine Learning of coarse-grained Molecular Dynamics Force Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atomistic or ab-initio molecular dynamics simulations are widely used to\npredict thermodynamics and kinetics and relate them to molecular structure. A\ncommon approach to go beyond the time- and length-scales accessible with such\ncomputationally expensive simulations is the definition of coarse-grained\nmolecular models. Existing coarse-graining approaches define an effective\ninteraction potential to match defined properties of high-resolution models or\nexperimental data. In this paper, we reformulate coarse-graining as a\nsupervised machine learning problem. We use statistical learning theory to\ndecompose the coarse-graining error and cross-validation to select and compare\nthe performance of different models. We introduce CGnets, a deep learning\napproach, that learns coarse-grained free energy functions and can be trained\nby a force matching scheme. CGnets maintain all physically relevant invariances\nand allow one to incorporate prior physics knowledge to avoid sampling of\nunphysical structures. We show that CGnets can capture all-atom\nexplicit-solvent free energy surfaces with models using only a few\ncoarse-grained beads and no solvent, while classical coarse-graining methods\nfail to capture crucial features of the free energy surface. Thus, CGnets are\nable to capture multi-body terms that emerge from the dimensionality reduction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 22:49:37 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 19:27:04 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 15:15:31 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Wang", "Jiang", ""], ["Olsson", "Simon", ""], ["Wehmeyer", "Christoph", ""], ["Perez", "Adria", ""], ["Charron", "Nicholas E.", ""], ["de Fabritiis", "Gianni", ""], ["Noe", "Frank", ""], ["Clementi", "Cecilia", ""]]}, {"id": "1812.01739", "submitter": "Peter Blouw", "authors": "Peter Blouw, Xuan Choo, Eric Hunsberger, Chris Eliasmith", "title": "Benchmarking Keyword Spotting Efficiency on Neuromorphic Hardware", "comments": "Updated power measurements on Loihi after improvements to I/O speed.\n  Updated discussion in light of results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using Intel's Loihi neuromorphic research chip and ABR's Nengo Deep Learning\ntoolkit, we analyze the inference speed, dynamic power consumption, and energy\ncost per inference of a two-layer neural network keyword spotter trained to\nrecognize a single phrase. We perform comparative analyses of this keyword\nspotter running on more conventional hardware devices including a CPU, a GPU,\nNvidia's Jetson TX1, and the Movidius Neural Compute Stick. Our results\nindicate that for this inference application, Loihi outperforms all of these\nalternatives on an energy cost per inference basis while maintaining equivalent\ninference accuracy. Furthermore, an analysis of tradeoffs between network size,\ninference speed, and energy cost indicates that Loihi's comparative advantage\nover other low-power computing devices improves for larger networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 22:58:23 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 20:48:51 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Blouw", "Peter", ""], ["Choo", "Xuan", ""], ["Hunsberger", "Eric", ""], ["Eliasmith", "Chris", ""]]}, {"id": "1812.01767", "submitter": "Qingsong Wen", "authors": "Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, Huan Xu, Shenghuo\n  Zhu", "title": "RobustSTL: A Robust Seasonal-Trend Decomposition Algorithm for Long Time\n  Series", "comments": "Accepted to the thirty-third AAAI Conference on Artificial\n  Intelligence (AAAI 2019), 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposing complex time series into trend, seasonality, and remainder\ncomponents is an important task to facilitate time series anomaly detection and\nforecasting. Although numerous methods have been proposed, there are still many\ntime series characteristics exhibiting in real-world data which are not\naddressed properly, including 1) ability to handle seasonality fluctuation and\nshift, and abrupt change in trend and reminder; 2) robustness on data with\nanomalies; 3) applicability on time series with long seasonality period. In the\npaper, we propose a novel and generic time series decomposition algorithm to\naddress these challenges. Specifically, we extract the trend component robustly\nby solving a regression problem using the least absolute deviations loss with\nsparse regularization. Based on the extracted trend, we apply the the non-local\nseasonal filtering to extract the seasonality component. This process is\nrepeated until accurate decomposition is obtained. Experiments on different\nsynthetic and real-world time series datasets demonstrate that our method\noutperforms existing solutions.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 01:01:52 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Wen", "Qingsong", ""], ["Gao", "Jingkun", ""], ["Song", "Xiaomin", ""], ["Sun", "Liang", ""], ["Xu", "Huan", ""], ["Zhu", "Shenghuo", ""]]}, {"id": "1812.01779", "submitter": "Vibhuti Gupta", "authors": "Vibhuti Gupta", "title": "Voice Disorder Detection Using Long Short Term Memory (LSTM) Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated detection of voice disorders with computational methods is a recent\nresearch area in the medical domain since it requires a rigorous endoscopy for\nthe accurate diagnosis. Efficient screening methods are required for the\ndiagnosis of voice disorders so as to provide timely medical facilities in\nminimal resources. Detecting Voice disorder using computational methods is a\nchallenging problem since audio data is continuous due to which extracting\nrelevant features and applying machine learning is hard and unreliable. This\npaper proposes a Long short term memory model (LSTM) to detect pathological\nvoice disorders and evaluates its performance in a real 400 testing samples\nwithout any labels. Different feature extraction methods are used to provide\nthe best set of features before applying LSTM model for classification. The\npaper describes the approach and experiments that show promising results with\n22% sensitivity, 97% specificity and 56% unweighted average recall.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 00:37:33 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Gupta", "Vibhuti", ""]]}, {"id": "1812.01803", "submitter": "Haichuan Yang", "authors": "Haichuan Yang, Yuhao Zhu, Ji Liu", "title": "ECC: Platform-Independent Energy-Constrained Deep Neural Network\n  Compression via a Bilinear Regression Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many DNN-enabled vision applications constantly operate under severe energy\nconstraints such as unmanned aerial vehicles, Augmented Reality headsets, and\nsmartphones. Designing DNNs that can meet a stringent energy budget is becoming\nincreasingly important. This paper proposes ECC, a framework that compresses\nDNNs to meet a given energy constraint while minimizing accuracy loss. The key\nidea of ECC is to model the DNN energy consumption via a novel bilinear\nregression function. The energy estimate model allows us to formulate DNN\ncompression as a constrained optimization that minimizes the DNN loss function\nover the energy constraint. The optimization problem, however, has nontrivial\nconstraints. Therefore, existing deep learning solvers do not apply directly.\nWe propose an optimization algorithm that combines the essence of the\nAlternating Direction Method of Multipliers (ADMM) framework with\ngradient-based learning algorithms. The algorithm decomposes the original\nconstrained optimization into several subproblems that are solved iteratively\nand efficiently. ECC is also portable across different hardware platforms\nwithout requiring hardware knowledge. Experiments show that ECC achieves higher\naccuracy under the same or lower energy budget compared to state-of-the-art\nresource-constrained DNN compression techniques.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 03:31:02 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 14:49:50 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 04:46:52 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Yang", "Haichuan", ""], ["Zhu", "Yuhao", ""], ["Liu", "Ji", ""]]}, {"id": "1812.01804", "submitter": "Huangyi Ge", "authors": "Huangyi Ge, Sze Yiu Chau, Bruno Ribeiro, Ninghui Li", "title": "Random Spiking and Systematic Evaluation of Defenses Against Adversarial\n  Examples", "comments": "To be appear in ACM CODESPY 2020", "journal-ref": null, "doi": "10.1145/3374664.3375736", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classifiers often suffer from adversarial examples, which are generated\nby strategically adding a small amount of noise to input images to trick\nclassifiers into misclassification. Over the years, many defense mechanisms\nhave been proposed, and different researchers have made seemingly contradictory\nclaims on their effectiveness. We present an analysis of possible adversarial\nmodels, and propose an evaluation framework for comparing different defense\nmechanisms. As part of the framework, we introduce a more powerful and\nrealistic adversary strategy. Furthermore, we propose a new defense mechanism\ncalled Random Spiking (RS), which generalizes dropout and introduces random\nnoises in the training process in a controlled manner. Evaluations under our\nproposed framework suggest RS delivers better protection against adversarial\nexamples than many existing schemes.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 03:31:07 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 17:08:21 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 20:55:52 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 22:09:40 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ge", "Huangyi", ""], ["Chau", "Sze Yiu", ""], ["Ribeiro", "Bruno", ""], ["Li", "Ninghui", ""]]}, {"id": "1812.01815", "submitter": "Stephen Mussmann", "authors": "Stephen Mussmann, Percy Liang", "title": "Uncertainty Sampling is Preconditioned Stochastic Gradient Descent on\n  Zero-One Loss", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty sampling, a popular active learning algorithm, is used to reduce\nthe amount of data required to learn a classifier, but it has been observed in\npractice to converge to different parameters depending on the initialization\nand sometimes to even better parameters than standard training on all the data.\nIn this work, we give a theoretical explanation of this phenomenon, showing\nthat uncertainty sampling on a convex loss can be interpreted as performing a\npreconditioned stochastic gradient step on a smoothed version of the population\nzero-one loss that converges to the population zero-one loss. Furthermore,\nuncertainty sampling moves in a descent direction and converges to stationary\npoints of the smoothed population zero-one loss. Experiments on synthetic and\nreal datasets support this connection.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 04:51:57 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Mussmann", "Stephen", ""], ["Liang", "Percy", ""]]}, {"id": "1812.01821", "submitter": "Yifan Chen", "authors": "Yifan Chen and Yevgeniy Vorobeychik", "title": "Regularized Ensembles and Transferability in Adversarial Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the considerable success of convolutional neural networks in a broad\narray of domains, recent research has shown these to be vulnerable to small\nadversarial perturbations, commonly known as adversarial examples. Moreover,\nsuch examples have shown to be remarkably portable, or transferable, from one\nmodel to another, enabling highly successful black-box attacks. We explore this\nissue of transferability and robustness from two dimensions: first, considering\nthe impact of conventional $l_p$ regularization as well as replacing the top\nlayer with a linear support vector machine (SVM), and second, the value of\ncombining regularized models into an ensemble. We show that models trained with\ndifferent regularizers present barriers to transferability, as does partial\ninformation about the models comprising the ensemble.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 05:32:00 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Chen", "Yifan", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1812.01839", "submitter": "Tianhong Li", "authors": "Tianhong Li, Jianguo Li, Zhuang Liu, Changshui Zhang", "title": "Few Sample Knowledge Distillation for Efficient Network Compression", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network compression techniques such as pruning and weight tensor\ndecomposition usually require fine-tuning to recover the prediction accuracy\nwhen the compression ratio is high. However, conventional fine-tuning suffers\nfrom the requirement of a large training set and the time-consuming training\nprocedure. This paper proposes a novel solution for knowledge distillation from\nlabel-free few samples to realize both data efficiency and training/processing\nefficiency. We treat the original network as \"teacher-net\" and the compressed\nnetwork as \"student-net\". A 1x1 convolution layer is added at the end of each\nlayer block of the student-net, and we fit the block-level outputs of the\nstudent-net to the teacher-net by estimating the parameters of the added\nlayers. We prove that the added layer can be merged without adding extra\nparameters and computation cost during inference. Experiments on multiple\ndatasets and network architectures verify the method's effectiveness on\nstudent-nets obtained by various network pruning and weight decomposition\nmethods. Our method can recover student-net's accuracy to the same level as\nconventional fine-tuning methods in minutes while using only 1% label-free data\nof the full training data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 07:24:39 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 15:33:23 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 04:53:15 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Li", "Tianhong", ""], ["Li", "Jianguo", ""], ["Liu", "Zhuang", ""], ["Zhang", "Changshui", ""]]}, {"id": "1812.01844", "submitter": "Jaiyam Sharma", "authors": "Jaiyam Sharma and Saket Navlakha", "title": "Improving Similarity Search with High-dimensional Locality-sensitive\n  Hashing", "comments": "12 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new class of data-independent locality-sensitive hashing (LSH)\nalgorithms based on the fruit fly olfactory circuit. The fundamental difference\nof this approach is that, instead of assigning hashes as dense points in a low\ndimensional space, hashes are assigned in a high dimensional space, which\nenhances their separability. We show theoretically and empirically that this\nnew family of hash functions is locality-sensitive and preserves rank\nsimilarity for inputs in any `p space. We then analyze different variations on\nthis strategy and show empirically that they outperform existing LSH methods\nfor nearest-neighbors search on six benchmark datasets. Finally, we propose a\nmulti-probe version of our algorithm that achieves higher performance for the\nsame query time, or conversely, that maintains performance of prior approaches\nwhile taking significantly less indexing time and memory. Overall, our approach\nleverages the advantages of separability provided by high-dimensional spaces,\nwhile still remaining computationally efficient\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 07:41:53 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Sharma", "Jaiyam", ""], ["Navlakha", "Saket", ""]]}, {"id": "1812.01939", "submitter": "Ke Ma", "authors": "Ke Ma and Qianqian Xu and Zhiyong Yang and Xiaochun Cao", "title": "Less but Better: Generalization Enhancement of Ordinal Embedding via\n  Distributional Margin", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the absence of prior knowledge, ordinal embedding methods obtain new\nrepresentation for items in a low-dimensional Euclidean space via a set of\nquadruple-wise comparisons. These ordinal comparisons often come from human\nannotators, and sufficient comparisons induce the success of classical\napproaches. However, collecting a large number of labeled data is known as a\nhard task, and most of the existing work pay little attention to the\ngeneralization ability with insufficient samples. Meanwhile, recent progress in\nlarge margin theory discloses that rather than just maximizing the minimum\nmargin, both the margin mean and variance, which characterize the margin\ndistribution, are more crucial to the overall generalization performance. To\naddress the issue of insufficient training samples, we propose a margin\ndistribution learning paradigm for ordinal embedding, entitled Distributional\nMargin based Ordinal Embedding (\\textit{DMOE}). Precisely, we first define the\nmargin for ordinal embedding problem. Secondly, we formulate a concise\nobjective function which avoids maximizing margin mean and minimizing margin\nvariance directly but exhibits the similar effect. Moreover, an Augmented\nLagrange Multiplier based algorithm is customized to seek the optimal solution\nof \\textit{DMOE} effectively. Experimental studies on both simulated and\nreal-world datasets are provided to show the effectiveness of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 12:03:39 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Ma", "Ke", ""], ["Xu", "Qianqian", ""], ["Yang", "Zhiyong", ""], ["Cao", "Xiaochun", ""]]}, {"id": "1812.01941", "submitter": "Swapneel Mehta", "authors": "Swapneel Mehta, Prasanth Kothuri, Daniel Lanza Garcia", "title": "Anomaly Detection for Network Connection Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage a streaming architecture based on ELK, Spark and Hadoop in order\nto collect, store, and analyse database connection logs in near real-time. The\nproposed system investigates outliers using unsupervised learning; widely\nadopted clustering and classification algorithms for log data, highlighting the\nsubtle variances in each model by visualisation of outliers. Arriving at a\nnovel solution to evaluate untagged, unfiltered connection logs, we propose an\napproach that can be extrapolated to a generalised system of analysing\nconnection logs across a large infrastructure comprising thousands of\nindividual nodes and generating hundreds of lines in logs per second.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 00:50:51 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Mehta", "Swapneel", ""], ["Kothuri", "Prasanth", ""], ["Garcia", "Daniel Lanza", ""]]}, {"id": "1812.01945", "submitter": "Ke Ma", "authors": "Ke Ma and Qianqian Xu and Xiaochun Cao", "title": "Robust Ordinal Embedding from Contaminated Relative Comparisons", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing ordinal embedding methods usually follow a two-stage routine:\noutlier detection is first employed to pick out the inconsistent comparisons;\nthen an embedding is learned from the clean data. However, learning in a\nmulti-stage manner is well-known to suffer from sub-optimal solutions. In this\npaper, we propose a unified framework to jointly identify the contaminated\ncomparisons and derive reliable embeddings. The merits of our method are\nthree-fold: (1) By virtue of the proposed unified framework, the sub-optimality\nof traditional methods is largely alleviated; (2) The proposed method is aware\nof global inconsistency by minimizing a corresponding cost, while traditional\nmethods only involve local inconsistency; (3) Instead of considering the\nnuclear norm heuristics, we adopt an exact solution for rank equality\nconstraint. Our studies are supported by experiments with both simulated\nexamples and real-world data. The proposed framework provides us a promising\ntool for robust ordinal embedding from the contaminated comparisons.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 12:09:00 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Ma", "Ke", ""], ["Xu", "Qianqian", ""], ["Cao", "Xiaochun", ""]]}, {"id": "1812.01965", "submitter": "Joseph Bethge", "authors": "Joseph Bethge, Marvin Bornstein, Adrian Loy, Haojin Yang, Christoph\n  Meinel", "title": "Training Competitive Binary Neural Networks from Scratch", "comments": "Our source code can be found at https://github.com/hpi-xnor/BMXNet-v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have achieved astonishing results in different\napplication areas. Various methods that allow us to use these models on mobile\nand embedded devices have been proposed. Especially binary neural networks are\na promising approach for devices with low computational power. However,\ntraining accurate binary models from scratch remains a challenge. Previous work\noften uses prior knowledge from full-precision models and complex training\nstrategies. In our work, we focus on increasing the performance of binary\nneural networks without such prior knowledge and a much simpler training\nstrategy. In our experiments we show that we are able to achieve\nstate-of-the-art results on standard benchmark datasets. Further, to the best\nof our knowledge, we are the first to successfully adopt a network architecture\nwith dense connections for binary networks, which lets us improve the\nstate-of-the-art even further.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 12:48:50 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Bethge", "Joseph", ""], ["Bornstein", "Marvin", ""], ["Loy", "Adrian", ""], ["Yang", "Haojin", ""], ["Meinel", "Christoph", ""]]}, {"id": "1812.01967", "submitter": "Jielei Chu", "authors": "Jielei Chu, Hongjun Wang, Jing Liu, Zhiguo Gong, and Tianrui Li", "title": "Unsupervised Feature Learning Architecture with Multi-clustering\n  Integration RBM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we present a novel unsupervised feature learning architecture,\nwhich consists of a multi-clustering integration module and a variant of RBM\ntermed multi-clustering integration RBM (MIRBM). In the multi-clustering\nintegration module, we apply three unsupervised K-means, affinity propagation\nand spectral clustering algorithms to obtain three different clustering\npartitions (CPs) without any background knowledge or label. Then, an unanimous\nvoting strategy is used to generate a local clustering partition (LCP). The\nnovel MIRBM model is a core feature encoding part of the proposed unsupervised\nfeature learning architecture. The novelty of it is that the LCP as an\nunsupervised guidance is integrated into one step contrastive divergence (CD1)\nlearning to guide the distribution of the hidden layer features. For the\ninstance in the same LCP cluster, the hidden and reconstructed hidden layer\nfeatures of the MIRBM model in the proposed architecture tend to constrict\ntogether in the training process. Meanwhile, each LCP center tends to disperse\nfrom each other as much as possible in the hidden and reconstructed hidden\nlayer during training. The experiments demonstrate that the proposed\nunsupervised feature learning architecture has more powerful feature\nrepresentation and generalization capability than the state-of-the-art graph\nregularized RBM (GraphRBM) for clustering tasks in the Microsoft Research Asia\nMultimedia (MSRA-MM)2.0 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 12:56:27 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 08:52:24 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Chu", "Jielei", ""], ["Wang", "Hongjun", ""], ["Liu", "Jing", ""], ["Gong", "Zhiguo", ""], ["Li", "Tianrui", ""]]}, {"id": "1812.02035", "submitter": "Xueshuang Xiang", "authors": "Haipeng Jia, Xueshuang Xiang, Da Fan, Meiyu Huang, Changhao Sun, Yang\n  He", "title": "Stochastic Model Pruning via Weight Dropping Away and Back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have dramatically achieved great success on a variety of\nchallenging tasks. However, most successful DNNs have an extremely complex\nstructure, leading to extensive research on model compression.As a significant\narea of progress in model compression, traditional gradual pruning approaches\ninvolve an iterative prune-retrain procedure and may suffer from two critical\nissues: local importance judgment, where the pruned weights are merely\nunimportant in the current model; and an irretrievable pruning process, where\nthe pruned weights have no chance to come back. Addressing these two issues,\nthis paper proposes the Drop Pruning approach, which leverages stochastic\noptimization in the pruning process by introducing a drop strategy at each\npruning step, namely, drop away, which stochastically deletes some unimportant\nweights, and drop back, which stochastically recovers some pruned weights. The\nsuitable choice of drop probabilities decreases the model size during the\npruning process and helps it flow to the target sparsity. Compared to the\nBayesian approaches that stochastically train a compact model for pruning, we\ndirectly aim at stochastic gradual pruning. We provide a detailed analysis\nshowing that the drop away and drop back approaches have individual\ncontributions. Moreover, Drop Pruning can achieve competitive compression\nperformance and accuracy on many benchmark tasks compared with state-of-the-art\nweights pruning and Bayesian training approaches.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 15:19:19 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 01:44:14 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Jia", "Haipeng", ""], ["Xiang", "Xueshuang", ""], ["Fan", "Da", ""], ["Huang", "Meiyu", ""], ["Sun", "Changhao", ""], ["He", "Yang", ""]]}, {"id": "1812.02061", "submitter": "Yacouba Boubacar Mainassara", "authors": "Yacouba Boubacar Ma\\\"inassara (LMB), Othman Kadmiri (LMB), Bruno\n  Saussereau (LMB)", "title": "Estimation of multivariate asymmetric power GARCH models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now widely accepted that volatility models have to incorporate the\nso-called leverage effect in order to to model the dynamics of daily financial\nreturns.We suggest a new class of multivariate power transformed asymmetric\nmodels. It includes several functional forms of multivariate GARCH models which\nare of great interest in financial modeling and time series literature. We\nprovide an explicit necessary and sufficient condition to establish the strict\nstationarity of the model. We derive the asymptotic properties of the\nquasi-maximum likelihood estimator of the parameters. These properties are\nestablished both when the power of the transformation is known or is unknown.\nThe asymptotic results are illustrated by Monte Carlo experiments. An\napplication to real financial data is also proposed.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 15:53:57 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:18:46 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Ma\u00efnassara", "Yacouba Boubacar", "", "LMB"], ["Kadmiri", "Othman", "", "LMB"], ["Saussereau", "Bruno", "", "LMB"]]}, {"id": "1812.02091", "submitter": "Kubilay Atasu", "authors": "Kubilay Atasu, Thomas Mittelholzer", "title": "Low-Complexity Data-Parallel Earth Mover's Distance Approximations", "comments": "To appear in ICML 2019:\n  http://proceedings.mlr.press/v97/atasu19a.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Earth Mover's Distance (EMD) is a state-of-the art metric for comparing\ndiscrete probability distributions, but its high distinguishability comes at a\nhigh cost in computational complexity. Even though linear-complexity\napproximation algorithms have been proposed to improve its scalability, these\nalgorithms are either limited to vector spaces with only a few dimensions or\nthey become ineffective when the degree of overlap between the probability\ndistributions is high. We propose novel approximation algorithms that overcome\nboth of these limitations, yet still achieve linear time complexity. All our\nalgorithms are data parallel, and thus, we take advantage of massively parallel\ncomputing engines, such as Graphics Processing Units (GPUs). On the popular\ntext-based 20 Newsgroups dataset, the new algorithms are four orders of\nmagnitude faster than a multi-threaded CPU implementation of Word Mover's\nDistance and match its nearest-neighbors-search accuracy. On MNIST images, the\nnew algorithms are four orders of magnitude faster than a GPU implementation of\nthe Sinkhorn's algorithm while offering a slightly higher\nnearest-neighbors-search accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 16:29:44 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 14:51:02 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Atasu", "Kubilay", ""], ["Mittelholzer", "Thomas", ""]]}, {"id": "1812.02108", "submitter": "Ernesto Araya Valdivia", "authors": "Ernesto Araya Valdivia", "title": "Relative concentration bounds for the spectrum of kernel matrices", "comments": "Typo in eq.7 fixed (this require to slightly change the analysis).\n  For the concentration ineq. in Thm.1 we need a slightly different variance\n  term. We improve eq. 9 in Prop.4, which improves the rate in Thm.2 for the\n  polynomial decay regime", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the concentration properties for the eigenvalues of\nkernel matrices, which are central objects in a wide range of kernel methods\nand, more recently, in network analysis. We present a set of concentration\ninequalities tailored for each individual eigenvalue of the kernel matrix with\nrespect to its known asymptotic limit. The inequalities presented here are of\nrelative type, meaning that they scale with the eigenvalue in consideration,\nwhich results in convergence rates that vary across the spectrum. The rates we\nobtain here are faster than the typical $\\O(\\frac{1}{\\sqrt n})$ and are often\nexponential, depending on regularity assumptions of Sobolev type. One key\nfeature of our results is that they apply to non positive kernels, which is\nfundamental in the context of network analysis. We show how our results are\nwell suited for the study of dot product kernels, which are related to random\ngeometric graphs on the sphere, via the graphon formalism. We illustrate our\nresults by applying them to a variety of dot product kernels on the sphere and\nto the one dimensional Gaussian kernel.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 16:58:07 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 20:06:00 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 20:05:48 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 11:42:43 GMT"}, {"version": "v5", "created": "Tue, 5 Mar 2019 12:20:34 GMT"}, {"version": "v6", "created": "Mon, 25 Mar 2019 09:39:27 GMT"}, {"version": "v7", "created": "Mon, 21 Sep 2020 20:07:37 GMT"}, {"version": "v8", "created": "Sun, 25 Oct 2020 20:14:37 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Valdivia", "Ernesto Araya", ""]]}, {"id": "1812.02127", "submitter": "Konstantinos Spiliopoulos", "authors": "Konstantinos Spiliopoulos", "title": "Information geometry for approximate Bayesian computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.PR math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to explore the basic Approximate Bayesian\nComputation (ABC) algorithm via the lens of information theory. ABC is a widely\nused algorithm in cases where the likelihood of the data is hard to work with\nor intractable, but one can simulate from it. We use relative entropy ideas to\nanalyze the behavior of the algorithm as a function of the threshold parameter\nand of the size of the data. Relative entropy here is data driven as it depends\non the values of the observed statistics. Relative entropy also allows us to\nexplore the effect of the distance metric and sets up a mathematical framework\nfor sensitivity analysis allowing to find important directions which could lead\nto lower computational cost of the algorithm for the same level of accuracy. In\naddition, we also investigate the bias of the estimators for generic\nobservables as a function of both the threshold parameters and the size of the\ndata. Our analysis provides error bounds on performance for positive tolerances\nand finite sample sizes. Simulation studies complement and illustrate the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 17:30:03 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 19:35:19 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1812.02159", "submitter": "Tristan Deleu", "authors": "Tristan Deleu, Yoshua Bengio", "title": "The effects of negative adaptation in Model-Agnostic Meta-Learning", "comments": "Workshop on Meta-Learning - 32nd Conference on Neural Information\n  Processing Systems (NeurIPS 2018), Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capacity of meta-learning algorithms to quickly adapt to a variety of\ntasks, including ones they did not experience during meta-training, has been a\nkey factor in the recent success of these methods on few-shot learning\nproblems. This particular advantage of using meta-learning over standard\nsupervised or reinforcement learning is only well founded under the assumption\nthat the adaptation phase does improve the performance of our model on the task\nof interest. However, in the classical framework of meta-learning, this\nconstraint is only mildly enforced, if not at all, and we only see an\nimprovement on average over a distribution of tasks. In this paper, we show\nthat the adaptation in an algorithm like MAML can significantly decrease the\nperformance of an agent in a meta-reinforcement learning setting, even on a\nrange of meta-training tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 18:53:02 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Deleu", "Tristan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1812.02171", "submitter": "Umanga Bista", "authors": "Umanga Bista, Alexander Mathews, Minjeong Shin, Aditya Krishna Menon,\n  Lexing Xie", "title": "Comparative Document Summarisation via Classification", "comments": "Accepted for AAAI 2019", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence.\n  Vol. 33. 2019", "doi": "10.1609/aaai.v33i01.330120", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers extractive summarisation in a comparative setting: given\ntwo or more document groups (e.g., separated by publication time), the goal is\nto select a small number of documents that are representative of each group,\nand also maximally distinguishable from other groups. We formulate a set of new\nobjective functions for this problem that connect recent literature on document\nsummarisation, interpretable machine learning, and data subset selection. In\nparticular, by casting the problem as a binary classification amongst different\ngroups, we derive objectives based on the notion of maximum mean discrepancy,\nas well as a simple yet effective gradient-based optimisation strategy. Our new\nformulation allows scalable evaluations of comparative summarisation as a\nclassification task, both automatically and via crowd-sourcing. To this end, we\nevaluate comparative summarisation methods on a newly curated collection of\ncontroversial news topics over 13 months. We observe that gradient-based\noptimisation outperforms discrete and baseline approaches in 14 out of 24\ndifferent automatic evaluation settings. In crowd-sourced evaluations,\nsummaries from gradient optimisation elicit 7% more accurate classification\nfrom human workers than discrete optimisation. Our result contrasts with recent\nliterature on submodular data subset selection that favours discrete\noptimisation. We posit that our formulation of comparative summarisation will\nprove useful in a diverse range of use cases such as comparing content sources,\nauthors, related topics, or distinct view points.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 04:04:56 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 08:42:03 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Bista", "Umanga", ""], ["Mathews", "Alexander", ""], ["Shin", "Minjeong", ""], ["Menon", "Aditya Krishna", ""], ["Xie", "Lexing", ""]]}, {"id": "1812.02183", "submitter": "Asad Khan", "authors": "Asad Khan, E. A. Huerta, Sibo Wang, Robert Gruendl, Elise Jennings and\n  Huihuo Zheng", "title": "Deep Learning at Scale for the Construction of Galaxy Catalogs in the\n  Dark Energy Survey", "comments": "14 pages, 12 Figures, 6 appendices, 2 visualizations see\n  \\<https://www.youtube.com/watch?v=n5rI573i6ws> and\n  \\<https://www.youtube.com/watch?v=1F3q7M8QjTQ>", "journal-ref": "Physics Letters B 795 (2019) 248-258", "doi": "10.1016/j.physletb.2019.06.009", "report-no": null, "categories": "astro-ph.IM cs.LG gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale of ongoing and future electromagnetic surveys pose formidable\nchallenges to classify astronomical objects. Pioneering efforts on this front\ninclude citizen science campaigns adopted by the Sloan Digital Sky Survey\n(SDSS). SDSS datasets have been recently used to train neural network models to\nclassify galaxies in the Dark Energy Survey (DES) that overlap the footprint of\nboth surveys. Herein, we demonstrate that knowledge from deep learning\nalgorithms, pre-trained with real-object images, can be transferred to classify\ngalaxies that overlap both SDSS and DES surveys, achieving state-of-the-art\naccuracy $\\gtrsim99.6\\%$. We demonstrate that this process can be completed\nwithin just eight minutes using distributed training. While this represents a\nsignificant step towards the classification of DES galaxies that overlap\nprevious surveys, we need to initiate the characterization of unlabelled DES\ngalaxies in new regions of parameter space. To accelerate this program, we use\nour neural network classifier to label over ten thousand unlabelled DES\ngalaxies, which do not overlap previous surveys. Furthermore, we use our neural\nnetwork model as a feature extractor for unsupervised clustering and find that\nunlabeled DES images can be grouped together in two distinct galaxy classes\nbased on their morphology, which provides a heuristic check that the learning\nis successfully transferred to the classification of unlabelled DES images. We\nconclude by showing that these newly labeled datasets can be combined with\nunsupervised recursive training to create large-scale DES galaxy catalogs in\npreparation for the Large Synoptic Survey Telescope era.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 19:00:24 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 17:17:34 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Khan", "Asad", ""], ["Huerta", "E. A.", ""], ["Wang", "Sibo", ""], ["Gruendl", "Robert", ""], ["Jennings", "Elise", ""], ["Zheng", "Huihuo", ""]]}, {"id": "1812.02207", "submitter": "Rafael Gomes Mantovani", "authors": "Rafael Gomes Mantovani, Tom\\'a\\v{s} Horv\\'ath, Ricardo Cerri, Sylvio\n  Barbon Junior, Joaquin Vanschoren, Andr\\'e Carlos Ponce de Leon Ferreira de\n  Carvalho", "title": "An empirical study on hyperparameter tuning of decision trees", "comments": "36 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms often contain many hyperparameters whose values\naffect the predictive performance of the induced models in intricate ways. Due\nto the high number of possibilities for these hyperparameter configurations,\nand their complex interactions, it is common to use optimization techniques to\nfind settings that lead to high predictive accuracy. However, we lack insight\ninto how to efficiently explore this vast space of configurations: which are\nthe best optimization techniques, how should we use them, and how significant\nis their effect on predictive or runtime performance? This paper provides a\ncomprehensive approach for investigating the effects of hyperparameter tuning\non three Decision Tree induction algorithms, CART, C4.5 and CTree. These\nalgorithms were selected because they are based on similar principles, have\npresented a high predictive performance in several previous works and induce\ninterpretable classification models. Additionally, they contain many\ninteracting hyperparameters to be adjusted. Experiments were carried out with\ndifferent tuning strategies to induce models and evaluate the relevance of\nhyperparameters using 94 classification datasets from OpenML. Experimental\nresults indicate that hyperparameter tuning provides statistically significant\nimprovements for C4.5 and CTree in only one-third of the datasets, and in most\nof the datasets for CART. Different tree algorithms may present different\ntuning scenarios, but in general, the tuning techniques required relatively few\niterations to find accurate solutions. Furthermore, the best technique for all\nthe algorithms was the Irace. Finally, we find that tuning a specific small\nsubset of hyperparameters contributes most of the achievable optimal predictive\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 19:59:20 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 10:50:33 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Mantovani", "Rafael Gomes", ""], ["Horv\u00e1th", "Tom\u00e1\u0161", ""], ["Cerri", "Ricardo", ""], ["Junior", "Sylvio Barbon", ""], ["Vanschoren", "Joaquin", ""], ["de Carvalho", "Andr\u00e9 Carlos Ponce de Leon Ferreira", ""]]}, {"id": "1812.02216", "submitter": "Jonathan Hunt", "authors": "Jonathan J Hunt, Andre Barreto, Timothy P Lillicrap, Nicolas Heess", "title": "Composing Entropic Policies using Divergence Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composing previously mastered skills to solve novel tasks promises dramatic\nimprovements in the data efficiency of reinforcement learning. Here, we analyze\ntwo recent works composing behaviors represented in the form of action-value\nfunctions and show that they perform poorly in some situations. As part of this\nanalysis, we extend an important generalization of policy improvement to the\nmaximum entropy framework and introduce an algorithm for the practical\nimplementation of successor features in continuous action spaces. Then we\npropose a novel approach which addresses the failure cases of prior work and,\nin principle, recovers the optimal policy during transfer. This method works by\nexplicitly learning the (discounted, future) divergence between base policies.\nWe study this approach in the tabular case and on non-trivial continuous\ncontrol problems with compositional structure and show that it outperforms or\nmatches existing methods across all tasks considered.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 20:43:29 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 16:22:52 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hunt", "Jonathan J", ""], ["Barreto", "Andre", ""], ["Lillicrap", "Timothy P", ""], ["Heess", "Nicolas", ""]]}, {"id": "1812.02224", "submitter": "Yunshu Du", "authors": "Yunshu Du, Wojciech M. Czarnecki, Siddhant M. Jayakumar, Mehrdad\n  Farajtabar, Razvan Pascanu, Balaji Lakshminarayanan", "title": "Adapting Auxiliary Losses Using Gradient Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One approach to deal with the statistical inefficiency of neural networks is\nto rely on auxiliary losses that help to build useful representations. However,\nit is not always trivial to know if an auxiliary task will be helpful for the\nmain task and when it could start hurting. We propose to use the cosine\nsimilarity between gradients of tasks as an adaptive weight to detect when an\nauxiliary loss is helpful to the main loss. We show that our approach is\nguaranteed to converge to critical points of the main task and demonstrate the\npractical usefulness of the proposed algorithm in a few domains: multi-task\nsupervised learning on subsets of ImageNet, reinforcement learning on\ngridworld, and reinforcement learning on Atari games.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 21:00:44 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 19:33:00 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Du", "Yunshu", ""], ["Czarnecki", "Wojciech M.", ""], ["Jayakumar", "Siddhant M.", ""], ["Farajtabar", "Mehrdad", ""], ["Pascanu", "Razvan", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1812.02230", "submitter": "Irina Higgins", "authors": "Irina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic\n  Matthey, Danilo Rezende, Alexander Lerchner", "title": "Towards a Definition of Disentangled Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can intelligent agents solve a diverse set of tasks in a data-efficient\nmanner? The disentangled representation learning approach posits that such an\nagent would benefit from separating out (disentangling) the underlying\nstructure of the world into disjoint parts of its representation. However,\nthere is no generally agreed-upon definition of disentangling, not least\nbecause it is unclear how to formalise the notion of world structure beyond toy\ndatasets with a known ground truth generative process. Here we propose that a\nprincipled solution to characterising disentangled representations can be found\nby focusing on the transformation properties of the world. In particular, we\nsuggest that those transformations that change only some properties of the\nunderlying world state, while leaving all other properties invariant, are what\ngives exploitable structure to any kind of data. Similar ideas have already\nbeen successfully applied in physics, where the study of symmetry\ntransformations has revolutionised the understanding of the world structure. By\nconnecting symmetry transformations to vector representations using the\nformalism of group and representation theory we arrive at the first formal\ndefinition of disentangled representations. Our new definition is in agreement\nwith many of the current intuitions about disentangling, while also providing\nprincipled resolutions to a number of previous points of contention. While this\nwork focuses on formally defining disentangling - as opposed to solving the\nlearning problem - we believe that the shift in perspective to studying data\ntransformations can stimulate the development of better representation learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 21:21:09 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Higgins", "Irina", ""], ["Amos", "David", ""], ["Pfau", "David", ""], ["Racaniere", "Sebastien", ""], ["Matthey", "Loic", ""], ["Rezende", "Danilo", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1812.02240", "submitter": "Robert Peharz", "authors": "Franz Pernkopf, Wolfgang Roth, Matthias Zoehrer, Lukas Pfeifenberger,\n  Guenther Schindler, Holger Froening, Sebastian Tschiatschek, Robert Peharz,\n  Matthew Mattina, Zoubin Ghahramani", "title": "Efficient and Robust Machine Learning for Real-World Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning is traditionally a resource intensive task, embedded\nsystems, autonomous navigation and the vision of the Internet-of-Things fuel\nthe interest in resource efficient approaches. These approaches require a\ncarefully chosen trade-off between performance and resource consumption in\nterms of computation and energy. On top of this, it is crucial to treat\nuncertainty in a consistent manner in all but the simplest applications of\nmachine learning systems. In particular, a desideratum for any real-world\nsystem is to be robust in the presence of outliers and corrupted data, as well\nas being `aware' of its limits, i.e.\\ the system should maintain and provide an\nuncertainty estimate over its own predictions. These complex demands are among\nthe major challenges in current machine learning research and key to ensure a\nsmooth transition of machine learning technology into every day's applications.\nIn this article, we provide an overview of the current state of the art of\nmachine learning techniques facilitating these real-world requirements. First\nwe provide a comprehensive review of resource-efficiency in deep neural\nnetworks with focus on techniques for model size reduction, compression and\nreduced precision. These techniques can be applied during training or as\npost-processing and are widely used to reduce both computational complexity and\nmemory footprint. As most (practical) neural networks are limited in their ways\nto treat uncertainty, we contrast them with probabilistic graphical models,\nwhich readily serve these desiderata by means of probabilistic inference. In\nthat way, we provide an extensive overview of the current state-of-the-art of\nrobust and efficient machine learning for real-world systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 21:47:23 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Pernkopf", "Franz", ""], ["Roth", "Wolfgang", ""], ["Zoehrer", "Matthias", ""], ["Pfeifenberger", "Lukas", ""], ["Schindler", "Guenther", ""], ["Froening", "Holger", ""], ["Tschiatschek", "Sebastian", ""], ["Peharz", "Robert", ""], ["Mattina", "Matthew", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1812.02256", "submitter": "Abbas Abdolmaleki", "authors": "Abbas Abdolmaleki, Jost Tobias Springenberg, Jonas Degrave, Steven\n  Bohez, Yuval Tassa, Dan Belov, Nicolas Heess, Martin Riedmiller", "title": "Relative Entropy Regularized Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an off-policy actor-critic algorithm for Reinforcement Learning\n(RL) that combines ideas from gradient-free optimization via stochastic search\nwith learned action-value function. The result is a simple procedure consisting\nof three steps: i) policy evaluation by estimating a parametric action-value\nfunction; ii) policy improvement via the estimation of a local non-parametric\npolicy; and iii) generalization by fitting a parametric policy. Each step can\nbe implemented in different ways, giving rise to several algorithm variants.\nOur algorithm draws on connections to existing literature on black-box\noptimization and 'RL as an inference' and it can be seen either as an extension\nof the Maximum a Posteriori Policy Optimisation algorithm (MPO) [Abdolmaleki et\nal., 2018a], or as an extension of Trust Region Covariance Matrix Adaptation\nEvolutionary Strategy (CMA-ES) [Abdolmaleki et al., 2017b; Hansen et al., 1997]\nto a policy iteration scheme. Our comparison on 31 continuous control tasks\nfrom parkour suite [Heess et al., 2017], DeepMind control suite [Tassa et al.,\n2018] and OpenAI Gym [Brockman et al., 2016] with diverse properties, limited\namount of compute and a single set of hyperparameters, demonstrate the\neffectiveness of our method and the state of art results. Videos, summarizing\nresults, can be found at goo.gl/HtvJKR .\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 22:29:11 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Abdolmaleki", "Abbas", ""], ["Springenberg", "Jost Tobias", ""], ["Degrave", "Jonas", ""], ["Bohez", "Steven", ""], ["Tassa", "Yuval", ""], ["Belov", "Dan", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1812.02261", "submitter": "Haimonti Dutta", "authors": "Haimonti Dutta and Nitin Nataraj", "title": "GADGET SVM: A Gossip-bAseD sub-GradiEnT Solver for Linear SVMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, an important weapon in a machine learning\nresearcher's arsenal is a scalable Support Vector Machine (SVM) algorithm. SVMs\nare extensively used for solving classification problems. Traditional\nalgorithms for learning SVMs often scale super linearly with training set size\nwhich becomes infeasible very quickly for large data sets. In recent years,\nscalable algorithms have been designed which study the primal or dual\nformulations of the problem. This often suggests a way to decompose the problem\nand facilitate development of distributed algorithms. In this paper, we present\na distributed algorithm for learning linear Support Vector Machines in the\nprimal form for binary classification called Gossip-bAseD sub-GradiEnT (GADGET)\nSVM. The algorithm is designed such that it can be executed locally on nodes of\na distributed system. Each node processes its local homogeneously partitioned\ndata and learns a primal SVM model. It then gossips with random neighbors about\nthe classifier learnt and uses this information to update the model. Extensive\ntheoretical and empirical results suggest that this anytime algorithm has\nperformance comparable to its centralized and online counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 22:56:06 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Dutta", "Haimonti", ""], ["Nataraj", "Nitin", ""]]}, {"id": "1812.02271", "submitter": "Ruishan Liu", "authors": "Ruishan Liu, Nicolo Fusi, Lester Mackey", "title": "Teacher-Student Compression with Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More accurate machine learning models often demand more computation and\nmemory at test time, making them difficult to deploy on CPU- or\nmemory-constrained devices. Teacher-student compression (TSC), also known as\ndistillation, alleviates this burden by training a less expensive student model\nto mimic the expensive teacher model while maintaining most of the original\naccuracy. However, when fresh data is unavailable for the compression task, the\nteacher's training data is typically reused, leading to suboptimal compression.\nIn this work, we propose to augment the compression dataset with synthetic data\nfrom a generative adversarial network (GAN) designed to approximate the\ntraining data distribution. Our GAN-assisted TSC (GAN-TSC) significantly\nimproves student accuracy for expensive models such as large random forests and\ndeep neural networks on both tabular and image datasets. Building on these\nresults, we propose a comprehensive metric---the TSC Score---to evaluate the\nquality of synthetic datasets based on their induced TSC performance. The TSC\nScore captures both data diversity and class affinity, and we illustrate its\nbenefits over the popular Inception Score in the context of image\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 23:43:00 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 22:53:19 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 02:53:42 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 22:17:50 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liu", "Ruishan", ""], ["Fusi", "Nicolo", ""], ["Mackey", "Lester", ""]]}, {"id": "1812.02275", "submitter": "Tom Pollard", "authors": "Alistair E. W. Johnson, Tom J. Pollard, and Tristan Naumann", "title": "Generalizability of predictive models for intensive care unit patients", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/233", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large volume of research has considered the creation of predictive models\nfor clinical data; however, much existing literature reports results using only\na single source of data. In this work, we evaluate the performance of models\ntrained on the publicly-available eICU Collaborative Research Database. We show\nthat cross-validation using many distinct centers provides a reasonable\nestimate of model performance in new centers. We further show that a single\nmodel trained across centers transfers well to distinct hospitals, even\ncompared to a model retrained using hospital-specific data. Our results\nmotivate the use of multi-center datasets for model development and highlight\nthe need for data sharing among hospitals to maximize model performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 00:12:50 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Johnson", "Alistair E. W.", ""], ["Pollard", "Tom J.", ""], ["Naumann", "Tristan", ""]]}, {"id": "1812.02288", "submitter": "Houssam Zenati", "authors": "Houssam Zenati, Manon Romain, Chuan Sheng Foo, Bruno Lecouat, Vijay\n  Ramaseshan Chandrasekhar", "title": "Adversarially Learned Anomaly Detection", "comments": "In the Proceedings of the 20th IEEE International Conference on Data\n  Mining (ICDM), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a significant and hence well-studied problem. However,\ndeveloping effective anomaly detection methods for complex and high-dimensional\ndata remains a challenge. As Generative Adversarial Networks (GANs) are able to\nmodel the complex high-dimensional distributions of real-world data, they offer\na promising approach to address this challenge. In this work, we propose an\nanomaly detection method, Adversarially Learned Anomaly Detection (ALAD) based\non bi-directional GANs, that derives adversarially learned features for the\nanomaly detection task. ALAD then uses reconstruction errors based on these\nadversarially learned features to determine if a data sample is anomalous. ALAD\nbuilds on recent advances to ensure data-space and latent-space\ncycle-consistencies and stabilize GAN training, which results in significantly\nimproved anomaly detection performance. ALAD achieves state-of-the-art\nperformance on a range of image and tabular datasets while being several\nhundred-fold faster at test time than the only published GAN-based method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 01:44:59 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Zenati", "Houssam", ""], ["Romain", "Manon", ""], ["Foo", "Chuan Sheng", ""], ["Lecouat", "Bruno", ""], ["Chandrasekhar", "Vijay Ramaseshan", ""]]}, {"id": "1812.02289", "submitter": "Srijan Kumar", "authors": "Srijan Kumar, Xikun Zhang, Jure Leskovec", "title": "Learning Dynamic Embeddings from Temporal Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling a sequence of interactions between users and items (e.g., products,\nposts, or courses) is crucial in domains such as e-commerce, social networking,\nand education to predict future interactions. Representation learning presents\nan attractive solution to model the dynamic evolution of user and item\nproperties, where each user/item can be embedded in a euclidean space and its\nevolution can be modeled by dynamic changes in embedding. However, existing\nembedding methods either generate static embeddings, treat users and items\nindependently, or are not scalable.\n  Here we present JODIE, a coupled recurrent model to jointly learn the dynamic\nembeddings of users and items from a sequence of user-item interactions. JODIE\nhas three components. First, the update component updates the user and item\nembedding from each interaction using their previous embeddings with the two\nmutually-recursive Recurrent Neural Networks. Second, a novel projection\ncomponent is trained to forecast the embedding of users at any future time.\nFinally, the prediction component directly predicts the embedding of the item\nin a future interaction. For models that learn from a sequence of interactions,\ntraditional training data batching cannot be done due to complex user-user\ndependencies. Therefore, we present a novel batching algorithm called t-Batch\nthat generates time-consistent batches of training data that can run in\nparallel, giving massive speed-up.\n  We conduct six experiments on two prediction tasks---future interaction\nprediction and state change prediction---using four real-world datasets. We\nshow that JODIE outperforms six state-of-the-art algorithms in these tasks by\nup to 22.4%. Moreover, we show that JODIE is highly scalable and up to 9.2x\nfaster than comparable models. As an additional experiment, we illustrate that\nJODIE can predict student drop-out from courses five interactions in advance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 01:50:47 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Kumar", "Srijan", ""], ["Zhang", "Xikun", ""], ["Leskovec", "Jure", ""]]}, {"id": "1812.02303", "submitter": "Tian Shi", "authors": "Tian Shi, Yaser Keneshloo, Naren Ramakrishnan, Chandan K. Reddy", "title": "Neural Abstractive Text Summarization with Sequence-to-Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, neural abstractive text summarization with\nsequence-to-sequence (seq2seq) models have gained a lot of popularity. Many\ninteresting techniques have been proposed to improve seq2seq models, making\nthem capable of handling different challenges, such as saliency, fluency and\nhuman readability, and generate high-quality summaries. Generally speaking,\nmost of these techniques differ in one of these three categories: network\nstructure, parameter inference, and decoding/generation. There are also other\nconcerns, such as efficiency and parallelism for training a model. In this\npaper, we provide a comprehensive literature survey on different seq2seq models\nfor abstractive text summarization from the viewpoint of network structures,\ntraining strategies, and summary generation algorithms. Several models were\nfirst proposed for language modeling and generation tasks, such as machine\ntranslation, and later applied to abstractive text summarization. Hence, we\nalso provide a brief review of these models. As part of this survey, we also\ndevelop an open source library, namely, Neural Abstractive Text Summarizer\n(NATS) toolkit, for the abstractive text summarization. An extensive set of\nexperiments have been conducted on the widely used CNN/Daily Mail dataset to\nexamine the effectiveness of several different neural network components.\nFinally, we benchmark two models implemented in NATS on the two recently\nreleased datasets, namely, Newsroom and Bytecup.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 04:06:27 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 02:11:27 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 14:38:09 GMT"}, {"version": "v4", "created": "Fri, 18 Sep 2020 19:03:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Shi", "Tian", ""], ["Keneshloo", "Yaser", ""], ["Ramakrishnan", "Naren", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1812.02307", "submitter": "Mario Graff", "authors": "Mario Graff and Sabino Miranda-Jim\\'enez and Eric S. Tellez and\n  Daniela Moctezuma", "title": "EvoMSA: A Multilingual Evolutionary Approach for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": "10.1109/MCI.2019.2954668", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis (SA) is a task related to understanding people's feelings\nin written text; the starting point would be to identify the polarity level\n(positive, neutral or negative) of a given text, moving on to identify emotions\nor whether a text is humorous or not. This task has been the subject of several\nresearch competitions in a number of languages, e.g., English, Spanish, and\nArabic, among others. In this contribution, we propose an SA system, namely\nEvoMSA, that unifies our participating systems in various SA competitions,\nmaking it domain independent and multilingual by processing text using only\nlanguage-independent techniques. EvoMSA is a classifier, based on Genetic\nProgramming, that works by combining the output of different text classifiers\nand text models to produce the final prediction. We analyze EvoMSA on different\nSA competitions to provide a global overview of its performance, and as the\nresults show, EvoMSA is competitive obtaining top rankings in several SA\ncompetitions. Furthermore, we performed an analysis of EvoMSA's components to\nmeasure their contribution to the performance; the idea is to facilitate a\npractitioner or newcomer to implement a competitive SA classifier. Finally, it\nis worth to mention that EvoMSA is available as open-source software.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 23:33:59 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 03:12:40 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 18:10:24 GMT"}, {"version": "v4", "created": "Mon, 30 Sep 2019 16:52:27 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Graff", "Mario", ""], ["Miranda-Jim\u00e9nez", "Sabino", ""], ["Tellez", "Eric S.", ""], ["Moctezuma", "Daniela", ""]]}, {"id": "1812.02308", "submitter": "Jan Kremer", "authors": "Jan Kremer, Lasse Borgholt, Lars Maal{\\o}e", "title": "On the Inductive Bias of Word-Character-Level Multi-Task Learning for\n  Speech Recognition", "comments": "Accepted at the IRASL workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end automatic speech recognition (ASR) commonly transcribes audio\nsignals into sequences of characters while its performance is evaluated by\nmeasuring the word-error rate (WER). This suggests that predicting sequences of\nwords directly may be helpful instead. However, training with word-level\nsupervision can be more difficult due to the sparsity of examples per label\nclass. In this paper we analyze an end-to-end ASR model that combines a\nword-and-character representation in a multi-task learning (MTL) framework. We\nshow that it improves on the WER and study how the word-level model can benefit\nfrom character-level supervision by analyzing the learned inductive preference\nbias of each model component empirically. We find that by adding\ncharacter-level supervision, the MTL model interpolates between recognizing\nmore frequent words (preferred by the word-level model) and shorter words\n(preferred by the character-level model).\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 10:37:24 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Kremer", "Jan", ""], ["Borgholt", "Lasse", ""], ["Maal\u00f8e", "Lars", ""]]}, {"id": "1812.02309", "submitter": "Lina Fatima Soualmia", "authors": "Sa\\\"id Abdedda\\\"im, Sylvestre Vimard, Lina Fatima Soualmia", "title": "The MeSH-gram Neural Network Model: Extending Word Embedding Vectors\n  with MeSH Concepts for UMLS Semantic Similarity and Relatedness in the\n  Biomedical Domain", "comments": "6 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eliciting semantic similarity between concepts in the biomedical domain\nremains a challenging task. Recent approaches founded on embedding vectors have\ngained in popularity as they risen to efficiently capture semantic\nrelationships The underlying idea is that two words that have close meaning\ngather similar contexts. In this study, we propose a new neural network model\nnamed MeSH-gram which relies on a straighforward approach that extends the\nskip-gram neural network model by considering MeSH (Medical Subject Headings)\ndescriptors instead words. Trained on publicly available corpus PubMed MEDLINE,\nMeSH-gram is evaluated on reference standards manually annotated for semantic\nsimilarity. MeSH-gram is first compared to skip-gram with vectors of size 300\nand at several windows contexts. A deeper comparison is performed with tewenty\nexisting models. All the obtained results of Spearman's rank correlations\nbetween human scores and computed similarities show that MeSH-gram outperforms\nthe skip-gram model, and is comparable to the best methods but that need more\ncomputation and external resources.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 07:48:27 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Abdedda\u00efm", "Sa\u00efd", ""], ["Vimard", "Sylvestre", ""], ["Soualmia", "Lina Fatima", ""]]}, {"id": "1812.02310", "submitter": "Edouard Fournier", "authors": "Edouard Fournier (ENAC), St\\'ephane Grihon, Thierry Klein (IMT)", "title": "A case study : Influence of Dimension Reduction on regression\n  trees-based Algorithms -Predicting Aeronautics Loads of a Derivative Aircraft", "comments": null, "journal-ref": "Journal de la Societe Fran{\\c c}aise de Statistique, Societe\n  Fran{\\c c}aise de Statistique et Societe Mathematique de France, In press", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In aircraft industry, market needs evolve quickly in a high competitiveness\ncontext. This requires adapting a given aircraft model in minimum time\nconsidering for example an increase of range or the number of passengers (cf\nA330 NEO family). The computation of loads and stress to resize the airframe is\non the critical path of this aircraft variant definition: this is a consuming\nand costly process, one of the reason being the high dimen-sionality and the\nlarge amount of data. This is why Airbus has invested since a couple of years\nin Big Data approaches (statistic methods up to machine learning) to improve\nthe speed, the data value extraction and the responsiveness of this process.\nThis paper presents recent advances in this work made in cooperation between\nAirbus, ENAC and Institut de Math{\\'e}-matiques de Toulouse in the framework of\na proof of value sprint project. It compares the influence of three dimensional\nreduction techniques (PCA, polynomial fitting, combined) on the extrapolation\ncapabilities of Regression Trees based algorithms for loads prediction. It\nshows that AdaBoost with Random Forest offers promising results in average in\nterms of accuracy and computational time to estimate loads on which a PCA is\napplied only on the outputs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 16:14:31 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Fournier", "Edouard", "", "ENAC"], ["Grihon", "St\u00e9phane", "", "IMT"], ["Klein", "Thierry", "", "IMT"]]}, {"id": "1812.02320", "submitter": "Matthew Hirn", "authors": "Xavier Brumwell and Paul Sinz and Kwang Jin Kim and Yue Qi and Matthew\n  Hirn", "title": "Steerable Wavelet Scattering for 3D Atomic Systems with Application to\n  Li-Si Energy Prediction", "comments": "NIPS 2018 Workshop on Machine Learning for Molecules and Materials,\n  Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general machine learning architecture is introduced that uses wavelet\nscattering coefficients of an inputted three dimensional signal as features.\nSolid harmonic wavelet scattering transforms of three dimensional signals were\npreviously introduced in a machine learning framework for the regression of\nproperties of small organic molecules. Here this approach is extended for\ngeneral steerable wavelets which are equivariant to translations and rotations,\nresulting in a sparse model of the target function. The scattering coefficients\ninherit from the wavelets invariance to translations and rotations. As an\nillustration of this approach a linear regression model is learned for the\nformation energy of amorphous lithium-silicon material states trained over a\ndatabase generated using plane-wave Density Functional Theory methods.\nState-of-the-art results are produced as compared to other machine learning\napproaches over similarly generated databases.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 14:50:37 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 22:33:59 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Brumwell", "Xavier", ""], ["Sinz", "Paul", ""], ["Kim", "Kwang Jin", ""], ["Qi", "Yue", ""], ["Hirn", "Matthew", ""]]}, {"id": "1812.02327", "submitter": "Amir Babaeian", "authors": "Amir Babaeian", "title": "Multiple Manifold Clustering Using Curvature Constrained Path", "comments": "arXiv admin note: text overlap with arXiv:1802.07416; text overlap\n  with arXiv:1509.00947 by other authors", "journal-ref": "ICIP 2015", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of multiple surface clustering is a challenging task,\nparticularly when the surfaces intersect. Available methods such as Isomap fail\nto capture the true shape of the surface nearby the intersection and result in\nincorrect clustering. The Isomap algorithm uses the shortest path between\npoints. The main draw back of the shortest path algorithm is due to the lack of\ncurvature constrained where causes to have a path between points on different\nsurfaces. In this paper, we tackle this problem by imposing a curvature\nconstraint to the shortest path algorithm used in Isomap. The algorithm chooses\nseveral landmark nodes at random and then checks whether there is a curvature\nconstrained path between each landmark node and every other node in the\nneighbourhood graph. We build a binary feature vector for each point where each\nentry represents the connectivity of that point to a particular landmark. Then\nthe binary feature vectors could be used as an input of conventional clustering\nalgorithm such as hierarchical clustering. We apply our method to simulated and\nsome real datasets and show, it performs comparably to the best methods such as\nK-manifold and spectral multi-manifold clustering.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 23:45:58 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Babaeian", "Amir", ""]]}, {"id": "1812.02335", "submitter": "Lida Zhang", "authors": "Lida Zhang and Abdolghani Ebrahimi and Diego Klabjan", "title": "Layer Flexible Adaptive Computational Time", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep recurrent neural networks perform well on sequence data and are the\nmodel of choice. However, it is a daunting task to decide the structure of the\nnetworks, i.e. the number of layers, especially considering different\ncomputational needs of a sequence. We propose a layer flexible recurrent neural\nnetwork with adaptive computation time, and expand it to a sequence to sequence\nmodel. Different from the adaptive computation time model, our model has a\ndynamic number of transmission states which vary by step and sequence. We\nevaluate the model on a financial data set and Wikipedia language modeling.\nExperimental results show the performance improvement of 7\\% to 12\\% and\nindicate the model's ability to dynamically change the number of layers along\nwith the computational steps.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 03:25:09 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 20:36:00 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2019 02:47:38 GMT"}, {"version": "v4", "created": "Tue, 21 May 2019 22:35:08 GMT"}, {"version": "v5", "created": "Mon, 4 Jan 2021 16:48:00 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhang", "Lida", ""], ["Ebrahimi", "Abdolghani", ""], ["Klabjan", "Diego", ""]]}, {"id": "1812.02340", "submitter": "Daniel Philps", "authors": "Daniel Philps, Tillman Weyde, Artur d'Avila Garcez, Roy Batchelor", "title": "Continual Learning Augmented Investment Decisions", "comments": "NeurIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services: the Impact of Fairness, Explainability, Accuracy, and\n  Privacy, Montreal, Canada. This is a non-archival publication - the authors\n  may submit revisions and extensions of this paper to other publication venues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.CP q-fin.PM q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investment decisions can benefit from incorporating an accumulated knowledge\nof the past to drive future decision making. We introduce Continual Learning\nAugmentation (CLA) which is based on an explicit memory structure and a feed\nforward neural network (FFNN) base model and used to drive long term financial\ninvestment decisions. We demonstrate that our approach improves accuracy in\ninvestment decision making while memory is addressed in an explainable way. Our\napproach introduces novel remember cues, consisting of empirically learned\nchange points in the absolute error series of the FFNN. Memory recall is also\nnovel, with contextual similarity assessed over time by sampling distances\nusing dynamic time warping (DTW). We demonstrate the benefits of our approach\nby using it in an expected return forecasting task to drive investment\ndecisions. In an investment simulation in a broad international equity universe\nbetween 2003-2017, our approach significantly outperforms FFNN base models. We\nalso illustrate how CLA's memory addressing works in practice, using a worked\nexample to demonstrate the explainability of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 04:26:25 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 17:26:47 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 10:19:57 GMT"}, {"version": "v4", "created": "Fri, 25 Jan 2019 09:51:52 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Philps", "Daniel", ""], ["Weyde", "Tillman", ""], ["Garcez", "Artur d'Avila", ""], ["Batchelor", "Roy", ""]]}, {"id": "1812.02341", "submitter": "Karl Cobbe", "authors": "Karl Cobbe, Oleg Klimov, Chris Hesse, Taehoon Kim, John Schulman", "title": "Quantifying Generalization in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of overfitting in deep\nreinforcement learning. Among the most common benchmarks in RL, it is customary\nto use the same environments for both training and testing. This practice\noffers relatively little insight into an agent's ability to generalize. We\naddress this issue by using procedurally generated environments to construct\ndistinct training and test sets. Most notably, we introduce a new environment\ncalled CoinRun, designed as a benchmark for generalization in RL. Using\nCoinRun, we find that agents overfit to surprisingly large training sets. We\nthen show that deeper convolutional architectures improve generalization, as do\nmethods traditionally found in supervised learning, including L2\nregularization, dropout, data augmentation and batch normalization.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 04:29:29 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 19:23:00 GMT"}, {"version": "v3", "created": "Sun, 14 Jul 2019 17:49:51 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Cobbe", "Karl", ""], ["Klimov", "Oleg", ""], ["Hesse", "Chris", ""], ["Kim", "Taehoon", ""], ["Schulman", "John", ""]]}, {"id": "1812.02353", "submitter": "Minmin Chen", "authors": "Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois\n  Belletti, Ed Chi", "title": "Top-K Off-Policy Correction for a REINFORCE Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Industrial recommender systems deal with extremely large action spaces --\nmany millions of items to recommend. Moreover, they need to serve billions of\nusers, who are unique at any point in time, making a complex user state space.\nLuckily, huge quantities of logged implicit feedback (e.g., user clicks, dwell\ntime) are available for learning. Learning from the logged feedback is however\nsubject to biases caused by only observing feedback on recommendations selected\nby the previous versions of the recommender. In this work, we present a general\nrecipe of addressing such biases in a production top-K recommender system at\nYoutube, built with a policy-gradient-based algorithm, i.e. REINFORCE. The\ncontributions of the paper are: (1) scaling REINFORCE to a production\nrecommender system with an action space on the orders of millions; (2) applying\noff-policy correction to address data biases in learning from logged feedback\ncollected from multiple behavior policies; (3) proposing a novel top-K\noff-policy correction to account for our policy recommending multiple items at\na time; (4) showcasing the value of exploration. We demonstrate the efficacy of\nour approaches through a series of simulations and multiple live experiments on\nYoutube.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 05:10:27 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 01:09:30 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chen", "Minmin", ""], ["Beutel", "Alex", ""], ["Covington", "Paul", ""], ["Jain", "Sagar", ""], ["Belletti", "Francois", ""], ["Chi", "Ed", ""]]}, {"id": "1812.02356", "submitter": "Sedigheh Mahdavi", "authors": "Sedigheh Mahdavi, Shima Khoshraftar and Aijun An", "title": "dynnode2vec: Scalable Dynamic Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning in low dimensional vector space has attracted\nconsiderable attention in both academic and industrial domains. Most real-world\nnetworks are dynamic with addition/deletion of nodes and edges. The existing\ngraph embedding methods are designed for static networks and they cannot\ncapture evolving patterns in a large dynamic network. In this paper, we propose\na dynamic embedding method, dynnode2vec, based on the well-known graph\nembedding method node2vec. Node2vec is a random walk based embedding method for\nstatic networks. Applying static network embedding in dynamic settings has two\ncrucial problems: 1) Generating random walks for every time step is time\nconsuming 2) Embedding vector spaces in each timestamp are different. In order\nto tackle these challenges, dynnode2vec uses evolving random walks and\ninitializes the current graph embedding with previous embedding vectors. We\ndemonstrate the advantages of the proposed dynamic network embedding by\nconducting empirical evaluations on several large dynamic network datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 05:30:02 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 04:06:09 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Mahdavi", "Sedigheh", ""], ["Khoshraftar", "Shima", ""], ["An", "Aijun", ""]]}, {"id": "1812.02395", "submitter": "Takayuki Katsuki", "authors": "Takayuki Katsuki, Takayuki Osogami, Akira Koseki, Masaki Ono,\n  Michiharu Kudo, Masaki Makino, Atsushi Suzuki", "title": "Time-Discounting Convolution for Event Sequences with Ambiguous\n  Timestamps", "comments": "18th IEEE International Conference on Data Mining (ICDM 2018)", "journal-ref": null, "doi": "10.1109/ICDM.2018.00139", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for modeling event sequences with ambiguous\ntimestamps, a time-discounting convolution. Unlike in ordinary time series,\ntime intervals are not constant, small time-shifts have no significant effect,\nand inputting timestamps or time durations into a model is not effective. The\ncriteria that we require for the modeling are providing robustness against\ntime-shifts or timestamps uncertainty as well as maintaining the essential\ncapabilities of time-series models, i.e., forgetting meaningless past\ninformation and handling infinite sequences. The proposed method handles them\nwith a convolutional mechanism across time with specific parameterizations,\nwhich efficiently represents the event dependencies in a time-shift invariant\nmanner while discounting the effect of past events, and a dynamic pooling\nmechanism, which provides robustness against the uncertainty in timestamps and\nenhances the time-discounting capability by dynamically changing the pooling\nwindow size. In our learning algorithm, the decaying and dynamic pooling\nmechanisms play critical roles in handling infinite and variable length\nsequences. Numerical experiments on real-world event sequences with ambiguous\ntimestamps and ordinary time series demonstrated the advantages of our method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 08:14:57 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Katsuki", "Takayuki", ""], ["Osogami", "Takayuki", ""], ["Koseki", "Akira", ""], ["Ono", "Masaki", ""], ["Kudo", "Michiharu", ""], ["Makino", "Masaki", ""], ["Suzuki", "Atsushi", ""]]}, {"id": "1812.02407", "submitter": "Siddharth Pramod", "authors": "Siddharth Pramod", "title": "Elastic Gossip: Distributing Neural Network Training Using Gossip-like\n  Protocols", "comments": "M.S. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributing Neural Network training is of particular interest for several\nreasons including scaling using computing clusters, training at data sources\nsuch as IOT devices and edge servers, utilizing underutilized resources across\nheterogeneous environments, and so on. Most contemporary approaches primarily\naddress scaling using computing clusters and require high network bandwidth and\nfrequent communication. This thesis presents an overview of standard approaches\nto distribute training and proposes a novel technique involving\npairwise-communication using Gossip-like protocols, called Elastic Gossip. This\napproach builds upon an existing technique known as Elastic Averaging SGD\n(EASGD), and is similar to another technique called Gossiping SGD which also\nuses Gossip-like protocols. Elastic Gossip is empirically evaluated against\nGossiping SGD using the MNIST digit recognition and CIFAR-10 classification\ntasks, using commonly used Neural Network architectures spanning Multi-Layer\nPerceptrons (MLPs) and Convolutional Neural Networks (CNNs). It is found that\nElastic Gossip, Gossiping SGD, and All-reduce SGD perform quite comparably,\neven though the latter entails a substantially higher communication cost. While\nElastic Gossip performs better than Gossiping SGD in these experiments, it is\npossible that a more thorough search over hyper-parameter space, specific to a\ngiven application, may yield configurations of Gossiping SGD that work better\nthan Elastic Gossip.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 09:00:34 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Pramod", "Siddharth", ""]]}, {"id": "1812.02463", "submitter": "Jayant Sen Gupta", "authors": "Ilyass Haloui and Jayant Sen Gupta and Vincent Feuillard", "title": "Anomaly detection with Wasserstein GAN", "comments": "Based on Ilyass Haloui internship report. arXiv admin note: text\n  overlap with arXiv:1701.07875, arXiv:1406.2661 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks are a class of generative algorithms that\nhave been widely used to produce state-of-the-art samples. In this paper, we\ninvestigate GAN to perform anomaly detection on time series dataset. In order\nto achieve this goal, a bibliography is made focusing on theoretical properties\nof GAN and GAN used for anomaly detection. A Wasserstein GAN has been chosen to\nlearn the representation of normal data distribution and a stacked encoder with\nthe generator performs the anomaly detection. W-GAN with encoder seems to\nproduce state of the art anomaly detection scores on MNIST dataset and we\ninvestigate its usage on multi-variate time series.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 11:17:48 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 08:43:30 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Haloui", "Ilyass", ""], ["Gupta", "Jayant Sen", ""], ["Feuillard", "Vincent", ""]]}, {"id": "1812.02497", "submitter": "Oznur Tastan", "authors": "Cem Orhan and Oznur Tastan", "title": "Active Learning Methods based on Statistical Leverage Scores", "comments": "Submitted to Machine Learning Journal, EMLP 2019 journal track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world machine learning applications, unlabeled data are abundant\nwhereas class labels are expensive and scarce. An active learner aims to obtain\na model of high accuracy with as few labeled instances as possible by\neffectively selecting useful examples for labeling. We propose a new selection\ncriterion that is based on statistical leverage scores and present two novel\nactive learning methods based on this criterion: ALEVS for querying single\nexample at each iteration and DBALEVS for querying a batch of examples. To\nassess the representativeness of the examples in the pool, ALEVS and DBALEVS\nuse the statistical leverage scores of the kernel matrices computed on the\nexamples of each class. Additionally, DBALEVS selects a diverse a set of\nexamples that are highly representative but are dissimilar to already labeled\nexamples through maximizing a submodular set function defined with the\nstatistical leverage scores and the kernel matrix computed on the pool of the\nexamples. The submodularity property of the set scoring function let us\nidentify batches with a constant factor approximate to the optimal batch in an\nefficient manner. Our experiments on diverse datasets show that querying based\non leverage scores is a powerful strategy for active learning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 12:38:22 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Orhan", "Cem", ""], ["Tastan", "Oznur", ""]]}, {"id": "1812.02538", "submitter": "Michal Kozlowski", "authors": "Michal Kozlowski and Ryan McConville and Raul Santos-Rodriguez and\n  Robert Piechocki", "title": "Energy Efficiency in Reinforcement Learning for Wireless Sensor Networks", "comments": "This paper was accepted on 30/07/2018 and presented at the ECML-PKDD\n  Workshop Green Data Mining 2018 on 14/09/2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As sensor networks for health monitoring become more prevalent, so will the\nneed to control their usage and consumption of energy. This paper presents a\nmethod which leverages the algorithm's performance and energy consumption. By\nutilising Reinforcement Learning (RL) techniques, we provide an adaptive\nframework, which continuously performs weak training in an energy-aware system.\nWe motivate this using a realistic example of residential localisation based on\nReceived Signal Strength (RSS). The method is cheap in terms of work-hours,\ncalibration and energy usage. It achieves this by utilising other sensors\navailable in the environment. These other sensors provide weak labels, which\nare then used to employ the State-Action-Reward-State-Action (SARSA) algorithm\nand train the model over time. Our approach is evaluated on a simulated\nlocalisation environment and validated on a widely available pervasive health\ndataset which facilitates realistic residential localisation using RSS. We show\nthat our method is cheaper to implement and requires less effort, whilst at the\nsame time providing a performance enhancement and energy savings over time.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 09:42:37 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Kozlowski", "Michal", ""], ["McConville", "Ryan", ""], ["Santos-Rodriguez", "Raul", ""], ["Piechocki", "Robert", ""]]}, {"id": "1812.02546", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni, Brian Stone", "title": "A two-stage hybrid model by using artificial neural networks as feature\n  construction algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-stage hybrid approach with neural networks as the new\nfeature construction algorithms for bankcard response classifications. The\nhybrid model uses a very simple neural network structure as the new feature\nconstruction tool in the first stage, then the newly created features are used\nas the additional input variables in logistic regression in the second stage.\nThe model is compared with the traditional one-stage model in credit customer\nresponse classification. It is observed that the proposed two-stage model\noutperforms the one-stage model in terms of accuracy, the area under ROC curve,\nand KS statistic. By creating new features with the neural network technique,\nthe underlying nonlinear relationships between variables are identified.\nFurthermore, by using a very simple neural network structure, the model could\novercome the drawbacks of neural networks in terms of its long training time,\ncomplex topology, and limited interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 14:26:42 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""], ["Stone", "Brian", ""]]}, {"id": "1812.02566", "submitter": "S\\\"oren Dittmer", "authors": "S\\\"oren Dittmer, Emily J. King, Peter Maass", "title": "Singular Values for ReLU Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their prevalence in neural networks we still lack a thorough\ntheoretical characterization of ReLU layers. This paper aims to further our\nunderstanding of ReLU layers by studying how the activation function ReLU\ninteracts with the linear component of the layer and what role this interaction\nplays in the success of the neural network in achieving its intended task. To\nthis end, we introduce two new tools: ReLU singular values of operators and the\nGaussian mean width of operators. By presenting on the one hand theoretical\njustifications, results, and interpretations of these two concepts and on the\nother hand numerical experiments and results of the ReLU singular values and\nthe Gaussian mean width being applied to trained neural networks, we hope to\ngive a comprehensive, singular-value-centric view of ReLU layers. We find that\nReLU singular values and the Gaussian mean width do not only enable theoretical\ninsights, but also provide one with metrics which seem promising for practical\napplications. In particular, these measures can be used to distinguish\ncorrectly and incorrectly classified data as it traverses the network. We\nconclude by introducing two tools based on our findings: double-layers and\nharmonic pruning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 14:48:56 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 13:17:27 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dittmer", "S\u00f6ren", ""], ["King", "Emily J.", ""], ["Maass", "Peter", ""]]}, {"id": "1812.02575", "submitter": "Andrey Malinin", "authors": "Andrey Malinin and Mark Gales", "title": "Prior Networks for Detection of Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are considered a serious issue for safety critical\napplications of AI, such as finance, autonomous vehicle control and medicinal\napplications. Though significant work has resulted in increased robustness of\nsystems to these attacks, systems are still vulnerable to well-crafted attacks.\nTo address this problem, several adversarial attack detection methods have been\nproposed. However, a system can still be vulnerable to adversarial samples that\nare designed to specifically evade these detection methods. One recent\ndetection scheme that has shown good performance is based on uncertainty\nestimates derived from Monte-Carlo dropout ensembles. Prior Networks, a new\nmethod of estimating predictive uncertainty, has been shown to outperform\nMonte-Carlo dropout on a range of tasks. One of the advantages of this approach\nis that the behaviour of a Prior Network can be explicitly tuned to, for\nexample, predict high uncertainty in regions where there are no training data\nsamples. In this work, Prior Networks are applied to adversarial attack\ndetection using measures of uncertainty in a similar fashion to Monte-Carlo\nDropout. Detection based on measures of uncertainty derived from DNNs and\nMonte-Carlo dropout ensembles are used as a baseline. Prior Networks are shown\nto significantly out-perform these baseline approaches over a range of\nadversarial attacks in both detection of whitebox and blackbox configurations.\nEven when the adversarial attacks are constructed with full knowledge of the\ndetection mechanism, it is shown to be highly challenging to successfully\ngenerate an adversarial sample.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 14:59:29 GMT"}], "update_date": "2018-12-08", "authors_parsed": [["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "1812.02598", "submitter": "Danilo Bzdok", "authors": "Hao-Ting Wang, Jonathan Smallwood, Janaina Mourao-Miranda, Cedric\n  Huchuan Xia, Theodore D. Satterthwaite, Danielle S. Bassett, Danilo Bzdok", "title": "Finding the needle in high-dimensional haystack: A tutorial on canonical\n  correlation analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the beginning of the 21st century, the size, breadth, and granularity\nof data in biology and medicine has grown rapidly. In the example of\nneuroscience, studies with thousands of subjects are becoming more common,\nwhich provide extensive phenotyping on the behavioral, neural, and genomic\nlevel with hundreds of variables. The complexity of such big data repositories\noffer new opportunities and pose new challenges to investigate brain,\ncognition, and disease. Canonical correlation analysis (CCA) is a prototypical\nfamily of methods for wrestling with and harvesting insight from such rich\ndatasets. This doubly-multivariate tool can simultaneously consider two\nvariable sets from different modalities to uncover essential hidden\nassociations. Our primer discusses the rationale, promises, and pitfalls of CCA\nin biomedicine.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 15:17:06 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Wang", "Hao-Ting", ""], ["Smallwood", "Jonathan", ""], ["Mourao-Miranda", "Janaina", ""], ["Xia", "Cedric Huchuan", ""], ["Satterthwaite", "Theodore D.", ""], ["Bassett", "Danielle S.", ""], ["Bzdok", "Danilo", ""]]}, {"id": "1812.02616", "submitter": "Radha Kopparti", "authors": "Tillman Weyde and Radha Manisha Kopparti", "title": "Modelling Identity Rules with Neural Networks", "comments": "To be Published in Journal of Applied Logic", "journal-ref": "Journal of applied logics (Online) ISSN 2631-9829 Volume 6, Number\n  4, June 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we show that standard feed-forward and recurrent neural\nnetworks fail to learn abstract patterns based on identity rules. We propose\nRelation Based Pattern (RBP) extensions to neural network structures that solve\nthis problem and answer, as well as raise, questions about integrating\nstructures for inductive bias into neural networks. Examples of abstract\npatterns are the sequence patterns ABA and ABB where A or B can be any object.\nThese were introduced by Marcus et al (1999) who also found that 7 month old\ninfants recognise these patterns in sequences that use an unfamiliar vocabulary\nwhile simple recurrent neural networks do not.This result has been contested in\nthe literature but it is confirmed by our experiments. We also show that the\ninability to generalise extends to different, previously untested, settings. We\npropose a new approach to modify standard neural network architectures, called\nRelation Based Patterns (RBP) with different variants for classification and\nprediction. Our experiments show that neural networks with the appropriate RBP\nstructure achieve perfect classification and prediction performance on\nsynthetic data, including mixed concrete and abstract patterns. RBP also\nimproves neural network performance in experiments with real-world sequence\nprediction tasks. We discuss these finding in terms of challenges for neural\nnetwork models and identify consequences from this result in terms of\ndeveloping inductive biases for neural network learning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 15:46:05 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 15:46:16 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Weyde", "Tillman", ""], ["Kopparti", "Radha Manisha", ""]]}, {"id": "1812.02618", "submitter": "Hojjat Rakhshani", "authors": "Hojjat Rakhshani, Lhassane Idoumghar, Julien Lepagnot, Mathieu\n  Brevilliers, Edward Keedwell", "title": "Automatic hyperparameter selection in Autodock", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autodock is a widely used molecular modeling tool which predicts how small\nmolecules bind to a receptor of known 3D structure. The current version of\nAutoDock uses meta-heuristic algorithms in combination with local search\nmethods for doing the conformation search. Appropriate settings of\nhyperparameters in these algorithms are important, particularly for novice\nusers who often find it hard to identify the best configuration. In this work,\nwe design a surrogate based multi-objective algorithm to help such users by\nautomatically tuning hyperparameter settings. The proposed method iteratively\nuses a radial basis function model and non-dominated sorting to evaluate the\nsampled configurations during the search phase. Our experimental results using\nAutodock show that the introduced component is practical and effective.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 21:24:10 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Rakhshani", "Hojjat", ""], ["Idoumghar", "Lhassane", ""], ["Lepagnot", "Julien", ""], ["Brevilliers", "Mathieu", ""], ["Keedwell", "Edward", ""]]}, {"id": "1812.02622", "submitter": "Jenn-Bing Ong", "authors": "Jenn-Bing Ong, Wee-Keong Ng, C.-C. Jay Kuo", "title": "Convolutional Neural Networks with Transformed Input based on Robust\n  Tensor Network Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor network decomposition, originated from quantum physics to model\nentangled many-particle quantum systems, turns out to be a promising\nmathematical technique to efficiently represent and process big data in\nparsimonious manner. In this study, we show that tensor networks can\nsystematically partition structured data, e.g. color images, for distributed\nstorage and communication in privacy-preserving manner. Leveraging the sea of\nbig data and metadata privacy, empirical results show that neighbouring\nsubtensors with implicit information stored in tensor network formats cannot be\nidentified for data reconstruction. This technique complements the existing\nencryption and randomization techniques which store explicit data\nrepresentation at one place and highly susceptible to adversarial attacks such\nas side-channel attacks and de-anonymization. Furthermore, we propose a theory\nfor adversarial examples that mislead convolutional neural networks to\nmisclassification using subspace analysis based on singular value decomposition\n(SVD). The theory is extended to analyze higher-order tensors using\ntensor-train SVD (TT-SVD); it helps to explain the level of susceptibility of\ndifferent datasets to adversarial attacks, the structural similarity of\ndifferent adversarial attacks including global and localized attacks, and the\nefficacy of different adversarial defenses based on input transformation. An\nefficient and adaptive algorithm based on robust TT-SVD is then developed to\ndetect strong and static adversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 10:57:25 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 10:24:34 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ong", "Jenn-Bing", ""], ["Ng", "Wee-Keong", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1812.02632", "submitter": "Si-An Chen", "authors": "Si-An Chen, Voot Tangkaratt, Hsuan-Tien Lin, Masashi Sugiyama", "title": "Active Deep Q-learning with Demonstration", "comments": null, "journal-ref": "Mach Learn 109, 1699-1725 (2020)", "doi": "10.1007/s10994-019-05849-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that although Reinforcement Learning (RL) can\nbenefit from expert demonstration, it usually takes considerable efforts to\nobtain enough demonstration. The efforts prevent training decent RL agents with\nexpert demonstration in practice. In this work, we propose Active Reinforcement\nLearning with Demonstration (ARLD), a new framework to streamline RL in terms\nof demonstration efforts by allowing the RL agent to query for demonstration\nactively during training. Under the framework, we propose Active Deep\nQ-Network, a novel query strategy which adapts to the dynamically-changing\ndistributions during the RL training process by estimating the uncertainty of\nrecent states. The expert demonstration data within Active DQN are then\nutilized by optimizing supervised max-margin loss in addition to temporal\ndifference loss within usual DQN training. We propose two methods of estimating\nthe uncertainty based on two state-of-the-art DQN models, namely the divergence\nof bootstrapped DQN and the variance of noisy DQN. The empirical results\nvalidate that both methods not only learn faster than other passive expert\ndemonstration methods with the same amount of demonstration and but also reach\nsuper-expert level of performance across four different tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 16:13:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Chen", "Si-An", ""], ["Tangkaratt", "Voot", ""], ["Lin", "Hsuan-Tien", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1812.02633", "submitter": "Pierre-Alexandre Mattei", "authors": "Pierre-Alexandre Mattei and Jes Frellsen", "title": "MIWAE: Deep Generative Modelling and Imputation of Incomplete Data", "comments": "A short version of this paper was presented at the 3rd NeurIPS\n  workshop on Bayesian Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of handling missing data with deep latent variable\nmodels (DLVMs). First, we present a simple technique to train DLVMs when the\ntraining set contains missing-at-random data. Our approach, called MIWAE, is\nbased on the importance-weighted autoencoder (IWAE), and maximises a\npotentially tight lower bound of the log-likelihood of the observed data.\nCompared to the original IWAE, our algorithm does not induce any additional\ncomputational overhead due to the missing data. We also develop Monte Carlo\ntechniques for single and multiple imputation using a DLVM trained on an\nincomplete data set. We illustrate our approach by training a convolutional\nDLVM on a static binarisation of MNIST that contains 50% of missing pixels.\nLeveraging multiple imputation, a convolutional network trained on these\nincomplete digits has a test performance similar to one trained on complete\ndata. On various continuous and binary data sets, we also show that MIWAE\nprovides accurate single imputations, and is highly competitive with\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 16:14:17 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 18:06:43 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Mattei", "Pierre-Alexandre", ""], ["Frellsen", "Jes", ""]]}, {"id": "1812.02637", "submitter": "Gavin Weiguang Ding", "authors": "Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, and Ruitong Huang", "title": "MMA Training: Direct Input Space Margin Maximization through Adversarial\n  Training", "comments": "Published at the Eighth International Conference on Learning\n  Representations (ICLR 2020), https://openreview.net/forum?id=HkeryxBtPB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial robustness of neural networks from a margin maximization\nperspective, where margins are defined as the distances from inputs to a\nclassifier's decision boundary. Our study shows that maximizing margins can be\nachieved by minimizing the adversarial loss on the decision boundary at the\n\"shortest successful perturbation\", demonstrating a close connection between\nadversarial losses and the margins. We propose Max-Margin Adversarial (MMA)\ntraining to directly maximize the margins to achieve adversarial robustness.\nInstead of adversarial training with a fixed $\\epsilon$, MMA offers an\nimprovement by enabling adaptive selection of the \"correct\" $\\epsilon$ as the\nmargin individually for each datapoint. In addition, we rigorously analyze\nadversarial training with the perspective of margin maximization, and provide\nan alternative interpretation for adversarial training, maximizing either a\nlower or an upper bound of the margins. Our experiments empirically confirm our\ntheory and demonstrate MMA training's efficacy on the MNIST and CIFAR10\ndatasets w.r.t. $\\ell_\\infty$ and $\\ell_2$ robustness. Code and models are\navailable at https://github.com/BorealisAI/mma_training.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 16:15:52 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 21:51:13 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 14:07:17 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 19:58:33 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ding", "Gavin Weiguang", ""], ["Sharma", "Yash", ""], ["Lui", "Kry Yik Chau", ""], ["Huang", "Ruitong", ""]]}, {"id": "1812.02682", "submitter": "Alexander Alemi", "authors": "Emily Fertig, Aryan Arbabi, Alexander A. Alemi", "title": "$\\beta$-VAEs can retain label information even at high compression", "comments": "NeurIPS2018, BDL workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the degree to which the encoding of a\n$\\beta$-VAE captures label information across multiple architectures on Binary\nStatic MNIST and Omniglot. Even though they are trained in a completely\nunsupervised manner, we demonstrate that a $\\beta$-VAE can retain a large\namount of label information, even when asked to learn a highly compressed\nrepresentation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 17:35:19 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Fertig", "Emily", ""], ["Arbabi", "Aryan", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "1812.02690", "submitter": "Karan Singh", "authors": "Elad Hazan, Sham M. Kakade, Karan Singh, Abby Van Soest", "title": "Provably Efficient Maximum Entropy Exploration", "comments": "Updated experiment results; minor revisions in writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose an agent is in a (possibly unknown) Markov Decision Process in the\nabsence of a reward signal, what might we hope that an agent can efficiently\nlearn to do? This work studies a broad class of objectives that are defined\nsolely as functions of the state-visitation frequencies that are induced by how\nthe agent behaves. For example, one natural, intrinsically defined, objective\nproblem is for the agent to learn a policy which induces a distribution over\nstate space that is as uniform as possible, which can be measured in an\nentropic sense. We provide an efficient algorithm to optimize such such\nintrinsically defined objectives, when given access to a black box planning\noracle (which is robust to function approximation). Furthermore, when\nrestricted to the tabular setting where we have sample based access to the MDP,\nour proposed algorithm is provably efficient, both in terms of its sample and\ncomputational complexities. Key to our algorithmic methodology is utilizing the\nconditional gradient method (a.k.a. the Frank-Wolfe algorithm) which utilizes\nan approximate MDP solver.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:15:44 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 01:54:32 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Hazan", "Elad", ""], ["Kakade", "Sham M.", ""], ["Singh", "Karan", ""], ["Van Soest", "Abby", ""]]}, {"id": "1812.02696", "submitter": "Saeed Sharifi-Malvajerdi", "authors": "Matthew Jagielski, Michael Kearns, Jieming Mao, Alina Oprea, Aaron\n  Roth, Saeed Sharifi-Malvajerdi, Jonathan Ullman", "title": "Differentially Private Fair Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by settings in which predictive models may be required to be\nnon-discriminatory with respect to certain attributes (such as race), but even\ncollecting the sensitive attribute may be forbidden or restricted, we initiate\nthe study of fair learning under the constraint of differential privacy. We\ndesign two learning algorithms that simultaneously promise differential privacy\nand equalized odds, a 'fairness' condition that corresponds to equalizing false\npositive and negative rates across protected groups. Our first algorithm is a\nprivate implementation of the equalized odds post-processing approach of [Hardt\net al., 2016]. This algorithm is appealingly simple, but must be able to use\nprotected group membership explicitly at test time, which can be viewed as a\nform of 'disparate treatment'. Our second algorithm is a differentially private\nversion of the oracle-efficient in-processing approach of [Agarwal et al.,\n2018] that can be used to find the optimal fair classifier, given access to a\nsubroutine that can solve the original (not necessarily fair) learning problem.\nThis algorithm is more complex but need not have access to protected group\nmembership at test time. We identify new tradeoffs between fairness, accuracy,\nand privacy that emerge only when requiring all three properties, and show that\nthese tradeoffs can be milder if group membership may be used at test time. We\nconclude with a brief experimental evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:24:52 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 16:19:19 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 18:01:49 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Jagielski", "Matthew", ""], ["Kearns", "Michael", ""], ["Mao", "Jieming", ""], ["Oprea", "Alina", ""], ["Roth", "Aaron", ""], ["Sharifi-Malvajerdi", "Saeed", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1812.02706", "submitter": "Wujie Wang", "authors": "Wujie Wang, Rafael G\\'omez-Bombarelli", "title": "Coarse-Graining Auto-Encoders for Molecular Dynamics", "comments": "8 pages, 6 figures", "journal-ref": "npj Comput Mater 5, 125 (2019)", "doi": "10.1038/s41524-019-0261-5", "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular dynamics simulations provide theoretical insight into the\nmicroscopic behavior of materials in condensed phase and, as a predictive tool,\nenable computational design of new compounds. However, because of the large\ntemporal and spatial scales involved in thermodynamic and kinetic phenomena in\nmaterials, atomistic simulations are often computationally unfeasible.\nCoarse-graining methods allow simulating larger systems, by reducing the\ndimensionality of the simulation, and propagating longer timesteps, by\naveraging out fast motions. Coarse-graining involves two coupled learning\nproblems; defining the mapping from an all-atom to a reduced representation,\nand the parametrization of a Hamiltonian over coarse-grained coordinates.\nMultiple statistical mechanics approaches have addressed the latter, but the\nformer is generally a hand-tuned process based on chemical intuition. Here we\npresent Autograin, an optimization framework based on auto-encoders to learn\nboth tasks simultaneously. Autograin is trained to learn the optimal mapping\nbetween all-atom and reduced representation, using the reconstruction loss to\nfacilitate the learning of coarse-grained variables. In addition, a\nforce-matching method is applied to variationally determine the coarse-grained\npotential energy function. This procedure is tested on a number of model\nsystems including single-molecule and bulk-phase periodic simulations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:42:14 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 15:52:12 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Wang", "Wujie", ""], ["G\u00f3mez-Bombarelli", "Rafael", ""]]}, {"id": "1812.02709", "submitter": "Sotirios Sabanis", "authors": "M. Barkhagen, N. H. Chau, \\'E. Moulines, M. R\\'asonyi, S. Sabanis, Y.\n  Zhang", "title": "On stochastic gradient Langevin dynamics with dependent data streams in\n  the logconcave case", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sampling from a probability distribution $\\pi$ on\n$\\rset^d$ which has a density \\wrt\\ the Lebesgue measure known up to a\nnormalization factor $x \\mapsto \\rme^{-U(x)} / \\int_{\\rset^d} \\rme^{-U(y)} \\rmd\ny$. We analyze a sampling method based on the Euler discretization of the\nLangevin stochastic differential equations under the assumptions that the\npotential $U$ is continuously differentiable, $\\nabla U$ is Lipschitz, and $U$\nis strongly concave. We focus on the case where the gradient of the log-density\ncannot be directly computed but unbiased estimates of the gradient from\npossibly dependent observations are available. This setting can be seen as a\ncombination of a stochastic approximation (here stochastic gradient) type\nalgorithms with discretized Langevin dynamics. We obtain an upper bound of the\nWasserstein-2 distance between the law of the iterates of this algorithm and\nthe target distribution $\\pi$ with constants depending explicitly on the\nLipschitz and strong convexity constants of the potential and the dimension of\nthe space. Finally, under weaker assumptions on $U$ and its gradient but in the\npresence of independent observations, we obtain analogous results in\nWasserstein-2 distance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:42:28 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 20:59:35 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 15:58:09 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Barkhagen", "M.", ""], ["Chau", "N. H.", ""], ["Moulines", "\u00c9.", ""], ["R\u00e1sonyi", "M.", ""], ["Sabanis", "S.", ""], ["Zhang", "Y.", ""]]}, {"id": "1812.02725", "submitter": "Jun-Yan Zhu", "authors": "Jun-Yan Zhu, Zhoutong Zhang, Chengkai Zhang, Jiajun Wu, Antonio\n  Torralba, Joshua B. Tenenbaum, William T. Freeman", "title": "Visual Object Networks: Image Generation with Disentangled 3D\n  Representation", "comments": "NeurIPS 2018. Code: https://github.com/junyanz/VON Website:\n  http://von.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in deep generative models has led to tremendous breakthroughs\nin image generation. However, while existing models can synthesize\nphotorealistic images, they lack an understanding of our underlying 3D world.\nWe present a new generative model, Visual Object Networks (VON), synthesizing\nnatural images of objects with a disentangled 3D representation. Inspired by\nclassic graphics rendering pipelines, we unravel our image formation process\ninto three conditionally independent factors---shape, viewpoint, and\ntexture---and present an end-to-end adversarial learning framework that jointly\nmodels 3D shapes and 2D images. Our model first learns to synthesize 3D shapes\nthat are indistinguishable from real shapes. It then renders the object's 2.5D\nsketches (i.e., silhouette and depth map) from its shape under a sampled\nviewpoint. Finally, it learns to add realistic texture to these 2.5D sketches\nto generate natural images. The VON not only generates images that are more\nrealistic than state-of-the-art 2D image synthesis methods, but also enables\nmany 3D operations such as changing the viewpoint of a generated image, editing\nof shape and texture, linear interpolation in texture and shape space, and\ntransferring appearance across different objects and viewpoints.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:58:34 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Zhu", "Jun-Yan", ""], ["Zhang", "Zhoutong", ""], ["Zhang", "Chengkai", ""], ["Wu", "Jiajun", ""], ["Torralba", "Antonio", ""], ["Tenenbaum", "Joshua B.", ""], ["Freeman", "William T.", ""]]}, {"id": "1812.02736", "submitter": "Yuan Jin", "authors": "Yuan Jin and Mark Carman and Ye Zhu and Yong Xiang", "title": "A Technical Survey on Statistical Modelling and Design Methods for\n  Crowdsourcing Quality Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online crowdsourcing provides a scalable and inexpensive means to collect\nknowledge (e.g. labels) about various types of data items (e.g. text, audio,\nvideo). However, it is also known to result in large variance in the quality of\nrecorded responses which often cannot be directly used for training machine\nlearning systems. To resolve this issue, a lot of work has been conducted to\ncontrol the response quality such that low-quality responses cannot adversely\naffect the performance of the machine learning systems. Such work is referred\nto as the quality control for crowdsourcing. Past quality control research can\nbe divided into two major branches: quality control mechanism design and\nstatistical models. The first branch focuses on designing measures, thresholds,\ninterfaces and workflows for payment, gamification, question assignment and\nother mechanisms that influence workers' behaviour. The second branch focuses\non developing statistical models to perform effective aggregation of responses\nto infer correct responses. The two branches are connected as statistical\nmodels (i) provide parameter estimates to support the measure and threshold\ncalculation, and (ii) encode modelling assumptions used to derive (theoretical)\nperformance guarantees for the mechanisms. There are surveys regarding each\nbranch but they lack technical details about the other branch. Our survey is\nthe first to bridge the two branches by providing technical details on how they\nwork together under frameworks that systematically unify crowdsourcing aspects\nmodelled by both of them to determine the response quality. We are also the\nfirst to provide taxonomies of quality control papers based on the proposed\nframeworks. Finally, we specify the current limitations and the corresponding\nfuture directions for the quality control research.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 22:29:42 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Jin", "Yuan", ""], ["Carman", "Mark", ""], ["Zhu", "Ye", ""], ["Xiang", "Yong", ""]]}, {"id": "1812.02765", "submitter": "Taylor Denouden", "authors": "Taylor Denouden, Rick Salay, Krzysztof Czarnecki, Vahdat Abdelzad, Buu\n  Phan, and Sachin Vernekar", "title": "Improving Reconstruction Autoencoder Out-of-distribution Detection with\n  Mahalanobis Distance", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasingly apparent need for validating the classifications\nmade by deep learning systems in safety-critical applications like autonomous\nvehicle systems. A number of recent papers have proposed methods for detecting\nanomalous image data that appear different from known inlier data samples,\nincluding reconstruction-based autoencoders. Autoencoders optimize the\ncompression of input data to a latent space of a dimensionality smaller than\nthe original input and attempt to accurately reconstruct the input using that\ncompressed representation. Since the latent vector is optimized to capture the\nsalient features from the inlier class only, it is commonly assumed that images\nof objects from outside of the training class cannot effectively be compressed\nand reconstructed. Some thus consider reconstruction error as a kind of novelty\nmeasure. Here we suggest that reconstruction-based approaches fail to capture\nparticular anomalies that lie far from known inlier samples in latent space but\nnear the latent dimension manifold defined by the parameters of the model. We\npropose incorporating the Mahalanobis distance in latent space to better\ncapture these out-of-distribution samples and our results show that this method\noften improves performance over the baseline approach.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 19:34:30 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Denouden", "Taylor", ""], ["Salay", "Rick", ""], ["Czarnecki", "Krzysztof", ""], ["Abdelzad", "Vahdat", ""], ["Phan", "Buu", ""], ["Vernekar", "Sachin", ""]]}, {"id": "1812.02768", "submitter": "Soledad Villar", "authors": "Culver McWhirter and Dustin G. Mixon and Soledad Villar", "title": "SqueezeFit: Label-aware dimensionality reduction by semidefinite\n  programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given labeled points in a high-dimensional vector space, we seek a\nlow-dimensional subspace such that projecting onto this subspace maintains some\nprescribed distance between points of differing labels. Intended applications\ninclude compressive classification. Taking inspiration from large margin\nnearest neighbor classification, this paper introduces a semidefinite\nrelaxation of this problem. Unlike its predecessors, this relaxation is\namenable to theoretical analysis, allowing us to provably recover a planted\nprojection operator from the data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 19:38:56 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["McWhirter", "Culver", ""], ["Mixon", "Dustin G.", ""], ["Villar", "Soledad", ""]]}, {"id": "1812.02769", "submitter": "Maksim Kretov", "authors": "Eugene Golikov and Maksim Kretov", "title": "Embedding-reparameterization procedure for manifold-valued latent\n  variables in generative models", "comments": "Presented at Bayesian Deep Learning workshop (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional prior for Variational Auto-Encoder (VAE) is a Gaussian\ndistribution. Recent works demonstrated that choice of prior distribution\naffects learning capacity of VAE models. We propose a general technique\n(embedding-reparameterization procedure, or ER) for introducing arbitrary\nmanifold-valued variables in VAE model. We compare our technique with a\nconventional VAE on a toy benchmark problem. This is work in progress.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 19:48:05 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Golikov", "Eugene", ""], ["Kretov", "Maksim", ""]]}, {"id": "1812.02783", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang and Zhuoran Yang and Han Liu and Tong Zhang and Tamer\n  Ba\\c{s}ar", "title": "Finite-Sample Analysis For Decentralized Batch Multi-Agent Reinforcement\n  Learning With Networked Agents", "comments": "Addressed comments from IFAC Congress 2020 and TAC reviews; added\n  simulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the increasing interest in multi-agent reinforcement learning (MARL)\nin multiple communities, understanding its theoretical foundation has long been\nrecognized as a challenging problem. In this work, we address this problem by\nproviding a finite-sample analysis for decentralized batch MARL with networked\nagents. Specifically, we consider two decentralized MARL settings, where teams\nof agents are connected by time-varying communication networks, and either\ncollaborate or compete in a zero-sum game setting, without any central\ncontroller. These settings cover many conventional MARL settings in the\nliterature. For both settings, we develop batch MARL algorithms that can be\nimplemented in a decentralized fashion, and quantify the finite-sample errors\nof the estimated action-value functions. Our error analysis captures how the\nfunction class, the number of samples within each iteration, and the number of\niterations determine the statistical accuracy of the proposed algorithms. Our\nresults, compared to the finite-sample bounds for single-agent RL, involve\nadditional error terms caused by decentralized computation, which is inherent\nin our decentralized MARL setting. This work appears to be the first\nfinite-sample analysis for batch MARL, a step towards rigorous theoretical\nunderstanding of general MARL algorithms in the finite-sample regime.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 20:09:40 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 07:22:23 GMT"}, {"version": "v3", "created": "Tue, 25 Dec 2018 18:45:26 GMT"}, {"version": "v4", "created": "Sat, 5 Jan 2019 04:00:57 GMT"}, {"version": "v5", "created": "Sat, 26 Jan 2019 06:24:09 GMT"}, {"version": "v6", "created": "Thu, 30 May 2019 19:19:44 GMT"}, {"version": "v7", "created": "Tue, 12 Nov 2019 17:09:11 GMT"}, {"version": "v8", "created": "Mon, 14 Dec 2020 06:10:22 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Liu", "Han", ""], ["Zhang", "Tong", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1812.02795", "submitter": "Krishnamurthy Dvijotham", "authors": "Krishnamurthy Dvijotham, Marta Garnelo, Alhussein Fawzi, Pushmeet\n  Kohli", "title": "Verification of deep probabilistic models", "comments": "Accepted to NeurIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic models are a critical part of the modern deep learning toolbox\n- ranging from generative models (VAEs, GANs), sequence to sequence models used\nin machine translation and speech processing to models over functional spaces\n(conditional neural processes, neural processes). Given the size and complexity\nof these models, safely deploying them in applications requires the development\nof tools to analyze their behavior rigorously and provide some guarantees that\nthese models are consistent with a list of desirable properties or\nspecifications. For example, a machine translation model should produce\nsemantically equivalent outputs for innocuous changes in the input to the\nmodel. A functional regression model that is learning a distribution over\nmonotonic functions should predict a larger value at a larger input.\nVerification of these properties requires a new framework that goes beyond\nnotions of verification studied in deterministic feedforward networks, since\nrequiring worst-case guarantees in probabilistic models is likely to produce\nconservative or vacuous results. We propose a novel formulation of verification\nfor deep probabilistic models that take in conditioning inputs and sample\nlatent variables in the course of producing an output: We require that the\noutput of the model satisfies a linear constraint with high probability over\nthe sampling of latent variables and for every choice of conditioning input to\nthe model. We show that rigorous lower bounds on the probability that the\nconstraint is satisfied can be obtained efficiently. Experiments with neural\nprocesses show that several properties of interest while modeling functional\nspaces can be modeled within this framework (monotonicity, convexity) and\nverified efficiently using our algorithms\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 20:38:19 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Dvijotham", "Krishnamurthy", ""], ["Garnelo", "Marta", ""], ["Fawzi", "Alhussein", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1812.02824", "submitter": "Yizheng Liao", "authors": "Yizheng Liao, Anne S. Kiremidjian, Ram Rajagopal, Chin-Hsuing Loh", "title": "Structural Damage Detection and Localization with Unknown Post-Damage\n  Feature Distribution Using Sequential Change-Point Detection Method", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high structural deficient rate poses serious risks to the operation of\nmany bridges and buildings. To prevent critical damage and structural collapse,\na quick structural health diagnosis tool is needed during normal operation or\nimmediately after extreme events. In structural health monitoring (SHM), many\nexisting works will have limited performance in the quick damage identification\nprocess because 1) the damage event needs to be identified with short delay and\n2) the post-damage information is usually unavailable. To address these\ndrawbacks, we propose a new damage detection and localization approach based on\nstochastic time series analysis. Specifically, the damage sensitive features\nare extracted from vibration signals and follow different distributions before\nand after a damage event. Hence, we use the optimal change point detection\ntheory to find damage occurrence time. As the existing change point detectors\nrequire the post-damage feature distribution, which is unavailable in SHM, we\npropose a maximum likelihood method to learn the distribution parameters from\nthe time-series data. The proposed damage detection using estimated parameters\nalso achieves the optimal performance. Also, we utilize the detection results\nto find damage location without any further computation. Validation results\nshow highly accurate damage identification in American Society of Civil\nEngineers benchmark structure and two shake table experiments.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 06:32:22 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Liao", "Yizheng", ""], ["Kiremidjian", "Anne S.", ""], ["Rajagopal", "Ram", ""], ["Loh", "Chin-Hsuing", ""]]}, {"id": "1812.02833", "submitter": "Tom Rainforth", "authors": "Emile Mathieu, Tom Rainforth, N. Siddharth, Yee Whye Teh", "title": "Disentangling Disentanglement in Variational Autoencoders", "comments": "Accepted for publication at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a generalisation of disentanglement in VAEs---decomposition of the\nlatent representation---characterising it as the fulfilment of two factors: a)\nthe latent encodings of the data having an appropriate level of overlap, and b)\nthe aggregate encoding of the data conforming to a desired structure,\nrepresented through the prior. Decomposition permits disentanglement, i.e.\nexplicit independence between latents, as a special case, but also allows for a\nmuch richer class of properties to be imposed on the learnt representation,\nsuch as sparsity, clustering, independent subspaces, or even intricate\nhierarchical dependency relationships. We show that the $\\beta$-VAE varies from\nthe standard VAE predominantly in its control of latent overlap and that for\nthe standard choice of an isotropic Gaussian prior, its objective is invariant\nto rotations of the latent representation. Viewed from the decomposition\nperspective, breaking this invariance with simple manipulations of the prior\ncan yield better disentanglement with little or no detriment to\nreconstructions. We further demonstrate how other choices of prior can assist\nin producing different decompositions and introduce an alternative training\nobjective that allows the control of both decomposition factors in a principled\nmanner.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 22:16:28 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 19:43:04 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 16:03:37 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Mathieu", "Emile", ""], ["Rainforth", "Tom", ""], ["Siddharth", "N.", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1812.02848", "submitter": "Anthony Palladino", "authors": "Anthony Palladino and Christopher J. Thissen", "title": "Cyber Anomaly Detection Using Graph-node Role-dynamics", "comments": null, "journal-ref": "Proceedings of DYnamic and Novel Advances in Machine Learning and\n  Intelligent Cyber Security Workshop (DYNAMICS'18). ACM, New York, NY, USA.\n  (2019)", "doi": "10.1145/3306195.3306198", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection systems (IDSs) generate valuable knowledge about network\nsecurity, but an abundance of false alarms and a lack of methods to capture the\ninterdependence among alerts hampers their utility for network defense. Here,\nwe explore a graph-based approach for fusing alerts generated by multiple IDSs\n(e.g., Snort, OSSEC, and Bro). Our approach generates a weighted graph of alert\nfields (not network topology) that makes explicit the connections between\nmultiple alerts, IDS systems, and other cyber artifacts. We use this\nmulti-modal graph to identify anomalous changes in the alert patterns of a\nnetwork. To detect the anomalies, we apply the role-dynamics approach, which\nhas successfully identified anomalies in social media, email, and IP\ncommunication graphs. In the cyber domain, each node (alert field) in the fused\nIDS alert graph is assigned a probability distribution across a small set of\nroles based on that node's features. A cyber attack should trigger IDS alerts\nand cause changes in the node features, but rather than track every feature for\nevery alert-field node individually, roles provide a succinct, integrated\nsummary of those feature changes. We measure changes in each node's\nprobabilistic role assignment over time, and identify anomalies as deviations\nfrom expected roles. We test our approach using simulations including three\nweeks of normal background traffic, as well as cyber attacks that occur near\nthe end of the simulations. This paper presents a novel approach to multi-modal\ndata fusion and a novel application of role dynamics within the cyber-security\ndomain. Our results show a drastic decrease in the false-positive rate when\nconsidering our anomaly indicator instead of the IDS alerts themselves, thereby\nreducing alarm fatigue and providing a promising avenue for threat intelligence\nin network defense.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 23:05:00 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 14:33:48 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Palladino", "Anthony", ""], ["Thissen", "Christopher J.", ""]]}, {"id": "1812.02849", "submitter": "Garrett Wilson", "authors": "Garrett Wilson and Diane J. Cook", "title": "A Survey of Unsupervised Deep Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has produced state-of-the-art results for a variety of tasks.\nWhile such approaches for supervised learning have performed well, they assume\nthat training and testing data are drawn from the same distribution, which may\nnot always be the case. As a complement to this challenge, single-source\nunsupervised domain adaptation can handle situations where a network is trained\non labeled data from a source domain and unlabeled data from a related but\ndifferent target domain with the goal of performing well at test-time on the\ntarget domain. Many single-source and typically homogeneous unsupervised deep\ndomain adaptation approaches have thus been developed, combining the powerful,\nhierarchical representations from deep learning with domain adaptation to\nreduce reliance on potentially-costly target data labels. This survey will\ncompare these approaches by examining alternative methods, the unique and\ncommon elements, results, and theoretical insights. We follow this with a look\nat application areas and open research directions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 23:07:23 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 04:29:35 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 19:39:09 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Wilson", "Garrett", ""], ["Cook", "Diane J.", ""]]}, {"id": "1812.02852", "submitter": "Gang Luo", "authors": "Gang Luo", "title": "Automatically Explaining Machine Learning Prediction Results: A\n  Demonstration on Type 2 Diabetes Risk Prediction", "comments": null, "journal-ref": "Gang Luo. Automatically Explaining Machine Learning Prediction\n  Results: A Demonstration on Type 2 Diabetes Risk Prediction. Health\n  Information Science and Systems, Vol. 4, No. 2, Mar. 2016", "doi": "10.1186/s13755-016-0015-4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Predictive modeling is a key component of solutions to many\nhealthcare problems. Among all predictive modeling approaches, machine learning\nmethods often achieve the highest prediction accuracy, but suffer from a\nlong-standing open problem precluding their widespread use in healthcare. Most\nmachine learning models give no explanation for their prediction results,\nwhereas interpretability is essential for a predictive model to be adopted in\ntypical healthcare settings. Methods: This paper presents the first complete\nmethod for automatically explaining results for any machine learning predictive\nmodel without degrading accuracy. We did a computer coding implementation of\nthe method. Using the electronic medical record data set from the Practice\nFusion diabetes classification competition containing patient records from all\n50 states in the United States, we demonstrated the method on predicting type 2\ndiabetes diagnosis within the next year. Results: For the champion machine\nlearning model of the competition, our method explained prediction results for\n87.4% of patients who were correctly predicted by the model to have type 2\ndiabetes diagnosis within the next year. Conclusions: Our demonstration showed\nthe feasibility of automatically explaining results for any machine learning\npredictive model without degrading accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 23:22:15 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Luo", "Gang", ""]]}, {"id": "1812.02855", "submitter": "Gang Luo", "authors": "Xueqiang Zeng, Gang Luo", "title": "Progressive Sampling-Based Bayesian Optimization for Efficient and\n  Automatic Machine Learning Model Selection", "comments": null, "journal-ref": "Xueqiang Zeng, Gang Luo. Progressive Sampling-Based Bayesian\n  Optimization for Efficient and Automatic Machine Learning Model Selection.\n  Health Information Science and Systems, Vol. 5, No. 1, Article 2, Sep. 2017", "doi": "10.1007/s13755-017-0023-z", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Machine learning is broadly used for clinical data analysis. Before\ntraining a model, a machine learning algorithm must be selected. Also, the\nvalues of one or more model parameters termed hyper-parameters must be set.\nSelecting algorithms and hyper-parameter values requires advanced machine\nlearning knowledge and many labor-intensive manual iterations. To lower the bar\nto machine learning, miscellaneous automatic selection methods for algorithms\nand/or hyper-parameter values have been proposed. Existing automatic selection\nmethods are inefficient on large data sets. This poses a challenge for using\nmachine learning in the clinical big data era. Methods: To address the\nchallenge, this paper presents progressive sampling-based Bayesian\noptimization, an efficient and automatic selection method for both algorithms\nand hyper-parameter values. Results: We report an implementation of the method.\nWe show that compared to a state of the art automatic selection method, our\nmethod can significantly reduce search time, classification error rate, and\nstandard deviation of error rate due to randomization. Conclusions: This is\nmajor progress towards enabling fast turnaround in identifying high-quality\nsolutions required by many machine learning-based clinical data analysis tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 23:46:15 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Zeng", "Xueqiang", ""], ["Luo", "Gang", ""]]}, {"id": "1812.02865", "submitter": "Lubna Shibly Mokatren", "authors": "Lubna Shibly Mokatren, Rashid Ansari, Ahmet Enis Cetin, Alex D. Leow,\n  Olusola Ajilore, Heide Klumpp and Fatos T.Yarman Vural", "title": "EEG Classification based on Image Configuration in Social Anxiety\n  Disorder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting the presence of Social Anxiety Disorder (SAD) using\nElectroencephalography (EEG) for classification has seen limited study and is\naddressed with a new approach that seeks to exploit the knowledge of EEG sensor\nspatial configuration. Two classification models, one which ignores the\nconfiguration (model 1) and one that exploits it with different interpolation\nmethods (model 2), are studied. Performance of these two models is examined for\nanalyzing 34 EEG data channels each consisting of five frequency bands and\nfurther decomposed with a filter bank. The data are collected from 64 subjects\nconsisting of healthy controls and patients with SAD. Validity of our\nhypothesis that model 2 will significantly outperform model 1 is borne out in\nthe results, with accuracy $6$--$7\\%$ higher for model 2 for each machine\nlearning algorithm we investigated. Convolutional Neural Networks (CNN) were\nfound to provide much better performance than SVM and kNNs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 01:14:06 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Mokatren", "Lubna Shibly", ""], ["Ansari", "Rashid", ""], ["Cetin", "Ahmet Enis", ""], ["Leow", "Alex D.", ""], ["Ajilore", "Olusola", ""], ["Klumpp", "Heide", ""], ["Vural", "Fatos T. Yarman", ""]]}, {"id": "1812.02868", "submitter": "Sam Witty", "authors": "Sam Witty, Jun Ki Lee, Emma Tosch, Akanksha Atrey, Michael Littman,\n  David Jensen", "title": "Measuring and Characterizing Generalization in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement-learning methods have achieved remarkable performance on\nchallenging control tasks. Observations of the resulting behavior give the\nimpression that the agent has constructed a generalized representation that\nsupports insightful action decisions. We re-examine what is meant by\ngeneralization in RL, and propose several definitions based on an agent's\nperformance in on-policy, off-policy, and unreachable states. We propose a set\nof practical methods for evaluating agents with these definitions of\ngeneralization. We demonstrate these techniques on a common benchmark task for\ndeep RL, and we show that the learned networks make poor decisions for states\nthat differ only slightly from on-policy states, even though those states are\nnot selected adversarially. Taken together, these results call into question\nthe extent to which deep Q-networks learn generalized representations, and\nsuggest that more experimentation and analysis is necessary before claims of\nrepresentation learning can be supported.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 01:32:02 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 13:17:52 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Witty", "Sam", ""], ["Lee", "Jun Ki", ""], ["Tosch", "Emma", ""], ["Atrey", "Akanksha", ""], ["Littman", "Michael", ""], ["Jensen", "David", ""]]}, {"id": "1812.02873", "submitter": "Anqing Jiang", "authors": "Anqing Jiang, Osamu Yoshie, LiangYao Chen", "title": "A new multilayer optical film optimal method based on deep q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-layer optical film has been found to afford important applications in\noptical communication, optical absorbers, optical filters, etc. Different\nalgorithms of multi-layer optical film design has been developed, as simplex\nmethod, colony algorithm, genetic algorithm. These algorithms rapidly promote\nthe design and manufacture of multi-layer films. However, traditional numerical\nalgorithms of converge to local optimum. This means that the algorithms can not\ngive a global optimal solution to the material researchers. In recent years,\ndue to the rapid development to far artificial intelligence, to optimize\noptical film structure using AI algorithm has become possible. In this paper,\nwe will introduce a new optical film design algorithm based on the deep Q\nlearning. This model can converge the global optimum of the optical thin film\nstructure, this will greatly improve the design efficiency of multi-layer\nfilms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 02:02:29 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Jiang", "Anqing", ""], ["Yoshie", "Osamu", ""], ["Chen", "LiangYao", ""]]}, {"id": "1812.02885", "submitter": "Andre Nguyen", "authors": "Andre T. Nguyen and Edward Raff", "title": "Adversarial Attacks, Regression, and Numerical Stability Regularization", "comments": "Presented at the AAAI 2019 Workshop on Engineering Dependable and\n  Secure Machine Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against neural networks in a regression setting are a\ncritical yet understudied problem. In this work, we advance the state of the\nart by investigating adversarial attacks against regression networks and by\nformulating a more effective defense against these attacks. In particular, we\ntake the perspective that adversarial attacks are likely caused by numerical\ninstability in learned functions. We introduce a stability inducing,\nregularization based defense against adversarial attacks in the regression\nsetting. Our new and easy to implement defense is shown to outperform prior\napproaches and to improve the numerical stability of learned functions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 02:50:20 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Nguyen", "Andre T.", ""], ["Raff", "Edward", ""]]}, {"id": "1812.02886", "submitter": "Saurabh Adya", "authors": "Saurabh Adya and Vinay Palakkode and Oncel Tuzel", "title": "Nonlinear Conjugate Gradients For Scaling Synchronous Distributed DNN\n  Training", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear conjugate gradient (NLCG) based optimizers have shown superior loss\nconvergence properties compared to gradient descent based optimizers for\ntraditional optimization problems. However, in Deep Neural Network (DNN)\ntraining, the dominant optimization algorithm of choice is still Stochastic\nGradient Descent (SGD) and its variants. In this work, we propose and evaluate\nthe stochastic preconditioned nonlinear conjugate gradient algorithm for large\nscale DNN training tasks. We show that a nonlinear conjugate gradient algorithm\nimproves the convergence speed of DNN training, especially in the large\nmini-batch scenario, which is essential for scaling synchronous distributed DNN\ntraining to large number of workers. We show how to efficiently use second\norder information in the NLCG pre-conditioner for improving DNN training\nconvergence. For the ImageNet classification task, at extremely large\nmini-batch sizes of greater than 65k, NLCG optimizer is able to improve top-1\naccuracy by more than 10 percentage points for standard training of the\nResnet-50 model for 90 epochs. For the CIFAR-100 classification task, at\nextremely large mini-batch sizes of greater than 16k, NLCG optimizer is able to\nimprove top-1 accuracy by more than 15 percentage points for standard training\nof the Resnet-32 model for 200 epochs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 02:59:59 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 02:52:34 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Adya", "Saurabh", ""], ["Palakkode", "Vinay", ""], ["Tuzel", "Oncel", ""]]}, {"id": "1812.02890", "submitter": "Koen Van Der Veen", "authors": "Koen Lennart van der Veen, Ruben Seggers, Peter Bloem, Giorgio Patrini", "title": "Three Tools for Practical Differential Privacy", "comments": "4 pages, 8 figures, PPML18: Privacy Preserving Machine Learning -\n  NIPS 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private learning on real-world data poses challenges for\nstandard machine learning practice: privacy guarantees are difficult to\ninterpret, hyperparameter tuning on private data reduces the privacy budget,\nand ad-hoc privacy attacks are often required to test model privacy. We\nintroduce three tools to make differentially private machine learning more\npractical: (1) simple sanity checks which can be carried out in a centralized\nmanner before training, (2) an adaptive clipping bound to reduce the effective\nnumber of tuneable privacy parameters, and (3) we show that large-batch\ntraining improves model performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 03:28:41 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["van der Veen", "Koen Lennart", ""], ["Seggers", "Ruben", ""], ["Bloem", "Peter", ""], ["Patrini", "Giorgio", ""]]}, {"id": "1812.02893", "submitter": "Yang-Hui He", "authors": "Yang-Hui He", "title": "The Calabi-Yau Landscape: from Geometry, to Physics, to Machine-Learning", "comments": "book to appear with Springer; v1 #pages = #irreps(Monster), 44\n  figures; v2 substantially expanded: about 100 extra pages and 10 figures\n  added", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th math-ph math.AG math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a pedagogical introduction to the recent advances in the\ncomputational geometry, physical implications, and data science of Calabi-Yau\nmanifolds. Aimed at the beginning research student and using Calabi-Yau spaces\nas an exciting play-ground, we intend to teach some mathematics to the budding\nphysicist, some physics to the budding mathematician, and some machine-learning\nto both. Based on various lecture series, colloquia and seminars given by the\nauthor in the past year, this writing is a very preliminary draft of a book to\nappear with Springer, by whose kind permission we post to ArXiv for comments\nand suggestions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 03:45:27 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 18:47:49 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["He", "Yang-Hui", ""]]}, {"id": "1812.02900", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, David Meger, Doina Precup", "title": "Off-Policy Deep Reinforcement Learning without Exploration", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical applications of reinforcement learning constrain agents to\nlearn from a fixed batch of data which has already been gathered, without\noffering further possibility for data collection. In this paper, we demonstrate\nthat due to errors introduced by extrapolation, standard off-policy deep\nreinforcement learning algorithms, such as DQN and DDPG, are incapable of\nlearning with data uncorrelated to the distribution under the current policy,\nmaking them ineffective for this fixed batch setting. We introduce a novel\nclass of off-policy algorithms, batch-constrained reinforcement learning, which\nrestricts the action space in order to force the agent towards behaving close\nto on-policy with respect to a subset of the given data. We present the first\ncontinuous control deep reinforcement learning algorithm which can learn\neffectively from arbitrary, fixed batch data, and empirically demonstrate the\nquality of its behavior in several tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 04:03:25 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 19:58:23 GMT"}, {"version": "v3", "created": "Sat, 10 Aug 2019 03:36:31 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Fujimoto", "Scott", ""], ["Meger", "David", ""], ["Precup", "Doina", ""]]}, {"id": "1812.02903", "submitter": "Timothy Yang", "authors": "Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li,\n  Nicholas Kong, Daniel Ramage, Fran\\c{c}oise Beaufays", "title": "Applied Federated Learning: Improving Google Keyboard Query Suggestions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed form of machine learning where both the\ntraining data and model training are decentralized. In this paper, we use\nfederated learning in a commercial, global-scale setting to train, evaluate and\ndeploy a model to improve virtual keyboard search suggestion quality without\ndirect access to the underlying user data. We describe our observations in\nfederated training, compare metrics to live deployments, and present resulting\nquality increases. In whole, we demonstrate how federated learning can be\napplied end-to-end to both improve user experiences and enhance user privacy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 04:18:12 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Yang", "Timothy", ""], ["Andrew", "Galen", ""], ["Eichner", "Hubert", ""], ["Sun", "Haicheng", ""], ["Li", "Wei", ""], ["Kong", "Nicholas", ""], ["Ramage", "Daniel", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "1812.02919", "submitter": "Xiu Yang", "authors": "Xiu Yang and Xueyu Zhu and Jing Li", "title": "When Bifidelity Meets CoKriging: An Efficient Physics-Informed\n  Multifidelity Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a framework that combines the\napproximation-theory-based multifidelity method and\nGaussian-process-regression-based multifidelity method to achieve data-model\nconvergence when stochastic simulation models and sparse accurate observation\ndata are available. Specifically, the two types of multifidelity methods we use\nare the bifidelity and CoKriging methods. The new approach uses the bifidelity\nmethod to efficiently estimate the empirical mean and covariance of the\nstochastic simulation outputs, then it uses these statistics to construct a\nGaussian process (GP) representing low-fidelity in CoKriging. We also combine\nthe bifidelity method with Kriging, where the approximated empirical statistics\nare used to construct the GP as well. We prove that the resulting posterior\nmean by the new physics-informed approach preserves linear physical constraints\nup to an error bound. By using this method, we can obtain an accurate\nconstruction of a state of interest based on a partially correct physical model\nand a few accurate observations. We present numerical examples to demonstrate\nperformance of the method.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 05:51:45 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Yang", "Xiu", ""], ["Zhu", "Xueyu", ""], ["Li", "Jing", ""]]}, {"id": "1812.02952", "submitter": "Hussein Mozannar", "authors": "Hussein Mozannar, Mesrob I. Ohannessian, Nathan Srebro", "title": "From Fair Decision Making to Social Equality", "comments": "Short version appears in the proceedings of ACM FAT* 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of fairness in intelligent decision systems has mostly ignored\nlong-term influence on the underlying population. Yet fairness considerations\n(e.g. affirmative action) have often the implicit goal of achieving balance\namong groups within the population. The most basic notion of balance is\neventual equality between the qualifications of the groups. How can we\nincorporate influence dynamics in decision making? How well do\ndynamics-oblivious fairness policies fare in terms of reaching equality? In\nthis paper, we propose a simple yet revealing model that encompasses (1) a\nselection process where an institution chooses from multiple groups according\nto their qualifications so as to maximize an institutional utility and (2)\ndynamics that govern the evolution of the groups' qualifications according to\nthe imposed policies. We focus on demographic parity as the formalism of\naffirmative action.\n  We then give conditions under which an unconstrained policy reaches equality\non its own. In this case, surprisingly, imposing demographic parity may break\nequality. When it doesn't, one would expect the additional constraint to reduce\nutility, however, we show that utility may in fact increase. In more realistic\nscenarios, unconstrained policies do not lead to equality. In such cases, we\nshow that although imposing demographic parity may remedy it, there is a danger\nthat groups settle at a worse set of qualifications. As a silver lining, we\nalso identify when the constraint not only leads to equality, but also improves\nall groups. This gives quantifiable insight into both sides of the mismatch\nhypothesis. These cases and trade-offs are instrumental in determining when and\nhow imposing demographic parity can be beneficial in selection processes, both\nfor the institution and for society on the long run.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 09:14:07 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 20:49:15 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Mozannar", "Hussein", ""], ["Ohannessian", "Mesrob I.", ""], ["Srebro", "Nathan", ""]]}, {"id": "1812.02956", "submitter": "Piotr Szyma\\'nski", "authors": "Piotr Szyma\\'nski, Tomasz Kajdanowicz, Nitesh Chawla", "title": "LNEMLC: Label Network Embeddings for Multi-Label Classification", "comments": "submitted to TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multi-label classification aims to classify instances with discrete\nnon-exclusive labels. Most approaches on multi-label classification focus on\neffective adaptation or transformation of existing binary and multi-class\nlearning approaches but fail in modelling the joint probability of labels or do\nnot preserve generalization abilities for unseen label combinations. To address\nthese issues we propose a new multi-label classification scheme, LNEMLC - Label\nNetwork Embedding for Multi-Label Classification, that embeds the label network\nand uses it to extend input space in learning and inference of any base\nmulti-label classifier. The approach allows capturing of labels' joint\nprobability at low computational complexity providing results comparable to the\nbest methods reported in the literature. We demonstrate how the method reveals\nstatistically significant improvements over the simple kNN baseline classifier.\nWe also provide hints for selecting the robust configuration that works\nsatisfactorily across data domains.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 09:30:18 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 21:11:09 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Szyma\u0144ski", "Piotr", ""], ["Kajdanowicz", "Tomasz", ""], ["Chawla", "Nitesh", ""]]}, {"id": "1812.02962", "submitter": "Xue Wang", "authors": "Xue Wang, Mike Mingcheng Wei, Tao Yao", "title": "Online Learning and Decision-Making under Generalized Linear Model with\n  High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a minimax concave penalized multi-armed bandit algorithm under\ngeneralized linear model (G-MCP-Bandit) for a decision-maker facing\nhigh-dimensional data in an online learning and decision-making process. We\ndemonstrate that the G-MCP-Bandit algorithm asymptotically achieves the optimal\ncumulative regret in the sample size dimension T , O(log T), and further\nattains a tight bound in the covariate dimension d, O(log d). In addition, we\ndevelop a linear approximation method, the 2-step weighted Lasso procedure, to\nidentify the MCP estimator for the G-MCP-Bandit algorithm under non-iid\nsamples. Under this procedure, the MCP estimator matches the oracle estimator\nwith high probability and converges to the true parameters with the optimal\nconvergence rate. Finally, through experiments based on synthetic data and two\nreal datasets (warfarin dosing dataset and Tencent search advertising dataset),\nwe show that the G-MCP-Bandit algorithm outperforms other benchmark algorithms,\nespecially when there is a high level of data sparsity or the decision set is\nlarge.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 09:58:16 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Wang", "Xue", ""], ["Wei", "Mike Mingcheng", ""], ["Yao", "Tao", ""]]}, {"id": "1812.02975", "submitter": "Kevin Alexander Laube", "authors": "Kevin Alexander Laube and Andreas Zell", "title": "ShuffleNASNets: Efficient CNN models through modified Efficient Neural\n  Architecture Search", "comments": "6 pages, 5 figures, 1 table", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852294", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network architectures found by sophistic search algorithms achieve\nstrikingly good test performance, surpassing most human-crafted network models\nby significant margins. Although computationally efficient, their design is\noften very complex, impairing execution speed. Additionally, finding models\noutside of the search space is not possible by design. While our space is still\nlimited, we implement undiscoverable expert knowledge into the economic search\nalgorithm Efficient Neural Architecture Search (ENAS), guided by the design\nprinciples and architecture of ShuffleNet V2. While maintaining baseline-like\n2.85% test error on CIFAR-10, our ShuffleNASNets are significantly less\ncomplex, require fewer parameters, and are two times faster than the ENAS\nbaseline in a classification task. These models also scale well to a low\nparameter space, achieving less than 5% test error with little regularization\nand only 236K parameters.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 10:53:31 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Laube", "Kevin Alexander", ""], ["Zell", "Andreas", ""]]}, {"id": "1812.02984", "submitter": "Ehsan Pajouheshgar", "authors": "Ehsan Pajouheshgar, Christoph H. Lampert", "title": "Back to square one: probabilistic trajectory forecasting without bells\n  and whistles", "comments": "4 pages, 3 figures, Workshop on Modeling and Decision-Making in the\n  Spatiotemporal Domain, 32nd Conference on Neural Information Processing\n  Systems (NIPS 2018), Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a spatio-temporal convolutional neural network model for\ntrajectory forecasting from visual sources. Applied in an auto-regressive way\nit provides an explicit probability distribution over continuations of a given\ninitial trajectory segment. We discuss it in relation to (more complicated)\nexisting work and report on experiments on two standard datasets for trajectory\nforecasting: MNISTseq and Stanford Drones, achieving results on-par with or\nbetter than previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 11:31:05 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Pajouheshgar", "Ehsan", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "1812.02990", "submitter": "Sophie Fosson", "authors": "Sophie M. Fosson", "title": "A biconvex analysis for Lasso l1 reweighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  l1 reweighting algorithms are very popular in sparse signal recovery and\ncompressed sensing, since in the practice they have been observed to outperform\nclassical l1 methods. Nevertheless, the theoretical analysis of their\nconvergence is a critical point, and generally is limited to the convergence of\nthe functional to a local minimum or to subsequence convergence. In this\nletter, we propose a new convergence analysis of a Lasso l1 reweighting method,\nbased on the observation that the algorithm is an alternated convex search for\na biconvex problem. Based on that, we are able to prove the numerical\nconvergence of the sequence of the iterates generated by the algorithm. This is\nnot yet the convergence of the sequence, but it is close enough for practical\nand numerical purposes. Furthermore, we propose an alternative iterative soft\nthresholding procedure, which is faster than the main algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 11:57:45 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Fosson", "Sophie M.", ""]]}, {"id": "1812.03049", "submitter": "Jonathan Blanchette", "authors": "Blanchette and Lagani\\`ere", "title": "On Batch Orthogonalization Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization has become ubiquitous in many state-of-the-art nets. It\naccelerates training and yields good performance results. However, there are\nvarious other alternatives to normalization, e.g. orthonormalization. The\nobjective of this paper is to explore the possible alternatives to channel\nnormalization with orthonormalization layers. The performance of the algorithms\nare compared together with BN with prescribed performance measures.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 14:53:03 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Blanchette", "", ""], ["Lagani\u00e8re", "", ""]]}, {"id": "1812.03057", "submitter": "Hiroshi Kuwajima", "authors": "Hiroshi Kuwajima, Hirotoshi Yasuoka, Toshihiro Nakae", "title": "Open Problems in Engineering and Quality Assurance of Safety Critical\n  Machine Learning Systems", "comments": "DISE1: Joint Workshop on Deep (or Machine) Learning for\n  Safety-Critical Applications in Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fatal accidents are a major issue hindering the wide acceptance of\nsafety-critical systems using machine-learning and deep-learning models, such\nas automated-driving vehicles. Quality assurance frameworks are required for\nsuch machine learning systems, but there are no widely accepted and established\nquality-assurance concepts and techniques. At the same time, open problems and\nthe relevant technical fields are not organized. To establish standard quality\nassurance frameworks, it is necessary to visualize and organize these open\nproblems in an interdisciplinary way, so that the experts from many different\ntechnical fields may discuss these problems in depth and develop solutions. In\nthe present study, we identify, classify, and explore the open problems in\nquality assurance of safety-critical machine-learning systems, and their\nrelevant corresponding industry and technological trends, using\nautomated-driving vehicles as an example. Our results show that addressing\nthese open problems requires incorporating knowledge from several different\ntechnological and industrial fields, including the automobile industry,\nstatistics, software engineering, and machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 15:02:40 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Kuwajima", "Hiroshi", ""], ["Yasuoka", "Hirotoshi", ""], ["Nakae", "Toshihiro", ""]]}, {"id": "1812.03087", "submitter": "Aly El Gamal", "authors": "Rajeev Sahay, Rehana Mahfuz, Aly El Gamal", "title": "Combatting Adversarial Attacks through Denoising and Dimensionality\n  Reduction: A Cascaded Autoencoder Approach", "comments": "7 pages, 8 figures, submitted to Conference on Information Sciences\n  and Systems (CISS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning models are vulnerable to adversarial attacks that rely on\nperturbing the input data. This work proposes a novel strategy using\nAutoencoder Deep Neural Networks to defend a machine learning model against two\ngradient-based attacks: The Fast Gradient Sign attack and Fast Gradient attack.\nFirst we use an autoencoder to denoise the test data, which is trained with\nboth clean and corrupted data. Then, we reduce the dimension of the denoised\ndata using the hidden layer representation of another autoencoder. We perform\nthis experiment for multiple values of the bound of adversarial perturbations,\nand consider different numbers of reduced dimensions. When the test data is\npreprocessed using this cascaded pipeline, the tested deep neural network\nclassifier yields a much higher accuracy, thus mitigating the effect of the\nadversarial perturbation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 16:21:24 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Sahay", "Rajeev", ""], ["Mahfuz", "Rehana", ""], ["Gamal", "Aly El", ""]]}, {"id": "1812.03090", "submitter": "Monika Bhattacharjee", "authors": "Monika Bhattacharjee, Moulinath Banerjee, George Michailidis", "title": "Change Point Estimation in a Dynamic Stochastic Block Model", "comments": "Please see the .pdf file for an extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the location of a single change point\nin a dynamic stochastic block model. We propose two methods of estimating the\nchange point, together with the model parameters. The first employs a least\nsquares criterion function and takes into consideration the full structure of\nthe stochastic block model and is evaluated at each point in time. Hence, as an\nintermediate step, it requires estimating the community structure based on a\nclustering algorithm at every time point. The second method comprises of the\nfollowing two steps: in the first one, a least squares function is used and\nevaluated at each time point, but ignores the community structures and just\nconsiders a random graph generating mechanism exhibiting a change point. Once\nthe change point is identified, in the second step, all network data before and\nafter it are used together with a clustering algorithm to obtain the\ncorresponding community structures and subsequently estimate the generating\nstochastic block model parameters. A comparison between these two methods is\nillustrated. Further, for both methods under their respective identifiability\nand certain additional regularity conditions, we establish rates of convergence\nand derive the asymptotic distributions of the change point estimators. The\nresults are illustrated on synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 16:25:10 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 14:13:56 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Bhattacharjee", "Monika", ""], ["Banerjee", "Moulinath", ""], ["Michailidis", "George", ""]]}, {"id": "1812.03123", "submitter": "Marouan Belhaj", "authors": "Marouan Belhaj, Pavlos Protopapas, Weiwei Pan", "title": "Deep Variational Transfer: Transfer Learning through Semi-supervised\n  Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications, it is often expensive and time-consuming to\nobtain labeled examples. In such cases, knowledge transfer from related\ndomains, where labels are abundant, could greatly reduce the need for extensive\nlabeling efforts. In this scenario, transfer learning comes in hand. In this\npaper, we propose Deep Variational Transfer (DVT), a variational autoencoder\nthat transfers knowledge across domains using a shared latent Gaussian mixture\nmodel. Thanks to the combination of a semi-supervised ELBO and parameters\nsharing across domains, we are able to simultaneously: (i) align all supervised\nexamples of the same class into the same latent Gaussian Mixture component,\nindependently from their domain; (ii) predict the class of unsupervised\nexamples from different domains and use them to better model the occurring\nshifts. We perform tests on MNIST and USPS digits datasets, showing DVT's\nability to perform transfer learning across heterogeneous datasets.\nAdditionally, we present DVT's top classification performances on the MNIST\nsemi-supervised learning challenge. We further validate DVT on a astronomical\ndatasets. DVT achieves states-of-the-art classification performances,\ntransferring knowledge across real stars surveys datasets, EROS, MACHO and\nHiTS, . In the worst performance, we double the achieved F1-score for rare\nclasses. These experiments show DVT's ability to tackle all major challenges\nposed by transfer learning: different covariate distributions, different and\nhighly imbalanced class distributions and different feature spaces.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 17:38:32 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Belhaj", "Marouan", ""], ["Protopapas", "Pavlos", ""], ["Pan", "Weiwei", ""]]}, {"id": "1812.03131", "submitter": "Miltiades Anagnostou", "authors": "Miltiades E. Anagnostou and Maria A. Lambrou", "title": "Playing with and against Hedge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NI cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hedge has been proposed as an adaptive scheme, which guides an agent's\ndecision in resource selection and distribution problems that can be modeled as\na multi-armed bandit full information game. Such problems are encountered in\nthe areas of computer and communication networks, e.g. network path selection,\nload distribution, network interdiction, and also in problems in the area of\ntransportation. We study Hedge under the assumption that the total loss that\ncan be suffered by the player in each round is upper bounded. In this paper, we\nstudy the worst performance of Hedge.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 10:25:56 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Anagnostou", "Miltiades E.", ""], ["Lambrou", "Maria A.", ""]]}, {"id": "1812.03170", "submitter": "Jason Ramapuram", "authors": "Jason Ramapuram, Maurits Diephuis, Frantzeska Lavda, Russ Webb,\n  Alexandros Kalousis", "title": "Variational Saccading: Efficient Inference for Large Resolution Images", "comments": "Published BMVC 2019 & NIPS 2018 Bayesian Deep Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification with deep neural networks is typically restricted to\nimages of small dimensionality such as 224 x 244 in Resnet models [24]. This\nlimitation excludes the 4000 x 3000 dimensional images that are taken by modern\nsmartphone cameras and smart devices. In this work, we aim to mitigate the\nprohibitive inferential and memory costs of operating in such large dimensional\nspaces. To sample from the high-resolution original input distribution, we\npropose using a smaller proxy distribution to learn the co-ordinates that\ncorrespond to regions of interest in the high-dimensional space. We introduce a\nnew principled variational lower bound that captures the relationship of the\nproxy distribution's posterior and the original image's co-ordinate space in a\nway that maximizes the conditional classification likelihood. We empirically\ndemonstrate on one synthetic benchmark and one real world large resolution DSLR\ncamera image dataset that our method produces comparable results with ~10x\nfaster inference and lower memory consumption than a model that utilizes the\nentire original input distribution. Finally, we experiment with a more complex\nsetting using mini-maps from Starcraft II [56] to infer the number of\ncharacters in a complex 3d-rendered scene. Even in such complicated scenes our\nmodel provides strong localization: a feature missing from traditional\nclassification models.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 16:53:02 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 14:53:06 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 11:41:23 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Ramapuram", "Jason", ""], ["Diephuis", "Maurits", ""], ["Lavda", "Frantzeska", ""], ["Webb", "Russ", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1812.03173", "submitter": "Amir Moradibaad", "authors": "Amir Moradibaad, Ramin Jalilian Mashhoud", "title": "Use Dimensionality Reduction and SVM Methods to Increase the Penetration\n  Rate of Computer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the world today computer networks have a very important position and most\nof the urban and national infrastructure as well as organizations are managed\nby computer networks, therefore, the security of these systems against the\nplanned attacks is of great importance. Therefore, researchers have been trying\nto find these vulnerabilities so that after identifying ways to penetrate the\nsystem, they will provide system protection through preventive or\ncountermeasures. SVM is one of the major algorithms for intrusion detection. In\nthis research, we studied a variety of malware and methods of intrusion\ndetection, provide an efficient method for detecting attacks and utilizing\ndimension reduction.Thus, we will be able to detect attacks by carefully\ncombining these two algorithms and pre-processes that are performed before the\ntwo on the input data. The main question raised is how we can identify attacks\non computer networks with the above-mentioned method. In anomalies diagnostic\nmethod, by identifying behavior as a normal behavior for the user, the host, or\nthe whole system, any deviation from this behavior is considered as an abnormal\nbehavior, which can be a potential occurrence of an attack. The network\nintrusion detection system is used by anomaly detection method that uses the\nSVM algorithm for classification and SVD to reduce the size. Steps of the\nproposed method include pre-processing of the data set, feature selection,\nsupport vector machine, and evaluation.The NSL-KDD data set has been used to\nteach and test the proposed model. In this study, we inferred the intrusion\ndetection using the SVM algorithm for classification and SVD for diminishing\ndimensions with no classification algorithm.Also the KNN algorithm has been\ncompared in situations with and without diminishing dimensions,the results have\nshown that the proposed method has a better performance than comparable\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 10:21:24 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 12:23:45 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Moradibaad", "Amir", ""], ["Mashhoud", "Ramin Jalilian", ""]]}, {"id": "1812.03188", "submitter": "Kabir Manghnani", "authors": "Kabir Manghnani, Adam Drake, Nathan Wan, and Imran Haque", "title": "METCC: METric learning for Confounder Control Making distance matter in\n  high dimensional biological analysis", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/211", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data acquired from biological experiments such as next\ngeneration sequencing are subject to a number of confounding effects. These\neffects include both technical effects, such as variation across batches from\ninstrument noise or sample processing, or institution-specific differences in\nsample acquisition and physical handling, as well as biological effects arising\nfrom true but irrelevant differences in the biology of each sample, such as age\nbiases in diseases. Prior work has used linear methods to adjust for such batch\neffects. Here, we apply contrastive metric learning by a non-linear triplet\nnetwork to optimize the ability to distinguish biologically distinct sample\nclasses in the presence of irrelevant technical and biological variation. Using\nwhole-genome cell-free DNA data from 817 patients, we demonstrate that our\napproach, METric learning for Confounder Control (METCC), is able to match or\nexceed the classification performance achieved using a best-in-class linear\nmethod (HCP) or no normalization. Critically, results from METCC appear less\nconfounded by irrelevant technical variables like institution and batch than\nthose from other methods even without access to high quality metadata\ninformation required by many existing techniques; offering hope for improved\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 19:20:43 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Manghnani", "Kabir", ""], ["Drake", "Adam", ""], ["Wan", "Nathan", ""], ["Haque", "Imran", ""]]}, {"id": "1812.03190", "submitter": "Pourya Habib Zadeh", "authors": "Pourya Habib Zadeh, Reshad Hosseini, and Suvrit Sra", "title": "Deep-RBF Networks Revisited: Robust Classification with Rejection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main drawbacks of deep neural networks, like many other\nclassifiers, is their vulnerability to adversarial attacks. An important reason\nfor their vulnerability is assigning high confidence to regions with few or\neven no feature points. By feature points, we mean a nonlinear transformation\nof the input space extracting a meaningful representation of the input data. On\nthe other hand, deep-RBF networks assign high confidence only to the regions\ncontaining enough feature points, but they have been discounted due to the\nwidely-held belief that they have the vanishing gradient problem. In this\npaper, we revisit the deep-RBF networks by first giving a general formulation\nfor them, and then proposing a family of cost functions thereof inspired by\nmetric learning. In the proposed deep-RBF learning algorithm, the vanishing\ngradient problem does not occur. We make these networks robust to adversarial\nattack by adding the reject option to their output layer. Through several\nexperiments on the MNIST dataset, we demonstrate that our proposed method not\nonly achieves significant classification accuracy but is also very resistant to\nvarious adversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 19:25:52 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Zadeh", "Pourya Habib", ""], ["Hosseini", "Reshad", ""], ["Sra", "Suvrit", ""]]}, {"id": "1812.03222", "submitter": "Victor Rodriguez", "authors": "Victor Rodriguez, Adler Perotte", "title": "Phenotype Inference with Semi-Supervised Mixed Membership Models", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  https://urldefense.proofpoint.com/v2/url?u=https-3A__arxiv.org_abs_1811.07216&d=DwIEaQ&c=G2MiLlal7SXE3PeSnG8W6_JBU6FcdVjSsBSbw6gcR0U&r=V4N8fh0BvUFXSfHS_5FyHekWwaQfwQATAFihsExKikM&m=3ZpgK5EnFWR2OpdKWz1sCspjnLWOElIt_VHn1RMHJ5U&s=iE0HP7cbAigUopbIm2O8hByUTkVYvOw7R2y8QoF6GRg&e=", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/226", "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease phenotyping algorithms process observational clinical data to\nidentify patients with specific diseases. Supervised phenotyping methods\nrequire significant quantities of expert-labeled data, while unsupervised\nmethods may learn non-disease phenotypes. To address these limitations, we\npropose the Semi-Supervised Mixed Membership Model (SS3M) -- a probabilistic\ngraphical model for learning disease phenotypes from clinical data with\nrelatively few labels. We show SS3M can learn interpretable, disease-specific\nphenotypes which capture the clinical characteristics of the diseases specified\nby the labels provided.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 21:42:20 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 14:34:35 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Rodriguez", "Victor", ""], ["Perotte", "Adler", ""]]}, {"id": "1812.03224", "submitter": "Stacey Truex", "authors": "Stacey Truex, Nathalie Baracaldo, Ali Anwar, Thomas Steinke, Heiko\n  Ludwig, Rui Zhang, Yi Zhou", "title": "A Hybrid Approach to Privacy-Preserving Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning facilitates the collaborative training of models without\nthe sharing of raw data. However, recent attacks demonstrate that simply\nmaintaining data locality during training processes does not provide sufficient\nprivacy guarantees. Rather, we need a federated learning system capable of\npreventing inference over both the messages exchanged during training and the\nfinal trained model while ensuring the resulting model also has acceptable\npredictive accuracy. Existing federated learning approaches either use secure\nmultiparty computation (SMC) which is vulnerable to inference or differential\nprivacy which can lead to low accuracy given a large number of parties with\nrelatively small amounts of data each. In this paper, we present an alternative\napproach that utilizes both differential privacy and SMC to balance these\ntrade-offs. Combining differential privacy with secure multiparty computation\nenables us to reduce the growth of noise injection as the number of parties\nincreases without sacrificing privacy while maintaining a pre-defined rate of\ntrust. Our system is therefore a scalable approach that protects against\ninference threats and produces models with high accuracy. Additionally, our\nsystem can be used to train a variety of machine learning models, which we\nvalidate with experimental results on 3 different machine learning algorithms.\nOur experiments demonstrate that our approach out-performs state of the art\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 21:52:09 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 22:19:10 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Truex", "Stacey", ""], ["Baracaldo", "Nathalie", ""], ["Anwar", "Ali", ""], ["Steinke", "Thomas", ""], ["Ludwig", "Heiko", ""], ["Zhang", "Rui", ""], ["Zhou", "Yi", ""]]}, {"id": "1812.03235", "submitter": "Bahare Fatemi", "authors": "Bahare Fatemi, Siamak Ravanbakhsh, and David Poole", "title": "Improved Knowledge Graph Embedding using Background Taxonomic\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are used to represent relational information in terms of\ntriples. To enable learning about domains, embedding models, such as tensor\nfactorization models, can be used to make predictions of new triples. Often\nthere is background taxonomic information (in terms of subclasses and\nsubproperties) that should also be taken into account. We show that existing\nfully expressive (a.k.a. universal) models cannot provably respect subclass and\nsubproperty information. We show that minimal modifications to an existing\nknowledge graph completion method enables injection of taxonomic information.\nMoreover, we prove that our model is fully expressive, assuming a lower-bound\non the size of the embeddings. Experimental results on public knowledge graphs\nshow that despite its simplicity our approach is surprisingly effective.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 22:40:00 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Fatemi", "Bahare", ""], ["Ravanbakhsh", "Siamak", ""], ["Poole", "David", ""]]}, {"id": "1812.03239", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Kaiqing Zhang, Georgios B. Giannakis, and Tamer Ba\\c{s}ar", "title": "Communication-Efficient Policy Gradient Methods for Distributed\n  Reinforcement Learning", "comments": "To appear in IEEE Transactions on Control of Network Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with distributed policy optimization in reinforcement\nlearning, which involves a central controller and a group of learners. In\nparticular, two typical settings encountered in several applications are\nconsidered: multi-agent reinforcement learning (RL) and parallel RL, where\nfrequent information exchanges between the learners and the controller are\nrequired. For many practical distributed systems, however, the overhead caused\nby these frequent communication exchanges is considerable, and becomes the\nbottleneck of the overall performance. To address this challenge, a novel\npolicy gradient approach is developed for solving distributed RL. The novel\napproach adaptively skips the policy gradient communication during iterations,\nand can reduce the communication overhead without degrading learning\nperformance. It is established analytically that: i) the novel algorithm has\nconvergence rate identical to that of the plain-vanilla policy gradient; while\nii) if the distributed learners are heterogeneous in terms of their reward\nfunctions, the number of communication rounds needed to achieve a desirable\nlearning accuracy is markedly reduced. Numerical experiments corroborate the\ncommunication reduction attained by the novel algorithm compared to\nalternatives.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 23:24:34 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 20:05:53 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 08:00:14 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Chen", "Tianyi", ""], ["Zhang", "Kaiqing", ""], ["Giannakis", "Georgios B.", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1812.03253", "submitter": "Michel Besserve", "authors": "Michel Besserve, Arash Mehrjou, R\\'emy Sun and Bernhard Sch\\\"olkopf", "title": "Counterfactuals uncover the modular structure of deep generative models", "comments": "26 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models can emulate the perceptual properties of complex image\ndatasets, providing a latent representation of the data. However, manipulating\nsuch representation to perform meaningful and controllable transformations in\nthe data space remains challenging without some form of supervision. While\nprevious work has focused on exploiting statistical independence to disentangle\nlatent factors, we argue that such requirement is too restrictive and propose\ninstead a non-statistical framework that relies on counterfactual manipulations\nto uncover a modular structure of the network composed of disentangled groups\nof internal variables. Experiments with a variety of generative models trained\non complex image datasets show the obtained modules can be used to design\ntargeted interventions. This opens the way to applications such as\ncomputationally efficient style transfer and the automated assessment of\nrobustness to contextual changes in pattern recognition systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 01:57:27 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 13:50:30 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Besserve", "Michel", ""], ["Mehrjou", "Arash", ""], ["Sun", "R\u00e9my", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1812.03260", "submitter": "Amir Karami", "authors": "George Shaw and Amir Karami", "title": "An Exploratory Study of (#)Exercise in the Twittersphere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CL cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media analytics allows us to extract, analyze, and establish semantic\nfrom user-generated contents in social media platforms. This study utilized a\nmixed method including a three-step process of data collection, topic modeling,\nand data annotation for recognizing exercise related patterns. Based on the\nfindings, 86% of the detected topics were identified as meaningful topics after\nconducting the data annotation process. The most discussed exercise-related\ntopics were physical activity (18.7%), lifestyle behaviors (6.6%), and dieting\n(4%). The results from our experiment indicate that the exploratory data\nanalysis is a practical approach to summarizing the various characteristics of\ntext data for different health and medical applications.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 03:21:26 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Shaw", "George", ""], ["Karami", "Amir", ""]]}, {"id": "1812.03271", "submitter": "Xiaoyong Yuan", "authors": "Xiaoyong Yuan, Zheng Feng, Matthew Norton, Xiaolin Li", "title": "Generalized Batch Normalization: Towards Accelerating Deep Neural\n  Networks", "comments": "accepted at AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilizing recently introduced concepts from statistics and quantitative risk\nmanagement, we present a general variant of Batch Normalization (BN) that\noffers accelerated convergence of Neural Network training compared to\nconventional BN. In general, we show that mean and standard deviation are not\nalways the most appropriate choice for the centering and scaling procedure\nwithin the BN transformation, particularly if ReLU follows the normalization\nstep. We present a Generalized Batch Normalization (GBN) transformation, which\ncan utilize a variety of alternative deviation measures for scaling and\nstatistics for centering, choices which naturally arise from the theory of\ngeneralized deviation measures and risk theory in general. When used in\nconjunction with the ReLU non-linearity, the underlying risk theory suggests\nnatural, arguably optimal choices for the deviation measure and statistic.\nUtilizing the suggested deviation measure and statistic, we show experimentally\nthat training is accelerated more so than with conventional BN, often with\nimproved error rate as well. Overall, we propose a more flexible BN\ntransformation supported by a complimentary theoretical framework that can\npotentially guide design choices.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 06:53:48 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Yuan", "Xiaoyong", ""], ["Feng", "Zheng", ""], ["Norton", "Matthew", ""], ["Li", "Xiaolin", ""]]}, {"id": "1812.03285", "submitter": "Chanwoo Park", "authors": "Chanwoo Park, Jae Myung Kim, Seok Hyeon Ha, Jungwoo Lee", "title": "Sampling-based Bayesian Inference with gradient uncertainty", "comments": "Presented at the Workshop on Bayesian Deep Learning, NeurIPS 2018,\n  Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks(NNs) have achieved impressive performance, often exceed\nhuman performance on many computer vision tasks. However, one of the most\nchallenging issues that still remains is that NNs are overconfident in their\npredictions, which can be very harmful when this arises in safety critical\napplications. In this paper, we show that predictive uncertainty can be\nefficiently estimated when we incorporate the concept of gradients uncertainty\ninto posterior sampling. The proposed method is tested on two different\ndatasets, MNIST for in-distribution confusing examples and notMNIST for\nout-of-distribution data. We show that our method is able to efficiently\nrepresent predictive uncertainty on both datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 08:23:37 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 06:56:51 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Park", "Chanwoo", ""], ["Kim", "Jae Myung", ""], ["Ha", "Seok Hyeon", ""], ["Lee", "Jungwoo", ""]]}, {"id": "1812.03288", "submitter": "Praneeth Vepakomma", "authors": "Praneeth Vepakomma, Tristan Swedish, Ramesh Raskar, Otkrist Gupta,\n  Abhimanyu Dubey", "title": "No Peek: A Survey of private distributed deep learning", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey distributed deep learning models for training or inference without\naccessing raw data from clients. These methods aim to protect confidential\npatterns in data while still allowing servers to train models. The distributed\ndeep learning methods of federated learning, split learning and large batch\nstochastic gradient descent are compared in addition to private and secure\napproaches of differential privacy, homomorphic encryption, oblivious transfer\nand garbled circuits in the context of neural networks. We study their\nbenefits, limitations and trade-offs with regards to computational resources,\ndata leakage and communication efficiency and also share our anticipated future\ntrends.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 08:54:37 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Vepakomma", "Praneeth", ""], ["Swedish", "Tristan", ""], ["Raskar", "Ramesh", ""], ["Gupta", "Otkrist", ""], ["Dubey", "Abhimanyu", ""]]}, {"id": "1812.03315", "submitter": "Cheng Cheng", "authors": "Cheng Cheng, Guijun Ma, Yong Zhang, Mingyang Sun, Fei Teng, Han Ding,\n  and Ye Yuan", "title": "Online Bearing Remaining Useful Life Prediction Based on a Novel\n  Degradation Indicator and Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TMECH.2020.2971503", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In industrial applications, nearly half the failures of motors are caused by\nthe degradation of rolling element bearings (REBs). Therefore, accurately\nestimating the remaining useful life (RUL) for REBs are of crucial importance\nto ensure the reliability and safety of mechanical systems. To tackle this\nchallenge, model-based approaches are often limited by the complexity of\nmathematical modeling. Conventional data-driven approaches, on the other hand,\nrequire massive efforts to extract the degradation features and construct\nhealth index. In this paper, a novel online data-driven framework is proposed\nto exploit the adoption of deep convolutional neural networks (CNN) in\npredicting the RUL of bearings. More concretely, the raw vibrations of training\nbearings are first processed using the Hilbert-Huang transform (HHT) and a\nnovel nonlinear degradation indicator is constructed as the label for learning.\nThe CNN is then employed to identify the hidden pattern between the extracted\ndegradation indicator and the vibration of training bearings, which makes it\npossible to estimate the degradation of the test bearings automatically.\nFinally, testing bearings' RULs are predicted by using a $\\epsilon$-support\nvector regression model. The superior performance of the proposed RUL\nestimation framework, compared with the state-of-the-art approaches, is\ndemonstrated through the experimental results. The generality of the proposed\nCNN model is also validated by transferring to bearings undergoing different\noperating conditions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 12:56:37 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Cheng", "Cheng", ""], ["Ma", "Guijun", ""], ["Zhang", "Yong", ""], ["Sun", "Mingyang", ""], ["Teng", "Fei", ""], ["Ding", "Han", ""], ["Yuan", "Ye", ""]]}, {"id": "1812.03337", "submitter": "Yang Liu", "authors": "Yang Liu, Yan Kang, Chaoping Xing, Tianjian Chen, Qiang Yang", "title": "Secure Federated Transfer Learning", "comments": "IEEE Intelligent Systems, doi: 10.1109/MIS.2020.2988525", "journal-ref": null, "doi": "10.1109/MIS.2020.2988525", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning relies on the availability of a vast amount of data for\ntraining. However, in reality, most data are scattered across different\norganizations and cannot be easily integrated under many legal and practical\nconstraints. In this paper, we introduce a new technique and framework, known\nas federated transfer learning (FTL), to improve statistical models under a\ndata federation. The federation allows knowledge to be shared without\ncompromising user privacy, and enables complimentary knowledge to be\ntransferred in the network. As a result, a target-domain party can build more\nflexible and powerful models by leveraging rich labels from a source-domain\nparty. A secure transfer cross validation approach is also proposed to guard\nthe FTL performance under the federation. The framework requires minimal\nmodifications to the existing model structure and provides the same level of\naccuracy as the non-privacy-preserving approach. This framework is very\nflexible and can be effectively adapted to various secure multi-party machine\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 15:15:13 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 03:35:19 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Liu", "Yang", ""], ["Kang", "Yan", ""], ["Xing", "Chaoping", ""], ["Chen", "Tianjian", ""], ["Yang", "Qiang", ""]]}, {"id": "1812.03350", "submitter": "Jeremiah Zhe Liu", "authors": "Jeremiah Zhe Liu, John Paisley, Marianthi-Anna Kioumourtzoglou, Brent\n  A. Coull", "title": "Adaptive and Calibrated Ensemble Learning with Dependent Tail-free\n  Process", "comments": "Work-in-progress manuscript appeared at Bayesian Nonparametrics\n  Workshop, Neural Information Processing Systems 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble learning is a mainstay in modern data science practice. Conventional\nensemble algorithms assigns to base models a set of deterministic, constant\nmodel weights that (1) do not fully account for variations in base model\naccuracy across subgroups, nor (2) provide uncertainty estimates for the\nensemble prediction, which could result in mis-calibrated (i.e. precise but\nbiased) predictions that could in turn negatively impact the algorithm\nperformance in real-word applications. In this work, we present an adaptive,\nprobabilistic approach to ensemble learning using dependent tail-free process\nas ensemble weight prior. Given input feature $\\mathbf{x}$, our method\noptimally combines base models based on their predictive accuracy in the\nfeature space $\\mathbf{x} \\in \\mathcal{X}$, and provides interpretable\nuncertainty estimates both in model selection and in ensemble prediction. To\nencourage scalable and calibrated inference, we derive a structured variational\ninference algorithm that jointly minimize KL objective and the model's\ncalibration score (i.e. Continuous Ranked Probability Score (CRPS)). We\nillustrate the utility of our method on both a synthetic nonlinear function\nregression task, and on the real-world application of spatio-temporal\nintegration of particle pollution prediction models in New England.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 16:49:32 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 16:47:21 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Liu", "Jeremiah Zhe", ""], ["Paisley", "John", ""], ["Kioumourtzoglou", "Marianthi-Anna", ""], ["Coull", "Brent A.", ""]]}, {"id": "1812.03362", "submitter": "Henry Kvinge", "authors": "Mark Blumstein and Henry Kvinge", "title": "Multi-Dimensional Scaling on Groups", "comments": "Significantly refined presentation of content. Addition of\n  connections to character theory. New more concise title and abstract. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO math.GR math.RT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the intrinsic symmetries in data for clear and efficient analysis\nis an important theme in signal processing and other data-driven sciences. A\nbasic example of this is the ubiquity of the discrete Fourier transform which\narises from translational symmetry (i.e. time-delay/phase-shift). Particularly\nimportant in this area is understanding how symmetries inform the algorithms\nthat we apply to our data. In this paper we explore the behavior of the\ndimensionality reduction algorithm multi-dimensional scaling (MDS) in the\npresence of symmetry. We show that understanding the properties of the\nunderlying symmetry group allows us to make strong statements about the output\nof MDS even before applying the algorithm itself. In analogy to Fourier theory,\nwe show that in some cases only a handful of fundamental \"frequencies\"\n(irreducible representations derived from the corresponding group) contribute\ninformation for the MDS Euclidean embedding.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 18:15:22 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 05:57:21 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Blumstein", "Mark", ""], ["Kvinge", "Henry", ""]]}, {"id": "1812.03365", "submitter": "Dennis George Wilson", "authors": "Dennis G Wilson, Sylvain Cussat-Blanc, Herv\\'e Luga, Kyle Harrington", "title": "Neuromodulated Learning in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the brain, learning signals change over time and synaptic location, and\nare applied based on the learning history at the synapse, in the complex\nprocess of neuromodulation. Learning in artificial neural networks, on the\nother hand, is shaped by hyper-parameters set before learning starts, which\nremain static throughout learning, and which are uniform for the entire\nnetwork. In this work, we propose a method of deep artificial neuromodulation\nwhich applies the concepts of biological neuromodulation to stochastic gradient\ndescent. Evolved neuromodulatory dynamics modify learning parameters at each\nlayer in a deep neural network over the course of the network's training. We\nshow that the same neuromodulatory dynamics can be applied to different models\nand can scale to new problems not encountered during evolution. Finally, we\nexamine the evolved neuromodulation, showing that evolution found dynamic,\nlocation-specific learning strategies.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 22:10:34 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Wilson", "Dennis G", ""], ["Cussat-Blanc", "Sylvain", ""], ["Luga", "Herv\u00e9", ""], ["Harrington", "Kyle", ""]]}, {"id": "1812.03372", "submitter": "Jonathon Byrd", "authors": "Jonathon Byrd and Zachary C. Lipton", "title": "What is the Effect of Importance Weighting in Deep Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance-weighted risk minimization is a key ingredient in many machine\nlearning algorithms for causal inference, domain adaptation, class imbalance,\nand off-policy reinforcement learning. While the effect of importance weighting\nis well-characterized for low-capacity misspecified models, little is known\nabout how it impacts over-parameterized, deep neural networks. This work is\ninspired by recent theoretical results showing that on (linearly) separable\ndata, deep linear networks optimized by SGD learn weight-agnostic solutions,\nprompting us to ask, for realistic deep networks, for which many practical\ndatasets are separable, what is the effect of importance weighting? We present\nthe surprising finding that while importance weighting impacts models early in\ntraining, its effect diminishes over successive epochs. Moreover, while L2\nregularization and batch normalization (but not dropout), restore some of the\nimpact of importance weighting, they express the effect via (seemingly) the\nwrong abstraction: why should practitioners tweak the L2 regularization, and by\nhow much, to produce the correct weighting effect? Our experiments confirm\nthese findings across a range of architectures and datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 19:19:04 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 17:40:28 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 23:27:19 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Byrd", "Jonathon", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1812.03381", "submitter": "Tim Salimans", "authors": "Tim Salimans and Richard Chen", "title": "Learning Montezuma's Revenge from a Single Demonstration", "comments": "Deep RL Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for learning from a single demonstration to solve\nhard exploration tasks like the Atari game Montezuma's Revenge. Instead of\nimitating human demonstrations, as proposed in other recent works, our approach\nis to maximize rewards directly. Our agent is trained using off-the-shelf\nreinforcement learning, but starts every episode by resetting to a state from a\ndemonstration. By starting from such demonstration states, the agent requires\nmuch less exploration to learn a game compared to when it starts from the\nbeginning of the game at every episode. We analyze reinforcement learning for\ntasks with sparse rewards in a simple toy environment, where we show that the\nrun-time of standard RL methods scales exponentially in the number of states\nbetween rewards. Our method reduces this to quadratic scaling, opening up many\ntasks that were previously infeasible. We then apply our method to Montezuma's\nRevenge, for which we present a trained agent achieving a high-score of 74,500,\nbetter than any previously published result.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 20:16:16 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Salimans", "Tim", ""], ["Chen", "Richard", ""]]}, {"id": "1812.03395", "submitter": "Mahito Sugiyama", "authors": "Yuka Yoneda and Mahito Sugiyama and Takashi Washio", "title": "Learning Graph Representation via Formal Concept Analysis", "comments": "5 pages, 2 figures, Relational Representation Learning Workshop\n  (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method that can learn a graph representation from\nmultivariate data. In our representation, each node represents a cluster of\ndata points and each edge represents the subset-superset relationship between\nclusters, which can be mutually overlapped. The key to our method is to use\nformal concept analysis (FCA), which can extract hierarchical relationships\nbetween clusters based on the algebraic closedness property. We empirically\nshow that our method can effectively extract hierarchical structures of\nclusters compared to the baseline method.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 22:30:11 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Yoneda", "Yuka", ""], ["Sugiyama", "Mahito", ""], ["Washio", "Takashi", ""]]}, {"id": "1812.03399", "submitter": "Christian Perez", "authors": "Christian F. Perez, Felipe Petroski Such, Theofanis Karaletsos", "title": "Efficient transfer learning and online adaptation with latent variable\n  models for continuous control", "comments": "Presented at Continual Learning Workshop, NeurIPS 2018, Montreal,\n  Canada. 5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional model-based RL relies on hand-specified or learned models of\ntransition dynamics of the environment. These methods are sample efficient and\nfacilitate learning in the real world but fail to generalize to subtle\nvariations in the underlying dynamics, e.g., due to differences in mass,\nfriction, or actuators across robotic agents or across time. We propose using\nvariational inference to learn an explicit latent representation of unknown\nenvironment properties that accelerates learning and facilitates generalization\non novel environments at test time. We use Online Bayesian Inference of these\nlearned latents to rapidly adapt online to changes in environments without\nretaining large replay buffers of recent data. Combined with a neural network\nensemble that models dynamics and captures uncertainty over dynamics, our\napproach demonstrates positive transfer during training and online adaptation\non the continuous control task HalfCheetah.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 22:46:37 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Perez", "Christian F.", ""], ["Such", "Felipe Petroski", ""], ["Karaletsos", "Theofanis", ""]]}, {"id": "1812.03405", "submitter": "Blerta Lindqvist", "authors": "Blerta Lindqvist, Shridatt Sugrim, Rauf Izmailov", "title": "AutoGAN: Robust Classifier Against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers fail to classify correctly input images that have been\npurposefully and imperceptibly perturbed to cause misclassification. This\nsusceptability has been shown to be consistent across classifiers, regardless\nof their type, architecture or parameters. Common defenses against adversarial\nattacks modify the classifer boundary by training on additional adversarial\nexamples created in various ways. In this paper, we introduce AutoGAN, which\ncounters adversarial attacks by enhancing the lower-dimensional manifold\ndefined by the training data and by projecting perturbed data points onto it.\nAutoGAN mitigates the need for knowing the attack type and magnitude as well as\nthe need for having adversarial samples of the attack. Our approach uses a\nGenerative Adversarial Network (GAN) with an autoencoder generator and a\ndiscriminator that also serves as a classifier. We test AutoGAN against\nadversarial samples generated with state-of-the-art Fast Gradient Sign Method\n(FGSM) as well as samples generated with random Gaussian noise, both using the\nMNIST dataset. For different magnitudes of perturbation in training and\ntesting, AutoGAN can surpass the accuracy of FGSM method by up to 25\\% points\non samples perturbed using FGSM. Without an augmented training dataset, AutoGAN\nachieves an accuracy of 89\\% compared to 1\\% achieved by FGSM method on FGSM\ntesting adversarial samples.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 23:50:11 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Lindqvist", "Blerta", ""], ["Sugrim", "Shridatt", ""], ["Izmailov", "Rauf", ""]]}, {"id": "1812.03410", "submitter": "Robert D\\\"urichen Dr.", "authors": "Robert D\\\"urichen, Thomas Rocznik, Oliver Renz, Christian Peters", "title": "Binary Input Layer: Training of CNN models with binary input data", "comments": "NeurIPS, 2nd Workshop on Machine Learning on the Phone and other\n  Consumer Devices (MLPCD 2), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For the efficient execution of deep convolutional neural networks (CNN) on\nedge devices, various approaches have been presented which reduce the bit width\nof the network parameters down to 1 bit. Binarization of the first layer was\nalways excluded, as it leads to a significant error increase. Here, we present\nthe novel concept of binary input layer (BIL), which allows the usage of binary\ninput data by learning bit specific binary weights. The concept is evaluated on\nthree datasets (PAMAP2, SVHN, CIFAR-10). Our results show that this approach is\nin particular beneficial for multimodal datasets (PAMAP2) where it outperforms\nnetworks using full precision weights in the first layer by 1:92 percentage\npoints (pp) while consuming only 2 % of the chip area.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 00:17:32 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["D\u00fcrichen", "Robert", ""], ["Rocznik", "Thomas", ""], ["Renz", "Oliver", ""], ["Peters", "Christian", ""]]}, {"id": "1812.03412", "submitter": "Cristian Rusu", "authors": "Cristian Rusu", "title": "Learning Multiplication-free Linear Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose several dictionary learning algorithms for sparse\nrepresentations that also impose specific structures on the learned\ndictionaries such that they are numerically efficient to use: reduced number of\naddition/multiplications and even avoiding multiplications altogether. We base\nour work on factorizations of the dictionary in highly structured basic\nbuilding blocks (binary orthonormal, scaling and shear transformations) for\nwhich we can write closed-form solutions to the optimization problems that we\nconsider. We show the effectiveness of our methods on image data where we can\ncompare against well-known numerically efficient transforms such as the fast\nFourier and the fast discrete cosine transforms.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 02:03:53 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 19:39:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Rusu", "Cristian", ""]]}, {"id": "1812.03425", "submitter": "Vedanshu Kumar", "authors": "Vedanshu and M M Tripathi", "title": "Zero Initialization of modified Gated Recurrent Encoder-Decoder Network\n  for Short Term Load Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single layer Feedforward Neural Network(FNN) is used many a time as a last\nlayer in models such as seq2seq or could be a simple RNN network. The\nimportance of such layer is to transform the output to our required dimensions.\nWhen it comes to weights and biases initialization, there is no such specific\ntechnique that could speed up the learning process. We could depend on deep\nnetwork initialization techniques such as Xavier or He initialization. But such\ninitialization fails to show much improvement in learning speed or accuracy. In\nthis paper we propose Zero Initialization (ZI) for weights of a single layer\nnetwork. We first test this technique with on a simple RNN network and compare\nthe results against Xavier, He and Identity initialization. As a final test we\nimplement it on a seq2seq network. It was found that ZI considerably reduces\nthe number of epochs used and improve the accuracy. The developed model has\nbeen applied for short-term load forecasting using the load data of Australian\nEnergy Market. The model is able to forecast the day ahead load accurately with\nerror of 0.94%.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 04:29:41 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Vedanshu", "", ""], ["Tripathi", "M M", ""]]}, {"id": "1812.03468", "submitter": "Sebastian Kauschke", "authors": "Sebastian Kauschke, David Hermann Lehmann", "title": "Towards Neural Network Patching: Evaluating Engagement-Layers and\n  Patch-Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we investigate fundamental requirements for the application of\nclassifier patching on neural networks. Neural network patching is an approach\nfor adapting neural network models to handle concept drift in nonstationary\nenvironments. Instead of creating or updating the existing network to\naccommodate concept drift, neural network patching leverages the inner layers\nof the network as well as its output to learn a patch that enhances the\nclassification and corrects errors caused by the drift. It learns (i) a\npredictor that estimates whether the original network will misclassify an\ninstance, and (ii) a patching network that fixes the misclassification. Neural\nnetwork patching is based on the idea that the original network can still\nclassify a majority of instances well, and that the inner feature\nrepresentations encoded in the deep network aid the classifier to cope with\nunseen or changed inputs. In order to apply this kind of patching, we evaluate\ndifferent engagement layers and patch architectures in this report, and find a\nset of generally applicable heuristics, which aid in parametrizing the patching\nprocedure.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 12:17:24 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 10:02:04 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Kauschke", "Sebastian", ""], ["Lehmann", "David Hermann", ""]]}, {"id": "1812.03469", "submitter": "Yenok Hakobyan", "authors": "Ruben A. Gevorgyan and Yenok B. Hakobyan", "title": "A matching based clustering algorithm for categorical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster analysis is one of the essential tasks in data mining and knowledge\ndiscovery. Each type of data poses unique challenges in achieving relatively\nefficient partitioning of the data into homogeneous groups. While the\nalgorithms for numeric data are relatively well studied in the literature,\nthere are still challenges to address in case of categorical data. The main\nissue is the unordered structure of categorical data, which makes the\nimplementation of the standard concepts of clustering algorithms difficult. For\ninstance, the assessment of distance between objects, the selection of\nrepresentatives for categorical data is not as straightforward as for\ncontinuous data. Therefore, this paper presents a new framework for\npartitioning categorical data, which does not use the distance measure as a key\nconcept. The Matching based clustering algorithm is designed based on the\nsimilarity matrix and a framework for updating the latter using the feature\nimportance criteria. The experimental results show this algorithm can serve as\nan alternative to existing ones and can be an efficient knowledge discovery\ntool.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 12:20:43 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Gevorgyan", "Ruben A.", ""], ["Hakobyan", "Yenok B.", ""]]}, {"id": "1812.03472", "submitter": "Daphna Weinshall", "authors": "Daphna Weinshall and Dan Amir", "title": "Theory of Curriculum Learning, with Convex Loss Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum Learning - the idea of teaching by gradually exposing the learner\nto examples in a meaningful order, from easy to hard, has been investigated in\nthe context of machine learning long ago. Although methods based on this\nconcept have been empirically shown to improve performance of several learning\nalgorithms, no theoretical analysis has been provided even for simple cases. To\naddress this shortfall, we start by formulating an ideal definition of\ndifficulty score - the loss of the optimal hypothesis at a given datapoint. We\nanalyze the possible contribution of curriculum learning based on this score in\ntwo convex problems - linear regression, and binary classification by hinge\nloss minimization. We show that in both cases, the expected convergence rate\ndecreases monotonically with the ideal difficulty score, in accordance with\nearlier empirical results. We also prove that when the ideal difficulty score\nis fixed, the convergence rate is monotonically increasing with respect to the\nloss of the current hypothesis at each point. We discuss how these results\nbring to term two apparently contradicting heuristics: curriculum learning on\nthe one hand, and hard data mining on the other.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 12:35:11 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Weinshall", "Daphna", ""], ["Amir", "Dan", ""]]}, {"id": "1812.03483", "submitter": "Yossi Adi", "authors": "Yossi Adi, Neil Zeghidour, Ronan Collobert, Nicolas Usunier, Vitaliy\n  Liptchinsky, Gabriel Synnaeve", "title": "To Reverse the Gradient or Not: An Empirical Comparison of Adversarial\n  and Multi-task Learning in Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcribed datasets typically contain speaker identity for each instance in\nthe data. We investigate two ways to incorporate this information during\ntraining: Multi-Task Learning and Adversarial Learning. In multi-task learning,\nthe goal is speaker prediction; we expect a performance improvement with this\njoint training if the two tasks of speech recognition and speaker recognition\nshare a common set of underlying features. In contrast, adversarial learning is\na means to learn representations invariant to the speaker. We then expect\nbetter performance if this learnt invariance helps generalizing to new\nspeakers. While the two approaches seem natural in the context of speech\nrecognition, they are incompatible because they correspond to opposite\ngradients back-propagated to the model. In order to better understand the\neffect of these approaches in terms of error rates, we compare both strategies\nin controlled settings. Moreover, we explore the use of additional\nuntranscribed data in a semi-supervised, adversarial learning manner to improve\nerror rates. Our results show that deep models trained on big datasets already\ndevelop invariant representations to speakers without any auxiliary loss. When\nconsidering adversarial learning and multi-task learning, the impact on the\nacoustic model seems minor. However, models trained in a semi-supervised manner\ncan improve error-rates.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 13:18:02 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 14:41:58 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 17:05:43 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Adi", "Yossi", ""], ["Zeghidour", "Neil", ""], ["Collobert", "Ronan", ""], ["Usunier", "Nicolas", ""], ["Liptchinsky", "Vitaliy", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "1812.03511", "submitter": "Yibo Yang", "authors": "Yibo Yang, Paris Perdikaris", "title": "Physics-informed deep generative models", "comments": "Accepted by the NIPS workshop 2018 of Bayesian Deep Learning. arXiv\n  admin note: text overlap with arXiv:1811.04026", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the application of deep generative models in propagating\nuncertainty through complex physical systems. Specifically, we put forth an\nimplicit variational inference formulation that constrains the generative model\noutput to satisfy given physical laws expressed by partial differential\nequations. Such physics-informed constraints provide a regularization mechanism\nfor effectively training deep probabilistic models for modeling physical\nsystems in which the cost of data acquisition is high and training data-sets\nare typically small. This provides a scalable framework for characterizing\nuncertainty in the outputs of physical systems due to randomness in their\ninputs or noise in their observations. We demonstrate the effectiveness of our\napproach through a canonical example in transport dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 16:12:59 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Yang", "Yibo", ""], ["Perdikaris", "Paris", ""]]}, {"id": "1812.03565", "submitter": "Stephen Tu", "authors": "Stephen Tu and Benjamin Recht", "title": "The Gap Between Model-Based and Model-Free Methods on the Linear\n  Quadratic Regulator: An Asymptotic Viewpoint", "comments": "Improved the main result regarding policy optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of model-based versus model-free methods is a long-standing\nquestion in reinforcement learning (RL). Motivated by recent empirical success\nof RL on continuous control tasks, we study the sample complexity of popular\nmodel-based and model-free algorithms on the Linear Quadratic Regulator (LQR).\nWe show that for policy evaluation, a simple model-based plugin method requires\nasymptotically less samples than the classical least-squares temporal\ndifference (LSTD) estimator to reach the same quality of solution; the sample\ncomplexity gap between the two methods can be at least a factor of state\ndimension. For policy evaluation, we study a simple family of problem instances\nand show that nominal (certainty equivalence principle) control also requires\nseveral factors of state and input dimension fewer samples than the policy\ngradient method to reach the same level of control performance on these\ninstances. Furthermore, the gap persists even when employing commonly used\nbaselines. To the best of our knowledge, this is the first theoretical result\nwhich demonstrates a separation in the sample complexity between model-based\nand model-free methods on a continuous control task.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 22:24:26 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 20:55:30 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tu", "Stephen", ""], ["Recht", "Benjamin", ""]]}, {"id": "1812.03580", "submitter": "Alessandro Davide Ialongo", "authors": "Alessandro Davide Ialongo, Mark van der Wilk, Carl Edward Rasmussen", "title": "Closed-form Inference and Prediction in Gaussian Process State-Space\n  Models", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine an analytic variational inference scheme for the Gaussian Process\nState Space Model (GPSSM) - a probabilistic model for system identification and\ntime-series modelling. Our approach performs variational inference over both\nthe system states and the transition function. We exploit Markov structure in\nthe true posterior, as well as an inducing point approximation to achieve\nlinear time complexity in the length of the time series. Contrary to previous\napproaches, no Monte Carlo sampling is required: inference is cast as a\ndeterministic optimisation problem. In a number of experiments, we demonstrate\nthe ability to model non-linear dynamics in the presence of both process and\nobservation noise as well as to impute missing information (e.g. velocities\nfrom raw positions through time), to de-noise, and to estimate the underlying\ndimensionality of the system. Finally, we also introduce a closed-form method\nfor multi-step prediction, and a novel criterion for assessing the quality of\nour approximate posterior.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 00:00:33 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Ialongo", "Alessandro Davide", ""], ["van der Wilk", "Mark", ""], ["Rasmussen", "Carl Edward", ""]]}, {"id": "1812.03596", "submitter": "Rahaf Aljundi", "authors": "Rahaf Aljundi and Klaas Kelchtermans and Tinne Tuytelaars", "title": "Task-Free Continual Learning", "comments": "Accepted as a conference paper in CVPR 2019. Rahaf Aljundi and Klaas\n  Kelchtermans have contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods proposed in the literature towards continual deep learning typically\noperate in a task-based sequential learning setup. A sequence of tasks is\nlearned, one at a time, with all data of current task available but not of\nprevious or future tasks. Task boundaries and identities are known at all\ntimes. This setup, however, is rarely encountered in practical applications.\nTherefore we investigate how to transform continual learning to an online\nsetup. We develop a system that keeps on learning over time in a streaming\nfashion, with data distributions gradually changing and without the notion of\nseparate tasks. To this end, we build on the work on Memory Aware Synapses, and\nshow how this method can be made online by providing a protocol to decide i)\nwhen to update the importance weights, ii) which data to use to update them,\nand iii) how to accumulate the importance weights at each update step.\nExperimental results show the validity of the approach in the context of two\napplications: (self-)supervised learning of a face recognition model by\nwatching soap series and learning a robot to avoid collisions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 02:07:57 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 08:09:27 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 10:42:15 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Aljundi", "Rahaf", ""], ["Kelchtermans", "Klaas", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1812.03599", "submitter": "Dongha Kim", "authors": "Yongdai Kim, Ilsang Ohn and Dongha Kim", "title": "Fast convergence rates of deep neural networks for classification", "comments": "35 pages, 2 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the fast convergence rates of a deep neural network (DNN)\nclassifier with the rectified linear unit (ReLU) activation function learned\nusing the hinge loss. We consider three cases for a true model: (1) a smooth\ndecision boundary, (2) smooth conditional class probability, and (3) the margin\ncondition (i.e., the probability of inputs near the decision boundary is\nsmall). We show that the DNN classifier learned using the hinge loss achieves\nfast rate convergences for all three cases provided that the architecture\n(i.e., the number of layers, number of nodes and sparsity). is carefully\nselected. An important implication is that DNN architectures are very flexible\nfor use in various cases without much modification. In addition, we consider a\nDNN classifier learned by minimizing the cross-entropy, and show that the DNN\nclassifier achieves a fast convergence rate under the condition that the\nconditional class probabilities of most data are sufficiently close to either 1\nor zero. This assumption is not unusual for image recognition because human\nbeings are extremely good at recognizing most images. To confirm our\ntheoretical explanation, we present the results of a small numerical study\nconducted to compare the hinge loss and cross-entropy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 02:41:06 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 08:23:48 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Kim", "Yongdai", ""], ["Ohn", "Ilsang", ""], ["Kim", "Dongha", ""]]}, {"id": "1812.03632", "submitter": "Nazmus Saquib", "authors": "Shoumik Sharar Chowdhury, Nazmus Saquib, Niamat Zawad, Manash Kumar\n  Mandal, Syed Haque", "title": "Statement networks: a power structure narrative as depicted by\n  newspapers", "comments": "Presented at NeurIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a data mining pipeline and subsequent analysis to understand the\ncore periphery power structure created in three national newspapers in\nBangladesh, as depicted by statements made by people appearing in news.\nStatements made by one actor about another actor can be considered a form of\npublic conversation. Named entity recognition techniques can be used to create\na temporal actor network from such conversations, which shows some unique\nstructure, and reveals much room for improvement in news reporting and also the\ntop actors' conversation preferences. Our results indicate there is a presence\nof cliquishness between powerful political leaders when it comes to their\nappearance in news. We also show how these cohesive cores form through the news\narticles, and how, over a decade, news cycles change the actors belonging in\nthese groups.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 05:40:54 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Chowdhury", "Shoumik Sharar", ""], ["Saquib", "Nazmus", ""], ["Zawad", "Niamat", ""], ["Mandal", "Manash Kumar", ""], ["Haque", "Syed", ""]]}, {"id": "1812.03662", "submitter": "Aviv Navon", "authors": "Aviv Navon, Saharon Rosset", "title": "Capturing Between-Tasks Covariance and Similarities Using Multivariate\n  Linear Mixed Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting several response variables using the\nsame set of explanatory variables. This setting naturally induces a group\nstructure over the coefficient matrix, in which every explanatory variable\ncorresponds to a set of related coefficients. Most of the existing methods that\nutilize this group formation assume that the similarities between related\ncoefficients arise solely through a joint sparsity structure. In this paper, we\npropose a procedure for constructing an estimator of a multivariate regression\ncoefficient matrix that directly models and captures the within-group\nsimilarities, by employing a multivariate linear mixed model formulation, with\na joint estimation of covariance matrices for coefficients and errors via\npenalized likelihood. Our approach, which we term Multivariate random\nRegression with Covariance Estimation (MrRCE) encourages structured similarity\nin parameters, in which coefficients for the same variable in related tasks\nsharing the same sign and similar magnitude. We illustrate the benefits of our\napproach in synthetic and real examples, and show that the proposed method\noutperforms natural competitors and alternative estimators under several model\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 07:52:15 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 12:19:59 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Navon", "Aviv", ""], ["Rosset", "Saharon", ""]]}, {"id": "1812.03684", "submitter": "Miljan Petrovi\\'c", "authors": "Miljan Petrovi\\'c (1 and 2), Thomas A.W. Bolton (1 and 2), Maria\n  Giulia Preti (1 and 2), Rapha\\\"el Li\\'egeois (1 and 2) and Dimitri Van De\n  Ville (1 and 2) ((1) Institute of Bioengineering, \\'Ecole Polytechnique\n  F\\'ed\\'erale de Lausanne, Campus Biotech, Geneva, Switzerland, (2) Department\n  of Radiology and Medical Informatics, University of Geneva, Geneva,\n  Switzerland)", "title": "Guided Graph Spectral Embedding: Application to the C. elegans\n  Connectome", "comments": "43 pages, 7 figures, submitted to Network Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph spectral analysis can yield meaningful embeddings of graphs by\nproviding insight into distributed features not directly accessible in nodal\ndomain. Recent efforts in graph signal processing have proposed new\ndecompositions-e.g., based on wavelets and Slepians-that can be applied to\nfilter signals defined on the graph. In this work, we take inspiration from\nthese constructions to define a new guided spectral embedding that combines\nmaximizing energy concentration with minimizing modified embedded distance for\na given importance weighting of the nodes. We show these optimization goals are\nintrinsically opposite, leading to a well-defined and stable spectral\ndecomposition. The importance weighting allows to put the focus on particular\nnodes and tune the trade-off between global and local effects. Following the\nderivation of our new optimization criterion and its linear approximation, we\nexemplify the methodology on the C. elegans structural connectome. The results\nof our analyses confirm known observations on the nematode's neural network in\nterms of functionality and importance of cells. Compared to Laplacian\nembedding, the guided approach, focused on a certain class of cells (sensory,\ninter- and motoneurons), provides more biological insights, such as the\ndistinction between somatic positions of cells, and their involvement in low or\nhigh order processing functions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 09:16:21 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 09:12:06 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 12:49:14 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Petrovi\u0107", "Miljan", "", "1 and 2"], ["Bolton", "Thomas A. W.", "", "1 and 2"], ["Preti", "Maria Giulia", "", "1 and 2"], ["Li\u00e9geois", "Rapha\u00ebl", "", "1 and 2"], ["Van De Ville", "Dimitri", "", "1 and 2"]]}, {"id": "1812.03699", "submitter": "Neema Kachappilly Davis", "authors": "Neema Davis, Gaurav Raina, Krishna Jagannathan", "title": "Taxi Demand-Supply Forecasting: Impact of Spatial Partitioning on the\n  Performance of Neural Networks", "comments": "Presented at the NIPS Workshop on Machine Learning in Intelligent\n  Transportation Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the significance of choosing an appropriate\ntessellation strategy for a spatio-temporal taxi demand-supply modeling\nframework. Our study compares (i) the variable-sized polygon based Voronoi\ntessellation, and (ii) the fixed-sized grid based Geohash tessellation, using\ntaxi demand-supply GPS data for the cities of Bengaluru, India and New York,\nUSA. Long Short-Term Memory (LSTM) networks are used for modeling and\nincorporating information from spatial neighbors into the model. We find that\nthe LSTM model based on input features extracted from a variable-sized polygon\ntessellation yields superior performance over the LSTM model based on\nfixed-sized grid tessellation. Our study highlights the need to explore\nmultiple spatial partitioning techniques for improving the prediction\nperformance in neural network models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 09:53:04 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Davis", "Neema", ""], ["Raina", "Gaurav", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "1812.03705", "submitter": "Chaithanya Kumar Mummadi", "authors": "Chaithanya Kumar Mummadi, Thomas Brox, Jan Hendrik Metzen", "title": "Defending Against Universal Perturbations With Shared Adversarial\n  Training", "comments": "ICCV 2019, 8 main pages, 9 appendix pages, 16 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers such as deep neural networks have been shown to be vulnerable\nagainst adversarial perturbations on problems with high-dimensional input\nspace. While adversarial training improves the robustness of image classifiers\nagainst such adversarial perturbations, it leaves them sensitive to\nperturbations on a non-negligible fraction of the inputs. In this work, we show\nthat adversarial training is more effective in preventing universal\nperturbations, where the same perturbation needs to fool a classifier on many\ninputs. Moreover, we investigate the trade-off between robustness against\nuniversal perturbations and performance on unperturbed data and propose an\nextension of adversarial training that handles this trade-off more gracefully.\nWe present results for image classification and semantic segmentation to\nshowcase that universal perturbations that fool a model hardened with\nadversarial training become clearly perceptible and show patterns of the target\nscene.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 10:02:45 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 11:58:27 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Mummadi", "Chaithanya Kumar", ""], ["Brox", "Thomas", ""], ["Metzen", "Jan Hendrik", ""]]}, {"id": "1812.03710", "submitter": "Zhen Wang", "authors": "Zhen Wang, Xu Chen, Chun-Na Li, and Yuan-Hai Shao", "title": "Ramp-based Twin Support Vector Clustering", "comments": "5 pages, 2 figures", "journal-ref": "Neural Computing and Applications, 2019", "doi": "10.1007/s00521-019-04511-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional plane-based clustering methods measure the cost of within-cluster\nand between-cluster by quadratic, linear or some other unbounded functions,\nwhich may amplify the impact of cost. This letter introduces a ramp cost\nfunction into the plane-based clustering to propose a new clustering method,\ncalled ramp-based twin support vector clustering (RampTWSVC). RampTWSVC is more\nrobust because of its boundness, and thus it is more easier to find the\nintrinsic clusters than other plane-based clustering methods. The non-convex\nprogramming problem in RampTWSVC is solved efficiently through an alternating\niteration algorithm, and its local solution can be obtained in a finite number\nof iterations theoretically. In addition, the nonlinear manifold-based\nformation of RampTWSVC is also proposed by kernel trick. Experimental results\non several benchmark datasets show the better performance of our RampTWSVC\ncompared with other plane-based clustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 10:10:53 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Wang", "Zhen", ""], ["Chen", "Xu", ""], ["Li", "Chun-Na", ""], ["Shao", "Yuan-Hai", ""]]}, {"id": "1812.03715", "submitter": "Krzysztof Bartoszek", "authors": "Krzysztof Bartoszek and Pietro Li\\`o", "title": "Modelling trait dependent speciation with Approximate Bayesian\n  Computation", "comments": null, "journal-ref": "Acta Physica Polonica B Proceedings Supplement, 12(1):25-47, 2019", "doi": "10.5506/APhysPolBSupp.12.25", "report-no": null, "categories": "q-bio.PE cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogeny is the field of modelling the temporal discrete dynamics of\nspeciation. Complex models can nowadays be studied using the Approximate\nBayesian Computation approach which avoids likelihood calculations. The field's\nprogression is hampered by the lack of robust software to estimate the numerous\nparameters of the speciation process. In this work we present an R package,\npcmabc, based on Approximate Bayesian Computations, that implements three novel\nphylogenetic algorithms for trait-dependent speciation modelling. Our\nphylogenetic comparative methodology takes into account both the simulated\ntraits and phylogeny, attempting to estimate the parameters of the processes\ngenerating the phenotype and the trait. The user is not restricted to a\npredefined set of models and can specify a variety of evolutionary and\nbranching models. We illustrate the software with a simulation-reestimation\nstudy focused around the branching Ornstein-Uhlenbeck process, where the\nbranching rate depends non-linearly on the value of the driving\nOrnstein-Uhlenbeck process. Included in this work is a tutorial on how to use\nthe software.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 10:17:12 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Bartoszek", "Krzysztof", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1812.03719", "submitter": "Marion G\u00f6del", "authors": "Marion G\\\"odel, Gerta K\\\"oster, Daniel Lehmberg, Manfred Gruber,\n  Angelika Kneidl, Florian Sesser", "title": "Can we learn where people go?", "comments": "Proceedings of the 9th International Conference on Pedestrian and\n  Evacuation Dynamics (PED2018) in Lund, Sweden, August 21-23, 2018 Paper No.\n  50, 8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most agent-based simulators, pedestrians navigate from origins to\ndestinations. Consequently, destinations are essential input parameters to the\nsimulation. While many other relevant parameters as positions, speeds and\ndensities can be obtained from sensors, like cameras, destinations cannot be\nobserved directly. Our research question is: Can we obtain this information\nfrom video data using machine learning methods? We use density heatmaps, which\nindicate the pedestrian density within a given camera cutout, as input to\npredict the destination distributions. For our proof of concept, we train a\nRandom Forest predictor on an exemplary data set generated with the Vadere\nmicroscopic simulator. The scenario is a crossroad where pedestrians can head\nleft, straight or right. In addition, we gain first insights on suitable\nplacement of the camera. The results motivate an in-depth analysis of the\nmethodology.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 10:24:51 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 10:13:58 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["G\u00f6del", "Marion", ""], ["K\u00f6ster", "Gerta", ""], ["Lehmberg", "Daniel", ""], ["Gruber", "Manfred", ""], ["Kneidl", "Angelika", ""], ["Sesser", "Florian", ""]]}, {"id": "1812.03813", "submitter": "Marcel Nassar", "authors": "Marcel Nassar", "title": "Hierarchical Bipartite Graph Convolution Networks", "comments": "Appeared in the Workshop on Relational Representation Learning (R2L)\n  at NIPS 2018. 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, graph neural networks have been adopted in a wide variety of\napplications ranging from relational representations to modeling irregular data\ndomains such as point clouds and social graphs. However, the space of graph\nneural network architectures remains highly fragmented impeding the development\nof optimized implementations similar to what is available for convolutional\nneural networks. In this work, we present BiGraphNet, a graph neural network\narchitecture that generalizes many popular graph neural network models and\nenables new efficient operations similar to those supported by ConvNets. By\nexplicitly separating the input and output nodes, BiGraphNet: (i) generalizes\nthe graph convolution to support new efficient operations such as coarsened\ngraph convolutions (similar to strided convolution in convnets), multiple input\ngraphs convolution and graph expansions (unpooling) which can be used to\nimplement various graph architectures such as graph autoencoders, and graph\nresidual nets; and (ii) accelerates and scales the computations and memory\nrequirements in hierarchical networks by performing computations only at\nspecified output nodes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 02:43:59 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 02:05:11 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Nassar", "Marcel", ""]]}, {"id": "1812.03825", "submitter": "Zijian Zhang", "authors": "Avishek Anand, Megha Khosla, Jaspreet Singh, Jan-Hendrik Zab and\n  Zijian Zhang", "title": "Asynchronous Training of Word Embeddings for Large Text Corpora", "comments": "This paper contains 9 pages and has been accepted in the WSDM2019", "journal-ref": null, "doi": "10.1145/3289600.3291011", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Word embeddings are a powerful approach for analyzing language and have been\nwidely popular in numerous tasks in information retrieval and text mining.\nTraining embeddings over huge corpora is computationally expensive because the\ninput is typically sequentially processed and parameters are synchronously\nupdated. Distributed architectures for asynchronous training that have been\nproposed either focus on scaling vocabulary sizes and dimensionality or suffer\nfrom expensive synchronization latencies.\n  In this paper, we propose a scalable approach to train word embeddings by\npartitioning the input space instead in order to scale to massive text corpora\nwhile not sacrificing the performance of the embeddings. Our training procedure\ndoes not involve any parameter synchronization except a final sub-model merge\nphase that typically executes in a few minutes. Our distributed training scales\nseamlessly to large corpus sizes and we get comparable and sometimes even up to\n45% performance improvement in a variety of NLP benchmarks using models trained\nby our distributed procedure which requires $1/10$ of the time taken by the\nbaseline approach. Finally we also show that we are robust to missing words in\nsub-models and are able to effectively reconstruct word representations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 11:34:33 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Anand", "Avishek", ""], ["Khosla", "Megha", ""], ["Singh", "Jaspreet", ""], ["Zab", "Jan-Hendrik", ""], ["Zhang", "Zijian", ""]]}, {"id": "1812.03859", "submitter": "Gennady Ososkov Alexeevich", "authors": "Dmitriy Baranov, Sergey Mitsyn, Pavel Goncharov, Gennady Ososkov", "title": "The particle track reconstruction based on deep learning neural networks", "comments": "8 pages, 3 figures, CHEP 2018, the 23rd International Conference on\n  Computing in High Energy and Nuclear Physics, Sofia, Bulgaria on July 9-13,\n  2018. arXiv admin note: text overlap with arXiv:1811.06002", "journal-ref": null, "doi": "10.1051/epjconf/201921406018", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most important problems of data processing in high energy and\nnuclear physics is the event reconstruction. Its main part is the track\nreconstruction procedure which consists in looking for all tracks that\nelementary particles leave when they pass through a detector among a huge\nnumber of points, so-called hits, produced when flying particles fire detector\ncoordinate planes. Unfortunately, the tracking is seriously impeded by the\nfamous shortcoming of multiwired, strip in GEM detectors due to the appearance\nin them a lot of fake hits caused by extra spurious crossings of fired strips.\nSince the number of those fakes is several orders of magnitude greater than for\ntrue hits, one faces with the quite serious difficulty to unravel possible\ntrack-candidates via true hits ignoring fakes. On the basis of our previous\ntwo-stage approach based on hits preprocessing using directed K-d tree search\nfollowed by a deep neural classifier we introduce here two new tracking\nalgorithms. Both algorithms combine those two stages in one while using\ndifferent types of deep neural nets. We show that both proposed deep networks\ndo not require any special preprocessing stage, are more accurate, faster and\ncan be easier parallelized. Preliminary results of our new approaches for\nsimulated events are presented.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 08:18:35 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Baranov", "Dmitriy", ""], ["Mitsyn", "Sergey", ""], ["Goncharov", "Pavel", ""], ["Ososkov", "Gennady", ""]]}, {"id": "1812.03889", "submitter": "S\\\"oren Dittmer", "authors": "S\\\"oren Dittmer, Tobias Kluth, Peter Maass, Daniel Otero Baguer", "title": "Regularization by architecture: A deep prior approach for inverse\n  problems", "comments": null, "journal-ref": "Journal of Mathematical Imaging and Vision (2019)", "doi": "10.1007/s10851-019-00923-x", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper studies so-called deep image prior (DIP) techniques in the\ncontext of ill-posed inverse problems. DIP networks have been recently\nintroduced for applications in image processing; also first experimental\nresults for applying DIP to inverse problems have been reported. This paper\naims at discussing different interpretations of DIP and to obtain analytic\nresults for specific network designs and linear operators. The main\ncontribution is to introduce the idea of viewing these approaches as the\noptimization of Tikhonov functionals rather than optimizing networks. Besides\ntheoretical results, we present numerical verifications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 15:54:33 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 14:46:22 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Dittmer", "S\u00f6ren", ""], ["Kluth", "Tobias", ""], ["Maass", "Peter", ""], ["Baguer", "Daniel Otero", ""]]}, {"id": "1812.03894", "submitter": "Reza Khodayi-mehr", "authors": "Reza Khodayi-mehr, Michael M. Zavlanos", "title": "Physics-Based Learning for Robotic Environmental Sensing", "comments": "20 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a physics-based method to learn environmental fields (EFs) using a\nmobile robot. Common purely data-driven methods require prohibitively many\nmeasurements to accurately learn such complex EFs. Alternatively, physics-based\nmodels provide global knowledge of EFs but require experimental validation,\ndepend on uncertain parameters, and are intractable for mobile robots. To\naddress these challenges, we propose a Bayesian framework to select the most\nlikely physics-based models of EFs in real-time, from a pool of numerical\nsolutions generated offline as a function of the uncertain parameters.\nSpecifically, we focus on turbulent flow fields and utilize Gaussian processes\n(GPs) to construct statistical models for them, using the pool of numerical\nsolutions to inform their prior mean. To incorporate flow measurements into\nthese GPs, we control a custom-built mobile robot through a sequence of\nwaypoints that maximize the information content of the measurements. We\nexperimentally demonstrate that our proposed framework constructs a posterior\ndistribution of the flow field that better approximates the real flow compared\nto the prior numerical solutions and purely data-driven methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 16:02:37 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 23:22:44 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 03:39:45 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 02:14:16 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Khodayi-mehr", "Reza", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "1812.03915", "submitter": "Cillian Brewitt", "authors": "Cillian Brewitt, Nigel Goddard", "title": "Non-Intrusive Load Monitoring with Fully Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-intrusive load monitoring or energy disaggregation involves estimating\nthe power consumption of individual appliances from measurements of the total\npower consumption of a home. Deep neural networks have been shown to be\neffective for energy disaggregation. In this work, we present a deep neural\nnetwork architecture which achieves state of the art disaggregation performance\nwith substantially improved computational efficiency, reducing model training\ntime by a factor of 32 and prediction time by a factor of 43. This improvement\nin efficiency could be especially useful for applications where disaggregation\nmust be performed in home on lower power devices, or for research experiments\nwhich involve training a large number of models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 16:50:32 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Brewitt", "Cillian", ""], ["Goddard", "Nigel", ""]]}, {"id": "1812.03928", "submitter": "Yan Zhang", "authors": "Yan Zhang, Jonathon Hare, Adam Pr\\\"ugel-Bennett", "title": "Learning Representations of Sets through Optimized Permutations", "comments": "Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations of sets are challenging to learn because operations on sets\nshould be permutation-invariant. To this end, we propose a\nPermutation-Optimisation module that learns how to permute a set end-to-end.\nThe permuted set can be further processed to learn a permutation-invariant\nrepresentation of that set, avoiding a bottleneck in traditional set models. We\ndemonstrate our model's ability to learn permutations and set representations\nwith either explicit or implicit supervision on four datasets, on which we\nachieve state-of-the-art results: number sorting, image mosaics, classification\nfrom image mosaics, and visual question answering.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 17:26:25 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 15:36:35 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 03:18:33 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Zhang", "Yan", ""], ["Hare", "Jonathon", ""], ["Pr\u00fcgel-Bennett", "Adam", ""]]}, {"id": "1812.03929", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, Osvaldo Simeone, Brian Gardner, and Andr\\'e Gr\\\"uning", "title": "An Introduction to Spiking Neural Networks: Probabilistic Models,\n  Learning Rules, and Applications", "comments": "This article is now superseded by arXiv:1910.01059. To appear on IEEE\n  Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) are distributed trainable systems whose\ncomputing elements, or neurons, are characterized by internal analog dynamics\nand by digital and sparse synaptic communications. The sparsity of the synaptic\nspiking inputs and the corresponding event-driven nature of neural processing\ncan be leveraged by hardware implementations that have demonstrated significant\nenergy reductions as compared to conventional Artificial Neural Networks\n(ANNs). Most existing training algorithms for SNNs have been designed either\nfor biological plausibility or through conversion from pre-trained ANNs via\nrate encoding. This paper aims at providing an introduction to SNNs by focusing\non a probabilistic signal processing methodology that enables the direct\nderivation of learning rules leveraging the unique time encoding capabilities\nof SNNs. To this end, the paper adopts discrete-time probabilistic models for\nnetworked spiking neurons, and it derives supervised and unsupervised learning\nrules from first principles by using variational inference. Examples and open\nresearch problems are also provided.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 17:29:12 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 11:39:43 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 16:21:34 GMT"}, {"version": "v4", "created": "Fri, 19 Jul 2019 18:10:12 GMT"}, {"version": "v5", "created": "Sun, 20 Oct 2019 12:43:05 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""], ["Gardner", "Brian", ""], ["Gr\u00fcning", "Andr\u00e9", ""]]}, {"id": "1812.03934", "submitter": "Tianbao Yang", "authors": "Zhuoning Yuan, Yan Yan, Rong Jin, Tianbao Yang", "title": "Stagewise Training Accelerates Convergence of Testing Error Over SGD", "comments": "More experiments on deep learning are added to verify the assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stagewise training strategy is widely used for learning neural networks,\nwhich runs a stochastic algorithm (e.g., SGD) starting with a relatively large\nstep size (aka learning rate) and geometrically decreasing the step size after\na number of iterations. It has been observed that the stagewise SGD has much\nfaster convergence than the vanilla SGD with a polynomially decaying step size\nin terms of both training error and testing error. {\\it But how to explain this\nphenomenon has been largely ignored by existing studies.} This paper provides\nsome theoretical evidence for explaining this faster convergence. In\nparticular, we consider a stagewise training strategy for minimizing empirical\nrisk that satisfies the Polyak-\\L ojasiewicz (PL) condition, which has been\nobserved/proved for neural networks and also holds for a broad family of convex\nfunctions. For convex loss functions and two classes of \"nice-behaviored\"\nnon-convex objectives that are close to a convex function, we establish faster\nconvergence of stagewise training than the vanilla SGD under the PL condition\non both training error and testing error. Experiments on stagewise learning of\ndeep residual networks exhibits that it satisfies one type of non-convexity\nassumption and therefore can be explained by our theory. Of independent\ninterest, the testing error bounds for the considered non-convex loss functions\nare dimensionality and norm independent.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 17:34:00 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 05:40:13 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 22:53:49 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Yuan", "Zhuoning", ""], ["Yan", "Yan", ""], ["Jin", "Rong", ""], ["Yang", "Tianbao", ""]]}, {"id": "1812.03955", "submitter": "Norman Di Palo", "authors": "Norman Di Palo, Harri Valpola", "title": "Improving Model-Based Control and Active Exploration with Reconstruction\n  Uncertainty Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model based predictions of future trajectories of a dynamical system often\nsuffer from inaccuracies, forcing model based control algorithms to re-plan\noften, thus being computationally expensive, suboptimal and not reliable. In\nthis work, we propose a model agnostic method for estimating the uncertainty of\na model?s predictions based on reconstruction error, using it in control and\nexploration. As our experiments show, this uncertainty estimation can be used\nto improve control performance on a wide variety of environments by choosing\npredictions of which the model is confident. It can also be used for active\nlearning to explore more efficiently the environment by planning for\ntrajectories with high uncertainty, allowing faster model learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:09:10 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Di Palo", "Norman", ""], ["Valpola", "Harri", ""]]}, {"id": "1812.03962", "submitter": "Leonhard Helminger", "authors": "Leonhard Helminger, Abdelaziz Djelouah, Markus Gross, Romann M. Weber", "title": "Disentangled Dynamic Representations from Unordered Data", "comments": "Symposium on Advances in Approximate Bayesian Inference, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep generative model that learns disentangled static and\ndynamic representations of data from unordered input. Our approach exploits\nregularities in sequential data that exist regardless of the order in which the\ndata is viewed. The result of our factorized graphical model is a\nwell-organized and coherent latent space for data dynamics. We demonstrate our\nmethod on several synthetic dynamic datasets and real video data featuring\nvarious facial expressions and head poses.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:19:04 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Helminger", "Leonhard", ""], ["Djelouah", "Abdelaziz", ""], ["Gross", "Markus", ""], ["Weber", "Romann M.", ""]]}, {"id": "1812.03965", "submitter": "Rohit Keshari", "authors": "Rohit Keshari, Richa Singh, Mayank Vatsa", "title": "Guided Dropout", "comments": "Accepted in AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is often used in deep neural networks to prevent over-fitting.\nConventionally, dropout training invokes \\textit{random drop} of nodes from the\nhidden layers of a Neural Network. It is our hypothesis that a guided selection\nof nodes for intelligent dropout can lead to better generalization as compared\nto the traditional dropout. In this research, we propose \"guided dropout\" for\ntraining deep neural network which drop nodes by measuring the strength of each\nnode. We also demonstrate that conventional dropout is a specific case of the\nproposed guided dropout. Experimental evaluation on multiple datasets including\nMNIST, CIFAR10, CIFAR100, SVHN, and Tiny ImageNet demonstrate the efficacy of\nthe proposed guided dropout.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:21:47 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Keshari", "Rohit", ""], ["Singh", "Richa", ""], ["Vatsa", "Mayank", ""]]}, {"id": "1812.03973", "submitter": "Dustin Tran", "authors": "Dustin Tran and Michael W. Dusenberry and Mark van der Wilk and\n  Danijar Hafner", "title": "Bayesian Layers: A Module for Neural Network Uncertainty", "comments": "Code available at https://github.com/tensorflow/tensor2tensor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Bayesian Layers, a module designed for fast experimentation with\nneural network uncertainty. It extends neural network libraries with drop-in\nreplacements for common layers. This enables composition via a unified\nabstraction over deterministic and stochastic functions and allows for\nscalability via the underlying system. These layers capture uncertainty over\nweights (Bayesian neural nets), pre-activation units (dropout), activations\n(\"stochastic output layers\"), or the function itself (Gaussian processes). They\ncan also be reversible to propagate uncertainty from input to output. We\ninclude code examples for common architectures such as Bayesian LSTMs, deep\nGPs, and flow-based models. As demonstration, we fit a 5-billion parameter\n\"Bayesian Transformer\" on 512 TPUv2 cores for uncertainty in machine\ntranslation and a Bayesian dynamics model for model-based planning. Finally, we\nshow how Bayesian Layers can be used within the Edward2 probabilistic\nprogramming language for probabilistic programs with stochastic processes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:46:21 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 20:05:54 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 23:11:16 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Tran", "Dustin", ""], ["Dusenberry", "Michael W.", ""], ["van der Wilk", "Mark", ""], ["Hafner", "Danijar", ""]]}, {"id": "1812.03981", "submitter": "Zhiyuan Li", "authors": "Sanjeev Arora, Zhiyuan Li, Kaifeng Lyu", "title": "Theoretical Analysis of Auto Rate-Tuning by Batch Normalization", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) has become a cornerstone of deep learning across\ndiverse architectures, appearing to help optimization as well as\ngeneralization. While the idea makes intuitive sense, theoretical analysis of\nits effectiveness has been lacking. Here theoretical support is provided for\none of its conjectured properties, namely, the ability to allow gradient\ndescent to succeed with less tuning of learning rates. It is shown that even if\nwe fix the learning rate of scale-invariant parameters (e.g., weights of each\nlayer with BN) to a constant (say, $0.3$), gradient descent still approaches a\nstationary point (i.e., a solution where gradient is zero) in the rate of\n$T^{-1/2}$ in $T$ iterations, asymptotically matching the best bound for\ngradient descent with well-tuned learning rates. A similar result with\nconvergence rate $T^{-1/4}$ is also shown for stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:58:12 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Arora", "Sanjeev", ""], ["Li", "Zhiyuan", ""], ["Lyu", "Kaifeng", ""]]}, {"id": "1812.04064", "submitter": "Shen Wang", "authors": "Shen Wang, Zhengzhang Chen, Ding Li, Lu-An Tang, Jingchao Ni, Zhichun\n  Li, Junghwan Rhee, Haifeng Chen, Philip S. Yu", "title": "Attentional Heterogeneous Graph Neural Network: Application to Program\n  Reidentification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program or process is an integral part of almost every IT/OT system. Can we\ntrust the identity/ID (e.g., executable name) of the program? To avoid\ndetection, malware may disguise itself using the ID of a legitimate program,\nand a system tool (e.g., PowerShell) used by the attackers may have the fake ID\nof another common software, which is less sensitive. However, existing\nintrusion detection techniques often overlook this critical program\nreidentification problem (i.e., checking the program's identity). In this\npaper, we propose an attentional heterogeneous graph neural network model\n(DeepHGNN) to verify the program's identity based on its system behaviors. The\nkey idea is to leverage the representation learning of the heterogeneous\nprogram behavior graph to guide the reidentification process. We formulate the\nprogram reidentification as a graph classification problem and develop an\neffective attentional heterogeneous graph embedding algorithm to solve it.\nExtensive experiments --- using real-world enterprise monitoring data and real\nattacks --- demonstrate the effectiveness of DeepHGNN across multiple popular\nmetrics and the robustness to the normal dynamic changes like program version\nupgrades.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 20:08:47 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 02:48:11 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Wang", "Shen", ""], ["Chen", "Zhengzhang", ""], ["Li", "Ding", ""], ["Tang", "Lu-An", ""], ["Ni", "Jingchao", ""], ["Li", "Zhichun", ""], ["Rhee", "Junghwan", ""], ["Chen", "Haifeng", ""], ["Yu", "Philip S.", ""]]}, {"id": "1812.04069", "submitter": "Swati Gupta", "authors": "Swati Gupta, Vijay Kamble", "title": "Individual Fairness in Hindsight", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since many critical decisions impacting human lives are increasingly being\nmade by algorithms, it is important to ensure that the treatment of individuals\nunder such algorithms is demonstrably fair under reasonable notions of\nfairness. One compelling notion proposed in the literature is that of\nindividual fairness (IF), which advocates that similar individuals should be\ntreated similarly (Dwork et al. 2012). Originally proposed for offline\ndecisions, this notion does not, however, account for temporal considerations\nrelevant for online decision-making. In this paper, we extend the notion of IF\nto account for the time at which a decision is made, in settings where there\nexists a notion of conduciveness of decisions as perceived by the affected\nindividuals. We introduce two definitions: (i) fairness-across-time (FT) and\n(ii) fairness-in-hindsight (FH). FT is the simplest temporal extension of IF\nwhere treatment of individuals is required to be individually fair relative to\nthe past as well as future, while in FH, we require a one-sided notion of\nindividual fairness that is defined relative to only the past decisions. We\nshow that these two definitions can have drastically different implications in\nthe setting where the principal needs to learn the utility model. Linear regret\nrelative to optimal individually fair decisions is inevitable under FT for\nnon-trivial examples. On the other hand, we design a new algorithm: Cautious\nFair Exploration (CaFE), which satisfies FH and achieves sub-linear regret\nguarantees for a broad range of settings. We characterize lower bounds showing\nthat these guarantees are order-optimal in the worst case. FH can thus be\nembedded as a primary safeguard against unfair discrimination in algorithmic\ndeployments, without hindering the ability to take good decisions in the\nlong-run.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 20:25:29 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 17:44:42 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 18:48:09 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Gupta", "Swati", ""], ["Kamble", "Vijay", ""]]}, {"id": "1812.04079", "submitter": "Stanislas Chambon", "authors": "Stanislas Chambon, Valentin Thorey, Pierrick J. Arnal, Emmanuel\n  Mignot, Alexandre Gramfort", "title": "DOSED: a deep learning approach to detect multiple sleep micro-events in\n  EEG signal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Electroencephalography (EEG) monitors brain activity during sleep\nand is used to identify sleep disorders. In sleep medicine, clinicians\ninterpret raw EEG signals in so-called sleep stages, which are assigned by\nexperts to every 30s window of signal. For diagnosis, they also rely on shorter\nprototypical micro-architecture events which exhibit variable durations and\nshapes, such as spindles, K-complexes or arousals. Annotating such events is\ntraditionally performed by a trained sleep expert, making the process time\nconsuming, tedious and subject to inter-scorer variability. To automate this\nprocedure, various methods have been developed, yet these are event-specific\nand rely on the extraction of hand-crafted features.\n  New method: We propose a novel deep learning architecure called Dreem One\nShot Event Detector (DOSED). DOSED jointly predicts locations, durations and\ntypes of events in EEG time series. The proposed approach, applied here on\nsleep related micro-architecture events, is inspired by object detectors\ndeveloped for computer vision such as YOLO and SSD. It relies on a\nconvolutional neural network that builds a feature representation from raw EEG\nsignals, as well as two modules performing localization and classification\nrespectively.\n  Results and comparison with other methods: The proposed approach is tested on\n4 datasets and 3 types of events (spindles, K-complexes, arousals) and compared\nto the current state-of-the-art detection algorithms.\n  Conclusions: Results demonstrate the versatility of this new approach and\nimproved performance compared to the current state-of-the-art detection\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 12:14:08 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Chambon", "Stanislas", ""], ["Thorey", "Valentin", ""], ["Arnal", "Pierrick J.", ""], ["Mignot", "Emmanuel", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1812.04103", "submitter": "Zhengyang Wang", "authors": "Zhengyang Wang, Na Zou, Dinggang Shen, Shuiwang Ji", "title": "Non-local U-Net for Biomedical Image Segmentation", "comments": "In Proceedings of the 34th AAAI Conference on Artificial Intelligence\n  (AAAI), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown its great promise in various biomedical image\nsegmentation tasks. Existing models are typically based on U-Net and rely on an\nencoder-decoder architecture with stacked local operators to aggregate\nlong-range information gradually. However, only using the local operators\nlimits the efficiency and effectiveness. In this work, we propose the non-local\nU-Nets, which are equipped with flexible global aggregation blocks, for\nbiomedical image segmentation. These blocks can be inserted into U-Net as\nsize-preserving processes, as well as down-sampling and up-sampling layers. We\nperform thorough experiments on the 3D multimodality isointense infant brain MR\nimage segmentation task to evaluate the non-local U-Nets. Results show that our\nproposed models achieve top performances with fewer parameters and faster\ncomputation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 21:28:55 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 21:00:45 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Wang", "Zhengyang", ""], ["Zou", "Na", ""], ["Shen", "Dinggang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "1812.04109", "submitter": "Junjie Liang", "authors": "Junjie Liang, Jinlong Hu, Shoubin Dong and Vasant Honavar", "title": "Top-N-Rank: A Scalable List-wise Ranking Method for Recommender Systems", "comments": "paper accepted by the 2018 IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Top-N-Rank, a novel family of list-wise Learning-to-Rank models\nfor reliably recommending the N top-ranked items. The proposed models optimize\na variant of the widely used discounted cumulative gain (DCG) objective\nfunction which differs from DCG in two important aspects: (i) It limits the\nevaluation of DCG only on the top N items in the ranked lists, thereby\neliminating the impact of low-ranked items on the learned ranking function; and\n(ii) it incorporates weights that allow the model to leverage multiple types of\nimplicit feedback with differing levels of reliability or trustworthiness.\nBecause the resulting objective function is non-smooth and hence challenging to\noptimize, we consider two smooth approximations of the objective function,\nusing the traditional sigmoid function and the rectified linear unit (ReLU). We\npropose a family of learning-to-rank algorithms (Top-N-Rank) that work with any\nsmooth objective function. Then, a more efficient variant, Top-N-Rank.ReLU, is\nintroduced, which effectively exploits the properties of ReLU function to\nreduce the computational complexity of Top-N-Rank from quadratic to linear in\nthe average number of items rated by users. The results of our experiments\nusing two widely used benchmarks, namely, the MovieLens data set and the Amazon\nVideo Games data set demonstrate that: (i) The `top-N truncation' of the\nobjective function substantially improves the ranking quality of the top N\nrecommendations; (ii) using the ReLU for smoothing the objective function\nyields significant improvement in both ranking quality as well as runtime as\ncompared to using the sigmoid; and (iii) Top-N-Rank.ReLU substantially\noutperforms the well-performing list-wise ranking methods in terms of ranking\nquality.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 21:39:16 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 17:24:46 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Liang", "Junjie", ""], ["Hu", "Jinlong", ""], ["Dong", "Shoubin", ""], ["Honavar", "Vasant", ""]]}, {"id": "1812.04118", "submitter": "Cailey Kerley", "authors": "Cailey I. Kerley, Yuankai Huo, Shikha Chaganti, Shunxing Bao, Mayur B.\n  Patel, Bennett A. Landman", "title": "Montage based 3D Medical Image Retrieval from Traumatic Brain Injury\n  Cohort using Deep Convolutional Neural Network", "comments": "Accepted for SPIE: Medical Imaging 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain imaging analysis on clinically acquired computed tomography (CT) is\nessential for the diagnosis, risk prediction of progression, and treatment of\nthe structural phenotypes of traumatic brain injury (TBI). However, in real\nclinical imaging scenarios, entire body CT images (e.g., neck, abdomen, chest,\npelvis) are typically captured along with whole brain CT scans. For instance,\nin a typical sample of clinical TBI imaging cohort, only ~15% of CT scans\nactually contain whole brain CT images suitable for volumetric brain analyses;\nthe remaining are partial brain or non-brain images. Therefore, a manual image\nretrieval process is typically required to isolate the whole brain CT scans\nfrom the entire cohort. However, the manual image retrieval is time and\nresource consuming and even more difficult for the larger cohorts. To alleviate\nthe manual efforts, in this paper we propose an automated 3D medical image\nretrieval pipeline, called deep montage-based image retrieval (dMIR), which\nperforms classification on 2D montage images via a deep convolutional neural\nnetwork. The novelty of the proposed method for image processing is to\ncharacterize the medical image retrieval task based on the montage images. In a\ncohort of 2000 clinically acquired TBI scans, 794 scans were used as training\ndata, 206 scans were used as validation data, and the remaining 1000 scans were\nused as testing data. The proposed achieved accuracy=1.0, recall=1.0,\nprecision=1.0, f1=1.0 for validation data, while achieved accuracy=0.988,\nrecall=0.962, precision=0.962, f1=0.962 for testing data. Thus, the proposed\ndMIR is able to perform accurate CT whole brain image retrieval from\nlarge-scale clinical cohorts.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 21:58:01 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Kerley", "Cailey I.", ""], ["Huo", "Yuankai", ""], ["Chaganti", "Shikha", ""], ["Bao", "Shunxing", ""], ["Patel", "Mayur B.", ""], ["Landman", "Bennett A.", ""]]}, {"id": "1812.04145", "submitter": "Barry-John Theobald", "authors": "Katherine Metcalf, Barry-John Theobald, Nicholas Apostoloff", "title": "Learning Sharing Behaviors with Arbitrary Numbers of Agents", "comments": "14 pages, 9 figures, 3 tables, International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS), machine learning, Reinforcement\n  learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for modeling and learning turn-taking behaviors for\naccessing a shared resource. We model the individual behavior for each agent in\nan interaction and then use a multi-agent fusion model to generate a summary\nover the expected actions of the group to render the model independent of the\nnumber of agents. The individual behavior models are weighted finite state\ntransducers (WFSTs) with weights dynamically updated during interactions, and\nthe multi-agent fusion model is a logistic regression classifier.\n  We test our models in a multi-agent tower-building environment, where a\nQ-learning agent learns to interact with rule-based agents. Our approach\naccurately models the underlying behavior patterns of the rule-based agents\nwith accuracy ranging between 0.63 and 1.0 depending on the stochasticity of\nthe other agent behaviors. In addition we show using KL-divergence that the\nmodel accurately captures the distribution of next actions when interacting\nwith both a single agent (KL-divergence < 0.1) and with multiple agents\n(KL-divergence < 0.37). Finally, we demonstrate that our behavior model can be\nused by a Q-learning agent to take turns in an interactive turn-taking\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 23:20:45 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Metcalf", "Katherine", ""], ["Theobald", "Barry-John", ""], ["Apostoloff", "Nicholas", ""]]}, {"id": "1812.04152", "submitter": "Lennard Hilgendorf", "authors": "Lennard Hilgendorf", "title": "Duelling Bandits with Weak Regret in Adversarial Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on the multi-armed bandit problem has studied the trade-off of\nexploration and exploitation in depth. However, there are numerous applications\nwhere the cardinal absolute-valued feedback model (e.g. ratings from one to\nfive) is not suitable. This has motivated the formulation of the duelling\nbandits problem, where the learner picks a pair of actions and observes a noisy\nbinary feedback, indicating a relative preference between the two. There exist\na multitude of different settings and interpretations of the problem for two\nreasons. First, due to the absence of a total order of actions, there is no\nnatural definition of the best action. Existing work either explicitly assumes\nthe existence of a linear order, or uses a custom definition for the winner.\nSecond, there are multiple reasonable notions of regret to measure the\nlearner's performance. Most prior work has been focussing on the\n$\\textit{strong regret}$, which averages the quality of the two actions picked.\nThis work focusses on the $\\textit{weak regret}$, which is based on the quality\nof the better of the two actions selected. Weak regret is the more appropriate\nperformance measure when the pair's inferior action has no significant\ndetrimental effect on the pair's quality.\n  We study the duelling bandits problem in the adversarial setting. We provide\nan algorithm which has theoretical guarantees in both the utility-based\nsetting, which implies a total order, and the unrestricted setting. For the\nlatter, we work with the $\\textit{Borda winner}$, finding the action maximising\nthe probability of winning against an action sampled uniformly at random. The\nthesis concludes with experimental results based on both real-world data and\nsynthetic data, showing the algorithm's performance and limitations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 23:43:36 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Hilgendorf", "Lennard", ""]]}, {"id": "1812.04155", "submitter": "Khanh Nguyen", "authors": "Khanh Nguyen, Debadeepta Dey, Chris Brockett, and Bill Dolan", "title": "Vision-based Navigation with Language-based Assistance via Imitation\n  Learning with Indirect Intervention", "comments": "In CVPR 2019, 16 pages, appendix included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Vision-based Navigation with Language-based Assistance (VNLA), a\ngrounded vision-language task where an agent with visual perception is guided\nvia language to find objects in photorealistic indoor environments. The task\nemulates a real-world scenario in that (a) the requester may not know how to\nnavigate to the target objects and thus makes requests by only specifying\nhigh-level end-goals, and (b) the agent is capable of sensing when it is lost\nand querying an advisor, who is more qualified at the task, to obtain language\nsubgoals to make progress. To model language-based assistance, we develop a\ngeneral framework termed Imitation Learning with Indirect Intervention (I3L),\nand propose a solution that is effective on the VNLA task. Empirical results\nshow that this approach significantly improves the success rate of the learning\nagent over other baselines in both seen and unseen environments. Our code and\ndata are publicly available at https://github.com/debadeepta/vnla .\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 23:48:25 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 13:40:30 GMT"}, {"version": "v3", "created": "Sat, 22 Dec 2018 03:27:28 GMT"}, {"version": "v4", "created": "Sat, 6 Apr 2019 02:02:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Nguyen", "Khanh", ""], ["Dey", "Debadeepta", ""], ["Brockett", "Chris", ""], ["Dolan", "Bill", ""]]}, {"id": "1812.04181", "submitter": "Mohammad Firouzi", "authors": "Mohammad Firouzi", "title": "KF-LAX: Kronecker-factored curvature estimation for control variate\n  optimization in reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key challenge for gradient based optimization methods in model-free\nreinforcement learning is to develop an approach that is sample efficient and\nhas low variance. In this work, we apply Kronecker-factored curvature\nestimation technique (KFAC) to a recently proposed gradient estimator for\ncontrol variate optimization, RELAX, to increase the sample efficiency of using\nthis gradient estimation method in reinforcement learning. The performance of\nthe proposed method is demonstrated on a synthetic problem and a set of three\ndiscrete control task Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 01:56:39 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Firouzi", "Mohammad", ""]]}, {"id": "1812.04202", "submitter": "Ziwei Zhang", "authors": "Ziwei Zhang, Peng Cui and Wenwu Zhu", "title": "Deep Learning on Graphs: A Survey", "comments": "Accepted by Transactions on Knowledge and Data Engineering. 24 pages,\n  11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been shown to be successful in a number of domains, ranging\nfrom acoustics, images, to natural language processing. However, applying deep\nlearning to the ubiquitous graph data is non-trivial because of the unique\ncharacteristics of graphs. Recently, substantial research efforts have been\ndevoted to applying deep learning methods to graphs, resulting in beneficial\nadvances in graph analysis techniques. In this survey, we comprehensively\nreview the different types of deep learning methods on graphs. We divide the\nexisting methods into five categories based on their model architectures and\ntraining strategies: graph recurrent neural networks, graph convolutional\nnetworks, graph autoencoders, graph reinforcement learning, and graph\nadversarial methods. We then provide a comprehensive overview of these methods\nin a systematic manner mainly by following their development history. We also\nanalyze the differences and compositions of different methods. Finally, we\nbriefly outline the applications in which they have been used and discuss\npotential future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 03:16:57 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 13:00:58 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 04:07:37 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Zhang", "Ziwei", ""], ["Cui", "Peng", ""], ["Zhu", "Wenwu", ""]]}, {"id": "1812.04214", "submitter": "Prasad Cheema", "authors": "Prasad Cheema, Mehrisadat M. Alamdari, Gareth A. Vio", "title": "New Approaches to Inverse Structural Modification Theory using Random\n  Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many contexts the modal properties of a structure change, either due to\nthe impact of a changing environment, fatigue, or due to the presence of\nstructural damage. For example during flight, an aircraft's modal properties\nare known to change with both altitude and velocity. It is thus important to\nquantify these changes given only a truncated set of modal data, which is\nusually the case experimentally. This procedure is formally known as the\ngeneralised inverse eigenvalue problem. In this paper we experimentally show\nthat first-order gradient-based methods that optimise objective functions\ndefined over a modal are prohibitive due to the required small step sizes. This\nin turn leads to the justification of using a non-gradient, black box optimiser\nin the form of particle swarm optimisation. We further show how it is possible\nto solve such inverse eigenvalue problems in a lower dimensional space by the\nuse of random projections, which in many cases reduces the total dimensionality\nof the optimisation problem by 80% to 99%. Two example problems are explored\ninvolving a ten-dimensional mass-stiffness toy problem, and a one-dimensional\nfinite element mass-stiffness approximation for a Boeing 737-300 aircraft.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 04:12:36 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Cheema", "Prasad", ""], ["Alamdari", "Mehrisadat M.", ""], ["Vio", "Gareth A.", ""]]}, {"id": "1812.04218", "submitter": "Jiaming Song", "authors": "Jiaming Song, Pratyusha Kalluri, Aditya Grover, Shengjia Zhao, Stefano\n  Ermon", "title": "Learning Controllable Fair Representations", "comments": "AISTATS 2019, fixed a typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning data representations that are transferable and are fair with respect\nto certain protected attributes is crucial to reducing unfair decisions while\npreserving the utility of the data. We propose an information-theoretically\nmotivated objective for learning maximally expressive representations subject\nto fairness constraints. We demonstrate that a range of existing approaches\noptimize approximations to the Lagrangian dual of our objective. In contrast to\nthese existing approaches, our objective allows the user to control the\nfairness of the representations by specifying limits on unfairness. Exploiting\nduality, we introduce a method that optimizes the model parameters as well as\nthe expressiveness-fairness trade-off. Empirical evidence suggests that our\nproposed method can balance the trade-off between multiple notions of fairness\nand achieves higher expressiveness at a lower computational cost.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 04:44:48 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:30:21 GMT"}, {"version": "v3", "created": "Sat, 14 Mar 2020 10:12:56 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Song", "Jiaming", ""], ["Kalluri", "Pratyusha", ""], ["Grover", "Aditya", ""], ["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "1812.04224", "submitter": "Zi Yin", "authors": "Zi Yin, Yuanyuan Shen", "title": "On the Dimensionality of Word Embedding", "comments": "18 pages, Advances in Neural Information Processing Systems 31\n  (NeurIPS 2018, Oral Presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a theoretical understanding of word embedding and\nits dimensionality. Motivated by the unitary-invariance of word embedding, we\npropose the Pairwise Inner Product (PIP) loss, a novel metric on the\ndissimilarity between word embeddings. Using techniques from matrix\nperturbation theory, we reveal a fundamental bias-variance trade-off in\ndimensionality selection for word embeddings. This bias-variance trade-off\nsheds light on many empirical observations which were previously unexplained,\nfor example the existence of an optimal dimensionality. Moreover, new insights\nand discoveries, like when and how word embeddings are robust to over-fitting,\nare revealed. By optimizing over the bias-variance trade-off of the PIP loss,\nwe can explicitly answer the open question of dimensionality selection for word\nembedding.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 05:25:38 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Yin", "Zi", ""], ["Shen", "Yuanyuan", ""]]}, {"id": "1812.04227", "submitter": "Hyunwoo Jung", "authors": "Hyunwoo Jung, Moonsu Han, Minki Kang, Sungju Hwang", "title": "Learning What to Remember: Long-term Episodic Memory Networks for\n  Learning from Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current generation of memory-augmented neural networks has limited\nscalability as they cannot efficiently process data that are too large to fit\nin the external memory storage. One example of this is lifelong learning\nscenario where the model receives unlimited length of data stream as an input\nwhich contains vast majority of uninformative entries. We tackle this problem\nby proposing a memory network fit for long-term lifelong learning scenario,\nwhich we refer to as Long-term Episodic Memory Networks (LEMN), that features a\nRNN-based retention agent that learns to replace less important memory entries\nbased on the retention probability generated on each entry that is learned to\nidentify data instances of generic importance relative to other memory entries,\nas well as its historical importance. Such learning of retention agent allows\nour long-term episodic memory network to retain memory entries of generic\nimportance for a given task. We validate our model on a path-finding task as\nwell as synthetic and real question answering tasks, on which our model\nachieves significant improvements over the memory augmented networks with\nrule-based memory scheduling as well as an RL-based baseline that does not\nconsider relative or historical importance of the memory.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 06:04:32 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Jung", "Hyunwoo", ""], ["Han", "Moonsu", ""], ["Kang", "Minki", ""], ["Hwang", "Sungju", ""]]}, {"id": "1812.04287", "submitter": "Yazhou Ren", "authors": "Yazhou Ren, Ni Wang, Mingxia Li, Zenglin Xu", "title": "Deep Density-based Image Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep clustering, which is able to perform feature learning that\nfavors clustering tasks via deep neural networks, has achieved remarkable\nperformance in image clustering applications. However, the existing deep\nclustering algorithms generally need the number of clusters in advance, which\nis usually unknown in real-world tasks. In addition, the initial cluster\ncenters in the learned feature space are generated by $k$-means. This only\nworks well on spherical clusters and probably leads to unstable clustering\nresults. In this paper, we propose a two-stage deep density-based image\nclustering (DDC) framework to address these issues. The first stage is to train\na deep convolutional autoencoder (CAE) to extract low-dimensional feature\nrepresentations from high-dimensional image data, and then apply t-SNE to\nfurther reduce the data to a 2-dimensional space favoring density-based\nclustering algorithms. The second stage is to apply the developed density-based\nclustering technique on the 2-dimensional embedded data to automatically\nrecognize an appropriate number of clusters with arbitrary shapes. Concretely,\na number of local clusters are generated to capture the local structures of\nclusters, and then are merged via their density relationship to form the final\nclustering result. Experiments demonstrate that the proposed DDC achieves\ncomparable or even better clustering performance than state-of-the-art deep\nclustering methods, even though the number of clusters is not given.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 09:27:20 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ren", "Yazhou", ""], ["Wang", "Ni", ""], ["Li", "Mingxia", ""], ["Xu", "Zenglin", ""]]}, {"id": "1812.04300", "submitter": "Nicolas Langren\\'e", "authors": "C\\^ome Hur\\'e (LPSM UMR 8001, UPD7), Huy\\^en Pham (LPSM (UMR\\_8001),\n  UPD7), Achref Bachouch (UiO), Nicolas Langren\\'e (CSIRO)", "title": "Deep neural networks algorithms for stochastic control problems on\n  finite horizon: convergence analysis", "comments": "To appear in SIAM Journal on Numerical Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops algorithms for high-dimensional stochastic control\nproblems based on deep learning and dynamic programming. Unlike classical\napproximate dynamic programming approaches, we first approximate the optimal\npolicy by means of neural networks in the spirit of deep reinforcement\nlearning, and then the value function by Monte Carlo regression. This is\nachieved in the dynamic programming recursion by performance or hybrid\niteration, and regress now methods from numerical probabilities. We provide a\ntheoretical justification of these algorithms. Consistency and rate of\nconvergence for the control and value function estimates are analyzed and\nexpressed in terms of the universal approximation error of the neural networks,\nand of the statistical error when estimating network function, leaving aside\nthe optimization error. Numerical results on various applications are presented\nin a companion paper (arxiv.org/abs/1812.05916) and illustrate the performance\nof the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 09:41:26 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 14:59:10 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 06:47:11 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Hur\u00e9", "C\u00f4me", "", "LPSM UMR 8001, UPD7"], ["Pham", "Huy\u00ean", "", "LPSM"], ["Bachouch", "Achref", "", "UiO"], ["Langren\u00e9", "Nicolas", "", "CSIRO"]]}, {"id": "1812.04314", "submitter": "Daniele Grattarola", "authors": "Daniele Grattarola, Lorenzo Livi, Cesare Alippi", "title": "Adversarial Autoencoders with Constant-Curvature Latent Manifolds", "comments": "Submitted to Applied Soft Computing", "journal-ref": null, "doi": "10.1016/j.asoc.2019.105511", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constant-curvature Riemannian manifolds (CCMs) have been shown to be ideal\nembedding spaces in many application domains, as their non-Euclidean geometry\ncan naturally account for some relevant properties of data, like hierarchy and\ncircularity. In this work, we introduce the CCM adversarial autoencoder\n(CCM-AAE), a probabilistic generative model trained to represent a data\ndistribution on a CCM. Our method works by matching the aggregated posterior of\nthe CCM-AAE with a probability distribution defined on a CCM, so that the\nencoder implicitly learns to represent data on the CCM to fool the\ndiscriminator network. The geometric constraint is also explicitly imposed by\njointly training the CCM-AAE to maximise the membership degree of the\nembeddings to the CCM. While a few works in recent literature make use of\neither hyperspherical or hyperbolic manifolds for different learning tasks,\nours is the first unified framework to seamlessly deal with CCMs of different\ncurvatures. We show the effectiveness of our model on three different datasets\ncharacterised by non-trivial geometry: semi-supervised classification on MNIST,\nlink prediction on two popular citation datasets, and graph-based molecule\ngeneration using the QM9 chemical database. Results show that our method\nimproves upon other autoencoders based on Euclidean and non-Euclidean\ngeometries on all tasks taken into account.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 10:12:24 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 17:22:27 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Grattarola", "Daniele", ""], ["Livi", "Lorenzo", ""], ["Alippi", "Cesare", ""]]}, {"id": "1812.04345", "submitter": "Philipp Bach", "authors": "Philipp Bach, Victor Chernozhukov, Martin Spindler", "title": "Closing the U.S. gender wage gap requires understanding its\n  heterogeneity", "comments": "Main text: 8 pages, 3 figures; Supplementary Material available\n  online", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2016, the majority of full-time employed women in the U.S. earned\nsignificantly less than comparable men. The extent to which women were affected\nby gender inequality in earnings, however, depended greatly on socio-economic\ncharacteristics, such as marital status or educational attainment. In this\npaper, we analyzed data from the 2016 American Community Survey using a\nhigh-dimensional wage regression and applying double lasso to quantify\nheterogeneity in the gender wage gap. We found that the gap varied\nsubstantially across women and was driven primarily by marital status, having\nchildren at home, race, occupation, industry, and educational attainment. We\nrecommend that policy makers use these insights to design policies that will\nreduce discrimination and unequal pay more effectively.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 12:05:26 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:18:17 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bach", "Philipp", ""], ["Chernozhukov", "Victor", ""], ["Spindler", "Martin", ""]]}, {"id": "1812.04346", "submitter": "Raad Bin Tareaf", "authors": "Raad Bin Tareaf, Philipp Berger, Patrick Hennig and Christoph Meinel", "title": "Towards Automatic Personality Prediction Using Facebook Like Categories", "comments": "14 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that effortlessly accessible digital records of behavior such\nas Facebook Likes can be obtained and utilized to automatically distinguish a\nwide range of highly delicate personal traits including: life satisfaction,\ncultural ethnicity, political views, age, gender and personality traits. The\nanalysis presented based on a dataset of over 738,000 users who conferred their\nFacebook Likes, social network activities, egocentric network, demographic\ncharacteristics, and the results of various psychometric tests for our extended\npersonality analysis. The proposed model uses unique mapping technique between\neach Facebook Like object to the corresponding Facebook page\ncategory/sub-category object, which is then evaluated as features for a set of\nmachine learning algorithms to predict individual psycho-demographic profiles\nfrom Likes. The model , distinguishes between a religious and non-religious\nindividual in 83% of circumstances, Asian and European in 87% of situations,\nand between emotional stable and emotion unstable in 81% of situations. We\nprovide exemplars of correlations between attributes and Likes and present\nsuggestions for future directions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 12:10:58 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Tareaf", "Raad Bin", ""], ["Berger", "Philipp", ""], ["Hennig", "Patrick", ""], ["Meinel", "Christoph", ""]]}, {"id": "1812.04356", "submitter": "Clement Levrard", "authors": "Aur\\'elie Fischer (LPSM (UMR\\_8001)), Cl\\'ement Levrard (DATASHAPE,\n  LPSM (UMR\\_8001)), Claire Br\\'echeteau (ECN, LMJL, DATASHAPE)", "title": "Robust Bregman Clustering", "comments": "Annals of Statistics, Institute of Mathematical Statistics, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a trimming approach, we investigate a k-means type method based on\nBregman divergences for clustering data possibly corrupted with clutter noise.\nThe main interest of Bregman divergences is that the standard Lloyd algorithm\nadapts to these distortion measures, and they are well-suited for clustering\ndata sampled according to mixture models from exponential families. We prove\nthat there exists an optimal codebook, and that an empirically optimal codebook\nconverges a.s. to an optimal codebook in the distortion sense. Moreover, we\nobtain the sub-Gaussian rate of convergence for k-means 1 $\\sqrt$ n under mild\ntail assumptions. Also, we derive a Lloyd-type algorithm with a trimming\nparameter that can be selected from data according to some heuristic, and\npresent some experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 12:35:36 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 15:15:17 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 14:11:38 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Fischer", "Aur\u00e9lie", "", "LPSM"], ["Levrard", "Cl\u00e9ment", "", "DATASHAPE,\n  LPSM"], ["Br\u00e9cheteau", "Claire", "", "ECN, LMJL, DATASHAPE"]]}, {"id": "1812.04359", "submitter": "Ying Fan", "authors": "Ying Fan, Letian Chen, Yizhou Wang", "title": "Efficient Model-Free Reinforcement Learning Using Gaussian Process", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Reinforcement Learning usually takes advantage of demonstration or\ngood exploration strategy. By applying posterior sampling in model-free RL\nunder the hypothesis of GP, we propose Gaussian Process Posterior Sampling\nReinforcement Learning(GPPSTD) algorithm in continuous state space, giving\ntheoretical justifications and empirical results. We also provide theoretical\nand empirical results that various demonstration could lower expected\nuncertainty and benefit posterior sampling exploration. In this way, we\ncombined the demonstration and exploration process together to achieve a more\nefficient reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 12:37:24 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Fan", "Ying", ""], ["Chen", "Letian", ""], ["Wang", "Yizhou", ""]]}, {"id": "1812.04363", "submitter": "Ronan Fruit", "authors": "Jian Qian, Ronan Fruit, Matteo Pirotta, Alessandro Lazaric", "title": "Exploration Bonus for Regret Minimization in Undiscounted Discrete and\n  Continuous Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyse two algorithms for exploration-exploitation in\ndiscrete and continuous Markov Decision Processes (MDPs) based on exploration\nbonuses. SCAL$^+$ is a variant of SCAL (Fruit et al., 2018) that performs\nefficient exploration-exploitation in any unknown weakly-communicating MDP for\nwhich an upper bound C on the span of the optimal bias function is known. For\nan MDP with $S$ states, $A$ actions and $\\Gamma \\leq S$ possible next states,\nwe prove that SCAL$^+$ achieves the same theoretical guarantees as SCAL (i.e.,\na high probability regret bound of $\\widetilde{O}(C\\sqrt{\\Gamma SAT})$), with a\nmuch smaller computational complexity. Similarly, C-SCAL$^+$ exploits an\nexploration bonus to achieve sublinear regret in any undiscounted MDP with\ncontinuous state space. We show that C-SCAL$^+$ achieves the same regret bound\nas UCCRL (Ortner and Ryabko, 2012) while being the first implementable\nalgorithm with regret guarantees in this setting. While optimistic algorithms\nsuch as UCRL, SCAL or UCCRL maintain a high-confidence set of plausible MDPs\naround the true unknown MDP, SCAL$^+$ and C-SCAL$^+$ leverage on an exploration\nbonus to directly plan on the empirically estimated MDP, thus being more\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 12:44:52 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Qian", "Jian", ""], ["Fruit", "Ronan", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1812.04369", "submitter": "Shuang Xu", "authors": "Shuang Xu and Chun-Xia Zhang and Pei Wang and Jiangshe Zhang", "title": "Variational Bayesian Weighted Complex Network Reconstruction", "comments": null, "journal-ref": "Information Sciences, vol. 521, pp. 291-306, 2020", "doi": "10.1016/j.ins.2020.02.050", "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex network reconstruction is a hot topic in many fields. Currently, the\nmost popular data-driven reconstruction framework is based on lasso. However,\nit is found that, in the presence of noise, lasso loses efficiency for weighted\nnetworks. This paper builds a new framework to cope with this problem. The key\nidea is to employ a series of linear regression problems to model the\nrelationship between network nodes, and then to use an efficient variational\nBayesian algorithm to infer the unknown coefficients. The numerical experiments\nconducted on both synthetic and real data demonstrate that the new method\noutperforms lasso with regard to both reconstruction accuracy and running\nspeed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 12:53:31 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 08:20:33 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 03:08:37 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Shuang", ""], ["Zhang", "Chun-Xia", ""], ["Wang", "Pei", ""], ["Zhang", "Jiangshe", ""]]}, {"id": "1812.04370", "submitter": "Jerome Bobin", "authors": "I. El Hamzaoui, J.Bobin", "title": "Sparse component separation from Poisson measurements", "comments": "in Proceedings of iTWIST'18, Paper-ID: 4, Marseille, France,\n  November, 21-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind source separation (BSS) aims at recovering signals from mixtures. This\nproblem has been extensively studied in cases where the mixtures are\ncontaminated with additive Gaussian noise. However, it is not well suited to\ndescribe data that are corrupted with Poisson measurements such as in low\nphoton count optics or in high-energy astronomical imaging (e.g. observations\nfrom the Chandra or Fermi telescopes). To that purpose, we propose a novel BSS\nalgorithm coined pGMCA that specifically tackles the blind separation of sparse\nsources from Poisson measurements.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 12:58:18 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Hamzaoui", "I. El", ""], ["Bobin", "J.", ""]]}, {"id": "1812.04397", "submitter": "Colas Schretter", "authors": "Colas Schretter, Jianyong Sun and Peter Schelkens", "title": "From Adaptive Kernel Density Estimation to Sparse Mixture Models", "comments": "in Proceedings of iTWIST'18, Paper-ID: 20, Marseille, France,\n  November, 21-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a balloon estimator in a generalized expectation-maximization\nmethod for estimating all parameters of a Gaussian mixture model given one data\nsample per mixture component. Instead of limiting explicitly the model size,\nthis regularization strategy yields low-complexity sparse models where the\nnumber of effective mixture components reduces with an increase of a smoothing\nprobability parameter $\\mathbf{P>0}$. This semi-parametric method bridges from\nnon-parametric adaptive kernel density estimation (KDE) to parametric ordinary\nleast-squares when $\\mathbf{P=1}$. Experiments show that simpler sparse mixture\nmodels retain the level of details present in the adaptive KDE solution.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 13:54:37 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Schretter", "Colas", ""], ["Sun", "Jianyong", ""], ["Schelkens", "Peter", ""]]}, {"id": "1812.04403", "submitter": "Jakob Knollm\\\"uller", "authors": "Jakob Knollm\\\"uller and Torsten A. En{\\ss}lin", "title": "Encoding prior knowledge in the structure of the likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inference of deep hierarchical models is problematic due to strong\ndependencies between the hierarchies. We investigate a specific transformation\nof the model parameters based on the multivariate distributional transform.\nThis transformation is a special form of the reparametrization trick, flattens\nthe hierarchy and leads to a standard Gaussian prior on all resulting\nparameters. The transformation also transfers all the prior information into\nthe structure of the likelihood, hereby decoupling the transformed parameters a\npriori from each other. A variational Gaussian approximation in this\nstandardized space will be excellent in situations of relatively uninformative\ndata. Additionally, the curvature of the log-posterior is well-conditioned in\ndirections that are weakly constrained by the data, allowing for fast inference\nin such a scenario. In an example we perform the transformation explicitly for\nGaussian process regression with a priori unknown correlation structure. Deep\nmodels are inferred rapidly in highly and slowly in poorly informed situations.\nThe flat model show exactly the opposite performance pattern. A synthesis of\nboth, the deep and the flat perspective, provides their combined advantages and\novercomes the individual limitations, leading to a faster inference.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 14:03:55 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Knollm\u00fcller", "Jakob", ""], ["En\u00dflin", "Torsten A.", ""]]}, {"id": "1812.04407", "submitter": "Xiaoting Zhao", "authors": "Xiaoting Zhao, Raphael Louca, Diane Hu, Liangjie Hong", "title": "Learning Item-Interaction Embeddings for User Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry-scale recommendation systems have become a cornerstone of the\ne-commerce shopping experience. For Etsy, an online marketplace with over 50\nmillion handmade and vintage items, users come to rely on personalized\nrecommendations to surface relevant items from its massive inventory. One\nhallmark of Etsy's shopping experience is the multitude of ways in which a user\ncan interact with an item they are interested in: they can view it, favorite\nit, add it to a collection, add it to cart, purchase it, etc. We hypothesize\nthat the different ways in which a user interacts with an item indicates\ndifferent kinds of intent. Consequently, a user's recommendations should be\nbased not only on the item from their past activity, but also the way in which\nthey interacted with that item. In this paper, we propose a novel method for\nlearning interaction-based item embeddings that encode the co-occurrence\npatterns of not only the item itself, but also the interaction type. The\nlearned embeddings give us a convenient way of approximating the likelihood\nthat one item-interaction pair would co-occur with another by way of a simple\ninner product. Because of its computational efficiency, our model lends itself\nnaturally as a candidate set selection method, and we evaluate it as such in an\nindustry-scale recommendation system that serves live traffic on Etsy.com. Our\nexperiments reveal that taking interaction type into account shows promising\nresults in improving the accuracy of modeling user shopping behavior.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 14:06:13 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Zhao", "Xiaoting", ""], ["Louca", "Raphael", ""], ["Hu", "Diane", ""], ["Hong", "Liangjie", ""]]}, {"id": "1812.04419", "submitter": "Daewon Seo", "authors": "Daewon Seo, Ravi Kiran Raman, Joong Bum Rhim, Vivek K Goyal, Lav R\n  Varshney", "title": "Beliefs in Decision-Making Cascades", "comments": "final version, to appear in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2019.2935865", "report-no": null, "categories": "cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores a social learning problem with agents having nonidentical\nnoise variances and mismatched beliefs. We consider an $N$-agent binary\nhypothesis test in which each agent sequentially makes a decision based not\nonly on a private observation, but also on preceding agents' decisions. In\naddition, the agents have their own beliefs instead of the true prior, and have\nnonidentical noise variances in the private signal. We focus on the Bayes risk\nof the last agent, where preceding agents are selfish.\n  We first derive the optimal decision rule by recursive belief update and\nconclude, counterintuitively, that beliefs deviating from the true prior could\nbe optimal in this setting. The effect of nonidentical noise levels in the\ntwo-agent case is also considered and analytical properties of the optimal\nbelief curves are given. Next, we consider a predecessor selection problem\nwherein the subsequent agent of a certain belief chooses a predecessor from a\nset of candidates with varying beliefs. We characterize the decision region for\nchoosing such a predecessor and argue that a subsequent agent with beliefs\nvarying from the true prior often ends up selecting a suboptimal predecessor,\nindicating the need for a social planner. Lastly, we discuss an augmented\nintelligence design problem that uses a model of human behavior from cumulative\nprospect theory and investigate its near-optimality and suboptimality.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 19:02:57 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 19:32:21 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Seo", "Daewon", ""], ["Raman", "Ravi Kiran", ""], ["Rhim", "Joong Bum", ""], ["Goyal", "Vivek K", ""], ["Varshney", "Lav R", ""]]}, {"id": "1812.04426", "submitter": "Zichao Long", "authors": "Zichao Long, Yiping Lu, Bin Dong", "title": "PDE-Net 2.0: Learning PDEs from Data with A Numeric-Symbolic Hybrid Deep\n  Network", "comments": "16 pages, 15 figures. arXiv admin note: substantial text overlap with\n  arXiv:1710.09668", "journal-ref": null, "doi": "10.1016/j.jcp.2019.108925", "report-no": null, "categories": "cs.LG cs.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations (PDEs) are commonly derived based on empirical\nobservations. However, recent advances of technology enable us to collect and\nstore massive amount of data, which offers new opportunities for data-driven\ndiscovery of PDEs. In this paper, we propose a new deep neural network, called\nPDE-Net 2.0, to discover (time-dependent) PDEs from observed dynamic data with\nminor prior knowledge on the underlying mechanism that drives the dynamics. The\ndesign of PDE-Net 2.0 is based on our earlier work \\cite{Long2018PDE} where the\noriginal version of PDE-Net was proposed. PDE-Net 2.0 is a combination of\nnumerical approximation of differential operators by convolutions and a\nsymbolic multi-layer neural network for model recovery. Comparing with existing\napproaches, PDE-Net 2.0 has the most flexibility and expressive power by\nlearning both differential operators and the nonlinear response function of the\nunderlying PDE model. Numerical experiments show that the PDE-Net 2.0 has the\npotential to uncover the hidden PDE of the observed dynamics, and predict the\ndynamical behavior for a relatively long time, even in a noisy environment.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 13:15:49 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 04:47:53 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Long", "Zichao", ""], ["Lu", "Yiping", ""], ["Dong", "Bin", ""]]}, {"id": "1812.04428", "submitter": "Paul Rolland", "authors": "Paul Rolland, Ali Kavis, Alex Immer, Adish Singla, Volkan Cevher", "title": "Efficient learning of smooth probability functions from Bernoulli tests\n  with guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of learning an unknown, smooth probability\nfunction via pointwise Bernoulli tests. We provide a scalable algorithm for\nefficiently solving this problem with rigorous guarantees. In particular, we\nprove the convergence rate of our posterior update rule to the true probability\nfunction in L2-norm. Moreover, we allow the Bernoulli tests to depend on\ncontextual features and provide a modified inference engine with provable\nguarantees for this novel setting. Numerical results show that the empirical\nconvergence rates match the theory, and illustrate the superiority of our\napproach in handling contextual features over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 14:29:13 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 08:59:37 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 13:15:29 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Rolland", "Paul", ""], ["Kavis", "Ali", ""], ["Immer", "Alex", ""], ["Singla", "Adish", ""], ["Cevher", "Volkan", ""]]}, {"id": "1812.04439", "submitter": "Talia Beatrice Kimber", "authors": "Talia B. Kimber, Sebastian Engelke, Igor V. Tetko, Eric Bruno,\n  Guillaume Godin", "title": "Synergy Effect between Convolutional Neural Networks and the\n  Multiplicity of SMILES for Improvement of Molecular Prediction", "comments": "18 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our study, we demonstrate the synergy effect between convolutional neural\nnetworks and the multiplicity of SMILES. The model we propose, the so-called\nConvolutional Neural Fingerprint (CNF) model, reaches the accuracy of\ntraditional descriptors such as Dragon (Mauri et al. [22]), RDKit (Landrum\n[18]), CDK2 (Willighagen et al. [43]) and PyDescriptor (Masand and Rastija\n[20]). Moreover the CNF model generally performs better than highly fine-tuned\ntraditional descriptors, especially on small data sets, which is of great\ninterest for the chemical field where data sets are generally small due to\nexperimental costs, the availability of molecules or accessibility to private\ndatabases. We evaluate the CNF model along with SMILES augmentation during both\ntraining and testing. To the best of our knowledge, this is the first time that\nsuch a methodology is presented. We show that using the multiplicity of SMILES\nduring training acts as a regulariser and therefore avoids overfitting and can\nbe seen as ensemble learning when considered for testing.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 14:46:58 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Kimber", "Talia B.", ""], ["Engelke", "Sebastian", ""], ["Tetko", "Igor V.", ""], ["Bruno", "Eric", ""], ["Godin", "Guillaume", ""]]}, {"id": "1812.04446", "submitter": "David Noever", "authors": "David Noever", "title": "Data Strategies for Fleetwide Predictive Maintenance", "comments": "3 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For predictive maintenance, we examine one of the largest public datasets for\nmachine failures derived along with their corresponding precursors as error\nrates, historical part replacements, and sensor inputs. To simplify the time\nand accuracy comparison between 27 different algorithms, we treat the imbalance\nbetween normal and failing states with nominal under-sampling. We identify 3\npromising regression and discriminant algorithms with both higher accuracy\n(96%) and twenty-fold faster execution times than previous work. Because\npredictive maintenance success hinges on input features prior to prediction, we\nprovide a methodology to rank-order feature importance and show that for this\ndataset, error counts prove more predictive than scheduled maintenance might\nimply solely based on more traditional factors such as machine age or last\nreplacement times.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 14:57:57 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Noever", "David", ""]]}, {"id": "1812.04448", "submitter": "Xuan-Hong Dang", "authors": "Xuan-Hong Dang, Syed Yousaf Shah and Petros Zerfos", "title": "seq2graph: Discovering Dynamic Dependencies from Multivariate Time\n  Series with Multi-level Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering temporal lagged and inter-dependencies in multivariate time\nseries data is an important task. However, in many real-world applications,\nsuch as commercial cloud management, manufacturing predictive maintenance, and\nportfolios performance analysis, such dependencies can be non-linear and\ntime-variant, which makes it more challenging to extract such dependencies\nthrough traditional methods such as Granger causality or clustering. In this\nwork, we present a novel deep learning model that uses multiple layers of\ncustomized gated recurrent units (GRUs) for discovering both time lagged\nbehaviors as well as inter-timeseries dependencies in the form of directed\nweighted graphs. We introduce a key component of Dual-purpose recurrent neural\nnetwork that decodes information in the temporal domain to discover lagged\ndependencies within each time series, and encodes them into a set of vectors\nwhich, collected from all component time series, form the informative inputs to\ndiscover inter-dependencies. Though the discovery of two types of dependencies\nare separated at different hierarchical levels, they are tightly connected and\njointly trained in an end-to-end manner. With this joint training, learning of\none type of dependency immediately impacts the learning of the other one,\nleading to overall accurate dependencies discovery. We empirically test our\nmodel on synthetic time series data in which the exact form of (non-linear)\ndependencies is known. We also evaluate its performance on two real-world\napplications, (i) performance monitoring data from a commercial cloud provider,\nwhich exhibit highly dynamic, non-linear, and volatile behavior and, (ii)\nsensor data from a manufacturing plant. We further show how our approach is\nable to capture these dependency behaviors via intuitive and interpretable\ndependency graphs and use them to generate highly accurate forecasts.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 21:20:42 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Dang", "Xuan-Hong", ""], ["Shah", "Syed Yousaf", ""], ["Zerfos", "Petros", ""]]}, {"id": "1812.04456", "submitter": "Khanh-Hung Tran", "authors": "Khanh-Hung Tran, Fred-Maurice Ngole-Mboula and Jean-Luc Starck", "title": "Semi-supervised dual graph regularized dictionary learning", "comments": "in Proceedings of iTWIST'18, Paper-ID: 33, Marseille, France,\n  November, 21-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a semi-supervised dictionary learning method that\nuses both the information in labelled and unlabelled data and jointly trains a\nlinear classifier embedded on the sparse codes. The manifold structure of the\ndata in the sparse code space is preserved using the same approach as the\nLocally Linear Embedding method (LLE). This enables one to enforce the\npredictive power of the unlabelled data sparse codes. We show that our approach\nprovides significant improvements over other methods. The results can be\nfurther improved by training a simple nonlinear classifier as SVM on the sparse\ncodes.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 15:16:33 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Tran", "Khanh-Hung", ""], ["Ngole-Mboula", "Fred-Maurice", ""], ["Starck", "Jean-Luc", ""]]}, {"id": "1812.04480", "submitter": "Ming Dong", "authors": "Ming Dong, L.S.Grumbach", "title": "A Hybrid Distribution Feeder Long-Term Load Forecasting Method Based on\n  Sequence Prediction", "comments": "12 pages,8 figures", "journal-ref": "IEEE Transactions on Smart Grid, 2019", "doi": "10.1109/TSG.2019.2924183", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution feeder long-term load forecast (LTLF) is a critical task many\nelectric utility companies perform on an annual basis. The goal of this task is\nto forecast the annual load of distribution feeders. The previous top-down and\nbottom-up LTLF methods are unable to incorporate different levels of\ninformation. This paper proposes a hybrid modeling method using sequence\nprediction for this classic and important task. The proposed method can\nseamlessly integrate top-down, bottom-up and sequential information hidden in\nmulti-year data. Two advanced sequence prediction models Long Short-Term Memory\n(LSTM) and Gated Recurrent Unit (GRU) networks are investigated in this paper.\nThey successfully solve the vanishing and exploding gradient problems a\nstandard recurrent neural network has. This paper firstly explains the theories\nof LSTM and GRU networks and then discusses the steps of feature selection,\nfeature engineering and model implementation in detail. In the end, a\nreal-world application example for a large urban grid in West Canada is\nprovided. LSTM and GRU networks under different sequential configurations and\ntraditional models including bottom-up, ARIMA and feed-forward neural network\nare all implemented and compared in detail. The proposed method demonstrates\nsuperior performance and great practicality.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 06:38:00 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 05:47:06 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 04:28:23 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Dong", "Ming", ""], ["Grumbach", "L. S.", ""]]}, {"id": "1812.04486", "submitter": "Eric Benhamou", "authors": "David Saltiel and Eric Benhamou", "title": "Trade Selection with Supervised Learning and OCA", "comments": "7 pages, 9 figures. arXiv admin note: substantial text overlap with\n  arXiv:1811.12064", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, state-of-the-art methods for supervised learning have\nexploited increasingly gradient boosting techniques, with mainstream efficient\nimplementations such as xgboost or lightgbm. One of the key points in\ngenerating proficient methods is Feature Selection (FS). It consists in\nselecting the right valuable effective features. When facing hundreds of these\nfeatures, it becomes critical to select best features. While filter and\nwrappers methods have come to some maturity, embedded methods are truly\nnecessary to find the best features set as they are hybrid methods combining\nfeatures filtering and wrapping. In this work, we tackle the problem of finding\nthrough machine learning best a priori trades from an algorithmic strategy. We\nderive this new method using coordinate ascent optimization and using block\nvariables. We compare our method to Recursive Feature Elimination (RFE) and\nBinary Coordinate Ascent (BCA). We show on a real life example the capacity of\nthis method to select good trades a priori. Not only this method outperforms\nthe initial trading strategy as it avoids taking loosing trades, it also\nsurpasses other method, having the smallest feature set and the highest score\nat the same time. The interest of this method goes beyond this simple trade\nclassification problem as it is a very general method to determine the optimal\nfeature set using some information about features relationship as well as using\ncoordinate ascent optimization.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 21:07:06 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Saltiel", "David", ""], ["Benhamou", "Eric", ""]]}, {"id": "1812.04513", "submitter": "Yiru Shen", "authors": "Yiru Shen, Eric Muth, Adam Hoover", "title": "The Impact of Quantity of Training Data on Recognition of Eating\n  Gestures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of recognizing eating gestures by tracking\nwrist motion. Eating gestures can have large variability in motion depending on\nthe subject, utensil, and type of food or beverage being consumed. Previous\nworks have shown viable proofs-of-concept of recognizing eating gestures in\nlaboratory settings with small numbers of subjects and food types, but it is\nunclear how well these methods would work if tested on a larger population in\nnatural settings. As more subjects, locations and foods are tested, a larger\namount of motion variability could cause a decrease in recognition accuracy. To\nexplore this issue, this paper describes the collection and annotation of\n51,614 eating gestures taken by 269 subjects eating a meal in a cafeteria.\nExperiments are described that explore the complexity of hidden Markov models\n(HMMs) and the amount of training data needed to adequately capture the motion\nvariability across this large data set. Results found that HMMs needed a\ncomplexity of 13 states and 5 Gaussians to reach a plateau in accuracy,\nsignifying that a minimum of 65 samples per gesture type are needed. Results\nalso found that 500 training samples per gesture type were needed to identify\nthe point of diminishing returns in recognition accuracy. Overall, the findings\nprovide evidence that the size a data set typically used to demonstrate a\nlaboratory proofs-of-concept may not be sufficiently large enough to capture\nall the motion variability that could be expected in transitioning to\ndeployment with a larger population. Our data set, which is 1-2 orders of\nmagnitude larger than all data sets tested in previous works, is being made\npublicly available.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 16:09:07 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Shen", "Yiru", ""], ["Muth", "Eric", ""], ["Hoover", "Adam", ""]]}, {"id": "1812.04529", "submitter": "Aaron Defazio Dr", "authors": "Aaron Defazio, L\\'eon Bottou", "title": "On the Ineffectiveness of Variance Reduced Optimization for Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The application of stochastic variance reduction to optimization has shown\nremarkable recent theoretical and practical success. The applicability of these\ntechniques to the hard non-convex optimization problems encountered during\ntraining of modern deep neural networks is an open problem. We show that naive\napplication of the SVRG technique and related approaches fail, and explore why.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 16:40:59 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 16:13:56 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Defazio", "Aaron", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1812.04549", "submitter": "Aaron Defazio Dr", "authors": "Aaron Defazio, L\\'eon Bottou", "title": "Controlling Covariate Shift using Balanced Normalization of Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new normalization technique that exhibits the fast convergence\nproperties of batch normalization using a transformation of layer weights\ninstead of layer outputs. The proposed technique keeps the contribution of\npositive and negative weights to the layer output balanced. We validate our\nmethod on a set of standard benchmarks including CIFAR-10/100, SVHN and ILSVRC\n2012 ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 17:12:50 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 14:19:14 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Defazio", "Aaron", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1812.04571", "submitter": "Pawel Mlynarski", "authors": "Pawel Mlynarski, Herv\\'e Delingette, Antonio Criminisi, Nicholas\n  Ayache", "title": "Deep Learning with Mixed Supervision for Brain Tumor Segmentation", "comments": "Submitted to SPIE Journal of Medical Imaging", "journal-ref": null, "doi": "10.1117/1.JMI.6.3.034002", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the current state-of-the-art methods for tumor segmentation are based\non machine learning models trained on manually segmented images. This type of\ntraining data is particularly costly, as manual delineation of tumors is not\nonly time-consuming but also requires medical expertise. On the other hand,\nimages with a provided global label (indicating presence or absence of a tumor)\nare less informative but can be obtained at a substantially lower cost. In this\npaper, we propose to use both types of training data (fully-annotated and\nweakly-annotated) to train a deep learning model for segmentation. The idea of\nour approach is to extend segmentation networks with an additional branch\nperforming image-level classification. The model is jointly trained for\nsegmentation and classification tasks in order to exploit information contained\nin weakly-annotated images while preventing the network to learn features which\nare irrelevant for the segmentation task. We evaluate our method on the\nchallenging task of brain tumor segmentation in Magnetic Resonance images from\nBRATS 2018 challenge. We show that the proposed approach provides a significant\nimprovement of segmentation performance compared to the standard supervised\nlearning. The observed improvement is proportional to the ratio between\nweakly-annotated and fully-annotated images available for training.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 16:03:27 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Mlynarski", "Pawel", ""], ["Delingette", "Herv\u00e9", ""], ["Criminisi", "Antonio", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1812.04594", "submitter": "Alexander Cloninger", "authors": "Alexander Cloninger", "title": "Bounding the Error From Reference Set Kernel Maximum Mean Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we bound the error induced by using a weighted skeletonization\nof two data sets for computing a two sample test with kernel maximum mean\ndiscrepancy. The error is quantified in terms of the speed in which heat\ndiffuses from those points to the rest of the data, as well as how at the\nweights on the reference points are, and gives a non-asymptotic,\nnon-probabilistic bound. The result ties into the problem of the eigenvector\ntriple product, which appears in a number of important problems. The error\nbound also suggests an optimization scheme for choosing the best set of\nreference points and weights. The method is tested on a several two sample test\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:28:17 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Cloninger", "Alexander", ""]]}, {"id": "1812.04597", "submitter": "Adarsh Subbaswamy", "authors": "Adarsh Subbaswamy, Peter Schulam, Suchi Saria", "title": "Preventing Failures Due to Dataset Shift: Learning Predictive Models\n  That Transport", "comments": "In Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS), 2019. Previously presented at the\n  NeurIPS 2018 Causal Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical supervised learning produces unreliable models when training and\ntarget distributions differ, with most existing solutions requiring samples\nfrom the target domain. We propose a proactive approach which learns a\nrelationship in the training domain that will generalize to the target domain\nby incorporating prior knowledge of aspects of the data generating process that\nare expected to differ as expressed in a causal selection diagram.\nSpecifically, we remove variables generated by unstable mechanisms from the\njoint factorization to yield the Surgery Estimator---an interventional\ndistribution that is invariant to the differences across environments. We prove\nthat the surgery estimator finds stable relationships in strictly more\nscenarios than previous approaches which only consider conditional\nrelationships, and demonstrate this in simulated experiments. We also evaluate\non real world data for which the true causal diagram is unknown, performing\ncompetitively against entirely data-driven approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:32:52 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 18:11:05 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Subbaswamy", "Adarsh", ""], ["Schulam", "Peter", ""], ["Saria", "Suchi", ""]]}, {"id": "1812.04599", "submitter": "Konrad Zolna", "authors": "Konrad Zolna and Michal Zajac and Negar Rostamzadeh and Pedro O.\n  Pinheiro", "title": "Adversarial Framing for Image and Video Classification", "comments": "This is an extended version of the paper published at 33rd AAAI\n  Conference on Artificial Intelligence (see\n  https://doi.org/10.1609/aaai.v33i01.330110077 )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are prone to adversarial attacks. In general, such attacks\ndeteriorate the quality of the input by either slightly modifying most of its\npixels, or by occluding it with a patch. In this paper, we propose a method\nthat keeps the image unchanged and only adds an adversarial framing on the\nborder of the image. We show empirically that our method is able to\nsuccessfully attack state-of-the-art methods on both image and video\nclassification problems. Notably, the proposed method results in a universal\nattack which is very fast at test time. Source code can be found at\nhttps://github.com/zajaczajac/adv_framing .\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:39:29 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 18:18:56 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 14:03:07 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zolna", "Konrad", ""], ["Zajac", "Michal", ""], ["Rostamzadeh", "Negar", ""], ["Pinheiro", "Pedro O.", ""]]}, {"id": "1812.04606", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Mantas Mazeika and Thomas Dietterich", "title": "Deep Anomaly Detection with Outlier Exposure", "comments": "ICLR 2019; PyTorch code available at\n  https://github.com/hendrycks/outlier-exposure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to detect anomalous inputs when deploying machine learning\nsystems. The use of larger and more complex inputs in deep learning magnifies\nthe difficulty of distinguishing between anomalous and in-distribution\nexamples. At the same time, diverse image and text data are available in\nenormous quantities. We propose leveraging these data to improve deep anomaly\ndetection by training anomaly detectors against an auxiliary dataset of\noutliers, an approach we call Outlier Exposure (OE). This enables anomaly\ndetectors to generalize and detect unseen anomalies. In extensive experiments\non natural language processing and small- and large-scale vision tasks, we find\nthat Outlier Exposure significantly improves detection performance. We also\nobserve that cutting-edge generative models trained on CIFAR-10 may assign\nhigher likelihoods to SVHN images than to CIFAR-10 images; we use OE to\nmitigate this issue. We also analyze the flexibility and robustness of Outlier\nExposure, and identify characteristics of the auxiliary dataset that improve\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:49:50 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 18:57:19 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 20:34:44 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Hendrycks", "Dan", ""], ["Mazeika", "Mantas", ""], ["Dietterich", "Thomas", ""]]}, {"id": "1812.04616", "submitter": "Sachin Kumar", "authors": "Sachin Kumar and Yulia Tsvetkov", "title": "Von Mises-Fisher Loss for Training Sequence to Sequence Models with\n  Continuous Outputs", "comments": "Seventh International Conference on Learning Representations (ICLR\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Softmax function is used in the final layer of nearly all existing\nsequence-to-sequence models for language generation. However, it is usually the\nslowest layer to compute which limits the vocabulary size to a subset of most\nfrequent types; and it has a large memory footprint. We propose a general\ntechnique for replacing the softmax layer with a continuous embedding layer.\nOur primary innovations are a novel probabilistic loss, and a training and\ninference procedure in which we generate a probability distribution over\npre-trained word embeddings, instead of a multinomial distribution over the\nvocabulary obtained via softmax. We evaluate this new class of\nsequence-to-sequence models with continuous outputs on the task of neural\nmachine translation. We show that our models obtain upto 2.5x speed-up in\ntraining time while performing on par with the state-of-the-art models in terms\nof translation quality. These models are capable of handling very large\nvocabularies without compromising on translation quality. They also produce\nmore meaningful errors than in the softmax-based models, as these errors\ntypically lie in a subspace of the vector space of the reference translations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 20:00:36 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 07:16:02 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 03:08:01 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Kumar", "Sachin", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "1812.04618", "submitter": "Lahiru Jayasinghe", "authors": "Jeremy Chew, Yingxiang Sun, Lahiru Jayasinghe, Chau Yuen", "title": "DCASE 2018 Challenge: Solution for Task 5", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address Task 5 in the Detection and Classification of Acoustic Scenes and\nEvents (DCASE) 2018 challenge, in this paper, we propose an ensemble learning\nsystem. The proposed system consists of three different models, based on\nconvolutional neural network and long short memory recurrent neural network.\nWith extracted features such as spectrogram and mel-frequency cepstrum\ncoefficients from different channels, the proposed system can classify\ndifferent domestic activities effectively. Experimental results obtained from\nthe provided development dataset show that good performance with F1-score of\n92.19% can be achieved. Compared with the baseline system, our proposed system\nsignificantly improves the performance of F1-score by 7.69%.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 07:35:42 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Chew", "Jeremy", ""], ["Sun", "Yingxiang", ""], ["Jayasinghe", "Lahiru", ""], ["Yuen", "Chau", ""]]}, {"id": "1812.04634", "submitter": "Aaron Defazio Dr", "authors": "Aaron Defazio", "title": "On the Curved Geometry of Accelerated Optimization", "comments": "NeurIPS 2019 Accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we propose a differential geometric motivation for Nesterov's\naccelerated gradient method (AGM) for strongly-convex problems. By considering\nthe optimization procedure as occurring on a Riemannian manifold with a natural\nstructure, The AGM method can be seen as the proximal point method applied in\nthis curved space. This viewpoint can also be extended to the continuous time\ncase, where the accelerated gradient method arises from the natural\nblock-implicit Euler discretization of an ODE on the manifold. We provide an\nanalysis of the convergence rate of this ODE for quadratic objectives.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 19:00:07 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 16:07:08 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Defazio", "Aaron", ""]]}, {"id": "1812.04650", "submitter": "Levan Shugliashvili", "authors": "Levan Shugliashvili, Davit Soselia, Shota Amashukeli, Irakli Koberidze", "title": "Reproduction Report on \"Learn to Pay Attention\"", "comments": "2 pages, 2 tables, originally made for the ICLR 2018 Reproducibility\n  Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have successfully implemented the \"Learn to Pay Attention\" model of\nattention mechanism in convolutional neural networks, and have replicated the\nresults of the original paper in the categories of image classification and\nfine-grained recognition.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 19:05:23 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Shugliashvili", "Levan", ""], ["Soselia", "Davit", ""], ["Amashukeli", "Shota", ""], ["Koberidze", "Irakli", ""]]}, {"id": "1812.04677", "submitter": "Shaobin Xu", "authors": "Shaobin Xu and David A. Smith", "title": "Contrastive Training for Models of Information Cascades", "comments": "Accepted in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a model of information cascades as directed spanning\ntrees (DSTs) over observed documents. In addition, we propose a contrastive\ntraining procedure that exploits partial temporal ordering of node infections\nin lieu of labeled training links. This combination of model and unsupervised\ntraining makes it possible to improve on models that use infection times alone\nand to exploit arbitrary features of the nodes and of the text content of\nmessages in information cascades. With only basic node and time lag features\nsimilar to previous models, the DST model achieves performance with\nunsupervised training comparable to strong baselines on a blog network\ninference task. Unsupervised training with additional content features achieves\nsignificantly better results, reaching half the accuracy of a fully supervised\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 20:23:46 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Xu", "Shaobin", ""], ["Smith", "David A.", ""]]}, {"id": "1812.04690", "submitter": "Kristof Sch\\\"utt", "authors": "Kristof T. Sch\\\"utt, Alexandre Tkatchenko, Klaus-Robert M\\\"uller", "title": "Learning representations of molecules and materials with atomistic\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has been shown to learn efficient representations for\nstructured data such as image, text or audio. In this chapter, we present\nneural network architectures that are able to learn efficient representations\nof molecules and materials. In particular, the continuous-filter convolutional\nnetwork SchNet accurately predicts chemical properties across compositional and\nconfigurational space on a variety of datasets. Beyond that, we analyze the\nobtained representations to find evidence that their spatial and chemical\nproperties agree with chemical intuition.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 21:02:28 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Sch\u00fctt", "Kristof T.", ""], ["Tkatchenko", "Alexandre", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1812.04693", "submitter": "Milad Salem", "authors": "Milad Salem, Shayan Taheri, Jiann Shiun-Yuan", "title": "ECG Arrhythmia Classification Using Transfer Learning from 2-Dimensional\n  Deep CNN Features", "comments": "Accepted and presented for IEEE Biomedical Circuits and Systems\n  (BioCAS) on 17th-19th October 2018 in Ohio, USA", "journal-ref": null, "doi": "10.1109/BIOCAS.2018.8584808", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the recent advances in the area of deep learning, it has been\ndemonstrated that a deep neural network, trained on a huge amount of data, can\nrecognize cardiac arrhythmias better than cardiologists. Moreover,\ntraditionally feature extraction was considered an integral part of ECG pattern\nrecognition; however, recent findings have shown that deep neural networks can\ncarry out the task of feature extraction directly from the data itself. In\norder to use deep neural networks for their accuracy and feature extraction,\nhigh volume of training data is required, which in the case of independent\nstudies is not pragmatic. To arise to this challenge, in this work, the\nidentification and classification of four ECG patterns are studied from a\ntransfer learning perspective, transferring knowledge learned from the image\nclassification domain to the ECG signal classification domain. It is\ndemonstrated that feature maps learned in a deep neural network trained on\ngreat amounts of generic input images can be used as general descriptors for\nthe ECG signal spectrograms and result in features that enable classification\nof arrhythmias. Overall, an accuracy of 97.23 percent is achieved in\nclassifying near 7000 instances by ten-fold cross validation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 21:11:30 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Salem", "Milad", ""], ["Taheri", "Shayan", ""], ["Shiun-Yuan", "Jiann", ""]]}, {"id": "1812.04697", "submitter": "Milad Salem", "authors": "Milad Salem, Shayan Taheri, Jiann Shiun Yuan", "title": "Anomaly Generation using Generative Adversarial Networks in Host Based\n  Intrusion Detection", "comments": "Accepted and presented at IEEE Annual Ubiquitous Computing,\n  Electronics, and Mobile Communications Conference (IEEE UEMCON) on 8th-10th\n  November 2018", "journal-ref": null, "doi": "10.1109/UEMCON.2018.8796769", "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks have been able to generate striking results\nin various domains. This generation capability can be general while the\nnetworks gain deep understanding regarding the data distribution. In many\ndomains, this data distribution consists of anomalies and normal data, with the\nanomalies commonly occurring relatively less, creating datasets that are\nimbalanced. The capabilities that generative adversarial networks offer can be\nleveraged to examine these anomalies and help alleviate the challenge that\nimbalanced datasets propose via creating synthetic anomalies. This anomaly\ngeneration can be specifically beneficial in domains that have costly data\ncreation processes as well as inherently imbalanced datasets. One of the\ndomains that fits this description is the host-based intrusion detection\ndomain. In this work, ADFA-LD dataset is chosen as the dataset of interest\ncontaining system calls of small foot-print next generation attacks. The data\nis first converted into images, and then a Cycle-GAN is used to create images\nof anomalous data from images of normal data. The generated data is combined\nwith the original dataset and is used to train a model to detect anomalies. By\ndoing so, it is shown that the classification results are improved, with the\nAUC rising from 0.55 to 0.71, and the anomaly detection rate rising from 17.07%\nto 80.49%. The results are also compared to SMOTE, showing the potential\npresented by generative adversarial networks in anomaly generation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 21:21:09 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Salem", "Milad", ""], ["Taheri", "Shayan", ""], ["Yuan", "Jiann Shiun", ""]]}, {"id": "1812.04700", "submitter": "Konstantinos Nikolakakis", "authors": "Konstantinos E. Nikolakakis, Dionysios S. Kalogerias and Anand D.\n  Sarwate", "title": "Predictive Learning on Hidden Tree-Structured Ising Models", "comments": "82 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide high-probability sample complexity guarantees for exact structure\nrecovery and accurate predictive learning using noise-corrupted samples from an\nacyclic (tree-shaped) graphical model. The hidden variables follow a\ntree-structured Ising model distribution, whereas the observable variables are\ngenerated by a binary symmetric channel taking the hidden variables as its\ninput (flipping each bit independently with some constant probability $q\\in\n[0,1/2)$). In the absence of noise, predictive learning on Ising models was\nrecently studied by Bresler and Karzand (2020); this paper quantifies how noise\nin the hidden model impacts the tasks of structure recovery and marginal\ndistribution estimation by proving upper and lower bounds on the sample\ncomplexity. Our results generalize state-of-the-art bounds reported in prior\nwork, and they exactly recover the noiseless case ($q=0$). In fact, for any\ntree with $p$ vertices and probability of incorrect recovery $\\delta>0$, the\nsufficient number of samples remains logarithmic as in the noiseless case,\ni.e., $\\mathcal{O}(\\log(p/\\delta))$, while the dependence on $q$ is\n$\\mathcal{O}\\big( 1/(1-2q)^{4} \\big)$, for both aforementioned tasks. We also\npresent a new equivalent of Isserlis' Theorem for sign-valued tree-structured\ndistributions, yielding a new low-complexity algorithm for higher-order moment\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 21:32:16 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 04:57:01 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 16:53:09 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2021 03:11:05 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Nikolakakis", "Konstantinos E.", ""], ["Kalogerias", "Dionysios S.", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "1812.04715", "submitter": "Vahid Pourahmadi Dr.", "authors": "Amirhossein Yazdani Abyaneh, Ali Hosein Gharari Foumani, Vahid\n  Pourahmadi", "title": "Deep Neural Networks Meet CSI-Based Authentication", "comments": "7 pages, 14 Figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first step of a secure communication is authenticating legible users and\ndetecting the malicious ones. In the last recent years, some promising schemes\nproposed using wireless medium network's features, in particular, channel state\ninformation (CSI) as a means for authentication. These schemes mainly compare\nuser's previous CSI with the new received CSI to determine if the user is in\nfact what it is claiming to be. Despite high accuracy, these approaches lack\nthe stability in authentication when the users rotate in their positions. This\nis due to a significant change in CSI when a user rotates which mislead the\nauthenticator when it compares the new CSI with the previous ones. Our approach\npresents a way of extracting features from raw CSI measurements which are\nstable towards rotation. We extract these features by the means of a deep\nneural network. We also present a scenario in which users can be {efficiently}\nauthenticated while they are at certain locations in an environment (even if\nthey rotate); and, they will be rejected if they change their location. Also,\nexperimental results are presented to show the performance of the proposed\nscheme.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 16:23:55 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Abyaneh", "Amirhossein Yazdani", ""], ["Foumani", "Ali Hosein Gharari", ""], ["Pourahmadi", "Vahid", ""]]}, {"id": "1812.04722", "submitter": "Shayne O'Brien", "authors": "David McClure, Shayne O'Brien, and Deb Roy", "title": "Context is Key: New Approaches to Neural Coherence Modeling", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We formulate coherence modeling as a regression task and propose two novel\nmethods to combine techniques from our setup with pairwise approaches. The\nfirst of our methods is a model that we call \"first-next,\" which operates\nsimilarly to selection sorting but conditions decision-making on information\nabout already-sorted sentences. The second consists of a technique for adding\ncontext to regression-based models by concatenating sentence-level\nrepresentations with an encoding of its corresponding out-of-order paragraph.\nThis latter model achieves Kendall-tau distance and positional accuracy scores\nthat match or exceed the current state-of-the-art on these metrics. Our results\nsuggest that many of the gains that come from more complex, machine-translation\ninspired approaches can be achieved with simpler, more efficient models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 03:16:06 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["McClure", "David", ""], ["O'Brien", "Shayne", ""], ["Roy", "Deb", ""]]}, {"id": "1812.04744", "submitter": "Dung Tran", "authors": "Dung N. Tran, Trac D. Tran, Lam Nguyen", "title": "Generative Adversarial Networks for Recovering Missing Spectral\n  Information", "comments": "arXiv admin note: text overlap with arXiv:1707.06873 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-wideband (UWB) radar systems nowadays typical operate in the low\nfrequency spectrum to achieve penetration capability. However, this spectrum is\nalso shared by many others communication systems, which causes missing\ninformation in the frequency bands. To recover this missing spectral\ninformation, we propose a generative adversarial network, called SARGAN, that\nlearns the relationship between original and missing band signals by observing\nthese training pairs in a clever way. Initial results shows that this approach\nis promising in tackling this challenging missing band problem.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 23:42:28 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 04:03:55 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Tran", "Dung N.", ""], ["Tran", "Trac D.", ""], ["Nguyen", "Lam", ""]]}, {"id": "1812.04754", "submitter": "Guy Gur-Ari", "authors": "Guy Gur-Ari, Daniel A. Roberts, Ethan Dyer", "title": "Gradient Descent Happens in a Tiny Subspace", "comments": "9 pages + appendices, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that in a variety of large-scale deep learning scenarios the gradient\ndynamically converges to a very small subspace after a short period of\ntraining. The subspace is spanned by a few top eigenvectors of the Hessian\n(equal to the number of classes in the dataset), and is mostly preserved over\nlong periods of training. A simple argument then suggests that gradient descent\nmay happen mostly in this subspace. We give an example of this effect in a\nsolvable model of classification, and we comment on possible implications for\noptimization and learning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 00:36:17 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Gur-Ari", "Guy", ""], ["Roberts", "Daniel A.", ""], ["Dyer", "Ethan", ""]]}, {"id": "1812.04778", "submitter": "Tzu-Yu Liu", "authors": "Tzu-Yu Liu, Ajay Kannan, Adam Drake, Marvin Bertin, Nathan Wan", "title": "Bridging the Generalization Gap: Training Robust Models on Confounded\n  Biological Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical learning on biological data can be challenging due to confounding\nvariables in sample collection and processing. Confounders can cause models to\ngeneralize poorly and result in inaccurate prediction performance metrics if\nmodels are not validated thoroughly. In this paper, we propose methods to\ncontrol for confounding factors and further improve prediction performance. We\nintroduce OrthoNormal basis construction In cOnfounding factor Normalization\n(ONION) to remove confounding covariates and use the Domain-Adversarial Neural\nNetwork (DANN) to penalize models for encoding confounder information. We apply\nthe proposed methods to simulated and empirical patient data and show\nsignificant improvements in generalization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 02:16:20 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Liu", "Tzu-Yu", ""], ["Kannan", "Ajay", ""], ["Drake", "Adam", ""], ["Bertin", "Marvin", ""], ["Wan", "Nathan", ""]]}, {"id": "1812.04783", "submitter": "Shengdong Du", "authors": "Shengdong Du, Tianrui Li, Yan Yang and Shi-Jinn Horng", "title": "Deep Air Quality Forecasting Using Hybrid Deep Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air quality forecasting has been regarded as the key problem of air pollution\nearly warning and control management. In this paper, we propose a novel deep\nlearning model for air quality (mainly PM2.5) forecasting, which learns the\nspatial-temporal correlation features and interdependence of multivariate air\nquality related time series data by hybrid deep learning architecture. Due to\nthe nonlinear and dynamic characteristics of multivariate air quality time\nseries data, the base modules of our model include one-dimensional\nConvolutional Neural Networks (1D-CNNs) and Bi-directional Long Short-term\nMemory networks (Bi-LSTM). The former is to extract the local trend features\nand spatial correlation features, and the latter is to learn spatial-temporal\ndependencies. Then we design a jointly hybrid deep learning framework based on\none-dimensional CNNs and Bi-LSTM for shared representation features learning of\nmultivariate air quality related time series data. We conduct extensive\nexperimental evaluations using two real-world datasets, and the results show\nthat our model is capable of dealing with PM2.5 air pollution forecasting with\nsatisfied accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 02:38:29 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 12:57:05 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 09:55:07 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Du", "Shengdong", ""], ["Li", "Tianrui", ""], ["Yang", "Yan", ""], ["Horng", "Shi-Jinn", ""]]}, {"id": "1812.04801", "submitter": "Michael Tsang", "authors": "Michael Tsang, Youbang Sun, Dongxu Ren, Yan Liu", "title": "Can I trust you more? Model-Agnostic Hierarchical Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactions such as double negation in sentences and scene interactions in\nimages are common forms of complex dependencies captured by state-of-the-art\nmachine learning models. We propose Mah\\'e, a novel approach to provide\nModel-agnostic hierarchical \\'explanations of how powerful machine learning\nmodels, such as deep neural networks, capture these interactions as either\ndependent on or free of the context of data instances. Specifically, Mah\\'e\nprovides context-dependent explanations by a novel local interpretation\nalgorithm that effectively captures any-order interactions, and obtains\ncontext-free explanations through generalizing context-dependent interactions\nto explain global behaviors. Experimental results show that Mah\\'e obtains\nimproved local interaction interpretations over state-of-the-art methods and\nsuccessfully explains interactions that are context-free.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 04:12:29 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Tsang", "Michael", ""], ["Sun", "Youbang", ""], ["Ren", "Dongxu", ""], ["Liu", "Yan", ""]]}, {"id": "1812.04808", "submitter": "Hedi Xia", "authors": "Hedi Xia, Hector D. Ceniceros", "title": "Kernel Treelets", "comments": null, "journal-ref": null, "doi": "10.1142/S2424922X19500062", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for hierarchical clustering is presented. It combines treelets,\na particular multiscale decomposition of data, with a projection on a\nreproducing kernel Hilbert space. The proposed approach, called kernel treelets\n(KT), effectively substitutes the correlation coefficient matrix used in\ntreelets with a symmetric, positive semi-definite matrix efficiently\nconstructed from a kernel function. Unlike most clustering methods, which\nrequire data sets to be numeric, KT can be applied to more general data and\nyield a multi-resolution sequence of basis on the data directly in feature\nspace. The effectiveness and potential of KT in clustering analysis is\nillustrated with some examples.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 04:55:24 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Xia", "Hedi", ""], ["Ceniceros", "Hector D.", ""]]}, {"id": "1812.04845", "submitter": "Prasad Cheema", "authors": "Prasad Cheema, Nguyen Lu Dang Khoa, Moray Kidd, Gareth A. Vio", "title": "A Tensor-based Structural Health Monitoring Approach for\n  Aeroservoelastic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural health monitoring is a condition-based field of study utilised to\nmonitor infrastructure, via sensing systems. It is therefore used in the field\nof aerospace engineering to assist in monitoring the health of aerospace\nstructures. A difficulty however is that in structural health monitoring the\ndata input is usually from sensor arrays, which results in data which are\nhighly redundant and correlated, an area in which traditional two-way matrix\napproaches have had difficulty in deconstructing and interpreting. Newer\nmethods involving tensor analysis allow us to analyse this multi-way structural\ndata in a coherent manner. In our approach, we demonstrate the usefulness of\ntensor-based learning coupled with for damage detection, on a novel $N$-DoF\nLagrangian aeroservoelastic model.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 04:15:44 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Cheema", "Prasad", ""], ["Khoa", "Nguyen Lu Dang", ""], ["Kidd", "Moray", ""], ["Vio", "Gareth A.", ""]]}, {"id": "1812.04912", "submitter": "Nana Wang", "authors": "Nana Wang, Li Cui, Xi Huang, Yingcong Xiang, Jing Xiao", "title": "EasiCSDeep: A deep learning model for Cervical Spondylosis\n  Identification using surface electromyography signal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cervical spondylosis (CS) is a common chronic disease that affects up to\ntwo-thirds of the population and poses a serious burden on individuals and\nsociety. The early identification has significant value in improving cure rate\nand reducing costs. However, the pathology is complex, and the mild symptoms\nincrease the difficulty of the diagnosis, especially in the early stage.\nBesides, the time-consuming and costliness of hospital medical service reduces\nthe attention to the CS identification. Thus, a convenient, low-cost\nintelligent CS identification method is imperious demanded. In this paper, we\npresent an intelligent method based on the deep learning to identify CS, using\nthe surface electromyography (sEMG) signal. Faced with the complex, high\ndimensionality and weak usability of the sEMG signal, we proposed and developed\na multi-channel EasiCSDeep algorithm based on the convolutional neural network,\nwhich consists of the feature extraction, spatial relationship representation\nand classification algorithm. To the best of our knowledge, this EasiCSDeep is\nthe first effort to employ the deep learning and the sEMG data to identify CS.\nCompared with previous state-of-the-art algorithm, our algorithm achieves a\nsignificant improvement.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 12:10:45 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Wang", "Nana", ""], ["Cui", "Li", ""], ["Huang", "Xi", ""], ["Xiang", "Yingcong", ""], ["Xiao", "Jing", ""]]}, {"id": "1812.04948", "submitter": "Samuli Laine", "authors": "Tero Karras, Samuli Laine, Timo Aila", "title": "A Style-Based Generator Architecture for Generative Adversarial Networks", "comments": "CVPR 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an alternative generator architecture for generative adversarial\nnetworks, borrowing from style transfer literature. The new architecture leads\nto an automatically learned, unsupervised separation of high-level attributes\n(e.g., pose and identity when trained on human faces) and stochastic variation\nin the generated images (e.g., freckles, hair), and it enables intuitive,\nscale-specific control of the synthesis. The new generator improves the\nstate-of-the-art in terms of traditional distribution quality metrics, leads to\ndemonstrably better interpolation properties, and also better disentangles the\nlatent factors of variation. To quantify interpolation quality and\ndisentanglement, we propose two new, automated methods that are applicable to\nany generator architecture. Finally, we introduce a new, highly varied and\nhigh-quality dataset of human faces.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 13:59:43 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 14:58:00 GMT"}, {"version": "v3", "created": "Fri, 29 Mar 2019 11:08:46 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Karras", "Tero", ""], ["Laine", "Samuli", ""], ["Aila", "Timo", ""]]}, {"id": "1812.04951", "submitter": "Martin Jung", "authors": "Martin Jung, Sujan Koirala, Ulrich Weber, Kazuhito Ichii, Fabian Gans,\n  Gustau-Camps-Valls, Dario Papale, Christopher Schwalm, Gianluca Tramontana,\n  Markus Reichstein", "title": "The FLUXCOM ensemble of global land-atmosphere energy fluxes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although a key driver of Earth's climate system, global land-atmosphere\nenergy fluxes are poorly constrained. Here we use machine learning to merge\nenergy flux measurements from FLUXNET eddy covariance towers with remote\nsensing and meteorological data to estimate net radiation, latent and sensible\nheat and their uncertainties. The resulting FLUXCOM database comprises 147\nglobal gridded products in two setups: (1) 0.0833${\\deg}$ resolution using\nMODIS remote sensing data (RS) and (2) 0.5${\\deg}$ resolution using remote\nsensing and meteorological data (RS+METEO). Within each setup we use a full\nfactorial design across machine learning methods, forcing datasets and energy\nbalance closure corrections. For RS and RS+METEO setups respectively, we\nestimate 2001-2013 global (${\\pm}$ 1 standard deviation) net radiation as\n75.8${\\pm}$1.4 ${W\\ m^{-2}}$ and 77.6${\\pm}$2 ${W\\ m^{-2}}$, sensible heat as\n33${\\pm}$4 ${W\\ m^{-2}}$ and 36${\\pm}$5 ${W\\ m^{-2}}$, and evapotranspiration\nas 75.6${\\pm}$10 ${\\times}$ 10$^3$ ${km^3\\ yr^{-1}}$ and 76${\\pm}$6 ${\\times}$\n10$^3$ ${km^3\\ yr^{-1}}$. FLUXCOM products are suitable to quantify global\nland-atmosphere interactions and benchmark land surface model simulations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 08:42:02 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Jung", "Martin", ""], ["Koirala", "Sujan", ""], ["Weber", "Ulrich", ""], ["Ichii", "Kazuhito", ""], ["Gans", "Fabian", ""], ["Gustau-Camps-Valls", "", ""], ["Papale", "Dario", ""], ["Schwalm", "Christopher", ""], ["Tramontana", "Gianluca", ""], ["Reichstein", "Markus", ""]]}, {"id": "1812.04994", "submitter": "Wolfgang Fr\\\"uhwirt", "authors": "Wolfgang Fruehwirt, Adam D. Cobb, Martin Mairhofer, Leonard Weydemann,\n  Heinrich Garn, Reinhold Schmidt, Thomas Benke, Peter Dal-Bianco, Gerhard\n  Ransmayr, Markus Waser, Dieter Grossegger, Pengfei Zhang, Georg Dorffner,\n  Stephen Roberts", "title": "Bayesian deep neural networks for low-cost neurophysiological markers of\n  Alzheimer's disease severity", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As societies around the world are ageing, the number of Alzheimer's disease\n(AD) patients is rapidly increasing. To date, no low-cost, non-invasive\nbiomarkers have been established to advance the objectivization of AD diagnosis\nand progression assessment. Here, we utilize Bayesian neural networks to\ndevelop a multivariate predictor for AD severity using a wide range of\nquantitative EEG (QEEG) markers. The Bayesian treatment of neural networks both\nautomatically controls model complexity and provides a predictive distribution\nover the target function, giving uncertainty bounds for our regression task. It\nis therefore well suited to clinical neuroscience, where data sets are\ntypically sparse and practitioners require a precise assessment of the\npredictive uncertainty. We use data of one of the largest prospective AD EEG\ntrials ever conducted to demonstrate the potential of Bayesian deep learning in\nthis domain, while comparing two distinct Bayesian neural network approaches,\ni.e., Monte Carlo dropout and Hamiltonian Monte Carlo.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 15:46:12 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 16:05:37 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Fruehwirt", "Wolfgang", ""], ["Cobb", "Adam D.", ""], ["Mairhofer", "Martin", ""], ["Weydemann", "Leonard", ""], ["Garn", "Heinrich", ""], ["Schmidt", "Reinhold", ""], ["Benke", "Thomas", ""], ["Dal-Bianco", "Peter", ""], ["Ransmayr", "Gerhard", ""], ["Waser", "Markus", ""], ["Grossegger", "Dieter", ""], ["Zhang", "Pengfei", ""], ["Dorffner", "Georg", ""], ["Roberts", "Stephen", ""]]}, {"id": "1812.04998", "submitter": "Seyed Mostafa Kia", "authors": "Seyed Mostafa Kia, Andre F. Marquand", "title": "Neural Processes Mixed-Effect Models for Deep Normative Modeling of\n  Clinical Neuroimaging Data", "comments": "Medical Imaging with Deep Learning (MIDL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normative modeling has recently been introduced as a promising approach for\nmodeling variation of neuroimaging measures across individuals in order to\nderive biomarkers of psychiatric disorders. Current implementations rely on\nGaussian process regression, which provides coherent estimates of uncertainty\nneeded for the method but also suffers from drawbacks including poor scaling to\nlarge datasets and a reliance on fixed parametric kernels. In this paper, we\npropose a deep normative modeling framework based on neural processes (NPs) to\nsolve these problems. To achieve this, we define a stochastic process\nformulation for mixed-effect models and show how NPs can be adopted for\nspatially structured mixed-effect modeling of neuroimaging data. This enables\nus to learn optimal feature representations and covariance structure for the\nrandom-effect and noise via global latent variables. In this scheme, predictive\nuncertainty can be approximated by sampling from the distribution of these\nglobal latent variables. On a publicly available clinical fMRI dataset, we\ncompare the novelty detection performance of multivariate normative models\nestimated by the proposed NP approach to a baseline multi-task Gaussian process\nregression approach and show substantial improvements for certain diagnostic\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 16:02:06 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 13:18:47 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kia", "Seyed Mostafa", ""], ["Marquand", "Andre F.", ""]]}, {"id": "1812.05013", "submitter": "Nikhil Vyas", "authors": "Mitali Bafna, Jack Murtagh and Nikhil Vyas", "title": "Thwarting Adversarial Examples: An $L_0$-RobustSparse Fourier Transform", "comments": "Accepted at 32nd Conference on Neural Information Processing Systems\n  (NeurIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm for approximating the Discrete Fourier transform of\nan approximately sparse signal that has been corrupted by worst-case $L_0$\nnoise, namely a bounded number of coordinates of the signal have been corrupted\narbitrarily. Our techniques generalize to a wide range of linear\ntransformations that are used in data analysis such as the Discrete Cosine and\nSine transforms, the Hadamard transform, and their high-dimensional analogs. We\nuse our algorithm to successfully defend against well known $L_0$ adversaries\nin the setting of image classification. We give experimental results on the\nJacobian-based Saliency Map Attack (JSMA) and the Carlini Wagner (CW) $L_0$\nattack on the MNIST and Fashion-MNIST datasets as well as the Adversarial Patch\non the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 16:36:14 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Bafna", "Mitali", ""], ["Murtagh", "Jack", ""], ["Vyas", "Nikhil", ""]]}, {"id": "1812.05043", "submitter": "Mucong Ding", "authors": "Mucong Ding, Yanbang Wang, Erik Hemberg, Una-May O'Reilly", "title": "Transfer Learning using Representation Learning in Massive Open Online\n  Courses", "comments": "10 pages, 11 figures, accepted at LAK'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a Massive Open Online Course (MOOC), predictive models of student behavior\ncan support multiple aspects of learning, including instructor feedback and\ntimely intervention. Ongoing courses, when the student outcomes are yet\nunknown, must rely on models trained from the historical data of previously\noffered courses. It is possible to transfer models, but they often have poor\nprediction performance. One reason is features that inadequately represent\npredictive attributes common to both courses. We present an automated\ntransductive transfer learning approach that addresses this issue. It relies on\nproblem-agnostic, temporal organization of the MOOC clickstream data, where,\nfor each student, for multiple courses, a set of specific MOOC event types is\nexpressed for each time unit. It consists of two alternative transfer methods\nbased on representation learning with auto-encoders: a passive approach using\ntransductive principal component analysis and an active approach that uses a\ncorrelation alignment loss term. With these methods, we investigate the\ntransferability of dropout prediction across similar and dissimilar MOOCs and\ncompare with known methods. Results show improved model transferability and\nsuggest that the methods are capable of automatically learning a feature\nrepresentation that expresses common predictive characteristics of MOOCs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 17:29:16 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 12:54:18 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Ding", "Mucong", ""], ["Wang", "Yanbang", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1812.05044", "submitter": "Mucong Ding", "authors": "Mucong Ding, Kai Yang, Dit-Yan Yeung, Ting-Chuen Pong", "title": "Effective Feature Learning with Unsupervised Learning for Improving the\n  Predictive Models in Massive Open Online Courses", "comments": "10 pages, 13 figures, accepted at LAK'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of learning in massive open online courses (MOOCs) can be\nsignificantly enhanced by introducing personalized intervention schemes which\nrely on building predictive models of student learning behaviors such as some\nengagement or performance indicators. A major challenge that has to be\naddressed when building such models is to design handcrafted features that are\neffective for the prediction task at hand. In this paper, we make the first\nattempt to solve the feature learning problem by taking the unsupervised\nlearning approach to learn a compact representation of the raw features with a\nlarge degree of redundancy. Specifically, in order to capture the underlying\nlearning patterns in the content domain and the temporal nature of the\nclickstream data, we train a modified auto-encoder (AE) combined with the long\nshort-term memory (LSTM) network to obtain a fixed-length embedding for each\ninput sequence. When compared with the original features, the new features that\ncorrespond to the embedding obtained by the modified LSTM-AE are not only more\nparsimonious but also more discriminative for our prediction task. Using simple\nsupervised learning models, the learned features can improve the prediction\naccuracy by up to 17% compared with the supervised neural networks and reduce\noverfitting to the dominant low-performing group of students, specifically in\nthe task of predicting students' performance. Our approach is generic in the\nsense that it is not restricted to a specific supervised learning model nor a\nspecific prediction task for MOOC learning analytics.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 17:30:27 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 19:21:26 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Ding", "Mucong", ""], ["Yang", "Kai", ""], ["Yeung", "Dit-Yan", ""], ["Pong", "Ting-Chuen", ""]]}, {"id": "1812.05068", "submitter": "Tijana Zrnic", "authors": "Tijana Zrnic, Aaditya Ramdas, Michael I. Jordan", "title": "Asynchronous Online Testing of Multiple Hypotheses", "comments": "36 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of asynchronous online testing, aimed at providing\ncontrol of the false discovery rate (FDR) during a continual stream of data\ncollection and testing, where each test may be a sequential test that can start\nand stop at arbitrary times. This setting increasingly characterizes real-world\napplications in science and industry, where teams of researchers across large\norganizations may conduct tests of hypotheses in a decentralized manner. The\noverlap in time and space also tends to induce dependencies among test\nstatistics, a challenge for classical methodology, which either assumes (overly\noptimistically) independence or (overly pessimistically) arbitrary dependence\nbetween test statistics. We present a general framework that addresses both of\nthese issues via a unified computational abstraction that we refer to as\n\"conflict sets.\" We show how this framework yields algorithms with formal FDR\nguarantees under a more intermediate, local notion of dependence. We illustrate\nour algorithms in simulations by comparing to existing algorithms for online\nFDR control.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 18:12:55 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 19:15:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zrnic", "Tijana", ""], ["Ramdas", "Aaditya", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1812.05069", "submitter": "Michael Tschannen", "authors": "Michael Tschannen, Olivier Bachem, Mario Lucic", "title": "Recent Advances in Autoencoder-Based Representation Learning", "comments": "Presented at the third workshop on Bayesian Deep Learning (NeurIPS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning useful representations with little or no supervision is a key\nchallenge in artificial intelligence. We provide an in-depth review of recent\nadvances in representation learning with a focus on autoencoder-based models.\nTo organize these results we make use of meta-priors believed useful for\ndownstream tasks, such as disentanglement and hierarchical organization of\nfeatures. In particular, we uncover three main mechanisms to enforce such\nproperties, namely (i) regularizing the (approximate or aggregate) posterior\ndistribution, (ii) factorizing the encoding and decoding distribution, or (iii)\nintroducing a structured prior distribution. While there are some promising\nresults, implicit or explicit supervision remains a key enabler and all current\nmethods use strong inductive biases and modeling assumptions. Finally, we\nprovide an analysis of autoencoder-based representation learning through the\nlens of rate-distortion theory and identify a clear tradeoff between the amount\nof prior knowledge available about the downstream tasks, and how useful the\nrepresentation is for this task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 18:13:41 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Tschannen", "Michael", ""], ["Bachem", "Olivier", ""], ["Lucic", "Mario", ""]]}, {"id": "1812.05072", "submitter": "Seyedeh Neelufar Payrovnaziri", "authors": "Laura A. Barrett, Seyedeh Neelufar Payrovnaziri, Jiang Bian, Zhe He", "title": "Building Computational Models to Predict One-Year Mortality in ICU\n  Patients with Acute Myocardial Infarction and Post Myocardial Infarction\n  Syndrome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heart disease remains the leading cause of death in the United States.\nCompared with risk assessment guidelines that require manual calculation of\nscores, machine learning-based prediction for disease outcomes such as\nmortality can be utilized to save time and improve prediction accuracy. This\nstudy built and evaluated various machine learning models to predict one-year\nmortality in patients diagnosed with acute myocardial infarction or post\nmyocardial infarction syndrome in the MIMIC-III database. The results of the\nbest performing shallow prediction models were compared to a deep feedforward\nneural network (Deep FNN) with back propagation. We included a cohort of 5436\nadmissions. Six datasets were developed and compared. The models applying\nLogistic Model Trees (LMT) and Simple Logistic algorithms to the combined\ndataset resulted in the highest prediction accuracy at 85.12% and the highest\nAUC at .901. In addition, other factors were observed to have an impact on\noutcomes as well.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 18:19:12 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Barrett", "Laura A.", ""], ["Payrovnaziri", "Seyedeh Neelufar", ""], ["Bian", "Jiang", ""], ["He", "Zhe", ""]]}, {"id": "1812.05159", "submitter": "Mariya Toneva", "authors": "Mariya Toneva, Alessandro Sordoni, Remi Tachet des Combes, Adam\n  Trischler, Yoshua Bengio, Geoffrey J. Gordon", "title": "An Empirical Study of Example Forgetting during Deep Neural Network\n  Learning", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the phenomenon of catastrophic forgetting, we investigate the\nlearning dynamics of neural networks as they train on single classification\ntasks. Our goal is to understand whether a related phenomenon occurs when data\ndoes not undergo a clear distributional shift. We define a `forgetting event'\nto have occurred when an individual training example transitions from being\nclassified correctly to incorrectly over the course of learning. Across several\nbenchmark data sets, we find that: (i) certain examples are forgotten with high\nfrequency, and some not at all; (ii) a data set's (un)forgettable examples\ngeneralize across neural architectures; and (iii) based on forgetting dynamics,\na significant fraction of examples can be omitted from the training data set\nwhile still maintaining state-of-the-art generalization performance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 21:24:15 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 21:31:40 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 17:08:30 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Toneva", "Mariya", ""], ["Sordoni", "Alessandro", ""], ["Combes", "Remi Tachet des", ""], ["Trischler", "Adam", ""], ["Bengio", "Yoshua", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1812.05165", "submitter": "Lai Wei", "authors": "Lai Wei and Vaibhav Srivastava", "title": "On Distributed Multi-player Multiarmed Bandit Problems in Abruptly\n  Changing Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-player stochastic multiarmed bandit (MAB) problem in an\nabruptly changing environment. We consider a collision model in which a player\nreceives reward at an arm if it is the only player to select the arm. We design\ntwo novel algorithms, namely, Round-Robin Sliding-Window Upper Confidence\nBound\\# (RR-SW-UCB\\#), and the Sliding-Window Distributed Learning with\nPrioritization (SW-DLP). We rigorously analyze these algorithms and show that\nthe expected cumulative group regret for these algorithms is upper bounded by\nsublinear functions of time, i.e., the time average of the regret\nasymptotically converges to zero. We complement our analytic results with\nnumerical illustrations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 21:36:04 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Wei", "Lai", ""], ["Srivastava", "Vaibhav", ""]]}, {"id": "1812.05189", "submitter": "Jason Altschuler", "authors": "Jason Altschuler, Francis Bach, Alessandro Rudi, Jonathan Niles-Weed", "title": "Massively scalable Sinkhorn distances via the Nystr\\\"om method", "comments": "to appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sinkhorn \"distance\", a variant of the Wasserstein distance with entropic\nregularization, is an increasingly popular tool in machine learning and\nstatistical inference. However, the time and memory requirements of standard\nalgorithms for computing this distance grow quadratically with the size of the\ndata, making them prohibitively expensive on massive data sets. In this work,\nwe show that this challenge is surprisingly easy to circumvent: combining two\nsimple techniques---the Nystr\\\"om method and Sinkhorn scaling---provably yields\nan accurate approximation of the Sinkhorn distance with significantly lower\ntime and memory requirements than other approaches. We prove our results via\nnew, explicit analyses of the Nystr\\\"om method and of the stability properties\nof Sinkhorn scaling. We validate our claims experimentally by showing that our\napproach easily computes Sinkhorn distances on data sets hundreds of times\nlarger than can be handled by other techniques.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 23:10:16 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 18:42:35 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 23:58:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Altschuler", "Jason", ""], ["Bach", "Francis", ""], ["Rudi", "Alessandro", ""], ["Niles-Weed", "Jonathan", ""]]}, {"id": "1812.05212", "submitter": "Xin Wang", "authors": "Marcel Nassar, Xin Wang, Evren Tumer", "title": "Conditional Graph Neural Processes: A Functional Autoencoder Approach", "comments": "3 pages, 1 figure, 1 table, published in the Third Workshop on\n  Bayesian Deep Learning (NeurIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel encoder-decoder architecture to embed functional\nprocesses into latent vector spaces. This embedding can then be decoded to\nsample the encoded functions over any arbitrary domain. This autoencoder\ngeneralizes the recently introduced Conditional Neural Process (CNP) model of\nrandom processes. Our architecture employs the latest advances in graph neural\nnetworks to process irregularly sampled functions. Thus, we refer to our model\nas Conditional Graph Neural Process (CGNP). Graph neural networks can\neffectively exploit `local' structures of the metric spaces over which the\nfunctions/processes are defined. The contributions of this paper are twofold:\n(i) a novel graph-based encoder-decoder architecture for functional and process\nembeddings, and (ii) a demonstration of the importance of using the structure\nof metric spaces for this type of representations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 00:52:56 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Nassar", "Marcel", ""], ["Wang", "Xin", ""], ["Tumer", "Evren", ""]]}, {"id": "1812.05214", "submitter": "Junnan Li Mr", "authors": "Junnan Li, Yongkang Wong, Qi Zhao, Mohan Kankanhalli", "title": "Learning to Learn from Noisy Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of deep neural networks (DNNs) in image classification\ntasks, the human-level performance relies on massive training data with\nhigh-quality manual annotations, which are expensive and time-consuming to\ncollect. There exist many inexpensive data sources on the web, but they tend to\ncontain inaccurate labels. Training on noisy labeled datasets causes\nperformance degradation because DNNs can easily overfit to the label noise. To\novercome this problem, we propose a noise-tolerant training algorithm, where a\nmeta-learning update is performed prior to conventional gradient update. The\nproposed meta-learning method simulates actual training by generating synthetic\nnoisy labels, and train the model such that after one gradient update using\neach set of synthetic noisy labels, the model does not overfit to the specific\nnoise. We conduct extensive experiments on the noisy CIFAR-10 dataset and the\nClothing1M dataset. The results demonstrate the advantageous performance of the\nproposed method compared to several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 00:58:05 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 12:28:54 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Li", "Junnan", ""], ["Wong", "Yongkang", ""], ["Zhao", "Qi", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1812.05217", "submitter": "Sikander Randhawa", "authors": "Nicholas J. A. Harvey, Christopher Liaw, Yaniv Plan, Sikander Randhawa", "title": "Tight Analyses for Non-Smooth Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of minimizing functions that are Lipschitz and strongly\nconvex, but not necessarily differentiable. We prove that after $T$ steps of\nstochastic gradient descent, the error of the final iterate is $O(\\log(T)/T)$\nwith high probability. We also construct a function from this class for which\nthe error of the final iterate of deterministic gradient descent is\n$\\Omega(\\log(T)/T)$. This shows that the upper bound is tight and that, in this\nsetting, the last iterate of stochastic gradient descent has the same general\nerror rate (with high probability) as deterministic gradient descent. This\nresolves both open questions posed by Shamir (2012).\n  An intermediate step of our analysis proves that the suffix averaging method\nachieves error $O(1/T)$ with high probability, which is optimal (for any\nfirst-order optimization method). This improves results of Rakhlin (2012) and\nHazan and Kale (2014), both of which achieved error $O(1/T)$, but only in\nexpectation, and achieved a high probability error bound of $O(\\log\n\\log(T)/T)$, which is suboptimal.\n  We prove analogous results for functions that are Lipschitz and convex, but\nnot necessarily strongly convex or differentiable. After $T$ steps of\nstochastic gradient descent, the error of the final iterate is\n$O(\\log(T)/\\sqrt{T})$ with high probability, and there exists a function for\nwhich the error of the final iterate of deterministic gradient descent is\n$\\Omega(\\log(T)/\\sqrt{T})$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 01:18:56 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Harvey", "Nicholas J. A.", ""], ["Liaw", "Christopher", ""], ["Plan", "Yaniv", ""], ["Randhawa", "Sikander", ""]]}, {"id": "1812.05221", "submitter": "Chengsheng Mao", "authors": "Chengsheng Mao, Lijuan Lu, Bin Hu", "title": "Local Probabilistic Model for Bayesian Classification: a Generalized\n  Local Classification Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian classification, it is important to establish a probabilistic\nmodel for each class for likelihood estimation. Most of the previous methods\nmodeled the probability distribution in the whole sample space. However,\nreal-world problems are usually too complex to model in the whole sample space;\nsome fundamental assumptions are required to simplify the global model, for\nexample, the class conditional independence assumption for naive Bayesian\nclassification. In this paper, with the insight that the distribution in a\nlocal sample space should be simpler than that in the whole sample space, a\nlocal probabilistic model established for a local region is expected much\nsimpler and can relax the fundamental assumptions that may not be true in the\nwhole sample space. Based on these advantages we propose establishing local\nprobabilistic models for Bayesian classification. In addition, a Bayesian\nclassifier adopting a local probabilistic model can even be viewed as a\ngeneralized local classification model; by tuning the size of the local region\nand the corresponding local model assumption, a fitting model can be\nestablished for a particular classification problem. The experimental results\non several real-world datasets demonstrate the effectiveness of local\nprobabilistic models for Bayesian classification.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 01:49:03 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Mao", "Chengsheng", ""], ["Lu", "Lijuan", ""], ["Hu", "Bin", ""]]}, {"id": "1812.05248", "submitter": "Zhuan Li", "authors": "Zhuan Li, Pan Zhang", "title": "Shortcut Matrix Product States and its applications", "comments": "15pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Product States (MPS), also known as Tensor Train (TT) decomposition in\nmathematics, has been proposed originally for describing an (especially\none-dimensional) quantum system, and recently has found applications in various\napplications such as compressing high-dimensional data, supervised kernel\nlinear classifier, and unsupervised generative modeling. However, when applied\nto systems which are not defined on one-dimensional lattices, a serious\ndrawback of the MPS is the exponential decay of the correlations, which limits\nits power in capturing long-range dependences among variables in the system. To\nalleviate this problem, we propose to introduce long-range interactions, which\nact as shortcuts, to MPS, resulting in a new model \\textit{ Shortcut Matrix\nProduct States} (SMPS). When chosen properly, the shortcuts can decrease\nsignificantly the correlation length of the MPS, while preserving the\ncomputational efficiency. We develop efficient training methods of SMPS for\nvarious tasks, establish some of their mathematical properties, and show how to\nfind a good location to add shortcuts. Finally, using extensive numerical\nexperiments we evaluate its performance in a variety of applications, including\nfunction fitting, partition function calculation of $2-$d Ising model, and\nunsupervised generative modeling of handwritten digits, to illustrate its\nadvantages over vanilla matrix product states.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 03:14:19 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Li", "Zhuan", ""], ["Zhang", "Pan", ""]]}, {"id": "1812.05288", "submitter": "Parminder Bhatia", "authors": "Parminder Bhatia, Kristjan Arumae, Busra Celikkaya", "title": "Dynamic Transfer Learning for Named Entity Recognition", "comments": "AAAI 2019 Workshop on Health Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art named entity recognition (NER) systems have been improving\ncontinuously using neural architectures over the past several years. However,\nmany tasks including NER require large sets of annotated data to achieve such\nperformance. In particular, we focus on NER from clinical notes, which is one\nof the most fundamental and critical problems for medical text analysis. Our\nwork centers on effectively adapting these neural architectures towards\nlow-resource settings using parameter transfer methods. We complement a\nstandard hierarchical NER model with a general transfer learning framework\nconsisting of parameter sharing between the source and target tasks, and\nshowcase scores significantly above the baseline architecture. These sharing\nschemes require an exponential search over tied parameter sets to generate an\noptimal configuration. To mitigate the problem of exhaustively searching for\nmodel optimization, we propose the Dynamic Transfer Networks (DTN), a gated\narchitecture which learns the appropriate parameter sharing scheme between\nsource and target datasets. DTN achieves the improvements of the optimized\ntransfer learning framework with just a single training setting, effectively\nremoving the need for exponential search.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 07:02:54 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 05:24:32 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 23:50:45 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 22:30:14 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bhatia", "Parminder", ""], ["Arumae", "Kristjan", ""], ["Celikkaya", "Busra", ""]]}, {"id": "1812.05421", "submitter": "Michael Vogt", "authors": "Michael Vogt", "title": "On the Differences between L2-Boosting and the Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that L2-Boosting lacks a theoretical property which is central to\nthe behaviour of l1-penalized methods such as basis pursuit and the Lasso:\nWhereas l1-penalized methods are guaranteed to recover the sparse parameter\nvector in a high-dimensional linear model under an appropriate restricted\nnullspace property, L2-Boosting is not guaranteed to do so. Hence, L2-Boosting\nbehaves quite differently from l1-penalized methods when it comes to parameter\nrecovery/estimation in high-dimensional linear models.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 13:41:38 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Vogt", "Michael", ""]]}, {"id": "1812.05443", "submitter": "Tara Salman", "authors": "Tara Salman, Deval Bhamare, Aiman Erbad, Raj Jain, and Mohammed Samaka", "title": "Machine Learning for Anomaly Detection and Categorization in Multi-cloud\n  Environments", "comments": "CSCLoud17", "journal-ref": "CSCLOUD 2017", "doi": "10.1109/CSCloud.2017.15", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, advances in machine learning techniques have attracted the\nattention of the research community to build intrusion detection systems (IDS)\nthat can detect anomalies in the network traffic. Most of the research works,\nhowever, do not differentiate among different types of attacks. This is, in\nfact, necessary for appropriate countermeasures and defense against attacks. In\nthis paper, we investigate both detecting and categorizing anomalies rather\nthan just detecting, which is a common trend in the contemporary research\nworks. We have used a popular publicly available dataset to build and test\nlearning models for both detection and categorization of different attacks. To\nbe precise, we have used two supervised machine learning techniques, namely\nlinear regression (LR) and random forest (RF). We show that even if detection\nis perfect, categorization can be less accurate due to similarities between\nattacks. Our results demonstrate more than 99% detection accuracy and\ncategorization accuracy of 93.6%, with the inability to categorize some\nattacks. Further, we argue that such categorization can be applied to\nmulti-cloud environments using the same machine learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:39:24 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Salman", "Tara", ""], ["Bhamare", "Deval", ""], ["Erbad", "Aiman", ""], ["Jain", "Raj", ""], ["Samaka", "Mohammed", ""]]}, {"id": "1812.05451", "submitter": "Sebastien Blandin", "authors": "Marc Jourdan, Sebastien Blandin, Laura Wynter, Pralhad Deshpande", "title": "A Probabilistic Model of the Bitcoin Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin transaction graph is a public data structure organized as\ntransactions between addresses, each associated with a logical entity. In this\nwork, we introduce a complete probabilistic model of the Bitcoin Blockchain. We\nfirst formulate a set of conditional dependencies induced by the Bitcoin\nprotocol at the block level and derive a corresponding fully observed graphical\nmodel of a Bitcoin block. We then extend the model to include hidden entity\nattributes such as the functional category of the associated logical agent and\nderive asymptotic bounds on the privacy properties implied by this model. At\nthe network level, we show evidence of complex transaction-to-transaction\nbehavior and present a relevant discriminative model of the agent categories.\nPerformance of both the block-based graphical model and the network-level\ndiscriminative model is evaluated on a subset of the public Bitcoin Blockchain.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 02:35:24 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Jourdan", "Marc", ""], ["Blandin", "Sebastien", ""], ["Wynter", "Laura", ""], ["Deshpande", "Pralhad", ""]]}, {"id": "1812.05477", "submitter": "Alessandro Di Martino", "authors": "Alessandro Di Martino and Erik Bodin and Carl Henrik Ek and Neill D.F.\n  Campbell", "title": "Gaussian Process Deep Belief Networks: A Smooth Generative Model of\n  Shape with Uncertainty Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shape of an object is an important characteristic for many vision\nproblems such as segmentation, detection and tracking. Being independent of\nappearance, it is possible to generalize to a large range of objects from only\nsmall amounts of data. However, shapes represented as silhouette images are\nchallenging to model due to complicated likelihood functions leading to\nintractable posteriors. In this paper we present a generative model of shapes\nwhich provides a low dimensional latent encoding which importantly resides on a\nsmooth manifold with respect to the silhouette images. The proposed model\npropagates uncertainty in a principled manner allowing it to learn from small\namounts of data and providing predictions with associated uncertainty. We\nprovide experiments that show how our proposed model provides favorable\nquantitative results compared with the state-of-the-art while simultaneously\nproviding a representation that resides on a low-dimensional interpretable\nmanifold.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 15:25:40 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Di Martino", "Alessandro", ""], ["Bodin", "Erik", ""], ["Ek", "Carl Henrik", ""], ["Campbell", "Neill D. F.", ""]]}, {"id": "1812.05501", "submitter": "Kenji Nagata", "authors": "Kenji Nagata, Yoh-ichi Mototake, Rei Muraoka, Takehiko Sasaki, Masato\n  Okada", "title": "Bayesian Spectral Deconvolution Based on Poisson Distribution: Bayesian\n  Measurement and Virtual Measurement Analytics (VMA)", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": "10.7566/JPSJ.88.044003", "report-no": null, "categories": "eess.SP cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method of Bayesian measurement for spectral\ndeconvolution, which regresses spectral data into the sum of unimodal basis\nfunction such as Gaussian or Lorentzian functions. Bayesian measurement is a\nframework for considering not only the target physical model but also the\nmeasurement model as a probabilistic model, and enables us to estimate the\nparameter of a physical model with its confidence interval through a Bayesian\nposterior distribution given a measurement data set. The measurement with\nPoisson noise is one of the most effective system to apply our proposed method.\nSince the measurement time is strongly related to the signal-to-noise ratio for\nthe Poisson noise model, Bayesian measurement with Poisson noise model enables\nus to clarify the relationship between the measurement time and the limit of\nestimation. In this study, we establish the probabilistic model with Poisson\nnoise for spectral deconvolution. Bayesian measurement enables us to perform\nvirtual and computer simulation for a certain measurement through the\nestablished probabilistic model. This property is called \"Virtual Measurement\nAnalytics(VMA)\" in this paper. We also show that the relationship between the\nmeasurement time and the limit of estimation can be extracted by using the\nproposed method in a simulation of synthetic data and real data for XPS\nmeasurement of MoS$_2$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 08:50:50 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Nagata", "Kenji", ""], ["Mototake", "Yoh-ichi", ""], ["Muraoka", "Rei", ""], ["Sasaki", "Takehiko", ""], ["Okada", "Masato", ""]]}, {"id": "1812.05519", "submitter": "Abhishek Das", "authors": "Samit Bhanja and Abhishek Das", "title": "Impact of Data Normalization on Deep Neural Network for Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the last few years it has been observed that the Deep Neural Networks\n(DNNs) has achieved an excellent success in image classification, speech\nrecognition. But DNNs are suffer great deal of challenges for time series\nforecasting because most of the time series data are nonlinear in nature and\nhighly dynamic in behaviour. The time series forecasting has a great impact on\nour socio-economic environment. Hence, to deal with these challenges its need\nto be redefined the DNN model and keeping this in mind, data pre-processing,\nnetwork architecture and network parameters are need to be consider before\nfeeding the data into DNN models. Data normalization is the basic data\npre-processing technique form which learning is to be done. The effectiveness\nof time series forecasting is heavily depend on the data normalization\ntechnique. In this paper, different normalization methods are used on time\nseries data before feeding the data into the DNN model and we try to find out\nthe impact of each normalization technique on DNN to forecast the time series.\nHere the Deep Recurrent Neural Network (DRNN) is used to predict the closing\nindex of Bombay Stock Exchange (BSE) and New York Stock Exchange (NYSE) by\nusing BSE and NYSE time series data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 16:54:49 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 19:34:25 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Bhanja", "Samit", ""], ["Das", "Abhishek", ""]]}, {"id": "1812.05551", "submitter": "Lior Shani", "authors": "Lior Shani, Yonathan Efroni, Shie Mannor", "title": "Exploration Conscious Reinforcement Learning Revisited", "comments": "Published @ICML 2019 (36th International Conference on Machine\n  Learning 2019)", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:5680-5689, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Exploration-Exploitation tradeoff arises in Reinforcement Learning when\none cannot tell if a policy is optimal. Then, there is a constant need to\nexplore new actions instead of exploiting past experience. In practice, it is\ncommon to resolve the tradeoff by using a fixed exploration mechanism, such as\n$\\epsilon$-greedy exploration or by adding Gaussian noise, while still trying\nto learn an optimal policy. In this work, we take a different approach and\nstudy exploration-conscious criteria, that result in optimal policies with\nrespect to the exploration mechanism. Solving these criteria, as we establish,\namounts to solving a surrogate Markov Decision Process. We continue and analyze\nproperties of exploration-conscious optimal policies and characterize two\ngeneral approaches to solve such criteria. Building on the approaches, we apply\nsimple changes in existing tabular and deep Reinforcement Learning algorithms\nand empirically demonstrate superior performance relatively to their\nnon-exploration-conscious counterparts, both for discrete and continuous action\nspaces.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 18:08:04 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 00:25:04 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 08:32:52 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shani", "Lior", ""], ["Efroni", "Yonathan", ""], ["Mannor", "Shie", ""]]}, {"id": "1812.05555", "submitter": "Zheng Zhao", "authors": "Zheng Zhao, Simo S\\\"arkk\\\"a, and Ali Bahrami Rad", "title": "Kalman-based Spectro-Temporal ECG Analysis using Deep Convolutional\n  Networks for Atrial Fibrillation Detection", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a novel ECG classification framework for atrial\nfibrillation (AF) detection using spectro-temporal representation (i.e., time\nvarying spectrum) and deep convolutional networks. In the first step we use a\nBayesian spectro-temporal representation based on the estimation of\ntime-varying coefficients of Fourier series using Kalman filter and smoother.\nNext, we derive an alternative model based on a stochastic oscillator\ndifferential equation to accelerate the estimation of the spectro-temporal\nrepresentation in lengthy signals. Finally, after comparative evaluations of\ndifferent convolutional architectures, we propose an efficient deep\nconvolutional neural network to classify the 2D spectro-temporal ECG data.\n  The ECG spectro-temporal data are classified into four different classes: AF,\nnon-AF normal rhythm (Normal), non-AF abnormal rhythm (Other), and noisy\nsegments (Noisy). The performance of the proposed methods is evaluated and\nscored with the PhysioNet/Computing in Cardiology (CinC) 2017 dataset. The\nexperimental results show that the proposed method achieves the overall F1\nscore of 80.2%, which is in line with the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 13:38:05 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Zhao", "Zheng", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Rad", "Ali Bahrami", ""]]}, {"id": "1812.05556", "submitter": "Liane Gabora", "authors": "Steve DiPaola, Liane Gabora, and Graeme McCaig", "title": "Informing Artificial Intelligence Generative Techniques using Cognitive\n  Theories of Human Creativity", "comments": "18 pages; 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:1610.02478", "journal-ref": "Procedia Computer Science, vol. 145 (pp. 158-168). Amsterdam:\n  Elsevier (2018)", "doi": "10.1016/j.procs.2018.11.024", "report-no": null, "categories": "cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The common view that our creativity is what makes us uniquely human suggests\nthat incorporating research on human creativity into generative deep learning\ntechniques might be a fruitful avenue for making their outputs more compelling\nand human-like. Using an original synthesis of Deep Dream-based convolutional\nneural networks and cognitive based computational art rendering systems, we\nshow how honing theory, intrinsic motivation, and the notion of a 'seed\nincident' can be implemented computationally, and demonstrate their impact on\nthe resulting generative art. Conversely, we discuss how explorations in deep\nlearn-ing convolutional neural net generative systems can inform our\nunderstanding of human creativity. We conclude with ideas for further\ncross-fertilization between AI based computational creativity and psychology of\ncreativity.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:12:44 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 21:00:09 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["DiPaola", "Steve", ""], ["Gabora", "Liane", ""], ["McCaig", "Graeme", ""]]}, {"id": "1812.05571", "submitter": "Carl Leake", "authors": "Carl Leake, Hunter Johnston, Lidia Smith, and Daniele Mortari", "title": "Analytically Embedding Differential Equation Constraints into Least\n  Squares Support Vector Machines using the Theory of Functional Connections", "comments": "22 pages, 8 Figures, 12 tables", "journal-ref": "Mach. Learn. Knowl. Extr. 2019, 1(4), 1058-1083", "doi": "10.3390/make1040060", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential equations (DEs) are used as numerical models to describe\nphysical phenomena throughout the field of engineering and science, including\nheat and fluid flow, structural bending, and systems dynamics. While there are\nmany other techniques for finding approximate solutions to these equations,\nthis paper looks to compare the application of the Theory of Functional\nConnections (TFC) with one based on least-squares support vector machines\n(LS-SVM). The TFC method uses a constrained expression, an expression that\nalways satisfies the DE constraints, which transforms the process of solving a\nDE into solving an unconstrained optimization problem that is ultimately solved\nvia least-squares (LS). In addition to individual analysis, the two methods are\nmerged into a new methodology, called constrained SVMs (CSVM), by incorporating\nthe LS-SVM method into the TFC framework to solve unconstrained problems.\nNumerical tests are conducted on four sample problems: One first order linear\nordinary differential equation (ODE), one first order nonlinear ODE, one second\norder linear ODE, and one two-dimensional linear partial differential equation\n(PDE). Using the LS-SVM method as a benchmark, a speed comparison is made for\nall the problems by timing the training period, and an accuracy comparison is\nmade using the maximum error and mean squared error on the training and test\nsets. In general, TFC is shown to be slightly faster (by an order of magnitude\nor less) and more accurate (by multiple orders of magnitude) than the LS-SVM\nand CSVM approaches.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 18:44:55 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 16:21:51 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 14:58:04 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Leake", "Carl", ""], ["Johnston", "Hunter", ""], ["Smith", "Lidia", ""], ["Mortari", "Daniele", ""]]}, {"id": "1812.05645", "submitter": "Moritz Wolter", "authors": "Moritz Wolter and Juergen Gall and Angela Yao", "title": "Sequence Prediction using Spectral RNNs", "comments": "Source code available at https://github.com/v0lta/Spectral-RNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier methods have a long and proven track record as an excellent tool in\ndata processing. As memory and computational constraints gain importance in\nembedded and mobile applications, we propose to combine Fourier methods and\nrecurrent neural network architectures. The short-time Fourier transform allows\nus to efficiently process multiple samples at a time. Additionally, weight\nreductions trough low pass filtering is possible. We predict time series data\ndrawn from the chaotic Mackey-Glass differential equation and real-world power\nload and motion capture data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 19:26:22 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 10:29:15 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 16:13:28 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Wolter", "Moritz", ""], ["Gall", "Juergen", ""], ["Yao", "Angela", ""]]}, {"id": "1812.05676", "submitter": "Lu Mi", "authors": "Lu Mi, Macheng Shen, Jingzhao Zhang", "title": "A Probe Towards Understanding GAN and VAE Models", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project report compares some known GAN and VAE models proposed prior to\n2017. There has been significant progress after we finished this report. We\nupload this report as an introduction to generative models and provide some\npersonal interpretations supported by empirical evidence. Both generative\nadversarial network models and variational autoencoders have been widely used\nto approximate probability distributions of data sets. Although they both use\nparametrized distributions to approximate the underlying data distribution,\nwhose exact inference is intractable, their behaviors are very different. We\nsummarize our experiment results that compare these two categories of models in\nterms of fidelity and mode collapse. We provide a hypothesis to explain their\ndifferent behaviors and propose a new model based on this hypothesis. We\nfurther tested our proposed model on MNIST dataset and CelebA dataset.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 20:33:34 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 20:35:51 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Mi", "Lu", ""], ["Shen", "Macheng", ""], ["Zhang", "Jingzhao", ""]]}, {"id": "1812.05692", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ekaterina Lobacheva, Nadezhda Chirkova, Dmitry Vetrov", "title": "Bayesian Sparsification of Gated Recurrent Neural Networks", "comments": "Published in Workshop on Compact Deep Neural Networks with industrial\n  applications, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian methods have been successfully applied to sparsify weights of neural\nnetworks and to remove structure units from the networks, e. g. neurons. We\napply and further develop this approach for gated recurrent architectures.\nSpecifically, in addition to sparsification of individual weights and neurons,\nwe propose to sparsify preactivations of gates and information flow in LSTM. It\nmakes some gates and information flow components constant, speeds up forward\npass and improves compression. Moreover, the resulting structure of gate\nsparsity is interpretable and depends on the task. Code is available on github:\nhttps://github.com/tipt0p/SparseBayesianRNN\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 14:32:16 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Lobacheva", "Ekaterina", ""], ["Chirkova", "Nadezhda", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1812.05710", "submitter": "Zhiba Su", "authors": "Dabiao Ma, Zhiba Su, Wenxuan Wang, Yuhao Lu", "title": "FPETS : Fully Parallel End-to-End Text-to-Speech System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end Text-to-speech (TTS) system can greatly improve the quality of\nsynthesised speech. But it usually suffers form high time latency due to its\nauto-regressive structure. And the synthesised speech may also suffer from some\nerror modes, e.g. repeated words, mispronunciations, and skipped words. In this\npaper, we propose a novel non-autoregressive, fully parallel end-to-end TTS\nsystem (FPETS). It utilizes a new alignment model and the recently proposed\nU-shape convolutional structure, UFANS. Different from RNN, UFANS can capture\nlong term information in a fully parallel manner. Trainable position encoding\nand two-step training strategy are used for learning better alignments.\nExperimental results show FPETS utilizes the power of parallel computation and\nreaches a significant speed up of inference compared with state-of-the-art\nend-to-end TTS systems. More specifically, FPETS is 600X faster than Tacotron2,\n50X faster than DCTTS and 10X faster than Deep Voice3. And FPETS can generates\naudios with equal or better quality and fewer errors comparing with other\nsystem. As far as we know, FPETS is the first end-to-end TTS system which is\nfully parallel.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 05:17:23 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 03:28:18 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 18:39:40 GMT"}, {"version": "v4", "created": "Tue, 17 Sep 2019 00:31:29 GMT"}, {"version": "v5", "created": "Sun, 9 Feb 2020 18:19:09 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ma", "Dabiao", ""], ["Su", "Zhiba", ""], ["Wang", "Wenxuan", ""], ["Lu", "Yuhao", ""]]}, {"id": "1812.05720", "submitter": "Maksym Andriushchenko", "authors": "Matthias Hein, Maksym Andriushchenko, Julian Bitterwolf", "title": "Why ReLU networks yield high-confidence predictions far away from the\n  training data and how to mitigate the problem", "comments": "Slight update of the CVPR 2019 final version [accepted with an oral\n  presentation]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers used in the wild, in particular for safety-critical systems,\nshould not only have good generalization properties but also should know when\nthey don't know, in particular make low confidence predictions far away from\nthe training data. We show that ReLU type neural networks which yield a\npiecewise linear classifier function fail in this regard as they produce almost\nalways high confidence predictions far away from the training data. For bounded\ndomains like images we propose a new robust optimization technique similar to\nadversarial training which enforces low confidence predictions far away from\nthe training data. We show that this technique is surprisingly effective in\nreducing the confidence of predictions far away from the training data while\nmaintaining high confidence predictions and test error on the original\nclassification task compared to standard training.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 22:52:42 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 06:57:43 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Hein", "Matthias", ""], ["Andriushchenko", "Maksym", ""], ["Bitterwolf", "Julian", ""]]}, {"id": "1812.05721", "submitter": "Giovanni Chierchia", "authors": "Mireille El Gheche, Giovanni Chierchia, Pascal Frossard", "title": "Stochastic Gradient Descent for Spectral Embedding with Implicit\n  Orthogonality Constraint", "comments": "Accepted at IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP), Brighton, UK, 12-17 May, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a scalable algorithm for spectral embedding. The\nlatter is a standard tool for graph clustering. However, its computational\nbottleneck is the eigendecomposition of the graph Laplacian matrix, which\nprevents its application to large-scale graphs. Our contribution consists of\nreformulating spectral embedding so that it can be solved via stochastic\noptimization. The idea is to replace the orthogonality constraint with an\northogonalization matrix injected directly into the criterion. As the gradient\ncan be computed through a Cholesky factorization, our reformulation allows us\nto develop an efficient algorithm based on mini-batch gradient descent.\nExperimental results, both on synthetic and real data, confirm the efficiency\nof the proposed method in term of execution speed with respect to similar\nexisting techniques.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 22:53:23 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 15:03:16 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Gheche", "Mireille El", ""], ["Chierchia", "Giovanni", ""], ["Frossard", "Pascal", ""]]}, {"id": "1812.05737", "submitter": "Venkatesh Umaashankar Mr", "authors": "Abdul Arfat Mohammed and Venkatesh Umaashankar", "title": "Effectiveness of Hierarchical Softmax in Large Scale Classification\n  Tasks", "comments": null, "journal-ref": null, "doi": "10.1109/ICACCI.2018.8554637", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, Softmax is used in the final layer of a neural network to get a\nprobability distribution for output classes. But the main problem with Softmax\nis that it is computationally expensive for large scale data sets with large\nnumber of possible outputs. To approximate class probability efficiently on\nsuch large scale data sets we can use Hierarchical Softmax. LSHTC datasets were\nused to study the performance of the Hierarchical Softmax. LSHTC datasets have\nlarge number of categories. In this paper we evaluate and report the\nperformance of normal Softmax Vs Hierarchical Softmax on LSHTC datasets. This\nevaluation used macro f1 score as a performance measure. The observation was\nthat the performance of Hierarchical Softmax degrades as the number of classes\nincrease.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 23:57:33 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Mohammed", "Abdul Arfat", ""], ["Umaashankar", "Venkatesh", ""]]}, {"id": "1812.05758", "submitter": "Al Mehdi Saadat Chowdhury", "authors": "Al Mehdi Saadat Chowdhury, M. Shahidur Rahman, Asia Khanom, Tamanna\n  Islam Chowdhury, Afaz Uddin", "title": "On Stacked Denoising Autoencoder based Pre-training of ANN for Isolated\n  Handwritten Bengali Numerals Dataset Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work attempts to find the most optimal parameter setting of a deep\nartificial neural network (ANN) for Bengali digit dataset by pre-training it\nusing stacked denoising autoencoder (SDA). Although SDA based recognition is\nhugely popular in image, speech and language processing related tasks among the\nresearchers, it was never tried in Bengali dataset recognition. For this work,\na dataset of 70000 handwritten samples were used from (Chowdhury and Rahman,\n2016) and was recognized using several settings of network architecture. Among\nall these settings, the most optimal setting being found to be five or more\ndeeper hidden layers with sigmoid activation and one output layer with softmax\nactivation. We proposed the optimal number of neurons that can be used in the\nhidden layer is 1500 or more. The minimum validation error found from this work\nis 2.34% which is the lowest error rate on handwritten Bengali dataset proposed\ntill date.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 02:01:13 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Chowdhury", "Al Mehdi Saadat", ""], ["Rahman", "M. Shahidur", ""], ["Khanom", "Asia", ""], ["Chowdhury", "Tamanna Islam", ""], ["Uddin", "Afaz", ""]]}, {"id": "1812.05784", "submitter": "Alex Lang", "authors": "Alex H. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang,\n  Oscar Beijbom", "title": "PointPillars: Fast Encoders for Object Detection from Point Clouds", "comments": "9 pages. v1 is initial submission to CVPR 2019. v2 is final version\n  accepted for publication at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection in point clouds is an important aspect of many robotics\napplications such as autonomous driving. In this paper we consider the problem\nof encoding a point cloud into a format appropriate for a downstream detection\npipeline. Recent literature suggests two types of encoders; fixed encoders tend\nto be fast but sacrifice accuracy, while encoders that are learned from data\nare more accurate, but slower. In this work we propose PointPillars, a novel\nencoder which utilizes PointNets to learn a representation of point clouds\norganized in vertical columns (pillars). While the encoded features can be used\nwith any standard 2D convolutional detection architecture, we further propose a\nlean downstream network. Extensive experimentation shows that PointPillars\noutperforms previous encoders with respect to both speed and accuracy by a\nlarge margin. Despite only using lidar, our full detection pipeline\nsignificantly outperforms the state of the art, even among fusion methods, with\nrespect to both the 3D and bird's eye view KITTI benchmarks. This detection\nperformance is achieved while running at 62 Hz: a 2 - 4 fold runtime\nimprovement. A faster version of our method matches the state of the art at 105\nHz. These benchmarks suggest that PointPillars is an appropriate encoding for\nobject detection in point clouds.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 05:15:08 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 02:00:24 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Lang", "Alex H.", ""], ["Vora", "Sourabh", ""], ["Caesar", "Holger", ""], ["Zhou", "Lubing", ""], ["Yang", "Jiong", ""], ["Beijbom", "Oscar", ""]]}, {"id": "1812.05792", "submitter": "Matt Olson", "authors": "Matthew A. Olson, Abraham J. Wyner", "title": "Making Sense of Random Forest Probabilities: a Kernel Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random forest is a popular tool for estimating probabilities in machine\nlearning classification tasks. However, the means by which this is accomplished\nis unprincipled: one simply counts the fraction of trees in a forest that vote\nfor a certain class. In this paper, we forge a connection between random\nforests and kernel regression. This places random forest probability estimation\non more sound statistical footing. As part of our investigation, we develop a\nmodel for the proximity kernel and relate it to the geometry and sparsity of\nthe estimation problem. We also provide intuition and recommendations for\ntuning a random forest to improve its probability estimates.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 05:57:39 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Olson", "Matthew A.", ""], ["Wyner", "Abraham J.", ""]]}, {"id": "1812.05793", "submitter": "Jingyi Wang Ph.D.", "authors": "Jingyi Wang and Guoliang Dong and Jun Sun and Xinyu Wang and Peixin\n  Zhang", "title": "Adversarial Sample Detection for Deep Neural Network through Model\n  Mutation Testing", "comments": "Accepted by ICSE 2019", "journal-ref": null, "doi": "10.1109/ICSE.2019.00126", "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have been shown to be useful in a wide range of\napplications. However, they are also known to be vulnerable to adversarial\nsamples. By transforming a normal sample with some carefully crafted human\nimperceptible perturbations, even highly accurate DNN make wrong decisions.\nMultiple defense mechanisms have been proposed which aim to hinder the\ngeneration of such adversarial samples. However, a recent work show that most\nof them are ineffective. In this work, we propose an alternative approach to\ndetect adversarial samples at runtime. Our main observation is that adversarial\nsamples are much more sensitive than normal samples if we impose random\nmutations on the DNN. We thus first propose a measure of `sensitivity' and show\nempirically that normal samples and adversarial samples have distinguishable\nsensitivity. We then integrate statistical hypothesis testing and model\nmutation testing to check whether an input sample is likely to be normal or\nadversarial at runtime by measuring its sensitivity. We evaluated our approach\non the MNIST and CIFAR10 datasets. The results show that our approach detects\nadversarial samples generated by state-of-the-art attacking methods efficiently\nand accurately.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 06:04:04 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 08:20:58 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Wang", "Jingyi", ""], ["Dong", "Guoliang", ""], ["Sun", "Jun", ""], ["Wang", "Xinyu", ""], ["Zhang", "Peixin", ""]]}, {"id": "1812.05796", "submitter": "Masataka Yamaguchi", "authors": "Masataka Yamaguchi, Yuma Koizumi, Noboru Harada", "title": "AdaFlow: Domain-Adaptive Density Estimator with Application to Anomaly\n  Detection and Unpaired Cross-Domain Translation", "comments": "Accepted to ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle unsupervised anomaly detection (UAD), a problem of detecting data\nthat significantly differ from normal data. UAD is typically solved by using\ndensity estimation. Recently, deep neural network (DNN)-based density\nestimators, such as Normalizing Flows, have been attracting attention. However,\none of their drawbacks is the difficulty in adapting them to the change in the\nnormal data's distribution. To address this difficulty, we propose AdaFlow, a\nnew DNN-based density estimator that can be easily adapted to the change of the\ndistribution. AdaFlow is a unified model of a Normalizing Flow and Adaptive\nBatch-Normalizations, a module that enables DNNs to adapt to new distributions.\nAdaFlow can be adapted to a new distribution by just conducting forward\npropagation once per sample; hence, it can be used on devices that have limited\ncomputational resources. We have confirmed the effectiveness of the proposed\nmodel through an anomaly detection in a sound task. We also propose a method of\napplying AdaFlow to the unpaired cross-domain translation problem, in which one\nhas to train a cross-domain translation model with only unpaired samples. We\nhave confirmed that our model can be used for the cross-domain translation\nproblem through experiments on image datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 06:40:02 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 09:38:51 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Yamaguchi", "Masataka", ""], ["Koizumi", "Yuma", ""], ["Harada", "Noboru", ""]]}, {"id": "1812.05836", "submitter": "Martin Mundt", "authors": "Martin Mundt, Sagnik Majumder, Tobias Weis, Visvanathan Ramesh", "title": "Rethinking Layer-wise Feature Amounts in Convolutional Neural Network\n  Architectures", "comments": "Accepted at the Critiquing and Correcting Trends in Machine Learning\n  (CRACT) Workshop at the 32nd Conference on Neural Information Processing\n  Systems (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize convolutional neural networks with respect to the relative\namount of features per layer. Using a skew normal distribution as a\nparametrized framework, we investigate the common assumption of monotonously\nincreasing feature-counts with higher layers of architecture designs. Our\nevaluation on models with VGG-type layers on the MNIST, Fashion-MNIST and\nCIFAR-10 image classification benchmarks provides evidence that motivates\nrethinking of our common assumption: architectures that favor larger early\nlayers seem to yield better accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 09:28:05 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Mundt", "Martin", ""], ["Majumder", "Sagnik", ""], ["Weis", "Tobias", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "1812.05877", "submitter": "Bo Han", "authors": "Bo Han", "title": "DATELINE: Deep Plackett-Luce Model with Uncertainty Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aggregation of k-ary preferences is a historical and important problem,\nsince it has many real-world applications, such as peer grading, presidential\nelections and restaurant ranking. Meanwhile, variants of Plackett-Luce model\nhas been applied to aggregate k-ary preferences. However, there are two urgent\nissues still existing in the current variants. First, most of them ignore\nfeature information. Namely, they consider k-ary preferences instead of\ninstance-dependent k-ary preferences. Second, these variants barely consider\nthe uncertainty in k-ary preferences provided by agnostic crowds. In this\npaper, we propose Deep plAckeTt-luce modEL wIth uNcertainty mEasurements\n(DATELINE), which can address both issues simultaneously. To address the first\nissue, we employ deep neural networks mapping each instance into its ranking\nscore in Plackett-Luce model. Then, we present a weighted Plackett-Luce model\nto solve the second issue, where the weight is a dynamic uncertainty vector\nmeasuring the worker quality. More importantly, we provide theoretical\nguarantees for DATELINE to justify its robustness.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 12:14:55 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Han", "Bo", ""]]}, {"id": "1812.05905", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker,\n  Sehoon Ha, Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel\n  and Sergey Levine", "title": "Soft Actor-Critic Algorithms and Applications", "comments": "arXiv admin note: substantial text overlap with arXiv:1801.01290", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) algorithms have been successfully\napplied to a range of challenging sequential decision making and control tasks.\nHowever, these methods typically suffer from two major challenges: high sample\ncomplexity and brittleness to hyperparameters. Both of these challenges limit\nthe applicability of such methods to real-world domains. In this paper, we\ndescribe Soft Actor-Critic (SAC), our recently introduced off-policy\nactor-critic algorithm based on the maximum entropy RL framework. In this\nframework, the actor aims to simultaneously maximize expected return and\nentropy. That is, to succeed at the task while acting as randomly as possible.\nWe extend SAC to incorporate a number of modifications that accelerate training\nand improve stability with respect to the hyperparameters, including a\nconstrained formulation that automatically tunes the temperature\nhyperparameter. We systematically evaluate SAC on a range of benchmark tasks,\nas well as real-world challenging tasks such as locomotion for a quadrupedal\nrobot and robotic manipulation with a dexterous hand. With these improvements,\nSAC achieves state-of-the-art performance, outperforming prior on-policy and\noff-policy methods in sample-efficiency and asymptotic performance.\nFurthermore, we demonstrate that, in contrast to other off-policy algorithms,\nour approach is very stable, achieving similar performance across different\nrandom seeds. These results suggest that SAC is a promising candidate for\nlearning in real-world robotics tasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 04:44:29 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 12:10:47 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Zhou", "Aurick", ""], ["Hartikainen", "Kristian", ""], ["Tucker", "George", ""], ["Ha", "Sehoon", ""], ["Tan", "Jie", ""], ["Kumar", "Vikash", ""], ["Zhu", "Henry", ""], ["Gupta", "Abhishek", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1812.05916", "submitter": "Come Hure", "authors": "Achref Bachouch, C\\^ome Hur\\'e, Nicolas Langren\\'e, Huyen Pham", "title": "Deep neural networks algorithms for stochastic control problems on\n  finite horizon: numerical applications", "comments": "39 pages, 14 figures. Methodology and Computing in Applied\n  Probability, Springer Verlag, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents several numerical applications of deep learning-based\nalgorithms that have been introduced in [HPBL18]. Numerical and comparative\ntests using TensorFlow illustrate the performance of our different algorithms,\nnamely control learning by performance iteration (algorithms NNcontPI and\nClassifPI), control learning by hybrid iteration (algorithms Hybrid-Now and\nHybrid-LaterQ), on the 100-dimensional nonlinear PDEs examples from [EHJ17] and\non quadratic backward stochastic differential equations as in [CR16]. We also\nperformed tests on low-dimension control problems such as an option hedging\nproblem in finance, as well as energy storage problems arising in the valuation\nof gas storage and in microgrid management. Numerical results and comparisons\nto quantization-type algorithms Qknn, as an efficient algorithm to numerically\nsolve low-dimensional control problems, are also provided; and some\ncorresponding codes are available on https://github.com/comeh/.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 09:44:23 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 09:08:07 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 07:24:40 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bachouch", "Achref", ""], ["Hur\u00e9", "C\u00f4me", ""], ["Langren\u00e9", "Nicolas", ""], ["Pham", "Huyen", ""]]}, {"id": "1812.05929", "submitter": "Fay\\c{c}al Ait Aoudia", "authors": "Fay\\c{c}al Ait Aoudia and Jakob Hoydis", "title": "Model-free Training of End-to-end Communication Systems", "comments": "Accepted for publication in JSAC Special Issue on Machine Learning in\n  Wireless Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of end-to-end learning of communication systems through neural\nnetwork-based autoencoders has the shortcoming that it requires a\ndifferentiable channel model. We present in this paper a novel learning\nalgorithm which alleviates this problem. The algorithm enables training of\ncommunication systems with an unknown channel model or with non-differentiable\ncomponents. It iterates between training of the receiver using the true\ngradient, and training of the transmitter using an approximation of the\ngradient. We show that this approach works as well as model-based training for\na variety of channels and tasks. Moreover, we demonstrate the algorithm's\npractical viability through hardware implementation on software-defined radios\nwhere it achieves state-of-the-art performance over a coaxial cable and\nwireless channel.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 13:46:24 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 12:08:48 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 14:46:37 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Aoudia", "Fay\u00e7al Ait", ""], ["Hoydis", "Jakob", ""]]}, {"id": "1812.05941", "submitter": "David Zimmerer", "authors": "David Zimmerer, Simon A. A. Kohl, Jens Petersen, Fabian Isensee, Klaus\n  H. Maier-Hein", "title": "Context-encoding Variational Autoencoder for Unsupervised Anomaly\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning can leverage large-scale data sources without the need\nfor annotations. In this context, deep learning-based auto encoders have shown\ngreat potential in detecting anomalies in medical images. However,\nstate-of-the-art anomaly scores are still based on the reconstruction error,\nwhich lacks in two essential parts: it ignores the model-internal\nrepresentation employed for reconstruction, and it lacks formal assertions and\ncomparability between samples. We address these shortcomings by proposing the\nContext-encoding Variational Autoencoder (ceVAE) which combines reconstruction-\nwith density-based anomaly scoring. This improves the sample- as well as\npixel-wise results. In our experiments on the BraTS-2017 and ISLES-2015\nsegmentation benchmarks, the ceVAE achieves unsupervised ROC-AUCs of 0.95 and\n0.89, respectively, thus outperforming state-of-the-art methods by a\nconsiderable margin.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 14:06:05 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Zimmerer", "David", ""], ["Kohl", "Simon A. A.", ""], ["Petersen", "Jens", ""], ["Isensee", "Fabian", ""], ["Maier-Hein", "Klaus H.", ""]]}, {"id": "1812.05944", "submitter": "Juan Luis Su\\'arez D\\'iaz", "authors": "Juan Luis Su\\'arez-D\\'iaz, Salvador Garc\\'ia, Francisco Herrera", "title": "A Tutorial on Distance Metric Learning: Mathematical Foundations,\n  Algorithms, Experimental Analysis, Prospects and Challenges (with Appendices\n  on Mathematical Background and Detailed Algorithms Explanation)", "comments": "36 pages with appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning is a branch of machine learning that aims to learn\ndistances from the data, which enhances the performance of similarity-based\nalgorithms. This tutorial provides a theoretical background and foundations on\nthis topic and a comprehensive experimental analysis of the most-known\nalgorithms. We start by describing the distance metric learning problem and its\nmain mathematical foundations, divided into three main blocks: convex analysis,\nmatrix analysis and information theory. Then, we will describe a representative\nset of the most popular distance metric learning methods used in\nclassification. All the algorithms studied in this paper will be evaluated with\nexhaustive testing in order to analyze their capabilities in standard\nclassification problems, particularly considering dimensionality reduction and\nkernelization. The results, verified by Bayesian statistical tests, highlight a\nset of outstanding algorithms. Finally, we will discuss several potential\nfuture prospects and challenges in this field. This tutorial will serve as a\nstarting point in the domain of distance metric learning from both a\ntheoretical and practical perspective.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 14:07:36 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 14:42:23 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 13:53:32 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Su\u00e1rez-D\u00edaz", "Juan Luis", ""], ["Garc\u00eda", "Salvador", ""], ["Herrera", "Francisco", ""]]}, {"id": "1812.05980", "submitter": "Alexandros Iosifidis", "authors": "Alexandros Iosifidis", "title": "Probabilistic Class-Specific Discriminant Analysis", "comments": "14 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we formulate a probabilistic model for class-specific\ndiscriminant subspace learning. The proposed model can naturally incorporate\nthe multi-modal structure of the negative class, which is neglected by existing\nclass-specific methods. Moreover, it can be directly used to define a\nclass-specific probabilistic classification rule in the discriminant subspace.\nWe show that existing class-specific discriminant analysis methods are special\ncases of the proposed probabilistic model and, by casting them as probabilistic\nmodels, they can be extended to class-specific classifiers. We illustrate the\nperformance of the proposed model in both verification and classification\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 15:30:22 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 15:42:58 GMT"}, {"version": "v3", "created": "Sat, 11 May 2019 05:48:11 GMT"}, {"version": "v4", "created": "Sat, 16 Nov 2019 07:12:52 GMT"}, {"version": "v5", "created": "Mon, 5 Oct 2020 05:50:24 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Iosifidis", "Alexandros", ""]]}, {"id": "1812.05981", "submitter": "Scott C. Douglas", "authors": "Scott C. Douglas and Jiutian Yu", "title": "Why ReLU Units Sometimes Die: Analysis of Single-Unit Error\n  Backpropagation in Neural Networks", "comments": "5 pages, 7 figures, Proc. 52nd Asilomar Conference on Signals,\n  Systems, and Computers, Pacific Grove, CA, October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks in machine learning use rectified linear units\n(ReLUs) in early processing layers for better performance. Training these\nstructures sometimes results in \"dying ReLU units\" with near-zero outputs. We\nfirst explore this condition via simulation using the CIFAR-10 dataset and\nvariants of two popular convolutive neural network architectures. Our\nexplorations show that the output activation probability Pr[y>0] is generally\nless than 0.5 at system convergence for layers that do not employ skip\nconnections, and this activation probability tends to decrease as one\nprogresses from input layer to output layer. Employing a simplified model of a\nsingle ReLU unit trained by a variant of error backpropagation, we then perform\na statistical convergence analysis to explore the model's evolutionary\nbehavior. Our analysis describes the potentially-slower convergence speeds of\ndying ReLU units, and this issue can occur regardless of how the weights are\ninitialized.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 15:33:45 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Douglas", "Scott C.", ""], ["Yu", "Jiutian", ""]]}, {"id": "1812.05988", "submitter": "Alexandros Iosifidis", "authors": "Alexandros Iosifidis", "title": "Class Mean Vector Component and Discriminant Analysis", "comments": "8 pages, 2 figures, 2 tables", "journal-ref": "Pattern Recognition Letters, 2020", "doi": "10.1016/j.patrec.2020.10.014", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel matrix used in kernel methods encodes all the information required\nfor solving complex nonlinear problems defined on data representations in the\ninput space using simple, but implicitly defined, solutions. Spectral analysis\non the kernel matrix defines an explicit nonlinear mapping of the input data\nrepresentations to a subspace of the kernel space, which can be used for\ndirectly applying linear methods. However, the selection of the kernel subspace\nis crucial for the performance of the proceeding processing steps. In this\npaper, we propose a component analysis method for kernel-based dimensionality\nreduction that optimally preserves the pair-wise distances of the class means\nin the feature space. We provide extensive analysis on the connection of the\nproposed criterion to those used in kernel principal component analysis and\nkernel discriminant analysis, leading to a discriminant analysis version of the\nproposed method. Our analysis also provides more insights on the properties of\nthe feature spaces obtained by applying these methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 15:43:23 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 21:18:08 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 11:07:23 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Iosifidis", "Alexandros", ""]]}, {"id": "1812.05994", "submitter": "Boris Hanin", "authors": "Boris Hanin, Mihai Nica", "title": "Products of Many Large Random Matrices and Gradients in Deep Neural\n  Networks", "comments": "v1. 26p. Comments Welcome", "journal-ref": null, "doi": "10.1007/s00220-019-03624-z", "report-no": null, "categories": "math.PR math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study products of random matrices in the regime where the number of terms\nand the size of the matrices simultaneously tend to infinity. Our main theorem\nis that the logarithm of the $\\ell_2$ norm of such a product applied to any\nfixed vector is asymptotically Gaussian. The fluctuations we find can be\nthought of as a finite temperature correction to the limit in which first the\nsize and then the number of matrices tend to infinity. Depending on the scaling\nlimit considered, the mean and variance of the limiting Gaussian depend only on\neither the first two or the first four moments of the measure from which matrix\nentries are drawn. We also obtain explicit error bounds on the moments of the\nnorm and the Kolmogorov-Smirnov distance to a Gaussian. Finally, we apply our\nresult to obtain precise information about the stability of gradients in\nrandomly initialized deep neural networks with ReLU activations. This provides\na quantitative measure of the extent to which the exploding and vanishing\ngradient problem occurs in a fully connected neural network with ReLU\nactivations and a given architecture.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 15:59:34 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Hanin", "Boris", ""], ["Nica", "Mihai", ""]]}, {"id": "1812.06003", "submitter": "Ming Zhong", "authors": "Fei Lu, Mauro Maggioni, Sui Tang, Ming Zhong", "title": "Nonparametric inference of interaction laws in systems of agents from\n  trajectory data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the laws of interaction between particles and agents in complex\ndynamical systems from observational data is a fundamental challenge in a wide\nvariety of disciplines. We propose a non-parametric statistical learning\napproach to estimate the governing laws of distance-based interactions, with no\nreference or assumption about their analytical form, from data consisting\ntrajectories of interacting agents. We demonstrate the effectiveness of our\nlearning approach both by providing theoretical guarantees, and by testing the\napproach on a variety of prototypical systems in various disciplines. These\nsystems include homogeneous and heterogeneous agents systems, ranging from\nparticle systems in fundamental physics to agent-based systems modeling opinion\ndynamics under the social influence, prey-predator dynamics, flocking and\nswarming, and phototaxis in cell dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 16:15:36 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 12:22:08 GMT"}, {"version": "v3", "created": "Mon, 31 Dec 2018 18:13:38 GMT"}, {"version": "v4", "created": "Sat, 23 Mar 2019 18:18:39 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Lu", "Fei", ""], ["Maggioni", "Mauro", ""], ["Tang", "Sui", ""], ["Zhong", "Ming", ""]]}, {"id": "1812.06055", "submitter": "Kelli Humbird", "authors": "K. D. Humbird, J. L. Peterson, R. G. McClarren", "title": "Transfer learning to model inertial confinement fusion experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inertial confinement fusion (ICF) experiments are designed using computer\nsimulations that are approximations of reality, and therefore must be\ncalibrated to accurately predict experimental observations. In this work, we\npropose a novel nonlinear technique for calibrating from simulations to\nexperiments, or from low fidelity simulations to high fidelity simulations, via\n\"transfer learning\". Transfer learning is a commonly used technique in the\nmachine learning community, in which models trained on one task are partially\nretrained to solve a separate, but related task, for which there is a limited\nquantity of data. We introduce the idea of hierarchical transfer learning, in\nwhich neural networks trained on low fidelity models are calibrated to high\nfidelity models, then to experimental data. This technique essentially\nbootstraps the calibration process, enabling the creation of models which\npredict high fidelity simulations or experiments with minimal computational\ncost. We apply this technique to a database of ICF simulations and experiments\ncarried out at the Omega laser facility. Transfer learning with deep neural\nnetworks enables the creation of models that are more predictive of Omega\nexperiments than simulations alone. The calibrated models accurately predict\nfuture Omega experiments, and are used to search for new, optimal implosion\ndesigns.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 18:02:42 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Humbird", "K. D.", ""], ["Peterson", "J. L.", ""], ["McClarren", "R. G.", ""]]}, {"id": "1812.06067", "submitter": "Alessandro Davide Ialongo", "authors": "Alessandro Davide Ialongo, Mark van der Wilk, James Hensman, Carl\n  Edward Rasmussen", "title": "Non-Factorised Variational Inference in Dynamical Systems", "comments": "6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on variational inference in dynamical systems where the discrete\ntime transition function (or evolution rule) is modelled by a Gaussian process.\nThe dominant approach so far has been to use a factorised posterior\ndistribution, decoupling the transition function from the system states. This\nis not exact in general and can lead to an overconfident posterior over the\ntransition function as well as an overestimation of the intrinsic stochasticity\nof the system (process noise). We propose a new method that addresses these\nissues and incurs no additional computational costs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 18:32:10 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Ialongo", "Alessandro Davide", ""], ["van der Wilk", "Mark", ""], ["Hensman", "James", ""], ["Rasmussen", "Carl Edward", ""]]}, {"id": "1812.06080", "submitter": "Erin Grant", "authors": "Ghassen Jerfel, Erin Grant, Thomas L. Griffiths, Katherine Heller", "title": "Reconciling meta-learning and continual learning with online mixtures of\n  tasks", "comments": "updated experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-to-learn or meta-learning leverages data-driven inductive bias to\nincrease the efficiency of learning on a novel task. This approach encounters\ndifficulty when transfer is not advantageous, for instance, when tasks are\nconsiderably dissimilar or change over time. We use the connection between\ngradient-based meta-learning and hierarchical Bayes to propose a Dirichlet\nprocess mixture of hierarchical Bayesian models over the parameters of an\narbitrary parametric model such as a neural network. In contrast to\nconsolidating inductive biases into a single set of hyperparameters, our\napproach of task-dependent hyperparameter selection better handles latent\ndistribution shift, as demonstrated on a set of evolving, image-based, few-shot\nlearning benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 18:59:03 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 18:24:39 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 17:53:49 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Jerfel", "Ghassen", ""], ["Grant", "Erin", ""], ["Griffiths", "Thomas L.", ""], ["Heller", "Katherine", ""]]}, {"id": "1812.06083", "submitter": "Jihwan Lee", "authors": "JIhwan Lee, Dongchan Kim, Ruhi Sarikaya, Young-Bum Kim", "title": "Coupled Representation Learning for Domains, Intents and Slots in Spoken\n  Language Understanding", "comments": "IEEE SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is an essential problem in a wide range of\napplications and it is important for performing downstream tasks successfully.\nIn this paper, we propose a new model that learns coupled representations of\ndomains, intents, and slots by taking advantage of their hierarchical\ndependency in a Spoken Language Understanding system. Our proposed model learns\nthe vector representation of intents based on the slots tied to these intents\nby aggregating the representations of the slots. Similarly, the vector\nrepresentation of a domain is learned by aggregating the representations of the\nintents tied to a specific domain. To the best of our knowledge, it is the\nfirst approach to jointly learning the representations of domains, intents, and\nslots using their hierarchical relationships. The experimental results\ndemonstrate the effectiveness of the representations learned by our model, as\nevidenced by improved performance on the contextual cross-domain reranking\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 22:23:51 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Lee", "JIhwan", ""], ["Kim", "Dongchan", ""], ["Sarikaya", "Ruhi", ""], ["Kim", "Young-Bum", ""]]}, {"id": "1812.06087", "submitter": "Michael Michelashvili", "authors": "Michael Michelashvili, Sagie Benaim, Lior Wolf", "title": "Semi-Supervised Monaural Singing Voice Separation With a Masking Network\n  Trained on Synthetic Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of semi-supervised singing voice separation, in which\nthe training data contains a set of samples of mixed music (singing and\ninstrumental) and an unmatched set of instrumental music. Our solution employs\na single mapping function g, which, applied to a mixed sample, recovers the\nunderlying instrumental music, and, applied to an instrumental sample, returns\nthe same sample. The network g is trained using purely instrumental samples, as\nwell as on synthetic mixed samples that are created by mixing reconstructed\nsinging voices with random instrumental samples. Our results indicate that we\nare on a par with or better than fully supervised methods, which are also\nprovided with training samples of unmixed singing voices, and are better than\nother recent semi-supervised methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 08:17:24 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 15:22:36 GMT"}, {"version": "v3", "created": "Mon, 6 May 2019 14:12:23 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Michelashvili", "Michael", ""], ["Benaim", "Sagie", ""], ["Wolf", "Lior", ""]]}, {"id": "1812.06127", "submitter": "Tian Li", "authors": "Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet\n  Talwalkar, Virginia Smith", "title": "Federated Optimization in Heterogeneous Networks", "comments": "MLSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a distributed learning paradigm with two key challenges\nthat differentiate it from traditional distributed optimization: (1)\nsignificant variability in terms of the systems characteristics on each device\nin the network (systems heterogeneity), and (2) non-identically distributed\ndata across the network (statistical heterogeneity). In this work, we introduce\na framework, FedProx, to tackle heterogeneity in federated networks. FedProx\ncan be viewed as a generalization and re-parametrization of FedAvg, the current\nstate-of-the-art method for federated learning. While this re-parameterization\nmakes only minor modifications to the method itself, these modifications have\nimportant ramifications both in theory and in practice. Theoretically, we\nprovide convergence guarantees for our framework when learning over data from\nnon-identical distributions (statistical heterogeneity), and while adhering to\ndevice-level systems constraints by allowing each participating device to\nperform a variable amount of work (systems heterogeneity). Practically, we\ndemonstrate that FedProx allows for more robust convergence than FedAvg across\na suite of realistic federated datasets. In particular, in highly heterogeneous\nsettings, FedProx demonstrates significantly more stable and accurate\nconvergence behavior relative to FedAvg---improving absolute test accuracy by\n22% on average.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 19:28:29 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 19:54:02 GMT"}, {"version": "v3", "created": "Thu, 11 Jul 2019 20:25:17 GMT"}, {"version": "v4", "created": "Sun, 22 Sep 2019 19:44:37 GMT"}, {"version": "v5", "created": "Tue, 21 Apr 2020 18:58:23 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Li", "Tian", ""], ["Sahu", "Anit Kumar", ""], ["Zaheer", "Manzil", ""], ["Sanjabi", "Maziar", ""], ["Talwalkar", "Ameet", ""], ["Smith", "Virginia", ""]]}, {"id": "1812.06135", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Pranay K. Lohia, Karthikeyan Natesan Ramamurthy, Manish Bhide,\n  Diptikalyan Saha, Kush R. Varshney, Ruchir Puri", "title": "Bias Mitigation Post-processing for Individual and Group Fairness", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas previous post-processing approaches for increasing the fairness of\npredictions of biased classifiers address only group fairness, we propose a\nmethod for increasing both individual and group fairness. Our novel framework\nincludes an individual bias detector used to prioritize data samples in a bias\nmitigation algorithm aiming to improve the group fairness measure of disparate\nimpact. We show superior performance to previous work in the combination of\nclassification accuracy, individual fairness and group fairness on several\nreal-world datasets in applications such as credit, employment, and criminal\njustice.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 19:41:25 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Lohia", "Pranay K.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Bhide", "Manish", ""], ["Saha", "Diptikalyan", ""], ["Varshney", "Kush R.", ""], ["Puri", "Ruchir", ""]]}, {"id": "1812.06145", "submitter": "Mahdi Abavisani", "authors": "Mahdi Abavisani, Hamid Reza Vaezi Joze, Vishal M. Patel", "title": "Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition\n  with Multimodal Training", "comments": null, "journal-ref": "The IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR), 2019, pp. 1165-1174", "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an efficient approach for leveraging the knowledge from multiple\nmodalities in training unimodal 3D convolutional neural networks (3D-CNNs) for\nthe task of dynamic hand gesture recognition. Instead of explicitly combining\nmultimodal information, which is commonplace in many state-of-the-art methods,\nwe propose a different framework in which we embed the knowledge of multiple\nmodalities in individual networks so that each unimodal network can achieve an\nimproved performance. In particular, we dedicate separate networks per\navailable modality and enforce them to collaborate and learn to develop\nnetworks with common semantics and better representations. We introduce a\n\"spatiotemporal semantic alignment\" loss (SSA) to align the content of the\nfeatures from different networks. In addition, we regularize this loss with our\nproposed \"focal regularization parameter\" to avoid negative knowledge transfer.\nExperimental results show that our framework improves the test time recognition\naccuracy of unimodal networks, and provides the state-of-the-art performance on\nvarious dynamic hand gesture recognition datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 20:08:24 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 09:51:14 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Abavisani", "Mahdi", ""], ["Joze", "Hamid Reza Vaezi", ""], ["Patel", "Vishal M.", ""]]}, {"id": "1812.06158", "submitter": "Maksim Kretov", "authors": "Alexander Fritzler and Varvara Logacheva and Maksim Kretov", "title": "Few-shot classification in Named Entity Recognition Task", "comments": "In proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing", "journal-ref": null, "doi": "10.1145/3297280.3297378", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many natural language processing (NLP) tasks the amount of annotated data\nis limited. This urges a need to apply semi-supervised learning techniques,\nsuch as transfer learning or meta-learning. In this work we tackle Named Entity\nRecognition (NER) task using Prototypical Network - a metric learning\ntechnique. It learns intermediate representations of words which cluster well\ninto named entity classes. This property of the model allows classifying words\nwith extremely limited number of training examples, and can potentially be used\nas a zero-shot learning method. By coupling this technique with transfer\nlearning we achieve well-performing classifiers trained on only 20 instances of\na target class.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 20:39:47 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Fritzler", "Alexander", ""], ["Logacheva", "Varvara", ""], ["Kretov", "Maksim", ""]]}, {"id": "1812.06162", "submitter": "Samuel McCandlish", "authors": "Sam McCandlish, Jared Kaplan, Dario Amodei, OpenAI Dota Team", "title": "An Empirical Model of Large-Batch Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an increasing number of domains it has been demonstrated that deep\nlearning models can be trained using relatively large batch sizes without\nsacrificing data efficiency. However the limits of this massive data\nparallelism seem to differ from domain to domain, ranging from batches of tens\nof thousands in ImageNet to batches of millions in RL agents that play the game\nDota 2. To our knowledge there is limited conceptual understanding of why these\nlimits to batch size differ or how we might choose the correct batch size in a\nnew domain. In this paper, we demonstrate that a simple and easy-to-measure\nstatistic called the gradient noise scale predicts the largest useful batch\nsize across many domains and applications, including a number of supervised\nlearning datasets (MNIST, SVHN, CIFAR-10, ImageNet, Billion Word),\nreinforcement learning domains (Atari and Dota), and even generative model\ntraining (autoencoders on SVHN). We find that the noise scale increases as the\nloss decreases over a training run and depends on the model size primarily\nthrough improved model performance. Our empirically-motivated theory also\ndescribes the tradeoff between compute-efficiency and time-efficiency, and\nprovides a rough model of the benefits of adaptive batch-size training.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 20:49:09 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["McCandlish", "Sam", ""], ["Kaplan", "Jared", ""], ["Amodei", "Dario", ""], ["Team", "OpenAI Dota", ""]]}, {"id": "1812.06181", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li and Nicha C. Dvornek and Yuan Zhou and Juntang Zhuang and\n  Pamela Ventola and James S. Duncan", "title": "Efficient Interpretation of Deep Learning Models Using Graph Structure\n  and Cooperative Game Theory: Application to ASD Biomarker Discovery", "comments": "12 pages, 7 figures, accpeted as a full paper in IPMI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering imaging biomarkers for autism spectrum disorder (ASD) is critical\nto help explain ASD and predict or monitor treatment outcomes. Toward this end,\ndeep learning classifiers have recently been used for identifying ASD from\nfunctional magnetic resonance imaging (fMRI) with higher accuracy than\ntraditional learning strategies. However, a key challenge with deep learning\nmodels is understanding just what image features the network is using, which\ncan in turn be used to define the biomarkers. Current methods extract\nbiomarkers, i.e., important features, by looking at how the prediction changes\nif \"ignoring\" one feature at a time. In this work, we go beyond looking at only\nindividual features by using Shapley value explanation (SVE) from cooperative\ngame theory. Cooperative game theory is advantageous here because it directly\nconsiders the interaction between features and can be applied to any machine\nlearning method, making it a novel, more accurate way of determining\ninstance-wise biomarker importance from deep learning models. A barrier to\nusing SVE is its computational complexity: $2^N$ given $N$ features. We\nexplicitly reduce the complexity of SVE computation by two approaches based on\nthe underlying graph structure of the input data: 1) only consider the\ncentralized coalition of each feature; 2) a hierarchical pipeline which first\nclusters features into small communities, then applies SVE in each community.\nMonte Carlo approximation can be used for large permutation sets. We first\nvalidate our methods on the MNIST dataset and compare to human perception.\nNext, to insure plausibility of our biomarker results, we train a Random Forest\n(RF) to classify ASD/control subjects from fMRI and compare SVE results to\nstandard RF-based feature importance. Finally, we show initial results on\nranked fMRI biomarkers using SVE on a deep learning classifier for the\nASD/control dataset.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 21:50:02 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 18:38:11 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Dvornek", "Nicha C.", ""], ["Zhou", "Yuan", ""], ["Zhuang", "Juntang", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "1812.06190", "submitter": "Jack Klys", "authors": "Jack Klys, Jake Snell, Richard Zemel", "title": "Learning Latent Subspaces in Variational Autoencoders", "comments": "Published as a conference paper at NeurIPS 2018. 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) are widely used deep generative models\ncapable of learning unsupervised latent representations of data. Such\nrepresentations are often difficult to interpret or control. We consider the\nproblem of unsupervised learning of features correlated to specific labels in a\ndataset. We propose a VAE-based generative model which we show is capable of\nextracting features correlated to binary labels in the data and structuring it\nin a latent subspace which is easy to interpret. Our model, the Conditional\nSubspace VAE (CSVAE), uses mutual information minimization to learn a\nlow-dimensional latent subspace associated with each label that can easily be\ninspected and independently manipulated. We demonstrate the utility of the\nlearned representations for attribute manipulation tasks on both the Toronto\nFace and CelebA datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 22:10:50 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Klys", "Jack", ""], ["Snell", "Jake", ""], ["Zemel", "Richard", ""]]}, {"id": "1812.06199", "submitter": "Enrique Noriega-Atala", "authors": "Enrique Noriega-Atala, Paul D. Hein, Shraddha S. Thumsi, Zechy Wong,\n  Xia Wang and Clayton T. Morrison", "title": "Inter-sentence Relation Extraction for Associating Biological Context\n  with Events in Biomedical Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis of the problem of identifying biological context and\nassociating it with biochemical events in biomedical texts. This constitutes a\nnon-trivial, inter-sentential relation extraction task. We focus on biological\ncontext as descriptions of the species, tissue type and cell type that are\nassociated with biochemical events. We describe the properties of an annotated\ncorpus of context-event relations and present and evaluate several classifiers\nfor context-event association trained on syntactic, distance and frequency\nfeatures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 23:03:41 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Noriega-Atala", "Enrique", ""], ["Hein", "Paul D.", ""], ["Thumsi", "Shraddha S.", ""], ["Wong", "Zechy", ""], ["Wang", "Xia", ""], ["Morrison", "Clayton T.", ""]]}, {"id": "1812.06210", "submitter": "Galen Andrew", "authors": "H. Brendan McMahan, Galen Andrew, Ulfar Erlingsson, Steve Chien, Ilya\n  Mironov, Nicolas Papernot and Peter Kairouz", "title": "A General Approach to Adding Differential Privacy to Iterative Training\n  Procedures", "comments": "Presented at NeurIPS 2018 workshop on Privacy Preserving Machine\n  Learning; Companion paper to TensorFlow Privacy OSS Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we address the practical challenges of training machine learning\nmodels on privacy-sensitive datasets by introducing a modular approach that\nminimizes changes to training algorithms, provides a variety of configuration\nstrategies for the privacy mechanism, and then isolates and simplifies the\ncritical logic that computes the final privacy guarantees. A key challenge is\nthat training algorithms often require estimating many different quantities\n(vectors) from the same set of examples --- for example, gradients of different\nlayers in a deep learning architecture, as well as metrics and batch\nnormalization parameters. Each of these may have different properties like\ndimensionality, magnitude, and tolerance to noise. By extending previous work\non the Moments Accountant for the subsampled Gaussian mechanism, we can provide\nprivacy for such heterogeneous sets of vectors, while also structuring the\napproach to minimize software engineering challenges.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 00:32:09 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 18:32:17 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["McMahan", "H. Brendan", ""], ["Andrew", "Galen", ""], ["Erlingsson", "Ulfar", ""], ["Chien", "Steve", ""], ["Mironov", "Ilya", ""], ["Papernot", "Nicolas", ""], ["Kairouz", "Peter", ""]]}, {"id": "1812.06227", "submitter": "Maria Dimakopoulou", "authors": "Maria Dimakopoulou, Zhengyuan Zhou, Susan Athey, Guido Imbens", "title": "Balanced Linear Contextual Bandits", "comments": "AAAI 2019 Oral Presentation. arXiv admin note: substantial text\n  overlap with arXiv:1711.07077", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are sensitive to the estimation method of the\noutcome model as well as the exploration method used, particularly in the\npresence of rich heterogeneity or complex outcome models, which can lead to\ndifficult estimation problems along the path of learning. We develop algorithms\nfor contextual bandits with linear payoffs that integrate balancing methods\nfrom the causal inference literature in their estimation to make it less prone\nto problems of estimation bias. We provide the first regret bound analyses for\nlinear contextual bandits with balancing and show that our algorithms match the\nstate of the art theoretical guarantees. We demonstrate the strong practical\nadvantage of balanced contextual bandits on a large number of supervised\nlearning datasets and on a synthetic example that simulates model\nmisspecification and prejudice in the initial training data.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 03:06:51 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Dimakopoulou", "Maria", ""], ["Zhou", "Zhengyuan", ""], ["Athey", "Susan", ""], ["Imbens", "Guido", ""]]}, {"id": "1812.06229", "submitter": "Linh Nguyen", "authors": "Linh Nguyen and Tsukasa Ishigaki", "title": "Domain-to-Domain Translation Model for Recommender System", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently multi-domain recommender systems have received much attention from\nresearchers because they can solve cold-start problem as well as support for\ncross-selling. However, when applying into multi-domain items, although\nalgorithms specifically addressing a single domain have many difficulties in\ncapturing the specific characteristics of each domain, multi-domain algorithms\nhave less opportunity to obtain similar features among domains. Because both\nsimilarities and differences exist among domains, multi-domain models must\ncapture both to achieve good performance. Other studies of multi-domain systems\nmerely transfer knowledge from the source domain to the target domain, so the\nsource domain usually comes from external factors such as the search query or\nsocial network, which is sometimes impossible to obtain. To handle the two\nproblems, we propose a model that can extract both homogeneous and divergent\nfeatures among domains and extract data in a domain can support for other\ndomain equally: a so-called Domain-to-Domain Translation Model (D2D-TM). It is\nbased on generative adversarial networks (GANs), Variational Autoencoders\n(VAEs), and Cycle-Consistency (CC) for weight-sharing. We use the user\ninteraction history of each domain as input and extract latent features through\na VAE-GAN-CC network. Experiments underscore the effectiveness of the proposed\nsystem over state-of-the-art methods by a large margin.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 03:42:27 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Nguyen", "Linh", ""], ["Ishigaki", "Tsukasa", ""]]}, {"id": "1812.06243", "submitter": "Zhao Song", "authors": "Yin Tat Lee, Zhao Song, Santosh S. Vempala", "title": "Algorithmic Theory of ODEs and Sampling from Well-conditioned Logconcave\n  Densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sampling logconcave functions arising in statistics and machine learning has\nbeen a subject of intensive study. Recent developments include analyses for\nLangevin dynamics and Hamiltonian Monte Carlo (HMC). While both approaches have\ndimension-independent bounds for the underlying $\\mathit{continuous}$ processes\nunder sufficiently strong smoothness conditions, the resulting discrete\nalgorithms have complexity and number of function evaluations growing with the\ndimension. Motivated by this problem, in this paper, we give a general\nalgorithm for solving multivariate ordinary differential equations whose\nsolution is close to the span of a known basis of functions (e.g., polynomials\nor piecewise polynomials). The resulting algorithm has polylogarithmic depth\nand essentially tight runtime - it is nearly linear in the size of the\nrepresentation of the solution.\n  We apply this to the sampling problem to obtain a nearly linear\nimplementation of HMC for a broad class of smooth, strongly logconcave\ndensities, with the number of iterations (parallel depth) and gradient\nevaluations being $\\mathit{polylogarithmic}$ in the dimension (rather than\npolynomial as in previous work). This class includes the widely-used loss\nfunction for logistic regression with incoherent weight matrices and has been\nsubject of much study recently. We also give a faster algorithm with $\n\\mathit{polylogarithmic~depth}$ for the more general and standard class of\nstrongly convex functions with Lipschitz gradient. These results are based on\n(1) an improved contraction bound for the exact HMC process and (2) logarithmic\nbounds on the degree of polynomials that approximate solutions of the\ndifferential equations arising in implementing HMC.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 06:46:03 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Lee", "Yin Tat", ""], ["Song", "Zhao", ""], ["Vempala", "Santosh S.", ""]]}, {"id": "1812.06247", "submitter": "Hock Hung Chieng", "authors": "Hock Hung Chieng, Noorhaniza Wahid, Pauline Ong and Sai Raj Kishore\n  Perla", "title": "Flatten-T Swish: a thresholded ReLU-Swish-like activation function for\n  deep learning", "comments": null, "journal-ref": "International Journal of Advances in Intelligent Informatics,\n  4(2), 76-86", "doi": "10.26555/ijain.v4i2.249", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Activation functions are essential for deep learning methods to learn and\nperform complex tasks such as image classification. Rectified Linear Unit\n(ReLU) has been widely used and become the default activation function across\nthe deep learning community since 2012. Although ReLU has been popular,\nhowever, the hard zero property of the ReLU has heavily hindered the negative\nvalues from propagating through the network. Consequently, the deep neural\nnetwork has not been benefited from the negative representations. In this work,\nan activation function called Flatten-T Swish (FTS) that leverage the benefit\nof the negative values is proposed. To verify its performance, this study\nevaluates FTS with ReLU and several recent activation functions. Each\nactivation function is trained using MNIST dataset on five different deep fully\nconnected neural networks (DFNNs) with depth vary from five to eight layers.\nFor a fair evaluation, all DFNNs are using the same configuration settings.\nBased on the experimental results, FTS with a threshold value, T=-0.20 has the\nbest overall performance. As compared with ReLU, FTS (T=-0.20) improves MNIST\nclassification accuracy by 0.13%, 0.70%, 0.67%, 1.07% and 1.15% on wider 5\nlayers, slimmer 5 layers, 6 layers, 7 layers and 8 layers DFNNs respectively.\nApart from this, the study also noticed that FTS converges twice as fast as\nReLU. Although there are other existing activation functions are also\nevaluated, this study elects ReLU as the baseline activation function.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 07:02:44 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Chieng", "Hock Hung", ""], ["Wahid", "Noorhaniza", ""], ["Ong", "Pauline", ""], ["Perla", "Sai Raj Kishore", ""]]}, {"id": "1812.06303", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Xianfeng Tan", "title": "Multi-Tasking Genetic Algorithm (MTGA) for Fuzzy System Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning uses auxiliary data or knowledge from relevant tasks to\nfacilitate the learning in a new task. Multi-task optimization applies\nmulti-task learning to optimization to study how to effectively and efficiently\ntackle multiple optimization problems simultaneously. Evolutionary\nmulti-tasking, or multi-factorial optimization, is an emerging subfield of\nmulti-task optimization, which integrates evolutionary computation and\nmulti-task learning. This paper proposes a novel and easy-to-implement\nmulti-tasking genetic algorithm (MTGA), which copes well with significantly\ndifferent optimization tasks by estimating and using the bias among them.\nComparative studies with eight state-of-the-art single- and multi-task\napproaches in the literature on nine benchmarks demonstrated that on average\nthe MTGA outperformed all of them, and had lower computational cost than six of\nthem. Based on the MTGA, a simultaneous optimization strategy for fuzzy system\ndesign is also proposed. Experiments on simultaneous optimization of type-1 and\ninterval type-2 fuzzy logic controllers for couple-tank water level control\ndemonstrated that the MTGA can find better fuzzy logic controllers than other\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 15:07:55 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 11:30:15 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Wu", "Dongrui", ""], ["Tan", "Xianfeng", ""]]}, {"id": "1812.06307", "submitter": "Aleksandar Vakanski", "authors": "L. Li, A. Vakanski (University of Idaho, USA)", "title": "Generative adversarial networks for generation and classification of\n  physical rehabilitation movement episodes", "comments": "11 pages, 6 figures", "journal-ref": "Int. J. Machine Learning Computing 8 (2018) 428-436", "doi": "10.18178/ijmlc.2018.8.5.724", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article proposes a method for mathematical modeling of human movements\nrelated to patient exercise episodes performed during physical therapy sessions\nby using artificial neural networks. The generative adversarial network\nstructure is adopted, whereby a discriminative and a generative model are\ntrained concurrently in an adversarial manner. Different network architectures\nare examined, with the discriminative and generative models structured as deep\nsubnetworks of hidden layers comprised of convolutional or recurrent\ncomputational units. The models are validated on a data set of human movements\nrecorded with an optical motion tracker. The results demonstrate an ability of\nthe networks for classification of new instances of motions, and for generation\nof motion examples that resemble the recorded motion sequences.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 15:24:38 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Li", "L.", "", "University of Idaho, USA"], ["Vakanski", "A.", "", "University of Idaho, USA"]]}, {"id": "1812.06309", "submitter": "Bruno Sudret", "authors": "C. Lataniotis, S. Marelli and B. Sudret", "title": "Extending classical surrogate modelling to high-dimensions through\n  supervised dimensionality reduction: a data-driven approach", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": "RSUQ-2018-008B", "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to their versatility, ease of deployment and high-performance,\nsurrogate models have become staple tools in the arsenal of uncertainty\nquantification (UQ). From local interpolants to global spectral decompositions,\nsurrogates are characterised by their ability to efficiently emulate complex\ncomputational models based on a small set of model runs used for training. An\ninherent limitation of many surrogate models is their susceptibility to the\ncurse of dimensionality, which traditionally limits their applicability to a\nmaximum of $\\mathcal{O}(10^2)$ input dimensions. We present a novel approach at\nhigh-dimensional surrogate modelling that is model-, dimensionality reduction-\nand surrogate model- agnostic (black box), and can enable the solution of high\ndimensional (i.e. up to $\\mathcal{O}(10^4)$) problems. After introducing the\ngeneral algorithm, we demonstrate its performance by combining Kriging and\npolynomial chaos expansions surrogates and kernel principal component analysis.\nIn particular, we compare the generalisation performance that the resulting\nsurrogates achieve to the classical sequential application of dimensionality\nreduction followed by surrogate modelling on several benchmark applications,\ncomprising an analytical function and two engineering applications of\nincreasing dimensionality and complexity.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 15:39:41 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 09:54:05 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 11:05:08 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Lataniotis", "C.", ""], ["Marelli", "S.", ""], ["Sudret", "B.", ""]]}, {"id": "1812.06319", "submitter": "Xueguang Lyu", "authors": "Xueguang Lyu, Christopher Amato", "title": "Likelihood Quantile Networks for Coordinating Multi-Agent Reinforcement\n  Learning", "comments": null, "journal-ref": "Proceedings of the 19th International Conference on Autonomous\n  Agents and MultiAgent Systems, pp. 798-806. 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When multiple agents learn in a decentralized manner, the environment appears\nnon-stationary from the perspective of an individual agent due to the\nexploration and learning of the other agents. Recently proposed deep\nmulti-agent reinforcement learning methods have tried to mitigate this\nnon-stationarity by attempting to determine which samples are from other agent\nexploration or suboptimality and take them less into account during learning.\nBased on the same philosophy, this paper introduces a decentralized quantile\nestimator, which aims to improve performance by distinguishing non-stationary\nsamples based on the likelihood of returns. In particular, each agent considers\nthe likelihood that other agent exploration and policy changes are occurring,\nessentially utilizing the agent's own estimations to weigh the learning rate\nthat should be applied towards the given samples. We introduce a formal method\nof calculating differences of our return distribution representations and\nmethods for utilizing it to guide updates. We also explore the effect of\nrisk-seeking strategies for adjusting learning over time and propose adaptive\nrisk distortion functions which guides risk sensitivity. Our experiments, on\ntraditional benchmarks and new domains, show our methods are more stable,\nsample efficient and more likely to converge to a joint optimal policy than\nprevious methods.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 16:31:19 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 22:56:22 GMT"}, {"version": "v3", "created": "Sun, 13 Jan 2019 05:25:22 GMT"}, {"version": "v4", "created": "Tue, 29 Jan 2019 10:02:21 GMT"}, {"version": "v5", "created": "Wed, 6 May 2020 03:48:18 GMT"}, {"version": "v6", "created": "Sun, 14 Jun 2020 19:43:28 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Lyu", "Xueguang", ""], ["Amato", "Christopher", ""]]}, {"id": "1812.06349", "submitter": "Oren Barkan", "authors": "Oren Barkan, David Tsiris, Ori Katz and Noam Koenigstein", "title": "InverSynth: Deep Estimation of Synthesizer Parameter Configurations from\n  Audio Signals", "comments": "To appear in IEEE/ACM Transactions on Audio Speech and Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound synthesis is a complex field that requires domain expertise. Manual\ntuning of synthesizer parameters to match a specific sound can be an exhaustive\ntask, even for experienced sound engineers. In this paper, we introduce\nInverSynth - an automatic method for synthesizer parameters tuning to match a\ngiven input sound. InverSynth is based on strided convolutional neural networks\nand is capable of inferring the synthesizer parameters configuration from the\ninput spectrogram and even from the raw audio. The effectiveness InverSynth is\ndemonstrated on a subtractive synthesizer with four frequency modulated\noscillators, envelope generator and a gater effect. We present extensive\nquantitative and qualitative results that showcase the superiority InverSynth\nover several baselines. Furthermore, we show that the network depth is an\nimportant factor that contributes to the prediction accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 20:23:51 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 06:47:08 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Barkan", "Oren", ""], ["Tsiris", "David", ""], ["Katz", "Ori", ""], ["Koenigstein", "Noam", ""]]}, {"id": "1812.06360", "submitter": "Rui Liu", "authors": "Rui Liu, Tianyi Wu, Barzan Mozafari", "title": "A Bandit Approach to Maximum Inner Product Search", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been substantial research on sub-linear time approximate algorithms\nfor Maximum Inner Product Search (MIPS). To achieve fast query time,\nstate-of-the-art techniques require significant preprocessing, which can be a\nburden when the number of subsequent queries is not sufficiently large to\namortize the cost. Furthermore, existing methods do not have the ability to\ndirectly control the suboptimality of their approximate results with\ntheoretical guarantees. In this paper, we propose the first approximate\nalgorithm for MIPS that does not require any preprocessing, and allows users to\ncontrol and bound the suboptimality of the results. We cast MIPS as a Best Arm\nIdentification problem, and introduce a new bandit setting that can fully\nexploit the special structure of MIPS. Our approach outperforms\nstate-of-the-art methods on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 21:33:56 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Liu", "Rui", ""], ["Wu", "Tianyi", ""], ["Mozafari", "Barzan", ""]]}, {"id": "1812.06369", "submitter": "Emmanuel Abbe A", "authors": "Emmanuel Abbe and Colin Sandon", "title": "Provable limitations of deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the success of deep learning reaches more grounds, one would like to also\nenvision the potential limits of deep learning. This paper gives a first set of\nresults proving that certain deep learning algorithms fail at learning certain\nefficiently learnable functions. The results put forward a notion of\ncross-predictability that characterizes when such failures take place. Parity\nfunctions provide an extreme example with a cross-predictability that decays\nexponentially, while a mere super-polynomial decay of the cross-predictability\nis shown to be sufficient to obtain failures. Examples in community detection\nand arithmetic learning are also discussed.\n  Recall that it is known that the class of neural networks (NNs) with\npolynomial network size can express any function that can be implemented in\npolynomial time, and that their sample complexity scales polynomially with the\nnetwork size. The challenge is with the optimization error (the ERM is\nNP-hard), and the success behind deep learning is to train deep NNs with\ndescent algorithms. The failures shown in this paper apply to training\npoly-size NNs on function distributions of low cross-predictability with a\ndescent algorithm that is either run with limited memory per sample or that is\ninitialized and run with enough randomness. We further claim that such types of\nconstraints are necessary to obtain failures, in that exact SGD with careful\nnon-random initialization can be shown to learn parities. The\ncross-predictability in our results plays a similar role the statistical\ndimension in statistical query (SQ) algorithms, with distinctions explained in\nthe paper. The proof techniques are based on exhibiting algorithmic constraints\nthat imply a statistical indistinguishability between the algorithm's output on\nthe test model v.s.\\ a null model, using information measures to bound the\ntotal variation distance.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 00:10:08 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 08:29:32 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Sandon", "Colin", ""]]}, {"id": "1812.06371", "submitter": "Amir Gholami", "authors": "Zhewei Yao and Amir Gholami and Peng Xu and Kurt Keutzer and Michael\n  Mahoney", "title": "Trust Region Based Adversarial Attack on Neural Networks", "comments": null, "journal-ref": "CVPR 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are quite vulnerable to adversarial perturbations.\nCurrent state-of-the-art adversarial attack methods typically require very time\nconsuming hyper-parameter tuning, or require many iterations to solve an\noptimization based adversarial attack. To address this problem, we present a\nnew family of trust region based adversarial attacks, with the goal of\ncomputing adversarial perturbations efficiently. We propose several attacks\nbased on variants of the trust region optimization method. We test the proposed\nmethods on Cifar-10 and ImageNet datasets using several different models\nincluding AlexNet, ResNet-50, VGG-16, and DenseNet-121 models. Our methods\nachieve comparable results with the Carlini-Wagner (CW) attack, but with\nsignificant speed up of up to $37\\times$, for the VGG-16 model on a Titan Xp\nGPU. For the case of ResNet-50 on ImageNet, we can bring down its\nclassification accuracy to less than 0.1\\% with at most $1.5\\%$ relative\n$L_\\infty$ (or $L_2$) perturbation requiring only $1.02$ seconds as compared to\n$27.04$ seconds for the CW attack. We have open sourced our method which can be\naccessed at [1].\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 00:52:18 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Xu", "Peng", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael", ""]]}, {"id": "1812.06391", "submitter": "Li Li", "authors": "Li Li, Hirokazu Kameoka, Shoji Makino", "title": "Fast MVAE: Joint separation and classification of mixed sources based on\n  multichannel variational autoencoder with auxiliary classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an alternative algorithm for multichannel variational\nautoencoder (MVAE), a recently proposed multichannel source separation\napproach. While MVAE is notable in its impressive source separation\nperformance, the convergence-guaranteed optimization algorithm and that it\nallows us to estimate source-class labels simultaneously with source\nseparation, there are still two major drawbacks, i.e., the high computational\ncomplexity and unsatisfactory source classification accuracy. To overcome these\ndrawbacks, the proposed method employs an auxiliary classifier VAE, an\ninformation-theoretic extension of the conditional VAE, for learning the\ngenerative model of the source spectrograms. Furthermore, with the trained\nauxiliary classifier, we introduce a novel algorithm for the optimization that\nis able to not only reduce the computational time but also improve the source\nclassification performance. We call the proposed method \"fast MVAE (fMVAE)\".\nExperimental evaluations revealed that fMVAE achieved comparative source\nseparation performance to MVAE and about 80% source classification accuracy\nrate while it reduced about 93% computational time.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 05:14:57 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 13:27:29 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Li", "Li", ""], ["Kameoka", "Hirokazu", ""], ["Makino", "Shoji", ""]]}, {"id": "1812.06393", "submitter": "Artidoro Pagnoni", "authors": "Artidoro Pagnoni, Stefan Gramatovici, Samuel Liu", "title": "PAC Learning Guarantees Under Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Domain Adaptation problem, also known as the covariate shift\nproblem, where the distributions that generate the training and test data\ndiffer while retaining the same labeling function. This problem occurs across a\nlarge range of practical applications, and is related to the more general\nchallenge of transfer learning. Most recent work on the topic focuses on\noptimization techniques that are specific to an algorithm or practical use case\nrather than a more general approach. The sparse literature attempting to\nprovide general bounds seems to suggest that efficient learning even under\nstrong assumptions is not possible for covariate shift. Our main contribution\nis to recontextualize these results by showing that any Probably Approximately\nCorrect (PAC) learnable concept class is still PAC learnable under covariate\nshift conditions with only a polynomial increase in the number of training\nsamples. This approach essentially demonstrates that the Domain Adaptation\nlearning problem is as hard as the underlying PAC learning problem, provided\nsome conditions over the training and test distributions. We also present\nbounds for the rejection sampling algorithm, justifying it as a solution to the\nDomain Adaptation problem in certain scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 05:24:59 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Pagnoni", "Artidoro", ""], ["Gramatovici", "Stefan", ""], ["Liu", "Samuel", ""]]}, {"id": "1812.06397", "submitter": "David Hofmeyr", "authors": "David P. Hofmeyr", "title": "Connecting Spectral Clustering to Maximum Margins and Level Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the connections between spectral clustering and the problems of\nmaximum margin clustering, and estimation of the components of level sets of a\ndensity function. Specifically, we obtain bounds on the eigenvectors of graph\nLaplacian matrices in terms of the between cluster separation, and within\ncluster connectivity. These bounds ensure that the spectral clustering solution\nconverges to the maximum margin clustering solution as the scaling parameter is\nreduced towards zero. The sensitivity of maximum margin clustering solutions to\noutlying points is well known, but can be mitigated by first removing such\noutliers, and applying maximum margin clustering to the remaining points. If\noutliers are identified using an estimate of the underlying probability\ndensity, then the remaining points may be seen as an estimate of a level set of\nthis density function. We show that such an approach can be used to\nconsistently estimate the components of the level sets of a density function\nunder very mild assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 05:48:23 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Hofmeyr", "David P.", ""]]}, {"id": "1812.06398", "submitter": "Ehsan Abbasnejad M", "authors": "Ehsan Abbasnejad, Iman Abbasnejad, Qi Wu, Javen Shi, Anton van den\n  Hengel", "title": "Gold Seeker: Information Gain from Policy Distributions for\n  Goal-oriented Vision-and-Langauge Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Computer Vision moves from a passive analysis of pixels to active analysis\nof semantics, the breadth of information algorithms need to reason over has\nexpanded significantly. One of the key challenges in this vein is the ability\nto identify the information required to make a decision, and select an action\nthat will recover it. We propose a reinforcement-learning approach that\nmaintains a distribution over its internal information, thus explicitly\nrepresenting the ambiguity in what it knows, and needs to know, towards\nachieving its goal. Potential actions are then generated according to this\ndistribution. For each potential action a distribution of the expected outcomes\nis calculated, and the value of the potential information gain assessed. The\naction taken is that which maximizes the potential information gain. We\ndemonstrate this approach applied to two vision-and-language problems that have\nattracted significant recent interest, visual dialog and visual query\ngeneration. In both cases, the method actively selects actions that will best\nreduce its internal uncertainty and outperforms its competitors in achieving\nthe goal of the challenge.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 05:48:54 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 15:09:58 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 02:17:10 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Abbasnejad", "Ehsan", ""], ["Abbasnejad", "Iman", ""], ["Wu", "Qi", ""], ["Shi", "Javen", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1812.06408", "submitter": "Asanka G. Perera", "authors": "Asanka G Perera, Yee Wei Law and Javaan Chahl", "title": "Human Pose and Path Estimation from Aerial Video using Dynamic\n  Classifier Selection", "comments": "For associated dataset, see\n  https://asankagp.github.io/aerialgaitdataset/", "journal-ref": "Cogn Comput 10 (2018) 1019-1041", "doi": "10.1007/s12559-018-9577-6", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating human pose and trajectory by an aerial\nrobot with a monocular camera in near real time. We present a preliminary\nsolution whose distinguishing feature is a dynamic classifier selection\narchitecture. In our solution, each video frame is corrected for perspective\nusing projective transformation. Then, two alternative feature sets are used:\n(i) Histogram of Oriented Gradients (HOG) of the silhouette, (ii) Convolutional\nNeural Network (CNN) features of the RGB image. The features (HOG or CNN) are\nclassified using a dynamic classifier. A class is defined as a pose-viewpoint\npair, and a total of 64 classes are defined to represent a forward walking and\nturning gait sequence. Our solution provides three main advantages: (i)\nClassification is efficient due to dynamic selection (4-class vs. 64-class\nclassification). (ii) Classification errors are confined to neighbors of the\ntrue view-points. (iii) The robust temporal relationship between poses is used\nto resolve the left-right ambiguities of human silhouettes. Experiments\nconducted on both fronto-parallel videos and aerial videos confirm our solution\ncan achieve accurate pose and trajectory estimation for both scenarios. We\nfound using HOG features provides higher accuracy than using CNN features. For\nexample, applying the HOG-based variant of our scheme to the 'walking on a\nfigure 8-shaped path' dataset (1652 frames) achieved estimation accuracies of\n99.6% for viewpoints and 96.2% for number of poses.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 07:27:26 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Perera", "Asanka G", ""], ["Law", "Yee Wei", ""], ["Chahl", "Javaan", ""]]}, {"id": "1812.06467", "submitter": "Seungjoon Lee", "authors": "Seungjoon Lee, Felix Dietrich, George E. Karniadakis, Ioannis G.\n  Kevrekidis", "title": "Linking Gaussian Process regression with data-driven manifold embeddings\n  for nonlinear data fusion", "comments": null, "journal-ref": null, "doi": "10.1098/rsfs.2018.0083", "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical modeling with Gaussian Process regression, it has been shown\nthat combining (few) high-fidelity data with (many) low-fidelity data can\nenhance prediction accuracy, compared to prediction based on the few\nhigh-fidelity data only. Such information fusion techniques for multifidelity\ndata commonly approach the high-fidelity model $f_h(t)$ as a function of two\nvariables $(t,y)$, and then using $f_l(t)$ as the $y$ data. More generally, the\nhigh-fidelity model can be written as a function of several variables\n$(t,y_1,y_2....)$; the low-fidelity model $f_l$ and, say, some of its\nderivatives, can then be substituted for these variables. In this paper, we\nwill explore mathematical algorithms for multifidelity information fusion that\nuse such an approach towards improving the representation of the high-fidelity\nfunction with only a few training data points. Given that $f_h$ may not be a\nsimple function -- and sometimes not even a function -- of $f_l$, we\ndemonstrate that using additional functions of $t$, such as derivatives or\nshifts of $f_l$, can drastically improve the approximation of $f_h$ through\nGaussian Processes. We also point out a connection with \"embedology\" techniques\nfrom topology and dynamical systems.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 13:56:37 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Lee", "Seungjoon", ""], ["Dietrich", "Felix", ""], ["Karniadakis", "George E.", ""], ["Kevrekidis", "Ioannis G.", ""]]}, {"id": "1812.06486", "submitter": "Henning Petzka", "authors": "Henning Petzka and Cristian Sminchisescu", "title": "Non-attracting Regions of Local Minima in Deep and Wide Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the loss surface of neural networks is essential for the design\nof models with predictable performance and their success in applications.\nExperimental results suggest that sufficiently deep and wide neural networks\nare not negatively impacted by suboptimal local minima. Despite recent\nprogress, the reason for this outcome is not fully understood. Could deep\nnetworks have very few, if at all, suboptimal local optima? or could all of\nthem be equally good? We provide a construction to show that suboptimal local\nminima (i.e., non-global ones), even though degenerate, exist for fully\nconnected neural networks with sigmoid activation functions. The local minima\nobtained by our construction belong to a connected set of local solutions that\ncan be escaped from via a non-increasing path on the loss curve. For extremely\nwide neural networks of decreasing width after the wide layer, we prove that\nevery suboptimal local minimum belongs to such a connected set. This provides a\npartial explanation for the successful application of deep neural networks. In\naddition, we also characterize under what conditions the same construction\nleads to saddle points instead of local minima for deep neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 15:35:03 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 13:59:52 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 06:48:19 GMT"}, {"version": "v4", "created": "Mon, 31 Aug 2020 09:16:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Petzka", "Henning", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "1812.06488", "submitter": "Theodore Moskovitz", "authors": "Theodore H. Moskovitz, Ashok Litwin-Kumar, L.F. Abbott", "title": "Feedback alignment in deep convolutional networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ongoing studies have identified similarities between neural representations\nin biological networks and in deep artificial neural networks. This has led to\nrenewed interest in developing analogies between the backpropagation learning\nalgorithm used to train artificial networks and the synaptic plasticity rules\noperative in the brain. These efforts are challenged by biologically\nimplausible features of backpropagation, one of which is a reliance on\nsymmetric forward and backward synaptic weights. A number of methods have been\nproposed that do not rely on weight symmetry but, thus far, these have failed\nto scale to deep convolutional networks and complex data. We identify principal\nobstacles to the scalability of such algorithms and introduce several\ntechniques to mitigate them. We demonstrate that a modification of the feedback\nalignment method that enforces a weaker form of weight symmetry, one that\nrequires agreement of weight sign but not magnitude, can achieve performance\ncompetitive with backpropagation. Our results complement those of Bartunov et\nal. (2018) and Xiao et al. (2018b) and suggest that mechanisms that promote\nalignment of feedforward and feedback weights are critical for learning in deep\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 22:12:53 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 04:19:00 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Moskovitz", "Theodore H.", ""], ["Litwin-Kumar", "Ashok", ""], ["Abbott", "L. F.", ""]]}, {"id": "1812.06502", "submitter": "Cheng Zeng", "authors": "Cheng Zeng, Hongming Zhang", "title": "A Logarithmic Barrier Method For Proximal Policy Optimization", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal policy optimization(PPO) has been proposed as a first-order\noptimization method for reinforcement learning. We should notice that an\nexterior penalty method is used in it. Often, the minimizers of the exterior\npenalty functions approach feasibility only in the limits as the penalty\nparameter grows increasingly large. Therefore, it may result in the low level\nof sampling efficiency. This method, which we call proximal policy optimization\nwith barrier method (PPO-B), keeps almost all advantageous spheres of PPO such\nas easy implementation and good generalization. Specifically, a new surrogate\nobjective with interior penalty method is proposed to avoid the defect arose\nfrom exterior penalty method. Conclusions can be draw that PPO-B is able to\noutperform PPO in terms of sampling efficiency since PPO-B achieved clearly\nbetter performance on Atari and Mujoco environment than PPO.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 17:07:20 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Zeng", "Cheng", ""], ["Zhang", "Hongming", ""]]}, {"id": "1812.06507", "submitter": "Yizhen Xu", "authors": "Yizhen Xu, Tao Liu, Michael J. Daniels, Rami Kantor, Ann Mwangi,\n  Joseph W. Hogan", "title": "Classification using Ensemble Learning under Weighted Misclassification\n  Loss", "comments": "23 pages, 4 tables, 4 figures", "journal-ref": "Statistics in Medicine 2019, Vol. 38, Issue 11, Pg. 2002-2012", "doi": "10.1002/sim.8082", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary classification rules based on covariates typically depend on simple\nloss functions such as zero-one misclassification. Some cases may require more\ncomplex loss functions. For example, individual-level monitoring of\nHIV-infected individuals on antiretroviral therapy (ART) requires periodic\nassessment of treatment failure, defined as having a viral load (VL) value\nabove a certain threshold. In some resource limited settings, VL tests may be\nlimited by cost or technology, and diagnoses are based on other clinical\nmarkers. Depending on scenario, higher premium may be placed on avoiding\nfalse-positives which brings greater cost and reduced treatment options. Here,\nthe optimal rule is determined by minimizing a weighted misclassification\nloss/risk.\n  We propose a method for finding and cross-validating optimal binary\nclassification rules under weighted misclassification loss. We focus on rules\ncomprising a prediction score and an associated threshold, where the score is\nderived using an ensemble learner. Simulations and examples show that our\nmethod, which derives the score and threshold jointly, more accurately\nestimates overall risk and has better operating characteristics compared with\nmethods that derive the score first and the cutoff conditionally on the score\nespecially for finite samples.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 17:43:08 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 20:59:25 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Xu", "Yizhen", ""], ["Liu", "Tao", ""], ["Daniels", "Michael J.", ""], ["Kantor", "Rami", ""], ["Mwangi", "Ann", ""], ["Hogan", "Joseph W.", ""]]}, {"id": "1812.06515", "submitter": "Subhadeep Paul", "authors": "Subhadeep Paul, Olgica Milenkovic, Yuguo Chen", "title": "Higher-Order Spectral Clustering under Superimposed Stochastic Block\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order motif structures and multi-vertex interactions are becoming\nincreasingly important in studies that aim to improve our understanding of\nfunctionalities and evolution patterns of networks. To elucidate the role of\nhigher-order structures in community detection problems over complex networks,\nwe introduce the notion of a Superimposed Stochastic Block Model (SupSBM). The\nmodel is based on a random graph framework in which certain higher-order\nstructures or subgraphs are generated through an independent hyperedge\ngeneration process, and are then replaced with graphs that are superimposed\nwith directed or undirected edges generated by an inhomogeneous random graph\nmodel. Consequently, the model introduces controlled dependencies between edges\nwhich allow for capturing more realistic network phenomena, namely strong local\nclustering in a sparse network, short average path length, and community\nstructure. We proceed to rigorously analyze the performance of a number of\nrecently proposed higher-order spectral clustering methods on the SupSBM. In\nparticular, we prove non-asymptotic upper bounds on the misclustering error of\nspectral community detection for a SupSBM setting in which triangles or\n3-uniform hyperedges are superimposed with undirected edges. As part of our\nanalysis, we also derive new bounds on the misclustering error of higher-order\nspectral clustering methods for the standard SBM and the 3-uniform hypergraph\nSBM. Furthermore, for a non-uniform hypergraph SBM model in which one directly\nobserves both edges and 3-uniform hyperedges, we obtain a criterion that\ndescribes when to perform spectral clustering based on edges and when on\nhyperedges, based on a function of hyperedge density and observation quality.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 18:20:00 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Paul", "Subhadeep", ""], ["Milenkovic", "Olgica", ""], ["Chen", "Yuguo", ""]]}, {"id": "1812.06535", "submitter": "Shlomo Chazan", "authors": "Shlomo E. Chazan, Sharon Gannot and Jacob Goldberger", "title": "Deep Clustering Based on a Mixture of Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a Deep Autoencoder MIxture Clustering (DAMIC)\nalgorithm based on a mixture of deep autoencoders where each cluster is\nrepresented by an autoencoder. A clustering network transforms the data into\nanother space and then selects one of the clusters. Next, the autoencoder\nassociated with this cluster is used to reconstruct the data-point. The\nclustering algorithm jointly learns the nonlinear data representation and the\nset of autoencoders. The optimal clustering is found by minimizing the\nreconstruction loss of the mixture of autoencoder network. Unlike other deep\nclustering algorithms, no regularization term is needed to avoid data\ncollapsing to a single point. Our experimental evaluations on image and text\ncorpora show significant improvement over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 21:03:32 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 11:45:12 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Chazan", "Shlomo E.", ""], ["Gannot", "Sharon", ""], ["Goldberger", "Jacob", ""]]}, {"id": "1812.06562", "submitter": "Xinghua Yao", "authors": "X. Yao, X. Li, Q. Ye, Y. Huang, Q. Cheng, and G.-Q. Zhang", "title": "A Robust Deep Learning Approach for Automatic Classification of Seizures\n  Against Non-seizures", "comments": "13 pages, 10 figures, submitted to Biomedical Signal Processing and\n  Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying epileptic seizures through analysis of the electroencephalography\n(EEG) signal becomes a standard method for the diagnosis of epilepsy. Manual\nseizure identification on EEG by trained neurologists is time-consuming,\nlabor-intensive and error-prone, and a reliable automatic seizure/non-seizure\nclassification method is needed. One of the challenges in automatic\nseizure/non-seizure classification is that seizure morphologies exhibit\nconsiderable variabilities. In order to capture essential seizure patterns,\nthis paper leverages an attention mechanism and a bidirectional long short-term\nmemory (BiLSTM) to exploit both spatial and temporal discriminating features\nand overcome seizure variabilities. The attention mechanism is to capture\nspatial features according to the contributions of different brain regions to\nseizures. The BiLSTM is to extract discriminating temporal features in the\nforward and the backward directions. Cross-validation experiments and\ncross-patient experiments over the noisy data of CHB-MIT are performed to\nevaluate our proposed approach. The obtained average sensitivity of 87.00%,\nspecificity of 88.60% and precision of 88.63% in cross-validation experiments\nare higher than using the current state-of-the-art methods, and the standard\ndeviations of our approach are lower. The evaluation results of cross-patient\nexperiments indicate that, our approach has better performance compared with\nthe current state-of-the-art methods and is more robust across patients.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 00:03:13 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 00:43:44 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Yao", "X.", ""], ["Li", "X.", ""], ["Ye", "Q.", ""], ["Huang", "Y.", ""], ["Cheng", "Q.", ""], ["Zhang", "G. -Q.", ""]]}, {"id": "1812.06571", "submitter": "Lili Pan", "authors": "Lili Pan, Shen Cheng, Jian Liu, Yazhou Ren, Zenglin Xu", "title": "Latent Dirichlet Allocation in Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of multimodal generative modelling of images based on\ngenerative adversarial networks (GANs). Despite the success of existing\nmethods, they often ignore the underlying structure of vision data or its\nmultimodal generation characteristics. To address this problem, we introduce\nthe Dirichlet prior for multimodal image generation, which leads to a new\nLatent Dirichlet Allocation based GAN (LDAGAN). In detail, for the generative\nprocess modelling, LDAGAN defines a generative mode for each sample,\ndetermining which generative sub-process it belongs to. For the adversarial\ntraining, LDAGAN derives a variational expectation-maximization (VEM) algorithm\nto estimate model parameters. Experimental results on real-world datasets have\ndemonstrated the outstanding performance of LDAGAN over other existing GANs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 01:21:20 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 10:06:57 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 10:28:54 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 08:58:45 GMT"}, {"version": "v5", "created": "Wed, 6 Nov 2019 14:56:54 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Pan", "Lili", ""], ["Cheng", "Shen", ""], ["Liu", "Jian", ""], ["Ren", "Yazhou", ""], ["Xu", "Zenglin", ""]]}, {"id": "1812.06580", "submitter": "Maria Brbi\\'c", "authors": "Maria Brbi\\'c and Ivica Kopriva", "title": "$\\ell_0$-Motivated Low-Rank Sparse Subspace Clustering", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2018.2883566", "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, high-dimensional data points can be well represented by\nlow-dimensional subspaces. To identify the subspaces, it is important to\ncapture a global and local structure of the data which is achieved by imposing\nlow-rank and sparseness constraints on the data representation matrix. In\nlow-rank sparse subspace clustering (LRSSC), nuclear and $\\ell_1$ norms are\nused to measure rank and sparsity. However, the use of nuclear and $\\ell_1$\nnorms leads to an overpenalized problem and only approximates the original\nproblem. In this paper, we propose two $\\ell_0$ quasi-norm based\nregularizations. First, the paper presents regularization based on multivariate\ngeneralization of minimax-concave penalty (GMC-LRSSC), which contains the\nglobal minimizers of $\\ell_0$ quasi-norm regularized objective. Afterward, we\nintroduce the Schatten-0 ($S_0$) and $\\ell_0$ regularized objective and\napproximate the proximal map of the joint solution using a proximal average\nmethod ($S_0/\\ell_0$-LRSSC). The resulting nonconvex optimization problems are\nsolved using alternating direction method of multipliers with established\nconvergence conditions of both algorithms. Results obtained on synthetic and\nfour real-world datasets show the effectiveness of GMC-LRSSC and\n$S_0/\\ell_0$-LRSSC when compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 02:06:16 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Brbi\u0107", "Maria", ""], ["Kopriva", "Ivica", ""]]}, {"id": "1812.06591", "submitter": "Rob Chew", "authors": "Rob Chew, Michael Wenger, Caroline Kery, Jason Nance, Keith Richards,\n  Emily Hadley, Peter Baumgartner", "title": "SMART: An Open Source Data Labeling Platform for Supervised Learning", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SMART is an open source web application designed to help data scientists and\nresearch teams efficiently build labeled training data sets for supervised\nmachine learning tasks. SMART provides users with an intuitive interface for\ncreating labeled data sets, supports active learning to help reduce the\nrequired amount of labeled data, and incorporates inter-rater reliability\nstatistics to provide insight into label quality. SMART is designed to be\nplatform agnostic and easily deployable to meet the needs of as many different\nresearch teams as possible. The project website contains links to the code\nrepository and extensive user documentation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 22:49:14 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Chew", "Rob", ""], ["Wenger", "Michael", ""], ["Kery", "Caroline", ""], ["Nance", "Jason", ""], ["Richards", "Keith", ""], ["Hadley", "Emily", ""], ["Baumgartner", "Peter", ""]]}, {"id": "1812.06594", "submitter": "Sebastian Mathias Keller", "authors": "Sebastian Mathias Keller, Maxim Samarin, Antonia Meyer, Vitalii Kosak\n  (Cozak), Ute Gschwandtner, Peter Fuhr, Volker Roth", "title": "Computational EEG in Personalized Medicine: A study in Parkinson's\n  Disease", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recordings of electrical brain activity carry information about a person's\ncognitive health. For recording EEG signals, a very common setting is for a\nsubject to be at rest with its eyes closed. Analysis of these recordings often\ninvolve a dimensionality reduction step in which electrodes are grouped into 10\nor more regions (depending on the number of electrodes available). Then an\naverage over each group is taken which serves as a feature in subsequent\nevaluation. Currently, the most prominent features used in clinical practice\nare based on spectral power densities. In our work we consider a simplified\ngrouping of electrodes into two regions only. In addition to spectral features\nwe introduce a secondary, non-redundant view on brain activity through the lens\nof Tsallis Entropy $S_{q=2}$. We further take EEG measurements not only in an\neyes closed (ec) but also in an eyes open (eo) state. For our cohort of healthy\ncontrols (HC) and individuals suffering from Parkinson's disease (PD), the\nquestion we are asking is the following: How well can one discriminate between\nHC and PD within this simplified, binary grouping? This question is motivated\nby the commercial availability of inexpensive and easy to use portable EEG\ndevices. If enough information is retained in this binary grouping, then such\nsimple devices could potentially be used as personal monitoring tools, as\nstandard screening tools by general practitioners or as digital biomarkers for\neasy long term monitoring during neurological studies.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 15:15:44 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Keller", "Sebastian Mathias", "", "Cozak"], ["Samarin", "Maxim", "", "Cozak"], ["Meyer", "Antonia", "", "Cozak"], ["Kosak", "Vitalii", "", "Cozak"], ["Gschwandtner", "Ute", ""], ["Fuhr", "Peter", ""], ["Roth", "Volker", ""]]}, {"id": "1812.06597", "submitter": "Hanting Chen", "authors": "Hanting Chen, Yunhe Wang, Chang Xu, Chao Xu, Dacheng Tao", "title": "Learning Student Networks via Feature Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have been widely used in numerous\napplications, but their demanding storage and computational resource\nrequirements prevent their applications on mobile devices. Knowledge\ndistillation aims to optimize a portable student network by taking the\nknowledge from a well-trained heavy teacher network. Traditional\nteacher-student based methods used to rely on additional fully-connected layers\nto bridge intermediate layers of teacher and student networks, which brings in\na large number of auxiliary parameters. In contrast, this paper aims to\npropagate information from teacher to student without introducing new variables\nwhich need to be optimized. We regard the teacher-student paradigm from a new\nperspective of feature embedding. By introducing the locality preserving loss,\nthe student network is encouraged to generate the low-dimensional features\nwhich could inherit intrinsic properties of their corresponding\nhigh-dimensional features from teacher network. The resulting portable network\nthus can naturally maintain the performance as that of the teacher network.\nTheoretical analysis is provided to justify the lower computation complexity of\nthe proposed method. Experiments on benchmark datasets and well-trained\nnetworks suggest that the proposed algorithm is superior to state-of-the-art\nteacher-student learning methods in terms of computational and storage\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 03:21:20 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Chen", "Hanting", ""], ["Wang", "Yunhe", ""], ["Xu", "Chang", ""], ["Xu", "Chao", ""], ["Tao", "Dacheng", ""]]}, {"id": "1812.06598", "submitter": "Cecile Bothorel", "authors": "Vinh-Loc Dao, C\\'ecile Bothorel, Philippe Lenca", "title": "Community structure: A comparative evaluation of community detection\n  methods", "comments": "This version will be published the Network Science journal\n  (http://journals.cambridge.org/NWS)", "journal-ref": "Network Science, 8(1), 1-41, 2020", "doi": "10.1017/nws.2019.59", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Discovering community structure in complex networks is a mature field since a\ntremendous number of community detection methods have been introduced in the\nliterature. Nevertheless, it is still very challenging for practioners to\ndetermine which method would be suitable to get insights into the structural\ninformation of the networks they study. Many recent efforts have been devoted\nto investigating various quality scores of the community structure, but the\nproblem of distinguishing between different types of communities is still open.\nIn this paper, we propose a comparative, extensive and empirical study to\ninvestigate what types of communities many state-of-the-art and well-known\ncommunity detection methods are producing. Specifically, we provide\ncomprehensive analyses on computation time, community size distribution, a\ncomparative evaluation of methods according to their optimisation schemes as\nwell as a comparison of their partioning strategy through validation metrics.\nWe process our analyses on a very large corpus of hundreds of networks from\nfive different network categories and propose ways to classify community\ndetection methods, helping a potential user to navigate the complex landscape\nof community detection.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 11:18:08 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 16:13:58 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 14:31:52 GMT"}, {"version": "v4", "created": "Mon, 4 Nov 2019 16:20:19 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Dao", "Vinh-Loc", ""], ["Bothorel", "C\u00e9cile", ""], ["Lenca", "Philippe", ""]]}, {"id": "1812.06600", "submitter": "Sebastian Jaimungal", "authors": "Brian Ning, Franco Ho Ting Lin, Sebastian Jaimungal", "title": "Double Deep Q-Learning for Optimal Execution", "comments": "20 pages, 7 figures, 1 table. Updated minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal trade execution is an important problem faced by essentially all\ntraders. Much research into optimal execution uses stringent model assumptions\nand applies continuous time stochastic control to solve them. Here, we instead\ntake a model free approach and develop a variation of Deep Q-Learning to\nestimate the optimal actions of a trader. The model is a fully connected Neural\nNetwork trained using Experience Replay and Double DQN with input features\ngiven by the current state of the limit order book, other trading signals, and\navailable execution actions, while the output is the Q-value function\nestimating the future rewards under an arbitrary action. We apply our model to\nnine different stocks and find that it outperforms the standard benchmark\napproach on most stocks using the measures of (i) mean and median\nout-performance, (ii) probability of out-performance, and (iii) gain-loss\nratios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 03:33:55 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 15:21:40 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ning", "Brian", ""], ["Lin", "Franco Ho Ting", ""], ["Jaimungal", "Sebastian", ""]]}, {"id": "1812.06625", "submitter": "Zhiwei Wang", "authors": "Zhiwei Wang, Yi Lin, Kwang-Ting Cheng and Xin Yang", "title": "Semi-supervised mp-MRI Data Synthesis with StitchLayer and Auxiliary\n  Distance Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of synthesizing multi-parameter\nmagnetic resonance imaging (mp-MRI) data, i.e. Apparent Diffusion Coefficients\n(ADC) and T2-weighted (T2w), containing clinically significant (CS) prostate\ncancer (PCa) via semi-supervised adversarial learning. Specifically, our\nsynthesizer generates mp-MRI data in a sequential manner: first generating ADC\nmaps from 128-d latent vectors, followed by translating them to the T2w images.\nThe synthesizer is trained in a semisupervised manner. In the supervised\ntraining process, a limited amount of paired ADC-T2w images and the\ncorresponding ADC encodings are provided and the synthesizer learns the paired\nrelationship by explicitly minimizing the reconstruction losses between\nsynthetic and real images. To avoid overfitting limited ADC encodings, an\nunlimited amount of random latent vectors and unpaired ADC-T2w Images are\nutilized in the unsupervised training process for learning the marginal image\ndistributions of real images. To improve the robustness of synthesizing, we\ndecompose the difficult task of generating full-size images into several\nsimpler tasks which generate sub-images only. A StitchLayer is then employed to\nfuse sub-images together in an interlaced manner into a full-size image. To\nenforce the synthetic images to indeed contain distinguishable CS PCa lesions,\nwe propose to also maximize an auxiliary distance of Jensen-Shannon divergence\n(JSD) between CS and nonCS images. Experimental results show that our method\ncan effectively synthesize a large variety of mpMRI images which contain\nmeaningful CS PCa lesions, display a good visual quality and have the correct\npaired relationship. Compared to the state-of-the-art synthesis methods, our\nmethod achieves a significant improvement in terms of both visual and\nquantitative evaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 06:27:51 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Wang", "Zhiwei", ""], ["Lin", "Yi", ""], ["Cheng", "Kwang-Ting", ""], ["Yang", "Xin", ""]]}, {"id": "1812.06626", "submitter": "Kevin Eykholt", "authors": "Kevin Eykholt and Atul Prakash", "title": "Designing Adversarially Resilient Classifiers using Resilient Feature\n  Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a methodology, resilient feature engineering, for creating\nadversarially resilient classifiers. According to existing work, adversarial\nattacks identify weakly correlated or non-predictive features learned by the\nclassifier during training and design the adversarial noise to utilize these\nfeatures. Therefore, highly predictive features should be used first during\nclassification in order to determine the set of possible output labels. Our\nmethodology focuses the problem of designing resilient classifiers into a\nproblem of designing resilient feature extractors for these highly predictive\nfeatures. We provide two theorems, which support our methodology. The Serial\nComposition Resilience and Parallel Composition Resilience theorems show that\nthe output of adversarially resilient feature extractors can be combined to\ncreate an equally resilient classifier. Based on our theoretical results, we\noutline the design of an adversarially resilient classifier.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 06:28:17 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Eykholt", "Kevin", ""], ["Prakash", "Atul", ""]]}, {"id": "1812.06635", "submitter": "Cassio Dantas", "authors": "Cassio Fraga Dantas (PANAMA), R\\'emi Gribonval (PANAMA)", "title": "Stable safe screening and structured dictionaries for faster L1\n  regularization", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, Institute of Electrical\n  and Electronics Engineers, 2019, 67 (14), pp.3756-3769", "doi": "10.1109/TSP.2019.2919404", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a way to combine two acceleration techniques for\nthe $\\ell\\_{1}$-regularized least squares problem: safe screening tests, which\nallow to eliminate useless dictionary atoms; and the use of fast structured\napproximations of the dictionary matrix. To do so, we introduce a new family of\nscreening tests, termed stable screening, which can cope with approximation\nerrors on the dictionary atoms while keeping the safety of the test (i.e. zero\nrisk of rejecting atoms belonging to the solution support). Some of the main\nexisting screening tests are extended to this new framework. The proposed\nalgorithm consists in using a coarser (but faster) approximation of the\ndictionary at the initial iterations and then switching to better\napproximations until eventually adopting the original dictionary. A systematic\nswitching criterion based on the duality gap saturation and the screening ratio\nis derived.Simulation results show significant reductions in both computational\ncomplexity and execution times for a wide range of tested scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 07:28:32 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 12:23:04 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 09:49:44 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Dantas", "Cassio Fraga", "", "PANAMA"], ["Gribonval", "R\u00e9mi", "", "PANAMA"]]}, {"id": "1812.06638", "submitter": "Tianqi Wang", "authors": "Peiwen Jiang, Tianqi Wang, Bin Han, Xuanxuan Gao, Jing Zhang, Chao-Kai\n  Wen, Shi Jin, and Geoffrey Ye Li", "title": "Artificial Intelligence-aided OFDM Receiver: Design and Experimental\n  Results", "comments": "29 pages, 13 figures, IEEE Transactions on Wireless\n  Communications,2021, Early access", "journal-ref": "\"AI-aided Online Adaptive OFDM Receiver: Design and Experimental\n  Results,\" IEEE Transactions on Wireless Communications, 2021", "doi": "10.1109/TWC.2021.3087191", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal frequency division multiplexing (OFDM) is one of the key\ntechnologies that are widely applied in current communication systems.\nRecently, artificial intelligence (AI)-aided OFDM receivers have been brought\nto the forefront to break the bottleneck of the traditional OFDM systems. In\nthis paper, we investigate two AI-aided OFDM receivers, data-driven fully\nconnected-deep neural network (FC-DNN) receiver and model-driven ComNet\nreceiver, respectively. We first study their performance under different\nchannel models through simulation and then establish a real-time video\ntransmission system using a 5G rapid prototyping (RaPro) system for\nover-the-air (OTA) test. To address the performance gap between the simulation\nand the OTA test caused by the discrepancy between the channel model for\noffline training and real environments, we develop a novel online training\nstrategy, called SwitchNet receiver. The SwitchNet receiver is with a flexible\nand extendable architecture and can adapts to real channel by training one\nparameter online. The OTA test verifies its feasibility and robustness to real\nenvironments and indicates its potential for future communications systems. At\nthe end of this paper, we discuss some challenges to inspire future research.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 07:53:47 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 02:12:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Jiang", "Peiwen", ""], ["Wang", "Tianqi", ""], ["Han", "Bin", ""], ["Gao", "Xuanxuan", ""], ["Zhang", "Jing", ""], ["Wen", "Chao-Kai", ""], ["Jin", "Shi", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1812.06647", "submitter": "Michael Lingzhi Li", "authors": "Dimitris Bertsimas, Michael Lingzhi Li", "title": "Interpretable Matrix Completion: A Discrete Optimization Approach", "comments": "Submitted to Operational Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of matrix completion on an $n \\times m$ matrix. We\nintroduce the problem of Interpretable Matrix Completion that aims to provide\nmeaningful insights for the low-rank matrix using side information. We show\nthat the problem can be reformulated as a binary convex optimization problem.\nWe design OptComplete, based on a novel concept of stochastic cutting planes to\nenable efficient scaling of the algorithm up to matrices of sizes $n=10^6$ and\n$m=10^6$. We report experiments on both synthetic and real-world datasets that\nshow that OptComplete has favorable scaling behavior and accuracy when compared\nwith state-of-the-art methods for other types of matrix completion, while\nproviding insight on the factors that affect the matrix.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 08:28:43 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 19:47:36 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 23:56:39 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Li", "Michael Lingzhi", ""]]}, {"id": "1812.06669", "submitter": "Florian Colombo", "authors": "Florian Colombo, Johanni Brea and Wulfram Gerstner", "title": "Learning to Generate Music with BachProp", "comments": null, "journal-ref": "in Proceedings of the 16th Sound and Music Computing Conference.\n  2019. p. 380-386", "doi": "10.5281/zenodo.3249394", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As deep learning advances, algorithms of music composition increase in\nperformance. However, most of the successful models are designed for specific\nmusical structures. Here, we present BachProp, an algorithmic composer that can\ngenerate music scores in many styles given sufficient training data. To adapt\nBachProp to a broad range of musical styles, we propose a novel representation\nof music and train a deep network to predict the note transition probabilities\nof a given music corpus. In this paper, new music scores generated by BachProp\nare compared with the original corpora as well as with different network\narchitectures and other related models. We show that BachProp captures\nimportant features of the original datasets better than other models and invite\nthe reader to a qualitative comparison on a large collection of generated\nsongs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 09:37:34 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 10:42:50 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Colombo", "Florian", ""], ["Brea", "Johanni", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1812.06686", "submitter": "Avijit Mitra", "authors": "Avijit Mitra, Khalid Ashraf", "title": "Sepsis Prediction and Vital Signs Ranking in Intensive Care Unit\n  Patients", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study multiple rule-based and machine learning (ML) models for sepsis\ndetection. We report the first neural network detection and prediction results\non three categories of sepsis. We have used the retrospective Medical\nInformation Mart for Intensive Care (MIMIC)-III dataset, restricted to\nintensive care unit (ICU) patients. Features for prediction were created from\nonly common vital sign measurements. We show significant improvement of AUC\nscore using neural network based ensemble model compared to single ML and\nrule-based models. For the detection of sepsis, severe sepsis, and septic\nshock, our model achieves an AUC of 0.97, 0.96 and 0.91, respectively. Four\nhours before the positive hours, it predicts the same three categories with an\nAUC of 0.90, 0.91 and 0.90 respectively. Further, we ranked the features and\nfound that using six vital signs consistently provides higher detection and\nprediction AUC for all the models tested. Our novel ensemble model achieves\nhighest AUC in detecting and predicting sepsis, severe sepsis, and septic shock\nin the MIMIC-III ICU patients, and is amenable to deployment in hospital\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 10:40:56 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 14:30:28 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 14:22:58 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Mitra", "Avijit", ""], ["Ashraf", "Khalid", ""]]}, {"id": "1812.06707", "submitter": "Rakshith Shetty", "authors": "Rakshith Shetty and Bernt Schiele and Mario Fritz", "title": "Not Using the Car to See the Sidewalk: Quantifying and Controlling the\n  Effects of Context in Classification and Segmentation", "comments": "14 pages (12 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance of visual context in scene understanding tasks is well recognized\nin the computer vision community. However, to what extent the computer vision\nmodels for image classification and semantic segmentation are dependent on the\ncontext to make their predictions is unclear. A model overly relying on context\nwill fail when encountering objects in context distributions different from\ntraining data and hence it is important to identify these dependencies before\nwe can deploy the models in the real-world. We propose a method to quantify the\nsensitivity of black-box vision models to visual context by editing images to\nremove selected objects and measuring the response of the target models. We\napply this methodology on two tasks, image classification and semantic\nsegmentation, and discover undesirable dependency between objects and context,\nfor example that \"sidewalk\" segmentation relies heavily on \"cars\" being present\nin the image. We propose an object removal based data augmentation solution to\nmitigate this dependency and increase the robustness of classification and\nsegmentation models to contextual variations. Our experiments show that the\nproposed data augmentation helps these models improve the performance in\nout-of-context scenarios, while preserving the performance on regular data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 11:28:05 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Shetty", "Rakshith", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1812.06737", "submitter": "Jerome Bobin", "authors": "Christophe Kervazo and Jerome Bobin and Cecile Chenot", "title": "Heuristics for Efficient Sparse Blind Source Separation", "comments": "in Proceedings of iTWIST'18, Paper-ID: 11, Marseille, France,\n  November, 21-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Blind Source Separation (sparse BSS) is a key method to analyze\nmultichannel data in fields ranging from medical imaging to astrophysics.\nHowever, since it relies on seeking the solution of a non-convex penalized\nmatrix factorization problem, its performances largely depend on the\noptimization strategy. In this context, Proximal Alternating Linearized\nMinimization (PALM) has become a standard algorithm which, despite its\ntheoretical grounding, generally provides poor practical separation results. In\nthis work, we propose a novel strategy that combines a heuristic approach with\nPALM. We show its relevance on realistic astrophysical data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 12:57:45 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Kervazo", "Christophe", ""], ["Bobin", "Jerome", ""], ["Chenot", "Cecile", ""]]}, {"id": "1812.06775", "submitter": "Dominik Zietlow", "authors": "Michal Rolinek, Dominik Zietlow, Georg Martius", "title": "Variational Autoencoders Pursue PCA Directions (by Accident)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Autoencoder (VAE) is a powerful architecture capable of\nrepresentation learning and generative modeling. When it comes to learning\ninterpretable (disentangled) representations, VAE and its variants show\nunparalleled performance. However, the reasons for this are unclear, since a\nvery particular alignment of the latent embedding is needed but the design of\nthe VAE does not encourage it in any explicit way. We address this matter and\noffer the following explanation: the diagonal approximation in the encoder\ntogether with the inherent stochasticity force local orthogonality of the\ndecoder. The local behavior of promoting both reconstruction and orthogonality\nmatches closely how the PCA embedding is chosen. Alongside providing an\nintuitive understanding, we justify the statement with full theoretical\nanalysis as well as with experiments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 14:06:18 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 12:20:39 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Rolinek", "Michal", ""], ["Zietlow", "Dominik", ""], ["Martius", "Georg", ""]]}, {"id": "1812.06825", "submitter": "Di Wang", "authors": "Di Wang and Adam Smith and Jinhui Xu", "title": "Noninteractive Locally Private Learning of Linear Models via Polynomial\n  Approximations", "comments": "Extended abstract will appear in Algorithmic Learning Theory 2019\n  (ALT 2019), this is the final full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing a convex risk function is the main step in many basic learning\nalgorithms. We study protocols for convex optimization which provably leak very\nlittle about the individual data points that constitute the loss function.\nSpecifically, we consider differentially private algorithms that operate in the\nlocal model, where each data record is stored on a separate user device and\nrandomization is performed locally by those devices. We give new protocols for\n\\emph{noninteractive} LDP convex optimization---i.e., protocols that require\nonly a single randomized report from each user to an untrusted aggregator.\n  We study our algorithms' performance with respect to expected loss---either\nover the data set at hand (empirical risk) or a larger population from which\nour data set is assumed to be drawn. Our error bounds depend on the form of\nindividuals' contribution to the expected loss. For the case of\n\\emph{generalized linear losses} (such as hinge and logistic losses), we give\nan LDP algorithm whose sample complexity is only linear in the dimensionality\n$p$ and quasipolynomial in other terms (the privacy parameters $\\epsilon$ and\n$\\delta$, and the desired excess risk $\\alpha$). This is the first algorithm\nfor nonsmooth losses with sub-exponential dependence on $p$.\n  For the Euclidean median problem, where the loss is given by the Euclidean\ndistance to a given data point, we give a protocol whose sample complexity\ngrows quasipolynomially in $p$. This is the first protocol with sub-exponential\ndependence on $p$ for a loss that is not a generalized linear loss .\n  Our result for the hinge loss is based on a technique, dubbed polynomial of\ninner product approximation, which may be applicable to other problems. Our\nresults for generalized linear losses and the Euclidean median are based on new\nreductions to the case of hinge loss.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 15:12:11 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 04:24:39 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 19:27:20 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wang", "Di", ""], ["Smith", "Adam", ""], ["Xu", "Jinhui", ""]]}, {"id": "1812.06833", "submitter": "Michael Rapp", "authors": "Michael Rapp, Eneldo Loza Menc\\'ia, Johannes F\\\"urnkranz", "title": "Exploiting Anti-monotonicity of Multi-label Evaluation Measures for\n  Inducing Multi-label Rules", "comments": "Preprint version. To appear in: Proceedings of the Pacific-Asia\n  Conference on Knowledge Discovery and Data Mining (PAKDD) 2018. See\n  http://www.ke.tu-darmstadt.de/bibtex/publications/show/3074 for further\n  information. arXiv admin note: text overlap with arXiv:1812.00050", "journal-ref": "Proc. PAKDD (1) 2018: 29-42", "doi": "10.1007/978-3-319-93034-3_3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting dependencies between labels is considered to be crucial for\nmulti-label classification. Rules are able to expose label dependencies such as\nimplications, subsumptions or exclusions in a human-comprehensible and\ninterpretable manner. However, the induction of rules with multiple labels in\nthe head is particularly challenging, as the number of label combinations which\nmust be taken into account for each rule grows exponentially with the number of\navailable labels. To overcome this limitation, algorithms for exhaustive rule\nmining typically use properties such as anti-monotonicity or decomposability in\norder to prune the search space. In the present paper, we examine whether\ncommonly used multi-label evaluation metrics satisfy these properties and\ntherefore are suited to prune the search space for multi-label heads.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 12:34:35 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Rapp", "Michael", ""], ["Menc\u00eda", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1812.06834", "submitter": "Yoon Kim", "authors": "Yoon Kim, Sam Wiseman, Alexander M. Rush", "title": "A Tutorial on Deep Latent Variable Models of Natural Language", "comments": "EMNLP 2018 Tutorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent, exciting work on combining the complementary\nstrengths of latent variable models and deep learning. Latent variable modeling\nmakes it easy to explicitly specify model constraints through conditional\nindependence properties, while deep learning makes it possible to parameterize\nthese conditional likelihoods with powerful function approximators. While these\n\"deep latent variable\" models provide a rich, flexible framework for modeling\nmany real-world phenomena, difficulties exist: deep parameterizations of\nconditional likelihoods usually make posterior inference intractable, and\nlatent variable objectives often complicate backpropagation by introducing\npoints of non-differentiability. This tutorial explores these issues in depth\nthrough the lens of variational inference.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 15:26:29 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 15:24:26 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 01:14:32 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kim", "Yoon", ""], ["Wiseman", "Sam", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1812.06855", "submitter": "Yutian Chen", "authors": "Yutian Chen, Aja Huang, Ziyu Wang, Ioannis Antonoglou, Julian\n  Schrittwieser, David Silver, Nando de Freitas", "title": "Bayesian Optimization in AlphaGo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the development of AlphaGo, its many hyper-parameters were tuned with\nBayesian optimization multiple times. This automatic tuning process resulted in\nsubstantial improvements in playing strength. For example, prior to the match\nwith Lee Sedol, we tuned the latest AlphaGo agent and this improved its\nwin-rate from 50% to 66.5% in self-play games. This tuned version was deployed\nin the final match. Of course, since we tuned AlphaGo many times during its\ndevelopment cycle, the compounded contribution was even higher than this\npercentage. It is our hope that this brief case study will be of interest to Go\nfans, and also provide Bayesian optimization practitioners with some insights\nand inspiration.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 15:52:01 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Chen", "Yutian", ""], ["Huang", "Aja", ""], ["Wang", "Ziyu", ""], ["Antonoglou", "Ioannis", ""], ["Schrittwieser", "Julian", ""], ["Silver", "David", ""], ["de Freitas", "Nando", ""]]}, {"id": "1812.06866", "submitter": "Alberto Lumbreras", "authors": "Alberto Lumbreras, Louis Filstroff, C\\'edric F\\'evotte", "title": "Bayesian Mean-parameterized Nonnegative Binary Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary data matrices can represent many types of data such as social\nnetworks, votes, or gene expression. In some cases, the analysis of binary\nmatrices can be tackled with nonnegative matrix factorization (NMF), where the\nobserved data matrix is approximated by the product of two smaller nonnegative\nmatrices. In this context, probabilistic NMF assumes a generative model where\nthe data is usually Bernoulli-distributed. Often, a link function is used to\nmap the factorization to the $[0,1]$ range, ensuring a valid Bernoulli mean\nparameter. However, link functions have the potential disadvantage to lead to\nuninterpretable models. Mean-parameterized NMF, on the contrary, overcomes this\nproblem. We propose a unified framework for Bayesian mean-parameterized\nnonnegative binary matrix factorization models (NBMF). We analyze three models\nwhich correspond to three possible constraints that respect the\nmean-parametrization without the need for link functions. Furthermore, we\nderive a novel collapsed Gibbs sampler and a collapsed variational algorithm to\ninfer the posterior distribution of the factors. Next, we extend the proposed\nmodels to a nonparametric setting where the number of used latent dimensions is\nautomatically driven by the observed data. We analyze the performance of our\nNBMF methods in multiple datasets for different tasks such as dictionary\nlearning and prediction of missing data. Experiments show that our methods\nprovide similar or superior results than the state of the art, while\nautomatically detecting the number of relevant components.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 16:08:21 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 12:36:19 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 17:07:15 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Lumbreras", "Alberto", ""], ["Filstroff", "Louis", ""], ["F\u00e9votte", "C\u00e9dric", ""]]}, {"id": "1812.06869", "submitter": "Alexey Gritsenko", "authors": "Alexey A. Gritsenko, Alex D'Amour, James Atwood, Yoni Halpern, D.\n  Sculley", "title": "BriarPatches: Pixel-Space Interventions for Inducing Demographic Parity", "comments": "6 pages, 5 figures, NeurIPS Workshop on Ethical, Social and\n  Governance Issues in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the BriarPatch, a pixel-space intervention that obscures\nsensitive attributes from representations encoded in pre-trained classifiers.\nThe patches encourage internal model representations not to encode sensitive\ninformation, which has the effect of pushing downstream predictors towards\nexhibiting demographic parity with respect to the sensitive information. The\nnet result is that these BriarPatches provide an intervention mechanism\navailable at user level, and complements prior research on fair representations\nthat were previously only applicable by model developers and ML experts.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 16:13:42 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Gritsenko", "Alexey A.", ""], ["D'Amour", "Alex", ""], ["Atwood", "James", ""], ["Halpern", "Yoni", ""], ["Sculley", "D.", ""]]}, {"id": "1812.06900", "submitter": "Alexandre Emerick", "authors": "Smith W. A. Canchumuni, Alexandre A. Emerick, Marco Aur\\'elio C.\n  Pacheco", "title": "Towards a Robust Parameterization for Conditioning Facies Models Using\n  Deep Variational Autoencoders and Ensemble Smoother", "comments": "32 pages, 24 figures", "journal-ref": null, "doi": "10.1016/j.cageo.2019.04.006", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature about history matching is vast and despite the impressive\nnumber of methods proposed and the significant progresses reported in the last\ndecade, conditioning reservoir models to dynamic data is still a challenging\ntask. Ensemble-based methods are among the most successful and efficient\ntechniques currently available for history matching. These methods are usually\nable to achieve reasonable data matches, especially if an iterative formulation\nis employed. However, they sometimes fail to preserve the geological realism of\nthe model, which is particularly evident in reservoir with complex facies\ndistributions. This occurs mainly because of the Gaussian assumptions inherent\nin these methods. This fact has encouraged an intense research activity to\ndevelop parameterizations for facies history matching. Despite the large number\nof publications, the development of robust parameterizations for facies remains\nan open problem.\n  Deep learning techniques have been delivering impressive results in a number\nof different areas and the first applications in data assimilation in\ngeoscience have started to appear in literature. The present paper reports the\ncurrent results of our investigations on the use of deep neural networks\ntowards the construction of a continuous parameterization of facies which can\nbe used for data assimilation with ensemble methods. Specifically, we use a\nconvolutional variational autoencoder and the ensemble smoother with multiple\ndata assimilation. We tested the parameterization in three synthetic\nhistory-matching problems with channelized facies. We focus on this type of\nfacies because they are among the most challenging to preserve after the\nassimilation of data. The parameterization showed promising results\noutperforming previous methods and generating well-defined channelized facies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 17:12:14 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Canchumuni", "Smith W. A.", ""], ["Emerick", "Alexandre A.", ""], ["Pacheco", "Marco Aur\u00e9lio C.", ""]]}, {"id": "1812.06905", "submitter": "Alessio Zappone", "authors": "Alessio Zappone and Luca Sanguinetti and Merouane Debbah", "title": "User Association and Load Balancing for Massive MIMO through Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the use of deep learning to perform user cell\nassociation for sum-rate maximization in Massive MIMO networks. It is shown how\na deep neural network can be trained to approach the optimal association rule\nwith a much more limited computational complexity, thus enabling to update the\nassociation rule in real-time, on the basis of the mobility patterns of users.\nIn particular, the proposed neural network design requires as input only the\nusers' geographical positions. Numerical results show that it guarantees the\nsame performance of traditional optimization-oriented methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 17:26:16 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Zappone", "Alessio", ""], ["Sanguinetti", "Luca", ""], ["Debbah", "Merouane", ""]]}, {"id": "1812.06920", "submitter": "Bho Matthiesen", "authors": "Bho Matthiesen, Alessio Zappone, Karl-L. Besser, Eduard A. Jorswieck,\n  Merouane Debbah", "title": "A Globally Optimal Energy-Efficient Power Control Framework and its\n  Efficient Implementation in Wireless Interference Networks", "comments": "submitted", "journal-ref": "IEEE Transactions on Signal Processing, Vol. 68, pp. 3887-3902,\n  Jun. 2020", "doi": "10.1109/TSP.2020.3000328", "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops a novel power control framework for energy-efficient power\ncontrol in wireless networks. The proposed method is a new branch-and-bound\nprocedure based on problem-specific bounds for energy-efficiency maximization\nthat allow for faster convergence. This enables to find the global solution for\nall of the most common energy-efficient power control problems with a\ncomplexity that, although still exponential in the number of variables, is much\nlower than other available global optimization frameworks. Moreover, the\nreduced complexity of the proposed framework allows its practical\nimplementation through the use of deep neural networks. Specifically, thanks to\nits reduced complexity, the proposed method can be used to train an artificial\nneural network to predict the optimal resource allocation. This is in contrast\nwith other power control methods based on deep learning, which train the neural\nnetwork based on suboptimal power allocations due to the large complexity that\ngenerating large training sets of optimal power allocations would have with\navailable global optimization methods. As a benchmark, we also develop a novel\nfirst-order optimal power allocation algorithm. Numerical results show that a\nneural network can be trained to predict the optimal power allocation policy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 17:42:25 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 18:49:03 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Matthiesen", "Bho", ""], ["Zappone", "Alessio", ""], ["Besser", "Karl-L.", ""], ["Jorswieck", "Eduard A.", ""], ["Debbah", "Merouane", ""]]}, {"id": "1812.06932", "submitter": "Kathleen M Lewis", "authors": "Kathleen M. Lewis and Natalia S. Rost and John Guttag and Adrian V.\n  Dalca", "title": "Fast Learning-based Registration of Sparse 3D Clinical Images", "comments": "This version was accepted to CHIL. It builds on the previous version\n  of the paper and includes more experimental results", "journal-ref": null, "doi": "10.1145/3368555.3384462", "report-no": null, "categories": "cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SparseVM, a method that registers clinical-quality 3D MR scans\nboth faster and more accurately than previously possible. Deformable alignment,\nor registration, of clinical scans is a fundamental task for many clinical\nneuroscience studies. However, most registration algorithms are designed for\nhigh-resolution research-quality scans. In contrast to research-quality scans,\nclinical scans are often sparse, missing up to 86% of the slices available in\nresearch-quality scans. Existing methods for registering these sparse images\nare either inaccurate or extremely slow. We present a learning-based\nregistration method, SparseVM, that is more accurate and orders of magnitude\nfaster than the most accurate clinical registration methods. To our knowledge,\nit is the first method to use deep learning specifically tailored to\nregistering clinical images. We demonstrate our method on a clinically-acquired\nMRI dataset of stroke patients and on a simulated sparse MRI dataset. Our code\nis available as part of the VoxelMorph package at http://voxelmorph.mit.edu/.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 18:14:24 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 15:43:29 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 13:45:39 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lewis", "Kathleen M.", ""], ["Rost", "Natalia S.", ""], ["Guttag", "John", ""], ["Dalca", "Adrian V.", ""]]}, {"id": "1812.06944", "submitter": "Elif Vural", "authors": "Elif Vural", "title": "Domain Adaptation on Graphs by Learning Graph Topologies: Theoretical\n  Analysis and an Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine learning algorithms assume that the training and test\ndata have the same distribution, while this assumption does not necessarily\nhold in real applications. Domain adaptation methods take into account the\ndeviations in the data distribution. In this work, we study the problem of\ndomain adaptation on graphs. We consider a source graph and a target graph\nconstructed with samples drawn from data manifolds. We study the problem of\nestimating the unknown class labels on the target graph using the label\ninformation on the source graph and the similarity between the two graphs. We\nparticularly focus on a setting where the target label function is learnt such\nthat its spectrum is similar to that of the source label function. We first\npropose a theoretical analysis of domain adaptation on graphs and present\nperformance bounds that characterize the target classification error in terms\nof the properties of the graphs and the data manifolds. We show that the\nclassification performance improves as the topologies of the graphs get more\nbalanced, i.e., as the numbers of neighbors of different graph nodes become\nmore proportionate, and weak edges with small weights are avoided. Our results\nalso suggest that graph edges between too distant data samples should be\navoided for good generalization performance. We then propose a graph domain\nadaptation algorithm inspired by our theoretical findings, which estimates the\nlabel functions while learning the source and target graph topologies at the\nsame time. The joint graph learning and label estimation problem is formulated\nthrough an objective function relying on our performance bounds, which is\nminimized with an alternating optimization scheme. Experiments on synthetic and\nreal data sets suggest that the proposed method outperforms baseline\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 18:30:35 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 16:16:42 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Vural", "Elif", ""]]}, {"id": "1812.06968", "submitter": "Michael Perlmutter", "authors": "Michael Perlmutter, Guy Wolf, and Matthew Hirn", "title": "Geometric Scattering on Manifolds", "comments": "A shorter version of this paper appeared in the NeurIPS 2018\n  Integration of Deep Learning Theories Workshop, Montr\\'{e}al, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean scattering transform was introduced nearly a decade ago to\nimprove the mathematical understanding of the success of convolutional neural\nnetworks (ConvNets) in image data analysis and other tasks. Inspired by recent\ninterest in geometric deep learning, which aims to generalize ConvNets to\nmanifold and graph-structured domains, we generalize the scattering transform\nto compact manifolds. Similar to the Euclidean scattering transform, our\ngeometric scattering transform is based on a cascade of designed filters and\npointwise nonlinearities, which enables rigorous analysis of the feature\nextraction provided by scattering layers. Our main focus here is on theoretical\nunderstanding of this geometric scattering network, while setting aside\nimplementation aspects, although we remark that application of similar\ntransforms to graph data analysis has been studied recently in related work.\nOur results establish conditions under which geometric scattering provides\nlocalized isometry invariant descriptions of manifold signals, which are also\nstable to families of diffeomorphisms formulated in intrinsic manifolds terms.\nThese results not only generalize the deformation stability and local\nroto-translation invariance of Euclidean scattering, but also demonstrate the\nimportance of linking the used filter structures (e.g., in geometric deep\nlearning) to the underlying manifold geometry, or the data geometry it\nrepresents.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 23:13:59 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 15:00:00 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 04:41:39 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 01:37:56 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Perlmutter", "Michael", ""], ["Wolf", "Guy", ""], ["Hirn", "Matthew", ""]]}, {"id": "1812.07010", "submitter": "Mark Kozdoba", "authors": "Mark Kozdoba, Edward Moroshko, Lior Shani, Takuya Takagi, Takashi\n  Katoh, Shie Mannor, Koby Crammer", "title": "Multi Instance Learning For Unbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Multi Instance Learning, we analyze the Single Instance\n(SI) learning objective. We show that when the data is unbalanced and the\nfamily of classifiers is sufficiently rich, the SI method is a useful learning\nalgorithm. In particular, we show that larger data imbalance, a quality that is\ntypically perceived as negative, in fact implies a better resilience of the\nalgorithm to the statistical dependencies of the objects in bags. In addition,\nour results shed new light on some known issues with the SI method in the\nsetting of linear classifiers, and we show that these issues are significantly\nless likely to occur in the setting of neural networks. We demonstrate our\nresults on a synthetic dataset, and on the COCO dataset for the problem of\npatch classification with weak image level labels derived from captions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 19:28:30 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Kozdoba", "Mark", ""], ["Moroshko", "Edward", ""], ["Shani", "Lior", ""], ["Takagi", "Takuya", ""], ["Katoh", "Takashi", ""], ["Mannor", "Shie", ""], ["Crammer", "Koby", ""]]}, {"id": "1812.07035", "submitter": "Yi Zhou", "authors": "Yi Zhou, Connelly Barnes, Jingwan Lu, Jimei Yang, Hao Li", "title": "On the Continuity of Rotation Representations in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural networks, it is often desirable to work with various\nrepresentations of the same space. For example, 3D rotations can be represented\nwith quaternions or Euler angles. In this paper, we advance a definition of a\ncontinuous representation, which can be helpful for training deep neural\nnetworks. We relate this to topological concepts such as homeomorphism and\nembedding. We then investigate what are continuous and discontinuous\nrepresentations for 2D, 3D, and n-dimensional rotations. We demonstrate that\nfor 3D rotations, all representations are discontinuous in the real Euclidean\nspaces of four or fewer dimensions. Thus, widely used representations such as\nquaternions and Euler angles are discontinuous and difficult for neural\nnetworks to learn. We show that the 3D rotations have continuous\nrepresentations in 5D and 6D, which are more suitable for learning. We also\npresent continuous representations for the general case of the n-dimensional\nrotation group SO(n). While our main focus is on rotations, we also show that\nour constructions apply to other groups such as the orthogonal group and\nsimilarity transforms. We finally present empirical results, which show that\nour continuous rotation representations outperform discontinuous ones for\nseveral practical problems in graphics and vision, including a simple\nautoencoder sanity test, a rotation estimator for 3D point clouds, and an\ninverse kinematics solver for 3D human poses.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 20:13:17 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 03:45:06 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 01:05:17 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 21:29:08 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zhou", "Yi", ""], ["Barnes", "Connelly", ""], ["Lu", "Jingwan", ""], ["Yang", "Jimei", ""], ["Li", "Hao", ""]]}, {"id": "1812.07051", "submitter": "Alona Golts", "authors": "Alona Golts, Daniel Freedman, Michael Elad", "title": "Unsupervised Single Image Dehazing Using Dark Channel Prior Loss", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2019.2952032", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single image dehazing is a critical stage in many modern-day autonomous\nvision applications. Early prior-based methods often involved a time-consuming\nminimization of a hand-crafted energy function. Recent learning-based\napproaches utilize the representational power of deep neural networks (DNNs) to\nlearn the underlying transformation between hazy and clear images. Due to\ninherent limitations in collecting matching clear and hazy images, these\nmethods resort to training on synthetic data; constructed from indoor images\nand corresponding depth information. This may result in a possible domain shift\nwhen treating outdoor scenes. We propose a completely unsupervised method of\ntraining via minimization of the well-known, Dark Channel Prior (DCP) energy\nfunction. Instead of feeding the network with synthetic data, we solely use\nreal-world outdoor images and tune the network's parameters by directly\nminimizing the DCP. Although our \"Deep DCP\" technique can be regarded as a fast\napproximator of DCP, it actually improves its results significantly. This\nsuggests an additional regularization obtained via the network and learning\nprocess. Experiments show that our method performs on par with large-scale\nsupervised methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 11:29:38 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 11:40:23 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Golts", "Alona", ""], ["Freedman", "Daniel", ""], ["Elad", "Michael", ""]]}, {"id": "1812.07060", "submitter": "Alexey Kruglov", "authors": "Alexey Kruglov", "title": "Channel-wise pruning of neural networks with tapering resource\n  constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning is an important step in design process of efficient\nneural networks for edge devices with limited computational power. Pruning is a\nform of knowledge transfer from the weights of the original network to a\nsmaller target subnetwork. We propose a new method for compute-constrained\nstructured channel-wise pruning of convolutional neural networks. The method\niteratively fine-tunes the network, while gradually tapering the computation\nresources available to the pruned network via a holonomic constraint in the\nmethod of Lagrangian multipliers framework. An explicit and adaptive automatic\ncontrol over the rate of tapering is provided. The trainable parameters of our\npruning method are separate from the weights of the neural network, which\nallows us to avoid the interference with the neural network solver (e.g. avoid\nthe direct dependence of pruning speed on neural network learning rates). Our\nmethod combines the `rigoristic' approach by the direct application of\nconstrained optimization, avoiding the pitfalls of ADMM-based methods, like\ntheir need to define the target amount of resources for each pruning run, and\ndirect dependence of pruning speed and priority of pruning on the relative\nscale of weights between layers. For VGG-16 @ ILSVRC-2012, we achieve reduction\nof 15.47 -> 3.87 GMAC with only 1% top-1 accuracy reduction (68.4% -> 67.4%).\nFor AlexNet @ ILSVRC-2012, we achieve 0.724 -> 0.411 GMAC with 1% top-1\naccuracy reduction (56.8% -> 55.8%).\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 10:41:09 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Kruglov", "Alexey", ""]]}, {"id": "1812.07066", "submitter": "Rohit Kannan", "authors": "Rohit Kannan and James Luedtke", "title": "A stochastic approximation method for approximating the efficient\n  frontier of chance-constrained nonlinear programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic approximation method for approximating the efficient\nfrontier of chance-constrained nonlinear programs. Our approach is based on a\nbi-objective viewpoint of chance-constrained programs that seeks solutions on\nthe efficient frontier of optimal objective value versus risk of constraint\nviolation. To this end, we construct a reformulated problem whose objective is\nto minimize the probability of constraints violation subject to deterministic\nconvex constraints (which includes a bound on the objective function value). We\nadapt existing smoothing-based approaches for chance-constrained problems to\nderive a convergent sequence of smooth approximations of our reformulated\nproblem, and apply a projected stochastic subgradient algorithm to solve it. In\ncontrast with exterior sampling-based approaches (such as sample average\napproximation) that approximate the original chance-constrained program with\none having finite support, our proposal converges to stationary solutions of a\nsmooth approximation of the original problem, thereby avoiding poor local\nsolutions that may be an artefact of a fixed sample. Our proposal also includes\na tailored implementation of the smoothing-based approach that chooses key\nalgorithmic parameters based on problem data. Computational results on four\ntest problems from the literature indicate that our proposed approach can\nefficiently determine good approximations of the efficient frontier.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 21:47:41 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 16:37:22 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 06:32:36 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Kannan", "Rohit", ""], ["Luedtke", "James", ""]]}, {"id": "1812.07071", "submitter": "Ari Azarafrooz", "authors": "Ari Azarafrooz, John Brock", "title": "Fuzzy Hashing as Perturbation-Consistent Adversarial Kernel Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": "AICS/2019/05", "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the similarity of two files is an important task in malware\nanalysis, with fuzzy hash functions being a popular approach. Traditional fuzzy\nhash functions are data agnostic: they do not learn from a particular dataset\nhow to determine similarity; their behavior is fixed across all datasets. In\nthis paper, we demonstrate that fuzzy hash functions can be learned in a novel\nminimax training framework and that these learned fuzzy hash functions\noutperform traditional fuzzy hash functions at the file similarity task for\nPortable Executable files. In our approach, hash digests can be extracted from\nthe kernel embeddings of two kernel networks, trained in a minimax framework,\nwhere the roles of players during training (i.e adversary versus generator)\nalternate along with the input data. We refer to this new minimax architecture\nas perturbation-consistent. The similarity score for a pair of files is the\nutility of the minimax game in equilibrium. Our experiments show that learned\nfuzzy hash functions generalize well, capable of determining that two files are\nsimilar even when one of those files was generated using insertion and deletion\noperations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 22:02:41 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Azarafrooz", "Ari", ""], ["Brock", "John", ""]]}, {"id": "1812.07101", "submitter": "Sourya Sengupta", "authors": "Sourya Sengupta, Amitojdeep Singh, Henry A.Leopold, Tanmay Gulati,\n  Vasudevan Lakshminarayanan", "title": "Application of Deep Learning in Fundus Image Processing for Ophthalmic\n  Diagnosis -- A Review", "comments": null, "journal-ref": "Artificial Intelligence in Medicine Volume 102, January 2020,\n  101758", "doi": "10.1016/j.artmed.2019.101758", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An overview of the applications of deep learning in ophthalmic diagnosis\nusing retinal fundus images is presented. We also review various retinal image\ndatasets that can be used for deep learning purposes. Applications of deep\nlearning for segmentation of optic disk, blood vessels and retinal layer as\nwell as detection of lesions are reviewed. Recent deep learning models for\nclassification of diseases such as age-related macular degeneration,\nglaucoma,diabetic macular edema and diabetic retinopathy are also reported.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 05:57:17 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 01:59:58 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 19:57:45 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Sengupta", "Sourya", ""], ["Singh", "Amitojdeep", ""], ["Leopold", "Henry A.", ""], ["Gulati", "Tanmay", ""], ["Lakshminarayanan", "Vasudevan", ""]]}, {"id": "1812.07102", "submitter": "Edward Lee", "authors": "Liyue Shen, Katie Shpanskaya, Edward Lee, Emily McKenna, Maryam\n  Maleki, Quin Lu, Safwan Halabi, John Pauly, and Kristen Yeom", "title": "Deep Learning with Attention to Predict Gestational Age of the Fetal\n  Brain", "comments": "NIPS Machine Learning for Health Workshop 2018, spotlight\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fetal brain imaging is a cornerstone of prenatal screening and early\ndiagnosis of congenital anomalies. Knowledge of fetal gestational age is the\nkey to the accurate assessment of brain development. This study develops an\nattention-based deep learning model to predict gestational age of the fetal\nbrain. The proposed model is an end-to-end framework that combines key insights\nfrom multi-view MRI including axial, coronal, and sagittal views. The model\nalso uses age-activated weakly-supervised attention maps to enable\nrotation-invariant localization of the fetal brain among background noise. We\nevaluate our methods on the collected fetal brain MRI cohort with a large age\ndistribution from 125 to 273 days. Our extensive experiments show age\nprediction performance with R2 = 0.94 using multi-view MRI and attention.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 09:30:11 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Shen", "Liyue", ""], ["Shpanskaya", "Katie", ""], ["Lee", "Edward", ""], ["McKenna", "Emily", ""], ["Maleki", "Maryam", ""], ["Lu", "Quin", ""], ["Halabi", "Safwan", ""], ["Pauly", "John", ""], ["Yeom", "Kristen", ""]]}, {"id": "1812.07103", "submitter": "Omar Mohammed", "authors": "Omar Mohammed, Gerard Bailly, Damien Pellier", "title": "Style Transfer and Extraction for the Handwritten Letters Using Deep\n  Learning", "comments": "Accepted in ICAART 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we learn, transfer and extract handwriting styles using deep neural\nnetworks? This paper explores these questions using a deep conditioned\nautoencoder on the IRON-OFF handwriting data-set. We perform three experiments\nthat systematically explore the quality of our style extraction procedure.\nFirst, We compare our model to handwriting benchmarks using multidimensional\nperformance metrics. Second, we explore the quality of style transfer, i.e. how\nthe model performs on new, unseen writers. In both experiments, we improve the\nmetrics of state of the art methods by a large margin. Lastly, we analyze the\nlatent space of our model, and we see that it separates consistently writing\nstyles.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 13:38:46 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Mohammed", "Omar", ""], ["Bailly", "Gerard", ""], ["Pellier", "Damien", ""]]}, {"id": "1812.07110", "submitter": "Am\u00e9rico Oliveira", "authors": "Am\\'erico Oliveira, S\\'ergio Pereira, Carlos A. Silva", "title": "Retinal vessel segmentation based on Fully Convolutional Neural Networks", "comments": "Support repository for this work:\n  https://github.com/americofmoliveira/VesselSegmentation_ESWA", "journal-ref": "Expert Systems with Applications Volume 112, 1 December 2018,\n  Pages 229-242", "doi": "10.1016/j.eswa.2018.06.034", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The retinal vascular condition is a reliable biomarker of several\nophthalmologic and cardiovascular diseases, so automatic vessel segmentation\nmay be crucial to diagnose and monitor them. In this paper, we propose a novel\nmethod that combines the multiscale analysis provided by the Stationary Wavelet\nTransform with a multiscale Fully Convolutional Neural Network to cope with the\nvarying width and direction of the vessel structure in the retina. Our proposal\nuses rotation operations as the basis of a joint strategy for both data\naugmentation and prediction, which allows us to explore the information learned\nduring training to refine the segmentation. The method was evaluated on three\npublicly available databases, achieving an average accuracy of 0.9576, 0.9694,\nand 0.9653, and average area under the ROC curve of 0.9821, 0.9905, and 0.9855\non the DRIVE, STARE, and CHASE_DB1 databases, respectively. It also appears to\nbe robust to the training set and to the inter-rater variability, which shows\nits potential for real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 00:14:27 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 23:01:03 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Oliveira", "Am\u00e9rico", ""], ["Pereira", "S\u00e9rgio", ""], ["Silva", "Carlos A.", ""]]}, {"id": "1812.07135", "submitter": "Chun-Ming Lai", "authors": "Yu-Cheng Lin, Chun-Ming Lai, S. Felix Wu and George A. Barnett", "title": "Globalness Detection in Online Social Network", "comments": "6 pages, to be appeared in IEEE International Conference on Semantic\n  Computing (ICSC2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification problems have made significant progress due to the maturity of\nartificial intelligence (AI). However, differentiating items from categories\nwithout noticeable boundaries is still a huge challenge for machines -- which\nis also crucial for machines to be intelligent.\n  In order to study the fuzzy concept on classification, we define and propose\na globalness detection with the four-stage operational flow. We then\ndemonstrate our framework on Facebook public pages inter-like graph with their\ngeo-location. Our prediction algorithm achieves high precision (89%) and recall\n(88%) of local pages. We evaluate the results on both states and countries\nlevel, finding that the global node ratios are relatively high in those states\n(NY, CA) having large and international cities. Several global nodes examples\nhave also been shown and studied in this paper.\n  It is our hope that our results unveil the perfect value from every\nclassification problem and provide a better understanding of global and local\nnodes in Online Social Networks (OSNs).\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 02:06:46 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Lin", "Yu-Cheng", ""], ["Lai", "Chun-Ming", ""], ["Wu", "S. Felix", ""], ["Barnett", "George A.", ""]]}, {"id": "1812.07136", "submitter": "Yasuhiro Ikeda", "authors": "Yasuhiro Ikeda, Keisuke Ishibashi, Yuusuke Nakano, Keishiro Watanabe,\n  Ryoichi Kawahara", "title": "Anomaly Detection and Interpretation using Multimodal Autoencoder and\n  Sparse Optimization", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated anomaly detection is essential for managing information and\ncommunications technology (ICT) systems to maintain reliable services with\nminimum burden on operators. For detecting varying and continually emerging\nanomalies as differences from normal states, learning normal relationships\ninherent among cross-domain data monitored from ICT systems is essential.\nDeep-learning-based anomaly detection using an autoencoder (AE) is therefore\npromising for such complicated learning; however, its interpretation is still\nproblematic. Since the dimensions of the input data contributing to the\ndetected anomaly are not directly indicated in an AE, they are not suitable for\nlocalizing anomalies in large ICT systems composed of a huge amount of\nequipment. We propose an algorithm using sparse optimization for estimating\ncontributing dimensions to anomalies detected with AEs. We also propose a\nmultimodal AE (MAE) for effectively learning the relationships among\ncross-domain data, which can induce nonlinearity and differences in\nlearnability among data types. We evaluated our algorithms with several\ndatasets including real measured data in comparison with conventional\nalgorithms and confirmed the superiority of our estimation algorithm in\nspecifying contributing dimensions of anomalous data and our MAE in detecting\nanomalies in cross-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 02:26:18 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Ikeda", "Yasuhiro", ""], ["Ishibashi", "Keisuke", ""], ["Nakano", "Yuusuke", ""], ["Watanabe", "Keishiro", ""], ["Kawahara", "Ryoichi", ""]]}, {"id": "1812.07142", "submitter": "Karan Aggarwal", "authors": "Karan Aggarwal, Onur Atan, Ahmed Farahat, Chi Zhang, Kosta Ristovski,\n  and Chetan Gupta", "title": "Two Birds with One Network: Unifying Failure Event Prediction and\n  Time-to-failure Modeling", "comments": "Accepted at IEEE International Conference on BigData 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key challenges in predictive maintenance is to predict the\nimpending downtime of an equipment with a reasonable prediction horizon so that\ncountermeasures can be put in place. Classically, this problem has been posed\nin two different ways which are typically solved independently: (1) Remaining\nuseful life (RUL) estimation as a long-term prediction task to estimate how\nmuch time is left in the useful life of the equipment and (2) Failure\nprediction (FP) as a short-term prediction task to assess the probability of a\nfailure within a pre-specified time window. As these two tasks are related,\nperforming them separately is sub-optimal and might results in inconsistent\npredictions for the same equipment. In order to alleviate these issues, we\npropose two methods: Deep Weibull model (DW-RNN) and multi-task learning\n(MTL-RNN). DW-RNN is able to learn the underlying failure dynamics by fitting\nWeibull distribution parameters using a deep neural network, learned with a\nsurvival likelihood, without training directly on each task. While DW-RNN makes\nan explicit assumption on the data distribution, MTL-RNN exploits the implicit\nrelationship between the long-term RUL and short-term FP tasks to learn the\nunderlying distribution. Additionally, both our methods can leverage the\nnon-failed equipment data for RUL estimation. We demonstrate that our methods\nconsistently outperform baseline RUL methods that can be used for FP while\nproducing consistent results for RUL and FP. We also show that our methods\nperform at par with baselines trained on the objectives optimized for either of\nthe two tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 02:46:09 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Aggarwal", "Karan", ""], ["Atan", "Onur", ""], ["Farahat", "Ahmed", ""], ["Zhang", "Chi", ""], ["Ristovski", "Kosta", ""], ["Gupta", "Chetan", ""]]}, {"id": "1812.07150", "submitter": "Mandana Hamidi-Haines", "authors": "Mandana Hamidi-Haines, Zhongang Qi, Alan Fern, Fuxin Li, Prasad\n  Tadepalli", "title": "Interactive Naming for Explaining Deep Neural Networks: A Formative\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of explaining the decisions of deep neural networks\nfor image recognition in terms of human-recognizable visual concepts. In\nparticular, given a test set of images, we aim to explain each classification\nin terms of a small number of image regions, or activation maps, which have\nbeen associated with semantic concepts by a human annotator. This allows for\ngenerating summary views of the typical reasons for classifications, which can\nhelp build trust in a classifier and/or identify example types for which the\nclassifier may not be trusted. For this purpose, we developed a user interface\nfor \"interactive naming,\" which allows a human annotator to manually cluster\nsignificant activation maps in a test set into meaningful groups called \"visual\nconcepts\". The main contribution of this paper is a systematic study of the\nvisual concepts produced by five human annotators using the interactive naming\ninterface. In particular, we consider the adequacy of the concepts for\nexplaining the classification of test-set images, correspondence of the\nconcepts to activations of individual neurons, and the inter-annotator\nagreement of visual concepts. We find that a large fraction of the activation\nmaps have recognizable visual concepts, and that there is significant agreement\nbetween the different annotators about their denotations. Our work is an\nexploratory study of the interplay between machine learning and human\nrecognition mediated by visualizations of the results of learning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 03:31:09 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 05:30:17 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Hamidi-Haines", "Mandana", ""], ["Qi", "Zhongang", ""], ["Fern", "Alan", ""], ["Li", "Fuxin", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1812.07159", "submitter": "Dhruv Ramani", "authors": "Dhruv Ramani, Samarjit Karmakar, Anirban Panda, Asad Ahmed, Pratham\n  Tangri", "title": "Autoencoder Based Architecture For Fast & Real Time Audio Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been great interest in the field of audio style transfer,\nwhere a stylized audio is generated by imposing the style of a reference audio\non the content of a target audio. We improve on the current approaches which\nuse neural networks to extract the content and the style of the audio signal\nand propose a new autoencoder based architecture for the task. This network\ngenerates a stylized audio for a content audio in a single forward pass. The\nproposed network architecture proves to be advantageous over the quality of\naudio produced and the time taken to train the network. The network is\nexperimented on speech signals to confirm the validity of our proposal.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 04:04:38 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 15:30:16 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ramani", "Dhruv", ""], ["Karmakar", "Samarjit", ""], ["Panda", "Anirban", ""], ["Ahmed", "Asad", ""], ["Tangri", "Pratham", ""]]}, {"id": "1812.07172", "submitter": "Risto Vuorio", "authors": "Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim", "title": "Toward Multimodal Model-Agnostic Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learners such as MAML are able to learn a meta-prior from\nsimilar tasks to adapt to novel tasks from the same distribution with few\ngradient updates. One important limitation of such frameworks is that they seek\na common initialization shared across the entire task distribution,\nsubstantially limiting the diversity of the task distributions that they are\nable to learn from. In this paper, we augment MAML with the capability to\nidentify tasks sampled from a multimodal task distribution and adapt quickly\nthrough gradient updates. Specifically, we propose a multimodal MAML algorithm\nthat is able to modulate its meta-learned prior according to the identified\ntask, allowing faster adaptation. We evaluate the proposed model on a diverse\nset of problems including regression, few-shot image classification, and\nreinforcement learning. The results demonstrate the effectiveness of our model\nin modulating the meta-learned prior in response to the characteristics of\ntasks sampled from a multimodal distribution.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 05:08:54 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Vuorio", "Risto", ""], ["Sun", "Shao-Hua", ""], ["Hu", "Hexiang", ""], ["Lim", "Joseph J.", ""]]}, {"id": "1812.07201", "submitter": "Valentin Emiya", "authors": "Farah Cherfaoui (QARMA), Valentin Emiya (QARMA), Liva Ralaivola\n  (QARMA), Sandrine Anthoine (I2M)", "title": "Frank-Wolfe Algorithm for the Exact Sparse Problem", "comments": null, "journal-ref": "iTWIST: international Traveling Workshop on Interactions between\n  low-complexity data models and Sensing Techniques, Nov 2018, Marseille,\n  France. https://sites.google.com/view/itwist18", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the properties of the Frank-Wolfe algorithm to solve\nthe \\ExactSparse reconstruction problem. We prove that when the dictionary is\nquasi-incoherent, at each iteration, the Frank-Wolfe algorithm picks up an atom\nindexed by the support. We also prove that when the dictionary is\nquasi-incoherent, there exists an iteration beyond which the algorithm\nconverges exponentially fast.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 07:15:21 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Cherfaoui", "Farah", "", "QARMA"], ["Emiya", "Valentin", "", "QARMA"], ["Ralaivola", "Liva", "", "QARMA"], ["Anthoine", "Sandrine", "", "I2M"]]}, {"id": "1812.07210", "submitter": "Sebastian Caldas", "authors": "Sebastian Caldas, Jakub Kone\\v{c}n\\`y, H. Brendan McMahan and Ameet\n  Talwalkar", "title": "Expanding the Reach of Federated Learning by Reducing Client Resource\n  Requirements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication on heterogeneous edge networks is a fundamental bottleneck in\nFederated Learning (FL), restricting both model capacity and user\nparticipation. To address this issue, we introduce two novel strategies to\nreduce communication costs: (1) the use of lossy compression on the global\nmodel sent server-to-client; and (2) Federated Dropout, which allows users to\nefficiently train locally on smaller subsets of the global model and also\nprovides a reduction in both client-to-server communication and local\ncomputation. We empirically show that these strategies, combined with existing\ncompression approaches for client-to-server communication, collectively provide\nup to a $14\\times$ reduction in server-to-client communication, a $1.7\\times$\nreduction in local computation, and a $28\\times$ reduction in upload\ncommunication, all without degrading the quality of the final model. We thus\ncomprehensively reduce FL's impact on client device resources, allowing higher\ncapacity models to be trained, and a more diverse set of users to be reached.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 07:31:18 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 16:01:46 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Caldas", "Sebastian", ""], ["Kone\u010dny", "Jakub", ""], ["McMahan", "H. Brendan", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1812.07238", "submitter": "Andrea Asperti", "authors": "Andrea Asperti", "title": "Sparsity in Variational Autoencoders", "comments": "An Extended Abstract of this survey will be presented at the 1st\n  International Conference on Advances in Signal Processing and Artificial\n  Intelligence (ASPAI' 2019), 20-22 March 2019, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working in high-dimensional latent spaces, the internal encoding of data in\nVariational Autoencoders becomes naturally sparse. We discuss this known but\ncontroversial phenomenon sometimes refereed to as overpruning, to emphasize the\nunder-use of the model capacity. In fact, it is an important form of\nself-regularization, with all the typical benefits associated with sparsity: it\nforces the model to focus on the really important features, highly reducing the\nrisk of overfitting. Especially, it is a major methodological guide for the\ncorrect tuning of the model capacity, progressively augmenting it to attain\nsparsity, or conversely reducing the dimension of the network removing links to\nzeroed out neurons. The degree of sparsity crucially depends on the network\narchitecture: for instance, convolutional networks typically show less\nsparsity, likely due to the tighter relation of features to different spatial\nregions of the input.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 08:47:40 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 16:18:07 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 08:54:50 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Asperti", "Andrea", ""]]}, {"id": "1812.07319", "submitter": "Johannes Hendriks", "authors": "J.N. Hendriks, C. Jidling, A. Wills and T.B. Sch\\\"on", "title": "Evaluating the squared-exponential covariance function in Gaussian\n  processes with integral observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the evaluation of double line integrals of the squared\nexponential covariance function. We propose a new approach in which the double\nintegral is reduced to a single integral using the error function. This single\nintegral is then computed with efficiently implemented numerical techniques.\nThe performance is compared against existing state of the art methods and the\nresults show superior properties in numerical robustness and accuracy per\ncomputation time.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 12:04:56 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Hendriks", "J. N.", ""], ["Jidling", "C.", ""], ["Wills", "A.", ""], ["Sch\u00f6n", "T. B.", ""]]}, {"id": "1812.07352", "submitter": "Jyri J. Kivinen", "authors": "Joel Jaskari, Jyri J. Kivinen", "title": "A Novel Variational Autoencoder with Applications to Generative\n  Modelling, Classification, and Ordinal Regression", "comments": "The first version [v1] contains our paper submitted (on 9 February,\n  2018) to and later rejected from the Thirty-Fifth International Conference on\n  Machine Learning (ICML 2018); earlier version of the paper was submitted (on\n  13 October, 2017 [UTC]) to and later rejected from the Twenty-First\n  International Conference on Artificial Intelligence and Statistics (AISTATS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel probabilistic generative model based on the variational\nautoencoder approach. Notable aspects of our architecture are: a novel way of\nspecifying the latent variables prior, and the introduction of an ordinality\nenforcing unit. We describe how to do supervised, unsupervised and\nsemi-supervised learning, and nominal and ordinal classification, with the\nmodel. We analyze generative properties of the approach, and the classification\neffectiveness under nominal and ordinal classification, using two benchmark\ndatasets. Our results show that our model can achieve comparable results with\nrelevant baselines in both of the classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 13:21:35 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 10:33:00 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Jaskari", "Joel", ""], ["Kivinen", "Jyri J.", ""]]}, {"id": "1812.07360", "submitter": "Alberto Lumbreras", "authors": "Alberto Lumbreras, Julien Velcin, Marie Gu\\'egan, Bertrand Jouve", "title": "Non-parametric clustering over user features and latent behavioral\n  functions with dual-view mixture models", "comments": null, "journal-ref": "Lumbreras, A., Velcin, J., Gu\\'egan, M. et al. Comput Stat (2017)\n  32:145", "doi": "10.1007/s00180-016-0668-0", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dual-view mixture model to cluster users based on their features\nand latent behavioral functions. Every component of the mixture model\nrepresents a probability density over a feature view for observed user\nattributes and a behavior view for latent behavioral functions that are\nindirectly observed through user actions or behaviors. Our task is to infer the\ngroups of users as well as their latent behavioral functions. We also propose a\nnon-parametric version based on a Dirichlet Process to automatically infer the\nnumber of clusters. We test the properties and performance of the model on a\nsynthetic dataset that represents the participation of users in the threads of\nan online forum. Experiments show that dual-view models outperform single-view\nones when one of the views lacks information.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 13:44:38 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Lumbreras", "Alberto", ""], ["Velcin", "Julien", ""], ["Gu\u00e9gan", "Marie", ""], ["Jouve", "Bertrand", ""]]}, {"id": "1812.07367", "submitter": "Shujiao Huang", "authors": "Cheng Zhan, Licheng Zhang, Zhenzhen Zhong, Sher Didi-Ooi, Youzuo Lin,\n  Yunxi Zhang, Shujiao Huang, Changchun Wang", "title": "Deep Learning Approach in Automatic Iceberg - Ship Detection with SAR\n  Remote Sensing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is gaining traction with geophysics community to understand\nsubsurface structures, such as fault detection or salt body in seismic data.\nThis study describes using deep learning method for iceberg or ship recognition\nwith synthetic aperture radar (SAR) data. Drifting icebergs pose a potential\nthreat to activities offshore around the Arctic, including for both ship\nnavigation and oil rigs. Advancement of satellite imagery using\nweather-independent cross-polarized radar has enabled us to monitor and\ndelineate icebergs and ships, however a human component is needed to classify\nthe images. Here we present Transfer Learning, a convolutional neural network\n(CNN) designed to work with a limited training data and features, while\ndemonstrating its effectiveness in this problem. Key aspect of the approach is\ndata augmentation and stacking of multiple outputs, resulted in a significant\nboost in accuracy (logarithmic score of 0.1463). This algorithm has been tested\nthrough participation at the Statoil/C-Core Kaggle competition.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 16:32:40 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Zhan", "Cheng", ""], ["Zhang", "Licheng", ""], ["Zhong", "Zhenzhen", ""], ["Didi-Ooi", "Sher", ""], ["Lin", "Youzuo", ""], ["Zhang", "Yunxi", ""], ["Huang", "Shujiao", ""], ["Wang", "Changchun", ""]]}, {"id": "1812.07385", "submitter": "Arash Behboodi", "authors": "Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar", "title": "Perturbation Analysis of Learning Algorithms: A Unifying Perspective on\n  Generation of Adversarial Examples", "comments": "arXiv admin note: text overlap with arXiv:1803.03607", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous success of deep neural networks in various learning\nproblems, it has been observed that adding an intentionally designed\nadversarial perturbation to inputs of these architectures leads to erroneous\nclassification with high confidence in the prediction. In this work, we propose\na general framework based on the perturbation analysis of learning algorithms\nwhich consists of convex programming and is able to recover many current\nadversarial attacks as special cases. The framework can be used to propose\nnovel attacks against learning algorithms for classification and regression\ntasks under various new constraints with closed form solutions in many\ninstances. In particular we derive new attacks against classification\nalgorithms which are shown to achieve comparable performances to notable\nexisting attacks. The framework is then used to generate adversarial\nperturbations for regression tasks which include single pixel and single subset\nattacks. By applying this method to autoencoding and image colorization tasks,\nit is shown that adversarial perturbations can effectively perturb the output\nof regression tasks as well.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 21:48:46 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Balda", "Emilio Rafael", ""], ["Behboodi", "Arash", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1812.07390", "submitter": "Mohammad Motamedi", "authors": "Mohammad Motamedi, Felix Portillo, Daniel Fong, and Soheil Ghiasi", "title": "Distill-Net: Application-Specific Distillation of Deep Convolutional\n  Neural Networks for Resource-Constrained IoT Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Internet-of-Things (IoT) applications demand fast and accurate\nunderstanding of a few key events in their surrounding environment. Deep\nConvolutional Neural Networks (CNNs) have emerged as an effective approach to\nunderstand speech, images, and similar high dimensional data types. Algorithmic\nperformance of modern CNNs, however, fundamentally relies on learning\nclass-agnostic hierarchical features that only exist in comprehensive training\ndatasets with many classes. As a result, fast inference using CNNs trained on\nsuch datasets is prohibitive for most resource-constrained IoT platforms. To\nbridge this gap, we present a principled and practical methodology for\ndistilling a complex modern CNN that is trained to effectively recognize many\ndifferent classes of input data into an application-dependent essential core\nthat not only recognizes the few classes of interest to the application\naccurately, but also runs efficiently on platforms with limited resources.\nExperimental results confirm that our approach strikes a favorable balance\nbetween classification accuracy (application constraint), inference efficiency\n(platform constraint), and productive development of new applications (business\nconstraint).\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 02:37:03 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Motamedi", "Mohammad", ""], ["Portillo", "Felix", ""], ["Fong", "Daniel", ""], ["Ghiasi", "Soheil", ""]]}, {"id": "1812.07394", "submitter": "Zhao Chen Mr.", "authors": "Zhao Chen, Xiaodong Wang", "title": "Decentralized Computation Offloading for Multi-User Mobile Edge\n  Computing: A Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": "10.1186/s13638-020-01801-6", "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (MEC) emerges recently as a promising solution to\nrelieve resource-limited mobile devices from computation-intensive tasks, which\nenables devices to offload workloads to nearby MEC servers and improve the\nquality of computation experience. Nevertheless, by considering a MEC system\nconsisting of multiple mobile users with stochastic task arrivals and wireless\nchannels in this paper, the design of computation offloading policies is\nchallenging to minimize the long-term average computation cost in terms of\npower consumption and buffering delay. A deep reinforcement learning (DRL)\nbased decentralized dynamic computation offloading strategy is investigated to\nbuild a scalable MEC system with limited feedback. Specifically, a continuous\naction space-based DRL approach named deep deterministic policy gradient (DDPG)\nis adopted to learn efficient computation offloading policies independently at\neach mobile user. Thus, powers of both local execution and task offloading can\nbe adaptively allocated by the learned policies from each user's local\nobservation of the MEC system. Numerical results are illustrated to demonstrate\nthat efficient policies can be learned at each user, and performance of the\nproposed DDPG based decentralized strategy outperforms the conventional deep\nQ-network (DQN) based discrete power control strategy and some other greedy\nstrategies with reduced computation cost. Besides, the power-delay tradeoff is\nalso analyzed for both the DDPG based and DQN based strategies.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 22:40:03 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Zhao", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1812.07405", "submitter": "Toshihiko Matsuura", "authors": "Toshihiko Matsuura, Kuniaki Saito, Tatsuya Harada", "title": "TWINs: Two Weighted Inconsistency-reduced Networks for Partial Domain\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of unsupervised domain adaptation is proposed to transfer the\nknowledge of a label-rich domain (source domain) to a label-scarce domain\n(target domain). Matching feature distributions between different domains is a\nwidely applied method for the aforementioned task. However, the method does not\nperform well when classes in the two domains are not identical. Specifically,\nwhen the classes of the target correspond to a subset of those of the source,\ntarget samples can be incorrectly aligned with the classes that exist only in\nthe source. This problem setting is termed as partial domain adaptation (PDA).\nIn this study, we propose a novel method called Two Weighted\nInconsistency-reduced Networks (TWINs) for PDA. We utilize two classification\nnetworks to estimate the ratio of the target samples in each class with which a\nclassification loss is weighted to adapt the classes present in the target\ndomain. Furthermore, to extract discriminative features for the target, we\npropose to minimize the divergence between domains measured by the classifiers'\ninconsistency on target samples. We empirically demonstrate that reducing the\ninconsistency between two networks is effective for PDA and that our method\noutperforms other existing methods with a large margin in several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 14:49:51 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Matsuura", "Toshihiko", ""], ["Saito", "Kuniaki", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1812.07410", "submitter": "Guangyuan Pan", "authors": "Guangyuan Pan, Liping Fu, Lalita Thakali, Matthew Muresan, Ming Yu", "title": "An Improved Deep Belief Network Model for Road Safety Analyses", "comments": null, "journal-ref": "Transportation Research Board 97th Annual Meeting, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crash prediction is a critical component of road safety analyses. A widely\nadopted approach to crash prediction is application of regression based\ntechniques. The underlying calibration process is often time-consuming,\nrequiring significant domain knowledge and expertise and cannot be easily\nautomated. This paper introduces a new machine learning (ML) based approach as\nan alternative to the traditional techniques. The proposed ML model is called\nregularized deep belief network, which is a deep neural network with two\ntraining steps: it is first trained using an unsupervised learning algorithm\nand then fine-tuned by initializing a Bayesian neural network with the trained\nweights from the first step. The resulting model is expected to have improved\nprediction power and reduced need for the time-consuming human intervention. In\nthis paper, we attempt to demonstrate the potential of this new model for crash\nprediction through two case studies including a collision data set from 800 km\nstretch of Highway 401 and other highways in Ontario, Canada. Our intention is\nto show the performance of this ML approach in comparison to various\ntraditional models including negative binomial (NB) model, kernel regression\n(KR), and Bayesian neural network (Bayesian NN). We also attempt to address\nother related issues such as effect of training data size and training\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 16:02:27 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Pan", "Guangyuan", ""], ["Fu", "Liping", ""], ["Thakali", "Lalita", ""], ["Muresan", "Matthew", ""], ["Yu", "Ming", ""]]}, {"id": "1812.07452", "submitter": "Thomas Carr", "authors": "Thomas Carr, Maria Chli, George Vogiatzis", "title": "Domain Adaptation for Reinforcement Learning on the Atari", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning agents have recently been successful across a\nvariety of discrete and continuous control tasks; however, they can be slow to\ntrain and require a large number of interactions with the environment to learn\na suitable policy. This is borne out by the fact that a reinforcement learning\nagent has no prior knowledge of the world, no pre-existing data to depend on\nand so must devote considerable time to exploration. Transfer learning can\nalleviate some of the problems by leveraging learning done on some source task\nto help learning on some target task. Our work presents an algorithm for\ninitialising the hidden feature representation of the target task. We propose a\ndomain adaptation method to transfer state representations and demonstrate\ntransfer across domains, tasks and action spaces. We utilise adversarial domain\nadaptation ideas combined with an adversarial autoencoder architecture. We\nalign our new policies' representation space with a pre-trained source policy,\ntaking target task data generated from a random policy. We demonstrate that\nthis initialisation step provides significant improvement when learning a new\nreinforcement learning task, which highlights the wide applicability of\nadversarial adaptation methods; even as the task and label/action space also\nchanges.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 16:08:57 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Carr", "Thomas", ""], ["Chli", "Maria", ""], ["Vogiatzis", "George", ""]]}, {"id": "1812.07478", "submitter": "Hangyu Zhu", "authors": "Hangyu Zhu and Yaochu Jin", "title": "Multi-objective Evolutionary Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is an emerging technique used to prevent the leakage of\nprivate information. Unlike centralized learning that needs to collect data\nfrom users and store them collectively on a cloud server, federated learning\nmakes it possible to learn a global model while the data are distributed on the\nusers' devices. However, compared with the traditional centralized approach,\nthe federated setting consumes considerable communication resources of the\nclients, which is indispensable for updating global models and prevents this\ntechnique from being widely used. In this paper, we aim to optimize the\nstructure of the neural network models in federated learning using a\nmulti-objective evolutionary algorithm to simultaneously minimize the\ncommunication costs and the global model test errors. A scalable method for\nencoding network connectivity is adapted to federated learning to enhance the\nefficiency in evolving deep neural networks. Experimental results on both\nmultilayer perceptrons and convolutional neural networks indicate that the\nproposed optimization method is able to find optimized neural network models\nthat can not only significantly reduce communication costs but also improve the\nlearning performance of federated learning compared with the standard fully\nconnected neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 16:55:03 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 16:47:39 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhu", "Hangyu", ""], ["Jin", "Yaochu", ""]]}, {"id": "1812.07480", "submitter": "Ulrich Paquet", "authors": "Ulrich Paquet and Sumedh K. Ghaisas and Olivier Tieleman", "title": "A Factorial Mixture Prior for Compositional Deep Generative Models", "comments": "16 pagers, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assume that a high-dimensional datum, like an image, is a compositional\nexpression of a set of properties, with a complicated non-linear relationship\nbetween the datum and its properties. This paper proposes a factorial mixture\nprior for capturing latent properties, thereby adding structured\ncompositionality to deep generative models. The prior treats a latent vector as\nbelonging to Cartesian product of subspaces, each of which is quantized\nseparately with a Gaussian mixture model. Some mixture components can be set to\nrepresent properties as observed random variables whenever labeled properties\nare present. Through a combination of stochastic variational inference and\ngradient descent, a method for learning how to infer discrete properties in an\nunsupervised or semi-supervised way is outlined and empirically evaluated.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 16:59:23 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Paquet", "Ulrich", ""], ["Ghaisas", "Sumedh K.", ""], ["Tieleman", "Olivier", ""]]}, {"id": "1812.07484", "submitter": "Ville Hyv\\\"onen", "authors": "Elias J\\\"a\\\"asaari, Ville Hyv\\\"onen, Teemu Roos", "title": "Efficient Autotuning of Hyperparameters in Approximate Nearest Neighbor\n  Search", "comments": "Accepted for the 23rd Pacific-Asia Conference on Knowledge Discovery\n  and Data Mining (PAKDD) 2019", "journal-ref": "Advances in Knowledge Discovery and Data Mining. PAKDD 2019.\n  Lecture Notes in Computer Science, vol 11440. Springer, Cham. pp. 590-602", "doi": "10.1007/978-3-030-16145-3_46", "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate nearest neighbor algorithms are used to speed up nearest neighbor\nsearch in a wide array of applications. However, current indexing methods\nfeature several hyperparameters that need to be tuned to reach an acceptable\naccuracy--speed trade-off. A grid search in the parameter space is often\nimpractically slow due to a time-consuming index-building procedure. Therefore,\nwe propose an algorithm for automatically tuning the hyperparameters of\nindexing methods based on randomized space-partitioning trees. In particular,\nwe present results using randomized k-d trees, random projection trees and\nrandomized PCA trees. The tuning algorithm adds minimal overhead to the\nindex-building process but is able to find the optimal hyperparameters\naccurately. We demonstrate that the algorithm is significantly faster than\nexisting approaches, and that the indexing methods used are competitive with\nthe state-of-the-art methods in query time while being faster to build.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:06:05 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["J\u00e4\u00e4saari", "Elias", ""], ["Hyv\u00f6nen", "Ville", ""], ["Roos", "Teemu", ""]]}, {"id": "1812.07488", "submitter": "Lei Sun", "authors": "Lei Sun and Matthew Stephens", "title": "Solving the Empirical Bayes Normal Means Problem with Correlated Noise", "comments": "27 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Normal Means problem plays a fundamental role in many areas of modern\nhigh-dimensional statistics, both in theory and practice. And the Empirical\nBayes (EB) approach to solving this problem has been shown to be highly\neffective, again both in theory and practice. However, almost all EB treatments\nof the Normal Means problem assume that the observations are independent. In\npractice correlations are ubiquitous in real-world applications, and these\ncorrelations can grossly distort EB estimates. Here, exploiting theory from\nSchwartzman (2010), we develop new EB methods for solving the Normal Means\nproblem that take account of unknown correlations among observations. We\nprovide practical software implementations of these methods, and illustrate\nthem in the context of large-scale multiple testing problems and False\nDiscovery Rate (FDR) control. In realistic numerical experiments our methods\ncompare favorably with other commonly-used multiple testing methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:15:58 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 16:55:16 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Sun", "Lei", ""], ["Stephens", "Matthew", ""]]}, {"id": "1812.07498", "submitter": "Arijit Ukil", "authors": "Arijit Ukil, Soma Bandyopadhyay, Chetanya Puri, Rituraj Singh, Arpan\n  Pal", "title": "Class Augmented Semi-Supervised Learning for Practical Clinical\n  Analytics on Physiological Signals", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018,\n  Montreal, Canada, December, 2018", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/15", "categories": "physics.med-ph eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational analysis on physiological signals would provide immense impact\nfor enabling automated clinical analytics. However, the class imbalance issue\nwhere negative or minority class instances are rare in number impairs the\nrobustness of the practical solution. The key idea of our approach is\nintelligent augmentation of minority class examples to construct smooth,\nunbiased decision boundary for robust semi-supervised learning. This solves the\npractical class imbalance problem in anomaly detection task for computational\nclinical analytics using physiological signals. We choose two critical cardiac\nmarker physiological signals: Heart sound or Phonocardiogram (PCG) and\nElectrocardiogram (ECG) to validate our claim of robust anomaly detection of\nclinical events under augmented class learning, where intelligent synthesis of\nminority class instances attempt to balance the class distribution. We perform\nextensive experiments on publicly available expert-labelled MIT-Physionet PCG\nand ECG datasets that establish high performance merit of the proposed scheme,\nand our scheme fittingly performs better than the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 09:12:54 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Ukil", "Arijit", ""], ["Bandyopadhyay", "Soma", ""], ["Puri", "Chetanya", ""], ["Singh", "Rituraj", ""], ["Pal", "Arpan", ""]]}, {"id": "1812.07504", "submitter": "Yedid Hoshen", "authors": "Yedid Hoshen", "title": "Towards Unsupervised Single-Channel Blind Source Separation using\n  Adversarial Pair Unmix-and-Remix", "comments": "ICASSP'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind single-channel source separation is a long standing signal processing\nchallenge. Many methods were proposed to solve this task utilizing multiple\nsignal priors such as low rank, sparsity, temporal continuity etc. The recent\nadvance of generative adversarial models presented new opportunities in signal\nregression tasks. The power of adversarial training however has not yet been\nrealized for blind source separation tasks. In this work, we propose a novel\nmethod for blind source separation (BSS) using adversarial methods. We rely on\nthe independence of sources for creating adversarial constraints on pairs of\napproximately separated sources, which ensure good separation. Experiments are\ncarried out on image sources validating the good performance of our approach,\nand presenting our method as a promising approach for solving BSS for general\nsignals.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 09:27:29 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 12:12:11 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Hoshen", "Yedid", ""]]}, {"id": "1812.07505", "submitter": "Rodrigo de Lamare", "authors": "S. Pinto and R. C. de Lamare", "title": "Direction Finding Based on Multi-Step Knowledge-Aided Iterative\n  Conjugate Gradient Algorithms", "comments": "7 figures, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG cs.SD eess.AS math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present direction-of-arrival (DoA) estimation algorithms\nbased on the Krylov subspace that effectively exploit prior knowledge of the\nsignals that impinge on a sensor array. The proposed multi-step knowledge-aided\niterative conjugate gradient (CG) (MS-KAI-CG) algorithms perform subtraction of\nthe unwanted terms found in the estimated covariance matrix of the sensor data.\nFurthermore, we develop a version of MS-KAI-CG equipped with forward-backward\naveraging, called MS-KAI-CG-FB, which is appropriate for scenarios with\ncorrelated signals. Unlike current knowledge-aided methods, which take\nadvantage of known DoAs to enhance the estimation of the covariance matrix of\nthe input data, the MS-KAI-CG algorithms take advantage of the knowledge of the\nstructure of the forward-backward smoothed covariance matrix and its\ndisturbance terms. Simulations with both uncorrelated and correlated signals\nshow that the MS-KAI-CG algorithms outperform existing techniques.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 00:25:58 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Pinto", "S.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1812.07509", "submitter": "Brendon Lutnick", "authors": "Brendon Lutnick, Brandon Ginley, Darshana Govind, Sean D. McGarry,\n  Peter S. LaViolette, Rabi Yacoub, Sanjay Jain, John E. Tomaszewski, Kuang-Yu\n  Jen, and Pinaki Sarder", "title": "Iterative annotation to ease neural network training: Specialized\n  machine learning in medical image analysis", "comments": "15 pages, 7 figures, 2 supplemental figures (on the last page)", "journal-ref": "Nature Machine Intelligence 1.2 (2019): 112", "doi": "10.1038/s42256-019-0018-3", "report-no": null, "categories": "eess.IV cs.CV cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks promise to bring robust, quantitative analysis to medical\nfields, but adoption is limited by the technicalities of training these\nnetworks. To address this translation gap between medical researchers and\nneural networks in the field of pathology, we have created an intuitive\ninterface which utilizes the commonly used whole slide image (WSI) viewer,\nAperio ImageScope (Leica Biosystems Imaging, Inc.), for the annotation and\ndisplay of neural network predictions on WSIs. Leveraging this, we propose the\nuse of a human-in-the-loop strategy to reduce the burden of WSI annotation. We\ntrack network performance improvements as a function of iteration and quantify\nthe use of this pipeline for the segmentation of renal histologic findings on\nWSIs. More specifically, we present network performance when applied to\nsegmentation of renal micro compartments, and demonstrate multi-class\nsegmentation in human and mouse renal tissue slides. Finally, to show the\nadaptability of this technique to other medical imaging fields, we demonstrate\nits ability to iteratively segment human prostate glands from radiology imaging\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:29:23 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Lutnick", "Brendon", ""], ["Ginley", "Brandon", ""], ["Govind", "Darshana", ""], ["McGarry", "Sean D.", ""], ["LaViolette", "Peter S.", ""], ["Yacoub", "Rabi", ""], ["Jain", "Sanjay", ""], ["Tomaszewski", "John E.", ""], ["Jen", "Kuang-Yu", ""], ["Sarder", "Pinaki", ""]]}, {"id": "1812.07518", "submitter": "Vahid Pourahmadi Dr.", "authors": "Mohammad Sadegh Safari, Vahid Pourahmadi, and Shabnam Sodagari", "title": "Deep UL2DL: Channel Knowledge Transfer from Uplink to Downlink", "comments": "16 pages, 20 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of the channel state information (CSI) at the transmitter side is\none of the primary sources of information that can be used for the efficient\nallocation of wireless resources. Obtaining downlink (DL) CSI in Frequency\nDivision Duplexing (FDD) systems from uplink (UL) CSI is not as straightforward\nas in TDD systems. Therefore, users usually feed the DL-CSI back to the\ntransmitter. To remove the need for feedback (and thus having less signaling\noverhead), we propose to use two recent deep neural network structures, i.e.,\nconvolutional neural networks and generative adversarial networks (GANs) to\ninfer the DL-CSI by observing the UL-CSI. The core idea of our data-driven\nscheme is exploiting the fact that both DL and UL channels share the same\npropagation environment. As such, we extracted the environment information from\nthe UL channel response to a latent domain and then transferred the derived\nenvironment information from the latent domain to predict the DL channel. To\novercome incorrect latent domain and the problem of oversimplistic assumptions,\nin this work, we did not use any specific parametric model and instead used\ndata-driven approaches to discover the underlying structure of data without any\nprior model assumptions. To overcome the challenge of capturing the UL-DL joint\ndistribution, we used a mean square error-based variant of the GAN structure\nwith improved convergence properties called boundary equilibrium GAN (BEGAN).\nFor training and testing we used simulated data of Extended Vehicular-A (EVA)\nand Extended Typical Urban (ETU) models. Simulation results verified that our\nmethods can accurately infer and predict the downlink CSI from the uplink CSI\nfor different multipath environments in FDD communications.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 04:43:14 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 22:28:11 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 04:18:11 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Safari", "Mohammad Sadegh", ""], ["Pourahmadi", "Vahid", ""], ["Sodagari", "Shabnam", ""]]}, {"id": "1812.07519", "submitter": "Franz J. Kir\\'aly", "authors": "Franz J Kir\\'aly and Bilal Mateen and Raphael Sonabend", "title": "NIPS - Not Even Wrong? A Systematic Review of Empirically Complete\n  Demonstrations of Algorithmic Effectiveness in the Machine Learning and\n  Artificial Intelligence Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To determine the completeness of argumentative steps necessary to\nconclude effectiveness of an algorithm in a sample of current ML/AI supervised\nlearning literature.\n  Data Sources: Papers published in the Neural Information Processing Systems\n(NeurIPS, n\\'ee NIPS) journal where the official record showed a 2017 year of\npublication.\n  Eligibility Criteria: Studies reporting a (semi-)supervised model, or\npre-processing fused with (semi-)supervised models for tabular data.\n  Study Appraisal: Three reviewers applied the assessment criteria to determine\nargumentative completeness. The criteria were split into three groups,\nincluding: experiments (e.g real and/or synthetic data), baselines (e.g\nuninformed and/or state-of-art) and quantitative comparison (e.g. performance\nquantifiers with confidence intervals and formal comparison of the algorithm\nagainst baselines).\n  Results: Of the 121 eligible manuscripts (from the sample of 679 abstracts),\n99\\% used real-world data and 29\\% used synthetic data. 91\\% of manuscripts did\nnot report an uninformed baseline and 55\\% reported a state-of-art baseline.\n32\\% reported confidence intervals for performance but none provided references\nor exposition for how these were calculated. 3\\% reported formal comparisons.\n  Limitations: The use of one journal as the primary information source may not\nbe representative of all ML/AI literature. However, the NeurIPS conference is\nrecognised to be amongst the top tier concerning ML/AI studies, so it is\nreasonable to consider its corpus to be representative of high-quality\nresearch.\n  Conclusion: Using the 2017 sample of the NeurIPS supervised learning corpus\nas an indicator for the quality and trustworthiness of current ML/AI research,\nit appears that complete argumentative chains in demonstrations of algorithmic\neffectiveness are rare.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:32:39 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Kir\u00e1ly", "Franz J", ""], ["Mateen", "Bilal", ""], ["Sonabend", "Raphael", ""]]}, {"id": "1812.07520", "submitter": "Wojciech Samek", "authors": "Simon Wiedemann, Arturo Marban, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Entropy-Constrained Training of Deep Neural Networks", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for neural network compression that is\nmotivated by the Minimum Description Length (MDL) principle. For that we first\nderive an expression for the entropy of a neural network, which measures its\ncomplexity explicitly in terms of its bit-size. Then, we formalize the problem\nof neural network compression as an entropy-constrained optimization objective.\nThis objective generalizes many of the compression techniques proposed in the\nliterature, in that pruning or reducing the cardinality of the weight elements\nof the network can be seen special cases of entropy-minimization techniques.\nFurthermore, we derive a continuous relaxation of the objective, which allows\nus to minimize it using gradient based optimization techniques. Finally, we\nshow that we can reach state-of-the-art compression results on different\nnetwork architectures and data sets, e.g. achieving x71 compression gains on a\nVGG-like architecture.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:36:22 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 13:14:50 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Wiedemann", "Simon", ""], ["Marban", "Arturo", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1812.07526", "submitter": "Rizal Fathony", "authors": "Rizal Fathony, Kaiser Asif, Anqi Liu, Mohammad Ali Bashiri, Wei Xing,\n  Sima Behpour, Xinhua Zhang, and Brian D. Ziebart", "title": "Consistent Robust Adversarial Prediction for General Multiclass\n  Classification", "comments": "49 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a robust adversarial prediction framework for general multiclass\nclassification. Our method seeks predictive distributions that robustly\noptimize non-convex and non-continuous multiclass loss metrics against the\nworst-case conditional label distributions (the adversarial distributions) that\n(approximately) match the statistics of the training data. Although the\noptimized loss metrics are non-convex and non-continuous, the dual formulation\nof the framework is a convex optimization problem that can be recast as a risk\nminimization model with a prescribed convex surrogate loss we call the\nadversarial surrogate loss. We show that the adversarial surrogate losses fill\nan existing gap in surrogate loss construction for general multiclass\nclassification problems, by simultaneously aligning better with the original\nmulticlass loss, guaranteeing Fisher consistency, enabling a way to incorporate\nrich feature spaces via the kernel trick, and providing competitive performance\nin practice.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:47:02 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 16:44:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Fathony", "Rizal", ""], ["Asif", "Kaiser", ""], ["Liu", "Anqi", ""], ["Bashiri", "Mohammad Ali", ""], ["Xing", "Wei", ""], ["Behpour", "Sima", ""], ["Zhang", "Xinhua", ""], ["Ziebart", "Brian D.", ""]]}, {"id": "1812.07538", "submitter": "Jean Thierry-Mieg", "authors": "Danielle Thierry-Mieg and Jean Thierry-Mieg", "title": "XOR_p A maximally intertwined p-classes problem used as a benchmark with\n  built-in truth for neural networks gradient descent optimization", "comments": "16 pages, 4 figures, 3 tables. The source code is public", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural p-classes generalization of the eXclusive OR problem, the\nsubtraction modulo p, where p is prime, is presented and solved using a single\nfully connected hidden layer with p-neurons. Although the problem is very\nsimple, the landscape is intricate and challenging and represents an\ninteresting benchmark for gradient descent optimization algorithms. Testing 9\noptimizers and 9 activation functions up to p = 191, the method converging most\noften and the fastest to a perfect classification is the Adam optimizer\ncombined with the ELU activation function.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 18:13:43 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Thierry-Mieg", "Danielle", ""], ["Thierry-Mieg", "Jean", ""]]}, {"id": "1812.07544", "submitter": "Nikolay Nikolov", "authors": "Nikolay Nikolov, Johannes Kirschner, Felix Berkenkamp, Andreas Krause", "title": "Information-Directed Exploration for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration remains a major challenge for reinforcement learning.\nOne reason is that the variability of the returns often depends on the current\nstate and action, and is therefore heteroscedastic. Classical exploration\nstrategies such as upper confidence bound algorithms and Thompson sampling fail\nto appropriately account for heteroscedasticity, even in the bandit setting.\nMotivated by recent findings that address this issue in bandits, we propose to\nuse Information-Directed Sampling (IDS) for exploration in reinforcement\nlearning. As our main contribution, we build on recent advances in\ndistributional reinforcement learning and propose a novel, tractable\napproximation of IDS for deep Q-learning. The resulting exploration strategy\nexplicitly accounts for both parametric uncertainty and heteroscedastic\nobservation noise. We evaluate our method on Atari games and demonstrate a\nsignificant improvement over alternative approaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 18:20:49 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 01:10:25 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Nikolov", "Nikolay", ""], ["Kirschner", "Johannes", ""], ["Berkenkamp", "Felix", ""], ["Krause", "Andreas", ""]]}, {"id": "1812.07567", "submitter": "Sorin Grigorescu", "authors": "Sorin Grigorescu", "title": "Generative One-Shot Learning (GOL): A Semi-Parametric Approach to\n  One-Shot Learning in Autonomous Vision", "comments": "Web-site: http://rovislab.com/gol.html", "journal-ref": "Int. Conf. on Robotics and Automation ICRA 2018", "doi": "10.1109/ICRA.2018.8461174", "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly Autonomous Driving (HAD) systems rely on deep neural networks for the\nvisual perception of the driving environment. Such networks are trained on\nlarge manually annotated databases. In this work, a semi-parametric approach to\none-shot learning is proposed, with the aim of bypassing the manual annotation\nstep required for training perceptions systems used in autonomous driving. The\nproposed generative framework, coined Generative One-Shot Learning (GOL), takes\nas input single one-shot objects, or generic patterns, and a small set of\nso-called regularization samples used to drive the generative process. New\nsynthetic data is generated as Pareto optimal solutions from one-shot objects\nusing a set of generalization functions built into a generalization generator.\nGOL has been evaluated on environment perception challenges encountered in\nautonomous vision.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 04:22:15 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Grigorescu", "Sorin", ""]]}, {"id": "1812.07568", "submitter": "Cyrus Cousins", "authors": "Clayton Sanford, Cyrus Cousins, Eli Upfal", "title": "Uniform Convergence Bounds for Codec Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We frame the problem of selecting an optimal audio encoding scheme as a\nsupervised learning task. Through uniform convergence theory, we guarantee\napproximately optimal codec selection while controlling for selection bias. We\npresent rigorous statistical guarantees for the codec selection problem that\nhold for arbitrary distributions over audio sequences and for arbitrary quality\nmetrics. Our techniques can thus balance sound quality and compression ratio,\nand use audio samples from the distribution to select a codec that performs\nwell on that particular type of data. The applications of our technique are\nimmense, as it can be used to optimize for quality and bandwidth usage of\nstreaming and other digital media, while significantly outperforming approaches\nthat apply a fixed codec to all data sources.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 04:42:34 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Sanford", "Clayton", ""], ["Cousins", "Cyrus", ""], ["Upfal", "Eli", ""]]}, {"id": "1812.07606", "submitter": "Li Chen", "authors": "Li Chen", "title": "Deep Transfer Learning for Static Malware Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to apply deep transfer learning from computer vision to static\nmalware classification. In the transfer learning scheme, we borrow knowledge\nfrom natural images or objects and apply to the target domain of static malware\ndetection. As a result, training time of deep neural networks is accelerated\nwhile high classification performance is still maintained. We demonstrate the\neffectiveness of our approach on three experiments and show that our proposed\nmethod outperforms other classical machine learning methods measured in\naccuracy, false positive rate, true positive rate and $F_1$ score (in binary\nclassification). We instrument an interpretation component to the algorithm and\nprovide interpretable explanations to enhance security practitioners' trust to\nthe model. We further discuss a convex combination scheme of transfer learning\nand training from scratch for enhanced malware detection, and provide insights\nof the algorithmic interpretation of vision-based malware classification\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 19:18:15 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Chen", "Li", ""]]}, {"id": "1812.07611", "submitter": "Yiheng Zhu", "authors": "Yiheng Zhu, Yichen Yao, Zili Wu, Yujie Chen, Guozheng Li, Haoyuan Hu,\n  Yinghui Xu", "title": "GP-CNAS: Convolutional Neural Network Architecture Search with Genetic\n  Programming", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are effective at solving difficult\nproblems like visual recognition, speech recognition and natural language\nprocessing. However, performance gain comes at the cost of laborious\ntrial-and-error in designing deeper CNN architectures. In this paper, a genetic\nprogramming (GP) framework for convolutional neural network architecture\nsearch, abbreviated as GP-CNAS, is proposed to automatically search for optimal\nCNN architectures. GP-CNAS encodes CNNs as trees where leaf nodes (GP\nterminals) are selected residual blocks and non-leaf nodes (GP functions)\nspecify the block assembling procedure. Our tree-based representation enables\neasy design and flexible implementation of genetic operators. Specifically, we\ndesign a dynamic crossover operator that strikes a balance between exploration\nand exploitation, which emphasizes CNN complexity at early stage and CNN\ndiversity at later stage. Therefore, the desired CNN architecture with balanced\ndepth and width can be found within limited trials. Moreover, our GP-CNAS\nframework is highly compatible with other manually-designed and NAS-generated\nblock types as well. Experimental results on the CIFAR-10 dataset show that\nGP-CNAS is competitive among the state-of-the-art automatic and semi-automatic\nNAS algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:44:15 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Zhu", "Yiheng", ""], ["Yao", "Yichen", ""], ["Wu", "Zili", ""], ["Chen", "Yujie", ""], ["Li", "Guozheng", ""], ["Hu", "Haoyuan", ""], ["Xu", "Yinghui", ""]]}, {"id": "1812.07617", "submitter": "Raymond Li", "authors": "Raymond Li, Samira Kahou, Hannes Schulz, Vincent Michalski, Laurent\n  Charlin, Chris Pal", "title": "Towards Deep Conversational Recommendations", "comments": "17 pages, 5 figures, Accepted at 32nd Conference on Neural\n  Information Processing Systems (NeurIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been growing interest in using neural networks and deep learning\ntechniques to create dialogue systems. Conversational recommendation is an\ninteresting setting for the scientific exploration of dialogue with natural\nlanguage as the associated discourse involves goal-driven dialogue that often\ntransforms naturally into more free-form chat. This paper provides two\ncontributions. First, until now there has been no publicly available\nlarge-scale dataset consisting of real-world dialogues centered around\nrecommendations. To address this issue and to facilitate our exploration here,\nwe have collected ReDial, a dataset consisting of over 10,000 conversations\ncentered around the theme of providing movie recommendations. We make this data\navailable to the community for further research. Second, we use this dataset to\nexplore multiple facets of conversational recommendations. In particular we\nexplore new neural architectures, mechanisms, and methods suitable for\ncomposing conversational recommendation systems. Our dataset allows us to\nsystematically probe model sub-components addressing different parts of the\noverall problem domain ranging from: sentiment analysis and cold-start\nrecommendation generation to detailed aspects of how natural language is used\nin this setting in the real world. We combine such sub-components into a\nfull-blown dialogue system and examine its behavior.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 19:34:32 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 18:54:59 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Li", "Raymond", ""], ["Kahou", "Samira", ""], ["Schulz", "Hannes", ""], ["Michalski", "Vincent", ""], ["Charlin", "Laurent", ""], ["Pal", "Chris", ""]]}, {"id": "1812.07626", "submitter": "Tom Schaul", "authors": "Diana Borsa, Andr\\'e Barreto, John Quan, Daniel Mankowitz, R\\'emi\n  Munos, Hado van Hasselt, David Silver, Tom Schaul", "title": "Universal Successor Features Approximators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of a reinforcement learning (RL) agent to learn about many reward\nfunctions at the same time has many potential benefits, such as the\ndecomposition of complex tasks into simpler ones, the exchange of information\nbetween tasks, and the reuse of skills. We focus on one aspect in particular,\nnamely the ability to generalise to unseen tasks. Parametric generalisation\nrelies on the interpolation power of a function approximator that is given the\ntask description as input; one of its most common form are universal value\nfunction approximators (UVFAs). Another way to generalise to new tasks is to\nexploit structure in the RL problem itself. Generalised policy improvement\n(GPI) combines solutions of previous tasks into a policy for the unseen task;\nthis relies on instantaneous policy evaluation of old policies under the new\nreward function, which is made possible through successor features (SFs). Our\nproposed universal successor features approximators (USFAs) combine the\nadvantages of all of these, namely the scalability of UVFAs, the instant\ninference of SFs, and the strong generalisation of GPI. We discuss the\nchallenges involved in training a USFA, its generalisation properties and\ndemonstrate its practical benefits and transfer abilities on a large-scale\ndomain in which the agent has to navigate in a first-person perspective\nthree-dimensional environment.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 20:01:41 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Borsa", "Diana", ""], ["Barreto", "Andr\u00e9", ""], ["Quan", "John", ""], ["Mankowitz", "Daniel", ""], ["Munos", "R\u00e9mi", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Schaul", "Tom", ""]]}, {"id": "1812.07627", "submitter": "Kian Kenyon-Dean", "authors": "Kian Kenyon-Dean, Andre Cianflone, Lucas Page-Caccia, Guillaume\n  Rabusseau, Jackie Chi Kit Cheung, Doina Precup", "title": "Clustering-Oriented Representation Learning with Attractive-Repulsive\n  Loss", "comments": "AAAI 2019 Workshop on Network Interpretability for Deep Learning (9\n  pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard loss function used to train neural network classifiers,\ncategorical cross-entropy (CCE), seeks to maximize accuracy on the training\ndata; building useful representations is not a necessary byproduct of this\nobjective. In this work, we propose clustering-oriented representation learning\n(COREL) as an alternative to CCE in the context of a generalized\nattractive-repulsive loss framework. COREL has the consequence of building\nlatent representations that collectively exhibit the quality of natural\nclustering within the latent space of the final hidden layer, according to a\npredefined similarity function. Despite being simple to implement, COREL\nvariants outperform or perform equivalently to CCE in a variety of scenarios,\nincluding image and news article classification using both feed-forward and\nconvolutional neural networks. Analysis of the latent spaces created with\ndifferent similarity functions facilitates insights on the different use cases\nCOREL variants can satisfy, where the Cosine-COREL variant makes a consistently\nclusterable latent space, while Gaussian-COREL consistently obtains better\nclassification accuracy than CCE.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 20:07:56 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Kenyon-Dean", "Kian", ""], ["Cianflone", "Andre", ""], ["Page-Caccia", "Lucas", ""], ["Rabusseau", "Guillaume", ""], ["Cheung", "Jackie Chi Kit", ""], ["Precup", "Doina", ""]]}, {"id": "1812.07641", "submitter": "Ershad Banijamali Mr.", "authors": "Ershad Banijamali, Amir-Hossein Karimi, Ali Ghodsi", "title": "Deep Variational Sufficient Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sufficient dimensionality reduction (SDR), where\nthe high-dimensional observation is transformed to a low-dimensional sub-space\nin which the information of the observations regarding the label variable is\npreserved. We propose DVSDR, a deep variational approach for sufficient\ndimensionality reduction. The deep structure in our model has a bottleneck that\nrepresent the low-dimensional embedding of the data. We explain the SDR problem\nusing graphical models and use the framework of variational autoencoders to\nmaximize the lower bound of the log-likelihood of the joint distribution of the\nobservation and label. We show that such a maximization problem can be\ninterpreted as solving the SDR problem. DVSDR can be easily adopted to\nsemi-supervised learning setting. In our experiment we show that DVSDR performs\ncompetitively on classification tasks while being able to generate novel data\nsamples.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 20:57:25 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Banijamali", "Ershad", ""], ["Karimi", "Amir-Hossein", ""], ["Ghodsi", "Ali", ""]]}, {"id": "1812.07669", "submitter": "Frank Noe", "authors": "Frank No\\'e", "title": "Machine Learning for Molecular Dynamics on Long Timescales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular Dynamics (MD) simulation is widely used to analyze the properties\nof molecules and materials. Most practical applications, such as comparison\nwith experimental measurements, designing drug molecules, or optimizing\nmaterials, rely on statistical quantities, which may be prohibitively expensive\nto compute from direct long-time MD simulations. Classical Machine Learning\n(ML) techniques have already had a profound impact on the field, especially for\nlearning low-dimensional models of the long-time dynamics and for devising more\nefficient sampling schemes for computing long-time statistics. Novel ML methods\nhave the potential to revolutionize long-timescale MD and to obtain\ninterpretable models. ML concepts such as statistical estimator theory,\nend-to-end learning, representation learning and active learning are highly\ninteresting for the MD researcher and will help to develop new solutions to\nhard MD problems. With the aim of better connecting the MD and ML research\nareas and spawning new research on this interface, we define the learning\nproblems in long-timescale MD, present successful approaches and outline some\nof the unsolved ML problems in this application field.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 22:25:54 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["No\u00e9", "Frank", ""]]}, {"id": "1812.07671", "submitter": "Anusha Nagabandi", "authors": "Anusha Nagabandi, Chelsea Finn, Sergey Levine", "title": "Deep Online Learning via Meta-Learning: Continual Adaptation for\n  Model-Based RL", "comments": "Project website: https://sites.google.com/berkeley.edu/onlineviameta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals can learn complex predictive models that allow them to\naccurately and reliably reason about real-world phenomena, and they can adapt\nsuch models extremely quickly in the face of unexpected changes. Deep neural\nnetwork models allow us to represent very complex functions, but lack this\ncapacity for rapid online adaptation. The goal in this paper is to develop a\nmethod for continual online learning from an incoming stream of data, using\ndeep neural network models. We formulate an online learning procedure that uses\nstochastic gradient descent to update model parameters, and an expectation\nmaximization algorithm with a Chinese restaurant process prior to develop and\nmaintain a mixture of models to handle non-stationary task distributions. This\nallows for all models to be adapted as necessary, with new models instantiated\nfor task changes and old models recalled when previously seen tasks are\nencountered again. Furthermore, we observe that meta-learning can be used to\nmeta-train a model such that this direct online adaptation with SGD is\neffective, which is otherwise not the case for large function approximators. In\nthis work, we apply our meta-learning for online learning (MOLe) approach to\nmodel-based reinforcement learning, where adapting the predictive model is\ncritical for control; we demonstrate that MOLe outperforms alternative prior\nmethods, and enables effective continuous adaptation in non-stationary task\ndistributions such as varying terrains, motor failures, and unexpected\ndisturbances.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 22:27:31 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 19:11:23 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Nagabandi", "Anusha", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1812.07676", "submitter": "Philipp Marquetand", "authors": "Michael Gastegger and Philipp Marquetand", "title": "Molecular Dynamics with Neural-Network Potentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular dynamics simulations are an important tool for describing the\nevolution of a chemical system with time. However, these simulations are\ninherently held back either by the prohibitive cost of accurate electronic\nstructure theory computations or the limited accuracy of classical empirical\nforce fields. Machine learning techniques can help to overcome these\nlimitations by providing access to potential energies, forces and other\nmolecular properties modeled directly after an electronic structure reference\nat only a fraction of the original computational cost. The present text\ndiscusses several practical aspects of conducting machine learning driven\nmolecular dynamics simulations. First, we study the efficient selection of\nreference data points on the basis of an active learning inspired adaptive\nsampling scheme. This is followed by the analysis of a machine-learning based\nmodel for simulating molecular dipole moments in the framework of predicting\ninfrared spectra via molecular dynamics simulations. Finally, we show that\nmachine learning models can offer valuable aid in understanding chemical\nsystems beyond a simple prediction of quantities.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 22:38:40 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Gastegger", "Michael", ""], ["Marquetand", "Philipp", ""]]}, {"id": "1812.07683", "submitter": "Nelly Elsayed", "authors": "Nelly Elsayed, Anthony S. Maida, Magdy Bayoumi", "title": "Deep Gated Recurrent and Convolutional Network Hybrid Model for\n  Univariate Time Series Classification", "comments": "The paper modified and has several new results", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications (IJACSA), 10(5), 2019", "doi": "10.14569/IJACSA.2019.0100582", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid LSTM-fully convolutional networks (LSTM-FCN) for time series\nclassification have produced state-of-the-art classification results on\nunivariate time series. We show that replacing the LSTM with a gated recurrent\nunit (GRU) to create a GRU-fully convolutional network hybrid model (GRU-FCN)\ncan offer even better performance on many time series datasets. The proposed\nGRU-FCN model outperforms state-of-the-art classification performance in many\nunivariate and multivariate time series datasets. In addition, since the GRU\nuses a simpler architecture than the LSTM, it has fewer training parameters,\nless training time, and a simpler hardware implementation, compared to the\nLSTM-based models.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 22:57:46 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 04:25:11 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 02:41:10 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Elsayed", "Nelly", ""], ["Maida", "Anthony S.", ""], ["Bayoumi", "Magdy", ""]]}, {"id": "1812.07692", "submitter": "Guang Zhao", "authors": "Guang Zhao, Raymundo Arroyave, Xiaoning Qian", "title": "Fast Exact Computation of Expected HyperVolume Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-objective Bayesian optimization and surrogate-based evolutionary\nalgorithms, Expected HyperVolume Improvement (EHVI) is widely used as the\nacquisition function to guide the search approaching the Pareto front. This\npaper focuses on the exact calculation of EHVI given a nondominated set, for\nwhich the existing exact algorithms are complex and can be inefficient for\nproblems with more than three objectives. Integrating with different\ndecomposition algorithms, we propose a new method for calculating the integral\nin each decomposed high-dimensional box in constant time. We develop three new\nexact EHVI calculation algorithms based on three region decomposition methods.\nThe first grid-based algorithm has a complexity of $O(m\\cdot n^m)$ with $n$\ndenoting the size of the nondominated set and $m$ the number of objectives. The\nWalking Fish Group (WFG)-based algorithm has a worst-case complexity of\n$O(m\\cdot 2^n)$ but has a better average performance. These two can be applied\nfor problems with any $m$. The third CLM-based algorithm is only for $m=3$ and\nasymptotically optimal with complexity $\\Theta(n\\log{n})$. Performance\ncomparison results show that all our three algorithms are at least twice faster\nthan the state-of-the-art algorithms with the same decomposition methods. When\n$m>3$, our WFG-based algorithm can be over $10^2$ faster than the corresponding\nexisting algorithms. Our algorithm is demonstrated in an example involving\nefficient multi-objective material design with Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 23:25:37 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 22:14:21 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Zhao", "Guang", ""], ["Arroyave", "Raymundo", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1812.07699", "submitter": "Thomas Hollis", "authors": "Thomas Hollis, Antoine Viscardi, Seung Eun Yi", "title": "A Comparison of LSTMs and Attention Mechanisms for Forecasting Financial\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While LSTMs show increasingly promising results for forecasting Financial\nTime Series (FTS), this paper seeks to assess if attention mechanisms can\nfurther improve performance. The hypothesis is that attention can help prevent\nlong-term dependencies experienced by LSTM models. To test this hypothesis, the\nmain contribution of this paper is the implementation of an LSTM with\nattention. Both the benchmark LSTM and the LSTM with attention were compared\nand both achieved reasonable performances of up to 60% on five stocks from\nKaggle's Two Sigma dataset. This comparative analysis demonstrates that an LSTM\nwith attention can indeed outperform standalone LSTMs but further investigation\nis required as issues do arise with such model architectures.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 23:43:48 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Hollis", "Thomas", ""], ["Viscardi", "Antoine", ""], ["Yi", "Seung Eun", ""]]}, {"id": "1812.07710", "submitter": "Holly Grimm", "authors": "Holly Grimm", "title": "Training on Art Composition Attributes to Influence CycleGAN Art\n  Generation", "comments": "Poster at Neural Information Processing Systems 2018 Workshop on\n  Machine Learning for Creativity and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I consider how to influence CycleGAN, image-to-image translation, by using\nadditional constraints from a neural network trained on art composition\nattributes. I show how I trained the the Art Composition Attributes Network\n(ACAN) by incorporating domain knowledge based on the rules of art evaluation\nand the result of applying each art composition attribute to apple2orange image\ntranslation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 00:36:10 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Grimm", "Holly", ""]]}, {"id": "1812.07716", "submitter": "Avishek Choudhury", "authors": "Avishek Choudhury, .Christopher Greene", "title": "Prognosticating Autism Spectrum Disorder Using Artificial Neural\n  Network: Levenberg-Marquardt Algorithm", "comments": null, "journal-ref": "Archives of Clinical and Biomedical Research 2018, 2(6):188-197", "doi": "10.26502/acbr.50170058", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autism spectrum condition (ASC) or autism spectrum disorder (ASD) is\nprimarily identified with the help of behavioral indications encompassing\nsocial, sensory and motor characteristics. Although categorized, recurring\nmotor actions are measured during diagnosis, quantifiable measures that\nascertain kinematic physiognomies in the movement configurations of autistic\npersons are not adequately studied, hindering the advances in understanding the\netiology of motor mutilation. Subject aspects such as behavioral characters\nthat influences ASD need further exploration. Presently, limited autism\ndatasets concomitant with screening ASD are available, and a majority of them\nare genetic. Hence, in this study, we used a dataset related to autism\nscreening enveloping ten behavioral and ten personal attributes that have been\neffective in diagnosing ASD cases from controls in behavior science. ASD\ndiagnosis is time exhaustive and uneconomical. The burgeoning ASD cases\nworldwide mandate a need for the fast and economical screening tool. Our study\naimed to implement an artificial neural network with the Levenberg-Marquardt\nalgorithm to detect ASD and examine its predictive accuracy. Consecutively,\ndevelop a clinical decision support system for early ASD identification.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 15:50:21 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 03:44:42 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Choudhury", "Avishek", ""], ["Greene", ". Christopher", ""]]}, {"id": "1812.07722", "submitter": "Sung-En Chiu", "authors": "Sung-En Chiu, Nancy Ronquillo and Tara Javidi", "title": "Active Learning and CSI Acquisition for mmWave Initial Alignment", "comments": "This paper appears in: IEEE Journal on Selected Areas in\n  Communications On page(s): 1-16 Print ISSN: 0733-8716 Online ISSN: 1558-0008", "journal-ref": null, "doi": "10.1109/JSAC.2019.2933967", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter wave (mmWave) communication with large antenna arrays is a\npromising technique to enable extremely high data rates due to the large\navailable bandwidth in mmWave frequency bands. In addition, given the knowledge\nof an optimal directional beamforming vector, large antenna arrays have been\nshown to overcome both the severe signal attenuation in mmWave as well as the\ninterference problem. However, fundamental limits on achievable learning rate\nof an optimal beamforming vector remain.\n  This paper considers the problem of adaptive and sequential optimization of\nthe beamforming vectors during the initial access phase of communication. With\na single-path channel model, the problem is reduced to actively learning the\nAngle-of-Arrival (AoA) of the signal sent from the user to the Base Station\n(BS). Drawing on the recent results in the design of a hierarchical beamforming\ncodebook [1], sequential measurement dependent noisy search strategies [2], and\nactive learning from an imperfect labeler [3], an adaptive and sequential\nalignment algorithm is proposed.\n  An upper bound on the expected search time of the proposed algorithm is\nderived via Extrinsic Jensen-Shannon Divergence. which demonstrates that the\nsearch time of the proposed algorithm asymptotically matches the performance of\nthe noiseless bisection search up to a constant factor. Furthermore, the upper\nbound shows that the acquired AoA error probability decays exponentially fast\nwith the search time with an exponent that is a decreasing function of the\nacquisition rate.\n  Numerically, the proposed algorithm is compared with prior work where a\nsignificant improvement of the system communication rate is observed. Most\nnotably, in the relevant regime of low (-10dB to 5dB) raw SNR, this establishes\nthe first practically viable solution for initial access and, hence, the first\ndemonstration of stand-alone mmWave communication\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 01:14:29 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 23:50:38 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 22:15:38 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 01:21:21 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Chiu", "Sung-En", ""], ["Ronquillo", "Nancy", ""], ["Javidi", "Tara", ""]]}, {"id": "1812.07725", "submitter": "Mert G\\\"urb\\\"uzbalaban", "authors": "Xuefeng Gao, Mert Gurbuzbalaban, Lingjiong Zhu", "title": "Breaking Reversibility Accelerates Langevin Dynamics for Global\n  Non-Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Langevin dynamics (LD) has been proven to be a powerful technique for\noptimizing a non-convex objective as an efficient algorithm to find local\nminima while eventually visiting a global minimum on longer time-scales. LD is\nbased on the first-order Langevin diffusion which is reversible in time. We\nstudy two variants that are based on non-reversible Langevin diffusions: the\nunderdamped Langevin dynamics (ULD) and the Langevin dynamics with a\nnon-symmetric drift (NLD). Adopting the techniques of Tzen, Liang and Raginsky\n(2018) for LD to non-reversible diffusions, we show that for a given local\nminimum that is within an arbitrary distance from the initialization, with high\nprobability, either the ULD trajectory ends up somewhere outside a small\nneighborhood of this local minimum within a recurrence time which depends on\nthe smallest eigenvalue of the Hessian at the local minimum or they enter this\nneighborhood by the recurrence time and stay there for a potentially\nexponentially long escape time. The ULD algorithms improve upon the recurrence\ntime obtained for LD in Tzen, Liang and Raginsky (2018) with respect to the\ndependency on the smallest eigenvalue of the Hessian at the local minimum.\nSimilar result and improvement are obtained for the NLD algorithm. We also show\nthat non-reversible variants can exit the basin of attraction of a local\nminimum faster in discrete time when the objective has two local minima\nseparated by a saddle point and quantify the amount of improvement. Our\nanalysis suggests that non-reversible Langevin algorithms are more efficient to\nlocate a local minimum as well as exploring the state space. Our analysis is\nbased on the quadratic approximation of the objective around a local minimum.\nAs a by-product of our analysis, we obtain optimal mixing rates for quadratic\nobjectives in the 2-Wasserstein distance for two non-reversible Langevin\nalgorithms we consider.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 01:27:19 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 22:31:32 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 02:46:08 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 21:37:12 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gao", "Xuefeng", ""], ["Gurbuzbalaban", "Mert", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "1812.07729", "submitter": "Maryam Pishgar", "authors": "Maryam Pishgar, Fazle Karim, Somshubra Majumdar, Houshang Darabi", "title": "Pathological Voice Classification Using Mel-Cepstrum Vectors and Support\n  Vector Machine", "comments": "Accepted at IEEE BigData 2018 Workshop - FEMH Voice Data Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vocal disorders have affected several patients all over the world. Due to the\ninherent difficulty of diagnosing vocal disorders without sophisticated\nequipment and trained personnel, a number of patients remain undiagnosed. To\nalleviate the monetary cost of diagnosis, there has been a recent growth in the\nuse of data analysis to accurately detect and diagnose individuals for a\nfraction of the cost. We propose a cheap, efficient and accurate model to\ndiagnose whether a patient suffers from one of three vocal disorders on the\nFEMH 2018 challenge.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 02:00:24 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Pishgar", "Maryam", ""], ["Karim", "Fazle", ""], ["Majumdar", "Somshubra", ""], ["Darabi", "Houshang", ""]]}, {"id": "1812.07738", "submitter": "Yong Liu", "authors": "Yong Liu and Jian Li and Weiping Wang", "title": "Max-Diversity Distributed Learning: Theory and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the risk performance of distributed learning for the regularization\nempirical risk minimization with fast convergence rate, substantially improving\nthe error analysis of the existing divide-and-conquer based distributed\nlearning. An interesting theoretical finding is that the larger the diversity\nof each local estimate is, the tighter the risk bound is. This theoretical\nanalysis motivates us to devise an effective maxdiversity distributed learning\nalgorithm (MDD). Experimental results show that MDD can outperform the existing\ndivide-andconquer methods but with a bit more time. Theoretical analysis and\nempirical results demonstrate that our proposed MDD is sound and effective.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 02:58:43 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 06:22:20 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Liu", "Yong", ""], ["Li", "Jian", ""], ["Wang", "Weiping", ""]]}, {"id": "1812.07764", "submitter": "Zeyuan Wang", "authors": "Zeyuan Wang, Josiah Poon, Shiding Sun, Simon Poon", "title": "CNN based Multi-Instance Multi-Task Learning for Syndrome\n  Differentiation of Diabetic Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syndrome differentiation in Traditional Chinese Medicine (TCM) is the process\nof understanding and reasoning body condition, which is the essential step and\npremise of effective treatments. However, due to its complexity and lack of\nstandardization, it is challenging to achieve. In this study, we consider each\npatient's record as a one-dimensional image and symptoms as pixels, in which\nmissing and negative values are represented by zero pixels. The objective is to\nfind relevant symptoms first and then map them to proper syndromes, that is\nsimilar to the object detection problem in computer vision. Inspired from it,\nwe employ multi-instance multi-task learning combined with the convolutional\nneural network (MIMT-CNN) for syndrome differentiation, which takes region\nproposals as input and output image labels directly. The neural network\nconsists of region proposals generation, convolutional layer, fully connected\nlayer, and max pooling (multi-instance pooling) layer followed by the sigmoid\nfunction in each syndrome prediction task for image representation learning and\nfinal results generation. On the diabetes dataset, it performs better than all\nother baseline methods. Moreover, it shows stability and reliability to\ngenerate results, even on the dataset with small sample size, a large number of\nmissing values and noises.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 05:44:47 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 05:37:43 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Wang", "Zeyuan", ""], ["Poon", "Josiah", ""], ["Sun", "Shiding", ""], ["Poon", "Simon", ""]]}, {"id": "1812.07768", "submitter": "Ferran Alet", "authors": "Ferran Alet and Maria Bauza and Alberto Rodriguez and Tomas\n  Lozano-Perez and Leslie P. Kaelbling", "title": "Modular meta-learning in abstract graph networks for combinatorial\n  generalization", "comments": "Presented at NeurIPS meta-learning workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modular meta-learning is a new framework that generalizes to unseen datasets\nby combining a small set of neural modules in different ways. In this work we\npropose abstract graph networks: using graphs as abstractions of a system's\nsubparts without a fixed assignment of nodes to system subparts, for which we\nwould need supervision. We combine this idea with modular meta-learning to get\na flexible framework with combinatorial generalization to new tasks built in.\nWe then use it to model the pushing of arbitrarily shaped objects from little\nor no training data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 06:07:51 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Alet", "Ferran", ""], ["Bauza", "Maria", ""], ["Rodriguez", "Alberto", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie P.", ""]]}, {"id": "1812.07805", "submitter": "Zheng Chen", "authors": "Zheng Chen, Yong Zhang, Yue Shang, Xiaohua Hu", "title": "Unifying Topic, Sentiment & Preference in an HDP-Based Rating Regression\n  Model for Online Reviews", "comments": null, "journal-ref": "Asian Conference on Machine Learning. 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a new HDP based online review rating regression model\nnamed Topic-Sentiment-Preference Regression Analysis (TSPRA). TSPRA combines\ntopics (i.e. product aspects), word sentiment and user preference as regression\nfactors, and is able to perform topic clustering, review rating prediction,\nsentiment analysis and what we invent as \"critical aspect\" analysis altogether\nin one framework. TSPRA extends sentiment approaches by integrating the key\nconcept \"user preference\" in collaborative filtering (CF) models into\nconsideration, while it is distinct from current CF models by decoupling \"user\npreference\" and \"sentiment\" as independent factors. Our experiments conducted\non 22 Amazon datasets show overwhelming better performance in rating\npredication against a state-of-art model FLAME (2015) in terms of error,\nPearson's Correlation and number of inverted pairs. For sentiment analysis, we\ncompare the derived word sentiments against a public sentiment resource\nSenticNet3 and our sentiment estimations clearly make more sense in the context\nof online reviews. Last, as a result of the de-correlation of \"user preference\"\nfrom \"sentiment\", TSPRA is able to evaluate a new concept \"critical aspects\",\ndefined as the product aspects seriously concerned by users but negatively\ncommented in reviews. Improvement to such \"critical aspects\" could be most\neffective to enhance user experience.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 08:33:31 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Chen", "Zheng", ""], ["Zhang", "Yong", ""], ["Shang", "Yue", ""], ["Hu", "Xiaohua", ""]]}, {"id": "1812.07809", "submitter": "Paul Pu Liang", "authors": "Hai Pham, Paul Pu Liang, Thomas Manzini, Louis-Philippe Morency,\n  Barnabas Poczos", "title": "Found in Translation: Learning Robust Joint Representations by Cyclic\n  Translations Between Modalities", "comments": "AAAI 2019, code available at https://github.com/hainow/MCTN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal sentiment analysis is a core research area that studies speaker\nsentiment expressed from the language, visual, and acoustic modalities. The\ncentral challenge in multimodal learning involves inferring joint\nrepresentations that can process and relate information from these modalities.\nHowever, existing work learns joint representations by requiring all modalities\nas input and as a result, the learned representations may be sensitive to noisy\nor missing modalities at test time. With the recent success of sequence to\nsequence (Seq2Seq) models in machine translation, there is an opportunity to\nexplore new ways of learning joint representations that may not require all\ninput modalities at test time. In this paper, we propose a method to learn\nrobust joint representations by translating between modalities. Our method is\nbased on the key insight that translation from a source to a target modality\nprovides a method of learning joint representations using only the source\nmodality as input. We augment modality translations with a cycle consistency\nloss to ensure that our joint representations retain maximal information from\nall modalities. Once our translation model is trained with paired multimodal\ndata, we only need data from the source modality at test time for final\nsentiment prediction. This ensures that our model remains robust from\nperturbations or missing information in the other modalities. We train our\nmodel with a coupled translation-prediction objective and it achieves new\nstate-of-the-art results on multimodal sentiment analysis datasets: CMU-MOSI,\nICT-MMMO, and YouTube. Additional experiments show that our model learns\nincreasingly discriminative joint representations with more input modalities\nwhile maintaining robustness to missing or perturbed modalities.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 08:38:21 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 09:20:33 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Pham", "Hai", ""], ["Liang", "Paul Pu", ""], ["Manzini", "Thomas", ""], ["Morency", "Louis-Philippe", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1812.07810", "submitter": "Zheng Chen", "authors": "Zheng Chen, Xinli Yu, Chi Zhang, Jin Zhang, Cui Lin, Bo Song,\n  Jianliang Gao, Xiaohua Hu, Wei-Shih Yang, Erjia Yan", "title": "Fast Botnet Detection From Streaming Logs Using Online Lanczos Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Botnet, a group of coordinated bots, is becoming the main platform of\nmalicious Internet activities like DDOS, click fraud, web scraping, spam/rumor\ndistribution, etc. This paper focuses on design and experiment of a new\napproach for botnet detection from streaming web server logs, motivated by its\nwide applicability, real-time protection capability, ease of use and better\nsecurity of sensitive data. Our algorithm is inspired by a Principal Component\nAnalysis (PCA) to capture correlation in data, and we are first to recognize\nand adapt Lanczos method to improve the time complexity of PCA-based botnet\ndetection from cubic to sub-cubic, which enables us to more accurately and\nsensitively detect botnets with sliding time windows rather than fixed time\nwindows. We contribute a generalized online correlation matrix update formula,\nand a new termination condition for Lanczos iteration for our purpose based on\nerror bound and non-decreasing eigenvalues of symmetric matrices. On our\ndataset of an ecommerce website logs, experiments show the time cost of Lanczos\nmethod with different time windows are consistently only 20% to 25% of PCA.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 08:40:21 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Chen", "Zheng", ""], ["Yu", "Xinli", ""], ["Zhang", "Chi", ""], ["Zhang", "Jin", ""], ["Lin", "Cui", ""], ["Song", "Bo", ""], ["Gao", "Jianliang", ""], ["Hu", "Xiaohua", ""], ["Yang", "Wei-Shih", ""], ["Yan", "Erjia", ""]]}, {"id": "1812.07813", "submitter": "Xiaojun Mao", "authors": "Xiaojun Mao, Raymond K. W. Wong and Song Xi Chen", "title": "Matrix Completion under Low-Rank Missing Mechanism", "comments": "29 pages, 0 figures", "journal-ref": null, "doi": "10.5705/ss.202019.0196", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a modern missing data problem where both the missing\nstructure and the underlying parameter are high dimensional. Although missing\nstructure is a key component to any missing data problems, existing matrix\ncompletion methods often assume a simple uniform missing mechanism. In this\nwork, we study matrix completion from corrupted data under a novel low-rank\nmissing mechanism. The probability matrix of observation is estimated via a\nhigh dimensional low-rank matrix estimation procedure, and further used to\ncomplete the target matrix via inverse probabilities weighting. Due to both\nhigh dimensional and extreme (i.e., very small) nature of the true probability\nmatrix, the effect of inverse probability weighting requires careful study. We\nderive optimal asymptotic convergence rates of the proposed estimators for both\nthe observation probabilities and the target matrix.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 08:46:50 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 02:56:27 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Mao", "Xiaojun", ""], ["Wong", "Raymond K. W.", ""], ["Chen", "Song Xi", ""]]}, {"id": "1812.07816", "submitter": "Haruki Imai", "authors": "Haruki Imai, Samuel Matzek, Tung D. Le, Yasushi Negishi, Kiyokuni\n  Kawachiya", "title": "Fast and Accurate 3D Medical Image Segmentation with Data-swapping\n  Method", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models used for medical image segmentation are large\nbecause they are trained with high-resolution three-dimensional (3D) images.\nGraphics processing units (GPUs) are widely used to accelerate the trainings.\nHowever, the memory on a GPU is not large enough to train the models. A popular\napproach to tackling this problem is patch-based method, which divides a large\nimage into small patches and trains the models with these small patches.\nHowever, this method would degrade the segmentation quality if a target object\nspans multiple patches. In this paper, we propose a novel approach for 3D\nmedical image segmentation that utilizes the data-swapping, which swaps out\nintermediate data from GPU memory to CPU memory to enlarge the effective GPU\nmemory size, for training high-resolution 3D medical images without patching.\nWe carefully tuned parameters in the data-swapping method to obtain the best\ntraining performance for 3D U-Net, a widely used deep neural network model for\nmedical image segmentation. We applied our tuning to train 3D U-Net with\nfull-size images of 192 x 192 x 192 voxels in brain tumor dataset. As a result,\ncommunication overhead, which is the most important issue, was reduced by\n17.1%. Compared with the patch-based method for patches of 128 x 128 x 128\nvoxels, our training for full-size images achieved improvement on the mean Dice\nscore by 4.48% and 5.32 % for detecting whole tumor sub-region and tumor core\nsub-region, respectively. The total training time was reduced from 164 hours to\n47 hours, resulting in 3.53 times of acceleration.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 08:49:50 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Imai", "Haruki", ""], ["Matzek", "Samuel", ""], ["Le", "Tung D.", ""], ["Negishi", "Yasushi", ""], ["Kawachiya", "Kiyokuni", ""]]}, {"id": "1812.07858", "submitter": "Idan Amit", "authors": "Idan Amit, John Matherly, William Hewlett, Zhi Xu, Yinnon Meshi, Yigal\n  Weinberger", "title": "Machine Learning in Cyber-Security - Problems, Challenges and Data Sets", "comments": null, "journal-ref": "The AAAI-19 Workshop on Engineering Dependable and Secure Machine\n  Learning Systems, 2019.\n  [[REF](https://sites.google.com/view/edsmls2019/home)]", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present cyber-security problems of high importance. We show that in order\nto solve these cyber-security problems, one must cope with certain machine\nlearning challenges. We provide novel data sets representing the problems in\norder to enable the academic community to investigate the problems and suggest\nmethods to cope with the challenges. We also present a method to generate\nlabels via pivoting, providing a solution to common problems of lack of labels\nin cyber-security.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 10:19:25 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 10:34:03 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2019 09:14:22 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Amit", "Idan", ""], ["Matherly", "John", ""], ["Hewlett", "William", ""], ["Xu", "Zhi", ""], ["Meshi", "Yinnon", ""], ["Weinberger", "Yigal", ""]]}, {"id": "1812.07872", "submitter": "Alexander Goncharenko", "authors": "Alexander Goncharenko, Andrey Denisov, Sergey Alyamkin, Evgeny\n  Terentev", "title": "Fast Adjustable Threshold For Uniform Neural Network Quantization\n  (Winning solution of LPIRC-II)", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-20518-8_26", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural network quantization procedure is the necessary step for porting of\nneural networks to mobile devices. Quantization allows accelerating the\ninference, reducing memory consumption and model size. It can be performed\nwithout fine-tuning using calibration procedure (calculation of parameters\nnecessary for quantization), or it is possible to train the network with\nquantization from scratch. Training with quantization from scratch on the\nlabeled data is rather long and resource-consuming procedure. Quantization of\nnetwork without fine-tuning leads to accuracy drop because of outliers which\nappear during the calibration. In this article we suggest to simplify the\nquantization procedure significantly by introducing the trained scale factors\nfor quantization thresholds. It allows speeding up the process of quantization\nwith fine-tuning up to 8 epochs as well as reducing the requirements to the set\nof train images. By our knowledge, the proposed method allowed us to get the\nfirst public available quantized version of MNAS without significant accuracy\nreduction - 74.8% vs 75.3% for original full-precision network. Model and code\nare ready for use and available at:\nhttps://github.com/agoncharenko1992/FAT-fast_adjustable_threshold.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 10:54:32 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 04:44:48 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 04:48:29 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Goncharenko", "Alexander", ""], ["Denisov", "Andrey", ""], ["Alyamkin", "Sergey", ""], ["Terentev", "Evgeny", ""]]}, {"id": "1812.07895", "submitter": "Mirko Polato", "authors": "Mirko Polato and Fabio Aiolli", "title": "Interpretable preference learning: a game theoretic framework for large\n  margin on-line feature and rule learning", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of research is currently investigating on the connection between\nmachine learning and game theory. In this work, game theory notions are\ninjected into a preference learning framework. Specifically, a preference\nlearning problem is seen as a two-players zero-sum game. An algorithm is\nproposed to incrementally include new useful features into the hypothesis. This\ncan be particularly important when dealing with a very large number of\npotential features like, for instance, in relational learning and rule\nextraction. A game theoretical analysis is used to demonstrate the convergence\nof the algorithm. Furthermore, leveraging on the natural analogy between\nfeatures and rules, the resulting models can be easily interpreted by humans.\nAn extensive set of experiments on classification tasks shows the effectiveness\nof the proposed method in terms of interpretability and feature selection\nquality, with accuracy at the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 11:58:19 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Polato", "Mirko", ""], ["Aiolli", "Fabio", ""]]}, {"id": "1812.07903", "submitter": "Paul Pu Liang", "authors": "Hui Han Chin, Paul Pu Liang", "title": "An Empirical Evaluation of Sketched SVD and its Application to Leverage\n  Score Ordering", "comments": "ACML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of randomized algorithms in numerical methods have led to fast\nsolutions which use the Singular Value Decomposition (SVD) as a core routine.\nHowever, given the large data size of modern and the modest runtime of SVD,\nmost practical algorithms would require some form of approximation, such as\nsketching, when running SVD. While these approximation methods satisfy many\ntheoretical guarantees, we provide the first algorithmic implementations for\nsketch-and-solve SVD problems on real-world, large-scale datasets. We provide a\ncomprehensive empirical evaluation of these algorithms and provide guidelines\non how to ensure accurate deployment to real-world data. As an application of\nsketched SVD, we present Sketched Leverage Score Ordering, a technique for\ndetermining the ordering of data in the training of neural networks. Our\ntechnique is based on the distributed computation of leverage scores using\nrandom projections. These computed leverage scores provide a flexible and\nefficient method to determine the optimal ordering of training data without\nmanual intervention or annotations. We present empirical results on an\nextensive set of experiments across image classification, language sentiment\nanalysis, and multi-modal sentiment analysis. Our method is faster compared to\nstandard randomized projection algorithms and shows improvements in convergence\nand results.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 12:06:58 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Chin", "Hui Han", ""], ["Liang", "Paul Pu", ""]]}, {"id": "1812.07909", "submitter": "Paul Rubenstein", "authors": "Paul K. Rubenstein, Yunpeng Li, Dominik Roblek", "title": "An Empirical Study of Generative Models with Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are capable of producing high quality\nimage samples. However, unlike variational autoencoders (VAEs), GANs lack\nencoders that provide the inverse mapping for the generators, i.e., encode\nimages back to the latent space. In this work, we consider adversarially\nlearned generative models that also have encoders. We evaluate models based on\ntheir ability to produce high quality samples and reconstructions of real\nimages. Our main contributions are twofold: First, we find that the baseline\nBidirectional GAN (BiGAN) can be improved upon with the addition of an\nautoencoder loss, at the expense of an extra hyper-parameter to tune. Second,\nwe show that comparable performance to BiGAN can be obtained by simply training\nan encoder to invert the generator of a normal GAN.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 12:28:47 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Rubenstein", "Paul K.", ""], ["Li", "Yunpeng", ""], ["Roblek", "Dominik", ""]]}, {"id": "1812.07941", "submitter": "Temitayo Olugbade", "authors": "Temitayo A. Olugbade, Joseph Newbold, Rose Johnson, Erica Volta, Paolo\n  Alborno, Radoslaw Niewiadomski, Max Dillon, Gualtiero Volpe, and Nadia\n  Bianchi-Berthouze", "title": "Automatic Detection of Reflective Thinking in Mathematical Problem\n  Solving based on Unconstrained Bodily Exploration", "comments": null, "journal-ref": null, "doi": "10.1109/TAFFC.2020.2978069", "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For technology (like serious games) that aims to deliver interactive\nlearning, it is important to address relevant mental experiences such as\nreflective thinking during problem solving. To facilitate research in this\ndirection, we present the weDraw-1 Movement Dataset of body movement sensor\ndata and reflective thinking labels for 26 children solving mathematical\nproblems in unconstrained settings where the body (full or parts) was required\nto explore these problems. Further, we provide qualitative analysis of\nbehaviours that observers used in identifying reflective thinking moments in\nthese sessions. The body movement cues from our compilation informed features\nthat lead to average F1 score of 0.73 for automatic detection of reflective\nthinking based on Long Short-Term Memory neural networks. We further obtained\n0.79 average F1 score for end-to-end detection of reflective thinking periods,\ni.e. based on raw sensor data. Finally, the algorithms resulted in 0.64 average\nF1 score for period subsegments as short as 4 seconds. Overall, our results\nshow the possibility of detecting reflective thinking moments from body\nmovement behaviours of a child exploring mathematical concepts bodily, such as\nwithin serious game play.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:38:19 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 08:23:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Olugbade", "Temitayo A.", ""], ["Newbold", "Joseph", ""], ["Johnson", "Rose", ""], ["Volta", "Erica", ""], ["Alborno", "Paolo", ""], ["Niewiadomski", "Radoslaw", ""], ["Dillon", "Max", ""], ["Volpe", "Gualtiero", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "1812.07965", "submitter": "Yali Amit", "authors": "Yali Amit", "title": "Deep learning with asymmetric connections and Hebbian updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that deep networks can be trained using Hebbian updates yielding\nsimilar performance to ordinary back-propagation on challenging image datasets.\nTo overcome the unrealistic symmetry in connections between layers, implicit in\nback-propagation, the feedback weights are separate from the feedforward\nweights. The feedback weights are also updated with a local rule, the same as\nthe feedforward weights - a weight is updated solely based on the product of\nactivity of the units it connects. With fixed feedback weights as proposed in\nLillicrap et. al (2016) performance degrades quickly as the depth of the\nnetwork increases. If the feedforward and feedback weights are initialized with\nthe same values, as proposed in Zipser and Rumelhart (1990), they remain the\nsame throughout training thus precisely implementing back-propagation. We show\nthat even when the weights are initialized differently and at random, and the\nalgorithm is no longer performing back-propagation, performance is comparable\non challenging datasets. We also propose a cost function whose derivative can\nbe represented as a local Hebbian update on the last layer. Convolutional\nlayers are updated with tied weights across space, which is not biologically\nplausible. We show that similar performance is achieved with untied layers,\nalso known as locally connected layers, corresponding to the connectivity\nimplied by the convolutional layers, but where weights are untied and updated\nseparately. In the linear case we show theoretically that the convergence of\nthe error to zero is accelerated by the update of the feedback weights.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 20:40:29 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 21:05:57 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Amit", "Yali", ""]]}, {"id": "1812.08011", "submitter": "Naigang Wang", "authors": "Naigang Wang, Jungwook Choi, Daniel Brand, Chia-Yu Chen and Kailash\n  Gopalakrishnan", "title": "Training Deep Neural Networks with 8-bit Floating Point Numbers", "comments": "NeurIPS 2018 (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art hardware platforms for training Deep Neural Networks\n(DNNs) are moving from traditional single precision (32-bit) computations\ntowards 16 bits of precision -- in large part due to the high energy efficiency\nand smaller bit storage associated with using reduced-precision\nrepresentations. However, unlike inference, training with numbers represented\nwith less than 16 bits has been challenging due to the need to maintain\nfidelity of the gradient computations during back-propagation. Here we\ndemonstrate, for the first time, the successful training of DNNs using 8-bit\nfloating point numbers while fully maintaining the accuracy on a spectrum of\nDeep Learning models and datasets. In addition to reducing the data and\ncomputation precision to 8 bits, we also successfully reduce the arithmetic\nprecision for additions (used in partial product accumulation and weight\nupdates) from 32 bits to 16 bits through the introduction of a number of key\nideas including chunk-based accumulation and floating point stochastic\nrounding. The use of these novel techniques lays the foundation for a new\ngeneration of hardware training platforms with the potential for 2-4x improved\nthroughput over today's systems.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 15:15:55 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Wang", "Naigang", ""], ["Choi", "Jungwook", ""], ["Brand", "Daniel", ""], ["Chen", "Chia-Yu", ""], ["Gopalakrishnan", "Kailash", ""]]}, {"id": "1812.08040", "submitter": "Jarek Duda dr", "authors": "Jarek Duda, Adam Szulc", "title": "Credibility evaluation of income data with hierarchical correlation\n  reconstruction", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In situations like tax declarations or analyzes of household budgets we would\nlike to automatically evaluate credibility of exogenous variable (declared\nincome) based on some available (endogenous) variables - we want to build a\nmodel and train it on provided data sample to predict (conditional) probability\ndistribution of exogenous variable based on values of endogenous variables.\nUsing Polish household budget survey data there will be discussed simple and\nsystematic adaptation of hierarchical correlation reconstruction (HCR)\ntechnique for this purpose, which allows to combine interpretability of\nstatistics with modelling of complex densities like in machine learning. For\ncredibility evaluation we normalize marginal distribution of predicted variable\nto $\\rho\\approx 1$ uniform distribution on $[0,1]$ using empirical distribution\nfunction $(x=EDF(y)\\in[0,1])$, then model density of its conditional\ndistribution $(\\textrm{Pr}(x_0|x_1 x_2\\ldots))$ as a linear combination of\northonormal polynomials using coefficients modelled as linear combinations of\nfeatures of the remaining variables. These coefficients can be calculated\nindependently, have similar interpretation as cumulants, additionally allowing\nto directly reconstruct probability distribution. Values corresponding to high\npredicted density can be considered as credible, while low density suggests\ndisagreement with statistics of data sample, for example to mark for manual\nverification a chosen percentage of data points evaluated as the least\ncredible.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 15:56:27 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 15:45:16 GMT"}, {"version": "v3", "created": "Sun, 21 Apr 2019 20:03:50 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Duda", "Jarek", ""], ["Szulc", "Adam", ""]]}, {"id": "1812.08047", "submitter": "Ramanarayan Mohanty", "authors": "Ramanarayan Mohanty, S L Happy, Aurobinda Routray", "title": "Spatial-Spectral Regularized Local Scaling Cut for Dimensionality\n  Reduction in Hyperspectral Image Classification", "comments": "arXiv admin note: text overlap with arXiv:1811.08223", "journal-ref": "IEEE Geoscience and Remote Sensing Letters, 2018", "doi": "10.1109/LGRS.2018.2885809", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction (DR) methods have attracted extensive attention to\nprovide discriminative information and reduce the computational burden of the\nhyperspectral image (HSI) classification. However, the DR methods face many\nchallenges due to limited training samples with high dimensional spectra. To\naddress this issue, a graph-based spatial and spectral regularized local\nscaling cut (SSRLSC) for DR of HSI data is proposed. The underlying idea of the\nproposed method is to utilize the information from both the spectral and\nspatial domains to achieve better classification accuracy than its spectral\ndomain counterpart. In SSRLSC, a guided filter is initially used to smoothen\nand homogenize the pixels of the HSI data in order to preserve the pixel\nconsistency. This is followed by generation of between-class and within-class\ndissimilarity matrices in both spectral and spatial domains by regularized\nlocal scaling cut (RLSC) and neighboring pixel local scaling cut (NPLSC)\nrespectively. Finally, we obtain the projection matrix by optimizing the\nupdated spatial-spectral between-class and total-class dissimilarity. The\neffectiveness of the proposed DR algorithm is illustrated with two popular\nreal-world HSI datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 04:13:31 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Mohanty", "Ramanarayan", ""], ["Happy", "S L", ""], ["Routray", "Aurobinda", ""]]}, {"id": "1812.08113", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Ke Sun", "title": "On The Chain Rule Optimal Transport Distance", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a novel class of distances between statistical multivariate\ndistributions by modeling an optimal transport problem on their marginals with\nrespect to a ground distance defined on their conditionals. These new distances\nare metrics whenever the ground distance between the marginals is a metric,\ngeneralize both the Wasserstein distances between discrete measures and a\nrecently introduced metric distance between statistical mixtures, and provide\nan upper bound for jointly convex distances between statistical mixtures. By\nentropic regularization of the optimal transport, we obtain a fast\ndifferentiable Sinkhorn-type distance. We experimentally evaluate our new\nfamily of distances by quantifying the upper bounds of several jointly convex\ndistances between statistical mixtures, and by proposing a novel efficient\nmethod to learn Gaussian mixture models (GMMs) by simplifying kernel density\nestimators with respect to our distance. Our GMM learning technique\nexperimentally improves significantly over the EM implementation of {\\tt\nsklearn} on the {\\tt MNIST} and {\\tt Fashion MNIST} datasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 17:43:02 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 06:59:12 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 07:12:37 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Nielsen", "Frank", ""], ["Sun", "Ke", ""]]}, {"id": "1812.08119", "submitter": "Atsushi Yaguchi", "authors": "Atsushi Yaguchi, Taiji Suzuki, Wataru Asano, Shuhei Nitta, Yukinobu\n  Sakata, Akiyuki Tanizawa", "title": "Adam Induces Implicit Weight Sparsity in Rectifier Neural Networks", "comments": "8 pages, 7 figures, 6 tables, 2018 17th IEEE International Conference\n  on Machine Learning and Applications (ICMLA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks (DNNs) have been applied to various\nmachine leaning tasks, including image recognition, speech recognition, and\nmachine translation. However, large DNN models are needed to achieve\nstate-of-the-art performance, exceeding the capabilities of edge devices. Model\nreduction is thus needed for practical use. In this paper, we point out that\ndeep learning automatically induces group sparsity of weights, in which all\nweights connected to an output channel (node) are zero, when training DNNs\nunder the following three conditions: (1) rectified-linear-unit (ReLU)\nactivations, (2) an $L_2$-regularized objective function, and (3) the Adam\noptimizer. Next, we analyze this behavior both theoretically and\nexperimentally, and propose a simple model reduction method: eliminate the zero\nweights after training the DNN. In experiments on MNIST and CIFAR-10 datasets,\nwe demonstrate the sparsity with various training setups. Finally, we show that\nour method can efficiently reduce the model size and performs well relative to\nmethods that use a sparsity-inducing regularizer.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 17:59:08 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Yaguchi", "Atsushi", ""], ["Suzuki", "Taiji", ""], ["Asano", "Wataru", ""], ["Nitta", "Shuhei", ""], ["Sakata", "Yukinobu", ""], ["Tanizawa", "Akiyuki", ""]]}, {"id": "1812.08194", "submitter": "Johannes Oberpriller", "authors": "Johannes Oberpriller, T. A. En{\\ss}lin", "title": "Bayesian parameter estimation of miss-specified models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting a simplifying model with several parameters to real data of complex\nobjects is a highly nontrivial task, but enables the possibility to get\ninsights into the objects physics. Here, we present a method to infer the\nparameters of the model, the model error as well as the statistics of the model\nerror. This method relies on the usage of many data sets in a simultaneous\nanalysis in order to overcome the problems caused by the degeneracy between\nmodel parameters and model error. Errors in the modeling of the measurement\ninstrument can be absorbed in the model error allowing for applications with\ncomplex instruments.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 19:05:59 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Oberpriller", "Johannes", ""], ["En\u00dflin", "T. A.", ""]]}, {"id": "1812.08237", "submitter": "Huadong Wang", "authors": "Yong Shi, Huadong Wang, Xin Shen, Lingfeng Niu", "title": "A Novel Large-scale Ordinal Regression Model", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal regression (OR) is a special multiclass classification problem where\nan order relation exists among the labels. Recent years, people share their\nopinions and sentimental judgments conveniently with social networks and\nE-Commerce so that plentiful large-scale OR problems arise. However, few\nstudies have focused on this kind of problems. Nonparallel Support Vector\nOrdinal Regression (NPSVOR) is a SVM-based OR model, which learns a hyperplane\nfor each rank by solving a series of independent sub-optimization problems and\nthen ensembles those learned hyperplanes to predict. The previous studies are\nfocused on its nonlinear case and got a competitive testing performance, but\nits training is time consuming, particularly for large-scale data. In this\npaper, we consider NPSVOR's linear case and design an efficient training method\nbased on the dual coordinate descent method (DCD). To utilize the order\ninformation among labels in prediction, a new prediction function is also\nproposed. Extensive contrast experiments on the text OR datasets indicate that\nthe carefully implemented DCD is very suitable for training large data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 20:53:24 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Shi", "Yong", ""], ["Wang", "Huadong", ""], ["Shen", "Xin", ""], ["Niu", "Lingfeng", ""]]}, {"id": "1812.08255", "submitter": "Jacob Whitehill", "authors": "Jacob Whitehill and Anand Ramakrishnan", "title": "Automatic Classifiers as Scientific Instruments: One Step Further Away\n  from Ground-Truth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic machine learning-based detectors of various psychological and\nsocial phenomena (e.g., emotion, stress, engagement) have great potential to\nadvance basic science. However, when a detector $d$ is trained to approximate\nan existing measurement tool (e.g., a questionnaire, observation protocol),\nthen care must be taken when interpreting measurements collected using $d$\nsince they are one step further removed from the underlying construct. We\nexamine how the accuracy of $d$, as quantified by the correlation $q$ of $d$'s\noutputs with the ground-truth construct $U$, impacts the estimated correlation\nbetween $U$ (e.g., stress) and some other phenomenon $V$ (e.g., academic\nperformance). In particular: (1) We show that if the true correlation between\n$U$ and $V$ is $r$, then the expected sample correlation, over all vectors\n$\\mathcal{T}^n$ whose correlation with $U$ is $q$, is $qr$. (2) We derive a\nformula for the probability that the sample correlation (over $n$ subjects)\nusing $d$ is positive given that the true correlation is negative (and\nvice-versa); this probability can be substantial (around $20-30\\%$) for values\nof $n$ and $q$ that have been used in recent affective computing studies. %We\nalso show that this probability decreases monotonically in $n$ and in $q$. (3)\nWith the goal to reduce the variance of correlations estimated by an automatic\ndetector, we show that training multiple neural networks\n$d^{(1)},\\ldots,d^{(m)}$ using different training architectures and\nhyperparameters for the same detection task provides only limited ``coverage''\nof $\\mathcal{T}^n$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 21:32:14 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 17:14:53 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Whitehill", "Jacob", ""], ["Ramakrishnan", "Anand", ""]]}, {"id": "1812.08265", "submitter": "Bart{\\l}omiej B{\\l}aszczyszyn", "authors": "Antoine Brochard, Bart{\\l}omiej B{\\l}aszczyszyn, St\\'ephane Mallat,\n  Sixin Zhang", "title": "Statistical learning of geometric characteristics of wireless networks", "comments": "Accepted for IEEE INFOCOM 2019", "journal-ref": "Proc. of IEEE Infocom 2019", "doi": "10.1109/INFOCOM.2019.8737441", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the prediction of cell loads in cellular networks, we formulate\nthe following new, fundamental problem of statistical learning of geometric\nmarks of point processes: An unknown marking function, depending on the\ngeometry of point patterns, produces characteristics (marks) of the points. One\naims at learning this function from the examples of marked point patterns in\norder to predict the marks of new point patterns. To approximate (interpolate)\nthe marking function, in our baseline approach, we build a statistical\nregression model of the marks with respect some local point distance\nrepresentation. In a more advanced approach, we use a global data\nrepresentation via the scattering moments of random measures, which build\ninformative and stable to deformations data representation, already proven\nuseful in image analysis and related application domains. In this case, the\nregression of the scattering moments of the marked point patterns with respect\nto the non-marked ones is combined with the numerical solution of the inverse\nproblem, where the marks are recovered from the estimated scattering moments.\nConsidering some simple, generic marks, often appearing in the modeling of\nwireless networks, such as the shot-noise values, nearest neighbour distance,\nand some characteristics of the Voronoi cells, we show that the scattering\nmoments can capture similar geometry information as the baseline approach, and\ncan reach even better performance, especially for non-local marking functions.\nOur results motivate further development of statistical learning tools for\nstochastic geometry and analysis of wireless networks, in particular to predict\ncell loads in cellular networks from the locations of base stations and traffic\ndemand.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 22:03:52 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Brochard", "Antoine", ""], ["B\u0142aszczyszyn", "Bart\u0142omiej", ""], ["Mallat", "St\u00e9phane", ""], ["Zhang", "Sixin", ""]]}, {"id": "1812.08284", "submitter": "Nutan Chen Ph.D.", "authors": "Nutan Chen, Francesco Ferroni, Alexej Klushyn, Alexandros Paraschos,\n  Justin Bayer, Patrick van der Smagt", "title": "Fast Approximate Geodesics for Deep Generative Models", "comments": "28th International Conference on Artificial Neural Networks, 2019", "journal-ref": "28th International Conference on Artificial Neural Networks, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The length of the geodesic between two data points along a Riemannian\nmanifold, induced by a deep generative model, yields a principled measure of\nsimilarity. Current approaches are limited to low-dimensional latent spaces,\ndue to the computational complexity of solving a non-convex optimisation\nproblem. We propose finding shortest paths in a finite graph of samples from\nthe aggregate approximate posterior, that can be solved exactly, at greatly\nreduced runtime, and without a notable loss in quality. Our approach,\ntherefore, is hence applicable to high-dimensional problems, e.g., in the\nvisual domain. We validate our approach empirically on a series of experiments\nusing variational autoencoders applied to image data, including the Chair,\nFashionMNIST, and human movement data sets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 23:06:32 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 09:32:25 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Chen", "Nutan", ""], ["Ferroni", "Francesco", ""], ["Klushyn", "Alexej", ""], ["Paraschos", "Alexandros", ""], ["Bayer", "Justin", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1812.08287", "submitter": "Pedram Ghamisi Dr.", "authors": "Pedram Ghamisi, Behnood Rasti, Naoto Yokoya, Qunming Wang, Bernhard\n  Hofle, Lorenzo Bruzzone, Francesca Bovolo, Mingmin Chi, Katharina Anders,\n  Richard Gloaguen, Peter M. Atkinson, Jon Atli Benediktsson", "title": "Multisource and Multitemporal Data Fusion in Remote Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sharp and recent increase in the availability of data captured by\ndifferent sensors combined with their considerably heterogeneous natures poses\na serious challenge for the effective and efficient processing of remotely\nsensed data. Such an increase in remote sensing and ancillary datasets,\nhowever, opens up the possibility of utilizing multimodal datasets in a joint\nmanner to further improve the performance of the processing approaches with\nrespect to the application at hand. Multisource data fusion has, therefore,\nreceived enormous attention from researchers worldwide for a wide variety of\napplications. Moreover, thanks to the revisit capability of several spaceborne\nsensors, the integration of the temporal information with the spatial and/or\nspectral/backscattering information of the remotely sensed data is possible and\nhelps to move from a representation of 2D/3D data to 4D data structures, where\nthe time variable adds new information as well as challenges for the\ninformation extraction algorithms. There are a huge number of research works\ndedicated to multisource and multitemporal data fusion, but the methods for the\nfusion of different modalities have expanded in different paths according to\neach research community. This paper brings together the advances of multisource\nand multitemporal data fusion approaches with respect to different research\ncommunities and provides a thorough and discipline-specific starting point for\nresearchers at different levels (i.e., students, researchers, and senior\nresearchers) willing to conduct novel investigations on this challenging topic\nby supplying sufficient detail and references.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 23:09:42 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Ghamisi", "Pedram", ""], ["Rasti", "Behnood", ""], ["Yokoya", "Naoto", ""], ["Wang", "Qunming", ""], ["Hofle", "Bernhard", ""], ["Bruzzone", "Lorenzo", ""], ["Bovolo", "Francesca", ""], ["Chi", "Mingmin", ""], ["Anders", "Katharina", ""], ["Gloaguen", "Richard", ""], ["Atkinson", "Peter M.", ""], ["Benediktsson", "Jon Atli", ""]]}, {"id": "1812.08288", "submitter": "Simone Parisi", "authors": "Simone Parisi, Voot Tangkaratt, Jan Peters, and Mohammad Emtiyaz Khan", "title": "TD-Regularized Actor-Critic Methods", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-019-05788-0", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor-critic methods can achieve incredible performance on difficult\nreinforcement learning problems, but they are also prone to instability. This\nis partly due to the interaction between the actor and critic during learning,\ne.g., an inaccurate step taken by one of them might adversely affect the other\nand destabilize the learning. To avoid such issues, we propose to regularize\nthe learning objective of the actor by penalizing the temporal difference (TD)\nerror of the critic. This improves stability by avoiding large steps in the\nactor update whenever the critic is highly inaccurate. The resulting method,\nwhich we call the TD-regularized actor-critic method, is a simple plug-and-play\napproach to improve stability and overall performance of the actor-critic\nmethods. Evaluations on standard benchmarks confirm this.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 23:15:16 GMT"}, {"version": "v2", "created": "Sun, 23 Dec 2018 16:25:20 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 16:41:26 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Parisi", "Simone", ""], ["Tangkaratt", "Voot", ""], ["Peters", "Jan", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "1812.08292", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko", "title": "Finite-time optimality of Bayesian predictors", "comments": null, "journal-ref": "On Asymptotic and Finite-Time Optimality of Bayesian Predictors,\n  Journal of Machine Learning Research (149):1-24, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of sequential probability forecasting is considered in the most\ngeneral setting: a model set C is given, and it is required to predict as well\nas possible if any of the measures (environments) in C is chosen to generate\nthe data. No assumptions whatsoever are made on the model class C, in\nparticular, no independence or mixing assumptions; C may not be measurable;\nthere may be no predictor whose loss is sublinear, etc. It is shown that the\ncumulative loss of any possible predictor can be matched by that of a Bayesian\npredictor whose prior is discrete and is concentrated on C, up to an additive\nterm of order $\\log n$, where $n$ is the time step. The bound holds for every\n$n$ and every measure in C. This is the first non-asymptotic result of this\nkind. In addition, a non-matching lower bound is established: it goes to\ninfinity with $n$ but may do so arbitrarily slow.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 00:18:28 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 07:07:21 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Ryabko", "Daniil", ""]]}, {"id": "1812.08295", "submitter": "Ryosuke Kasahara", "authors": "Takuya Tanaka, Ryosuke Kasahara, Daishiro Kobayashi", "title": "Efficient logic architecture in training gradient boosting decision tree\n  for high-performance and edge computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a logic architecture for the high-speed and power\nefficiently training of a gradient boosting decision tree model of binary\nclassification. We implemented the proposed logic architecture on an FPGA and\ncompared training time and power efficiency with three general GBDT software\nlibraries using CPU and GPU. The training speed of the logic architecture on\nthe FPGA was 26-259 times faster than the software libraries. The power\nefficiency of the logic architecture was 90-1,104 times higher than the\nsoftware libraries. The results show that the logic architecture suits for\nhigh-performance and edge computing.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 00:28:12 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Tanaka", "Takuya", ""], ["Kasahara", "Ryosuke", ""], ["Kobayashi", "Daishiro", ""]]}, {"id": "1812.08305", "submitter": "Ashwin Pananjady", "authors": "Dhruv Malik, Ashwin Pananjady, Kush Bhatia, Koulik Khamaru, Peter L.\n  Bartlett, Martin J. Wainwright", "title": "Derivative-Free Methods for Policy Optimization: Guarantees for Linear\n  Quadratic Systems", "comments": "Version v3 consistent with paper appearing in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study derivative-free methods for policy optimization over the class of\nlinear policies. We focus on characterizing the convergence rate of these\nmethods when applied to linear-quadratic systems, and study various settings of\ndriving noise and reward feedback. We show that these methods provably converge\nto within any pre-specified tolerance of the optimal policy with a number of\nzero-order evaluations that is an explicit polynomial of the error tolerance,\ndimension, and curvature properties of the problem. Our analysis reveals some\ninteresting differences between the settings of additive driving noise and\nrandom initialization, as well as the settings of one-point and two-point\nreward feedback. Our theory is corroborated by extensive simulations of\nderivative-free methods on these systems. Along the way, we derive convergence\nrates for stochastic zero-order optimization algorithms when applied to a\ncertain class of non-convex problems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 01:22:44 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 02:37:58 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 15:50:36 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Malik", "Dhruv", ""], ["Pananjady", "Ashwin", ""], ["Bhatia", "Kush", ""], ["Khamaru", "Koulik", ""], ["Bartlett", "Peter L.", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1812.08306", "submitter": "Josif Grabocka", "authors": "Josif Grabocka, Lars Schmidt-Thieme", "title": "NeuralWarp: Time-Series Similarity with Warping Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on time-series similarity measures has emphasized the need for\nelastic methods which align the indices of pairs of time series and a plethora\nof non-parametric have been proposed for the task. On the other hand, deep\nlearning approaches are dominant in closely related domains, such as learning\nimage and text sentence similarity. In this paper, we propose\n\\textit{NeuralWarp}, a novel measure that models the alignment of time-series\nindices in a deep representation space, by modeling a warping function as an\nupper level neural network between deeply-encoded time series values.\nExperimental results demonstrate that \\textit{NeuralWarp} outperforms both\nnon-parametric and un-warped deep models on a range of diverse real-life\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 01:26:08 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1812.08329", "submitter": "Tsui-Wei Weng", "authors": "Tsui-Wei Weng, Pin-Yu Chen, Lam M. Nguyen, Mark S. Squillante, Ivan\n  Oseledets, Luca Daniel", "title": "PROVEN: Certifying Robustness of Neural Networks with a Probabilistic\n  Approach", "comments": "updated ref [25]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With deep neural networks providing state-of-the-art machine learning models\nfor numerous machine learning tasks, quantifying the robustness of these models\nhas become an important area of research. However, most of the research\nliterature merely focuses on the \\textit{worst-case} setting where the input of\nthe neural network is perturbed with noises that are constrained within an\n$\\ell_p$ ball; and several algorithms have been proposed to compute certified\nlower bounds of minimum adversarial distortion based on such worst-case\nanalysis. In this paper, we address these limitations and extend the approach\nto a \\textit{probabilistic} setting where the additive noises can follow a\ngiven distributional characterization. We propose a novel probabilistic\nframework PROVEN to PRObabilistically VErify Neural networks with statistical\nguarantees -- i.e., PROVEN certifies the probability that the classifier's\ntop-1 prediction cannot be altered under any constrained $\\ell_p$ norm\nperturbation to a given input. Importantly, we show that it is possible to\nderive closed-form probabilistic certificates based on current state-of-the-art\nneural network robustness verification frameworks. Hence, the probabilistic\ncertificates provided by PROVEN come naturally and with almost no overhead when\nobtaining the worst-case certified lower bounds from existing methods such as\nFast-Lin, CROWN and CNN-Cert. Experiments on small and large MNIST and CIFAR\nneural network models demonstrate our probabilistic approach can achieve up to\naround $75\\%$ improvement in the robustness certification with at least a\n$99.99\\%$ confidence compared with the worst-case robustness certificate\ndelivered by CROWN.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 18:59:38 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 05:34:00 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Weng", "Tsui-Wei", ""], ["Chen", "Pin-Yu", ""], ["Nguyen", "Lam M.", ""], ["Squillante", "Mark S.", ""], ["Oseledets", "Ivan", ""], ["Daniel", "Luca", ""]]}, {"id": "1812.08352", "submitter": "Yu Cheng", "authors": "Yu Cheng, Zhe Gan, Yitong Li, Jingjing Liu, Jianfeng Gao", "title": "Sequential Attention GAN for Interactive Image Editing", "comments": "ACM MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing text-to-image synthesis tasks are static single-turn\ngeneration, based on pre-defined textual descriptions of images. To explore\nmore practical and interactive real-life applications, we introduce a new task\n- Interactive Image Editing, where users can guide an agent to edit images via\nmulti-turn textual commands on-the-fly. In each session, the agent takes a\nnatural language description from the user as the input and modifies the image\ngenerated in the previous turn to a new design, following the user description.\nThe main challenges in this sequential and interactive image generation task\nare two-fold: 1) contextual consistency between a generated image and the\nprovided textual description; 2) step-by-step region-level modification to\nmaintain visual consistency across the generated image sequence in each\nsession. To address these challenges, we propose a novel Sequential Attention\nGenerative Adversarial Net-work (SeqAttnGAN), which applies a neural state\ntracker to encode the previous image and the textual description in each turn\nof the sequence, and uses a GAN framework to generate a modified version of the\nimage that is consistent with the preceding images and coherent with the\ndescription. To achieve better region-specific refinement, we also introduce a\nsequential attention mechanism into the model. To benchmark on the new task, we\nintroduce two new datasets, Zap-Seq and DeepFashion-Seq, which contain\nmulti-turn sessions with image-description sequences in the fashion domain.\nExperiments on both datasets show that the proposed SeqAttnGANmodel outperforms\nstate-of-the-art approaches on the interactive image editing task across all\nevaluation metrics including visual quality, image sequence coherence, and\ntext-image consistency.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 03:55:33 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 00:32:27 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2019 19:06:18 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2020 22:13:20 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Li", "Yitong", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1812.08389", "submitter": "Shandong Dong", "authors": "Zhang Rong, Dong Shandong, Nie Xin, Xiao Shiguang", "title": "Feedforward Neural Network for Time Series Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series anomaly detection is usually formulated as finding outlier data\npoints relative to some usual data, which is also an important problem in\nindustry and academia. To ensure systems working stably, internet companies,\nbanks and other companies need to monitor time series, which is called KPI (Key\nPerformance Indicators), such as CPU used, number of orders, number of online\nusers and so on. However, millions of time series have several shapes (e.g.\nseasonal KPIs, KPIs of timed tasks and KPIs of CPU used), so that it is very\ndifficult to use a simple statistical model to detect anomaly for all kinds of\ntime series. Although some anomaly detectors have developed many years and some\nsupervised models are also available in this field, we find many methods have\ntheir own disadvantages. In this paper, we present our system, which is based\non deep feedforward neural network and detect anomaly points of time series.\nThe main difference between our system and other systems based on supervised\nmodels is that we do not need feature engineering of time series to train deep\nfeedforward neural network in our system, which is essentially an end-to-end\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 07:11:11 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 01:28:14 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Rong", "Zhang", ""], ["Shandong", "Dong", ""], ["Xin", "Nie", ""], ["Shiguang", "Xiao", ""]]}, {"id": "1812.08398", "submitter": "Genevieve Robin", "authors": "Genevi\\`eve Robin (XPOP,CMAP), Hoi-To Wai (ASU), Julie Josse (CMAP),\n  Olga Klopp (MODAL'X), \\'Eric Moulines (CMAP,XPOP)", "title": "Low-rank Interaction with Sparse Additive Effects Model for Large Data\n  Frames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of machine learning involve the analysis of large data\nframes-matrices collecting heterogeneous measurements (binary, numerical,\ncounts, etc.) across samples-with missing values. Low-rank models, as studied\nby Udell et al. [30], are popular in this framework for tasks such as\nvisualization, clustering and missing value imputation. Yet, available methods\nwith statistical guarantees and efficient optimization do not allow explicit\nmodeling of main additive effects such as row and column, or covariate effects.\nIn this paper, we introduce a low-rank interaction and sparse additive effects\n(LORIS) model which combines matrix regression on a dictionary and low-rank\ndesign, to estimate main effects and interactions simultaneously. We provide\nstatistical guarantees in the form of upper bounds on the estimation error of\nboth components. Then, we introduce a mixed coordinate gradient descent (MCGD)\nmethod which provably converges sub-linearly to an optimal solution and is\ncomputationally efficient for large scale data sets. We show on simulated and\nsurvey data that the method has a clear advantage over current practices, which\nconsist in dealing separately with additive effects in a preprocessing step.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 07:28:42 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Robin", "Genevi\u00e8ve", "", "XPOP,CMAP"], ["Wai", "Hoi-To", "", "ASU"], ["Josse", "Julie", "", "CMAP"], ["Klopp", "Olga", "", "MODAL'X"], ["Moulines", "\u00c9ric", "", "CMAP,XPOP"]]}, {"id": "1812.08434", "submitter": "Jie Zhou", "authors": "Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan\n  Liu, Lifeng Wang, Changcheng Li, Maosong Sun", "title": "Graph Neural Networks: A Review of Methods and Applications", "comments": "Published at AI Open 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lots of learning tasks require dealing with graph data which contains rich\nrelation information among elements. Modeling physics systems, learning\nmolecular fingerprints, predicting protein interface, and classifying diseases\ndemand a model to learn from graph inputs. In other domains such as learning\nfrom non-structural data like texts and images, reasoning on extracted\nstructures (like the dependency trees of sentences and the scene graphs of\nimages) is an important research topic which also needs graph reasoning models.\nGraph neural networks (GNNs) are neural models that capture the dependence of\ngraphs via message passing between the nodes of graphs. In recent years,\nvariants of GNNs such as graph convolutional network (GCN), graph attention\nnetwork (GAT), graph recurrent network (GRN) have demonstrated ground-breaking\nperformances on many deep learning tasks. In this survey, we propose a general\ndesign pipeline for GNN models and discuss the variants of each component,\nsystematically categorize the applications, and propose four open problems for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 09:30:12 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 02:01:05 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 09:08:03 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2019 14:50:01 GMT"}, {"version": "v5", "created": "Fri, 9 Apr 2021 07:27:34 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Zhou", "Jie", ""], ["Cui", "Ganqu", ""], ["Hu", "Shengding", ""], ["Zhang", "Zhengyan", ""], ["Yang", "Cheng", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Lifeng", ""], ["Li", "Changcheng", ""], ["Sun", "Maosong", ""]]}, {"id": "1812.08468", "submitter": "Patrick Schlachter", "authors": "Patrick Schlachter, Yiwen Liao and Bin Yang", "title": "One-Class Feature Learning Using Intra-Class Splitting", "comments": "IEEE European Signal Processing Conference 2019 (EUSIPCO 2019)", "journal-ref": null, "doi": "10.23919/EUSIPCO.2019.8902848", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel generic one-class feature learning method based\non intra-class splitting. In one-class classification, feature learning is\nchallenging, because only samples of one class are available during training.\nHence, state-of-the-art methods require reference multi-class datasets to\npretrain feature extractors. In contrast, the proposed method realizes feature\nlearning by splitting the given normal class into typical and atypical normal\nsamples. By introducing closeness loss and dispersion loss, an intra-class\njoint training procedure between the two subsets after splitting enables the\nextraction of valuable features for one-class classification. Various\nexperiments on three well-known image classification datasets demonstrate the\neffectiveness of our method which outperformed other baseline models in\naverage.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 10:32:46 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 08:12:38 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 08:35:08 GMT"}, {"version": "v4", "created": "Wed, 19 Jun 2019 14:38:47 GMT"}, {"version": "v5", "created": "Wed, 20 Nov 2019 13:51:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Schlachter", "Patrick", ""], ["Liao", "Yiwen", ""], ["Yang", "Bin", ""]]}, {"id": "1812.08555", "submitter": "Vasileios Belagiannis", "authors": "Leslie Casas, Attila Klimmek, Nassir Navab, Vasileios Belagiannis", "title": "Adversarial Signal Denoising with Encoder-Decoder Networks", "comments": "5 pages, 2 figures. Accepted at EUSIPCO 2020 (2020 28th European\n  Signal Processing Conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of noise is common in signal processing regardless the signal\ntype. Deep neural networks have shown good performance in noise removal,\nespecially on the image domain. In this work, we consider deep neural networks\nas a denoising tool where our focus is on one dimensional signals. We introduce\nan encoder-decoder architecture to denoise signals, represented by a sequence\nof measurements. Instead of relying only on the standard reconstruction error\nto train the encoder-decoder network, we treat the task of denoising as\ndistribution alignment between the clean and noisy signals. Then, we propose an\nadversarial learning formulation where the goal is to align the clean and noisy\nsignal latent representation given that both signals pass through the encoder.\nIn our approach, the discriminator has the role of detecting whether the latent\nrepresentation comes from clean or noisy signals. We evaluate on\nelectrocardiogram and motion signal denoising; and show better performance than\nlearning-based and non-learning approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 13:40:18 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 08:15:56 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 09:35:05 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Casas", "Leslie", ""], ["Klimmek", "Attila", ""], ["Navab", "Nassir", ""], ["Belagiannis", "Vasileios", ""]]}, {"id": "1812.08625", "submitter": "Carl Leake", "authors": "Carl Leake", "title": "Deep Theory of Functional Connections: A New Method for Estimating the\n  Solutions of PDEs", "comments": "14 pages, 7 figures", "journal-ref": "Mach. Learn. Knowl. Extr. 2020, 2(1), 37-55", "doi": "10.3390/make2010004", "report-no": null, "categories": "cs.NA cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a new methodology called deep Theory of Functional\nConnections (TFC) that estimates the solutions of partial differential\nequations (PDEs) by combining neural networks with TFC. TFC is used to\ntransform PDEs with boundary conditions into unconstrained optimization\nproblems by embedding the boundary conditions into a \"constrained expression.\"\nIn this work, a neural network is chosen as the free function, and used to\nsolve the now unconstrained optimization problem. The loss function is taken as\nthe square of the residual of the PDE. Then, the neural network is trained in\nan unsupervised manner to solve the unconstrained optimization problem. This\nmethodology has two major differences when compared with popular methods used\nto estimate the solutions of PDEs. First, this methodology does not need to\ndiscretize the domain into a grid, rather, this methodology randomly samples\npoints from the domain during the training phase. Second, after training, this\nmethodology represents a closed form, analytical, differentiable approximation\nof the solution throughout the entire training domain. In contrast, other\npopular methods require interpolation if the estimated solution is desired at\npoints that do not lie on the discretized grid. The deep TFC method for\nestimating the solution of PDEs is demonstrated on four problems with a variety\nof boundary conditions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 15:05:25 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 16:58:52 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 14:42:18 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Leake", "Carl", ""]]}, {"id": "1812.08655", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Danial Azam, Arpit Kapoor, R. Dietmar M\\\"uller", "title": "Surrogate-assisted Bayesian inversion for landscape and basin evolution\n  models", "comments": "Geoscientific Model Development", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NE physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The complex and computationally expensive nature of landscape evolution\nmodels pose significant challenges in the inference and optimisation of unknown\nparameters. Bayesian inference provides a methodology for estimation and\nuncertainty quantification of unknown model parameters. In our previous work,\nwe developed parallel tempering Bayeslands as a framework for parameter\nestimation and uncertainty quantification for the Badlands landscape evolution\nmodel. Parallel tempering Bayeslands features high-performance computing with\ndozens of processing cores running in parallel to enhance computational\nefficiency. Although we use parallel computing, the procedure remains\ncomputationally challenging since thousands of samples need to be drawn and\nevaluated. \\textcolor{black}{In large-scale landscape and basin evolution\nproblems, a single model evaluation can take from several minutes to hours, and\nin some instances, even days. Surrogate-assisted optimisation has been used for\nseveral computationally expensive engineering problems which motivate its use\nin optimisation and inference of complex geoscientific models.} The use of\nsurrogate models can speed up parallel tempering Bayeslands by developing\ncomputationally inexpensive models to mimic expensive ones. In this paper, we\napply surrogate-assisted parallel tempering where that surrogate mimics a\nlandscape evolution model by estimating the likelihood function from the model.\n\\textcolor{black}{We employ a neural network-based surrogate model that learns\nfrom the history of samples generated. } The entire framework is developed in a\nparallel computing infrastructure to take advantage of parallelism. The results\nshow that the proposed methodology is effective in lowering the overall\ncomputational cost significantly while retaining the quality of solutions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 03:56:20 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 09:51:22 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 13:05:43 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Chandra", "Rohitash", ""], ["Azam", "Danial", ""], ["Kapoor", "Arpit", ""], ["M\u00fcller", "R. Dietmar", ""]]}, {"id": "1812.08674", "submitter": "Xi Chen", "authors": "Xi Chen, Jin Xie, Qingcong Yuan", "title": "A Method to Facilitate Cancer Detection and Type Classification from\n  Gene Expression Data using a Deep Autoencoder and Neural Network", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased affordability and availability of whole-genome sequencing,\nlarge-scale and high-throughput gene expression is widely used to characterize\ndiseases, including cancers. However, establishing specificity in cancer\ndiagnosis using gene expression data continues to pose challenges due to the\nhigh dimensionality and complexity of the data. Here we present models of deep\nlearning (DL) and apply them to gene expression data for the diagnosis and\ncategorization of cancer. In this study, we have developed two DL models using\nmessenger ribonucleic acid (mRNA) datasets available from the Genomic Data\nCommons repository. Our models achieved 98% accuracy in cancer detection, with\nfalse negative and false positive rates below 1.7%. In our results, we\ndemonstrated that 18 out of 32 cancer-typing classifications achieved more than\n90% accuracy. Due to the limitation of a small sample size (less than 50\nobservations), certain cancers could not achieve a higher accuracy in typing\nclassification, but still achieved high accuracy for the cancer detection task.\nTo validate our models, we compared them with traditional statistical models.\nThe main advantage of our models over traditional cancer detection is the\nability to use data from various cancer types to automatically form features to\nenhance the detection and diagnosis of a specific cancer type.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 16:22:51 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Chen", "Xi", ""], ["Xie", "Jin", ""], ["Yuan", "Qingcong", ""]]}, {"id": "1812.08683", "submitter": "Yang Ning", "authors": "Yang Ning, Sida Peng, Kosuke Imai", "title": "Robust Estimation of Causal Effects via High-Dimensional Covariate\n  Balancing Propensity Score", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a robust method to estimate the average treatment\neffects in observational studies when the number of potential confounders is\npossibly much greater than the sample size. We first use a class of penalized\nM-estimators for the propensity score and outcome models. We then calibrate the\ninitial estimate of the propensity score by balancing a carefully selected\nsubset of covariates that are predictive of the outcome. Finally, the estimated\npropensity score is used to construct the inverse probability weighting\nestimator. We prove that the proposed estimator, which has the sample\nboundedness property, is root-n consistent, asymptotically normal, and\nsemiparametrically efficient when the propensity score model is correctly\nspecified and the outcome model is linear in covariates. More importantly, we\nshow that our estimator remains root-n consistent and asymptotically normal so\nlong as either the propensity score model or the outcome model is correctly\nspecified. We provide valid confidence intervals in both cases and further\nextend these results to the case where the outcome model is a generalized\nlinear model. In simulation studies, we find that the proposed methodology\noften estimates the average treatment effect more accurately than the existing\nmethods. We also present an empirical application, in which we estimate the\naverage causal effect of college attendance on adulthood political\nparticipation. Open-source software is available for implementing the proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 16:33:08 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Ning", "Yang", ""], ["Peng", "Sida", ""], ["Imai", "Kosuke", ""]]}, {"id": "1812.08733", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues and Francisco C. Pereira", "title": "Heteroscedastic Gaussian processes for uncertainty modeling in\n  large-scale crowdsourced traffic data", "comments": "22 pages, Transportation Research Part C: Emerging Technologies\n  (Elsevier)", "journal-ref": "Rodrigues, F., & Pereira, F. C. (2018). Heteroscedastic Gaussian\n  processes for uncertainty modeling in large-scale crowdsourced traffic data.\n  Transportation Research Part C: Emerging Technologies, 95, 636-651", "doi": "10.1016/j.trc.2018.08.007", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately modeling traffic speeds is a fundamental part of efficient\nintelligent transportation systems. Nowadays, with the widespread deployment of\nGPS-enabled devices, it has become possible to crowdsource the collection of\nspeed information to road users (e.g. through mobile applications or dedicated\nin-vehicle devices). Despite its rather wide spatial coverage, crowdsourced\nspeed data also brings very important challenges, such as the highly variable\nmeasurement noise in the data due to a variety of driving behaviors and sample\nsizes. When not properly accounted for, this noise can severely compromise any\napplication that relies on accurate traffic data. In this article, we propose\nthe use of heteroscedastic Gaussian processes (HGP) to model the time-varying\nuncertainty in large-scale crowdsourced traffic data. Furthermore, we develop a\nHGP conditioned on sample size and traffic regime (SRC-HGP), which makes use of\nsample size information (probe vehicles per minute) as well as previous\nobserved speeds, in order to more accurately model the uncertainty in observed\nspeeds. Using 6 months of crowdsourced traffic data from Copenhagen, we\nempirically show that the proposed heteroscedastic models produce significantly\nbetter predictive distributions when compared to current state-of-the-art\nmethods for both speed imputation and short-term forecasting tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 18:06:57 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Rodrigues", "Filipe", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "1812.08739", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues, Kristian Henrickson, Francisco C. Pereira", "title": "Multi-Output Gaussian Processes for Crowdsourced Traffic Data Imputation", "comments": "10 pages, IEEE Transactions on Intelligent Transportation Systems,\n  2018", "journal-ref": null, "doi": "10.1109/TITS.2018.2817879", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic speed data imputation is a fundamental challenge for data-driven\ntransport analysis. In recent years, with the ubiquity of GPS-enabled devices\nand the widespread use of crowdsourcing alternatives for the collection of\ntraffic data, transportation professionals increasingly look to such\nuser-generated data for many analysis, planning, and decision support\napplications. However, due to the mechanics of the data collection process,\ncrowdsourced traffic data such as probe-vehicle data is highly prone to missing\nobservations, making accurate imputation crucial for the success of any\napplication that makes use of that type of data. In this article, we propose\nthe use of multi-output Gaussian processes (GPs) to model the complex spatial\nand temporal patterns in crowdsourced traffic data. While the Bayesian\nnonparametric formalism of GPs allows us to model observation uncertainty, the\nmulti-output extension based on convolution processes effectively enables us to\ncapture complex spatial dependencies between nearby road segments. Using 6\nmonths of crowdsourced traffic speed data or \"probe vehicle data\" for several\nlocations in Copenhagen, the proposed approach is empirically shown to\nsignificantly outperform popular state-of-the-art imputation methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 18:15:40 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 08:13:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Rodrigues", "Filipe", ""], ["Henrickson", "Kristian", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "1812.08755", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues, Stanislav S. Borysov, Bernardete Ribeiro, Francisco\n  C. Pereira", "title": "A Bayesian Additive Model for Understanding Public Transport Usage in\n  Special Events", "comments": "14 pages, IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (Volume: 39 , Issue: 11 , Nov. 1 2017)", "journal-ref": "Rodrigues, F., Borysov, S. S., Ribeiro, B., & Pereira, F. C.\n  (2017). A Bayesian additive model for understanding public transport usage in\n  special events. IEEE transactions on pattern analysis and machine\n  intelligence, 39(11), 2113-2126", "doi": "10.1109/TPAMI.2016.2635136", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public special events, like sports games, concerts and festivals are well\nknown to create disruptions in transportation systems, often catching the\noperators by surprise. Although these are usually planned well in advance,\ntheir impact is difficult to predict, even when organisers and transportation\noperators coordinate. The problem highly increases when several events happen\nconcurrently. To solve these problems, costly processes, heavily reliant on\nmanual search and personal experience, are usual practice in large cities like\nSingapore, London or Tokyo. This paper presents a Bayesian additive model with\nGaussian process components that combines smart card records from public\ntransport with context information about events that is continuously mined from\nthe Web. We develop an efficient approximate inference algorithm using\nexpectation propagation, which allows us to predict the total number of public\ntransportation trips to the special event areas, thereby contributing to a more\nadaptive transportation system. Furthermore, for multiple concurrent event\nscenarios, the proposed algorithm is able to disaggregate gross trip counts\ninto their most likely components related to specific events and routine\nbehavior. Using real data from Singapore, we show that the presented model\noutperforms the best baseline model by up to 26% in R2 and also has explanatory\npower for its individual components.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 18:37:35 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Rodrigues", "Filipe", ""], ["Borysov", "Stanislav S.", ""], ["Ribeiro", "Bernardete", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "1812.08808", "submitter": "Luoluo Liu", "authors": "Luoluo Liu, Sang Peter Chin, Trac D. Tran", "title": "Reducing Sampling Ratios Improves Bagging in Sparse Regression", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.03743", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bagging, a powerful ensemble method from machine learning, improves the\nperformance of unstable predictors. Although the power of Bagging has been\nshown mostly in classification problems, we demonstrate the success of\nemploying Bagging in sparse regression over the baseline method (L1\nminimization). The framework employs the generalized version of the original\nBagging with various bootstrap ratios. The performance limits associated with\ndifferent choices of bootstrap sampling ratio L/m and number of estimates K is\nanalyzed theoretically. Simulation shows that the proposed method yields\nstate-of-the-art recovery performance, outperforming L1 minimization and\nBolasso in the challenging case of low levels of measurements. A lower L/m\nratio (60% - 90%) leads to better performance, especially with a small number\nof measurements. With the reduced sampling rate, SNR improves over the original\nBagging by up to 24%. With a properly chosen sampling ratio, a reasonably small\nnumber of estimates K = 30 gives satisfying result, even though increasing K is\ndiscovered to always improve or at least maintain the performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 19:25:17 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 05:22:50 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 00:56:54 GMT"}, {"version": "v4", "created": "Wed, 1 May 2019 21:40:26 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Liu", "Luoluo", ""], ["Chin", "Sang Peter", ""], ["Tran", "Trac D.", ""]]}, {"id": "1812.08839", "submitter": "Ricardo Vilalta", "authors": "Ricardo Vilalta, Kinjal Dhar Gupta, Dainis Boumber, Mikhail M. Meskhi", "title": "A General Approach to Domain Adaptation with Applications in Astronomy", "comments": null, "journal-ref": null, "doi": "10.1088/1538-3873/aaf1fc", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to build a model on a source task and subsequently adapt such\nmodel on a new target task is a pervasive need in many astronomical\napplications. The problem is generally known as transfer learning in machine\nlearning, where domain adaptation is a popular scenario. An example is to build\na predictive model on spectroscopic data to identify Supernovae IA, while\nsubsequently trying to adapt such model on photometric data. In this paper we\npropose a new general approach to domain adaptation that does not rely on the\nproximity of source and target distributions. Instead we simply assume a strong\nsimilarity in model complexity across domains, and use active learning to\nmitigate the dependency on source examples. Our work leads to a new formulation\nfor the likelihood as a function of empirical error using a theoretical\nlearning bound; the result is a novel mapping from generalization error to a\nlikelihood estimation. Results using two real astronomical problems, Supernova\nIa classification and identification of Mars landforms, show two main\nadvantages with our approach: increased accuracy performance and substantial\nsavings in computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 21:04:45 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Vilalta", "Ricardo", ""], ["Gupta", "Kinjal Dhar", ""], ["Boumber", "Dainis", ""], ["Meskhi", "Mikhail M.", ""]]}, {"id": "1812.08843", "submitter": "Sahar Khawatmi", "authors": "Sahar Khawatmi, Abdelhak M. Zoubir, Ali H. Sayed", "title": "Decentralized Decision-Making Over Multi-Task Networks", "comments": "26 pages, 13 figures, Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In important applications involving multi-task networks with multiple\nobjectives, agents in the network need to decide between these multiple\nobjectives and reach an agreement about which single objective to follow for\nthe network. In this work we propose a distributed decision-making algorithm.\nThe agents are assumed to observe data that may be generated by different\nmodels. Through localized interactions, the agents reach agreement about which\nmodel to track and interact with each other in order to enhance the network\nperformance. We investigate the approach for both static and mobile networks.\nThe simulations illustrate the performance of the proposed strategies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 21:14:13 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 12:47:00 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Khawatmi", "Sahar", ""], ["Zoubir", "Abdelhak M.", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1812.08861", "submitter": "Aliaksandr Siarohin", "authors": "Aliaksandr Siarohin, St\\'ephane Lathuili\\`ere, Sergey Tulyakov, Elisa\n  Ricci and Nicu Sebe", "title": "Animating Arbitrary Objects via Deep Motion Transfer", "comments": "CVPR-2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel deep learning framework for image animation.\nGiven an input image with a target object and a driving video sequence\ndepicting a moving object, our framework generates a video in which the target\nobject is animated according to the driving sequence. This is achieved through\na deep architecture that decouples appearance and motion information. Our\nframework consists of three main modules: (i) a Keypoint Detector unsupervisely\ntrained to extract object keypoints, (ii) a Dense Motion prediction network for\ngenerating dense heatmaps from sparse keypoints, in order to better encode\nmotion information and (iii) a Motion Transfer Network, which uses the motion\nheatmaps and appearance information extracted from the input image to\nsynthesize the output frames. We demonstrate the effectiveness of our method on\nseveral benchmark datasets, spanning a wide variety of object appearances, and\nshow that our approach outperforms state-of-the-art image animation and video\ngeneration methods. Our source code is publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 21:45:56 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 08:01:58 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 23:48:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Siarohin", "Aliaksandr", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Tulyakov", "Sergey", ""], ["Ricci", "Elisa", ""], ["Sebe", "Nicu", ""]]}, {"id": "1812.08883", "submitter": "Kailai Xu", "authors": "Kailai Xu, Eric Darve", "title": "Calibrating Multivariate L\\'evy Processes with Neural Networks", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibrating a L\\'evy process usually requires characterizing its jump\ndistribution. Traditionally this problem can be solved with nonparametric\nestimation using the empirical characteristic functions (ECF), assuming certain\nregularity, and results to date are mostly in 1D. For multivariate L\\'evy\nprocesses and less smooth L\\'evy densities, the problem becomes challenging as\nECFs decay slowly and have large uncertainty because of limited observations.\nWe solve this problem by approximating the L\\'evy density with a parametrized\nfunctional form; the characteristic function is then estimated using numerical\nintegration. In our benchmarks, we used deep neural networks and found that\nthey are robust and can capture sharp transitions in the L\\'evy density. They\nperform favorably compared to piecewise linear functions and radial basis\nfunctions. The methods and techniques developed here apply to many other\nproblems that involve nonparametric estimation of functions embedded in a\nsystem model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 23:07:20 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 21:48:14 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 00:14:25 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Xu", "Kailai", ""], ["Darve", "Eric", ""]]}, {"id": "1812.08904", "submitter": "Gabriel De La Cruz Jr", "authors": "Gabriel V. de la Cruz, Yunshu Du and Matthew E. Taylor", "title": "Pre-training with Non-expert Human Demonstration for Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1017/S0269888919000055", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) has achieved superior performance in\ncomplex sequential tasks by using deep neural networks as function\napproximators to learn directly from raw input images. However, learning\ndirectly from raw images is data inefficient. The agent must learn feature\nrepresentation of complex states in addition to learning a policy. As a result,\ndeep RL typically suffers from slow learning speeds and often requires a\nprohibitively large amount of training time and data to reach reasonable\nperformance, making it inapplicable to real-world settings where data is\nexpensive. In this work, we improve data efficiency in deep RL by addressing\none of the two learning goals, feature learning. We leverage supervised\nlearning to pre-train on a small set of non-expert human demonstrations and\nempirically evaluate our approach using the asynchronous advantage actor-critic\nalgorithms (A3C) in the Atari domain. Our results show significant improvements\nin learning speed, even when the provided demonstration is noisy and of low\nquality.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 01:10:06 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["de la Cruz", "Gabriel V.", ""], ["Du", "Yunshu", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1812.08954", "submitter": "Hosik Choi", "authors": "Jong-June Jeon and Yongdai Kim and Sungho Won and Hosik Choi", "title": "Primal path algorithm for compositional data analysis", "comments": "23pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositional data have two unique characteristics compared to typical\nmultivariate data: the observed values are nonnegative and their summand is\nexactly one. To reflect these characteristics, a specific regularized\nregression model with linear constraints is commonly used. However, linear\nconstraints incur additional computational time, which becomes severe in\nhigh-dimensional cases. As such, we propose an efficient solution path\nalgorithm for a $l_1$ regularized regression with compositional data. The\nalgorithm is then extended to a classification model with compositional\npredictors. We also compare its computational speed with that of previously\ndeveloped algorithms and apply the proposed algorithm to analyze human gut\nmicrobiome data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 05:23:36 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Jeon", "Jong-June", ""], ["Kim", "Yongdai", ""], ["Won", "Sungho", ""], ["Choi", "Hosik", ""]]}, {"id": "1812.08985", "submitter": "Yedid Hoshen", "authors": "Yedid Hoshen and Jitendra Malik", "title": "Non-Adversarial Image Synthesis with Generative Latent Nearest Neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unconditional image generation has recently been dominated by generative\nadversarial networks (GANs). GAN methods train a generator which regresses\nimages from random noise vectors, as well as a discriminator that attempts to\ndifferentiate between the generated images and a training set of real images.\nGANs have shown amazing results at generating realistic looking images. Despite\ntheir success, GANs suffer from critical drawbacks including: unstable training\nand mode-dropping. The weaknesses in GANs have motivated research into\nalternatives including: variational auto-encoders (VAEs), latent embedding\nlearning methods (e.g. GLO) and nearest-neighbor based implicit maximum\nlikelihood estimation (IMLE). Unfortunately at the moment, GANs still\nsignificantly outperform the alternative methods for image generation. In this\nwork, we present a novel method - Generative Latent Nearest Neighbors (GLANN) -\nfor training generative models without adversarial training. GLANN combines the\nstrengths of IMLE and GLO in a way that overcomes the main drawbacks of each\nmethod. Consequently, GLANN generates images that are far better than GLO and\nIMLE. Our method does not suffer from mode collapse which plagues GAN training\nand is much more stable. Qualitative results show that GLANN outperforms a\nbaseline consisting of 800 GANs and VAEs on commonly used datasets. Our models\nare also shown to be effective for training truly non-adversarial unsupervised\nimage translation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 07:54:02 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Hoshen", "Yedid", ""], ["Malik", "Jitendra", ""]]}, {"id": "1812.08997", "submitter": "Jihye Choi", "authors": "Kanghoon Lee, Jihye Choi, Moonsu Cha, Jung-Kwon Lee, Taeyoon Kim", "title": "Stochastic Doubly Robust Gradient", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training a machine learning model with observational data, it is often\nencountered that some values are systemically missing. Learning from the\nincomplete data in which the missingness depends on some covariates may lead to\nbiased estimation of parameters and even harm the fairness of decision outcome.\nThis paper proposes how to adjust the causal effect of covariates on the\nmissingness when training models using stochastic gradient descent (SGD).\nInspired by the design of doubly robust estimator and its theoretical property\nof double robustness, we introduce stochastic doubly robust gradient (SDRG)\nconsisting of two models: weight-corrected gradients for inverse propensity\nscore weighting and per-covariate control variates for regression adjustment.\nAlso, we identify the connection between double robustness and variance\nreduction in SGD by demonstrating the SDRG algorithm with a unifying framework\nfor variance reduced SGD. The performance of our approach is empirically tested\nby showing the convergence in training image classifiers with several examples\nof missing data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 08:44:38 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Lee", "Kanghoon", ""], ["Choi", "Jihye", ""], ["Cha", "Moonsu", ""], ["Lee", "Jung-Kwon", ""], ["Kim", "Taeyoon", ""]]}, {"id": "1812.08999", "submitter": "Klas Leino", "authors": "Klas Leino, Emily Black, Matt Fredrikson, Shayak Sen, Anupam Datta", "title": "Feature-Wise Bias Amplification", "comments": "Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the phenomenon of bias amplification in classifiers, wherein a\nmachine learning model learns to predict classes with a greater disparity than\nthe underlying ground truth. We demonstrate that bias amplification can arise\nvia an inductive bias in gradient descent methods that results in the\noverestimation of the importance of moderately-predictive \"weak\" features if\ninsufficient training data is available. This overestimation gives rise to\nfeature-wise bias amplification -- a previously unreported form of bias that\ncan be traced back to the features of a trained model. Through analysis and\nexperiments, we show that while some bias cannot be mitigated without\nsacrificing accuracy, feature-wise bias amplification can be mitigated through\ntargeted feature selection. We present two new feature selection algorithms for\nmitigating bias amplification in linear models, and show how they can be\nadapted to convolutional neural networks efficiently. Our experiments on\nsynthetic and real data demonstrate that these algorithms consistently lead to\nreduced bias without harming accuracy, in some cases eliminating predictive\nbias altogether while providing modest gains in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 08:48:30 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 16:08:42 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Leino", "Klas", ""], ["Black", "Emily", ""], ["Fredrikson", "Matt", ""], ["Sen", "Shayak", ""], ["Datta", "Anupam", ""]]}, {"id": "1812.09027", "submitter": "Eric Benhamou", "authors": "E. Benhamou, J. Atif, R. Laraki", "title": "A new approach to learning in Dynamic Bayesian Networks (DBNs)", "comments": "14 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:1811.11618", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the parameter learning problem, namely the\nestimation of model parameters for Dynamic Bayesian Networks (DBNs). DBNs are\ndirected graphical models of stochastic processes that encompasses and\ngeneralize Hidden Markov models (HMMs) and Linear Dynamical Systems (LDSs).\nWhenever we apply these models to economics and finance, we are forced to make\nsome modeling assumptions about the state dynamics and the graph topology (the\nDBN structure). These assumptions may be incorrectly specified and contain some\nadditional noise compared to reality. Trying to use a best fit approach through\nmaximum likelihood estimation may miss this point and try to fit at any price\nthese models on data. We present here a new methodology that takes a radical\npoint of view and instead focus on the final efficiency of our model.\nParameters are hence estimated in terms of their efficiency rather than their\ndistributional fit to the data. The resulting optimization problem that\nconsists in finding the optimal parameters is a hard problem. We rely on\nCovariance Matrix Adaptation Evolution Strategy (CMA-ES) method to tackle this\nissue. We apply this method to the seminal problem of trend detection in\nfinancial markets. We see on numerical results that the resulting parameters\nseem less error prone to over fitting than traditional moving average cross\nover trend detection and perform better. The method developed here for\nalgorithmic trading is general. It can be applied to other real case\napplications whenever there is no physical law underlying our DBNs.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 10:15:29 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 19:57:30 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Benhamou", "E.", ""], ["Atif", "J.", ""], ["Laraki", "R.", ""]]}, {"id": "1812.09028", "submitter": "Sirui Xie", "authors": "Sirui Xie, Junning Huang, Lanxin Lei, Chunxiao Liu, Zheng Ma, Wei\n  Zhang, Liang Lin", "title": "NADPEx: An on-policy temporally consistent exploration method for deep\n  reinforcement learning", "comments": "To appear in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents need exploratory behaviors to escape from local\noptima. These behaviors may include both immediate dithering perturbation and\ntemporally consistent exploration. To achieve these, a stochastic policy model\nthat is inherently consistent through a period of time is in desire, especially\nfor tasks with either sparse rewards or long term information. In this work, we\nintroduce a novel on-policy temporally consistent exploration strategy - Neural\nAdaptive Dropout Policy Exploration (NADPEx) - for deep reinforcement learning\nagents. Modeled as a global random variable for conditional distribution,\ndropout is incorporated to reinforcement learning policies, equipping them with\ninherent temporal consistency, even when the reward signals are sparse. Two\nfactors, gradients' alignment with the objective and KL constraint in policy\nspace, are discussed to guarantee NADPEx policy's stable improvement. Our\nexperiments demonstrate that NADPEx solves tasks with sparse reward while naive\nexploration and parameter noise fail. It yields as well or even faster\nconvergence in the standard mujoco benchmark for continuous control.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 10:17:29 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 14:22:28 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Xie", "Sirui", ""], ["Huang", "Junning", ""], ["Lei", "Lanxin", ""], ["Liu", "Chunxiao", ""], ["Ma", "Zheng", ""], ["Zhang", "Wei", ""], ["Lin", "Liang", ""]]}, {"id": "1812.09041", "submitter": "Boyang Li", "authors": "Guoyun Tu, Yanwei Fu, Boyang Li, Jiarui Gao, Yu-Gang Jiang, Xiangyang\n  Xue", "title": "A Multi-task Neural Approach for Emotion Attribution, Classification and\n  Summarization", "comments": "Authors' manuscript; published at the IEEE Transactions on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotional content is a crucial ingredient in user-generated videos. However,\nthe sparsity of emotional expressions in the videos poses an obstacle to visual\nemotion analysis. In this paper, we propose a new neural approach, Bi-stream\nEmotion Attribution-Classification Network (BEAC-Net), to solve three related\nemotion analysis tasks: emotion recognition, emotion attribution, and\nemotion-oriented summarization, in a single integrated framework. BEAC-Net has\ntwo major constituents, an attribution network and a classification network.\nThe attribution network extracts the main emotional segment that classification\nshould focus on in order to mitigate the sparsity issue. The classification\nnetwork utilizes both the extracted segment and the original video in a\nbi-stream architecture. We contribute a new dataset for the emotion attribution\ntask with human-annotated ground-truth labels for emotion segments. Experiments\non two video datasets demonstrate superior performance of the proposed\nframework and the complementary nature of the dual classification streams.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 10:53:44 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 04:21:23 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Tu", "Guoyun", ""], ["Fu", "Yanwei", ""], ["Li", "Boyang", ""], ["Gao", "Jiarui", ""], ["Jiang", "Yu-Gang", ""], ["Xue", "Xiangyang", ""]]}, {"id": "1812.09042", "submitter": "Patrick Heas", "authors": "Patrick Heas and Cedric Herzet", "title": "Low-rank Approximation of Linear Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides closed-form solutions and minimal achievable errors for a\nlarge class of low-rank approximation problems in Hilbert spaces. The proposed\ntheorem generalizes to the case of linear bounded operators and p-th Schatten\nnorms previous results obtained in the finite dimensional case for the\nFrobenius norm. The theorem is illustrated in various settings, including\nlow-rank approximation problems with respect to the trace norm, the 2-induced\nnorm or the Hilbert-Schmidt norm. The theorem provides also the basics for the\ndesign of tractable algorithms for kernel-based or continuous DMD\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 10:54:18 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Heas", "Patrick", ""], ["Herzet", "Cedric", ""]]}, {"id": "1812.09064", "submitter": "Christopher Nemeth", "authors": "Jamie Fairbrother, Christopher Nemeth, Maxime Rischard, Johanni Brea,\n  Thomas Pinder", "title": "GaussianProcesses.jl: A Nonparametric Bayes package for the Julia\n  Language", "comments": "32 pages, 10 figures. Updated version includes sparse GPs", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are a class of flexible nonparametric Bayesian tools that\nare widely used across the sciences, and in industry, to model complex data\nsources. Key to applying Gaussian process models is the availability of\nwell-developed open source software, which is available in many programming\nlanguages. In this paper, we present a tutorial of the GaussianProcesses.jl\npackage that has been developed for the Julia programming language.\nGaussianProcesses.jl utilises the inherent computational benefits of the Julia\nlanguage, including multiple dispatch and just-in-time compilation, to produce\na fast, flexible and user-friendly Gaussian processes package. The package\nprovides many mean and kernel functions with supporting inference tools to fit\nexact Gaussian process models, as well as a range of alternative likelihood\nfunctions to handle non-Gaussian data (e.g. binary classification models) and\nsparse approximations for scalable Gaussian processes. The package makes\nefficient use of existing Julia packages to provide users with a range of\noptimization and plotting tools.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 11:45:16 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 20:40:58 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fairbrother", "Jamie", ""], ["Nemeth", "Christopher", ""], ["Rischard", "Maxime", ""], ["Brea", "Johanni", ""], ["Pinder", "Thomas", ""]]}, {"id": "1812.09066", "submitter": "Stefano Sarao Mannelli", "authors": "Stefano Sarao Mannelli, Giulio Biroli, Chiara Cammarota, Florent\n  Krzakala, Pierfrancesco Urbani, Lenka Zdeborov\\'a", "title": "Marvels and Pitfalls of the Langevin Algorithm in Noisy High-dimensional\n  Inference", "comments": "11 pages and 5 figures + appendix", "journal-ref": "Phys. Rev. X 10, 011057 (2020)", "doi": "10.1103/PhysRevX.10.011057", "report-no": null, "categories": "cs.LG cond-mat.dis-nn math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-descent-based algorithms and their stochastic versions have\nwidespread applications in machine learning and statistical inference. In this\nwork we perform an analytic study of the performances of one of them, the\nLangevin algorithm, in the context of noisy high-dimensional inference. We\nemploy the Langevin algorithm to sample the posterior probability measure for\nthe spiked matrix-tensor model. The typical behaviour of this algorithm is\ndescribed by a system of integro-differential equations that we call the\nLangevin state evolution, whose solution is compared with the one of the state\nevolution of approximate message passing (AMP). Our results show that,\nremarkably, the algorithmic threshold of the Langevin algorithm is sub-optimal\nwith respect to the one given by AMP. We conjecture this phenomenon to be due\nto the residual glassiness present in that region of parameters. Finally we\nshow how a landscape-annealing protocol, that uses the Langevin algorithm but\nviolate the Bayes-optimality condition, can approach the performance of AMP.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 11:56:50 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 15:40:21 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 07:39:43 GMT"}, {"version": "v4", "created": "Mon, 13 Jan 2020 11:03:07 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Mannelli", "Stefano Sarao", ""], ["Biroli", "Giulio", ""], ["Cammarota", "Chiara", ""], ["Krzakala", "Florent", ""], ["Urbani", "Pierfrancesco", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1812.09073", "submitter": "Yilong Yang", "authors": "Zhuyifan Ye, Yilong Yang, Xiaoshan Li, Dongsheng Cao, Defang Ouyang", "title": "An Integrated Transfer Learning and Multitask Learning Approach for\n  Pharmacokinetic Parameter Prediction", "comments": null, "journal-ref": null, "doi": "10.1021/acs.molpharmaceut.8b00816", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Pharmacokinetic evaluation is one of the key processes in drug\ndiscovery and development. However, current absorption, distribution,\nmetabolism, excretion prediction models still have limited accuracy. Aim: This\nstudy aims to construct an integrated transfer learning and multitask learning\napproach for developing quantitative structure-activity relationship models to\npredict four human pharmacokinetic parameters. Methods: A pharmacokinetic\ndataset included 1104 U.S. FDA approved small molecule drugs. The dataset\nincluded four human pharmacokinetic parameter subsets (oral bioavailability,\nplasma protein binding rate, apparent volume of distribution at steady-state\nand elimination half-life). The pre-trained model was trained on over 30\nmillion bioactivity data. An integrated transfer learning and multitask\nlearning approach was established to enhance the model generalization. Results:\nThe pharmacokinetic dataset was split into three parts (60:20:20) for training,\nvalidation and test by the improved Maximum Dissimilarity algorithm with the\nrepresentative initial set selection algorithm and the weighted distance\nfunction. The multitask learning techniques enhanced the model predictive\nability. The integrated transfer learning and multitask learning model\ndemonstrated the best accuracies, because deep neural networks have the general\nfeature extraction ability, transfer learning and multitask learning improved\nthe model generalization. Conclusions: The integrated transfer learning and\nmultitask learning approach with the improved dataset splitting algorithm was\nfirstly introduced to predict the pharmacokinetic parameters. This method can\nbe further employed in drug discovery and development.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 12:16:50 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ye", "Zhuyifan", ""], ["Yang", "Yilong", ""], ["Li", "Xiaoshan", ""], ["Cao", "Dongsheng", ""], ["Ouyang", "Defang", ""]]}, {"id": "1812.09077", "submitter": "Alberto Fachechi", "authors": "Elena Agliari, Francesco Alemanno, Adriano Barra, Alberto Fachechi", "title": "Dreaming neural networks: rigorous results", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/ab371d", "report-no": "Roma01.Math", "categories": "cond-mat.dis-nn cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a daily routine for associative neural networks has been proposed:\nthe network Hebbian-learns during the awake state (thus behaving as a standard\nHopfield model), then, during its sleep state, optimizing information storage,\nit consolidates pure patterns and removes spurious ones: this forces the\nsynaptic matrix to collapse to the projector one (ultimately approaching the\nKanter-Sompolinksy model). This procedure keeps the learning Hebbian-based (a\nbiological must) but, by taking advantage of a (properly stylized) sleep phase,\nstill reaches the maximal critical capacity (for symmetric interactions). So\nfar this emerging picture (as well as the bulk of papers on unlearning\ntechniques) was supported solely by mathematically-challenging routes, e.g.\nmainly replica-trick analysis and numerical simulations: here we rely\nextensively on Guerra's interpolation techniques developed for neural networks\nand, in particular, we extend the generalized stochastic stability approach to\nthe case. Confining our description within the replica symmetric approximation\n(where the previous ones lie), the picture painted regarding this\ngeneralization (and the previously existing variations on theme) is here\nentirely confirmed. Further, still relying on Guerra's schemes, we develop a\nsystematic fluctuation analysis to check where ergodicity is broken (an\nanalysis entirely absent in previous investigations). We find that, as long as\nthe network is awake, ergodicity is bounded by the Amit-Gutfreund-Sompolinsky\ncritical line (as it should), but, as the network sleeps, sleeping destroys\nspin glass states by extending both the retrieval as well as the ergodic\nregion: after an entire sleeping session the solely surviving regions are\nretrieval and ergodic ones and this allows the network to achieve the perfect\nretrieval regime (the number of storable patterns equals the number of neurons\nin the network).\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 12:29:48 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Agliari", "Elena", ""], ["Alemanno", "Francesco", ""], ["Barra", "Adriano", ""], ["Fachechi", "Alberto", ""]]}, {"id": "1812.09113", "submitter": "Nicolas Vecoven", "authors": "Nicolas Vecoven, Damien Ernst, Antoine Wehenkel, Guillaume Drion", "title": "Introducing Neuromodulation in Deep Neural Networks to Learn Adaptive\n  Behaviours", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals excel at adapting their intentions, attention, and actions to the\nenvironment, making them remarkably efficient at interacting with a rich,\nunpredictable and ever-changing external world, a property that intelligent\nmachines currently lack. Such an adaptation property relies heavily on cellular\nneuromodulation, the biological mechanism that dynamically controls intrinsic\nproperties of neurons and their response to external stimuli in a\ncontext-dependent manner. In this paper, we take inspiration from cellular\nneuromodulation to construct a new deep neural network architecture that is\nspecifically designed to learn adaptive behaviours. The network adaptation\ncapabilities are tested on navigation benchmarks in a meta-reinforcement\nlearning context and compared with state-of-the-art approaches. Results show\nthat neuromodulation is capable of adapting an agent to different tasks and\nthat neuromodulation-based approaches provide a promising way of improving\nadaptation of artificial systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 13:43:32 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 15:19:20 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 09:57:58 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Vecoven", "Nicolas", ""], ["Ernst", "Damien", ""], ["Wehenkel", "Antoine", ""], ["Drion", "Guillaume", ""]]}, {"id": "1812.09138", "submitter": "Md Ashad Alam PhD", "authors": "Md.Siraj-Ud-Doula and Md. Ashad Alam", "title": "Ecological Data Analysis Based on Machine Learning Algorithms", "comments": "18 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is an important supervised machine learning method, which is\nnecessary and challenging issue for ecological research. It offers a way to\nclassify a dataset into subsets that share common patterns. Notably, there are\nmany classification algorithms to choose from, each making certain assumptions\nabout the data and about how classification should be formed. In this paper, we\napplied eight machine learning classification algorithms such as Decision\nTrees, Random Forest, Artificial Neural Network, Support Vector Machine, Linear\nDiscriminant Analysis, k-nearest neighbors, Logistic Regression and Naive Bayes\non ecological data. The goal of this study is to compare different machine\nlearning classification algorithms in ecological dataset. In this analysis we\nhave checked the accuracy test among the algorithms. In our study we conclude\nthat Linear Discriminant Analysis and k-nearest neighbors are the best methods\namong all other methods\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 14:18:56 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Siraj-Ud-Doula", "Md.", ""], ["Alam", "Md. Ashad", ""]]}, {"id": "1812.09178", "submitter": "Yuanzhi Huang", "authors": "Yuanzhi Huang, Eamonn Ahearne, Szymon Baron, Andrew Parnell", "title": "An Evaluation of Methods for Real-Time Anomaly Detection using Force\n  Measurements from the Turning Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examined the use of three conventional anomaly detection methods and\nassess their potential for on-line tool wear monitoring. Through efficient data\nprocessing and transformation of the algorithm proposed here, in a real-time\nenvironment, these methods were tested for fast evaluation of cutting tools on\nCNC machines. The three-dimensional force data streams we used were extracted\nfrom a turning experiment of 21 runs for which a tool was run until it\ngenerally satisfied an end-of-life criterion. Our real-time anomaly detection\nalgorithm was scored and optimised according to how precisely it can predict\nthe progressive wear of the tool flank. Most of our tool wear predictions were\naccurate and reliable as illustrated in our off-line simulation results.\nParticularly when the multivariate analysis was applied, the algorithm we\ndevelop was found to be very robust across different scenarios and against\nparameter changes. It shall be reasonably easy to apply our approach elsewhere\nfor real-time tool wear analytics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 17:15:18 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Huang", "Yuanzhi", ""], ["Ahearne", "Eamonn", ""], ["Baron", "Szymon", ""], ["Parnell", "Andrew", ""]]}, {"id": "1812.09195", "submitter": "Izzeddin Gur", "authors": "Izzeddin Gur and Ulrich Rueckert and Aleksandra Faust and Dilek\n  Hakkani-Tur", "title": "Learning to Navigate the Web", "comments": "International Conference on Learning Representations (ICLR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in environments with large state and action spaces, and sparse\nrewards, can hinder a Reinforcement Learning (RL) agent's learning through\ntrial-and-error. For instance, following natural language instructions on the\nWeb (such as booking a flight ticket) leads to RL settings where input\nvocabulary and number of actionable elements on a page can grow very large.\nEven though recent approaches improve the success rate on relatively simple\nenvironments with the help of human demonstrations to guide the exploration,\nthey still fail in environments where the set of possible instructions can\nreach millions. We approach the aforementioned problems from a different\nperspective and propose guided RL approaches that can generate unbounded amount\nof experience for an agent to learn from. Instead of learning from a\ncomplicated instruction with a large vocabulary, we decompose it into multiple\nsub-instructions and schedule a curriculum in which an agent is tasked with a\ngradually increasing subset of these relatively easier sub-instructions. In\naddition, when the expert demonstrations are not available, we propose a novel\nmeta-learning framework that generates new instruction following tasks and\ntrains the agent more effectively. We train DQN, deep reinforcement learning\nagent, with Q-value function approximated with a novel QWeb neural network\narchitecture on these smaller, synthetic instructions. We evaluate the ability\nof our agent to generalize to new instructions on World of Bits benchmark, on\nforms with up to 100 elements, supporting 14 million possible instructions. The\nQWeb agent outperforms the baseline without using any human demonstration\nachieving 100% success rate on several difficult environments.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 15:32:59 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Gur", "Izzeddin", ""], ["Rueckert", "Ulrich", ""], ["Faust", "Aleksandra", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1812.09225", "submitter": "Morteza Haghir Chehreghani", "authors": "Morteza Haghir Chehreghani and Mostafa Haghir Chehreghani", "title": "Nonparametric Feature Extraction from Dendrograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose feature extraction from dendrograms in a nonparametric way. The\nMinimax distance measures correspond to building a dendrogram with single\nlinkage criterion, with defining specific forms of a level function and a\ndistance function over that. Therefore, we extend this method to arbitrary\ndendrograms. We develop a generalized framework wherein different distance\nmeasures can be inferred from different types of dendrograms, level functions\nand distance functions. Via an appropriate embedding, we compute a vector-based\nrepresentation of the inferred distances, in order to enable many numerical\nmachine learning algorithms to employ such distances. Then, to address the\nmodel selection problem, we study the aggregation of different dendrogram-based\ndistances respectively in solution space and in representation space in the\nspirit of deep representations. In the first approach, for example for the\nclustering problem, we build a graph with positive and negative edge weights\naccording to the consistency of the clustering labels of different objects\namong different solutions, in the context of ensemble methods. Then, we use an\nefficient variant of correlation clustering to produce the final clusters. In\nthe second approach, we investigate the sequential combination of different\ndistances and features sequentially in the spirit of multi-layered\narchitectures to obtain the final features. Finally, we demonstrate the\neffectiveness of our approach via several numerical studies.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 16:11:00 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 22:36:58 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 22:22:39 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chehreghani", "Morteza Haghir", ""], ["Chehreghani", "Mostafa Haghir", ""]]}, {"id": "1812.09234", "submitter": "Ningyuan Chen", "authors": "Ningyuan Chen, Guillermo Gallego", "title": "A Primal-dual Learning Algorithm for Personalized Dynamic Pricing with\n  an Inventory Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of a firm seeking to use personalized pricing to sell\nan exogenously given stock of a product over a finite selling horizon to\ndifferent consumer types. We assume that the type of an arriving consumer can\nbe observed but the demand function associated with each type is initially\nunknown. The firm sets personalized prices dynamically for each type and\nattempts to maximize the revenue over the season. We provide a learning\nalgorithm that is near-optimal when the demand and capacity scale in\nproportion. The algorithm utilizes the primal-dual formulation of the problem\nand learns the dual optimal solution explicitly. It allows the algorithm to\novercome the curse of dimensionality (the rate of regret is independent of the\nnumber of types) and sheds light on novel algorithmic designs for learning\nproblems with resource constraints.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 06:15:16 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 19:57:15 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Chen", "Ningyuan", ""], ["Gallego", "Guillermo", ""]]}, {"id": "1812.09245", "submitter": "Mateusz Juda", "authors": "Bartosz Zieli\\'nski, Micha{\\l} Lipi\\'nski, Mateusz Juda, Matthias\n  Zeppelzauer, Pawe{\\l} D{\\l}otko", "title": "Persistence Bag-of-Words for Topological Data Analysis", "comments": "Accepted for the Twenty-Eight International Joint Conference on\n  Artificial Intelligence (IJCAI-19). arXiv admin note: substantial text\n  overlap with arXiv:1802.04852", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology (PH) is a rigorous mathematical theory that provides a\nrobust descriptor of data in the form of persistence diagrams (PDs). PDs\nexhibit, however, complex structure and are difficult to integrate in today's\nmachine learning workflows. This paper introduces persistence bag-of-words: a\nnovel and stable vectorized representation of PDs that enables the seamless\nintegration with machine learning. Comprehensive experiments show that the new\nrepresentation achieves state-of-the-art performance and beyond in much less\ntime than alternative approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 16:38:39 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 09:50:01 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 07:51:23 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zieli\u0144ski", "Bartosz", ""], ["Lipi\u0144ski", "Micha\u0142", ""], ["Juda", "Mateusz", ""], ["Zeppelzauer", "Matthias", ""], ["D\u0142otko", "Pawe\u0142", ""]]}, {"id": "1812.09276", "submitter": "Feras Almasri", "authors": "Feras Almasri, Olivier Debeir", "title": "Multimodal Sensor Fusion In Single Thermal image Super-Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast growth in the visual surveillance and security sectors, thermal\ninfrared images have become increasingly necessary ina large variety of\nindustrial applications. This is true even though IR sensors are still more\nexpensive than their RGB counterpart having the same resolution. In this paper,\nwe propose a deep learning solution to enhance the thermal image resolution.\nThe following results are given:(I) Introduction of a multimodal,\nvisual-thermal fusion model that ad-dresses thermal image super-resolution, via\nintegrating high-frequency information from the visual image. (II)\nInvestigation of different net-work architecture schemes in the literature,\ntheir up-sampling methods,learning procedures, and their optimization functions\nby showing their beneficial contribution to the super-resolution problem. (III)\nA bench-mark ULB17-VT dataset that contains thermal images and their visual\nimages counterpart is presented. (IV) Presentation of a qualitative evaluation\nof a large test set with 58 samples and 22 raters which shows that our proposed\nmodel performs better against state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 17:36:35 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Almasri", "Feras", ""], ["Debeir", "Olivier", ""]]}, {"id": "1812.09323", "submitter": "Jianshu Chen", "authors": "Chih-Kuan Yeh, Jianshu Chen, Chengzhu Yu, Dong Yu", "title": "Unsupervised Speech Recognition via Segmental Empirical Output\n  Distribution Matching", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training speech recognition systems without using\nany labeled data, under the assumption that the learner can only access to the\ninput utterances and a phoneme language model estimated from a non-overlapping\ncorpus. We propose a fully unsupervised learning algorithm that alternates\nbetween solving two sub-problems: (i) learn a phoneme classifier for a given\nset of phoneme segmentation boundaries, and (ii) refining the phoneme\nboundaries based on a given classifier. To solve the first sub-problem, we\nintroduce a novel unsupervised cost function named Segmental Empirical Output\nDistribution Matching, which generalizes the work in (Liu et al., 2017) to\nsegmental structures. For the second sub-problem, we develop an approximate MAP\napproach to refining the boundaries obtained from Wang et al. (2017).\nExperimental results on TIMIT dataset demonstrate the success of this fully\nunsupervised phoneme recognition system, which achieves a phone error rate\n(PER) of 41.6%. Although it is still far away from the state-of-the-art\nsupervised systems, we show that with oracle boundaries and matching language\nmodel, the PER could be improved to 32.5%.This performance approaches the\nsupervised system of the same model architecture, demonstrating the great\npotential of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 01:58:39 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Yeh", "Chih-Kuan", ""], ["Chen", "Jianshu", ""], ["Yu", "Chengzhu", ""], ["Yu", "Dong", ""]]}, {"id": "1812.09380", "submitter": "Radin Hamidi Rad", "authors": "Maliheh Goliforoushani, Radin Hamidi Rad, Maryam Amir Haeri", "title": "A Fuzzy Community-Based Recommender System Using PageRank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are widely used by different user service providers\nspecially those who have interactions with the large community of users. This\npaper introduces a recommender system based on community detection. The\nrecommendation is provided using the local and global similarities between\nusers. The local information is obtained from communities, and the global ones\nare based on the ratings. Here, a new fuzzy community detection using the\npersonalized PageRank metaphor is introduced. The fuzzy membership values of\nthe users to the communities are utilized to define a similarity measure. The\nmethod is evaluated by using two well-known datasets: MovieLens and FilmTrust.\nThe results show that our method outperforms recent recommender systems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 21:35:44 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Goliforoushani", "Maliheh", ""], ["Rad", "Radin Hamidi", ""], ["Haeri", "Maryam Amir", ""]]}, {"id": "1812.09387", "submitter": "Xinli Yu T", "authors": "Zheng Chen, Xinli Yu, Yuan Ling, Bo Song, Wei Quan, Xiaohua Hu, Erjia\n  Yan", "title": "Correlated Anomaly Detection from Large Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Correlated anomaly detection (CAD) from streaming data is a type of group\nanomaly detection and an essential task in useful real-time data mining\napplications like botnet detection, financial event detection, industrial\nprocess monitor, etc. The primary approach for this type of detection in\nprevious researches is based on principal score (PS) of divided batches or\nsliding windows by computing top eigenvalues of the correlation matrix, e.g.\nthe Lanczos algorithm. However, this paper brings up the phenomenon of\nprincipal score degeneration for large data set, and then mathematically and\npractically prove current PS-based methods are likely to fail for CAD on\nlarge-scale streaming data even if the number of correlated anomalies grows\nwith the data size at a reasonable rate; in reality, anomalies tend to be the\nminority of the data, and this issue can be more serious. We propose a\nframework with two novel randomized algorithms rPS and gPS for better detection\nof correlated anomalies from large streaming data of various correlation\nstrength. The experiment shows high and balanced recall and estimated accuracy\nof our framework for anomaly detection from a large server log data set and a\nU.S. stock daily price data set in comparison to direct principal score\nevaluation and some other recent group anomaly detection algorithms. Moreover,\nour techniques significantly improve the computation efficiency and scalability\nfor principal score calculation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 08:03:56 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 20:24:59 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Chen", "Zheng", ""], ["Yu", "Xinli", ""], ["Ling", "Yuan", ""], ["Song", "Bo", ""], ["Quan", "Wei", ""], ["Hu", "Xiaohua", ""], ["Yan", "Erjia", ""]]}, {"id": "1812.09395", "submitter": "Nima Mohajerin", "authors": "Nima Mohajerin and Mohsen Rohani", "title": "Multi-Step Prediction of Occupancy Grid Maps with Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the multi-step prediction of the drivable space, represented\nby Occupancy Grid Maps (OGMs), for autonomous vehicles. Our motivation is that\naccurate multi-step prediction of the drivable space can efficiently improve\npath planning and navigation resulting in safe, comfortable and optimum paths\nin autonomous driving. We train a variety of Recurrent Neural Network (RNN)\nbased architectures on the OGM sequences from the KITTI dataset. The results\ndemonstrate significant improvement of the prediction accuracy using our\nproposed difference learning method, incorporating motion related features,\nover the state of the art. We remove the egomotion from the OGM sequences by\ntransforming them into a common frame. Although in the transformed sequences\nthe KITTI dataset is heavily biased toward static objects, by learning the\ndifference between subsequent OGMs, our proposed method provides accurate\nprediction over both the static and moving objects.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 22:27:10 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 19:02:46 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 20:29:59 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Mohajerin", "Nima", ""], ["Rohani", "Mohsen", ""]]}, {"id": "1812.09400", "submitter": "Li Chen", "authors": "Li Chen, Chih-Yuan Yang, Anindya Paul, Ravi Sahita", "title": "Towards resilient machine learning for ransomware detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a surge of interest in using machine learning (ML) to\nautomatically detect malware through their dynamic behaviors. These approaches\nhave achieved significant improvement in detection rates and lower false\npositive rates at large scale compared with traditional malware analysis\nmethods. ML in threat detection has demonstrated to be a good cop to guard\nplatform security. However it is imperative to evaluate - is ML-powered\nsecurity resilient enough?\n  In this paper, we juxtapose the resiliency and trustworthiness of ML\nalgorithms for security, via a case study of evaluating the resiliency of\nransomware detection via the generative adversarial network (GAN). In this case\nstudy, we propose to use GAN to automatically produce dynamic features that\nexhibit generalized malicious behaviors that can reduce the efficacy of\nblack-box ransomware classifiers. We examine the quality of the GAN-generated\nsamples by comparing the statistical similarity of these samples to real\nransomware and benign software. Further we investigate the latent subspace\nwhere the GAN-generated samples lie and explore reasons why such samples cause\na certain class of ransomware classifiers to degrade in performance. Our focus\nis to emphasize necessary defense improvement in ML-based approaches for\nransomware detection before deployment in the wild. Our results and discoveries\nshould pose relevant questions for defenders such as how ML models can be made\nmore resilient for robust enforcement of security objectives.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 22:38:27 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 23:51:13 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Chen", "Li", ""], ["Yang", "Chih-Yuan", ""], ["Paul", "Anindya", ""], ["Sahita", "Ravi", ""]]}, {"id": "1812.09424", "submitter": "Yuan-chin Ivan Chang", "authors": "Zhanfeng Wang and Yuan-chin Ivan Chang", "title": "Distributed sequential method for analyzing massive data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To analyse a very large data set containing lengthy variables, we adopt a\nsequential estimation idea and propose a parallel divide-and-conquer method. We\nconduct several conventional sequential estimation procedures separately, and\nproperly integrate their results while maintaining the desired statistical\nproperties. Additionally, using a criterion from the statistical experiment\ndesign, we adopt an adaptive sample selection, together with an adaptive\nshrinkage estimation method, to simultaneously accelerate the estimation\nprocedure and identify the effective variables. We confirm the cogency of our\nmethods through theoretical justifications and numerical results derived from\nsynthesized data sets. We then apply the proposed method to three real data\nsets, including those pertaining to appliance energy use and particulate matter\nconcentration.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 00:54:31 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Wang", "Zhanfeng", ""], ["Chang", "Yuan-chin Ivan", ""]]}, {"id": "1812.09427", "submitter": "Yongli Zhu", "authors": "Yongli Zhu, Chengxi Liu, Kai Sun", "title": "Image Embedding of PMU Data for Deep Learning towards Transient\n  Disturbance Classification", "comments": "An updated version of this manuscript has been accepted by the 2018\n  IEEE International Conference on Energy Internet (ICEI), Beijing, China", "journal-ref": null, "doi": "10.1109/ICEI.2018.00038", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study on power grid disturbance classification by Deep\nLearning (DL). A real synchrophasor set composing of three different types of\ndisturbance events from the Frequency Monitoring Network (FNET) is used. An\nimage embedding technique called Gramian Angular Field is applied to transform\neach time series of event data to a two-dimensional image for learning. Two\nmain DL algorithms, i.e. CNN (Convolutional Neural Network) and RNN (Recurrent\nNeural Network) are tested and compared with two widely used data mining tools,\nthe Support Vector Machine and Decision Tree. The test results demonstrate the\nsuperiority of the both DL algorithms over other methods in the application of\npower system transient disturbance classification.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 01:08:47 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zhu", "Yongli", ""], ["Liu", "Chengxi", ""], ["Sun", "Kai", ""]]}, {"id": "1812.09430", "submitter": "Aravind Sankar", "authors": "Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, Hao Yang", "title": "Dynamic Graph Representation Learning via Self-Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning latent representations of nodes in graphs is an important and\nubiquitous task with widespread applications such as link prediction, node\nclassification, and graph visualization. Previous methods on graph\nrepresentation learning mainly focus on static graphs, however, many real-world\ngraphs are dynamic and evolve over time. In this paper, we present Dynamic\nSelf-Attention Network (DySAT), a novel neural architecture that operates on\ndynamic graphs and learns node representations that capture both structural\nproperties and temporal evolutionary patterns. Specifically, DySAT computes\nnode representations by jointly employing self-attention layers along two\ndimensions: structural neighborhood and temporal dynamics. We conduct link\nprediction experiments on two classes of graphs: communication networks and\nbipartite rating networks. Our experimental results show that DySAT has a\nsignificant performance gain over several different state-of-the-art graph\nembedding baselines.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 01:43:07 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 20:22:42 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sankar", "Aravind", ""], ["Wu", "Yanhong", ""], ["Gou", "Liang", ""], ["Zhang", "Wei", ""], ["Yang", "Hao", ""]]}, {"id": "1812.09444", "submitter": "Shaoxing Mo", "authors": "Shaoxing Mo, Nicholas Zabaras, Xiaoqing Shi, Jichun Wu", "title": "Deep autoregressive neural networks for high-dimensional inverse\n  problems in groundwater contaminant source identification", "comments": "30 pages, 21 figures, submitted to Water Resources Research", "journal-ref": null, "doi": "10.1029/2018WR024638", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of a groundwater contaminant source simultaneously with the\nhydraulic conductivity in highly-heterogeneous media often results in a\nhigh-dimensional inverse problem. In this study, a deep autoregressive neural\nnetwork-based surrogate method is developed for the forward model to allow us\nto solve efficiently such high-dimensional inverse problems. The surrogate is\ntrained using limited evaluations of the forward model. Since the relationship\nbetween the time-varying inputs and outputs of the forward transport model is\ncomplex, we propose an autoregressive strategy, which treats the output at the\nprevious time step as input to the network for predicting the output at the\ncurrent time step. We employ a dense convolutional encoder-decoder network\narchitecture in which the high-dimensional input and output fields of the model\nare treated as images to leverage the robust capability of convolutional\nnetworks in image-like data processing. An iterative local updating ensemble\nsmoother (ILUES) algorithm is used as the inversion framework. The proposed\nmethod is evaluated using a synthetic contaminant source identification problem\nwith 686 uncertain input parameters. Results indicate that, with relatively\nlimited training data, the deep autoregressive neural network consisting of 27\nconvolutional layers is capable of providing an accurate approximation for the\nhigh-dimensional model input-output relationship. The autoregressive strategy\nsubstantially improves the network's accuracy and computational efficiency. The\napplication of the surrogate-based ILUES in solving the inverse problem shows\nthat it can achieve accurate inversion results and predictive uncertainty\nestimates.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 03:46:41 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Mo", "Shaoxing", ""], ["Zabaras", "Nicholas", ""], ["Shi", "Xiaoqing", ""], ["Wu", "Jichun", ""]]}, {"id": "1812.09464", "submitter": "Kunjin Chen", "authors": "Kunjin Chen, Jun Hu, Yu Zhang, Zhanqing Yu, Jinliang He", "title": "Fault Location in Power Distribution Systems via Deep Graph\n  Convolutional Networks", "comments": "Accepcted by IEEE Journal on Selected Areas in Communication", "journal-ref": null, "doi": "10.1109/JSAC.2019.2951964", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a novel graph convolutional network (GCN) framework for\nfault location in power distribution networks. The proposed approach integrates\nmultiple measurements at different buses while taking system topology into\naccount. The effectiveness of the GCN model is corroborated by the IEEE 123 bus\nbenchmark system. Simulation results show that the GCN model significantly\noutperforms other widely-used machine learning schemes with very high fault\nlocation accuracy. In addition, the proposed approach is robust to measurement\nnoise and data loss errors. Data visualization results of two competing neural\nnetworks are presented to explore the mechanism of GCN's superior performance.\nA data augmentation procedure is proposed to increase the robustness of the\nmodel under various levels of noise and data loss errors. Further experiments\nshow that the model can adapt to topology changes of distribution networks and\nperform well with a limited number of measured buses.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 06:31:04 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 02:25:07 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chen", "Kunjin", ""], ["Hu", "Jun", ""], ["Zhang", "Yu", ""], ["Yu", "Zhanqing", ""], ["He", "Jinliang", ""]]}, {"id": "1812.09467", "submitter": "Bin Wang", "authors": "Bin Wang, Jie Lu, Zheng Yan, Huaishao Luo, Tianrui Li, Yu Zheng, and\n  Guangquan Zhang", "title": "Deep Uncertainty Quantification: A Machine Learning Approach for Weather\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather forecasting is usually solved through numerical weather prediction\n(NWP), which can sometimes lead to unsatisfactory performance due to\ninappropriate setting of the initial states. In this paper, we design a\ndata-driven method augmented by an effective information fusion mechanism to\nlearn from historical data that incorporates prior knowledge from NWP. We cast\nthe weather forecasting problem as an end-to-end deep learning problem and\nsolve it by proposing a novel negative log-likelihood error (NLE) loss\nfunction. A notable advantage of our proposed method is that it simultaneously\nimplements single-value forecasting and uncertainty quantification, which we\nrefer to as deep uncertainty quantification (DUQ). Efficient deep ensemble\nstrategies are also explored to further improve performance. This new approach\nwas evaluated on a public dataset collected from weather stations in Beijing,\nChina. Experimental results demonstrate that the proposed NLE loss\nsignificantly improves generalization compared to mean squared error (MSE) loss\nand mean absolute error (MAE) loss. Compared with NWP, this approach\nsignificantly improves accuracy by 47.76%, which is a state-of-the-art result\non this benchmark dataset. The preliminary version of the proposed method won\n2nd place in an online competition for daily weather forecasting.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 07:17:27 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 06:20:35 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 01:49:29 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wang", "Bin", ""], ["Lu", "Jie", ""], ["Yan", "Zheng", ""], ["Luo", "Huaishao", ""], ["Li", "Tianrui", ""], ["Zheng", "Yu", ""], ["Zhang", "Guangquan", ""]]}, {"id": "1812.09484", "submitter": "Victoria Mingote Bueno", "authors": "Victoria Mingote, Antonio Miguel, Alfonso Ortega, Eduardo Lleida", "title": "Differentiable Supervector Extraction for Encoding Speaker and Phrase\n  Information in Text Dependent Speaker Verification", "comments": "5 pages, IberSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new differentiable neural network alignment\nmechanism for text-dependent speaker verification which uses alignment models\nto produce a supervector representation of an utterance. Unlike previous works\nwith similar approaches, we do not extract the embedding of an utterance from\nthe mean reduction of the temporal dimension. Our system replaces the mean by a\nphrase alignment model to keep the temporal structure of each phrase which is\nrelevant in this application since the phonetic information is part of the\nidentity in the verification task. Moreover, we can apply a convolutional\nneural network as front-end, and thanks to the alignment process being\ndifferentiable, we can train the whole network to produce a supervector for\neach utterance which will be discriminative with respect to the speaker and the\nphrase simultaneously. As we show, this choice has the advantage that the\nsupervector encodes the phrase and speaker information providing good\nperformance in text-dependent speaker verification tasks. In this work, the\nprocess of verification is performed using a basic similarity metric, due to\nsimplicity, compared to other more elaborate models that are commonly used. The\nnew model using alignment to produce supervectors was tested on the\nRSR2015-Part I database for text-dependent speaker verification, providing\ncompetitive results compared to similar size networks using the mean to extract\nembeddings.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 09:25:59 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Mingote", "Victoria", ""], ["Miguel", "Antonio", ""], ["Ortega", "Alfonso", ""], ["Lleida", "Eduardo", ""]]}, {"id": "1812.09487", "submitter": "Michael Lechner", "authors": "Michael Lechner", "title": "Modified Causal Forests for Estimating Heterogeneous Causal Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Uncovering the heterogeneity of causal effects of policies and business\ndecisions at various levels of granularity provides substantial value to\ndecision makers. This paper develops new estimation and inference procedures\nfor multiple treatment models in a selection-on-observables framework by\nmodifying the Causal Forest approach suggested by Wager and Athey (2018) in\nseveral dimensions. The new estimators have desirable theoretical,\ncomputational and practical properties for various aggregation levels of the\ncausal effects. While an Empirical Monte Carlo study suggests that they\noutperform previously suggested estimators, an application to the evaluation of\nan active labour market programme shows the value of the new methods for\napplied research.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 09:48:56 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 06:33:11 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Lechner", "Michael", ""]]}, {"id": "1812.09489", "submitter": "Piotr W\\'ojcik", "authors": "Piotr Iwo W\\'ojcik", "title": "Random Projection in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the ways in which deep learning methods can benefit\nfrom random projection (RP), a classic linear dimensionality reduction method.\nWe focus on two areas where, as we have found, employing RP techniques can\nimprove deep models: training neural networks on high-dimensional data and\ninitialization of network parameters. Training deep neural networks (DNNs) on\nsparse, high-dimensional data with no exploitable structure implies a network\narchitecture with an input layer that has a huge number of weights, which often\nmakes training infeasible. We show that this problem can be solved by\nprepending the network with an input layer whose weights are initialized with\nan RP matrix. We propose several modifications to the network architecture and\ntraining regime that makes it possible to efficiently train DNNs with learnable\nRP layer on data with as many as tens of millions of input features and\ntraining examples. In comparison to the state-of-the-art methods, neural\nnetworks with RP layer achieve competitive performance or improve the results\non several extremely high-dimensional real-world datasets. The second area\nwhere the application of RP techniques can be beneficial for training deep\nmodels is weight initialization. Setting the initial weights in DNNs to\nelements of various RP matrices enabled us to train residual deep networks to\nhigher levels of performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 09:55:26 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["W\u00f3jcik", "Piotr Iwo", ""]]}, {"id": "1812.09520", "submitter": "Meir Feder", "authors": "Yaniv Fogel and Meir Feder", "title": "Universal Supervised Learning for Individual Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal supervised learning is considered from an information theoretic\npoint of view following the universal prediction approach, see Merhav and Feder\n(1998). We consider the standard supervised \"batch\" learning where prediction\nis done on a test sample once the entire training data is observed, and the\nindividual setting where the features and labels, both in the training and\ntest, are specific individual quantities. The information theoretic approach\nnaturally uses the self-information loss or log-loss. Our results provide\nuniversal learning schemes that compete with a \"genie\" (or reference) that\nknows the true test label. In particular, it is demonstrated that the main\nproposed scheme, termed Predictive Normalized Maximum Likelihood (pNML), is a\nrobust learning solution that outperforms the current leading approach based on\nEmpirical Risk Minimization (ERM). Furthermore, the pNML construction provides\na pointwise indication for the learnability of the specific test challenge with\nthe given training examples\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 12:24:02 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Fogel", "Yaniv", ""], ["Feder", "Meir", ""]]}, {"id": "1812.09549", "submitter": "Ahmed Allam", "authors": "Ahmed Allam, Mate Nagy, George Thoma, Michael Krauthammer", "title": "Neural networks versus Logistic regression for 30 days all-cause\n  readmission prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart failure (HF) is one of the leading causes of hospital admissions in the\nUS. Readmission within 30 days after a HF hospitalization is both a recognized\nindicator for disease progression and a source of considerable financial burden\nto the healthcare system. Consequently, the identification of patients at risk\nfor readmission is a key step in improving disease management and patient\noutcome. In this work, we used a large administrative claims dataset to\n(1)explore the systematic application of neural network-based models versus\nlogistic regression for predicting 30 days all-cause readmission after\ndischarge from a HF admission, and (2)to examine the additive value of\npatients' hospitalization timelines on prediction performance. Based on data\nfrom 272,778 (49% female) patients with a mean (SD) age of 73 years (14) and\n343,328 HF admissions (67% of total admissions), we trained and tested our\npredictive readmission models following a stratified 5-fold cross-validation\nscheme. Among the deep learning approaches, a recurrent neural network (RNN)\ncombined with conditional random fields (CRF) model (RNNCRF) achieved the best\nperformance in readmission prediction with 0.642 AUC (95% CI, 0.640-0.645).\nOther models, such as those based on RNN, convolutional neural networks and CRF\nalone had lower performance, with a non-timeline based model (MLP) performing\nworst. A competitive model based on logistic regression with LASSO achieved a\nperformance of 0.643 AUC (95%CI, 0.640-0.646). We conclude that data from\npatient timelines improve 30 day readmission prediction for neural\nnetwork-based models, that a logistic regression with LASSO has equal\nperformance to the best neural network model and that the use of administrative\ndata result in competitive performance compared to published approaches based\non richer clinical datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 15:59:39 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Allam", "Ahmed", ""], ["Nagy", "Mate", ""], ["Thoma", "George", ""], ["Krauthammer", "Michael", ""]]}, {"id": "1812.09567", "submitter": "Hanchen Xu", "authors": "Hanchen Xu, Hongbo Sun, Daniel Nikovski, Kitamura Shoichi, Kazuyuki\n  Mori", "title": "Learning Dynamical Demand Response Model in Real-Time Pricing Program", "comments": "Accepted to IEEE ISGT NA 2019", "journal-ref": null, "doi": "10.1109/ISGT.2019.8791624", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Price responsiveness is a major feature of end use customers (EUCs) that\nparticipate in demand response (DR) programs, and has been conventionally\nmodeled with static demand functions, which take the electricity price as the\ninput and the aggregate energy consumption as the output. This, however,\nneglects the inherent temporal correlation of the EUC behaviors, and may result\nin large errors when predicting the actual responses of EUCs in real-time\npricing (RTP) programs. In this paper, we propose a dynamical DR model so as to\ncapture the temporal behavior of the EUCs. The states in the proposed dynamical\nDR model can be explicitly chosen, in which case the model can be represented\nby a linear function or a multi-layer feedforward neural network, or implicitly\nchosen, in which case the model can be represented by a recurrent neural\nnetwork or a long short-term memory unit network. In both cases, the dynamical\nDR model can be learned from historical price and energy consumption data.\nNumerical simulation illustrated how the states are chosen and also showed the\nproposed dynamical DR model significantly outperforms the static ones.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 17:09:22 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Xu", "Hanchen", ""], ["Sun", "Hongbo", ""], ["Nikovski", "Daniel", ""], ["Shoichi", "Kitamura", ""], ["Mori", "Kazuyuki", ""]]}, {"id": "1812.09584", "submitter": "Albert Shaw", "authors": "Albert Shaw, Wei Wei, Weiyang Liu, Le Song, Bo Dai", "title": "Meta Architecture Search", "comments": "11 pages, 4 figures, 4 tables, 4 pages of appendix; NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has been quite successful in constructing\nstate-of-the-art models on a variety of tasks. Unfortunately, the computational\ncost can make it difficult to scale. In this paper, we make the first attempt\nto study Meta Architecture Search which aims at learning a task-agnostic\nrepresentation that can be used to speed up the process of architecture search\non a large number of tasks. We propose the Bayesian Meta Architecture SEarch\n(BASE) framework which takes advantage of a Bayesian formulation of the\narchitecture search problem to learn over an entire set of tasks\nsimultaneously. We show that on Imagenet classification, we can find a model\nthat achieves 25.7% top-1 error and 8.1% top-5 error by adapting the\narchitecture in less than an hour from an 8 GPU days pretrained meta-network.\nBy learning a good prior for NAS, our method dramatically decreases the\nrequired computation cost while achieving comparable performance to current\nstate-of-the-art methods - even finding competitive models for unseen datasets\nwith very quick adaptation. We believe our framework will open up new\npossibilities for efficient and massively scalable architecture search research\nacross multiple tasks.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 19:25:08 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 16:06:14 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Shaw", "Albert", ""], ["Wei", "Wei", ""], ["Liu", "Weiyang", ""], ["Song", "Le", ""], ["Dai", "Bo", ""]]}, {"id": "1812.09587", "submitter": "Yury Maximov", "authors": "Valerii Likhosherstov, Yury Maximov, Michael Chertkov", "title": "Inference and Sampling of $K_{33}$-free Ising Models", "comments": "20 pages", "journal-ref": "36-th International Conference on Machine Learning, PMLR 97, 2019", "doi": null, "report-no": null, "categories": "stat.CO cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call an Ising model tractable when it is possible to compute its partition\nfunction value (statistical inference) in polynomial time. The tractability\nalso implies an ability to sample configurations of this model in polynomial\ntime. The notion of tractability extends the basic case of planar zero-field\nIsing models. Our starting point is to describe algorithms for the basic case\ncomputing partition function and sampling efficiently. To derive the\nalgorithms, we use an equivalent linear transition to perfect matching counting\nand sampling on an expanded dual graph. Then, we extend our tractable inference\nand sampling algorithms to models, whose triconnected components are either\nplanar or graphs of $O(1)$ size. In particular, it results in a polynomial-time\ninference and sampling algorithms for $K_{33}$ (minor) free topologies of\nzero-field Ising models - a generalization of planar graphs with a potentially\nunbounded genus.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 19:32:44 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 19:43:47 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Likhosherstov", "Valerii", ""], ["Maximov", "Yury", ""], ["Chertkov", "Michael", ""]]}, {"id": "1812.09603", "submitter": "Pedram Rooshenas", "authors": "Amirmohammad Rooshenas, Dongxu Zhang, Gopal Sharma, Andrew McCallum", "title": "Search-Guided, Lightly-supervised Training of Structured Prediction\n  Energy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In structured output prediction tasks, labeling ground-truth training output\nis often expensive. However, for many tasks, even when the true output is\nunknown, we can evaluate predictions using a scalar reward function, which may\nbe easily assembled from human knowledge or non-differentiable pipelines. But\nsearching through the entire output space to find the best output with respect\nto this reward function is typically intractable. In this paper, we instead use\nefficient truncated randomized search in this reward function to train\nstructured prediction energy networks (SPENs), which provide efficient\ntest-time inference using gradient-based search on a smooth, learned\nrepresentation of the score landscape, and have previously yielded\nstate-of-the-art results in structured prediction. In particular, this\ntruncated randomized search in the reward function yields previously unknown\nlocal improvements, providing effective supervision to SPENs, avoiding their\ntraditional need for labeled training data.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 21:06:02 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 17:36:24 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rooshenas", "Amirmohammad", ""], ["Zhang", "Dongxu", ""], ["Sharma", "Gopal", ""], ["McCallum", "Andrew", ""]]}, {"id": "1812.09624", "submitter": "Alican Bozkurt", "authors": "Alican Bozkurt, Babak Esmaeili, Dana H. Brooks, Jennifer G. Dy,\n  Jan-Willem van de Meent", "title": "Can VAEs Generate Novel Examples?", "comments": "Presented at Critiquing and Correcting Trends in Machine Learning\n  Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An implicit goal in works on deep generative models is that such models\nshould be able to generate novel examples that were not previously seen in the\ntraining data. In this paper, we investigate to what extent this property holds\nfor widely employed variational autoencoder (VAE) architectures. VAEs maximize\na lower bound on the log marginal likelihood, which implies that they will in\nprinciple overfit the training data when provided with a sufficiently\nexpressive decoder. In the limit of an infinite capacity decoder, the optimal\ngenerative model is a uniform mixture over the training data. More generally,\nan optimal decoder should output a weighted average over the examples in the\ntraining data, where the magnitude of the weights is determined by the\nproximity in the latent space. This leads to the hypothesis that, for a\nsufficiently high capacity encoder and decoder, the VAE decoder will perform\nnearest-neighbor matching according to the coordinates in the latent space. To\ntest this hypothesis, we investigate generalization on the MNIST dataset. We\nconsider both generalization to new examples of previously seen classes, and\ngeneralization to the classes that were withheld from the training set. In both\ncases, we find that reconstructions are closely approximated by nearest\nneighbors for higher-dimensional parameterizations. When generalizing to unseen\nclasses however, lower-dimensional parameterizations offer a clear advantage.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 23:43:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Bozkurt", "Alican", ""], ["Esmaeili", "Babak", ""], ["Brooks", "Dana H.", ""], ["Dy", "Jennifer G.", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1812.09632", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Csan\\'ad Cs\\'aji, Kriszti\\'an Bal\\'azs Kis", "title": "Distribution-Free Uncertainty Quantification for Kernel Methods by\n  Gradient Perturbations", "comments": "18 figures", "journal-ref": "Machine Learning, Volume 108, Issue 8, 2019, pp. 1677-1699", "doi": "10.1007/s10994-019-05822-1", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven approach to quantify the uncertainty of models\nconstructed by kernel methods. Our approach minimizes the needed distributional\nassumptions, hence, instead of working with, for example, Gaussian processes or\nexponential families, it only requires knowledge about some mild regularity of\nthe measurement noise, such as it is being symmetric or exchangeable. We show,\nby building on recent results from finite-sample system identification, that by\nperturbing the residuals in the gradient of the objective function, information\ncan be extracted about the amount of uncertainty our model has. Particularly,\nwe provide an algorithm to build exact, non-asymptotically guaranteed,\ndistribution-free confidence regions for ideal, noise-free representations of\nthe function we try to estimate. For the typical convex quadratic problems and\nsymmetric noises, the regions are star convex centered around a given nominal\nestimate, and have efficient ellipsoidal outer approximations. Finally, we\nillustrate the ideas on typical kernel methods, such as LS-SVC, KRR,\n$\\varepsilon$-SVR and kernelized LASSO.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 01:37:13 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 13:34:51 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Csan\u00e1d", ""], ["Kis", "Kriszti\u00e1n Bal\u00e1zs", ""]]}, {"id": "1812.09640", "submitter": "Vikram Krishnamurthy", "authors": "William Hoiles and Vikram Krishnamurthy", "title": "Estimating Rationally Inattentive Utility Functions with Deep Clustering\n  for Framing - Applications in YouTube Engagement Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a framework involving behavioral economics and machine learning.\nRationally inattentive Bayesian agents make decisions based on their posterior\ndistribution, utility function and information acquisition cost Renyi\ndivergence which generalizes Shannon mutual information). By observing these\ndecisions, how can an observer estimate the utility function and information\nacquisition cost? Using deep learning, we estimate framing information\n(essential extrinsic features) that determines the agent's attention strategy.\nThen we present a preference based inverse reinforcement learning algorithm to\ntest for rational inattention: is the agent an utility maximizer, attention\nmaximizer, and does an information cost function exist that rationalizes the\ndata? The test imposes a Renyi mutual information constraint which impacts how\nthe agent can select attention strategies to maximize their expected utility.\nThe test provides constructive estimates of the utility function and\ninformation acquisition cost of the agent. We illustrate these methods on a\nmassive YouTube dataset for characterizing the commenting behavior of users.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 02:31:11 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Hoiles", "William", ""], ["Krishnamurthy", "Vikram", ""]]}, {"id": "1812.09645", "submitter": "Ghazal Fazelnia", "authors": "Ghazal Fazelnia, Mark Ibrahim, Ceena Modarres, Kevin Wu, John Paisley", "title": "Mixed Membership Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models for sequential data such as the recurrent neural network (RNN) often\nimplicitly model a sequence as having a fixed time interval between\nobservations and do not account for group-level effects when multiple sequences\nare observed. We propose a model for grouped sequential data based on the RNN\nthat accounts for varying time intervals between observations in a sequence by\nlearning a group-level base parameter to which each sequence can revert. Our\napproach is motivated by the mixed membership framework, and we show how it can\nbe used for dynamic topic modeling in which the distribution on topics (not the\ntopics themselves) are evolving in time. We demonstrate our approach on a\ndataset of 3.4 million online grocery shopping orders made by 206K customers.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 02:57:40 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Fazelnia", "Ghazal", ""], ["Ibrahim", "Mark", ""], ["Modarres", "Ceena", ""], ["Wu", "Kevin", ""], ["Paisley", "John", ""]]}, {"id": "1812.09650", "submitter": "Nikhil Marda", "authors": "Peter Hansel, Nik Marda, William Yin", "title": "Improving Context-Aware Semantic Relationships in Sparse Mobile Datasets", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional semantic similarity models often fail to encapsulate the external\ncontext in which texts are situated. However, textual datasets generated on\nmobile platforms can help us build a truer representation of semantic\nsimilarity by introducing multimodal data. This is especially important in\nsparse datasets, making solely text-driven interpretation of context more\ndifficult. In this paper, we develop new algorithms for building external\nfeatures into sentence embeddings and semantic similarity scores. Then, we test\nthem on embedding spaces on data from Twitter, using each tweet's time and\ngeolocation to better understand its context. Ultimately, we show that applying\nPCA with eight components to the embedding space and appending multimodal\nfeatures yields the best outcomes. This yields a considerable improvement over\npure text-based approaches for discovering similar tweets. Our results suggest\nthat our new algorithm can help improve semantic understanding in various\nsettings.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 03:35:56 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Hansel", "Peter", ""], ["Marda", "Nik", ""], ["Yin", "William", ""]]}, {"id": "1812.09658", "submitter": "Jaeho Lee", "authors": "Jaeho Lee, Maxim Raginsky", "title": "Learning finite-dimensional coding schemes with nonlinear reconstruction\n  maps", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper generalizes the Maurer--Pontil framework of finite-dimensional\nlossy coding schemes to the setting where a high-dimensional random vector is\nmapped to an element of a compact set of latent representations in a\nlower-dimensional Euclidean space, and the reconstruction map belongs to a\ngiven class of nonlinear maps. Under this setup, which encompasses a broad\nclass of unsupervised representation learning problems, we establish a\nconnection to approximate generative modeling under structural constraints\nusing the tools from the theory of optimal transportation. Next, we consider\nproblem of learning a coding scheme on the basis of a finite collection of\ntraining samples and present generalization bounds that hold with high\nprobability. We then illustrate the general theory in the setting where the\nreconstruction maps are implemented by deep neural nets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 05:02:54 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 15:43:10 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Lee", "Jaeho", ""], ["Raginsky", "Maxim", ""]]}, {"id": "1812.09659", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Nestor Sepulveda, Ming Zheng", "title": "Artificial neural networks condensation: A strategy to facilitate\n  adaption of machine learning in medical settings by reducing computational\n  burden", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) applications on healthcare can have a great impact on\npeople's lives helping deliver better and timely treatment to those in need. At\nthe same time, medical data is usually big and sparse requiring important\ncomputational resources. Although it might not be a problem for wide-adoption\nof ML tools in developed nations, availability of computational resource can\nvery well be limited in third-world nations. This can prevent the less favored\npeople from benefiting of the advancement in ML applications for healthcare. In\nthis project we explored methods to increase computational efficiency of ML\nalgorithms, in particular Artificial Neural Nets (NN), while not compromising\nthe accuracy of the predicted results. We used in-hospital mortality prediction\nas our case analysis based on the MIMIC III publicly available dataset. We\nexplored three methods on two different NN architectures. We reduced the size\nof recurrent neural net (RNN) and dense neural net (DNN) by applying pruning of\n\"unused\" neurons. Additionally, we modified the RNN structure by adding a\nhidden-layer to the LSTM cell allowing to use less recurrent layers for the\nmodel. Finally, we implemented quantization on DNN forcing the weights to be\n8-bits instead of 32-bits. We found that all our methods increased\ncomputational efficiency without compromising accuracy and some of them even\nachieved higher accuracy than the pre-condensed baseline models.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 05:08:24 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Liu", "Dianbo", ""], ["Sepulveda", "Nestor", ""], ["Zheng", "Ming", ""]]}, {"id": "1812.09687", "submitter": "Karl-Heinz Zimmermann", "authors": "Karl-Heinz Zimmermann", "title": "Computations in Stochastic Acceptors", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning provides algorithms that can learn from data and make\ninferences or predictions on data. Stochastic acceptors or probabilistic\nautomata are stochastic automata without output that can model components in\nmachine learning scenarios. In this paper, we provide dynamic programming\nalgorithms for the computation of input marginals and the acceptance\nprobabilities in stochastic acceptors. Furthermore, we specify an algorithm for\nthe parameter estimation of the conditional probabilities using the\nexpectation-maximization technique and a more efficient implementation related\nto the Baum-Welch algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 10:57:57 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zimmermann", "Karl-Heinz", ""]]}, {"id": "1812.09707", "submitter": "David Peer", "authors": "David Peer, Sebastian Stabinger, Antonio Rodriguez-Sanchez", "title": "Increasing the adversarial robustness and explainability of capsule\n  networks with $\\gamma$-capsules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new inductive bias for capsule networks and call\nnetworks that use this prior $\\gamma$-capsule networks. Our inductive bias that\nis inspired by TE neurons of the inferior temporal cortex increases the\nadversarial robustness and the explainability of capsule networks. A\ntheoretical framework with formal definitions of $\\gamma$-capsule networks and\nmetrics for evaluation are also provided. Under our framework we show that\ncommon capsule networks do not necessarily make use of this inductive bias. For\nthis reason we introduce a novel routing algorithm and use a different training\nalgorithm to be able to implement $\\gamma$-capsule networks. We then show\nexperimentally that $\\gamma$-capsule networks are indeed more transparent and\nmore robust against adversarial attacks than regular capsule networks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 13:32:59 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 16:38:48 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 09:04:49 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 10:04:26 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Peer", "David", ""], ["Stabinger", "Sebastian", ""], ["Rodriguez-Sanchez", "Antonio", ""]]}, {"id": "1812.09746", "submitter": "Tobias Baum", "authors": "Tobias Baum and Steffen Herbold and Kurt Schneider", "title": "A Multi-Objective Anytime Rule Mining System to Ease Iterative Feedback\n  from Domain Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data extracted from software repositories is used intensively in Software\nEngineering research, for example, to predict defects in source code. In our\nresearch in this area, with data from open source projects as well as an\nindustrial partner, we noticed several shortcomings of conventional data mining\napproaches for classification problems: (1) Domain experts' acceptance is of\ncritical importance, and domain experts can provide valuable input, but it is\nhard to use this feedback. (2) The evaluation of the model is not a simple\nmatter of calculating AUC or accuracy. Instead, there are multiple objectives\nof varying importance, but their importance cannot be easily quantified.\nFurthermore, the performance of the model cannot be evaluated on a per-instance\nlevel in our case, because it shares aspects with the set cover problem. To\novercome these problems, we take a holistic approach and develop a rule mining\nsystem that simplifies iterative feedback from domain experts and can easily\nincorporate the domain-specific evaluation needs. A central part of the system\nis a novel multi-objective anytime rule mining algorithm. The algorithm is\nbased on the GRASP-PR meta-heuristic but extends it with ideas from several\nother approaches. We successfully applied the system in the industrial context.\nIn the current article, we focus on the description of the algorithm and the\nconcepts of the system. We provide an implementation of the system for reuse.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 17:56:17 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Baum", "Tobias", ""], ["Herbold", "Steffen", ""], ["Schneider", "Kurt", ""]]}, {"id": "1812.09747", "submitter": "Brian Sifringer", "authors": "Brian Sifringer, Virginie Lurkin, Alexandre Alahi", "title": "Enhancing Discrete Choice Models with Representation Learning", "comments": "35 pages, 12 tables, 6 figures, +11 p. Appendix", "journal-ref": "Transportation Research Part B: Methodological 140 (2020) 236-261", "doi": "10.1016/j.trb.2020.08.006", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In discrete choice modeling (DCM), model misspecifications may lead to\nlimited predictability and biased parameter estimates. In this paper, we\npropose a new approach for estimating choice models in which we divide the\nsystematic part of the utility specification into (i) a knowledge-driven part,\nand (ii) a data-driven one, which learns a new representation from available\nexplanatory variables. Our formulation increases the predictive power of\nstandard DCM without sacrificing their interpretability. We show the\neffectiveness of our formulation by augmenting the utility specification of the\nMultinomial Logit (MNL) and the Nested Logit (NL) models with a new non-linear\nrepresentation arising from a Neural Network (NN), leading to new choice models\nreferred to as the Learning Multinomial Logit (L-MNL) and Learning Nested Logit\n(L-NL) models. Using multiple publicly available datasets based on revealed and\nstated preferences, we show that our models outperform the traditional ones,\nboth in terms of predictive performance and accuracy in parameter estimation.\nAll source code of the models are shared to promote open science.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 17:59:51 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 14:27:41 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 07:57:35 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Sifringer", "Brian", ""], ["Lurkin", "Virginie", ""], ["Alahi", "Alexandre", ""]]}, {"id": "1812.09755", "submitter": "Amanpreet Singh", "authors": "Amanpreet Singh, Tushar Jain, Sainbayar Sukhbaatar", "title": "Learning when to Communicate at Scale in Multiagent Cooperative and\n  Competitive Tasks", "comments": "Accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning when to communicate and doing that effectively is essential in\nmulti-agent tasks. Recent works show that continuous communication allows\nefficient training with back-propagation in multi-agent scenarios, but have\nbeen restricted to fully-cooperative tasks. In this paper, we present\nIndividualized Controlled Continuous Communication Model (IC3Net) which has\nbetter training efficiency than simple continuous communication model, and can\nbe applied to semi-cooperative and competitive settings along with the\ncooperative settings. IC3Net controls continuous communication with a gating\nmechanism and uses individualized rewards foreach agent to gain better\nperformance and scalability while fixing credit assignment issues. Using\nvariety of tasks including StarCraft BroodWars explore and combat scenarios, we\nshow that our network yields improved performance and convergence rates than\nthe baselines as the scale increases. Our results convey that IC3Net agents\nlearn when to communicate based on the scenario and profitability.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 19:07:36 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Singh", "Amanpreet", ""], ["Jain", "Tushar", ""], ["Sukhbaatar", "Sainbayar", ""]]}, {"id": "1812.09758", "submitter": "Paul McNicholas", "authors": "Forrest Paton and Paul D. McNicholas", "title": "Detecting British Columbia Coastal Rainfall Patterns by Clustering\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional data analysis is a statistical framework where data are assumed to\nfollow some functional form. This method of analysis is commonly applied to\ntime series data, where time, measured continuously or in discrete intervals,\nserves as the location for a function's value. Gaussian processes are a\ngeneralization of the multivariate normal distribution to function space and,\nin this paper, they are used to shed light on coastal rainfall patterns in\nBritish Columbia (BC). Specifically, this work addressed the question over how\none should carry out an exploratory cluster analysis for the BC, or any\nsimilar, coastal rainfall data. An approach is developed for clustering\nmultiple processes observed on a comparable interval, based on how similar\ntheir underlying covariance kernel is. This approach provides interesting\ninsights into the BC data, and these insights can be framed in terms of El\nNi\\~{n}o and La Ni\\~{n}a; however, the result is not simply one cluster\nrepresenting El Ni\\~{n}o years and another for La Ni\\~{n}a years. From one\nperspective, the results show that clustering annual rainfall can potentially\nbe used to identify extreme weather patterns.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 19:15:36 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 22:54:47 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Paton", "Forrest", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1812.09764", "submitter": "Bastian Rieck", "authors": "Bastian Rieck, Matteo Togninalli, Christian Bock, Michael Moor, Max\n  Horn, Thomas Gumbsch, Karsten Borgwardt", "title": "Neural Persistence: A Complexity Measure for Deep Neural Networks Using\n  Algebraic Topology", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": "10.3929/ethz-b-000327207", "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many approaches to make neural networks more fathomable have been\nproposed, they are restricted to interrogating the network with input data.\nMeasures for characterizing and monitoring structural properties, however, have\nnot been developed. In this work, we propose neural persistence, a complexity\nmeasure for neural network architectures based on topological data analysis on\nweighted stratified graphs. To demonstrate the usefulness of our approach, we\nshow that neural persistence reflects best practices developed in the deep\nlearning community such as dropout and batch normalization. Moreover, we derive\na neural persistence-based stopping criterion that shortens the training\nprocess while achieving comparable accuracies as early stopping based on\nvalidation loss.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 19:41:02 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 12:43:10 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 06:54:59 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Rieck", "Bastian", ""], ["Togninalli", "Matteo", ""], ["Bock", "Christian", ""], ["Moor", "Michael", ""], ["Horn", "Max", ""], ["Gumbsch", "Thomas", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "1812.09771", "submitter": "Ayoub Belhadji", "authors": "Ayoub Belhadji, R\\'emi Bardenet, Pierre Chainais", "title": "A determinantal point process for column subset selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is a first step of many machine learning pipelines.\nTwo popular approaches are principal component analysis, which projects onto a\nsmall number of well chosen but non-interpretable directions, and feature\nselection, which selects a small number of the original features. Feature\nselection can be abstracted as a numerical linear algebra problem called the\ncolumn subset selection problem (CSSP). CSSP corresponds to selecting the best\nsubset of columns of a matrix $X \\in \\mathbb{R}^{N \\times d}$, where\n\\emph{best} is often meant in the sense of minimizing the approximation error,\ni.e., the norm of the residual after projection of $X$ onto the space spanned\nby the selected columns. Such an optimization over subsets of $\\{1,\\dots,d\\}$\nis usually impractical. One workaround that has been vastly explored is to\nresort to polynomial-cost, random subset selection algorithms that favor small\nvalues of this approximation error. We propose such a randomized algorithm,\nbased on sampling from a projection determinantal point process (DPP), a\nrepulsive distribution over a fixed number $k$ of indices $\\{1,\\dots,d\\}$ that\nfavors diversity among the selected columns. We give bounds on the ratio of the\nexpected approximation error for this DPP over the optimal error of PCA. These\nbounds improve over the state-of-the-art bounds of \\emph{volume sampling} when\nsome realistic structural assumptions are satisfied for $X$. Numerical\nexperiments suggest that our bounds are tight, and that our algorithms have\ncomparable performance with the \\emph{double phase} algorithm, often considered\nto be the practical state-of-the-art. Column subset selection with DPPs thus\ninherits the best of both worlds: good empirical performance and tight error\nbounds.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 20:23:00 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Belhadji", "Ayoub", ""], ["Bardenet", "R\u00e9mi", ""], ["Chainais", "Pierre", ""]]}, {"id": "1812.09803", "submitter": "Thomas Brunner", "authors": "Thomas Brunner, Frederik Diehl, Michael Truong Le, Alois Knoll", "title": "Guessing Smart: Biased Sampling for Efficient Black-Box Adversarial\n  Attacks", "comments": "For source code and videos, see\n  https://github.com/ttbrunner/biased_boundary_attack", "journal-ref": null, "doi": "10.1109/ICCV.2019.00506", "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider adversarial examples for image classification in the black-box\ndecision-based setting. Here, an attacker cannot access confidence scores, but\nonly the final label. Most attacks for this scenario are either unreliable or\ninefficient. Focusing on the latter, we show that a specific class of attacks,\nBoundary Attacks, can be reinterpreted as a biased sampling framework that\ngains efficiency from domain knowledge. We identify three such biases, image\nfrequency, regional masks and surrogate gradients, and evaluate their\nperformance against an ImageNet classifier. We show that the combination of\nthese biases outperforms the state of the art by a wide margin. We also\nshowcase an efficient way to attack the Google Cloud Vision API, where we craft\nconvincing perturbations with just a few hundred queries. Finally, the methods\nwe propose have also been found to work very well against strong defenses: Our\ntargeted attack won second place in the NeurIPS 2018 Adversarial Vision\nChallenge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 00:48:31 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 13:39:59 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 13:05:16 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Brunner", "Thomas", ""], ["Diehl", "Frederik", ""], ["Le", "Michael Truong", ""], ["Knoll", "Alois", ""]]}, {"id": "1812.09859", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Jan Vondrak", "title": "Generalization Bounds for Uniformly Stable Algorithms", "comments": "Appeared in Neural Information Processing Systems (NeurIPS), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniform stability of a learning algorithm is a classical notion of\nalgorithmic stability introduced to derive high-probability bounds on the\ngeneralization error (Bousquet and Elisseeff, 2002). Specifically, for a loss\nfunction with range bounded in $[0,1]$, the generalization error of a\n$\\gamma$-uniformly stable learning algorithm on $n$ samples is known to be\nwithin $O((\\gamma +1/n) \\sqrt{n \\log(1/\\delta)})$ of the empirical error with\nprobability at least $1-\\delta$. Unfortunately, this bound does not lead to\nmeaningful generalization bounds in many common settings where $\\gamma \\geq\n1/\\sqrt{n}$. At the same time the bound is known to be tight only when $\\gamma\n= O(1/n)$.\n  We substantially improve generalization bounds for uniformly stable\nalgorithms without making any additional assumptions. First, we show that the\nbound in this setting is $O(\\sqrt{(\\gamma + 1/n) \\log(1/\\delta)})$ with\nprobability at least $1-\\delta$. In addition, we prove a tight bound of\n$O(\\gamma^2 + 1/n)$ on the second moment of the estimation error. The best\nprevious bound on the second moment is $O(\\gamma + 1/n)$. Our proofs are based\non new analysis techniques and our results imply substantially stronger\ngeneralization guarantees for several well-studied algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 07:55:45 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 05:12:35 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Feldman", "Vitaly", ""], ["Vondrak", "Jan", ""]]}, {"id": "1812.09895", "submitter": "Maximilian Kurthen", "authors": "Maximilian Kurthen, Torsten A. En{\\ss}lin", "title": "A Bayesian Model for Bivariate Causal Inference", "comments": null, "journal-ref": "Entropy 2020, 22(1), 46", "doi": "10.3390/e22010046", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of two-variable causal inference without intervention.\nThis task is to infer an existing causal relation between two random variables,\ni.e. $X \\rightarrow Y$ or $Y \\rightarrow X$ , from purely observational data.\nAs the option to modify a potential cause is not given in many situations only\nstructural properties of the data can be used to solve this ill-posed problem.\nWe briefly review a number of state-of-the-art methods for this, including very\nrecent ones. A novel inference method is introduced, Bayesian Causal Inference\n(BCI), which assumes a generative Bayesian hierarchical model to pursue the\nstrategy of Bayesian model selection. In the adopted model the distribution of\nthe cause variable is given by a Poisson lognormal distribution, which allows\nto explicitly regard the discrete nature of datasets, correlations in the\nparameter spaces, as well as the variance of probability densities on\nlogarithmic scales. We assume Fourier diagonal Field covariance operators. The\nmodel itself is restricted to use cases where a direct causal relation $X\n\\rightarrow Y$ has to be decided against a relation $Y \\rightarrow X$ ,\ntherefore we compare it other methods for this exact problem setting. The\ngenerative model assumed provides synthetic causal data for benchmarking our\nmodel in comparison to existing State-of-the-art models, namely LiNGAM ,\nANM-HSIC , ANM-MML , IGCI and CGNN . We explore how well the above methods\nperform in case of high noise settings, strongly discretized data and very\nsparse data. BCI performs generally reliable with synthetic data as well as\nwith the real world TCEP benchmark set, with an accuracy comparable to\nstate-of-the-art algorithms. We discuss directions for the future development\nof BCI .\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 11:34:09 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 16:54:10 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kurthen", "Maximilian", ""], ["En\u00dflin", "Torsten A.", ""]]}, {"id": "1812.09902", "submitter": "Haggai Maron", "authors": "Haggai Maron, Heli Ben-Hamu, Nadav Shamir, Yaron Lipman", "title": "Invariant and Equivariant Graph Networks", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariant and equivariant networks have been successfully used for learning\nimages, sets, point clouds, and graphs. A basic challenge in developing such\nnetworks is finding the maximal collection of invariant and equivariant linear\nlayers. Although this question is answered for the first three examples (for\npopular transformations, at-least), a full characterization of invariant and\nequivariant linear layers for graphs is not known.\n  In this paper we provide a characterization of all permutation invariant and\nequivariant linear layers for (hyper-)graph data, and show that their\ndimension, in case of edge-value graph data, is 2 and 15, respectively. More\ngenerally, for graph data defined on k-tuples of nodes, the dimension is the\nk-th and 2k-th Bell numbers. Orthogonal bases for the layers are computed,\nincluding generalization to multi-graph data. The constant number of basis\nelements and their characteristics allow successfully applying the networks to\ndifferent size graphs. From the theoretical point of view, our results\ngeneralize and unify recent advancement in equivariant deep learning. In\nparticular, we show that our model is capable of approximating any message\npassing neural network\n  Applying these new linear layers in a simple deep neural network framework is\nshown to achieve comparable results to state-of-the-art and to have better\nexpressivity than previous invariant and equivariant bases.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 11:52:27 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 06:01:53 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Maron", "Haggai", ""], ["Ben-Hamu", "Heli", ""], ["Shamir", "Nadav", ""], ["Lipman", "Yaron", ""]]}, {"id": "1812.09910", "submitter": "Vikas Kumar", "authors": "Vikas Kumar, Arun K Pujari, Vineet Padmanabhan, Venkateswara Rao\n  Kagita", "title": "Group Preserving Label Embedding for Multi-Label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label learning is concerned with the classification of data with\nmultiple class labels. This is in contrast to the traditional classification\nproblem where every data instance has a single label. Due to the exponential\nsize of output space, exploiting intrinsic information in feature and label\nspaces has been the major thrust of research in recent years and use of\nparametrization and embedding have been the prime focus. Researchers have\nstudied several aspects of embedding which include label embedding, input\nembedding, dimensionality reduction and feature selection. These approaches\ndiffer from one another in their capability to capture other intrinsic\nproperties such as label correlation, local invariance etc. We assume here that\nthe input data form groups and as a result, the label matrix exhibits a\nsparsity pattern and hence the labels corresponding to objects in the same\ngroup have similar sparsity. In this paper, we study the embedding of labels\ntogether with the group information with an objective to build an efficient\nmulti-label classification. We assume the existence of a low-dimensional space\nonto which the feature vectors and label vectors can be embedded. In order to\nachieve this, we address three sub-problems namely; (1) Identification of\ngroups of labels; (2) Embedding of label vectors to a low rank-space so that\nthe sparsity characteristic of individual groups remains invariant; and (3)\nDetermining a linear mapping that embeds the feature vectors onto the same set\nof points, as in stage 2, in the low-dimensional space. We compare our method\nwith seven well-known algorithms on twelve benchmark data sets. Our\nexperimental analysis manifests the superiority of our proposed method over\nstate-of-art algorithms for multi-label learning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 12:58:44 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Kumar", "Vikas", ""], ["Pujari", "Arun K", ""], ["Padmanabhan", "Vineet", ""], ["Kagita", "Venkateswara Rao", ""]]}, {"id": "1812.09916", "submitter": "Wei Wang", "authors": "Wei Wang, Yuan Sun, Saman Halgamuge", "title": "Improving MMD-GAN Training with Repulsive Loss Function", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial nets (GANs) are widely used to learn the data sampling\nprocess and their performance may heavily depend on the loss functions, given a\nlimited computational budget. This study revisits MMD-GAN that uses the maximum\nmean discrepancy (MMD) as the loss function for GAN and makes two\ncontributions. First, we argue that the existing MMD loss function may\ndiscourage the learning of fine details in data as it attempts to contract the\ndiscriminator outputs of real data. To address this issue, we propose a\nrepulsive loss function to actively learn the difference among the real data by\nsimply rearranging the terms in MMD. Second, inspired by the hinge loss, we\npropose a bounded Gaussian kernel to stabilize the training of MMD-GAN with the\nrepulsive loss function. The proposed methods are applied to the unsupervised\nimage generation tasks on CIFAR-10, STL-10, CelebA, and LSUN bedroom datasets.\nResults show that the repulsive loss function significantly improves over the\nMMD loss at no additional computational cost and outperforms other\nrepresentative loss functions. The proposed methods achieve an FID score of\n16.21 on the CIFAR-10 dataset using a single DCGAN network and spectral\nnormalization.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 13:23:18 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 03:06:33 GMT"}, {"version": "v3", "created": "Wed, 16 Jan 2019 11:04:01 GMT"}, {"version": "v4", "created": "Fri, 8 Feb 2019 06:28:35 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Wang", "Wei", ""], ["Sun", "Yuan", ""], ["Halgamuge", "Saman", ""]]}, {"id": "1812.09926", "submitter": "Sirui Xie", "authors": "Sirui Xie, Hehui Zheng, Chunxiao Liu, Liang Lin", "title": "SNAS: Stochastic Neural Architecture Search", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Stochastic Neural Architecture Search (SNAS), an economical\nend-to-end solution to Neural Architecture Search (NAS) that trains neural\noperation parameters and architecture distribution parameters in same round of\nback-propagation, while maintaining the completeness and differentiability of\nthe NAS pipeline. In this work, NAS is reformulated as an optimization problem\non parameters of a joint distribution for the search space in a cell. To\nleverage the gradient information in generic differentiable loss for\narchitecture search, a novel search gradient is proposed. We prove that this\nsearch gradient optimizes the same objective as reinforcement-learning-based\nNAS, but assigns credits to structural decisions more efficiently. This credit\nassignment is further augmented with locally decomposable reward to enforce a\nresource-efficient constraint. In experiments on CIFAR-10, SNAS takes less\nepochs to find a cell architecture with state-of-the-art accuracy than\nnon-differentiable evolution-based and reinforcement-learning-based NAS, which\nis also transferable to ImageNet. It is also shown that child networks of SNAS\ncan maintain the validation accuracy in searching, with which attention-based\nNAS requires parameter retraining to compete, exhibiting potentials to stride\ntowards efficient NAS on big datasets. We have released our implementation at\nhttps://github.com/SNAS-Series/SNAS-Series.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 14:13:16 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 17:19:01 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 00:44:35 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Xie", "Sirui", ""], ["Zheng", "Hehui", ""], ["Liu", "Chunxiao", ""], ["Lin", "Liang", ""]]}, {"id": "1812.09954", "submitter": "Arvind Krishna Sridhar", "authors": "Anees Kazi (1), S.Arvind krishna (2), Shayan Shekarforoush (3),\n  Karsten Kortuem (4), Shadi Albarqouni (1), Nassir Navab (1 and 5) ((1)\n  Computer Aided Medical Procedures, Technische Universit Munchen, Germany, (2)\n  National Institute of Technology Tiruchirappalli, India, (3) Sharif\n  University of Technology, Iran, (4) Augenklinik der Universitat, Klinikum der\n  Universitat Munchen, Germany, (5) Johns Hopkins University, Baltimore MD,\n  USA)", "title": "Self-Attention Equipped Graph Convolutions for Disease Prediction", "comments": "4 pages, 4 figures, paper accepted in ISBI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal data comprising imaging (MRI, fMRI, PET, etc.) and non-imaging\n(clinical test, demographics, etc.) data can be collected together and used for\ndisease prediction. Such diverse data gives complementary information about the\npatient\\'s condition to make an informed diagnosis. A model capable of\nleveraging the individuality of each multi-modal data is required for better\ndisease prediction. We propose a graph convolution based deep model which takes\ninto account the distinctiveness of each element of the multi-modal data. We\nincorporate a novel self-attention layer, which weights every element of the\ndemographic data by exploring its relation to the underlying disease. We\ndemonstrate the superiority of our developed technique in terms of\ncomputational speed and performance when compared to state-of-the-art methods.\nOur method outperforms other methods with a significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 16:56:37 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Kazi", "Anees", "", "1 and 5"], ["krishna", "S. Arvind", "", "1 and 5"], ["Shekarforoush", "Shayan", "", "1 and 5"], ["Kortuem", "Karsten", "", "1 and 5"], ["Albarqouni", "Shadi", "", "1 and 5"], ["Navab", "Nassir", "", "1 and 5"]]}, {"id": "1812.09975", "submitter": "Michael Przystupa", "authors": "Fabian Ruffy, Michael Przystupa, Ivan Beschastnikh", "title": "Iroko: A Framework to Prototype Reinforcement Learning for Data Center\n  Traffic Control", "comments": "5 figures, 1 Table, 11 pages, Accepted to\n  http://mlforsystems.org/accepted_papers.html (ML for Systems) workshop", "journal-ref": "Proceedings of the Workshop on ML for Systems at NeurIPS, 2018", "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent networking research has identified that data-driven congestion control\n(CC) can be more efficient than traditional CC in TCP. Deep reinforcement\nlearning (RL), in particular, has the potential to learn optimal network\npolicies. However, RL suffers from instability and over-fitting, deficiencies\nwhich so far render it unacceptable for use in datacenter networks. In this\npaper, we analyze the requirements for RL to succeed in the datacenter context.\nWe present a new emulator, Iroko, which we developed to support different\nnetwork topologies, congestion control algorithms, and deployment scenarios.\nIroko interfaces with the OpenAI gym toolkit, which allows for fast and fair\nevaluation of different RL and traditional CC algorithms under the same\nconditions. We present initial benchmarks on three deep RL algorithms compared\nto TCP New Vegas and DCTCP. Our results show that these algorithms are able to\nlearn a CC policy which exceeds the performance of TCP New Vegas on a dumbbell\nand fat-tree topology. We make our emulator open-source and publicly available:\nhttps://github.com/dcgym/iroko\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 19:48:42 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Ruffy", "Fabian", ""], ["Przystupa", "Michael", ""], ["Beschastnikh", "Ivan", ""]]}, {"id": "1812.10004", "submitter": "Samet Oymak", "authors": "Samet Oymak and Mahdi Soltanolkotabi", "title": "Overparameterized Nonlinear Learning: Gradient Descent Takes the\n  Shortest Path?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern learning tasks involve fitting nonlinear models to data which are\ntrained in an overparameterized regime where the parameters of the model exceed\nthe size of the training dataset. Due to this overparameterization, the\ntraining loss may have infinitely many global minima and it is critical to\nunderstand the properties of the solutions found by first-order optimization\nschemes such as (stochastic) gradient descent starting from different\ninitializations. In this paper we demonstrate that when the loss has certain\nproperties over a minimally small neighborhood of the initial point, first\norder methods such as (stochastic) gradient descent have a few intriguing\nproperties: (1) the iterates converge at a geometric rate to a global optima\neven when the loss is nonconvex, (2) among all global optima of the loss the\niterates converge to one with a near minimal distance to the initial point, (3)\nthe iterates take a near direct route from the initial point to this global\noptima. As part of our proof technique, we introduce a new potential function\nwhich captures the precise tradeoff between the loss function and the distance\nto the initial point as the iterations progress. For Stochastic Gradient\nDescent (SGD), we develop novel martingale techniques that guarantee SGD never\nleaves a small neighborhood of the initialization, even with rather large\nlearning rates. We demonstrate the utility of our general theory for a variety\nof problem domains spanning low-rank matrix recovery to neural network\ntraining. Underlying our analysis are novel insights that may have implications\nfor training and generalization of more sophisticated learning problems\nincluding those involving deep neural network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 01:10:28 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Oymak", "Samet", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1812.10012", "submitter": "Chenping Hou", "authors": "Hong Tao and Chenping Hou and Dongyun Yi and Jubo Zhu and Dewen Hu", "title": "Joint Embedding Learning and Low-Rank Approximation: A Framework for\n  Incomplete Multi-view Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2019.2953564", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications, not all instances in multi-view data are fully\nrepresented. To deal with incomplete data, Incomplete Multi-view Learning (IML)\nrises. In this paper, we propose the Joint Embedding Learning and Low-Rank\nApproximation (JELLA) framework for IML. The JELLA framework approximates the\nincomplete data by a set of low-rank matrices and learns a full and common\nembedding by linear transformation. Several existing IML methods can be unified\nas special cases of the framework. More interestingly, some linear\ntransformation based complete multi-view methods can be adapted to IML directly\nwith the guidance of the framework. Thus, the JELLA framework improves the\nefficiency of processing incomplete multi-view data, and bridges the gap\nbetween complete multi-view learning and IML. Moreover, the JELLA framework can\nprovide guidance for developing new algorithms. For illustration, within the\nframework, we propose the Incomplete Multi-view Learning with Block Diagonal\nRepresentation (IML-BDR) method. Assuming that the sampled examples have\napproximate linear subspace structure, IML-BDR uses the block diagonal\nstructure prior to learn the full embedding, which would lead to more correct\nclustering. A convergent alternating iterative algorithm with the Successive\nOver-Relaxation optimization technique is devised for optimization.\nExperimental results on various datasets demonstrate the effectiveness of\nIML-BDR.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 02:07:57 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 07:44:12 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Tao", "Hong", ""], ["Hou", "Chenping", ""], ["Yi", "Dongyun", ""], ["Zhu", "Jubo", ""], ["Hu", "Dewen", ""]]}, {"id": "1812.10048", "submitter": "Tiehang Duan", "authors": "Tiehang Duan, Jos\\'e P. Pinto, Xiaohui Xie", "title": "Parallel Clustering of Single Cell Transcriptomic Data with Split-Merge\n  Sampling on Dirichlet Process Mixtures", "comments": "Accepted for Bioinformatics Oxford", "journal-ref": null, "doi": "10.1093/bioinformatics/bty702", "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: With the development of droplet based systems, massive single\ncell transcriptome data has become available, which enables analysis of\ncellular and molecular processes at single cell resolution and is instrumental\nto understanding many biological processes. While state-of-the-art clustering\nmethods have been applied to the data, they face challenges in the following\naspects: (1) the clustering quality still needs to be improved; (2) most models\nneed prior knowledge on number of clusters, which is not always available; (3)\nthere is a demand for faster computational speed. Results: We propose to tackle\nthese challenges with Parallel Split Merge Sampling on Dirichlet Process\nMixture Model (the Para-DPMM model). Unlike classic DPMM methods that perform\nsampling on each single data point, the split merge mechanism samples on the\ncluster level, which significantly improves convergence and optimality of the\nresult. The model is highly parallelized and can utilize the computing power of\nhigh performance computing (HPC) clusters, enabling massive clustering on huge\ndatasets. Experiment results show the model outperforms current widely used\nmodels in both clustering quality and computational speed. Availability: Source\ncode is publicly available on\nhttps://github.com/tiehangd/Para_DPMM/tree/master/Para_DPMM_package\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 06:14:25 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Duan", "Tiehang", ""], ["Pinto", "Jos\u00e9 P.", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1812.10049", "submitter": "Mehdi Jafarnia-Jahromi", "authors": "Mehdi Jafarnia-Jahromi, Tasmin Chowdhury, Hsin-Tai Wu, Sayandev\n  Mukherjee", "title": "PPD: Permutation Phase Defense Against Adversarial Examples in Deep\n  Learning", "comments": "Code is added. Small revisions made", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have demonstrated cutting edge performance on various\ntasks including classification. However, it is well known that adversarially\ndesigned imperceptible perturbation of the input can mislead advanced\nclassifiers. In this paper, Permutation Phase Defense (PPD), is proposed as a\nnovel method to resist adversarial attacks. PPD combines random permutation of\nthe image with phase component of its Fourier transform. The basic idea behind\nthis approach is to turn adversarial defense problems analogously into\nsymmetric cryptography, which relies solely on safekeeping of the keys for\nsecurity. In PPD, safe keeping of the selected permutation ensures\neffectiveness against adversarial attacks. Testing PPD on MNIST and CIFAR-10\ndatasets yielded state-of-the-art robustness against the most powerful\nadversarial attacks currently available.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 06:17:54 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 08:24:04 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Jafarnia-Jahromi", "Mehdi", ""], ["Chowdhury", "Tasmin", ""], ["Wu", "Hsin-Tai", ""], ["Mukherjee", "Sayandev", ""]]}, {"id": "1812.10119", "submitter": "Salah Zaiem", "authors": "Salah Zaiem and Fatiha Sadat", "title": "Sequence to Sequence Learning for Query Expansion", "comments": "8 pages, 2 figures, AAAI-19 Student Abstract and Poster Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using sequence to sequence algorithms for query expansion has not been\nexplored yet in Information Retrieval literature nor in Question-Answering's.\nWe tried to fill this gap in the literature with a custom Query Expansion\nengine trained and tested on open datasets. Starting from open datasets, we\nbuilt a Query Expansion training set using sentence-embeddings-based Keyword\nExtraction. We therefore assessed the ability of the Sequence to Sequence\nneural networks to capture expanding relations in the words embeddings' space.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 15:24:04 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zaiem", "Salah", ""], ["Sadat", "Fatiha", ""]]}, {"id": "1812.10140", "submitter": "Yan Ge", "authors": "Yan Ge, Haiping Lu, Pan Peng", "title": "Mixed-Order Spectral Clustering for Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is fundamental for gaining insights from complex networks, and\nspectral clustering (SC) is a popular approach. Conventional SC focuses on\nsecond-order structures (e.g., edges connecting two nodes) without direct\nconsideration of higher-order structures (e.g., triangles and cliques). This\nhas motivated SC extensions that directly consider higher-order structures.\nHowever, both approaches are limited to considering a single order. This paper\nproposes a new Mixed-Order Spectral Clustering (MOSC) approach to model both\nsecond-order and third-order structures simultaneously, with two MOSC methods\ndeveloped based on Graph Laplacian (GL) and Random Walks (RW). MOSC-GL combines\nedge and triangle adjacency matrices, with theoretical performance guarantee.\nMOSC-RW combines first-order and second-order random walks for a probabilistic\ninterpretation. We automatically determine the mixing parameter based on cut\ncriteria or triangle density, and construct new structure-aware error metrics\nfor performance evaluation. Experiments on real-world networks show 1) the\nsuperior performance of two MOSC methods over existing SC methods, 2) the\neffectiveness of the mixing parameter determination strategy, and 3) insights\noffered by the structure-aware error metrics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 17:23:13 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ge", "Yan", ""], ["Lu", "Haiping", ""], ["Peng", "Pan", ""]]}, {"id": "1812.10156", "submitter": "Giacomo De Palma", "authors": "Giacomo De Palma, Bobak Toussi Kiani and Seth Lloyd", "title": "Random deep neural networks are biased towards simple functions", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32, 1962-1974\n  (2019)", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math-ph math.MP quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the binary classifiers of bit strings generated by random wide\ndeep neural networks with ReLU activation function are biased towards simple\nfunctions. The simplicity is captured by the following two properties. For any\ngiven input bit string, the average Hamming distance of the closest input bit\nstring with a different classification is at least sqrt(n / (2{\\pi} log n)),\nwhere n is the length of the string. Moreover, if the bits of the initial\nstring are flipped randomly, the average number of flips required to change the\nclassification grows linearly with n. These results are confirmed by numerical\nexperiments on deep neural networks with two hidden layers, and settle the\nconjecture stating that random deep neural networks are biased towards simple\nfunctions. This conjecture was proposed and numerically explored in [Valle\nP\\'erez et al., ICLR 2019] to explain the unreasonably good generalization\nproperties of deep learning algorithms. The probability distribution of the\nfunctions generated by random deep neural networks is a good choice for the\nprior probability distribution in the PAC-Bayesian generalization bounds. Our\nresults constitute a fundamental step forward in the characterization of this\ndistribution, therefore contributing to the understanding of the generalization\nproperties of deep learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 19:11:25 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 18:51:02 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["De Palma", "Giacomo", ""], ["Kiani", "Bobak Toussi", ""], ["Lloyd", "Seth", ""]]}, {"id": "1812.10158", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy, Ethem Alpayd{\\i}n", "title": "Dropout Regularization in Hierarchical Mixture of Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a very effective method in preventing overfitting and has become\nthe go-to regularizer for multi-layer neural networks in recent years.\nHierarchical mixture of experts is a hierarchically gated model that defines a\nsoft decision tree where leaves correspond to experts and decision nodes\ncorrespond to gating models that softly choose between its children, and as\nsuch, the model defines a soft hierarchical partitioning of the input space. In\nthis work, we propose a variant of dropout for hierarchical mixture of experts\nthat is faithful to the tree hierarchy defined by the model, as opposed to\nhaving a flat, unitwise independent application of dropout as one has with\nmulti-layer perceptrons. We show that on a synthetic regression data and on\nMNIST and CIFAR-10 datasets, our proposed dropout mechanism prevents\noverfitting on trees with many levels improving generalization and providing\nsmoother fits.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 19:19:39 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["\u0130rsoy", "Ozan", ""], ["Alpayd\u0131n", "Ethem", ""]]}, {"id": "1812.10183", "submitter": "Konul Mustafayeva", "authors": "Babak Mahdavi-Damghani, Konul Mustafayeva, Stephen Roberts, Cristin\n  Buescu", "title": "Portfolio Optimization for Cointelated Pairs: SDEs vs. Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent rise of Machine Learning as a candidate to partially replace\nclassic Financial Mathematics methodologies, we investigate the performances of\nboth in solving the problem of dynamic portfolio optimization in\ncontinuous-time, finite-horizon setting for a portfolio of two assets that are\nintertwined.\n  In Financial Mathematics approach we model the asset prices not via the\ncommon approaches used in pairs trading such as a high correlation or\ncointegration, but with the cointelation model that aims to reconcile both\nshort-term risk and long-term equilibrium. We maximize the overall P&L with\nFinancial Mathematics approach that dynamically switches between a\nmean-variance optimal strategy and a power utility maximizing strategy. We use\na stochastic control formulation of the problem of power utility maximization\nand solve numerically the resulting HJB equation with the Deep Galerkin method.\n  We turn to Machine Learning for the same P&L maximization problem and use\nclustering analysis to devise bands, combined with in-band optimization.\nAlthough this approach is model agnostic, results obtained with data simulated\nfrom the same cointelation model as FM give an edge to ML.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 00:17:58 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 18:58:53 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mahdavi-Damghani", "Babak", ""], ["Mustafayeva", "Konul", ""], ["Roberts", "Stephen", ""], ["Buescu", "Cristin", ""]]}, {"id": "1812.10186", "submitter": "Yawei Zhao", "authors": "Yawei Zhao, En Zhu, Xinwang Liu, and Jianping Yin", "title": "Dynamic Online Gradient Descent with Improved Query Complexity: A\n  Theoretical Revisit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new theoretical analysis framework to investigate online\ngradient descent in the dynamic environment. Comparing with the previous work,\nthe new framework recovers the state-of-the-art dynamic regret, but does not\nrequire extra gradient queries for every iteration. Specifically, when\nfunctions are $\\alpha$ strongly convex and $\\beta$ smooth, to achieve the\nstate-of-the-art dynamic regret, the previous work requires $O(\\kappa)$ with\n$\\kappa = \\frac{\\beta}{\\alpha}$ queries of gradients at every iteration. But,\nour framework shows that the query complexity can be improved to be $O(1)$,\nwhich does not depend on $\\kappa$. The improvement is significant for\nill-conditioned problems because that their objective function usually has a\nlarge $\\kappa$.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 00:28:27 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 01:38:40 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2019 22:03:16 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Zhao", "Yawei", ""], ["Zhu", "En", ""], ["Liu", "Xinwang", ""], ["Yin", "Jianping", ""]]}, {"id": "1812.10193", "submitter": "Aria Rezaei", "authors": "Aria Rezaei, Chaowei Xiao, Jie Gao, Bo Li, Sirajum Munir", "title": "Application-driven Privacy-preserving Data Publishing with Correlated\n  Attributes", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in computing have allowed for the possibility to collect\nlarge amounts of data on personal activities and private living spaces. To\naddress the privacy concerns of users in this environment, we propose a novel\nframework called PR-GAN that offers privacy-preserving mechanism using\ngenerative adversarial networks. Given a target application, PR-GAN\nautomatically modifies the data to hide sensitive attributes -- which may be\nhidden and can be inferred by machine learning algorithms -- while preserving\nthe data utility in the target application. Unlike prior works, the public's\npossible knowledge of the correlation between the target application and\nsensitive attributes is built into our modeling. We formulate our problem as an\noptimization problem, show that an optimal solution exists and use generative\nadversarial networks (GAN) to create perturbations. We further show that our\nmethod provides privacy guarantees under the Pufferfish framework, an elegant\ngeneralization of the differential privacy that allows for the modeling of\nprior knowledge on data and correlations. Through experiments, we show that our\nmethod outperforms conventional methods in effectively hiding the sensitive\nattributes while guaranteeing high performance in the target application, for\nboth property inference and training purposes. Finally, we demonstrate through\nfurther experiments that once our model learns a privacy-preserving task, such\nas hiding subjects' identity, on a group of individuals, it can perform the\nsame task on a separate group with minimal performance drops.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 01:01:16 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 02:43:15 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Rezaei", "Aria", ""], ["Xiao", "Chaowei", ""], ["Gao", "Jie", ""], ["Li", "Bo", ""], ["Munir", "Sirajum", ""]]}, {"id": "1812.10234", "submitter": "Yu Wang", "authors": "Yu Wang, Abhishek Patel, Hongxia Jin", "title": "A New Concept of Deep Reinforcement Learning based Augmented General\n  Sequence Tagging System", "comments": "Published at 2018 COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new deep reinforcement learning based augmented general\nsequence tagging system is proposed. The new system contains two parts: a deep\nneural network (DNN) based sequence tagging model and a deep reinforcement\nlearning (DRL) based augmented tagger. The augmented tagger helps improve\nsystem performance by modeling the data with minority tags. The new system is\nevaluated on SLU and NLU sequence tagging tasks using ATIS and CoNLL-2003\nbenchmark datasets, to demonstrate the new system's outstanding performance on\ngeneral tagging tasks. Evaluated by F1 scores, it shows that the new system\noutperforms the current state-of-the-art model on ATIS dataset by 1.9% and that\non CoNLL-2003 dataset by 1.4%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 05:54:34 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Wang", "Yu", ""], ["Patel", "Abhishek", ""], ["Jin", "Hongxia", ""]]}, {"id": "1812.10244", "submitter": "Yibo Lin", "authors": "Yibo Lin, Zhao Song, Lin F. Yang", "title": "Towards a Theoretical Understanding of Hashing-Based Neural Nets", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parameter reduction has been an important topic in deep learning due to the\never-increasing size of deep neural network models and the need to train and\nrun them on resource limited machines. Despite many efforts in this area, there\nwere no rigorous theoretical guarantees on why existing neural net compression\nmethods should work. In this paper, we provide provable guarantees on some\nhashing-based parameter reduction methods in neural nets. First, we introduce a\nneural net compression scheme based on random linear sketching (which is\nusually implemented efficiently via hashing), and show that the sketched\n(smaller) network is able to approximate the original network on all input data\ncoming from any smooth and well-conditioned low-dimensional manifold. The\nsketched network can also be trained directly via back-propagation. Next, we\nstudy the previously proposed HashedNets architecture and show that the\noptimization landscape of one-hidden-layer HashedNets has a local strong\nconvexity property similar to a normal fully connected neural network. We\ncomplement our theoretical results with empirical verifications.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 06:45:12 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:50:51 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Lin", "Yibo", ""], ["Song", "Zhao", ""], ["Yang", "Lin F.", ""]]}, {"id": "1812.10252", "submitter": "Yagna Patel", "authors": "Yagna Patel", "title": "Optimizing Market Making using Multi-Agent Reinforcement Learning", "comments": "10 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, reinforcement learning is applied to the problem of optimizing\nmarket making. A multi-agent reinforcement learning framework is used to\noptimally place limit orders that lead to successful trades. The framework\nconsists of two agents. The macro-agent optimizes on making the decision to\nbuy, sell, or hold an asset. The micro-agent optimizes on placing limit orders\nwithin the limit order book. For the context of this paper, the proposed\nframework is applied and studied on the Bitcoin cryptocurrency market. The goal\nof this paper is to show that reinforcement learning is a viable strategy that\ncan be applied to complex problems (with complex environments) such as market\nmaking.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 07:29:10 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Patel", "Yagna", ""]]}, {"id": "1812.10260", "submitter": "Kong Aik Lee", "authors": "Kong Aik Lee, Qiongqiong Wang, Takafumi Koshinaka", "title": "The CORAL+ Algorithm for Unsupervised Domain Adaptation of PLDA", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art speaker recognition systems comprise an x-vector (or\ni-vector) speaker embedding front-end followed by a probabilistic linear\ndiscriminant analysis (PLDA) backend. The effectiveness of these components\nrelies on the availability of a large collection of labeled training data. In\npractice, it is common that the domains (e.g., language, demographic) in which\nthe system are deployed differs from that we trained the system. To close the\ngap due to the domain mismatch, we propose an unsupervised PLDA adaptation\nalgorithm to learn from a small amount of unlabeled in-domain data. The\nproposed method was inspired by a prior work on feature-based domain adaptation\ntechnique known as the correlation alignment (CORAL). We refer to the\nmodel-based adaptation technique proposed in this paper as CORAL+. The efficacy\nof the proposed technique is experimentally validated on the recent NIST 2016\nand 2018 Speaker Recognition Evaluation (SRE'16, SRE'18) datasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 08:38:57 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 01:59:11 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lee", "Kong Aik", ""], ["Wang", "Qiongqiong", ""], ["Koshinaka", "Takafumi", ""]]}, {"id": "1812.10360", "submitter": "Abdelmonim Naway", "authors": "Abdelmonim Naway, Yuancheng LI", "title": "A Review on The Use of Deep Learning in Android Malware Detection", "comments": "15 pages, 4 tables", "journal-ref": "International Journal of Computer Science and Mobile Computing,\n  Vol.7 Issue.12, December- 2018, pg. 42-58", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Android is the predominant mobile operating system for the past few years.\nThe prevalence of devices that can be powered by Android magnetized not merely\napplication developers but also malware developers with criminal intention to\ndesign and spread malicious applications that can affect the normal work of\nAndroid phones and tablets, steal personal information and credential data, or\neven worse lock the phone and ask for ransom. Researchers persistently devise\ncountermeasures strategies to fight back malware. One of these strategies\napplied in the past five years is the use of deep learning methods in Android\nmalware detection. This necessitates a review to inspect the accomplished work\nin order to know where the endeavors have been established, identify unresolved\nproblems, and motivate future research directions. In this work, an extensive\nsurvey of static analysis, dynamic analysis, and hybrid analysis that utilized\ndeep learning methods are reviewed with an elaborated discussion on their key\nconcepts, contributions, and limitations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 16:18:51 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Naway", "Abdelmonim", ""], ["LI", "Yuancheng", ""]]}, {"id": "1812.10366", "submitter": "Yinhao Zhu", "authors": "Yide Zhang, Yinhao Zhu, Evan Nichols, Qingfei Wang, Siyuan Zhang, Cody\n  Smith, Scott Howard", "title": "A Poisson-Gaussian Denoising Dataset with Real Fluorescence Microscopy\n  Images", "comments": "Camera-ready version for CVPR 2019. The Fluorescence Microscopy\n  Denoising (FMD) dataset is available at\n  https://drive.google.com/drive/folders/1aygMzSDdoq63IqSk-ly8cMq0_owup8UM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluorescence microscopy has enabled a dramatic development in modern biology.\nDue to its inherently weak signal, fluorescence microscopy is not only much\nnoisier than photography, but also presented with Poisson-Gaussian noise where\nPoisson noise, or shot noise, is the dominating noise source. To get clean\nfluorescence microscopy images, it is highly desirable to have effective\ndenoising algorithms and datasets that are specifically designed to denoise\nfluorescence microscopy images. While such algorithms exist, no such datasets\nare available. In this paper, we fill this gap by constructing a dataset - the\nFluorescence Microscopy Denoising (FMD) dataset - that is dedicated to\nPoisson-Gaussian denoising. The dataset consists of 12,000 real fluorescence\nmicroscopy images obtained with commercial confocal, two-photon, and wide-field\nmicroscopes and representative biological samples such as cells, zebrafish, and\nmouse brain tissues. We use image averaging to effectively obtain ground truth\nimages and 60,000 noisy images with different noise levels. We use this dataset\nto benchmark 10 representative denoising algorithms and find that deep learning\nmethods have the best performance. To our knowledge, this is the first real\nmicroscopy image dataset for Poisson-Gaussian denoising purposes and it could\nbe an important tool for high-quality, real-time denoising applications in\nbiomedical research.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 16:42:02 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 22:26:25 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhang", "Yide", ""], ["Zhu", "Yinhao", ""], ["Nichols", "Evan", ""], ["Wang", "Qingfei", ""], ["Zhang", "Siyuan", ""], ["Smith", "Cody", ""], ["Howard", "Scott", ""]]}, {"id": "1812.10381", "submitter": "Avishek Choudhury", "authors": "Ehsan Khan, Avishek Choudhury, Amy L Friedman, Daehan Won", "title": "Decision Support System for Renal Transplantation", "comments": null, "journal-ref": "In: Proceedings of the 2018 IISE Annual Conference: 2018; Orlando:\n  IISE; 2018: 431-436", "doi": "10.13140/RG.2.2.18890.00965", "report-no": null, "categories": "cs.CY cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The burgeoning need for kidney transplantation mandates immediate attention.\nMismatch of deceased donor-recipient kidney leads to post-transplant death. To\nensure ideal kidney donor-recipient match and minimize post-transplant deaths,\nthe paper develops a prediction model that identifies factors that determine\nthe probability of success of renal transplantation, that is, if the kidney\nprocured from the deceased donor can be transplanted or discarded. The paper\nconducts a study enveloping data for 584 imported kidneys collected from 12\ntransplant centers associated with an organ procurement organization located in\nNew York City, NY. The predicting model yielding best performance measures can\nbe beneficial to the healthcare industry. Transplant centers and organ\nprocurement organizations can take advantage of the prediction model to\nefficiently predict the outcome of kidney transplantation. Consequently, it\nwill reduce the mortality rate caused by mismatching of donor-recipient kidney\ntransplantation during the surgery. Keywords\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 07:00:37 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Khan", "Ehsan", ""], ["Choudhury", "Avishek", ""], ["Friedman", "Amy L", ""], ["Won", "Daehan", ""]]}, {"id": "1812.10382", "submitter": "Vinayak Sachidananda", "authors": "Zi Yin, Vin Sachidananda, Balaji Prabhakar", "title": "The Global Anchor Method for Quantifying Linguistic Shifts and Domain\n  Adaptation", "comments": "Accepted to NeuRIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is dynamic, constantly evolving and adapting with respect to time,\ndomain or topic. The adaptability of language is an active research area, where\nresearchers discover social, cultural and domain-specific changes in language\nusing distributional tools such as word embeddings. In this paper, we introduce\nthe global anchor method for detecting corpus-level language shifts. We show\nboth theoretically and empirically that the global anchor method is equivalent\nto the alignment method, a widely-used method for comparing word embeddings, in\nterms of detecting corpus-level language shifts. Despite their equivalence in\nterms of detection abilities, we demonstrate that the global anchor method is\nsuperior in terms of applicability as it can compare embeddings of different\ndimensionalities. Furthermore, the global anchor method has implementation and\nparallelization advantages. We show that the global anchor method reveals fine\nstructures in the evolution of language and domain adaptation. When combined\nwith the graph Laplacian technique, the global anchor method recovers the\nevolution trajectory and domain clustering of disparate text corpora.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 02:38:56 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Yin", "Zi", ""], ["Sachidananda", "Vin", ""], ["Prabhakar", "Balaji", ""]]}, {"id": "1812.10383", "submitter": "Avishek Choudhury", "authors": "Avishek Choudhury, Y.M.S Al Wesabi, Daehan Won", "title": "Classification of Cervical Cancer Dataset", "comments": null, "journal-ref": "In: Proceedings of the 2018 IISE Annual Conference. Edited by\n  Barker. K, Berry. D, Rainwater. C. Orlando: IISE; 2018: 1456-1461", "doi": "10.13140/RG.2.2.32311.78245", "report-no": null, "categories": "cs.CY cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cervical cancer is the leading gynecological malignancy worldwide. This paper\npresents diverse classification techniques and shows the advantage of feature\nselection approaches to the best predicting of cervical cancer disease. There\nare thirty-two attributes with eight hundred and fifty-eight samples. Besides,\nthis data suffers from missing values and imbalance data. Therefore,\nover-sampling, under-sampling and embedded over and under sampling have been\nused. Furthermore, dimensionality reduction techniques are required for\nimproving the accuracy of the classifier. Therefore, feature selection methods\nhave been studied as they divided into two distinct categories, filters and\nwrappers. The results show that age, first sexual intercourse, number of\npregnancies, smokes, hormonal contraceptives, and STDs: genital herpes are the\nmain predictive features with high accuracy with 97.5%. Decision Tree\nclassifier is shown to be advantageous in handling classification assignment\nwith excellent performance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 07:05:22 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Choudhury", "Avishek", ""], ["Wesabi", "Y. M. S Al", ""], ["Won", "Daehan", ""]]}, {"id": "1812.10384", "submitter": "Avishek Choudhury", "authors": "Avishek Choudhury", "title": "Identification of Cancer -- Mesothelioma Disease Using Logistic\n  Regression and Association Rule", "comments": null, "journal-ref": "American Journal of Engineering and Applied Sciences 2018,\n  11(4):1310.1319", "doi": "10.3844/ajeassp.2018.1310.1319", "report-no": null, "categories": "cs.CY cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malignant Pleural Mesothelioma (MPM) or malignant mesothelioma (MM) is an\natypical, aggressive tumor that matures into cancer in the pleura, a stratum of\ntissue bordering the lungs. Diagnosis of MPM is difficult and it accounts for\nabout seventy-five percent of all mesothelioma diagnosed yearly in the United\nStates of America. Being a fatal disease, early identification of MPM is\ncrucial for patient survival. Our study implements logistic regression and\ndevelops association rules to identify early stage symptoms of MM. We retrieved\nmedical reports generated by Dicle University and implemented logistic\nregression to measure the model accuracy. We conducted (a) logistic\ncorrelation, (b) Omnibus test and (c) Hosmer and Lemeshow test for model\nevaluation. Moreover, we also developed association rules by confidence, rule\nsupport, lift, condition support and deployability. Categorical logistic\nregression increases the training accuracy from 72.30% to 81.40% with a testing\naccuracy of 63.46%. The study also shows the top 5 symptoms that is mostly\nlikely indicates the presence in MM. This study concludes that using predictive\nmodeling can enhance primary presentation and diagnosis of MM.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 16:20:31 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 03:32:24 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Choudhury", "Avishek", ""]]}, {"id": "1812.10386", "submitter": "Iana Sereda", "authors": "Iana Sereda, Sergey Alekseev, Aleksandra Koneva, Roman Kataev, Grigory\n  Osipov", "title": "ECG Segmentation by Neural Networks: Errors and Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we examined the question of how error correction occurs in an\nensemble of deep convolutional networks, trained for an important applied\nproblem: segmentation of Electrocardiograms(ECG). We also explore the\npossibility of using the information about ensemble errors to evaluate a\nquality of data representation, built by the network. This possibility arises\nfrom the effect of distillation of outliers, which was demonstarted for the\nensemble, described in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 17:08:54 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Sereda", "Iana", ""], ["Alekseev", "Sergey", ""], ["Koneva", "Aleksandra", ""], ["Kataev", "Roman", ""], ["Osipov", "Grigory", ""]]}, {"id": "1812.10387", "submitter": "Pavlos Fafalios", "authors": "Renato Stoffalette Jo\\~ao, Pavlos Fafalios, Stefan Dietze", "title": "Same but Different: Distant Supervision for Predicting and Understanding\n  Entity Linking Difficulty", "comments": "Preprint of paper accepted for publication in the 34th ACM/SIGAPP\n  Symposium On Applied Computing (SAC 2019)", "journal-ref": null, "doi": "10.1145/3297280.3297381", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity Linking (EL) is the task of automatically identifying entity mentions\nin a piece of text and resolving them to a corresponding entity in a reference\nknowledge base like Wikipedia. There is a large number of EL tools available\nfor different types of documents and domains, yet EL remains a challenging task\nwhere the lack of precision on particularly ambiguous mentions often spoils the\nusefulness of automated disambiguation results in real applications. A priori\napproximations of the difficulty to link a particular entity mention can\nfacilitate flagging of critical cases as part of semi-automated EL systems,\nwhile detecting latent factors that affect the EL performance, like\ncorpus-specific features, can provide insights on how to improve a system based\non the special characteristics of the underlying corpus. In this paper, we\nfirst introduce a consensus-based method to generate difficulty labels for\nentity mentions on arbitrary corpora. The difficulty labels are then exploited\nas training data for a supervised classification task able to predict the EL\ndifficulty of entity mentions using a variety of features. Experiments over a\ncorpus of news articles show that EL difficulty can be estimated with high\naccuracy, revealing also latent features that affect EL performance. Finally,\nevaluation results demonstrate the effectiveness of the proposed method to\ninform semi-automated EL pipelines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 12:48:40 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Jo\u00e3o", "Renato Stoffalette", ""], ["Fafalios", "Pavlos", ""], ["Dietze", "Stefan", ""]]}, {"id": "1812.10389", "submitter": "Gilles Stoltz", "authors": "Rapha\\\"el Deswarte (CMAP), V\\'eronique Gervais (IFPEN), Gilles Stoltz\n  (LMO), S\\'ebastien da Veiga", "title": "Sequential model aggregation for production forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production forecasting is a key step to design the future development of a\nreservoir. A classical way to generate such forecasts consists in simulating\nfuture production for numerical models representative of the reservoir.\nHowever, identifying such models can be very challenging as they need to be\nconstrained to all available data. In particular, they should reproduce past\nproduction data, which requires to solve a complex non-linear inverse problem.\nIn this paper, we thus propose to investigate the potential of machine learning\nalgorithms to predict the future production of a reservoir based on past\nproduction data without model calibration. We focus more specifically on robust\nonline aggregation, a deterministic approach that provides a robust framework\nto make forecasts on a regular basis. This method does not rely on any specific\nassumption or need for stochastic modeling. Forecasts are first simulated for a\nset of base reservoir models representing the prior uncertainty, and then\ncombined to predict production at the next time step. The weight associated to\neach forecast is related to its past performance. Three different algorithms\nare considered for weight computations: the exponentially weighted average\nalgorithm, ridge regression and the Lasso regression. They are applied on a\nsynthetic reservoir case study, the Brugge case, for sequential predictions. To\nestimate the potential of development scenarios, production forecasts are\nneeded on long periods of time without intermediary data acquisition. An\nextension of the deterministic aggregation approach is thus proposed in this\npaper to provide such multi-step-ahead forecasts.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 12:56:56 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 12:45:55 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Deswarte", "Rapha\u00ebl", "", "CMAP"], ["Gervais", "V\u00e9ronique", "", "IFPEN"], ["Stoltz", "Gilles", "", "LMO"], ["da Veiga", "S\u00e9bastien", ""]]}, {"id": "1812.10394", "submitter": "Afsaneh Doryab", "authors": "Afsaneh Doryab, Prerna Chikarsel, Xinwen Liu, Anind K. Dey", "title": "Extraction of Behavioral Features from Smartphone and Wearable Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rich set of sensors in smartphones and wearable devices provides the\npossibility to passively collect streams of data in the wild. The raw data\nstreams, however, can rarely be directly used in the modeling pipeline. We\nprovide a generic framework that can process raw data streams and extract\nuseful features related to non-verbal human behavior. This framework can be\nused by researchers in the field who are interested in processing data from\nsmartphones and Wearable devices.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 18:45:33 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 01:46:42 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Doryab", "Afsaneh", ""], ["Chikarsel", "Prerna", ""], ["Liu", "Xinwen", ""], ["Dey", "Anind K.", ""]]}, {"id": "1812.10398", "submitter": "William Herlands", "authors": "Maria De-Arteaga, Amanda Coston, William Herlands", "title": "Proceedings of NeurIPS 2018 Workshop on Machine Learning for the\n  Developing World: Achieving Sustainable Impact", "comments": "18 papers in the proceedings. 10 additional papers were presented at\n  the workshop but not included in the proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of NeurIPS 2018 Workshop on Machine Learning for the\nDeveloping World: Achieving Sustainable Impact, held in Montreal, Canada on\nDecember 8, 2018\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 03:29:09 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 22:25:48 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["De-Arteaga", "Maria", ""], ["Coston", "Amanda", ""], ["Herlands", "William", ""]]}, {"id": "1812.10400", "submitter": "Bertie Vidgen", "authors": "Bertie Vidgen, Taha Yasseri", "title": "Detecting weak and strong Islamophobic hate speech on social media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Islamophobic hate speech on social media inflicts considerable harm on both\ntargeted individuals and wider society, and also risks reputational damage for\nthe host platforms. Accordingly, there is a pressing need for robust tools to\ndetect and classify Islamophobic hate speech at scale. Previous research has\nlargely approached the detection of Islamophobic hate speech on social media as\na binary task. However, the varied nature of Islamophobia means that this is\noften inappropriate for both theoretically-informed social science and\neffectively monitoring social media. Drawing on in-depth conceptual work we\nbuild a multi-class classifier which distinguishes between non-Islamophobic,\nweak Islamophobic and strong Islamophobic content. Accuracy is 77.6% and\nbalanced accuracy is 83%. We apply the classifier to a dataset of 109,488\ntweets produced by far right Twitter accounts during 2017. Whilst most tweets\nare not Islamophobic, weak Islamophobia is considerably more prevalent (36,963\ntweets) than strong (14,895 tweets). Our main input feature is a gloVe word\nembeddings model trained on a newly collected corpus of 140 million tweets. It\noutperforms a generic word embeddings model by 5.9 percentage points,\ndemonstrating the importan4ce of context. Unexpectedly, we also find that a\none-against-one multi class SVM outperforms a deep learning algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 10:34:21 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Vidgen", "Bertie", ""], ["Yasseri", "Taha", ""]]}, {"id": "1812.10401", "submitter": "Denis Sedov", "authors": "Denis Sedov, Zhirong Yang", "title": "Word Embedding based on Low-Rank Doubly Stochastic Matrix Decomposition", "comments": null, "journal-ref": "Cheng, L., Leung, A., Ozawa, S. (eds.) ICONIP 2018. LNCS, vol.\n  11303, pp. 90-100. Springer, Cham (2018)", "doi": "10.1007/978-3-030-04182-3_9", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding, which encodes words into vectors, is an important starting\npoint in natural language processing and commonly used in many text-based\nmachine learning tasks. However, in most current word embedding approaches, the\nsimilarity in embedding space is not optimized in the learning. In this paper\nwe propose a novel neighbor embedding method which directly learns an embedding\nsimplex where the similarities between the mapped words are optimal in terms of\nminimal discrepancy to the input neighborhoods. Our method is built upon\ntwo-step random walks between words via topics and thus able to better reveal\nthe topics among the words. Experiment results indicate that our method,\ncompared with another existing word embedding approach, is more favorable for\nvarious queries.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 15:38:46 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Sedov", "Denis", ""], ["Yang", "Zhirong", ""]]}, {"id": "1812.10404", "submitter": "Sebastian Vollmer", "authors": "Sebastian Vollmer, Bilal A. Mateen, Gergo Bohner, Franz J Kir\\'aly,\n  Rayid Ghani, Pall Jonsson, Sarah Cumbers, Adrian Jonas, Katherine S.L.\n  McAllister, Puja Myles, David Granger, Mark Birse, Richard Branson, Karel GM\n  Moons, Gary S Collins, John P.A. Ioannidis, Chris Holmes, Harry Hemingway", "title": "Machine learning and AI research for Patient Benefit: 20 Critical\n  Questions on Transparency, Replicability, Ethics and Effectiveness", "comments": "25 pages, 2 boxes, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML), artificial intelligence (AI) and other modern\nstatistical methods are providing new opportunities to operationalize\npreviously untapped and rapidly growing sources of data for patient benefit.\nWhilst there is a lot of promising research currently being undertaken, the\nliterature as a whole lacks: transparency; clear reporting to facilitate\nreplicability; exploration for potential ethical concerns; and, clear\ndemonstrations of effectiveness. There are many reasons for why these issues\nexist, but one of the most important that we provide a preliminary solution for\nhere is the current lack of ML/AI- specific best practice guidance. Although\nthere is no consensus on what best practice looks in this field, we believe\nthat interdisciplinary groups pursuing research and impact projects in the\nML/AI for health domain would benefit from answering a series of questions\nbased on the important issues that exist when undertaking work of this nature.\nHere we present 20 questions that span the entire project life cycle, from\ninception, data analysis, and model evaluation, to implementation, as a means\nto facilitate project planning and post-hoc (structured) independent\nevaluation. By beginning to answer these questions in different settings, we\ncan start to understand what constitutes a good answer, and we expect that the\nresulting discussion will be central to developing an international consensus\nframework for transparent, replicable, ethical and effective research in\nartificial intelligence (AI-TREE) for health.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 18:11:20 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Vollmer", "Sebastian", ""], ["Mateen", "Bilal A.", ""], ["Bohner", "Gergo", ""], ["Kir\u00e1ly", "Franz J", ""], ["Ghani", "Rayid", ""], ["Jonsson", "Pall", ""], ["Cumbers", "Sarah", ""], ["Jonas", "Adrian", ""], ["McAllister", "Katherine S. L.", ""], ["Myles", "Puja", ""], ["Granger", "David", ""], ["Birse", "Mark", ""], ["Branson", "Richard", ""], ["Moons", "Karel GM", ""], ["Collins", "Gary S", ""], ["Ioannidis", "John P. A.", ""], ["Holmes", "Chris", ""], ["Hemingway", "Harry", ""]]}, {"id": "1812.10413", "submitter": "Nazmus Saquib", "authors": "Halima Akhter, Nazmus Saquib, Deeni Fatiha", "title": "Studying oppressive cityscapes of Bangladesh", "comments": "Presented at NeurIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a densely populated city like Dhaka (Bangladesh), a growing number of\nhigh-rise buildings is an inevitable reality. However, they pose mental health\nrisks for citizens in terms of detachment from natural light, sky view,\ngreenery, and environmental landscapes. The housing economy and rent structure\nin different areas may or may not take account of such environmental factors.\nIn this paper, we build a computer vision based pipeline to study factors like\nsky visibility, greenery in the sidewalks, and dominant colors present in\nstreets from a pedestrian's perspective. We show that people in lower economy\nclasses may suffer from lower sky visibility, whereas people in higher economy\nclasses may suffer from lack of greenery in their environment, both of which\ncould be possibly addressed by implementing rent restructuring schemes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 05:55:22 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Akhter", "Halima", ""], ["Saquib", "Nazmus", ""], ["Fatiha", "Deeni", ""]]}, {"id": "1812.10422", "submitter": "Florian Dumpert", "authors": "Martin Beck, Florian Dumpert, Joerg Feuerhake", "title": "Machine Learning in Official Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the first half of 2018, the Federal Statistical Office of Germany\n(Destatis) carried out a \"Proof of Concept Machine Learning\" as part of its\nDigital Agenda. A major component of this was surveys on the use of machine\nlearning methods in official statistics, which were conducted at selected\nnational and international statistical institutions and among the divisions of\nDestatis. It was of particular interest to find out in which statistical areas\nand for which tasks machine learning is used and which methods are applied.\nThis paper is intended to make the results of the surveys publicly accessible.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 11:02:01 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Beck", "Martin", ""], ["Dumpert", "Florian", ""], ["Feuerhake", "Joerg", ""]]}, {"id": "1812.10424", "submitter": "Navid Rekabsaz", "authors": "Navid Rekabsaz, Robert West, James Henderson, Allan Hanbury", "title": "Measuring Societal Biases from Text Corpora with Smoothed First-Order\n  Co-occurrence", "comments": "In proceedings of the International AAAI Conference on Web and Social\n  Media (ICWSM) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text corpora are widely used resources for measuring societal biases and\nstereotypes. The common approach to measuring such biases using a corpus is by\ncalculating the similarities between the embedding vector of a word (like\nnurse) and the vectors of the representative words of the concepts of interest\n(such as genders). In this study, we show that, depending on what one aims to\nquantify as bias, this commonly-used approach can introduce non-relevant\nconcepts into bias measurement. We propose an alternative approach to bias\nmeasurement utilizing the smoothed first-order co-occurrence relations between\nthe word and the representative concept words, which we derive by\nreconstructing the co-occurrence estimates inherent in word embedding models.\nWe compare these approaches by conducting several experiments on the scenario\nof measuring gender bias of occupational words, according to an English\nWikipedia corpus. Our experiments show higher correlations of the measured\ngender bias with the actual gender bias statistics of the U.S. job market - on\ntwo collections and with a variety of word embedding models - using the\nfirst-order approach in comparison with the vector similarity-based approaches.\nThe first-order approach also suggests a more severe bias towards female in a\nfew specific occupations than the other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 21:00:05 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 12:08:55 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 07:18:47 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 14:27:41 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Rekabsaz", "Navid", ""], ["West", "Robert", ""], ["Henderson", "James", ""], ["Hanbury", "Allan", ""]]}, {"id": "1812.10426", "submitter": "Vinod Kumar Chauhan", "authors": "Vinod Kumar Chauhan and Anuj Sharma and Kalpana Dahiya", "title": "Stochastic Trust Region Inexact Newton Method for Large-scale Machine\n  Learning", "comments": "32 figures, accepted in International Journal of Machine Learning and\n  Cybernetics", "journal-ref": null, "doi": "10.1007/s13042-019-01055-9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays stochastic approximation methods are one of the major research\ndirection to deal with the large-scale machine learning problems. From\nstochastic first order methods, now the focus is shifting to stochastic second\norder methods due to their faster convergence and availability of computing\nresources. In this paper, we have proposed a novel Stochastic Trust RegiOn\nInexact Newton method, called as STRON, to solve large-scale learning problems\nwhich uses conjugate gradient (CG) to inexactly solve trust region subproblem.\nThe method uses progressive subsampling in the calculation of gradient and\nHessian values to take the advantage of both, stochastic and full-batch\nregimes. We have extended STRON using existing variance reduction techniques to\ndeal with the noisy gradients and using preconditioned conjugate gradient (PCG)\nas subproblem solver, and empirically proved that they do not work as expected,\nfor the large-scale learning problems. Finally, our empirical results prove\nefficacy of the proposed method against existing methods with bench marked\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 17:33:43 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 13:17:30 GMT"}, {"version": "v3", "created": "Thu, 26 Dec 2019 12:22:46 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Chauhan", "Vinod Kumar", ""], ["Sharma", "Anuj", ""], ["Dahiya", "Kalpana", ""]]}, {"id": "1812.10430", "submitter": "Samaneh Ebrahimi", "authors": "Samaneh Ebrahimi, Chitta Ranjan, and Kamran Paynabar", "title": "Large Multistream Data Analytics for Monitoring and Diagnostics in\n  Manufacturing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high-dimensionality and volume of large scale multistream data has\ninhibited significant research progress in developing an integrated monitoring\nand diagnostics (M&D) approach. This data, also categorized as big data, is\nbecoming common in manufacturing plants. In this paper, we propose an\nintegrated M\\&D approach for large scale streaming data. We developed a novel\nmonitoring method named Adaptive Principal Component monitoring (APC) which\nadaptively chooses PCs that are most likely to vary due to the change for early\ndetection. Importantly, we integrate a novel diagnostic approach, Principal\nComponent Signal Recovery (PCSR), to enable a streamlined SPC. This diagnostics\napproach draws inspiration from Compressed Sensing and uses Adaptive Lasso for\nidentifying the sparse change in the process. We theoretically motivate our\napproaches and do a performance evaluation of our integrated M&D method through\nsimulations and case studies.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 17:48:10 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ebrahimi", "Samaneh", ""], ["Ranjan", "Chitta", ""], ["Paynabar", "Kamran", ""]]}, {"id": "1812.10437", "submitter": "Mostafa Tavassolipour", "authors": "Mostafa Tavassolipour, Armin Karamzade, Reza Mirzaeifard, Seyed\n  Abolfazl Motahari, and Mohammad-Taghi Manzuri Shalmani", "title": "Structure Learning of Sparse GGMs over Multiple Access Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central machine is interested in estimating the underlying structure of a\nsparse Gaussian Graphical Model (GGM) from datasets distributed across multiple\nlocal machines. The local machines can communicate with the central machine\nthrough a wireless multiple access channel. In this paper, we are interested in\ndesigning effective strategies where reliable learning is feasible under power\nand bandwidth limitations. Two approaches are proposed: Signs and Uncoded\nmethods. In Signs method, the local machines quantize their data into binary\nvectors and an optimal channel coding scheme is used to reliably send the\nvectors to the central machine where the structure is learned from the received\ndata. In Uncoded method, data symbols are scaled and transmitted through the\nchannel. The central machine uses the received noisy symbols to recover the\nstructure. Theoretical results show that both methods can recover the structure\nwith high probability for large enough sample size. Experimental results\nindicate the superiority of Signs method over Uncoded method under several\ncircumstances.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 18:10:40 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Tavassolipour", "Mostafa", ""], ["Karamzade", "Armin", ""], ["Mirzaeifard", "Reza", ""], ["Motahari", "Seyed Abolfazl", ""], ["Shalmani", "Mohammad-Taghi Manzuri", ""]]}, {"id": "1812.10479", "submitter": "Marcelo Sardelich", "authors": "Marcelo Sardelich and Suresh Manandhar", "title": "Multimodal deep learning for short-term stock volatility prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CL cs.LG q-fin.RM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stock market volatility forecasting is a task relevant to assessing market\nrisk. We investigate the interaction between news and prices for the\none-day-ahead volatility prediction using state-of-the-art deep learning\napproaches. The proposed models are trained either end-to-end or using sentence\nencoders transfered from other tasks. We evaluate a broad range of stock market\nsectors, namely Consumer Staples, Energy, Utilities, Heathcare, and Financials.\nOur experimental results show that adding news improves the volatility\nforecasting as compared to the mainstream models that rely only on price data.\nIn particular, our model outperforms the widely-recognized GARCH(1,1) model for\nall sectors in terms of coefficient of determination $R^2$, $MSE$ and $MAE$,\nachieving the best performance when training from both news and price data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 14:35:08 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Sardelich", "Marcelo", ""], ["Manandhar", "Suresh", ""]]}, {"id": "1812.10486", "submitter": "Avishek Choudhury", "authors": "Avishek Choudhury, Sunanda Perumalla", "title": "Forecasting Cardiology Admissions from Catheterization Laboratory", "comments": "In: Proceedings of the 2019 IISE Annual Conference. Edited by\n  Romeijn. HE, Schaefer. A, Thomas. R. Orlando: IISE; 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emergent and unscheduled cardiology admissions from cardiac catheterization\nlaboratory add complexity to the management of Cardiology and in-patient\ndepartment. In this article, we sought to study the behavior of cardiology\nadmissions from Catheterization laboratory using time series models. Our\nresearch involves retrospective cardiology admission data from March 1, 2012,\nto November 3, 2016, retrieved from a hospital in Iowa. Autoregressive\nintegrated moving average (ARIMA), Holts method, mean method, na\\\"ive method,\nseasonal na\\\"ive, exponential smoothing, and drift method were implemented to\nforecast weekly cardiology admissions from Catheterization laboratory. ARIMA\n(2,0,2) (1,1,1) was selected as the best fit model with the minimum sum of\nerror, Akaike information criterion and Schwartz Bayesian criterion. The model\nfailed to reject the null hypothesis of stationarity, it lacked the evidence of\nindependence, and rejected the null hypothesis of normality. The implication of\nthis study will not only improve catheterization laboratory staff schedule,\nadvocate efficient use of imaging equipment and inpatient telemetry beds but\nalso equip management to proactively tackle inpatient overcrowding, plan for\nphysical capacity expansion and so forth.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 17:38:06 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 03:52:03 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Choudhury", "Avishek", ""], ["Perumalla", "Sunanda", ""]]}, {"id": "1812.10519", "submitter": "Jes\\'us Daniel Arroyo Reli\\'on", "authors": "Jes\\'us Arroyo, Daniel L. Sussman, Carey E. Priebe, Vince Lyzinski", "title": "Maximum Likelihood Estimation and Graph Matching in Errorfully Observed\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a pair of graphs with the same number of vertices, the inexact graph\nmatching problem consists in finding a correspondence between the vertices of\nthese graphs that minimizes the total number of induced edge disagreements. We\nstudy this problem from a statistical framework in which one of the graphs is\nan errorfully observed copy of the other. We introduce a corrupting channel\nmodel, and show that in this model framework, the solution to the graph\nmatching problem is a maximum likelihood estimator. Necessary and sufficient\nconditions for consistency of this MLE are presented, as well as a relaxed\nnotion of consistency in which a negligible fraction of the vertices need not\nbe matched correctly. The results are used to study matchability in several\nfamilies of random graphs, including edge independent models, random regular\ngraphs and small-world networks. We also use these results to introduce\nmeasures of matching feasibility, and experimentally validate the results on\nsimulated and real-world networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 20:01:30 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 20:23:08 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 18:45:41 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 20:27:33 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Arroyo", "Jes\u00fas", ""], ["Sussman", "Daniel L.", ""], ["Priebe", "Carey E.", ""], ["Lyzinski", "Vince", ""]]}, {"id": "1812.10538", "submitter": "Elad Plaut", "authors": "Elad Plaut and Raja Giryes", "title": "A Greedy Approach to $\\ell_{0,\\infty}$ Based Convolutional Sparse Coding", "comments": "Accepted for publication in SIAM Journal on Imaging Sciences (SIIMS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding techniques for image processing traditionally rely on a\nprocessing of small overlapping patches separately followed by averaging. This\nhas the disadvantage that the reconstructed image no longer obeys the sparsity\nprior used in the processing. For this purpose convolutional sparse coding has\nbeen introduced, where a shift-invariant dictionary is used and the sparsity of\nthe recovered image is maintained. Most such strategies target the $\\ell_0$\n\"norm\" or the $\\ell_1$ norm of the whole image, which may create an imbalanced\nsparsity across various regions in the image. In order to face this challenge,\nthe $\\ell_{0,\\infty}$ \"norm\" has been proposed as an alternative that \"operates\nlocally while thinking globally\". The approaches taken for tackling the\nnon-convexity of these optimization problems have been either using a convex\nrelaxation or local pursuit algorithms. In this paper, we present an efficient\ngreedy method for sparse coding and dictionary learning, which is specifically\ntailored to $\\ell_{0,\\infty}$, and is based on matching pursuit. We demonstrate\nthe usage of our approach in salt-and-pepper noise removal and image\ninpainting. A code package which reproduces the experiments presented in this\nwork is available at https://web.eng.tau.ac.il/~raja\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 21:05:27 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Plaut", "Elad", ""], ["Giryes", "Raja", ""]]}, {"id": "1812.10539", "submitter": "Aditya Grover", "authors": "Aditya Grover, Stefano Ermon", "title": "Uncertainty Autoencoders: Learning Compressed Representations via\n  Variational Information Maximization", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing techniques enable efficient acquisition and recovery of\nsparse, high-dimensional data signals via low-dimensional projections. In this\nwork, we propose Uncertainty Autoencoders, a learning framework for\nunsupervised representation learning inspired by compressed sensing. We treat\nthe low-dimensional projections as noisy latent representations of an\nautoencoder and directly learn both the acquisition (i.e., encoding) and\namortized recovery (i.e., decoding) procedures. Our learning objective\noptimizes for a tractable variational lower bound to the mutual information\nbetween the datapoints and the latent representations. We show how our\nframework provides a unified treatment to several lines of research in\ndimensionality reduction, compressed sensing, and generative modeling.\nEmpirically, we demonstrate a 32% improvement on average over competing\napproaches for the task of statistical compressed sensing of high-dimensional\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 21:14:06 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 06:45:27 GMT"}, {"version": "v3", "created": "Thu, 11 Apr 2019 22:16:32 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Grover", "Aditya", ""], ["Ermon", "Stefano", ""]]}, {"id": "1812.10549", "submitter": "Marc Johnson", "authors": "Marc Everett Johnson", "title": "Automatic Summarization of Natural Language", "comments": "6 pages, 1 literature synthesis matrix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic summarization of natural language is a current topic in computer\nscience research and industry, studied for decades because of its usefulness\nacross multiple domains. For example, summarization is necessary to create\nreviews such as this one. Research and applications have achieved some success\nin extractive summarization (where key sentences are curated), however,\nabstractive summarization (synthesis and re-stating) is a hard problem and\ngenerally unsolved in computer science. This literature review contrasts\nhistorical progress up through current state of the art, comparing dimensions\nsuch as: extractive vs. abstractive, supervised vs. unsupervised, NLP (Natural\nLanguage Processing) vs Knowledge-based, deep learning vs algorithms,\nstructured vs. unstructured sources, and measurement metrics such as Rouge and\nBLEU. Multiple dimensions are contrasted since current research uses\ncombinations of approaches as seen in the review matrix. Throughout this\nsummary, synthesis and critique is provided. This review concludes with\ninsights for improved abstractive summarization measurement, with surprising\nimplications for detecting understanding and comprehension in general.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 14:17:56 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Johnson", "Marc Everett", ""]]}, {"id": "1812.10551", "submitter": "Shiqing Yu", "authors": "Shiqing Yu, Mathias Drton, Ali Shojaie", "title": "Generalized Score Matching for Non-Negative Data", "comments": "70 pages, 76 figures", "journal-ref": "Journal of Machine Learning Research, 20(76):1-70, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common challenge in estimating parameters of probability density functions\nis the intractability of the normalizing constant. While in such cases maximum\nlikelihood estimation may be implemented using numerical integration, the\napproach becomes computationally intensive. The score matching method of\nHyv\\\"arinen [2005] avoids direct calculation of the normalizing constant and\nyields closed-form estimates for exponential families of continuous\ndistributions over $\\mathbb{R}^m$. Hyv\\\"arinen [2007] extended the approach to\ndistributions supported on the non-negative orthant, $\\mathbb{R}_+^m$. In this\npaper, we give a generalized form of score matching for non-negative data that\nimproves estimation efficiency. As an example, we consider a general class of\npairwise interaction models. Addressing an overlooked inexistence problem, we\ngeneralize the regularized score matching method of Lin et al. [2016] and\nimprove its theoretical guarantees for non-negative Gaussian graphical models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 21:50:40 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 00:28:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Yu", "Shiqing", ""], ["Drton", "Mathias", ""], ["Shojaie", "Ali", ""]]}, {"id": "1812.10564", "submitter": "Yongjoo Park", "authors": "Yongjoo Park, Jingyi Qing, Xiaoyang Shen, Barzan Mozafari", "title": "BlinkML: Efficient Maximum Likelihood Estimation with Probabilistic\n  Guarantees", "comments": "22 pages, SIGMOD 2019", "journal-ref": null, "doi": "10.1145/3299869.3300077", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising volume of datasets has made training machine learning (ML) models\na major computational cost in the enterprise. Given the iterative nature of\nmodel and parameter tuning, many analysts use a small sample of their entire\ndata during their initial stage of analysis to make quick decisions (e.g., what\nfeatures or hyperparameters to use) and use the entire dataset only in later\nstages (i.e., when they have converged to a specific model). This sampling,\nhowever, is performed in an ad-hoc fashion. Most practitioners cannot precisely\ncapture the effect of sampling on the quality of their model, and eventually on\ntheir decision-making process during the tuning phase. Moreover, without\nsystematic support for sampling operators, many optimizations and reuse\nopportunities are lost.\n  In this paper, we introduce BlinkML, a system for fast, quality-guaranteed ML\ntraining. BlinkML allows users to make error-computation tradeoffs: instead of\ntraining a model on their full data (i.e., full model), BlinkML can quickly\ntrain an approximate model with quality guarantees using a sample. The quality\nguarantees ensure that, with high probability, the approximate model makes the\nsame predictions as the full model. BlinkML currently supports any ML model\nthat relies on maximum likelihood estimation (MLE), which includes Generalized\nLinear Models (e.g., linear regression, logistic regression, max entropy\nclassifier, Poisson regression) as well as PPCA (Probabilistic Principal\nComponent Analysis). Our experiments show that BlinkML can speed up the\ntraining of large-scale ML tasks by 6.26x-629x while guaranteeing the same\npredictions, with 95% probability, as the full model.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 22:35:21 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Park", "Yongjoo", ""], ["Qing", "Jingyi", ""], ["Shen", "Xiaoyang", ""], ["Mozafari", "Barzan", ""]]}, {"id": "1812.10576", "submitter": "Chaochao Lu", "authors": "Chaochao Lu, Bernhard Sch\\\"olkopf, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Deconfounding Reinforcement Learning in Observational Settings", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general formulation for addressing reinforcement learning (RL)\nproblems in settings with observational data. That is, we consider the problem\nof learning good policies solely from historical data in which unobserved\nfactors (confounders) affect both observed actions and rewards. Our formulation\nallows us to extend a representative RL algorithm, the Actor-Critic method, to\nits deconfounding variant, with the methodology for this extension being easily\napplied to other RL algorithms. In addition to this, we develop a new benchmark\nfor evaluating deconfounding RL algorithms by modifying the OpenAI Gym\nenvironments and the MNIST dataset. Using this benchmark, we demonstrate that\nthe proposed algorithms are superior to traditional RL methods in confounded\nenvironments with observational data. To the best of our knowledge, this is the\nfirst time that confounders are taken into consideration for addressing full RL\nproblems with observational data. Code is available at\nhttps://github.com/CausalRL/DRL.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 23:48:51 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Lu", "Chaochao", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1812.10587", "submitter": "Jianwen Xie", "authors": "Jianwen Xie, Ruiqi Gao, Zilong Zheng, Song-Chun Zhu, Ying Nian Wu", "title": "Learning Dynamic Generator Model by Alternating Back-Propagation Through\n  Time", "comments": "10 pages", "journal-ref": "The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)\n  2019", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the dynamic generator model for spatial-temporal processes\nsuch as dynamic textures and action sequences in video data. In this model,\neach time frame of the video sequence is generated by a generator model, which\nis a non-linear transformation of a latent state vector, where the non-linear\ntransformation is parametrized by a top-down neural network. The sequence of\nlatent state vectors follows a non-linear auto-regressive model, where the\nstate vector of the next frame is a non-linear transformation of the state\nvector of the current frame as well as an independent noise vector that\nprovides randomness in the transition. The non-linear transformation of this\ntransition model can be parametrized by a feedforward neural network. We show\nthat this model can be learned by an alternating back-propagation through time\nalgorithm that iteratively samples the noise vectors and updates the parameters\nin the transition model and the generator model. We show that our training\nmethod can learn realistic models for dynamic textures and action patterns.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 01:34:08 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Xie", "Jianwen", ""], ["Gao", "Ruiqi", ""], ["Zheng", "Zilong", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1812.10613", "submitter": "Xinshi Chen", "authors": "Xinshi Chen, Shuang Li, Hui Li, Shaohua Jiang, Yuan Qi, Le Song", "title": "Generative Adversarial User Model for Reinforcement Learning Based\n  Recommendation System", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:1052-1061, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are great interests as well as many challenges in applying\nreinforcement learning (RL) to recommendation systems. In this setting, an\nonline user is the environment; neither the reward function nor the environment\ndynamics are clearly defined, making the application of RL challenging. In this\npaper, we propose a novel model-based reinforcement learning framework for\nrecommendation systems, where we develop a generative adversarial network to\nimitate user behavior dynamics and learn her reward function. Using this user\nmodel as the simulation environment, we develop a novel Cascading DQN algorithm\nto obtain a combinatorial recommendation policy which can handle a large number\nof candidate items efficiently. In our experiments with real data, we show this\ngenerative adversarial user model can better explain user behavior than\nalternatives, and the RL policy based on this model can lead to a better\nlong-term reward for the user and higher click rate for the system.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 03:44:07 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 06:42:35 GMT"}, {"version": "v3", "created": "Wed, 1 Jan 2020 03:17:02 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chen", "Xinshi", ""], ["Li", "Shuang", ""], ["Li", "Hui", ""], ["Jiang", "Shaohua", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "1812.10617", "submitter": "Gaurav Nagesh Shetty", "authors": "Gaurav N. Shetty, Konstantinos Slavakis, Abhishek Bose, Ukash Nakarmi,\n  Gesualdo Scutari, Leslie Ying", "title": "Bi-Linear Modeling of Data Manifolds for Dynamic-MRI Recovery", "comments": null, "journal-ref": null, "doi": "10.1109/TMI.2019.2934125", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper puts forth a novel bi-linear modeling framework for data recovery\nvia manifold-learning and sparse-approximation arguments and considers its\napplication to dynamic magnetic-resonance imaging (dMRI). Each temporal-domain\nMR image is viewed as a point that lies onto or close to a smooth manifold, and\nlandmark points are identified to describe the point cloud concisely. To\nfacilitate computations, a dimensionality reduction module generates\nlow-dimensional/compressed renditions of the landmark points. Recovery of the\nhigh-fidelity MRI data is realized by solving a non-convex minimization task\nfor the linear decompression operator and those affine combinations of landmark\npoints which locally approximate the latent manifold geometry. An algorithm\nwith guaranteed convergence to stationary solutions of the non-convex\nminimization task is also provided. The aforementioned framework exploits the\nunderlying spatio-temporal patterns and geometry of the acquired data without\nany prior training on external data or information. Extensive numerical results\non simulated as well as real cardiac-cine and perfusion MRI data illustrate\nnoteworthy improvements of the advocated machine-learning framework over\nstate-of-the-art reconstruction techniques.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 04:02:54 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 22:08:34 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Shetty", "Gaurav N.", ""], ["Slavakis", "Konstantinos", ""], ["Bose", "Abhishek", ""], ["Nakarmi", "Ukash", ""], ["Scutari", "Gesualdo", ""], ["Ying", "Leslie", ""]]}, {"id": "1812.10622", "submitter": "Alex Frid", "authors": "Alex Frid and Larry M. Manevitz", "title": "Features and Machine Learning for Correlating and Classifying between\n  Brain Areas and Dyslexia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method that is based on processing gathered Event Related\nPotentials (ERP) signals and the use of machine learning technique for\nmultivariate analysis (i.e. classification) that we apply in order to analyze\nthe differences between Dyslexic and Skilled readers.\n  No human intervention is needed in the analysis process. This is the state of\nthe art results for automatic identification of Dyslexic readers using a\nLexical Decision Task. We use mathematical and machine learning based\ntechniques to automatically discover novel complex features that (i) allow for\nreliable distinction between Dyslexic and Normal Control Skilled readers and\n(ii) to validate the assumption that the most of the differences between\nDyslexic and Skilled readers located in the left hemisphere.\n  Interestingly, these tools also pointed to the fact that High Pass signals\n(typically considered as \"noise\" during ERP/EEG analyses) in fact contains\nsignificant relevant information. Finally, the proposed scheme can be used for\nanalysis of any ERP based studies.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 04:50:33 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 22:40:16 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Frid", "Alex", ""], ["Manevitz", "Larry M.", ""]]}, {"id": "1812.10624", "submitter": "Xiaorui Wu", "authors": "Xiaorui Wu, Hong Xu, Bo Li, Yongqiang Xiong", "title": "Stanza: Layer Separation for Distributed Training in Deep Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parameter server architecture is prevalently used for distributed deep\nlearning. Each worker machine in a parameter server system trains the complete\nmodel, which leads to a hefty amount of network data transfer between workers\nand servers. We empirically observe that the data transfer has a non-negligible\nimpact on training time.\n  To tackle the problem, we design a new distributed training system called\nStanza. Stanza exploits the fact that in many models such as convolution neural\nnetworks, most data exchange is attributed to the fully connected layers, while\nmost computation is carried out in convolutional layers. Thus, we propose layer\nseparation in distributed training: the majority of the nodes just train the\nconvolutional layers, and the rest train the fully connected layers only.\nGradients and parameters of the fully connected layers no longer need to be\nexchanged across the cluster, thereby substantially reducing the data transfer\nvolume. We implement Stanza on PyTorch and evaluate its performance on Azure\nand EC2. Results show that Stanza accelerates training significantly over\ncurrent parameter server systems: on EC2 instances with Tesla V100 GPU and 10Gb\nbandwidth for example, Stanza is 1.34x--13.9x faster for common deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 05:01:19 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 07:16:22 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Wu", "Xiaorui", ""], ["Xu", "Hong", ""], ["Li", "Bo", ""], ["Xiong", "Yongqiang", ""]]}, {"id": "1812.10637", "submitter": "Deqing Wang", "authors": "Deqing Wang, Fengyu Cong, Tapani Ristaniemi", "title": "Sparse Nonnegative CANDECOMP/PARAFAC Decomposition in Block Coordinate\n  Descent Framework: A Comparison Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative CANDECOMP/PARAFAC (NCP) decomposition is an important tool to\nprocess nonnegative tensor. Sometimes, additional sparse regularization is\nneeded to extract meaningful nonnegative and sparse components. Thus, an\noptimization method for NCP that can impose sparsity efficiently is required.\nIn this paper, we construct NCP with sparse regularization (sparse NCP) by\nl1-norm. Several popular optimization methods in block coordinate descent\nframework are employed to solve the sparse NCP, all of which are deeply\nanalyzed with mathematical solutions. We compare these methods by experiments\non synthetic and real tensor data, both of which contain third-order and\nfourth-order cases. After comparison, the methods that have fast computation\nand high effectiveness to impose sparsity will be concluded. In addition, we\nproposed an accelerated method to compute the objective function and relative\nerror of sparse NCP, which has significantly improved the computation of tensor\ndecomposition especially for higher-order tensor.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 06:07:43 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Wang", "Deqing", ""], ["Cong", "Fengyu", ""], ["Ristaniemi", "Tapani", ""]]}, {"id": "1812.10650", "submitter": "Wonbong Jang", "authors": "Wonbong Jang", "title": "Sampling Using Neural Networks for colorizing the grayscale images", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main idea of this paper is to explore the possibilities of generating\nsamples from the neural networks, mostly focusing on the colorization of the\ngrey-scale images. I will compare the existing methods for colorization and\nexplore the possibilities of using new generative modeling to the task of\ncolorization. The contributions of this paper are to compare the existing\nstructures with similar generating structures(Decoders) and to apply the novel\nstructures including Conditional VAE(CVAE), Conditional Wasserstein GAN with\nGradient Penalty(CWGAN-GP), CWGAN-GP with L1 reconstruction loss, Adversarial\nGenerative Encoders(AGE) and Introspective VAE(IVAE). I trained these models\nusing CIFAR-10 images. To measure the performance, I use Inception Score(IS)\nwhich measures how distinctive each image is and how diverse overall samples\nare as well as human eyes for CIFAR-10 images. It turns out that CVAE with L1\nreconstruction loss and IVAE achieve the highest score in IS. CWGAN-GP with L1\ntends to learn faster than CWGAN-GP, but IS does not increase from CWGAN-GP.\nCWGAN-GP tends to generate more diverse images than other models using\nreconstruction loss. Also, I figured out that the proper regularization plays a\nvital role in generative modeling.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 07:51:45 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Jang", "Wonbong", ""]]}, {"id": "1812.10659", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Oren Elisha, Ran Gilad-Bachrach", "title": "Low Latency Privacy Preserving Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applying machine learning to sensitive data, one has to find a balance\nbetween accuracy, information security, and computational-complexity. Recent\nstudies combined Homomorphic Encryption with neural networks to make inferences\nwhile protecting against information leakage. However, these methods are\nlimited by the width and depth of neural networks that can be used (and hence\nthe accuracy) and exhibit high latency even for relatively simple networks. In\nthis study we provide two solutions that address these limitations. In the\nfirst solution, we present more than $10\\times$ improvement in latency and\nenable inference on wider networks compared to prior attempts with the same\nlevel of security. The improved performance is achieved by novel methods to\nrepresent the data during the computation. In the second solution, we apply the\nmethod of transfer learning to provide private inference services using deep\nnetworks with latency of $\\sim0.16$ seconds. We demonstrate the efficacy of our\nmethods on several computer vision tasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 08:38:54 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 15:03:32 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Brutzkus", "Alon", ""], ["Elisha", "Oren", ""], ["Gilad-Bachrach", "Ran", ""]]}, {"id": "1812.10666", "submitter": "Andrea Gesmundo", "authors": "Stanis{\\l}aw Jastrz\\k{e}bski, Quentin de Laroussilhe, Mingxing Tan,\n  Xiao Ma, Neil Houlsby, Andrea Gesmundo", "title": "Neural Architecture Search Over a Graph Search Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) enabled the discovery of state-of-the-art\narchitectures in many domains. However, the success of NAS depends on the\ndefinition of the search space. Current search spaces are defined as a static\nsequence of decisions and a set of available actions for each decision. Each\npossible sequence of actions defines an architecture. We propose a more\nexpressive class of search space: directed graphs. In our formalism, each\ndecision is a vertex and each action is an edge. This allows us to model\niterative and branching architecture design decisions. We demonstrate in\nsimulation, and on image classification experiments, basic iterative and\nbranching search structures, and show that the graph representation improves\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 09:04:17 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 16:19:31 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["de Laroussilhe", "Quentin", ""], ["Tan", "Mingxing", ""], ["Ma", "Xiao", ""], ["Houlsby", "Neil", ""], ["Gesmundo", "Andrea", ""]]}, {"id": "1812.10687", "submitter": "Rowan McAllister", "authors": "Rowan McAllister, Gregory Kahn, Jeff Clune, Sergey Levine", "title": "Robustness to Out-of-Distribution Inputs via Task-Aware Generative\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning provides a powerful tool for machine perception when the\nobservations resemble the training data. However, real-world robotic systems\nmust react intelligently to their observations even in unexpected\ncircumstances. This requires a system to reason about its own uncertainty given\nunfamiliar, out-of-distribution observations. Approximate Bayesian approaches\nare commonly used to estimate uncertainty for neural network predictions, but\ncan struggle with out-of-distribution observations. Generative models can in\nprinciple detect out-of-distribution observations as those with a low estimated\ndensity. However, the mere presence of an out-of-distribution input does not by\nitself indicate an unsafe situation. In this paper, we present a method for\nuncertainty-aware robotic perception that combines generative modeling and\nmodel uncertainty to cope with uncertainty stemming from out-of-distribution\nstates. Our method estimates an uncertainty measure about the model's\nprediction, taking into account an explicit (generative) model of the\nobservation distribution to handle out-of-distribution inputs. This is\naccomplished by probabilistically projecting observations onto the training\ndistribution, such that out-of-distribution inputs map to uncertain\nin-distribution observations, which in turn produce uncertain task-related\npredictions, but only if task-relevant parts of the image change. We evaluate\nour method on an action-conditioned collision prediction task with both\nsimulated and real data, and demonstrate that our method of projecting\nout-of-distribution observations improves the performance of four standard\nBayesian and non-Bayesian neural network approaches, offering more favorable\ntrade-offs between the proportion of time a robot can remain autonomous and the\nproportion of impending crashes successfully avoided.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 10:36:26 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["McAllister", "Rowan", ""], ["Kahn", "Gregory", ""], ["Clune", "Jeff", ""], ["Levine", "Sergey", ""]]}, {"id": "1812.10730", "submitter": "Abdullah Zyarah", "authors": "Abdullah M. Zyarah and Dhireesha Kudithipudi", "title": "Neuromemrisitive Architecture of HTM with On-Device Learning and\n  Neurogenesis", "comments": null, "journal-ref": null, "doi": "10.1145/3300971", "report-no": null, "categories": "cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical temporal memory (HTM) is a biomimetic sequence memory algorithm\nthat holds promise for invariant representations of spatial and spatiotemporal\ninputs. This paper presents a comprehensive neuromemristive crossbar\narchitecture for the spatial pooler (SP) and the sparse distributed\nrepresentation classifier, which are fundamental to the algorithm. There are\nseveral unique features in the proposed architecture that tightly link with the\nHTM algorithm. A memristor that is suitable for emulating the HTM synapses is\nidentified and a new Z-window function is proposed. The architecture exploits\nthe concept of synthetic synapses to enable potential synapses in the HTM. The\ncrossbar for the SP avoids dark spots caused by unutilized crossbar regions and\nsupports rapid on-chip training within 2 clock cycles. This research also\nleverages plasticity mechanisms such as neurogenesis and homeostatic intrinsic\nplasticity to strengthen the robustness and performance of the SP. The proposed\ndesign is benchmarked for image recognition tasks using MNIST and Yale faces\ndatasets, and is evaluated using different metrics including entropy,\nsparseness, and noise robustness. Detailed power analysis at different stages\nof the SP operations is performed to demonstrate the suitability for mobile\nplatforms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 14:27:10 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Zyarah", "Abdullah M.", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1812.10747", "submitter": "Aniket Pramanik", "authors": "Aniket Pramanik, Hemant Kumar Aggarwal, Mathews Jacob", "title": "Off-the-grid model based deep learning (O-MODL)", "comments": "ISBI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model based off-the-grid image reconstruction algorithm using\ndeep learned priors. The main difference of the proposed scheme with current\ndeep learning strategies is the learning of non-linear annihilation relations\nin Fourier space. We rely on a model based framework, which allows us to use a\nsignificantly smaller deep network, compared to direct approaches that also\nlearn how to invert the forward model. Preliminary comparisons against image\ndomain MoDL approach demonstrates the potential of the off-the-grid\nformulation. The main benefit of the proposed scheme compared to structured\nlow-rank methods is the quite significant reduction in computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 15:48:10 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Pramanik", "Aniket", ""], ["Aggarwal", "Hemant Kumar", ""], ["Jacob", "Mathews", ""]]}, {"id": "1812.10761", "submitter": "Shen-Huan Lyu", "authors": "Shen-Huan Lyu, Lu Wang, Zhi-Hua Zhou", "title": "Improving Generalization of Deep Neural Networks by Leveraging Margin\n  Distribution", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches use margin theory to analyze the generalization performance\nfor deep neural networks. The main results are based on the\nspectrally-normalized minimum margin. However, optimizing the minimum margin\nignores a mass of information about margin distribution which is crucial to\ngeneralization performance. In this paper, we prove a generalization bound\ndominated by a ratio of the margin standard deviation to the margin mean, where\nthe huge magnitude of spectral norms is reduced. Compared with the spectral\nnorm terms in the existing results, the margin ratio term in our bound is\norders of magnitude better in practice. On the other hand, our bound inspires\nus to optimize the margin ratio. We utilize a convex margin distribution loss\nfunction on the deep neural networks to validate our theoretical results.\nExperiments and visualizations confirm the effectiveness of our approach in\nterms of performance and representation learning ability.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 16:34:54 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 15:02:14 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Lyu", "Shen-Huan", ""], ["Wang", "Lu", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1812.10782", "submitter": "Shayne O'Brien", "authors": "Shayne O'Brien, Matt Groh and Abhimanyu Dubey", "title": "Evaluating Generative Adversarial Networks on Explicitly Parameterized\n  Distributions", "comments": "Presented at the NeurIPS 2018 Workshop on Critiquing and Correcting\n  Trends in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The true distribution parameterizations of commonly used image datasets are\ninaccessible. Rather than designing metrics for feature spaces with unknown\ncharacteristics, we propose to measure GAN performance by evaluating on\nexplicitly parameterized, synthetic data distributions. As a case study, we\nexamine the performance of 16 GAN variants on six multivariate distributions of\nvarying dimensionalities and training set sizes. In this learning environment,\nwe observe that: GANs exhibit similar performance trends across\ndimensionalities; learning depends on the underlying distribution and its\ncomplexity; the number of training samples can have a large impact on\nperformance; evaluation and relative comparisons are metric-dependent; diverse\nsets of hyperparameters can produce a \"best\" result; and some GANs are more\nrobust to hyperparameter changes than others. These observations both\ncorroborate findings of previous GAN evaluation studies and make novel\ncontributions regarding the relationship between size, complexity, and GAN\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 17:55:50 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["O'Brien", "Shayne", ""], ["Groh", "Matt", ""], ["Dubey", "Abhimanyu", ""]]}, {"id": "1812.10783", "submitter": "Luca Falorsi", "authors": "Pim de Haan and Luca Falorsi", "title": "Topological Constraints on Homeomorphic Auto-Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When doing representation learning on data that lives on a known non-trivial\nmanifold embedded in high dimensional space, it is natural to desire the\nencoder to be homeomorphic when restricted to the manifold, so that it is\nbijective and continuous with a continuous inverse. Using topological\narguments, we show that when the manifold is non-trivial, the encoder must be\nglobally discontinuous and propose a universal, albeit impractical,\nconstruction. In addition, we derive necessary constraints which need to be\nsatisfied when designing manifold-specific practical encoders. These are used\nto analyse candidates for a homeomorphic encoder for the manifold of 3D\nrotations $SO(3)$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 17:59:07 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["de Haan", "Pim", ""], ["Falorsi", "Luca", ""]]}, {"id": "1812.10793", "submitter": "Rashid Bakirov", "authors": "Rashid Bakirov, Bogdan Gabrys and Damien Fay", "title": "Automated Adaptation Strategies for Stream Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation of machine learning model development is increasingly becoming an\nestablished research area. While automated model selection and automated data\npre-processing have been studied in depth, there is, however, a gap concerning\nautomated model adaptation strategies when multiple strategies are available.\nManually developing an adaptation strategy can be time consuming and costly. In\nthis paper we address this issue by proposing the use of flexible adaptive\nmechanism deployment for automated development of adaptation strategies.\nExperimental results after using the proposed strategies with five adaptive\nalgorithms on 36 datasets confirm their viability. These strategies achieve\nbetter or comparable performance to the custom adaptation strategies and the\nrepeated deployment of any single adaptive mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 18:43:21 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 14:09:07 GMT"}, {"version": "v3", "created": "Sat, 1 May 2021 01:00:32 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bakirov", "Rashid", ""], ["Gabrys", "Bogdan", ""], ["Fay", "Damien", ""]]}, {"id": "1812.10818", "submitter": "Marina Bendersky", "authors": "Marina Bendersky and Joy Wu and Tanveer Syeda-Mahmood", "title": "Classification of radiology reports by modality and anatomy: A\n  comparative study", "comments": "8 pages, 4 figures, BIBM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data labeling is currently a time-consuming task that often requires expert\nknowledge. In research settings, the availability of correctly labeled data is\ncrucial to ensure that model predictions are accurate and useful. We propose\nrelatively simple machine learning-based models that achieve high performance\nmetrics in the binary and multiclass classification of radiology reports. We\ncompare the performance of these algorithms to that of a data-driven approach\nbased on NLP, and find that the logistic regression classifier outperforms all\nother models, in both the binary and multiclass classification tasks. We then\nchoose the logistic regression binary classifier to predict chest X-ray (CXR)/\nnon-chest X-ray (non-CXR) labels in reports from different datasets, unseen\nduring any training phase of any of the models. Even in unseen report\ncollections, the binary logistic regression classifier achieves average\nprecision values of above 0.9. Based on the regression coefficient values, we\nalso identify frequent tokens in CXR and non-CXR reports that are features with\npossibly high predictive power.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 20:21:36 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Bendersky", "Marina", ""], ["Wu", "Joy", ""], ["Syeda-Mahmood", "Tanveer", ""]]}, {"id": "1812.10857", "submitter": "Lili Zhang", "authors": "Lili Zhang, Herman Ray, Jennifer Priestley and Soon Tan", "title": "A Descriptive Study of Variable Discretization and Cost-Sensitive\n  Logistic Regression on Imbalanced Credit Data", "comments": "Journal of Applied Statistics (2019)", "journal-ref": null, "doi": "10.1080/02664763.2019.1643829", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training classification models on imbalanced data tends to result in bias\ntowards the majority class. In this paper, we demonstrate how variable\ndiscretization and cost-sensitive logistic regression help mitigate this bias\non an imbalanced credit scoring dataset, and further show the application of\nthe variable discretization technique on the data from other domains,\ndemonstrating its potential as a generic technique for classifying imbalanced\ndata beyond credit socring. The performance measurements include ROC curves,\nArea under ROC Curve (AUC), Type I Error, Type II Error, accuracy, and F1\nscore. The results show that proper variable discretization and cost-sensitive\nlogistic regression with the best class weights can reduce the model bias\nand/or variance. From the perspective of the algorithm, cost-sensitive logistic\nregression is beneficial for increasing the value of predictors even if they\nare not in their optimized forms while maintaining monotonicity. From the\nperspective of predictors, the variable discretization performs better than\ncost-sensitive logistic regression, provides more reasonable coefficient\nestimates for predictors which have nonlinear relationships against their\nempirical logit, and is robust to penalty weights on misclassifications of\nevents and non-events determined by their apriori proportions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 01:10:13 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 14:20:37 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Zhang", "Lili", ""], ["Ray", "Herman", ""], ["Priestley", "Jennifer", ""], ["Tan", "Soon", ""]]}, {"id": "1812.10869", "submitter": "Sankaran Vaidyanathan", "authors": "Tarun Kumar, Sankaran Vaidyanathan, Harini Ananthapadmanabhan,\n  Srinivasan Parthasarathy, Balaraman Ravindran", "title": "Hypergraph Clustering: A Modularity Maximization Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering on hypergraphs has been garnering increased attention with\npotential applications in network analysis, VLSI design and computer vision,\namong others. In this work, we generalize the framework of modularity\nmaximization for clustering on hypergraphs. To this end, we introduce a\nhypergraph null model, analogous to the configuration model on undirected\ngraphs, and a node-degree preserving reduction to work with this model. This is\nused to define a modularity function that can be maximized using the popular\nand fast Louvain algorithm. We additionally propose a refinement over this\nclustering, by reweighting cut hyperedges in an iterative fashion. The efficacy\nand efficiency of our methods are demonstrated on several real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 02:20:03 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Kumar", "Tarun", ""], ["Vaidyanathan", "Sankaran", ""], ["Ananthapadmanabhan", "Harini", ""], ["Parthasarathy", "Srinivasan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1812.10889", "submitter": "Sangwoo Mo", "authors": "Sangwoo Mo, Minsu Cho, Jinwoo Shin", "title": "InstaGAN: Instance-aware Image-to-Image Translation", "comments": "Accepted to ICLR 2019. High resolution images are available in\n  https://github.com/sangwoomo/instagan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised image-to-image translation has gained considerable attention due\nto the recent impressive progress based on generative adversarial networks\n(GANs). However, previous methods often fail in challenging cases, in\nparticular, when an image has multiple target instances and a translation task\ninvolves significant changes in shape, e.g., translating pants to skirts in\nfashion images. To tackle the issues, we propose a novel method, coined\ninstance-aware GAN (InstaGAN), that incorporates the instance information\n(e.g., object segmentation masks) and improves multi-instance transfiguration.\nThe proposed method translates both an image and the corresponding set of\ninstance attributes while maintaining the permutation invariance property of\nthe instances. To this end, we introduce a context preserving loss that\nencourages the network to learn the identity function outside of target\ninstances. We also propose a sequential mini-batch inference/training technique\nthat handles multiple instances with a limited GPU memory and enhances the\nnetwork to generalize better for multiple instances. Our comparative evaluation\ndemonstrates the effectiveness of the proposed method on different image\ndatasets, in particular, in the aforementioned challenging cases. Code and\nresults are available in https://github.com/sangwoomo/instagan\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 04:30:47 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 09:29:21 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Mo", "Sangwoo", ""], ["Cho", "Minsu", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1812.10906", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Gus Xia", "title": "A Framework for Automated Pop-song Melody Generation with Piano\n  Accompaniment Arrangement", "comments": "In Proceeding of 6th Conference on Sound and Music Technology, 2018,\n  Xiamen, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contribute a pop-song automation framework for lead melody generation and\naccompaniment arrangement. The framework reflects the major procedures of human\nmusic composition, generating both lead melody and piano accompaniment by a\nunified strategy. Specifically, we take chord progression as an input and\npropose three models to generate a structured melody with piano accompaniment\ntextures. First, the harmony alternation model transforms a raw input chord\nprogression to an altered one to better fit the specified music style. Second,\nthe melody generation model generates the lead melody and other voices (melody\nlines) of the accompaniment using seasonal ARMA (Autoregressive Moving Average)\nprocesses. Third, the melody integration model integrates melody lines (voices)\ntogether as the final piano accompaniment. We evaluate the proposed framework\nusing subjective listening tests. Experimental results show that the generated\nmelodies are rated significantly higher than the ones generated by\nbi-directional LSTM, and our accompaniment arrangement result is comparable\nwith a state-of-the-art commercial software, Band in a Box.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 06:32:04 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Wang", "Ziyu", ""], ["Xia", "Gus", ""]]}, {"id": "1812.10907", "submitter": "Erik Nijkamp", "authors": "Tian Han, Erik Nijkamp, Xiaolin Fang, Mitch Hill, Song-Chun Zhu, Ying\n  Nian Wu", "title": "Divergence Triangle for Joint Training of Generator Model, Energy-based\n  Model, and Inference Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the divergence triangle as a framework for joint training\nof generator model, energy-based model and inference model. The divergence\ntriangle is a compact and symmetric (anti-symmetric) objective function that\nseamlessly integrates variational learning, adversarial learning, wake-sleep\nalgorithm, and contrastive divergence in a unified probabilistic formulation.\nThis unification makes the processes of sampling, inference, energy evaluation\nreadily available without the need for costly Markov chain Monte Carlo methods.\nOur experiments demonstrate that the divergence triangle is capable of learning\n(1) an energy-based model with well-formed energy landscape, (2) direct\nsampling in the form of a generator network, and (3) feed-forward inference\nthat faithfully reconstructs observed as well as synthesized data. The\ndivergence triangle is a robust training method that can learn from incomplete\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 06:35:39 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 09:35:03 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Han", "Tian", ""], ["Nijkamp", "Erik", ""], ["Fang", "Xiaolin", ""], ["Hill", "Mitch", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1812.10912", "submitter": "Haoming Jiang", "authors": "Haoming Jiang, Zhehui Chen, Minshuo Chen, Feng Liu, Dingding Wang, Tuo\n  Zhao", "title": "On Computation and Generalization of GANs with Spectrum Control", "comments": "Seventh International Conference on Learning Representations, ICLR\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs), though powerful, is hard to train.\nSeveral recent works (brock2016neural,miyato2018spectral) suggest that\ncontrolling the spectra of weight matrices in the discriminator can\nsignificantly improve the training of GANs. Motivated by their discovery, we\npropose a new framework for training GANs, which allows more flexible spectrum\ncontrol (e.g., making the weight matrices of the discriminator have slow\nsingular value decays). Specifically, we propose a new reparameterization\napproach for the weight matrices of the discriminator in GANs, which allows us\nto directly manipulate the spectra of the weight matrices through various\nregularizers and constraints, without intensively computing singular value\ndecompositions. Theoretically, we further show that the spectrum control\nimproves the generalization ability of GANs. Our experiments on CIFAR-10,\nSTL-10, and ImageNet datasets confirm that compared to other methods, our\nproposed method is capable of generating images with competitive quality by\nutilizing spectral normalization and encouraging the slow singular value decay.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 07:17:55 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 03:44:44 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Jiang", "Haoming", ""], ["Chen", "Zhehui", ""], ["Chen", "Minshuo", ""], ["Liu", "Feng", ""], ["Wang", "Dingding", ""], ["Zhao", "Tuo", ""]]}, {"id": "1812.10924", "submitter": "Xuan Liu", "authors": "Xuan Liu, Xiaoguang Wang, Stan Matwin", "title": "Improving the Interpretability of Deep Neural Networks with Knowledge\n  Distillation", "comments": "2018 IEEE International Conference on Data Mining (ICDM), in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have achieved huge success at a wide spectrum of\napplications from language modeling, computer vision to speech recognition.\nHowever, nowadays, good performance alone is not sufficient to satisfy the\nneeds of practical deployment where interpretability is demanded for cases\ninvolving ethics and mission critical applications. The complex models of Deep\nNeural Networks make it hard to understand and reason the predictions, which\nhinders its further progress. To tackle this problem, we apply the Knowledge\nDistillation technique to distill Deep Neural Networks into decision trees in\norder to attain good performance and interpretability simultaneously. We\nformulate the problem at hand as a multi-output regression problem and the\nexperiments demonstrate that the student model achieves significantly better\naccuracy performance (about 1\\% to 5\\%) than vanilla decision trees at the same\nlevel of tree depth. The experiments are implemented on the TensorFlow platform\nto make it scalable to big datasets. To the best of our knowledge, we are the\nfirst to distill Deep Neural Networks into vanilla decision trees on\nmulti-class datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 08:50:04 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Liu", "Xuan", ""], ["Wang", "Xiaoguang", ""], ["Matwin", "Stan", ""]]}, {"id": "1812.10962", "submitter": "Sylvain Lamprier", "authors": "Sylvain Lamprier", "title": "A Variational Topological Neural Model for Cascade-based Diffusion in\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many works have been proposed in the literature to capture the dynamics of\ndiffusion in networks. While some of them define graphical markovian models to\nextract temporal relationships between node infections in networks, others\nconsider diffusion episodes as sequences of infections via recurrent neural\nmodels. In this paper we propose a model at the crossroads of these two\nextremes, which embeds the history of diffusion in infected nodes as hidden\ncontinuous states. Depending on the trajectory followed by the content before\nreaching a given node, the distribution of influence probabilities may vary.\nHowever, content trajectories are usually hidden in the data, which induces\nchallenging learning problems. We propose a topological recurrent neural model\nwhich exhibits good experimental performances for diffusion modelling and\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 11:53:08 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Lamprier", "Sylvain", ""]]}, {"id": "1812.10972", "submitter": "Michael Janner", "authors": "Michael Janner, Sergey Levine, William T. Freeman, Joshua B.\n  Tenenbaum, Chelsea Finn, Jiajun Wu", "title": "Reasoning About Physical Interactions with Object-Oriented Prediction\n  and Planning", "comments": "ICLR 2019, project page:\n  https://people.eecs.berkeley.edu/~janner/o2p2/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-based factorizations provide a useful level of abstraction for\ninteracting with the world. Building explicit object representations, however,\noften requires supervisory signals that are difficult to obtain in practice. We\npresent a paradigm for learning object-centric representations for physical\nscene understanding without direct supervision of object properties. Our model,\nObject-Oriented Prediction and Planning (O2P2), jointly learns a perception\nfunction to map from image observations to object representations, a pairwise\nphysics interaction function to predict the time evolution of a collection of\nobjects, and a rendering function to map objects back to pixels. For\nevaluation, we consider not only the accuracy of the physical predictions of\nthe model, but also its utility for downstream tasks that require an actionable\nrepresentation of intuitive physics. After training our model on an image\nprediction task, we can use its learned representations to build block towers\nmore complicated than those observed during training.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 12:18:23 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 08:27:03 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Janner", "Michael", ""], ["Levine", "Sergey", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Finn", "Chelsea", ""], ["Wu", "Jiajun", ""]]}, {"id": "1812.11006", "submitter": "Moran Rubin", "authors": "Moran Rubin, Omer Stein, Nir A. Turko, Yoav Nygate, Darina Roitshtain,\n  Lidor Karako, Itay Barnea, Raja Giryes, and Natan T. Shaked", "title": "TOP-GAN: Label-Free Cancer Cell Classification Using Deep Learning with\n  a Small Training Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new deep learning approach for medical imaging that copes with\nthe problem of a small training set, the main bottleneck of deep learning, and\napply it for classification of healthy and cancer cells acquired by\nquantitative phase imaging. The proposed method, called transferring of\npre-trained generative adversarial network (TOP-GAN), is a hybridization\nbetween transfer learning and generative adversarial networks (GANs). Healthy\ncells and cancer cells of different metastatic potential have been imaged by\nlow-coherence off-axis holography. After the acquisition, the optical path\ndelay maps of the cells have been extracted and directly used as an input to\nthe deep networks. In order to cope with the small number of classified images,\nwe have used GANs to train a large number of unclassified images from another\ncell type (sperm cells). After this preliminary training, and after\ntransforming the last layer of the network with new ones, we have designed an\nautomatic classifier for the correct cell type (healthy/primary\ncancer/metastatic cancer) with 90-99% accuracy, although small training sets of\ndown to several images have been used. These results are better in comparison\nto other classic methods that aim at coping with the same problem of a small\ntraining set. We believe that our approach makes the combination of holographic\nmicroscopy and deep learning networks more accessible to the medical field by\nenabling a rapid, automatic and accurate classification in stain-free imaging\nflow cytometry. Furthermore, our approach is expected to be applicable to many\nother medical image classification tasks, suffering from a small training set.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 17:02:58 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Rubin", "Moran", ""], ["Stein", "Omer", ""], ["Turko", "Nir A.", ""], ["Nygate", "Yoav", ""], ["Roitshtain", "Darina", ""], ["Karako", "Lidor", ""], ["Barnea", "Itay", ""], ["Giryes", "Raja", ""], ["Shaked", "Natan T.", ""]]}, {"id": "1812.11027", "submitter": "Sergey Zagoruyko", "authors": "Xu Shell Hu, Sergey Zagoruyko, Nikos Komodakis", "title": "Exploring Weight Symmetry in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to impose symmetry in neural network parameters to improve\nparameter usage and make use of dedicated convolution and matrix multiplication\nroutines. Due to significant reduction in the number of parameters as a result\nof the symmetry constraints, one would expect a dramatic drop in accuracy.\nSurprisingly, we show that this is not the case, and, depending on network\nsize, symmetry can have little or no negative effect on network accuracy,\nespecially in deep overparameterized networks. We propose several ways to\nimpose local symmetry in recurrent and convolutional neural networks, and show\nthat our symmetry parameterizations satisfy universal approximation property\nfor single hidden layer networks. We extensively evaluate these\nparameterizations on CIFAR, ImageNet and language modeling datasets, showing\nsignificant benefits from the use of symmetry. For instance, our ResNet-101\nwith channel-wise symmetry has almost 25% less parameters and only 0.2%\naccuracy loss on ImageNet. Code for our experiments is available at\nhttps://github.com/hushell/deep-symmetry\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 15:11:42 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 16:38:20 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Hu", "Xu Shell", ""], ["Zagoruyko", "Sergey", ""], ["Komodakis", "Nikos", ""]]}, {"id": "1812.11028", "submitter": "Avishek Choudhury", "authors": "Avishek Choudhury, Christopher M Greene", "title": "Evaluating Patient Readmission Risk: A Predictive Analytics Approach", "comments": "arXiv admin note: text overlap with arXiv:1403.1210 by other authors", "journal-ref": "American Journal of Engineering and Applied Sciences 2018,\n  11(4):1320.1331", "doi": "10.3844/ajeassp.2018.1320.1331", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of the Hospital Readmission Reduction Program of the\nCenter for Medicare and Medicaid Services on October 1, 2012, forecasting\nunplanned patient readmission risk became crucial to the healthcare domain.\nThere are tangible works in the literature emphasizing on developing\nreadmission risk prediction models; However, the models are not accurate enough\nto be deployed in an actual clinical setting. Our study considers patient\nreadmission risk as the objective for optimization and develops a useful risk\nprediction model to address unplanned readmissions. Furthermore, Genetic\nAlgorithm and Greedy Ensemble is used to optimize the developed model\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 16:18:45 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 03:36:48 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Choudhury", "Avishek", ""], ["Greene", "Christopher M", ""]]}, {"id": "1812.11039", "submitter": "Tian Ding", "authors": "Dawei Li and Tian Ding and Ruoyu Sun", "title": "On the Benefit of Width for Neural Networks: Disappearance of Bad Basins", "comments": "ver1: Nov 22, 2018; ver2: Jan 20, 2020; ver3: July 26, 2020; ver4:\n  Jan 19, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide networks are often believed to have nice optimization landscape, but\nwhat rigorous results can we prove? To understand the benefit of width, it is\nimportant to identify the difference between wide and narrow networks. In this\nwork, we prove that from narrow to wide networks, there is a phase transition\nfrom having sub-optimal basins to no sub-optimal basins. Specifically, we prove\ntwo results: on the positive side, for any continuous activation functions, the\nloss surface of a class of wide networks has no sub-optimal basin, where\n\"basin\" is defined as the set-wise strict local minimum; on the negative side,\nfor a large class of networks with width below a threshold, we construct strict\nlocal minima that are not global. These two results together show the phase\ntransition from narrow to wide networks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 15:24:21 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 17:12:43 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 16:39:25 GMT"}, {"version": "v4", "created": "Sun, 26 Jul 2020 07:14:35 GMT"}, {"version": "v5", "created": "Mon, 18 Jan 2021 16:06:38 GMT"}, {"version": "v6", "created": "Tue, 19 Jan 2021 13:02:17 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Li", "Dawei", ""], ["Ding", "Tian", ""], ["Sun", "Ruoyu", ""]]}, {"id": "1812.11065", "submitter": "Fahad Shamshad", "authors": "Fahad Shamshad, Farwa Abbas, Ali Ahmed", "title": "Deep Ptych: Subsampled Fourier Ptychography using Generative Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel framework to regularize the highly ill-posed and\nnon-linear Fourier ptychography problem using generative models. We demonstrate\nexperimentally that our proposed algorithm, Deep Ptych, outperforms the\nexisting Fourier ptychography techniques, in terms of quality of reconstruction\nand robustness against noise, using far fewer samples. We further modify the\nproposed approach to allow the generative model to explore solutions outside\nthe range, leading to improved performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 19:57:12 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Shamshad", "Fahad", ""], ["Abbas", "Farwa", ""], ["Ahmed", "Ali", ""]]}, {"id": "1812.11092", "submitter": "Bas Peters", "authors": "Bas Peters, Justin Granek, Eldad Haber", "title": "Multi-resolution neural networks for tracking seismic horizons from few\n  training images", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting a specific horizon in seismic images is a valuable tool for\ngeological interpretation. Because hand-picking the locations of the horizon is\na time-consuming process, automated computational methods were developed\nstarting three decades ago. Older techniques for such picking include\ninterpolation of control points however, in recent years neural networks have\nbeen used for this task. Until now, most networks trained on small patches from\nlarger images. This limits the networks ability to learn from large-scale\ngeologic structures. Moreover, currently available networks and training\nstrategies require label patches that have full and continuous annotations,\nwhich are also time-consuming to generate.\n  We propose a projected loss-function for training convolutional networks with\na multi-resolution structure, including variants of the U-net. Our networks\nlearn from a small number of large seismic images without creating patches. The\nprojected loss-function enables training on labels with just a few annotated\npixels and has no issue with the other unknown label pixels. Training uses all\ndata without reserving some for validation. Only the labels are split into\ntraining/testing. Contrary to other work on horizon tracking, we train the\nnetwork to perform non-linear regression, and not classification. As such, we\npropose labels as the convolution of a Gaussian kernel and the known horizon\nlocations that indicate uncertainty in the labels. The network output is the\nprobability of the horizon location. We demonstrate the proposed computational\ningredients on two different datasets, for horizon extrapolation and\ninterpolation. We show that the predictions of our methodology are accurate\neven in areas far from known horizon locations because our learning strategy\nexploits all data in large seismic images.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 07:35:24 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Peters", "Bas", ""], ["Granek", "Justin", ""], ["Haber", "Eldad", ""]]}, {"id": "1812.11097", "submitter": "Hamsa Bastani", "authors": "Hamsa Bastani", "title": "Predicting with Proxies: Transfer Learning in High Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive analytics is increasingly used to guide decision-making in many\napplications. However, in practice, we often have limited data on the true\npredictive task of interest, and must instead rely on more abundant data on a\nclosely-related proxy predictive task. For example, e-commerce platforms use\nabundant customer click data (proxy) to make product recommendations rather\nthan the relatively sparse customer purchase data (true outcome of interest);\nalternatively, hospitals often rely on medical risk scores trained on a\ndifferent patient population (proxy) rather than their own patient population\n(true cohort of interest) to assign interventions. Yet, not accounting for the\nbias in the proxy can lead to sub-optimal decisions. Using real datasets, we\nfind that this bias can often be captured by a sparse function of the features.\nThus, we propose a novel two-step estimator that uses techniques from\nhigh-dimensional statistics to efficiently combine a large amount of proxy data\nand a small amount of true data. We prove upper bounds on the error of our\nproposed estimator and lower bounds on several heuristics used by data\nscientists; in particular, our proposed estimator can achieve the same accuracy\nwith exponentially less true data (in the number of features). Our proof relies\non a new LASSO tail inequality for approximately sparse vectors. Finally, we\ndemonstrate the effectiveness of our approach on e-commerce and healthcare\ndatasets; in both cases, we achieve significantly better predictive accuracy as\nwell as managerial insights into the nature of the bias in the proxy data.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 16:29:20 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 03:34:54 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 19:06:56 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Bastani", "Hamsa", ""]]}, {"id": "1812.11103", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Sehoon Ha, Aurick Zhou, Jie Tan, George Tucker,\n  Sergey Levine", "title": "Learning to Walk via Deep Reinforcement Learning", "comments": "RSS 2019, https://sites.google.com/view/minitaur-locomotion/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) holds the promise of automating the\nacquisition of complex controllers that can map sensory inputs directly to\nlow-level actions. In the domain of robotic locomotion, deep RL could enable\nlearning locomotion skills with minimal engineering and without an explicit\nmodel of the robot dynamics. Unfortunately, applying deep RL to real-world\nrobotic tasks is exceptionally difficult, primarily due to poor sample\ncomplexity and sensitivity to hyperparameters. While hyperparameters can be\neasily tuned in simulated domains, tuning may be prohibitively expensive on\nphysical systems, such as legged robots, that can be damaged through extensive\ntrial-and-error learning. In this paper, we propose a sample-efficient deep RL\nalgorithm based on maximum entropy RL that requires minimal per-task tuning and\nonly a modest number of trials to learn neural network policies. We apply this\nmethod to learning walking gaits on a real-world Minitaur robot. Our method can\nacquire a stable gait from scratch directly in the real world in about two\nhours, without relying on any model or simulation, and the resulting policy is\nrobust to moderate variations in the environment. We further show that our\nalgorithm achieves state-of-the-art performance on simulated benchmarks with a\nsingle set of hyperparameters. Videos of training and the learned policy can be\nfound on the project website.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 10:07:13 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 09:36:49 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 17:40:58 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Ha", "Sehoon", ""], ["Zhou", "Aurick", ""], ["Tan", "Jie", ""], ["Tucker", "George", ""], ["Levine", "Sergey", ""]]}, {"id": "1812.11106", "submitter": "Vincent Adam", "authors": "Vincent Adam, Nicolas Durrande, ST John", "title": "Scalable GAM using sparse variational Gaussian processes", "comments": null, "journal-ref": "1st Symposium on Advances in Approximate Bayesian Inference, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized additive models (GAMs) are a widely used class of models of\ninterest to statisticians as they provide a flexible way to design\ninterpretable models of data beyond linear models. We here propose a scalable\nand well-calibrated Bayesian treatment of GAMs using Gaussian processes (GPs)\nand leveraging recent advances in variational inference. We use sparse GPs to\nrepresent each component and exploit the additive structure of the model to\nefficiently represent a Gaussian a posteriori coupling between the components.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 16:42:39 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Adam", "Vincent", ""], ["Durrande", "Nicolas", ""], ["John", "ST", ""]]}, {"id": "1812.11118", "submitter": "Daniel Hsu", "authors": "Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal", "title": "Reconciling modern machine learning practice and the bias-variance\n  trade-off", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breakthroughs in machine learning are rapidly changing science and society,\nyet our fundamental understanding of this technology has lagged far behind.\nIndeed, one of the central tenets of the field, the bias-variance trade-off,\nappears to be at odds with the observed behavior of methods used in the modern\nmachine learning practice. The bias-variance trade-off implies that a model\nshould balance under-fitting and over-fitting: rich enough to express\nunderlying structure in data, simple enough to avoid fitting spurious patterns.\nHowever, in the modern practice, very rich models such as neural networks are\ntrained to exactly fit (i.e., interpolate) the data. Classically, such models\nwould be considered over-fit, and yet they often obtain high accuracy on test\ndata. This apparent contradiction has raised questions about the mathematical\nfoundations of machine learning and their relevance to practitioners.\n  In this paper, we reconcile the classical understanding and the modern\npractice within a unified performance curve. This \"double descent\" curve\nsubsumes the textbook U-shaped bias-variance trade-off curve by showing how\nincreasing model capacity beyond the point of interpolation results in improved\nperformance. We provide evidence for the existence and ubiquity of double\ndescent for a wide spectrum of models and datasets, and we posit a mechanism\nfor its emergence. This connection between the performance and the structure of\nmachine learning models delineates the limits of classical analyses, and has\nimplications for both the theory and practice of machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 17:15:38 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 19:51:04 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Belkin", "Mikhail", ""], ["Hsu", "Daniel", ""], ["Ma", "Siyuan", ""], ["Mandal", "Soumik", ""]]}, {"id": "1812.11137", "submitter": "Adithya M Devraj", "authors": "Adithya M. Devraj and Ioannis Kontoyiannis and Sean P. Meyn", "title": "Differential Temporal Difference Learning", "comments": "Preliminary versions of some of the results in this article were\n  submitted as arXiv:1604.01828", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value functions derived from Markov decision processes arise as a central\ncomponent of algorithms as well as performance metrics in many statistics and\nengineering applications of machine learning techniques. Computation of the\nsolution to the associated Bellman equations is challenging in most practical\ncases of interest. A popular class of approximation techniques, known as\nTemporal Difference (TD) learning algorithms, are an important sub-class of\ngeneral reinforcement learning methods. The algorithms introduced in this paper\nare intended to resolve two well-known difficulties of TD-learning approaches:\nTheir slow convergence due to very high variance, and the fact that, for the\nproblem of computing the relative value function, consistent algorithms exist\nonly in special cases. First we show that the gradients of these value\nfunctions admit a representation that lends itself to algorithm design. Based\non this result, a new class of differential TD-learning algorithms is\nintroduced. For Markovian models on Euclidean space with smooth dynamics, the\nalgorithms are shown to be consistent under general conditions. Numerical\nresults show dramatic variance reduction when compared to standard methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 18:05:21 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 22:25:02 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Devraj", "Adithya M.", ""], ["Kontoyiannis", "Ioannis", ""], ["Meyn", "Sean P.", ""]]}, {"id": "1812.11167", "submitter": "Xiyu Zhai", "authors": "Alexander Rakhlin and Xiyu Zhai", "title": "Consistency of Interpolation with Laplace Kernels is a High-Dimensional\n  Phenomenon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that minimum-norm interpolation in the Reproducing Kernel Hilbert\nSpace corresponding to the Laplace kernel is not consistent if input dimension\nis constant. The lower bound holds for any choice of kernel bandwidth, even if\nselected based on data. The result supports the empirical observation that\nminimum-norm interpolation (that is, exact fit to training data) in RKHS\ngeneralizes well for some high-dimensional datasets, but not for\nlow-dimensional ones.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 18:52:53 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Rakhlin", "Alexander", ""], ["Zhai", "Xiyu", ""]]}, {"id": "1812.11178", "submitter": "Pengfei Liu", "authors": "Pengfei Liu", "title": "Drug cell line interaction prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the phenotypic drug response on cancer cell lines plays a vital\nrule in anti-cancer drug discovery and re-purposing. The Genomics of Drug\nSensitivity in Cancer (GDSC) database provides open data for researchers in\nphenotypic screening to test their models and methods. Previously, most\nresearch in these areas starts from the fingerprints or features of drugs,\ninstead of their structures. In this paper, we introduce a model for phenotypic\nscreening, which is called twin Convolutional Neural Network for drugs in\nSMILES format (tCNNS). tCNNS is comprised of CNN input channels for drugs in\nSMILES format and cancer cell lines respectively. Our model achieves $0.84$ for\nthe coefficient of determinant($R^2$) and $0.92$ for Pearson\ncorrelation($R_p$), which are significantly better than previous\nworks\\cite{ammad2014integrative,haider2015copula,menden2013machine}. Besides\nthese statistical metrics, tCNNS also provides some insights into phenotypic\nscreening.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 09:14:16 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Liu", "Pengfei", ""]]}, {"id": "1812.11183", "submitter": "Junhao Wen", "authors": "Junhao Wen, Jorge Samper-Gonzalez, Simona Bottani, Alexandre Routier,\n  Ninon Burgos, Thomas Jacquemont, Sabrina Fontanella, Stanley Durrleman,\n  Stephane Epelbaum, Anne Bertrand, Olivier Colliot (for the Alzheimers Disease\n  Neuroimaging Initiative)", "title": "Reproducible evaluation of diffusion MRI features for automatic\n  classification of patients with Alzheimers disease", "comments": "51 pages, 5 figure and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion MRI is the modality of choice to study alterations of white matter.\nIn past years, various works have used diffusion MRI for automatic\nclassification of AD. However, classification performance obtained with\ndifferent approaches is difficult to compare and these studies are also\ndifficult to reproduce. In the present paper, we first extend a previously\nproposed framework to diffusion MRI data for AD classification. Specifically,\nwe add: conversion of diffusion MRI ADNI data into the BIDS standard and\npipelines for diffusion MRI preprocessing and feature extraction. We then apply\nthe framework to compare different components. First, FS has a positive impact\non classification results: highest balanced accuracy (BA) improved from 0.76 to\n0.82 for task CN vs AD. Secondly, voxel-wise features generally gives better\nperformance than regional features. Fractional anisotropy (FA) and mean\ndiffusivity (MD) provided comparable results for voxel-wise features. Moreover,\nwe observe that the poor performance obtained in tasks involving MCI were\npotentially caused by the small data samples, rather than by the data\nimbalance. Furthermore, no extensive classification difference exists for\ndifferent degree of smoothing and registration methods. Besides, we demonstrate\nthat using non-nested validation of FS leads to unreliable and over-optimistic\nresults: 0.05 up to 0.40 relative increase in BA. Lastly, with proper FR and\nFS, the performance of diffusion MRI features is comparable to that of T1w MRI.\nAll the code of the framework and the experiments are publicly available:\ngeneral-purpose tools have been integrated into the Clinica software package\n(www.clinica.run) and the paper-specific code is available at:\nhttps://github.com/aramis-lab/AD-ML.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 17:11:28 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 14:20:37 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 00:36:19 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 15:07:45 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Wen", "Junhao", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Samper-Gonzalez", "Jorge", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Bottani", "Simona", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Routier", "Alexandre", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Burgos", "Ninon", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Jacquemont", "Thomas", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Fontanella", "Sabrina", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Durrleman", "Stanley", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Epelbaum", "Stephane", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Bertrand", "Anne", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"], ["Colliot", "Olivier", "", "for the Alzheimers Disease\n  Neuroimaging Initiative"]]}, {"id": "1812.11212", "submitter": "Jatin Kumar", "authors": "Jatin N. Kumar, Qianxiao Li, Karen Y.T. Tang, Tonio Buonassisi, Anibal\n  L. Gonzalez-Oyarce, Jun Ye", "title": "Machine learning enables polymer cloud-point engineering via inverse\n  design", "comments": "27 pages made up of main article and electronic supplementary\n  information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.mtrl-sci cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse design is an outstanding challenge in disordered systems with\nmultiple length scales such as polymers, particularly when designing polymers\nwith desired phase behavior. We demonstrate high-accuracy tuning of\npoly(2-oxazoline) cloud point via machine learning. With a design space of four\nrepeating units and a range of molecular masses, we achieve an accuracy of 4\n{\\deg}C root mean squared error (RMSE) in a temperature range of 24-90 {\\deg}C,\nemploying gradient boosting with decision trees. The RMSE is >3x better than\nlinear and polynomial regression. We perform inverse design via particle-swarm\noptimization, predicting and synthesizing 17 polymers with constrained design\nat 4 target cloud points from 37 to 80 {\\deg}C. Our approach challenges the\nstatus quo in polymer design with a machine learning algorithm, that is capable\nof fast and systematic discovery of new polymers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 06:41:26 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Kumar", "Jatin N.", ""], ["Li", "Qianxiao", ""], ["Tang", "Karen Y. T.", ""], ["Buonassisi", "Tonio", ""], ["Gonzalez-Oyarce", "Anibal L.", ""], ["Ye", "Jun", ""]]}, {"id": "1812.11214", "submitter": "Eugene Belilovsky", "authors": "Mathieu Andreux, Tom\\'as Angles, Georgios Exarchakis, Roberto\n  Leonarduzzi, Gaspar Rochette, Louis Thiry, John Zarka, St\\'ephane Mallat,\n  Joakim And\\'en, Eugene Belilovsky, Joan Bruna, Vincent Lostanlen, Matthew J.\n  Hirn, Edouard Oyallon, Sixin Zhang, Carmine Cella, Michael Eickenberg", "title": "Kymatio: Scattering Transforms in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The wavelet scattering transform is an invariant signal representation\nsuitable for many signal processing and machine learning applications. We\npresent the Kymatio software package, an easy-to-use, high-performance Python\nimplementation of the scattering transform in 1D, 2D, and 3D that is compatible\nwith modern deep learning frameworks. All transforms may be executed on a GPU\n(in addition to CPU), offering a considerable speed up over CPU\nimplementations. The package also has a small memory footprint, resulting\ninefficient memory usage. The source code, documentation, and examples are\navailable undera BSD license at https://www.kymat.io/\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 20:53:29 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 06:00:28 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Andreux", "Mathieu", ""], ["Angles", "Tom\u00e1s", ""], ["Exarchakis", "Georgios", ""], ["Leonarduzzi", "Roberto", ""], ["Rochette", "Gaspar", ""], ["Thiry", "Louis", ""], ["Zarka", "John", ""], ["Mallat", "St\u00e9phane", ""], ["And\u00e9n", "Joakim", ""], ["Belilovsky", "Eugene", ""], ["Bruna", "Joan", ""], ["Lostanlen", "Vincent", ""], ["Hirn", "Matthew J.", ""], ["Oyallon", "Edouard", ""], ["Zhang", "Sixin", ""], ["Cella", "Carmine", ""], ["Eickenberg", "Michael", ""]]}, {"id": "1812.11240", "submitter": "Norman Tasfi", "authors": "Norman Tasfi and Miriam Capretz", "title": "Dynamic Planning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Dynamic Planning Networks (DPN), a novel architecture for deep\nreinforcement learning, that combines model-based and model-free aspects for\nonline planning. Our architecture learns to dynamically construct plans using a\nlearned state-transition model by selecting and traversing between simulated\nstates and actions to maximize information before acting. In contrast to\nmodel-free methods, model-based planning lets the agent efficiently test action\nhypotheses without performing costly trial-and-error in the environment. DPN\nlearns to efficiently form plans by expanding a single action-conditional state\ntransition at a time instead of exhaustively evaluating each action, reducing\nthe required number of state-transitions during planning by up to 96%. We\nobserve various emergent planning patterns used to solve environments,\nincluding classical search methods such as breadth-first and depth-first\nsearch. DPN shows improved data efficiency, performance, and generalization to\nnew and unseen domains in comparison to several baselines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 22:37:30 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 15:15:44 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tasfi", "Norman", ""], ["Capretz", "Miriam", ""]]}, {"id": "1812.11262", "submitter": "Lianfa Li", "authors": "Lianfa Li, Ying Fang, Jun Wu, Jinfeng Wang", "title": "Autoencoder Based Residual Deep Networks for Robust Regression\n  Prediction and Spatiotemporal Estimation", "comments": "including supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To have a superior generalization, a deep learning neural network often\ninvolves a large size of training sample. With increase of hidden layers in\norder to increase learning ability, neural network has potential degradation in\naccuracy. Both could seriously limit applicability of deep learning in some\ndomains particularly involving predictions of continuous variables with a small\nsize of samples. Inspired by residual convolutional neural network in computer\nvision and recent findings of crucial shortcuts in the brains in neuroscience,\nwe propose an autoencoder-based residual deep network for robust prediction. In\na nested way, we leverage shortcut connections to implement residual mapping\nwith a balanced structure for efficient propagation of error signals. The novel\nmethod is demonstrated by multiple datasets, imputation of high spatiotemporal\nresolution non-randomness missing values of aerosol optical depth, and\nspatiotemporal estimation of fine particulate matter <2.5 \\mu m, achieving the\ncutting edge of accuracy and efficiency. Our approach is also a general-purpose\nregression learner to be applicable in diverse domains.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 01:43:53 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Li", "Lianfa", ""], ["Fang", "Ying", ""], ["Wu", "Jun", ""], ["Wang", "Jinfeng", ""]]}, {"id": "1812.11276", "submitter": "Song Bai", "authors": "Zhao Yang and Song Bai and Li Zhang and Philip H.S. Torr", "title": "Learn to Interpret Atari Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DeepRL) agents surpass human-level performances\nin a multitude of tasks. However, the direct mapping from states to actions\nmakes it hard to interpret the rationale behind the decision making of agents.\nIn contrast to previous a-posteriori methods of visualizing DeepRL policies, we\npropose an end-to-end trainable framework based on Rainbow, a representative\nDeep Q-Network (DQN) agent. Our method automatically learns important regions\nin the input domain, which enables characterizations of the decision making and\ninterpretations for non-intuitive behaviors. Hence we name it Region Sensitive\nRainbow (RS-Rainbow). RS-Rainbow utilizes a simple yet effective mechanism to\nincorporate visualization ability into the learning model, not only improving\nmodel interpretability, but leading to improved performance. Extensive\nexperiments on the challenging platform of Atari 2600 demonstrate the\nsuperiority of RS-Rainbow. In particular, our agent achieves state of the art\nat just 25% of the training frames. Demonstrations and code are available at\nhttps://github.com/yz93/Learn-to-Interpret-Atari-Agents.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 03:35:32 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 21:58:22 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Yang", "Zhao", ""], ["Bai", "Song", ""], ["Zhang", "Li", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1812.11295", "submitter": "Jianqiao Wangni", "authors": "Jianqiao Wangni, Dahua Lin, Ji Liu, Kostas Daniilidis, Jianbo Shi", "title": "Monocular 3D Pose Recovery via Nonconvex Sparsity with Theoretical\n  Analysis", "comments": "Partially overlap with arXiv:1711.02857, which targeted different\n  applications and will not be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For recovering 3D object poses from 2D images, a prevalent method is to\npre-train an over-complete dictionary $\\mathcal D=\\{B_i\\}_i^D$ of 3D basis\nposes. During testing, the detected 2D pose $Y$ is matched to dictionary by $Y\n\\approx \\sum_i M_i B_i$ where $\\{M_i\\}_i^D=\\{c_i \\Pi R_i\\}$, by estimating the\nrotation $R_i$, projection $\\Pi$ and sparse combination coefficients $c \\in\n\\mathbb R_{+}^D$. In this paper, we propose non-convex regularization $H(c)$ to\nlearn coefficients $c$, including novel leaky capped $\\ell_1$-norm\nregularization (LCNR), \\begin{align*} H(c)=\\alpha \\sum_{i } \\min(|c_i|,\\tau)+\n\\beta \\sum_{i } \\max(| c_i|,\\tau), \\end{align*} where $0\\leq \\beta \\leq \\alpha$\nand $0<\\tau$ is a certain threshold, so the invalid components smaller than\n$\\tau$ are composed with larger regularization and other valid components with\nsmaller regularization. We propose a multi-stage optimizer with convex\nrelaxation and ADMM. We prove that the estimation error $\\mathcal L(l)$ decays\nw.r.t. the stages $l$, \\begin{align*} Pr\\left(\\mathcal L(l) < \\rho^{l-1}\n\\mathcal L(0) + \\delta \\right) \\geq 1- \\epsilon, \\end{align*} where $0< \\rho\n<1, 0<\\delta, 0<\\epsilon \\ll 1$. Experiments on large 3D human datasets like\nH36M are conducted to support our improvement upon previous approaches. To the\nbest of our knowledge, this is the first theoretical analysis in this line of\nresearch, to understand how the recovery error is affected by fundamental\nfactors, e.g. dictionary size, observation noises, optimization times. We\ncharacterize the trade-off between speed and accuracy towards real-time\ninference in applications.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 06:23:11 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Wangni", "Jianqiao", ""], ["Lin", "Dahua", ""], ["Liu", "Ji", ""], ["Daniilidis", "Kostas", ""], ["Shi", "Jianbo", ""]]}, {"id": "1812.11305", "submitter": "Dan Wang", "authors": "Dan Wang, Mengqi Ji, Yong Wang, Haoqian Wang, Lu Fang", "title": "SPI-Optimizer: an integral-Separated PI Controller for Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To overcome the oscillation problem in the classical momentum-based\noptimizer, recent work associates it with the proportional-integral (PI)\ncontroller, and artificially adds D term producing a PID controller. It\nsuppresses oscillation with the sacrifice of introducing extra hyper-parameter.\nIn this paper, we start by analyzing: why momentum-based method oscillates\nabout the optimal point? and answering that: the fluctuation problem relates to\nthe lag effect of integral (I) term. Inspired by the conditional integration\nidea in classical control society, we propose SPI-Optimizer, an\nintegral-Separated PI controller based optimizer WITHOUT introducing extra\nhyperparameter. It separates momentum term adaptively when the inconsistency of\ncurrent and historical gradient direction occurs. Extensive experiments\ndemonstrate that SPIOptimizer generalizes well on popular network architectures\nto eliminate the oscillation, and owns competitive performance with faster\nconvergence speed (up to 40% epochs reduction ratio ) and more accurate\nclassification result on MNIST, CIFAR10, and CIFAR100 (up to 27.5% error\nreduction ratio) than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 07:41:57 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 04:54:01 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Wang", "Dan", ""], ["Ji", "Mengqi", ""], ["Wang", "Yong", ""], ["Wang", "Haoqian", ""], ["Fang", "Lu", ""]]}, {"id": "1812.11314", "submitter": "Kehan Yang", "authors": "Yiming Shen, Kehan Yang, Yufeng Yuan and Simon Cheng Liu", "title": "Meta Reinforcement Learning with Distribution of Exploration Parameters\n  Learned by Evolution Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel meta-learning method in a reinforcement\nlearning setting, based on evolution strategies (ES), exploration in parameter\nspace and deterministic policy gradients. ES methods are easy to parallelize,\nwhich is desirable for modern training architectures; however, such methods\ntypically require a huge number of samples for effective training. We use\ndeterministic policy gradients during adaptation and other techniques to\ncompensate for the sample-efficiency problem while maintaining the inherent\nscalability of ES methods. We demonstrate that our method achieves good results\ncompared to gradient-based meta-learning in high-dimensional control tasks in\nthe MuJoCo simulator. In addition, because of gradient-free methods in the\nmeta-training phase, which do not need information about gradients and policies\nin adaptation training, we predict and confirm our algorithm performs better in\ntasks that need multi-step adaptation.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 08:40:38 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 07:32:06 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Shen", "Yiming", ""], ["Yang", "Kehan", ""], ["Yuan", "Yufeng", ""], ["Liu", "Simon Cheng", ""]]}, {"id": "1812.11377", "submitter": "Haishan Ye", "authors": "Haishan Ye, Zhichao Huang, Cong Fang, Chris Junchi Li, Tong Zhang", "title": "Hessian-Aware Zeroth-Order Optimization for Black-Box Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Zeroth-order optimization is an important research topic in machine learning.\nIn recent years, it has become a key tool in black-box adversarial attack to\nneural network based image classifiers. However, existing zeroth-order\noptimization algorithms rarely extract second-order information of the model\nfunction. In this paper, we utilize the second-order information of the\nobjective function and propose a novel \\textit{Hessian-aware zeroth-order\nalgorithm} called \\texttt{ZO-HessAware}. Our theoretical result shows that\n\\texttt{ZO-HessAware} has an improved zeroth-order convergence rate and query\ncomplexity under structured Hessian approximation, where we propose a few\napproximation methods for estimating Hessian. Our empirical studies on the\nblack-box adversarial attack problem validate that our algorithm can achieve\nimproved success rates with a lower query complexity.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 15:18:58 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 09:19:44 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Ye", "Haishan", ""], ["Huang", "Zhichao", ""], ["Fang", "Cong", ""], ["Li", "Chris Junchi", ""], ["Zhang", "Tong", ""]]}, {"id": "1812.11409", "submitter": "Aude Sportisse", "authors": "Aude Sportisse (LPSM (UMR\\_8001), CMAP), Claire Boyer (LPSM\n  (UMR\\_8001), DMA), Julie Josse (CMAP, XPOP)", "title": "Imputation and low-rank estimation with Missing Not At Random data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing values challenge data analysis because many supervised and\nunsupervised learning methods cannot be applied directly to incomplete data.\nMatrix completion based on low-rank assumptions are very powerful solution for\ndealing with missing values. However, existing methods do not consider the case\nof informative missing values which are widely encountered in practice. This\npaper proposes matrix completion methods to recover Missing Not At Random\n(MNAR) data. Our first contribution is to suggest a model-based estimation\nstrategy by modelling the missing mechanism distribution. An EM algorithm is\nthen implemented, involving a Fast Iterative Soft-Thresholding Algorithm\n(FISTA). Our second contribution is to suggest a computationally efficient\nsurrogate estimation by implicitly taking into account the joint distribution\nof the data and the missing mechanism: the data matrix is concatenated with the\nmask coding for the missing values; a low-rank structure for exponential family\nis assumed on this new matrix, in order to encode links between variables and\nmissing mechanisms. The methodology that has the great advantage of handling\ndifferent missing value mechanisms is robust to model specification errors.The\nperformances of our methods are assessed on the real data collected from a\ntrauma registry (TraumaBase ) containing clinical information about over twenty\nthousand severely traumatized patients in France. The aim is then to predict if\nthe doctors should administrate tranexomic acid to patients with traumatic\nbrain injury, that would limit excessive bleeding.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 17:51:34 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 11:43:33 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 08:16:16 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Sportisse", "Aude", "", "LPSM"], ["Boyer", "Claire", "", "LPSM"], ["Josse", "Julie", "", "CMAP, XPOP"]]}, {"id": "1812.11422", "submitter": "Bibek Paudel", "authors": "Bibek Paudel, Sandro Luck, Abraham Bernstein", "title": "Loss Aversion in Recommender Systems: Utilizing Negative User Preference\n  to Improve Recommendation Quality", "comments": "The First International Workshop on Context-Aware Recommendation\n  Systems with Big Data Analytics (CARS-BDA), co-organized with the 12th ACM\n  International Conference on Web Search and Data Mining, 2019, Melbourne,\n  Australia", "journal-ref": "CARS-BDA, at the 12th ACM International Conference on Web Search\n  and Data Mining (WSDM), 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negative user preference is an important context that is not sufficiently\nutilized by many existing recommender systems. This context is especially\nuseful in scenarios where the cost of negative items is high for the users. In\nthis work, we describe a new recommender algorithm that explicitly models\nnegative user preferences in order to recommend more positive items at the top\nof recommendation-lists. We build upon existing machine-learning model to\nincorporate the contextual information provided by negative user preference.\nWith experimental evaluations on two openly available datasets, we show that\nour method is able to improve recommendation quality: by improving accuracy and\nat the same time reducing the number of negative items at the top of\nrecommendation-lists. Our work demonstrates the value of the contextual\ninformation provided by negative feedback, and can also be extended to signed\nsocial networks and link prediction in other networks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 18:49:13 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Paudel", "Bibek", ""], ["Luck", "Sandro", ""], ["Bernstein", "Abraham", ""]]}, {"id": "1812.11440", "submitter": "Veronica Vilaplana", "authors": "Irina Sanchez and Veronica Vilaplana", "title": "Brain MRI super-resolution using 3D generative adversarial networks", "comments": "First International Conference on Medical Imaging with Deep Learning,\n  Amsterdam, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose an adversarial learning approach to generate high\nresolution MRI scans from low resolution images. The architecture, based on the\nSRGAN model, adopts 3D convolutions to exploit volumetric information. For the\ndiscriminator, the adversarial loss uses least squares in order to stabilize\nthe training. For the generator, the loss function is a combination of a least\nsquares adversarial loss and a content term based on mean square error and\nimage gradients in order to improve the quality of the generated images. We\nexplore different solutions for the upsampling phase. We present promising\nresults that improve classical interpolation, showing the potential of the\napproach for 3D medical imaging super-resolution. Source code available at\nhttps://github.com/imatge-upc/3D-GAN-superresolution\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 22:19:00 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Sanchez", "Irina", ""], ["Vilaplana", "Veronica", ""]]}, {"id": "1812.11444", "submitter": "Tianle Chen", "authors": "Tianle Chen, Brian Keng, Javier Moreno", "title": "Multivariate Arrival Times with Recurrent Neural Networks for\n  Personalized Demand Forecasting", "comments": "Presented at ICDM DMS Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to a large variety of data across a massive population has made it\npossible to predict customer purchase patterns and responses to marketing\ncampaigns. In particular, accurate demand forecasts for popular products with\nfrequent repeat purchases are essential since these products are one of the\nmain drivers of profits. However, buyer purchase patterns are extremely diverse\nand sparse on a per-product level due to population heterogeneity as well as\ndependence in purchase patterns across product categories. Traditional methods\nin survival analysis have proven effective in dealing with censored data by\nassuming parametric distributions on inter-arrival times. Distributional\nparameters are then fitted, typically in a regression framework. On the other\nhand, neural-network based models take a non-parametric approach to learn\nrelations from a larger functional class. However, the lack of distributional\nassumptions make it difficult to model partially observed data. In this paper,\nwe model directly the inter-arrival times as well as the partially observed\ninformation at each time step in a survival-based approach using Recurrent\nNeural Networks (RNN) to model purchase times jointly over several products.\nInstead of predicting a point estimate for inter-arrival times, the RNN outputs\nparameters that define a distributional estimate. The loss function is the\nnegative log-likelihood of these parameters given partially observed data. This\napproach allows one to leverage both fully observed data as well as partial\ninformation. By externalizing the censoring problem through a log-likelihood\nloss function, we show that substantial improvements over state-of-the-art\nmachine learning methods can be achieved. We present experimental results based\non two open datasets as well as a study on a real dataset from a large\nretailer.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 23:23:29 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Chen", "Tianle", ""], ["Keng", "Brian", ""], ["Moreno", "Javier", ""]]}, {"id": "1812.11446", "submitter": "Eugene Belilovsky", "authors": "Eugene Belilovsky, Michael Eickenberg, Edouard Oyallon", "title": "Greedy Layerwise Learning Can Scale to ImageNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Shallow supervised 1-hidden layer neural networks have a number of favorable\nproperties that make them easier to interpret, analyze, and optimize than their\ndeep counterparts, but lack their representational power. Here we use 1-hidden\nlayer learning problems to sequentially build deep networks layer by layer,\nwhich can inherit properties from shallow networks. Contrary to previous\napproaches using shallow networks, we focus on problems where deep learning is\nreported as critical for success. We thus study CNNs on image classification\ntasks using the large-scale ImageNet dataset and the CIFAR-10 dataset. Using a\nsimple set of ideas for architecture and training we find that solving\nsequential 1-hidden-layer auxiliary problems lead to a CNN that exceeds AlexNet\nperformance on ImageNet. Extending this training methodology to construct\nindividual layers by solving 2-and-3-hidden layer auxiliary problems, we obtain\nan 11-layer network that exceeds several members of the VGG model family on\nImageNet, and can train a VGG-11 model to the same accuracy as end-to-end\nlearning. To our knowledge, this is the first competitive alternative to\nend-to-end training of CNNs that can scale to ImageNet. We illustrate several\ninteresting properties of these models theoretically and conduct a range of\nexperiments to study the properties this training induces on the intermediate\nlayers.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 23:31:50 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 06:00:15 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 17:43:48 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Belilovsky", "Eugene", ""], ["Eickenberg", "Michael", ""], ["Oyallon", "Edouard", ""]]}, {"id": "1812.11466", "submitter": "Salar Fattahi", "authors": "Salar Fattahi and Somayeh Sojoudi", "title": "Exact Guarantees on the Absence of Spurious Local Minima for\n  Non-negative Rank-1 Robust Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is concerned with the non-negative rank-1 robust principal\ncomponent analysis (RPCA), where the goal is to recover the dominant\nnon-negative principal components of a data matrix precisely, where a number of\nmeasurements could be grossly corrupted with sparse and arbitrary large noise.\nMost of the known techniques for solving the RPCA rely on convex relaxation\nmethods by lifting the problem to a higher dimension, which significantly\nincrease the number of variables. As an alternative, the well-known\nBurer-Monteiro approach can be used to cast the RPCA as a non-convex and\nnon-smooth $\\ell_1$ optimization problem with a significantly smaller number of\nvariables. In this work, we show that the low-dimensional formulation of the\nsymmetric and asymmetric positive rank-1 RPCA based on the Burer-Monteiro\napproach has benign landscape, i.e., 1) it does not have any spurious local\nsolution, 2) has a unique global solution, and 3) its unique global solution\ncoincides with the true components. An implication of this result is that\nsimple local search algorithms are guaranteed to achieve a zero global\noptimality gap when directly applied to the low-dimensional formulation.\nFurthermore, we provide strong deterministic and probabilistic guarantees for\nthe exact recovery of the true principal components. In particular, it is shown\nthat a constant fraction of the measurements could be grossly corrupted and yet\nthey would not create any spurious local solution.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 04:06:40 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 22:22:54 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Fattahi", "Salar", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1812.11473", "submitter": "Hajar Falahati", "authors": "Hajar Falahati and Pejman Lotfi-Kamran and Mohammad Sadrosadati and\n  Hamid Sarbazi-Azad", "title": "ORIGAMI: A Heterogeneous Split Architecture for In-Memory Acceleration\n  of Learning", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory bandwidth bottleneck is a major challenges in processing machine\nlearning (ML) algorithms. In-memory acceleration has potential to address this\nproblem; however, it needs to address two challenges. First, in-memory\naccelerator should be general enough to support a large set of different ML\nalgorithms. Second, it should be efficient enough to utilize bandwidth while\nmeeting limited power and area budgets of logic layer of a 3D-stacked memory.\nWe observe that previous work fails to simultaneously address both challenges.\nWe propose ORIGAMI, a heterogeneous set of in-memory accelerators, to support\ncompute demands of different ML algorithms, and also uses an off-the-shelf\ncompute platform (e.g.,FPGA,GPU,TPU,etc.) to utilize bandwidth without\nviolating strict area and power budgets. ORIGAMI offers a pattern-matching\ntechnique to identify similar computation patterns of ML algorithms and\nextracts a compute engine for each pattern. These compute engines constitute\nheterogeneous accelerators integrated on logic layer of a 3D-stacked memory.\nCombination of these compute engines can execute any type of ML algorithms. To\nutilize available bandwidth without violating area and power budgets of logic\nlayer, ORIGAMI comes with a computation-splitting compiler that divides an ML\nalgorithm between in-memory accelerators and an out-of-the-memory platform in a\nbalanced way and with minimum inter-communications. Combination of pattern\nmatching and split execution offers a new design point for acceleration of ML\nalgorithms. Evaluation results across 12 popular ML algorithms show that\nORIGAMI outperforms state-of-the-art accelerator with 3D-stacked memory in\nterms of performance and energy-delay product (EDP) by 1.5x and 29x (up to 1.6x\nand 31x), respectively. Furthermore, results are within a 1% margin of an ideal\nsystem that has unlimited compute resources on logic layer of a 3D-stacked\nmemory.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 05:59:07 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 12:02:18 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Falahati", "Hajar", ""], ["Lotfi-Kamran", "Pejman", ""], ["Sadrosadati", "Mohammad", ""], ["Sarbazi-Azad", "Hamid", ""]]}, {"id": "1812.11477", "submitter": "Meenakshi Khosla", "authors": "Meenakshi Khosla, Keith Jamison, Gia H. Ngo, Amy Kuceyeski and Mert R.\n  Sabuncu", "title": "Machine learning in resting-state fMRI analysis", "comments": "51 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have gained prominence for the analysis of\nresting-state functional Magnetic Resonance Imaging (rs-fMRI) data. Here, we\npresent an overview of various unsupervised and supervised machine learning\napplications to rs-fMRI. We present a methodical taxonomy of machine learning\nmethods in resting-state fMRI. We identify three major divisions of\nunsupervised learning methods with regard to their applications to rs-fMRI,\nbased on whether they discover principal modes of variation across space, time\nor population. Next, we survey the algorithms and rs-fMRI feature\nrepresentations that have driven the success of supervised subject-level\npredictions. The goal is to provide a high-level overview of the burgeoning\nfield of rs-fMRI from the perspective of machine learning applications.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 06:37:46 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Khosla", "Meenakshi", ""], ["Jamison", "Keith", ""], ["Ngo", "Gia H.", ""], ["Kuceyeski", "Amy", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1812.11526", "submitter": "Umit Buyuksahin", "authors": "\\\"Umit \\c{C}avu\\c{s} B\\\"uy\\\"uk\\c{s}ahin, \\c{S}eyda Ertekin", "title": "Improving forecasting accuracy of time series data using a new ARIMA-ANN\n  hybrid method and empirical mode decomposition", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.05.099", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications in different domains produce large amount of time series\ndata. Making accurate forecasting is critical for many decision makers. Various\ntime series forecasting methods exist which use linear and nonlinear models\nseparately or combination of both. Studies show that combining of linear and\nnonlinear models can be effective to improve forecasting performance. However,\nsome assumptions that those existing methods make, might restrict their\nperformance in certain situations. We provide a new Autoregressive Integrated\nMoving Average (ARIMA)-Artificial Neural Network(ANN) hybrid method that work\nin a more general framework. Experimental results show that strategies for\ndecomposing the original data and for combining linear and nonlinear models\nthroughout the hybridization process are key factors in the forecasting\nperformance of the methods. By using appropriate strategies, our hybrid method\ncan be an effective way to improve forecasting accuracy obtained by traditional\nhybrid methods and also either of the individual methods used separately.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 13:07:07 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["B\u00fcy\u00fck\u015fahin", "\u00dcmit \u00c7avu\u015f", ""], ["Ertekin", "\u015eeyda", ""]]}, {"id": "1812.11527", "submitter": "Luca Pedrelli", "authors": "Claudio Gallicchio, Alessio Micheli, Luca Pedrelli", "title": "Comparison between DeepESNs and gated RNNs on multivariate time-series\n  prediction", "comments": "Preprint version of Claudio Gallicchio, Alessio Micheli and Luca\n  Pedrelli (2019) Comparison between DeepESNs and gated RNNs on multivariate\n  time-series prediction. In: ESANN 2019 proceedings, European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning.\n  Bruges (Belgium), 24-26 April 2019, i6doc.com publ., ISBN 978-287-587-065-0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an experimental comparison between Deep Echo State Networks\n(DeepESNs) and gated Recurrent Neural Networks (RNNs) on multivariate\ntime-series prediction tasks. In particular, we compare reservoir and\nfully-trained RNNs able to represent signals featured by multiple time-scales\ndynamics. The analysis is performed in terms of efficiency and prediction\naccuracy on 4 polyphonic music tasks. Our results show that DeepESN is able to\noutperform ESN in terms of prediction accuracy and efficiency. Whereas, between\nfully-trained approaches, Gated Recurrent Units (GRU) outperforms Long\nShort-Term Memory (LSTM) and simple RNN models in most cases. Overall, DeepESN\nturned out to be extremely more efficient than others RNN approaches and the\nbest solution in terms of prediction accuracy on 3 out of 4 tasks.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 13:13:16 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:49:23 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""], ["Pedrelli", "Luca", ""]]}, {"id": "1812.11555", "submitter": "Yiyuan She", "authors": "Yiyuan She and Hoang Tran", "title": "On Cross-validation for Sparse Reduced Rank Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-dimensional data analysis, regularization methods pursuing sparsity\nand/or low rank have received a lot of attention recently. To provide a proper\namount of shrinkage, it is typical to use a grid search and a model comparison\ncriterion to find the optimal regularization parameters. However, we show that\nfixing the parameters across all folds may result in an inconsistency issue,\nand it is more appropriate to cross-validate projection-selection patterns to\nobtain the best coefficient estimate. Our in-sample error studies in jointly\nsparse and rank-deficient models lead to a new class of information criteria\nwith four scale-free forms to bypass the estimation of the noise level. By use\nof an identity, we propose a novel scale-free calibration to help\ncross-validation achieve the minimax optimal error rate non-asymptotically.\nExperiments support the efficacy of the proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 15:24:40 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["She", "Yiyuan", ""], ["Tran", "Hoang", ""]]}, {"id": "1812.11560", "submitter": "Veronica Vilaplana", "authors": "Marc Combalia and Veronica Vilaplana", "title": "Monte-Carlo Sampling applied to Multiple Instance Learning for\n  Histological Image Classification", "comments": "accepted at 4th International Workshop on Deep Learning for Medical\n  Image Analysis (DLMIA), MICCAI 2018, Deep Learning in Medical Image Analysis\n  and Multimodal Learning for Clinical Decision Support, Springer International\n  Publishing, 2018", "journal-ref": null, "doi": "10.1007/978-3-030-00889-5", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a patch sampling strategy based on a sequential Monte-Carlo method\nfor high resolution image classification in the context of Multiple Instance\nLearning. When compared with grid sampling and uniform sampling techniques, it\nachieves higher generalization performance. We validate the strategy on two\nartificial datasets and two histological datasets for breast cancer and sun\nexposure classification.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 15:38:25 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Combalia", "Marc", ""], ["Vilaplana", "Veronica", ""]]}, {"id": "1812.11588", "submitter": "Veronica Vilaplana", "authors": "Adri\\`a Casamitjana, Marcel Cat\\`a, Irina S\\'anchez, Marc Combalia and\n  Ver\\'onica Vilaplana", "title": "Cascaded V-Net using ROI masks for brain tumor segmentation", "comments": "Third International Workshop, BrainLes 2017, Held in Conjunction with\n  MICCAI 2017, Quebec City, QC, Canada, September 14, 2017, Revised Selected\n  Papers", "journal-ref": "Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic\n  Brain Injuries, Series volume 10670, 2018, Springer International Publishing\n  AG, part of Springer Nature", "doi": "10.1007/978-3-319-75238-9", "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we approach the brain tumor segmentation problem with a cascade\nof two CNNs inspired in the V-Net architecture \\cite{VNet}, reformulating\nresidual connections and making use of ROI masks to constrain the networks to\ntrain only on relevant voxels. This architecture allows dense training on\nproblems with highly skewed class distributions, such as brain tumor\nsegmentation, by focusing training only on the vecinity of the tumor area. We\nreport results on BraTS2017 Training and Validation sets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 18:51:37 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Casamitjana", "Adri\u00e0", ""], ["Cat\u00e0", "Marcel", ""], ["S\u00e1nchez", "Irina", ""], ["Combalia", "Marc", ""], ["Vilaplana", "Ver\u00f3nica", ""]]}, {"id": "1812.11651", "submitter": "Sumit Darak Dr", "authors": "Sumit J Darak and Manjesh K. Hanawal", "title": "Multi-player Multi-armed Bandits for Stable Allocation in Heterogeneous\n  Ad-Hoc Networks", "comments": "Accepted in IEEE JSAC Special Issue on Machine Learning in Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation networks are expected to be ultradense and aim to explore\nspectrum sharing paradigm that allows users to communicate in licensed, shared\nas well as unlicensed spectrum. Such ultra-dense networks will incur\nsignificant signaling load at base stations leading to a negative effect on\nspectrum and energy efficiency. To minimize signaling overhead, an adhoc\napproach is being considered for users communicating in the unlicensed and\nshared spectrums. For such users, decisions need to be completely decentralized\nas: 1) No communication between users and signaling from the base station is\npossible which necessitates independent channel selection at each user. A\ncollision occurs when multiple users transmit simultaneously on the same\nchannel, 2) Channel qualities may be heterogeneous, i.e., they are not same\nacross all users, and moreover, are unknown, and 3) The network could be\ndynamic where users can enter or leave anytime. We develop a multi-armed bandit\nbased distributed algorithm for static networks and extend it for the dynamic\nnetworks. The algorithms aim to achieve stable orthogonal allocation (SOC) in\nfinite time and meet the above three constraints with two novel\ncharacteristics: 1) Low complexity narrowband radio compared to wideband radio\nin existing works, and 2) Epoch-less approach for dynamic networks. We\nestablish a convergence of our algorithms to SOC and validate via extensive\nsimulation experiments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 12:29:35 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 18:20:31 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Darak", "Sumit J", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "1812.11652", "submitter": "Salman Memon", "authors": "Salman Memon and Muthucumaru Maheswaran", "title": "Using Machine Learning for Handover Optimization in Vehicular Fog\n  Computing", "comments": null, "journal-ref": null, "doi": "10.1145/3297280.3297300", "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart mobility management would be an important prerequisite for future fog\ncomputing systems. In this research, we propose a learning-based handover\noptimization for the Internet of Vehicles that would assist the smooth\ntransition of device connections and offloaded tasks between fog nodes. To\naccomplish this, we make use of machine learning algorithms to learn from\nvehicle interactions with fog nodes. Our approach uses a three-layer\nfeed-forward neural network to predict the correct fog node at a given location\nand time with 99.2 % accuracy on a test set. We also implement a dual stacked\nrecurrent neural network (RNN) with long short-term memory (LSTM) cells capable\nof learning the latency, or cost, associated with these service requests. We\ncreate a simulation in JAMScript using a dataset of real-world vehicle\nmovements to create a dataset to train these networks. We further propose the\nuse of this predictive system in a smarter request routing mechanism to\nminimize the service interruption during handovers between fog nodes and to\nanticipate areas of low coverage through a series of experiments and test the\nmodels' performance on a test set.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 06:02:15 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Memon", "Salman", ""], ["Maheswaran", "Muthucumaru", ""]]}, {"id": "1812.11670", "submitter": "Yulin Liu", "authors": "Yulin Liu and Mark Hansen", "title": "Predicting Aircraft Trajectories: A Deep Generative Convolutional\n  Recurrent Neural Networks Approach", "comments": "24 pages, 11 figures, 1 table. Source code available at\n  https://github.com/yulinliu101/DeepTP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable 4D aircraft trajectory prediction, whether in a real-time setting or\nfor analysis of counterfactuals, is important to the efficiency of the aviation\nsystem. Toward this end, we first propose a highly generalizable efficient\ntree-based matching algorithm to construct image-like feature maps from\nhigh-fidelity meteorological datasets - wind, temperature and convective\nweather. We then model the track points on trajectories as conditional Gaussian\nmixtures with parameters to be learned from our proposed deep generative model,\nwhich is an end-to-end convolutional recurrent neural network that consists of\na long short-term memory (LSTM) encoder network and a mixture density LSTM\ndecoder network. The encoder network embeds last-filed flight plan information\ninto fixed-size hidden state variables and feeds the decoder network, which\nfurther learns the spatiotemporal correlations from the historical flight\ntracks and outputs the parameters of Gaussian mixtures. Convolutional layers\nare integrated into the pipeline to learn representations from the\nhigh-dimension weather features. During the inference process, beam search,\nadaptive Kalman filter, and Rauch-Tung-Striebel smoother algorithms are used to\nprune the variance of generated trajectories.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 02:11:31 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Liu", "Yulin", ""], ["Hansen", "Mark", ""]]}, {"id": "1812.11675", "submitter": "Fenglei Fan", "authors": "Fenglei Fan, Mengzhou Li, Yueyang Teng, Ge Wang", "title": "Soft Autoencoder and Its Wavelet Adaptation Interpretation", "comments": "This manuscript is out-of-date", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning becomes the main focus of machine learning research\nand has greatly impacted many important fields. However, deep learning is\ncriticized for lack of interpretability. As a successful unsupervised model in\ndeep learning, the autoencoder embraces a wide spectrum of applications, yet it\nsuffers from the model opaqueness as well. In this paper, we propose a new type\nof convolutional autoencoders, termed as Soft Autoencoder (Soft-AE), in which\nthe activation functions of encoding layers are implemented with adaptable\nsoft-thresholding units while decoding layers are realized with linear units.\nConsequently, Soft-AE can be naturally interpreted as a learned cascaded\nwavelet shrinkage system. Our denoising experiments demonstrate that Soft-AE\nnot only is interpretable but also offers a competitive performance relative to\nits counterparts. Furthermore, we propose a generalized linear unit (GenLU) to\nmake an autoencoder more adaptive in nonlinearly filtering images and data,\nsuch as denoising and deblurring.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 02:20:05 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 01:44:15 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 15:24:07 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 02:54:30 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Fan", "Fenglei", ""], ["Li", "Mengzhou", ""], ["Teng", "Yueyang", ""], ["Wang", "Ge", ""]]}, {"id": "1812.11689", "submitter": "Donghui Yan", "authors": "Donghui Yan, Yingjie Wang, Jin Wang, Honggang Wang and Zhenpeng Li", "title": "K-nearest Neighbor Search by Random Projection Forests", "comments": "15 pages, 4 figures, 2018 IEEE Big Data Conference", "journal-ref": "IEEE International Conference on Big Data, 2018", "doi": "10.1109/BigData.2018.8622307", "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-nearest neighbor (kNN) search has wide applications in many areas,\nincluding data mining, machine learning, statistics and many applied domains.\nInspired by the success of ensemble methods and the flexibility of tree-based\nmethodology, we propose random projection forests (rpForests), for kNN search.\nrpForests finds kNNs by aggregating results from an ensemble of random\nprojection trees with each constructed recursively through a series of\ncarefully chosen random projections. rpForests achieves a remarkable accuracy\nin terms of fast decay in the missing rate of kNNs and that of discrepancy in\nthe kNN distances. rpForests has a very low computational complexity. The\nensemble nature of rpForests makes it easily run in parallel on multicore or\nclustered computers; the running time is expected to be nearly inversely\nproportional to the number of cores or machines. We give theoretical insights\nby showing the exponential decay of the probability that neighboring points\nwould be separated by ensemble random projection trees when the ensemble size\nincreases. Our theory can be used to refine the choice of random projections in\nthe growth of trees, and experiments show that the effect is remarkable.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 03:54:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Yan", "Donghui", ""], ["Wang", "Yingjie", ""], ["Wang", "Jin", ""], ["Wang", "Honggang", ""], ["Li", "Zhenpeng", ""]]}, {"id": "1812.11690", "submitter": "Max Ehrlich", "authors": "Max Ehrlich and Larry Davis", "title": "Deep Residual Learning in the JPEG Transform Domain", "comments": "Published in ICCV 2019. Code and notes are available on our website\n  at https://maxehr.umiacs.io/jpeg_domain_resnet/jpeg_domain_resnet_html.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general method of performing Residual Network inference and\nlearning in the JPEG transform domain that allows the network to consume\ncompressed images as input. Our formulation leverages the linearity of the JPEG\ntransform to redefine convolution and batch normalization with a tune-able\nnumerical approximation for ReLu. The result is mathematically equivalent to\nthe spatial domain network up to the ReLu approximation accuracy. A formulation\nfor image classification and a model conversion algorithm for spatial domain\nnetworks are given as examples of the method. We show that the sparsity of the\nJPEG format allows for faster processing of images with little to no penalty in\nthe network accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 03:55:09 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2019 20:40:37 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 14:41:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ehrlich", "Max", ""], ["Davis", "Larry", ""]]}, {"id": "1812.11731", "submitter": "Yuri G. Gordienko", "authors": "Yuriy Kochura, Yuri Gordienko, Vlad Taran, Nikita Gordienko, Alexandr\n  Rokovyi, Oleg Alienin, Sergii Stirenko", "title": "Batch Size Influence on Performance of Graphic and Tensor Processing\n  Units during Training and Inference Phases", "comments": "10 pages, 7 figures, 2 tables", "journal-ref": "Hu Z., Petoukhov S., Dychka I., He M. (eds) Advances in Computer\n  Science for Engineering and Education II. ICCSEEA 2019. Advances in\n  Intelligent Systems and Computing, vol 938 (pp. 658-668). Springer, Cham", "doi": "10.1007/978-3-030-16621-2_61", "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of the maximally possible batch size (for the better runtime) on\nperformance of graphic processing units (GPU) and tensor processing units (TPU)\nduring training and inference phases is investigated. The numerous runs of the\nselected deep neural network (DNN) were performed on the standard MNIST and\nFashion-MNIST datasets. The significant speedup was obtained even for extremely\nlow-scale usage of Google TPUv2 units (8 cores only) in comparison to the quite\npowerful GPU NVIDIA Tesla K80 card with the speedup up to 10x for training\nstage (without taking into account the overheads) and speedup up to 2x for\nprediction stage (with and without taking into account overheads). The precise\nspeedup values depend on the utilization level of TPUv2 units and increase with\nthe increase of the data volume under processing, but for the datasets used in\nthis work (MNIST and Fashion-MNIST with images of sizes 28x28) the speedup was\nobserved for batch sizes >512 images for training phase and >40 000 images for\nprediction phase. It should be noted that these results were obtained without\ndetriment to the prediction accuracy and loss that were equal for both GPU and\nTPU runs up to the 3rd significant digit for MNIST dataset, and up to the 2nd\nsignificant digit for Fashion-MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 09:24:36 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Kochura", "Yuriy", ""], ["Gordienko", "Yuri", ""], ["Taran", "Vlad", ""], ["Gordienko", "Nikita", ""], ["Rokovyi", "Alexandr", ""], ["Alienin", "Oleg", ""], ["Stirenko", "Sergii", ""]]}, {"id": "1812.11732", "submitter": "Charbel Sakr", "authors": "Charbel Sakr and Naresh Shanbhag", "title": "Per-Tensor Fixed-Point Quantization of the Back-Propagation Algorithm", "comments": "Published as a conference paper in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high computational and parameter complexity of neural networks makes\ntheir training very slow and difficult to deploy on energy and\nstorage-constrained computing systems. Many network complexity reduction\ntechniques have been proposed including fixed-point implementation. However, a\nsystematic approach for designing full fixed-point training and inference of\ndeep neural networks remains elusive. We describe a precision assignment\nmethodology for neural network training in which all network parameters, i.e.,\nactivations and weights in the feedforward path, gradients and weight\naccumulators in the feedback path, are assigned close to minimal precision. The\nprecision assignment is derived analytically and enables tracking the\nconvergence behavior of the full precision training, known to converge a\npriori. Thus, our work leads to a systematic methodology of determining\nsuitable precision for fixed-point training. The near optimality (minimality)\nof the resulting precision assignment is validated empirically for four\nnetworks on the CIFAR-10, CIFAR-100, and SVHN datasets. The complexity\nreduction arising from our approach is compared with other fixed-point neural\nnetwork designs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 09:30:54 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Sakr", "Charbel", ""], ["Shanbhag", "Naresh", ""]]}, {"id": "1812.11750", "submitter": "Kai Yang", "authors": "Kai Yang, Tao Jiang, Yuanming Shi, Zhi Ding", "title": "Federated Learning via Over-the-Air Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stringent requirements for low-latency and privacy of the emerging\nhigh-stake applications with intelligent devices such as drones and smart\nvehicles make the cloud computing inapplicable in these scenarios. Instead,\nedge machine learning becomes increasingly attractive for performing training\nand inference directly at network edges without sending data to a centralized\ndata center. This stimulates a nascent field termed as federated learning for\ntraining a machine learning model on computation, storage, energy and bandwidth\nlimited mobile devices in a distributed manner. To preserve data privacy and\naddress the issues of unbalanced and non-IID data points across different\ndevices, the federated averaging algorithm has been proposed for global model\naggregation by computing the weighted average of locally updated model at each\nselected device. However, the limited communication bandwidth becomes the main\nbottleneck for aggregating the locally computed updates. We thus propose a\nnovel over-the-air computation based approach for fast global model aggregation\nvia exploring the superposition property of a wireless multiple-access channel.\nThis is achieved by joint device selection and beamforming design, which is\nmodeled as a sparse and low-rank optimization problem to support efficient\nalgorithms design. To achieve this goal, we provide a\ndifference-of-convex-functions (DC) representation for the sparse and low-rank\nfunction to enhance sparsity and accurately detect the fixed-rank constraint in\nthe procedure of device selection. A DC algorithm is further developed to solve\nthe resulting DC program with global convergence guarantees. The algorithmic\nadvantages and admirable performance of the proposed methodologies are\ndemonstrated through extensive numerical results.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 10:29:57 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 04:05:49 GMT"}, {"version": "v3", "created": "Sun, 17 Feb 2019 18:27:28 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Yang", "Kai", ""], ["Jiang", "Tao", ""], ["Shi", "Yuanming", ""], ["Ding", "Zhi", ""]]}, {"id": "1812.11755", "submitter": "Daniel Tait", "authors": "Daniel J. Tait and Bruce J. Worton", "title": "Approximate Inference for Multiplicative Latent Force Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent force models are a class of hybrid models for dynamic systems,\ncombining simple mechanistic models with flexible Gaussian process (GP)\nperturbations. An extension of this framework to include multiplicative\ninteractions between the state and GP terms allows strong a priori control of\nthe model geometry at the expense of tractable inference. In this paper we\nconsider two methods of carrying out inference within this broader class of\nmodels. The first is based on an adaptive gradient matching approximation, and\nthe second is constructed around mixtures of local approximations to the\nsolution. We compare the performance of both methods on simulated data, and\nalso demonstrate an application of the multiplicative latent force model on\nmotion capture data.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 10:48:56 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Tait", "Daniel J.", ""], ["Worton", "Bruce J.", ""]]}, {"id": "1812.11780", "submitter": "F\\'abio Vin\\'icius Moreira Perez", "authors": "F\\'abio Perez, R\\'emi Lebret, Karl Aberer", "title": "Weakly Supervised Active Learning with Cluster Annotation", "comments": "Poster session at the Bayesian Deep Learning Workshop - NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a novel framework that employs cluster annotation\nto boost active learning by reducing the number of human interactions required\nto train deep neural networks. Instead of annotating single samples\nindividually, humans can also label clusters, producing a higher number of\nannotated samples with the cost of a small label error. Our experiments show\nthat the proposed framework requires 82% and 87% less human interactions for\nCIFAR-10 and EuroSAT datasets respectively when compared with the\nfully-supervised training while maintaining similar performance on the test\nset.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 13:06:09 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 11:37:04 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Perez", "F\u00e1bio", ""], ["Lebret", "R\u00e9mi", ""], ["Aberer", "Karl", ""]]}, {"id": "1812.11794", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Ngoc Duy Nguyen, Saeid Nahavandi", "title": "Deep Reinforcement Learning for Multi-Agent Systems: A Review of\n  Challenges, Solutions and Applications", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, 20 March 2020", "doi": "10.1109/TCYB.2020.2977374", "report-no": "https://ieeexplore.ieee.org/document/9043893", "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms have been around for decades and\nemployed to solve various sequential decision-making problems. These algorithms\nhowever have faced great challenges when dealing with high-dimensional\nenvironments. The recent development of deep learning has enabled RL methods to\ndrive optimal policies for sophisticated and capable agents, which can perform\nefficiently in these challenging environments. This paper addresses an\nimportant aspect of deep RL related to situations that require multiple agents\nto communicate and cooperate to solve complex tasks. A survey of different\napproaches to problems related to multi-agent deep RL (MADRL) is presented,\nincluding non-stationarity, partial observability, continuous state and action\nspaces, multi-agent training schemes, multi-agent transfer learning. The merits\nand demerits of the reviewed methods will be analyzed and discussed, with their\ncorresponding applications explored. It is envisaged that this review provides\ninsights about various MADRL methods and can lead to future development of more\nrobust and highly useful multi-agent learning methods for solving real-world\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 13:39:54 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 13:21:20 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Ngoc Duy", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "1812.11797", "submitter": "Greg Stephens", "authors": "Katarzyna Bozek, Laetitia Hebert, Alexander S Mikheyev and Greg J\n  Stephens", "title": "Pixel personality for dense object tracking in a 2D honeybee hive", "comments": "13 pages, 4 main and 9 supplementary figures as well as a link to\n  supplementary movies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking large numbers of densely-arranged, interacting objects is\nchallenging due to occlusions and the resulting complexity of possible\ntrajectory combinations, as well as the sparsity of relevant, labeled datasets.\nHere we describe a novel technique of collective tracking in the model\nenvironment of a 2D honeybee hive in which sample colonies consist of\n$N\\sim10^3$ highly similar individuals, tightly packed, and in rapid, irregular\nmotion. Such a system offers universal challenges for multi-object tracking,\nwhile being conveniently accessible for image recording. We first apply an\naccurate, segmentation-based object detection method to build initial short\ntrajectory segments by matching object configurations based on class, position\nand orientation. We then join these tracks into full single object trajectories\nby creating an object recognition model which is adaptively trained to\nrecognize honeybee individuals through their visual appearance across multiple\nframes, an attribute we denote as pixel personality. Overall, we reconstruct\n~46% of the trajectories in 5 min recordings from two different hives and over\n71% of the tracks for at least 2 min. We provide validated trajectories\nspanning 3000 video frames of 876 unmarked moving bees in two distinct colonies\nin different locations and filmed with different pixel resolutions, which we\nexpect to be useful in the further development of general-purpose tracking\nsolutions.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 13:46:21 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Bozek", "Katarzyna", ""], ["Hebert", "Laetitia", ""], ["Mikheyev", "Alexander S", ""], ["Stephens", "Greg J", ""]]}, {"id": "1812.11806", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw, Marco Loog", "title": "An introduction to domain adaptation and transfer learning", "comments": "Technical Report. 41 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, if the training data is an unbiased sample of an\nunderlying distribution, then the learned classification function will make\naccurate predictions for new samples. However, if the training data is not an\nunbiased sample, then there will be differences between how the training data\nis distributed and how the test data is distributed. Standard classifiers\ncannot cope with changes in data distributions between training and test\nphases, and will not perform well. Domain adaptation and transfer learning are\nsub-fields within machine learning that are concerned with accounting for these\ntypes of changes. Here, we present an introduction to these fields, guided by\nthe question: when and how can a classifier generalize from a source to a\ntarget domain? We will start with a brief introduction into risk minimization,\nand how transfer learning and domain adaptation expand upon this framework.\nFollowing that, we discuss three special cases of data set shift, namely prior,\ncovariate and concept shift. For more complex domain shifts, there are a wide\nvariety of approaches. These are categorized into: importance-weighting,\nsubspace mapping, domain-invariant spaces, feature augmentation, minimax\nestimators and robust algorithms. A number of points will arise, which we will\ndiscuss in the last section. We conclude with the remark that many open\nquestions will have to be addressed before transfer learners and\ndomain-adaptive classifiers become practical.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 14:19:20 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 13:06:25 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Kouw", "Wouter M.", ""], ["Loog", "Marco", ""]]}, {"id": "1812.11832", "submitter": "Patrizio Frosini", "authors": "Mattia G. Bergomi, Patrizio Frosini, Daniela Giorgi, Nicola Quercioli", "title": "Towards a topological-geometrical theory of group equivariant\n  non-expansive operators for data analysis and machine learning", "comments": "Added references. Extended Section 7. Added 3 figures. Corrected\n  typos. 42 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.AT math.OA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to provide a general mathematical framework for\ngroup equivariance in the machine learning context. The framework builds on a\nsynergy between persistent homology and the theory of group actions. We define\ngroup-equivariant non-expansive operators (GENEOs), which are maps between\nfunction spaces associated with groups of transformations. We study the\ntopological and metric properties of the space of GENEOs to evaluate their\napproximating power and set the basis for general strategies to initialise and\ncompose operators. We begin by defining suitable pseudo-metrics for the\nfunction spaces, the equivariance groups, and the set of non-expansive\noperators. Basing on these pseudo-metrics, we prove that the space of GENEOs is\ncompact and convex, under the assumption that the function spaces are compact\nand convex. These results provide fundamental guarantees in a machine learning\nperspective. We show examples on the MNIST and fashion-MNIST datasets. By\nconsidering isometry-equivariant non-expansive operators, we describe a simple\nstrategy to select and sample operators, and show how the selected and sampled\noperators can be used to perform both classical metric learning and an\neffective initialisation of the kernels of a convolutional neural network.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 15:17:07 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 22:13:41 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 19:18:26 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Bergomi", "Mattia G.", ""], ["Frosini", "Patrizio", ""], ["Giorgi", "Daniela", ""], ["Quercioli", "Nicola", ""]]}, {"id": "1812.11856", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Latent Variable Modeling for Generative Concept Representations and Deep\n  Generative Models", "comments": "arXiv admin note: text overlap with arXiv:1706.00400 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent representations are the essence of deep generative models and\ndetermine their usefulness and power. For latent representations to be useful\nas generative concept representations, their latent space must support latent\nspace interpolation, attribute vectors and concept vectors, among other things.\nWe investigate and discuss latent variable modeling, including latent variable\nmodels, latent representations and latent spaces, particularly hierarchical\nlatent representations and latent space vectors and geometry. Our focus is on\nthat used in variational autoencoders and generative adversarial networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 20:09:02 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1812.11859", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, Jamal Atif, Rida Laraki", "title": "A discrete version of CMA-ES", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning uses more and more advanced optimization techniques\nto find optimal hyper parameters. Whenever the objective function is\nnon-convex, non continuous and with potentially multiple local minima, standard\ngradient descent optimization methods fail. A last resource and very different\nmethod is to assume that the optimum(s), not necessarily unique, is/are\ndistributed according to a distribution and iteratively to adapt the\ndistribution according to tested points. These strategies originated in the\nearly 1960s, named Evolution Strategy (ES) have culminated with the CMA-ES\n(Covariance Matrix Adaptation) ES. It relies on a multi variate normal\ndistribution and is supposed to be state of the art for general optimization\nprogram. However, it is far from being optimal for discrete variables. In this\npaper, we extend the method to multivariate binomial correlated distributions.\nFor such a distribution, we show that it shares similar features to the multi\nvariate normal: independence and correlation is equivalent and correlation is\nefficiently modeled by interaction between different variables. We discuss this\ndistribution in the framework of the exponential family. We prove that the\nmodel can estimate not only pairwise interactions among the two variables but\nalso is capable of modeling higher order interactions. This allows creating a\nversion of CMA ES that can accommodate efficiently discrete variables. We\nprovide the corresponding algorithm and conclude.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 23:21:47 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 19:59:07 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Benhamou", "Eric", ""], ["Atif", "Jamal", ""], ["Laraki", "Rida", ""]]}, {"id": "1812.11891", "submitter": "Weiyu Xu", "authors": "Weiyu Xu, Lifeng Lai, Amin Khajehnejad", "title": "How did Donald Trump Surprisingly Win the 2016 United States\n  Presidential Election? an Information-Theoretic Perspective (Clean Sensing\n  for Big Data Analytics:Optimal Strategies,Estimation Error Bounds Tighter\n  than the Cram\\'{e}r-Rao Bound)", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Donald Trump was lagging behind in nearly all opinion polls leading up to the\n2016 US presidential election, but he surprisingly won the election. This\nraises the following important questions: 1) why most opinion polls were not\naccurate in 2016? and 2) how to improve the accuracies of opinion polls? In\nthis paper, we study the inaccuracies of opinion polls in the 2016 election\nthrough the lens of information theory. We first propose a general framework of\nparameter estimation, called clean sensing (polling), which performs optimal\nparameter estimation with sensing cost constraints, from heterogeneous and\npotentially distorted data sources. We then cast the opinion polling as a\nproblem of parameter estimation from potentially distorted heterogeneous data\nsources, and derive the optimal polling strategy using heterogenous and\npossibly distorted data under cost constraints. Our results show that a larger\nnumber of data samples do not necessarily lead to better polling accuracy,\nwhich give a possible explanation of the inaccuracies of opinion polls in 2016.\nThe optimal sensing strategy should instead optimally allocate sensing\nresources over heterogenous data sources according to several factors including\ndata quality, and, moreover, for a particular data source, it should strike an\noptimal balance between the quality of data samples, and the quantity of data\nsamples.\n  As a byproduct of this research, in a general setting, we derive a group of\nnew lower bounds on the mean-squared errors of general unbiased and biased\nparameter estimators. These new lower bounds can be tighter than the classical\nCram\\'{e}r-Rao bound (CRB) and Chapman-Robbins bound. Our derivations are via\nstudying the Lagrange dual problems of certain convex programs. The classical\nCram\\'{e}r-Rao bound and Chapman-Robbins bound follow naturally from our\nresults for special cases of these convex programs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 16:41:10 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Xu", "Weiyu", ""], ["Lai", "Lifeng", ""], ["Khajehnejad", "Amin", ""]]}, {"id": "1812.11917", "submitter": "Dogyoon Song", "authors": "Devavrat Shah and Dogyoon Song", "title": "Learning RUMs: Reducing Mixture to Single Component via PCA", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a mixture of Random Utility Models\n(RUMs). Despite the success of RUMs in various domains and the versatility of\nmixture RUMs to capture the heterogeneity in preferences, there has been only\nlimited progress in learning a mixture of RUMs from partial data such as\npairwise comparisons. In contrast, there have been significant advances in\nterms of learning a single component RUM using pairwise comparisons. In this\npaper, we aim to bridge this gap between mixture learning and single component\nlearning of RUM by developing a `reduction' procedure. We propose to utilize\nPCA-based spectral clustering that simultaneously `de-noises' pairwise\ncomparison data. We prove that our algorithm manages to cluster the partial\ndata correctly (i.e., comparisons from the same RUM component are grouped in\nthe same cluster) with high probability even when data is generated from a\npossibly {\\em heterogeneous} mixture of well-separated {\\em generic} RUMs. Both\nthe time and the sample complexities scale polynomially in model parameters\nincluding the number of items. Two key features in the analysis are in\nestablishing (1) a meaningful upper bound on the sub-Gaussian norm for RUM\ncomponents embedded into the vector space of pairwise marginals and (2) the\nrobustness of PCA with missing values in the $L_{2, \\infty}$ sense, which might\nbe of interest in their own right.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 17:49:58 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 22:36:43 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 03:22:16 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Shah", "Devavrat", ""], ["Song", "Dogyoon", ""]]}, {"id": "1812.11946", "submitter": "Antonio Miguel", "authors": "Antonio Miguel, Jorge Llombart, Alfonso Ortega, Eduardo Lleida", "title": "Tied Hidden Factors in Neural Networks for End-to-End Speaker\n  Recognition", "comments": null, "journal-ref": "Proc. Interspeech 2017, 2819-2823", "doi": "10.21437/Interspeech.2017-1314", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a method to model speaker and session variability\nand able to generate likelihood ratios using neural networks in an end-to-end\nphrase dependent speaker verification system. As in Joint Factor Analysis, the\nmodel uses tied hidden variables to model speaker and session variability and a\nMAP adaptation of some of the parameters of the model. In the training\nprocedure our method jointly estimates the network parameters and the values of\nthe speaker and channel hidden variables. This is done in a two-step\nbackpropagation algorithm, first the network weights and factor loading\nmatrices are updated and then the hidden variables, whose gradients are\ncalculated by aggregating the corresponding speaker or session frames, since\nthese hidden variables are tied. The last layer of the network is defined as a\nlinear regression probabilistic model whose inputs are the previous layer\noutputs. This choice has the advantage that it produces likelihoods and\nadditionally it can be adapted during the enrolment using MAP without the need\nof a gradient optimization. The decisions are made based on the ratio of the\noutput likelihoods of two neural network models, speaker adapted and universal\nbackground model. The method was evaluated on the RSR2015 database.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 17:07:12 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Miguel", "Antonio", ""], ["Llombart", "Jorge", ""], ["Ortega", "Alfonso", ""], ["Lleida", "Eduardo", ""]]}, {"id": "1812.11951", "submitter": "Danny Stoll", "authors": "Frederic Runge, Danny Stoll, Stefan Falkner, Frank Hutter", "title": "Learning to Design RNA", "comments": "Published as a conference paper at the International Conference on\n  Learning Representations 2019 (ICLR19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing RNA molecules has garnered recent interest in medicine, synthetic\nbiology, biotechnology and bioinformatics since many functional RNA molecules\nwere shown to be involved in regulatory processes for transcription,\nepigenetics and translation. Since an RNA's function depends on its structural\nproperties, the RNA Design problem is to find an RNA sequence which satisfies\ngiven structural constraints. Here, we propose a new algorithm for the RNA\nDesign problem, dubbed LEARNA. LEARNA uses deep reinforcement learning to train\na policy network to sequentially design an entire RNA sequence given a\nspecified target structure. By meta-learning across 65000 different RNA Design\ntasks for one hour on 20 CPU cores, our extension Meta-LEARNA constructs an RNA\nDesign policy that can be applied out of the box to solve novel RNA Design\ntasks. Methodologically, for what we believe to be the first time, we jointly\noptimize over a rich space of architectures for the policy network, the\nhyperparameters of the training procedure and the formulation of the decision\nprocess. Comprehensive empirical results on two widely-used RNA Design\nbenchmarks, as well as a third one that we introduce, show that our approach\nachieves new state-of-the-art performance on the former while also being orders\nof magnitudes faster in reaching the previous state-of-the-art performance. In\nan ablation study, we analyze the importance of our method's different\ncomponents.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:45:51 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 16:11:05 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Runge", "Frederic", ""], ["Stoll", "Danny", ""], ["Falkner", "Stefan", ""], ["Hutter", "Frank", ""]]}, {"id": "1812.11954", "submitter": "Qiang Sun", "authors": "Anna Little, Yuying Xie, Qiang Sun", "title": "Exact Cluster Recovery via Classical Multidimensional Scaling", "comments": "42 pages in cluding appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical multidimensional scaling is an important dimension reduction\ntechnique. Yet few theoretical results characterizing its statistical\nperformance exist. This paper provides a theoretical framework for analyzing\nthe quality of embedded samples produced by classical multidimensional scaling.\nThis lays the foundation for various downstream statistical analyses, and we\nfocus on clustering noisy data. Our results provide scaling conditions on the\nsample size, ambient dimensionality, between-class distance, and noise level\nunder which classical multidimensional scaling followed by a distance-based\nclustering algorithm can recover the cluster labels of all samples with high\nprobability. Numerical simulations confirm these scaling conditions are\nnear-sharp. Applications to both human genomics data and natural language data\nlend strong support to the methodology and theory.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:48:33 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 23:37:57 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 05:28:28 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 03:16:10 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Little", "Anna", ""], ["Xie", "Yuying", ""], ["Sun", "Qiang", ""]]}, {"id": "1812.11958", "submitter": "Shakiba Yaghoubi", "authors": "Shakiba Yaghoubi, Georgios Fainekos", "title": "Gray-box Adversarial Testing for Control Systems with Machine Learning\n  Component", "comments": "11 pages, 5 figures, 1 table, International Conference on Hybrid\n  Systems: Computation and Control (HSSC) 2019, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NN) have been proposed in the past as an effective means for\nboth modeling and control of systems with very complex dynamics. However,\ndespite the extensive research, NN-based controllers have not been adopted by\nthe industry for safety critical systems. The primary reason is that systems\nwith learning based controllers are notoriously hard to test and verify. Even\nharder is the analysis of such systems against system-level specifications. In\nthis paper, we provide a gradient based method for searching the input space of\na closed-loop control system in order to find adversarial samples against some\nsystem-level requirements. Our experimental results show that combined with\nrandomized search, our method outperforms Simulated Annealing optimization.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:55:17 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Yaghoubi", "Shakiba", ""], ["Fainekos", "Georgios", ""]]}]